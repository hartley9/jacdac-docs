/******/ (() => { // webpackBootstrap
/******/ 	"use strict";
var __webpack_exports__ = {};
function _extends(){return(_extends=Object.assign||function(e){for(var t=1;t<arguments.length;t++){var n=arguments[t];for(var r in n)Object.prototype.hasOwnProperty.call(n,r)&&(e[r]=n[r])}return e}).apply(this,arguments)}function _objectWithoutPropertiesLoose(e,t){if(null==e)return{};var n,r,a={},s=Object.keys(e);for(r=0;r<s.length;r++)t.indexOf(n=s[r])>=0||(a[n]=e[n]);return a}const EPSILON_FLOAT32$3=1e-7,EPSILON_FLOAT16$3=1e-4;class DataStorage$1{constructor(e,t){this.backend=e,this.dataMover=t,this.data=new WeakMap,this.dataIdsCount=0}get(e){return this.data.has(e)||this.dataMover.moveData(this.backend,e),this.data.get(e)}set(e,t){this.dataIdsCount++,this.data.set(e,t)}has(e){return this.data.has(e)}delete(e){return this.dataIdsCount--,this.data.delete(e)}numDataIds(){return this.dataIdsCount}}class KernelBackend$1{refCount(e){return notYetImplemented$1("refCount")}incRef(e){return notYetImplemented$1("incRef")}timerAvailable(){return!0}time(e){return notYetImplemented$1("time")}read(e){return notYetImplemented$1("read")}readSync(e){return notYetImplemented$1("readSync")}numDataIds(){return notYetImplemented$1("numDataIds")}disposeData(e,t){return notYetImplemented$1("disposeData")}write(e,t,n){return notYetImplemented$1("write")}move(e,t,n,r,a){return notYetImplemented$1("move")}memory(){return notYetImplemented$1("memory")}floatPrecision(){return notYetImplemented$1("floatPrecision")}epsilon(){return 32===this.floatPrecision()?EPSILON_FLOAT32$3:EPSILON_FLOAT16$3}dispose(){return notYetImplemented$1("dispose")}}function notYetImplemented$1(e){throw new Error(`'${e}' not yet implemented or not found in the registry. This kernel may not be supported by the tfjs backend you have chosen`)}function shuffle$1(e){let t=e.length,n=0;for(;t>0;)n=Math.random()*t|0,t--,swap$1(e,t,n)}function clamp$1(e,t,n){return Math.max(e,Math.min(t,n))}function nearestLargerEven$1(e){return e%2==0?e:e+1}function swap$1(e,t,n){const r=e[t];e[t]=e[n],e[n]=r}function sum$7(e){let t=0;for(let n=0;n<e.length;n++)t+=e[n];return t}function assert$6(e,t){if(!e)throw new Error("string"==typeof t?t:t())}function assertShapesMatch$1(e,t,n=""){assert$6(arraysEqual$1(e,t),()=>n+` Shapes ${e} and ${t} must match`)}function assertNonNull$1(e){assert$6(null!=e,()=>"The input to the tensor constructor must be a non-null value.")}function flatten$6(e,t=[],n=!1){if(null==t&&(t=[]),Array.isArray(e)||isTypedArray$1(e)&&!n)for(let r=0;r<e.length;++r)flatten$6(e[r],t,n);else t.push(e);return t}function sizeFromShape$1(e){if(0===e.length)return 1;let t=e[0];for(let n=1;n<e.length;n++)t*=e[n];return t}function arraysEqual$1(e,t){if(e===t)return!0;if(null==e||null==t)return!1;if(e.length!==t.length)return!1;for(let n=0;n<e.length;n++)if(e[n]!==t[n])return!1;return!0}function isInt$1(e){return e%1==0}function sizeToSquarishShape$1(e){const t=Math.ceil(Math.sqrt(e));return[t,Math.ceil(e/t)]}function rightPad$1(e,t){return t<=e.length?e:e+" ".repeat(t-e.length)}function repeatedTry$1(e,t=(e=>0),n){return new Promise((r,a)=>{let s=0;const o=()=>{if(e())return void r();s++;const i=t(s);null!=n&&s>=n?a():setTimeout(o,i)};o()})}function inferFromImplicitShape$1(e,t){let n=1,r=-1;for(let t=0;t<e.length;++t)if(e[t]>=0)n*=e[t];else if(-1===e[t]){if(-1!==r)throw Error(`Shapes can only have 1 implicit size. Found -1 at dim ${r} and dim ${t}`);r=t}else if(e[t]<0)throw Error(`Shapes can not be < 0. Found ${e[t]} at dim ${t}`);if(-1===r){if(t>0&&t!==n)throw Error(`Size(${t}) must match the product of shape ${e}`);return e}if(0===n)throw Error(`Cannot infer the missing size in [${e}] when there are 0 elements`);if(t%n!=0)throw Error(`The implicit shape can't be a fractional number. Got ${t} / ${n}`);const a=e.slice();return a[r]=t/n,a}function parseAxisParam$1(e,t){const n=t.length;return assert$6((e=null==e?t.map((e,t)=>t):[].concat(e)).every(e=>e>=-n&&e<n),()=>`All values in axis param must be in range [-${n}, ${n}) but got axis ${e}`),assert$6(e.every(e=>isInt$1(e)),()=>`All values in axis param must be integers but got axis ${e}`),e.map(e=>e<0?n+e:e)}function squeezeShape$1(e,t){const n=[],r=[],a=null!=t&&Array.isArray(t)&&0===t.length,s=null==t||a?null:parseAxisParam$1(t,e).sort();let o=0;for(let t=0;t<e.length;++t){if(null!=s){if(s[o]===t&&1!==e[t])throw new Error(`Can't squeeze axis ${t} since its dim '${e[t]}' is not 1`);(null==s[o]||s[o]>t)&&1===e[t]&&(n.push(e[t]),r.push(t)),s[o]<=t&&o++}1!==e[t]&&(n.push(e[t]),r.push(t))}return{newShape:n,keptDims:r}}function getTypedArrayFromDType$1(e,t){let n=null;if(null==e||"float32"===e)n=new Float32Array(t);else if("int32"===e)n=new Int32Array(t);else{if("bool"!==e)throw new Error(`Unknown data type ${e}`);n=new Uint8Array(t)}return n}function getArrayFromDType$1(e,t){let n=null;if(null==e||"float32"===e)n=new Float32Array(t);else if("int32"===e)n=new Int32Array(t);else if("bool"===e)n=new Uint8Array(t);else{if("string"!==e)throw new Error(`Unknown data type ${e}`);n=new Array(t)}return n}function checkConversionForErrors$1(e,t){for(let n=0;n<e.length;n++){const r=e[n];if(isNaN(r)||!isFinite(r))throw Error(`A tensor of type ${t} being uploaded contains ${r}.`)}}function isValidDtype$1(e){return"bool"===e||"complex64"===e||"float32"===e||"int32"===e||"string"===e}function hasEncodingLoss$1(e,t){return!("complex64"===t||"float32"===t&&"complex64"!==e||"int32"===t&&"float32"!==e&&"complex64"!==e||"bool"===t&&"bool"===e)}function isTypedArray$1(e){return e instanceof Float32Array||e instanceof Int32Array||e instanceof Uint8Array}function bytesPerElement$1(e){if("float32"===e||"int32"===e)return 4;if("complex64"===e)return 8;if("bool"===e)return 1;throw new Error(`Unknown dtype ${e}`)}function bytesFromStringArray$1(e){if(null==e)return 0;let t=0;return e.forEach(e=>t+=e.length),t}function isString$1(e){return"string"==typeof e||e instanceof String}function isBoolean$1(e){return"boolean"==typeof e}function isNumber$1(e){return"number"==typeof e}function inferDtype$1(e){return Array.isArray(e)?inferDtype$1(e[0]):e instanceof Float32Array?"float32":e instanceof Int32Array||e instanceof Uint8Array?"int32":isNumber$1(e)?"float32":isString$1(e)?"string":isBoolean$1(e)?"bool":"float32"}function isFunction$1(e){return!!(e&&e.constructor&&e.call&&e.apply)}function nearestDivisor$1(e,t){for(let n=t;n<e;++n)if(e%n==0)return n;return e}function computeStrides$1(e){const t=e.length;if(t<2)return[];const n=new Array(t-1);n[t-2]=e[t-1];for(let r=t-3;r>=0;--r)n[r]=n[r+1]*e[r+1];return n}function createNestedArray$1(e,t,n,r=!1){const a=new Array;if(1===t.length){const s=t[0]*(r?2:1);for(let t=0;t<s;t++)a[t]=n[e+t]}else{const s=t[0],o=t.slice(1),i=o.reduce((e,t)=>e*t)*(r?2:1);for(let t=0;t<s;t++)a[t]=createNestedArray$1(e+t*i,o,n,r)}return a}function toNestedArray$1(e,t,n=!1){if(0===e.length)return t[0];const r=e.reduce((e,t)=>e*t)*(n?2:1);if(0===r)return[];if(r!==t.length)throw new Error(`[${e}] does not match the input size ${t.length}${n?" for a complex tensor":""}.`);return createNestedArray$1(0,e,t,n)}function makeOnesTypedArray$1(e,t){const n=makeZerosTypedArray$1(e,t);for(let e=0;e<n.length;e++)n[e]=1;return n}function makeZerosTypedArray$1(e,t){if(null==t||"float32"===t||"complex64"===t)return new Float32Array(e);if("int32"===t)return new Int32Array(e);if("bool"===t)return new Uint8Array(e);throw new Error(`Unknown data type ${t}`)}function makeZerosNestedTypedArray$1(e,t){const n=e.reduce((e,t)=>e*t,1);if(null==t||"float32"===t)return toNestedArray$1(e,new Float32Array(n));if("int32"===t)return toNestedArray$1(e,new Int32Array(n));if("bool"===t)return toNestedArray$1(e,new Uint8Array(n));throw new Error(`Unknown data type ${t}`)}function assertNonNegativeIntegerDimensions$1(e){e.forEach(t=>{assert$6(Number.isInteger(t)&&t>=0,()=>`Tensor must have a shape comprised of positive integers but got shape [${e}].`)})}function locToIndex$1(e,t,n){if(0===t)return 0;if(1===t)return e[0];let r=e[e.length-1];for(let t=0;t<e.length-1;++t)r+=n[t]*e[t];return r}function indexToLoc$1(e,t,n){if(0===t)return[];if(1===t)return[e];const r=new Array(t);for(let t=0;t<r.length-1;++t)r[t]=Math.floor(e/n[t]),e-=r[t]*n[t];return r[r.length-1]=e,r}function isPromise$1(e){return e&&e.then&&"function"==typeof e.then}const TENSORFLOWJS_FLAGS_PREFIX$1="tfjsflags";class Environment$1{constructor(e){this.global=e,this.flags={},this.flagRegistry={},this.urlFlags={},this.getQueryParams=getQueryParams$1,this.populateURLFlags()}setPlatform(e,t){null!=this.platform&&console.warn(`Platform ${this.platformName} has already been set. Overwriting the platform with ${t}.`),this.platformName=e,this.platform=t}registerFlag(e,t,n){if(this.flagRegistry[e]={evaluationFn:t,setHook:n},null!=this.urlFlags[e]){const t=this.urlFlags[e];console.warn(`Setting feature override from URL ${e}: ${t}.`),this.set(e,t)}}async getAsync(e){return e in this.flags||(this.flags[e]=await this.evaluateFlag(e)),this.flags[e]}get(e){if(e in this.flags)return this.flags[e];const t=this.evaluateFlag(e);if(isPromise$1(t))throw new Error(`Flag ${e} cannot be synchronously evaluated. Please use getAsync() instead.`);return this.flags[e]=t,this.flags[e]}getNumber(e){return this.get(e)}getBool(e){return this.get(e)}getFlags(){return this.flags}get features(){return this.flags}set(e,t){if(null==this.flagRegistry[e])throw new Error(`Cannot set flag ${e} as it has not been registered.`);this.flags[e]=t,null!=this.flagRegistry[e].setHook&&this.flagRegistry[e].setHook(t)}evaluateFlag(e){if(null==this.flagRegistry[e])throw new Error(`Cannot evaluate flag '${e}': no evaluation function found.`);return this.flagRegistry[e].evaluationFn()}setFlags(e){this.flags=Object.assign({},e)}reset(){this.flags={},this.urlFlags={},this.populateURLFlags()}populateURLFlags(){if(void 0===this.global||void 0===this.global.location||void 0===this.global.location.search)return;const e=this.getQueryParams(this.global.location.search);TENSORFLOWJS_FLAGS_PREFIX$1 in e&&e[TENSORFLOWJS_FLAGS_PREFIX$1].split(",").forEach(e=>{const[t,n]=e.split(":");this.urlFlags[t]=parseValue$1(t,n)})}}function getQueryParams$1(e){const t={};return e.replace(/[?&]([^=?&]+)(?:=([^&]*))?/g,(e,...n)=>(decodeParam$1(t,n[0],n[1]),n.join("="))),t}function decodeParam$1(e,t,n){e[decodeURIComponent(t)]=decodeURIComponent(n||"")}function parseValue$1(e,t){if("true"===(t=t.toLowerCase())||"false"===t)return"true"===t;if(""+ +t===t)return+t;throw new Error(`Could not parse value flag value ${t} for flag ${e}.`)}function env$1(){return ENV$5}let ENV$5=null,globalNameSpace$1;function setEnvironmentGlobal$1(e){ENV$5=e}function getGlobalNamespace$1(){if(null==globalNameSpace$1){let e;if("undefined"!=typeof window)e=window;else if("undefined"!=typeof global)e=global;else if("undefined"!=typeof process)e=process;else{if("undefined"==typeof self)throw new Error("Could not find a global object");e=self}globalNameSpace$1=e}return globalNameSpace$1}function getGlobalMap$1(){const e=getGlobalNamespace$1();return null==e._tfGlobals&&(e._tfGlobals=new Map),e._tfGlobals}function getGlobal$1(e,t){const n=getGlobalMap$1();if(n.has(e))return n.get(e);{const r=t();return n.set(e,r),n.get(e)}}const Abs$1="Abs",Acos$1="Acos",Acosh$1="Acosh",Add$3="Add",AddN$1="AddN",All$1="All",Any$1="Any",ArgMax$1="ArgMax",ArgMin$1="ArgMin",Asin$1="Asin",Asinh$1="Asinh",Atan$1="Atan",Atanh$1="Atanh",Atan2$1="Atan2",AvgPool$1="AvgPool",AvgPoolGrad$1="AvgPoolGrad",AvgPool3D$1="AvgPool3D",AvgPool3DGrad$1="AvgPool3DGrad",BatchMatMul$1="BatchMatMul",BatchToSpaceND$1="BatchToSpaceND",Bincount$1="Bincount",BroadcastTo$1="BroadcastTo",Cast$1="Cast",Ceil$1="Ceil",ClipByValue$1="ClipByValue",Complex$1="Complex",ComplexAbs$1="ComplexAbs",Concat$1="Concat",Conv2D$3="Conv2D",Conv2DBackpropFilter$1="Conv2DBackpropFilter",Conv2DBackpropInput$1="Conv2DBackpropInput",Conv3D$3="Conv3D",Conv3DBackpropFilterV2$1="Conv3DBackpropFilterV2",Conv3DBackpropInputV2$1="Conv3DBackpropInputV2",Cos$1="Cos",Cosh$1="Cosh",Cumsum$1="Cumsum",CropAndResize$1="CropAndResize",DenseBincount$1="DenseBincount",DepthToSpace$1="DepthToSpace",DepthwiseConv2dNative$1="DepthwiseConv2dNative",DepthwiseConv2dNativeBackpropFilter$1="DepthwiseConv2dNativeBackpropFilter",DepthwiseConv2dNativeBackpropInput$1="DepthwiseConv2dNativeBackpropInput",Diag$1="Diag",Dilation2D$1="Dilation2D",Dilation2DBackpropInput$1="Dilation2DBackpropInput",Dilation2DBackpropFilter$1="Dilation2DBackpropFilter",RealDiv$1="RealDiv",Einsum$1="Einsum",Elu$3="Elu",EluGrad$1="EluGrad",Erf$1="Erf",Equal$1="Equal",Exp$1="Exp",ExpandDims$1="ExpandDims",Expm1$1="Expm1",FFT$1="FFT",Fill$1="Fill",FlipLeftRight$1="FlipLeftRight",Floor$1="Floor",FloorDiv$1="FloorDiv",FusedBatchNorm$1="FusedBatchNorm",GatherV2$1="GatherV2",GatherNd$1="GatherNd",Greater$1="Greater",GreaterEqual$1="GreaterEqual",Identity$3="Identity",IFFT$1="IFFT",Imag$1="Imag",IsFinite$1="IsFinite",IsInf$1="IsInf",IsNan$1="IsNan",LeakyRelu$1="LeakyRelu",Less$1="Less",LessEqual$1="LessEqual",LinSpace$1="LinSpace",Log$1="Log",Log1p$1="Log1p",LogicalAnd$1="LogicalAnd",LogicalNot$1="LogicalNot",LogicalOr$1="LogicalOr",LogSoftmax$3="LogSoftmax",LRN$1="LRN",LRNGrad$1="LRNGrad",Max$1="Max",Maximum$3="Maximum",MaxPool$1="MaxPool",MaxPoolGrad$1="MaxPoolGrad",MaxPool3D$1="MaxPool3D",MaxPool3DGrad$1="MaxPool3DGrad",MaxPoolWithArgmax$1="MaxPoolWithArgmax",Mean$1="Mean",Min$1="Min",Minimum$3="Minimum",MirrorPad$1="MirrorPad",Mod$1="Mod",Multinomial$1="Multinomial",Multiply$3="Multiply",Neg$1="Neg",NotEqual$1="NotEqual",NonMaxSuppressionV3$1="NonMaxSuppressionV3",NonMaxSuppressionV4$1="NonMaxSuppressionV4",NonMaxSuppressionV5$1="NonMaxSuppressionV5",OnesLike$1="OnesLike",OneHot$1="OneHot",Pack$1="Pack",PadV2$1="PadV2",Pow$1="Pow",Prelu$1="Prelu",Prod$1="Prod",Range$1="Range",Real$1="Real",Reciprocal$1="Reciprocal",Relu$3="Relu",Reshape$3="Reshape",ResizeNearestNeighbor$1="ResizeNearestNeighbor",ResizeNearestNeighborGrad$1="ResizeNearestNeighborGrad",ResizeBilinear$1="ResizeBilinear",ResizeBilinearGrad$1="ResizeBilinearGrad",Relu6$3="Relu6",Reverse$1="Reverse",Round$1="Round",Rsqrt$1="Rsqrt",ScatterNd$1="ScatterNd",Select$1="Select",Selu$3="Selu",Slice$1="Slice",Sin$1="Sin",Sinh$1="Sinh",Sign$1="Sign",Sigmoid$3="Sigmoid",Softplus$3="Softplus",Sqrt$1="Sqrt",Sum$1="Sum",SpaceToBatchND$1="SpaceToBatchND",SplitV$1="SplitV",Softmax$5="Softmax",SparseFillEmptyRows$1="SparseFillEmptyRows",SparseReshape$1="SparseReshape",SparseSegmentMean$1="SparseSegmentMean",SparseSegmentSum$1="SparseSegmentSum",SparseToDense$1="SparseToDense",SquaredDifference$1="SquaredDifference",Square$1="Square",StridedSlice$1="StridedSlice",StringNGrams$1="StringNGrams",StringSplit$1="StringSplit",StringToHashBucketFast$1="StringToHashBucketFast",Sub$1="Sub",Tan$1="Tan",Tanh$3="Tanh",Tile$1="Tile",TopK$1="TopK",Transform$1="Transform",Transpose$1="Transpose",Unique$1="Unique",Unpack$1="Unpack",UnsortedSegmentSum$1="UnsortedSegmentSum",ZerosLike$1="ZerosLike",Step$1="Step",FromPixels$1="FromPixels",RotateWithOffset$1="RotateWithOffset",_FusedMatMul$1="_FusedMatMul",FusedConv2D$1="FusedConv2D",FusedDepthwiseConv2D$1="FusedDepthwiseConv2D",kernelRegistry$1=getGlobal$1("kernelRegistry",()=>new Map),gradRegistry$1=getGlobal$1("gradRegistry",()=>new Map);function getKernel$1(e,t){const n=makeKey$1(e,t);return kernelRegistry$1.get(n)}function getGradient$1(e){return gradRegistry$1.get(e)}function getKernelsForBackend$1(e){const t=kernelRegistry$1.entries(),n=[];for(;;){const{done:r,value:a}=t.next();if(r)break;const[s,o]=a,[i]=s.split("_");i===e&&n.push(o)}return n}function registerKernel$1(e){const{kernelName:t,backendName:n}=e,r=makeKey$1(t,n);kernelRegistry$1.has(r)&&console.warn(`The kernel '${t}' for backend '${n}' is already registered`),kernelRegistry$1.set(r,e)}function registerGradient$1(e){const{kernelName:t}=e;gradRegistry$1.has(t)&&env$1().getBool("DEBUG")&&console.warn(`Overriding the gradient for '${t}'`),gradRegistry$1.set(t,e)}function makeKey$1(e,t){return`${t}_${e}`}var long$2=Long$3,wasm$1=null;try{wasm$1=new WebAssembly.Instance(new WebAssembly.Module(new Uint8Array([0,97,115,109,1,0,0,0,1,13,2,96,0,1,127,96,4,127,127,127,127,1,127,3,7,6,0,1,1,1,1,1,6,6,1,127,1,65,0,11,7,50,6,3,109,117,108,0,1,5,100,105,118,95,115,0,2,5,100,105,118,95,117,0,3,5,114,101,109,95,115,0,4,5,114,101,109,95,117,0,5,8,103,101,116,95,104,105,103,104,0,0,10,191,1,6,4,0,35,0,11,36,1,1,126,32,0,173,32,1,173,66,32,134,132,32,2,173,32,3,173,66,32,134,132,126,34,4,66,32,135,167,36,0,32,4,167,11,36,1,1,126,32,0,173,32,1,173,66,32,134,132,32,2,173,32,3,173,66,32,134,132,127,34,4,66,32,135,167,36,0,32,4,167,11,36,1,1,126,32,0,173,32,1,173,66,32,134,132,32,2,173,32,3,173,66,32,134,132,128,34,4,66,32,135,167,36,0,32,4,167,11,36,1,1,126,32,0,173,32,1,173,66,32,134,132,32,2,173,32,3,173,66,32,134,132,129,34,4,66,32,135,167,36,0,32,4,167,11,36,1,1,126,32,0,173,32,1,173,66,32,134,132,32,2,173,32,3,173,66,32,134,132,130,34,4,66,32,135,167,36,0,32,4,167,11])),{}).exports}catch(e){}function Long$3(e,t,n){this.low=0|e,this.high=0|t,this.unsigned=!!n}function isLong$1(e){return!0===(e&&e.__isLong__)}Object.defineProperty(Long$3.prototype,"__isLong__",{value:!0}),Long$3.isLong=isLong$1;var INT_CACHE$1={},UINT_CACHE$1={};function fromInt$1(e,t){var n,r,a;return t?(a=0<=(e>>>=0)&&e<256)&&(r=UINT_CACHE$1[e])?r:(n=fromBits$1(e,(0|e)<0?-1:0,!0),a&&(UINT_CACHE$1[e]=n),n):(a=-128<=(e|=0)&&e<128)&&(r=INT_CACHE$1[e])?r:(n=fromBits$1(e,e<0?-1:0,!1),a&&(INT_CACHE$1[e]=n),n)}function fromNumber$1(e,t){if(isNaN(e))return t?UZERO$1:ZERO$1;if(t){if(e<0)return UZERO$1;if(e>=TWO_PWR_64_DBL$1)return MAX_UNSIGNED_VALUE$1}else{if(e<=-TWO_PWR_63_DBL$1)return MIN_VALUE$1;if(e+1>=TWO_PWR_63_DBL$1)return MAX_VALUE$1}return e<0?fromNumber$1(-e,t).neg():fromBits$1(e%TWO_PWR_32_DBL$1|0,e/TWO_PWR_32_DBL$1|0,t)}function fromBits$1(e,t,n){return new Long$3(e,t,n)}Long$3.fromInt=fromInt$1,Long$3.fromNumber=fromNumber$1,Long$3.fromBits=fromBits$1;var pow_dbl$1=Math.pow;function fromString$1(e,t,n){if(0===e.length)throw Error("empty string");if("NaN"===e||"Infinity"===e||"+Infinity"===e||"-Infinity"===e)return ZERO$1;if("number"==typeof t?(n=t,t=!1):t=!!t,(n=n||10)<2||36<n)throw RangeError("radix");var r;if((r=e.indexOf("-"))>0)throw Error("interior hyphen");if(0===r)return fromString$1(e.substring(1),t,n).neg();for(var a=fromNumber$1(pow_dbl$1(n,8)),s=ZERO$1,o=0;o<e.length;o+=8){var i=Math.min(8,e.length-o),l=parseInt(e.substring(o,o+i),n);if(i<8){var u=fromNumber$1(pow_dbl$1(n,i));s=s.mul(u).add(fromNumber$1(l))}else s=(s=s.mul(a)).add(fromNumber$1(l))}return s.unsigned=t,s}function fromValue$1(e,t){return"number"==typeof e?fromNumber$1(e,t):"string"==typeof e?fromString$1(e,t):fromBits$1(e.low,e.high,"boolean"==typeof t?t:e.unsigned)}Long$3.fromString=fromString$1,Long$3.fromValue=fromValue$1;var TWO_PWR_16_DBL$1=65536,TWO_PWR_24_DBL$1=1<<24,TWO_PWR_32_DBL$1=TWO_PWR_16_DBL$1*TWO_PWR_16_DBL$1,TWO_PWR_64_DBL$1=TWO_PWR_32_DBL$1*TWO_PWR_32_DBL$1,TWO_PWR_63_DBL$1=TWO_PWR_64_DBL$1/2,TWO_PWR_24$1=fromInt$1(TWO_PWR_24_DBL$1),ZERO$1=fromInt$1(0);Long$3.ZERO=ZERO$1;var UZERO$1=fromInt$1(0,!0);Long$3.UZERO=UZERO$1;var ONE$1=fromInt$1(1);Long$3.ONE=ONE$1;var UONE$1=fromInt$1(1,!0);Long$3.UONE=UONE$1;var NEG_ONE$1=fromInt$1(-1);Long$3.NEG_ONE=NEG_ONE$1;var MAX_VALUE$1=fromBits$1(-1,2147483647,!1);Long$3.MAX_VALUE=MAX_VALUE$1;var MAX_UNSIGNED_VALUE$1=fromBits$1(-1,-1,!0);Long$3.MAX_UNSIGNED_VALUE=MAX_UNSIGNED_VALUE$1;var MIN_VALUE$1=fromBits$1(0,-2147483648,!1);Long$3.MIN_VALUE=MIN_VALUE$1;var LongPrototype$1=Long$3.prototype;LongPrototype$1.toInt=function(){return this.unsigned?this.low>>>0:this.low},LongPrototype$1.toNumber=function(){return this.unsigned?(this.high>>>0)*TWO_PWR_32_DBL$1+(this.low>>>0):this.high*TWO_PWR_32_DBL$1+(this.low>>>0)},LongPrototype$1.toString=function(e){if((e=e||10)<2||36<e)throw RangeError("radix");if(this.isZero())return"0";if(this.isNegative()){if(this.eq(MIN_VALUE$1)){var t=fromNumber$1(e),n=this.div(t),r=n.mul(t).sub(this);return n.toString(e)+r.toInt().toString(e)}return"-"+this.neg().toString(e)}for(var a=fromNumber$1(pow_dbl$1(e,6),this.unsigned),s=this,o="";;){var i=s.div(a),l=(s.sub(i.mul(a)).toInt()>>>0).toString(e);if((s=i).isZero())return l+o;for(;l.length<6;)l="0"+l;o=""+l+o}},LongPrototype$1.getHighBits=function(){return this.high},LongPrototype$1.getHighBitsUnsigned=function(){return this.high>>>0},LongPrototype$1.getLowBits=function(){return this.low},LongPrototype$1.getLowBitsUnsigned=function(){return this.low>>>0},LongPrototype$1.getNumBitsAbs=function(){if(this.isNegative())return this.eq(MIN_VALUE$1)?64:this.neg().getNumBitsAbs();for(var e=0!=this.high?this.high:this.low,t=31;t>0&&0==(e&1<<t);t--);return 0!=this.high?t+33:t+1},LongPrototype$1.isZero=function(){return 0===this.high&&0===this.low},LongPrototype$1.eqz=LongPrototype$1.isZero,LongPrototype$1.isNegative=function(){return!this.unsigned&&this.high<0},LongPrototype$1.isPositive=function(){return this.unsigned||this.high>=0},LongPrototype$1.isOdd=function(){return 1==(1&this.low)},LongPrototype$1.isEven=function(){return 0==(1&this.low)},LongPrototype$1.equals=function(e){return isLong$1(e)||(e=fromValue$1(e)),(this.unsigned===e.unsigned||this.high>>>31!=1||e.high>>>31!=1)&&this.high===e.high&&this.low===e.low},LongPrototype$1.eq=LongPrototype$1.equals,LongPrototype$1.notEquals=function(e){return!this.eq(e)},LongPrototype$1.neq=LongPrototype$1.notEquals,LongPrototype$1.ne=LongPrototype$1.notEquals,LongPrototype$1.lessThan=function(e){return this.comp(e)<0},LongPrototype$1.lt=LongPrototype$1.lessThan,LongPrototype$1.lessThanOrEqual=function(e){return this.comp(e)<=0},LongPrototype$1.lte=LongPrototype$1.lessThanOrEqual,LongPrototype$1.le=LongPrototype$1.lessThanOrEqual,LongPrototype$1.greaterThan=function(e){return this.comp(e)>0},LongPrototype$1.gt=LongPrototype$1.greaterThan,LongPrototype$1.greaterThanOrEqual=function(e){return this.comp(e)>=0},LongPrototype$1.gte=LongPrototype$1.greaterThanOrEqual,LongPrototype$1.ge=LongPrototype$1.greaterThanOrEqual,LongPrototype$1.compare=function(e){if(isLong$1(e)||(e=fromValue$1(e)),this.eq(e))return 0;var t=this.isNegative(),n=e.isNegative();return t&&!n?-1:!t&&n?1:this.unsigned?e.high>>>0>this.high>>>0||e.high===this.high&&e.low>>>0>this.low>>>0?-1:1:this.sub(e).isNegative()?-1:1},LongPrototype$1.comp=LongPrototype$1.compare,LongPrototype$1.negate=function(){return!this.unsigned&&this.eq(MIN_VALUE$1)?MIN_VALUE$1:this.not().add(ONE$1)},LongPrototype$1.neg=LongPrototype$1.negate,LongPrototype$1.add=function(e){isLong$1(e)||(e=fromValue$1(e));var t=0,n=0,r=0,a=0;return r+=(a+=(65535&this.low)+(65535&e.low))>>>16,n+=(r+=(this.low>>>16)+(e.low>>>16))>>>16,t+=(n+=(65535&this.high)+(65535&e.high))>>>16,t+=(this.high>>>16)+(e.high>>>16),fromBits$1((r&=65535)<<16|(a&=65535),(t&=65535)<<16|(n&=65535),this.unsigned)},LongPrototype$1.subtract=function(e){return isLong$1(e)||(e=fromValue$1(e)),this.add(e.neg())},LongPrototype$1.sub=LongPrototype$1.subtract,LongPrototype$1.multiply=function(e){if(this.isZero())return ZERO$1;if(isLong$1(e)||(e=fromValue$1(e)),wasm$1)return fromBits$1(wasm$1.mul(this.low,this.high,e.low,e.high),wasm$1.get_high(),this.unsigned);if(e.isZero())return ZERO$1;if(this.eq(MIN_VALUE$1))return e.isOdd()?MIN_VALUE$1:ZERO$1;if(e.eq(MIN_VALUE$1))return this.isOdd()?MIN_VALUE$1:ZERO$1;if(this.isNegative())return e.isNegative()?this.neg().mul(e.neg()):this.neg().mul(e).neg();if(e.isNegative())return this.mul(e.neg()).neg();if(this.lt(TWO_PWR_24$1)&&e.lt(TWO_PWR_24$1))return fromNumber$1(this.toNumber()*e.toNumber(),this.unsigned);var t=65535&this.high,n=this.low>>>16,r=65535&this.low,a=65535&e.high,s=e.low>>>16,o=65535&e.low,i=0,l=0,u=0,c=0;return u+=(c+=r*o)>>>16,l+=(u+=n*o)>>>16,u&=65535,l+=(u+=r*s)>>>16,i+=(l+=t*o)>>>16,l&=65535,i+=(l+=n*s)>>>16,l&=65535,i+=(l+=r*a)>>>16,i+=(this.high>>>16)*o+t*s+n*a+r*(e.high>>>16),fromBits$1((u&=65535)<<16|(c&=65535),(i&=65535)<<16|(l&=65535),this.unsigned)},LongPrototype$1.mul=LongPrototype$1.multiply,LongPrototype$1.divide=function(e){if(isLong$1(e)||(e=fromValue$1(e)),e.isZero())throw Error("division by zero");var t,n,r;if(wasm$1)return this.unsigned||-2147483648!==this.high||-1!==e.low||-1!==e.high?fromBits$1((this.unsigned?wasm$1.div_u:wasm$1.div_s)(this.low,this.high,e.low,e.high),wasm$1.get_high(),this.unsigned):this;if(this.isZero())return this.unsigned?UZERO$1:ZERO$1;if(this.unsigned){if(e.unsigned||(e=e.toUnsigned()),e.gt(this))return UZERO$1;if(e.gt(this.shru(1)))return UONE$1;r=UZERO$1}else{if(this.eq(MIN_VALUE$1))return e.eq(ONE$1)||e.eq(NEG_ONE$1)?MIN_VALUE$1:e.eq(MIN_VALUE$1)?ONE$1:(t=this.shr(1).div(e).shl(1)).eq(ZERO$1)?e.isNegative()?ONE$1:NEG_ONE$1:(n=this.sub(e.mul(t)),r=t.add(n.div(e)));if(e.eq(MIN_VALUE$1))return this.unsigned?UZERO$1:ZERO$1;if(this.isNegative())return e.isNegative()?this.neg().div(e.neg()):this.neg().div(e).neg();if(e.isNegative())return this.div(e.neg()).neg();r=ZERO$1}for(n=this;n.gte(e);){t=Math.max(1,Math.floor(n.toNumber()/e.toNumber()));for(var a=Math.ceil(Math.log(t)/Math.LN2),s=a<=48?1:pow_dbl$1(2,a-48),o=fromNumber$1(t),i=o.mul(e);i.isNegative()||i.gt(n);)i=(o=fromNumber$1(t-=s,this.unsigned)).mul(e);o.isZero()&&(o=ONE$1),r=r.add(o),n=n.sub(i)}return r},LongPrototype$1.div=LongPrototype$1.divide,LongPrototype$1.modulo=function(e){return isLong$1(e)||(e=fromValue$1(e)),wasm$1?fromBits$1((this.unsigned?wasm$1.rem_u:wasm$1.rem_s)(this.low,this.high,e.low,e.high),wasm$1.get_high(),this.unsigned):this.sub(this.div(e).mul(e))},LongPrototype$1.mod=LongPrototype$1.modulo,LongPrototype$1.rem=LongPrototype$1.modulo,LongPrototype$1.not=function(){return fromBits$1(~this.low,~this.high,this.unsigned)},LongPrototype$1.and=function(e){return isLong$1(e)||(e=fromValue$1(e)),fromBits$1(this.low&e.low,this.high&e.high,this.unsigned)},LongPrototype$1.or=function(e){return isLong$1(e)||(e=fromValue$1(e)),fromBits$1(this.low|e.low,this.high|e.high,this.unsigned)},LongPrototype$1.xor=function(e){return isLong$1(e)||(e=fromValue$1(e)),fromBits$1(this.low^e.low,this.high^e.high,this.unsigned)},LongPrototype$1.shiftLeft=function(e){return isLong$1(e)&&(e=e.toInt()),0==(e&=63)?this:e<32?fromBits$1(this.low<<e,this.high<<e|this.low>>>32-e,this.unsigned):fromBits$1(0,this.low<<e-32,this.unsigned)},LongPrototype$1.shl=LongPrototype$1.shiftLeft,LongPrototype$1.shiftRight=function(e){return isLong$1(e)&&(e=e.toInt()),0==(e&=63)?this:e<32?fromBits$1(this.low>>>e|this.high<<32-e,this.high>>e,this.unsigned):fromBits$1(this.high>>e-32,this.high>=0?0:-1,this.unsigned)},LongPrototype$1.shr=LongPrototype$1.shiftRight,LongPrototype$1.shiftRightUnsigned=function(e){if(isLong$1(e)&&(e=e.toInt()),0==(e&=63))return this;var t=this.high;return e<32?fromBits$1(this.low>>>e|t<<32-e,t>>>e,this.unsigned):fromBits$1(32===e?t:t>>>e-32,0,this.unsigned)},LongPrototype$1.shru=LongPrototype$1.shiftRightUnsigned,LongPrototype$1.shr_u=LongPrototype$1.shiftRightUnsigned,LongPrototype$1.toSigned=function(){return this.unsigned?fromBits$1(this.low,this.high,!1):this},LongPrototype$1.toUnsigned=function(){return this.unsigned?this:fromBits$1(this.low,this.high,!0)},LongPrototype$1.toBytes=function(e){return e?this.toBytesLE():this.toBytesBE()},LongPrototype$1.toBytesLE=function(){var e=this.high,t=this.low;return[255&t,t>>>8&255,t>>>16&255,t>>>24,255&e,e>>>8&255,e>>>16&255,e>>>24]},LongPrototype$1.toBytesBE=function(){var e=this.high,t=this.low;return[e>>>24,e>>>16&255,e>>>8&255,255&e,t>>>24,t>>>16&255,t>>>8&255,255&t]},Long$3.fromBytes=function(e,t,n){return n?Long$3.fromBytesLE(e,t):Long$3.fromBytesBE(e,t)},Long$3.fromBytesLE=function(e,t){return new Long$3(e[0]|e[1]<<8|e[2]<<16|e[3]<<24,e[4]|e[5]<<8|e[6]<<16|e[7]<<24,t)},Long$3.fromBytesBE=function(e,t){return new Long$3(e[4]<<24|e[5]<<16|e[6]<<8|e[7],e[0]<<24|e[1]<<16|e[2]<<8|e[3],t)};var long$3=long$2,LongExports$1=/*#__PURE__*/Object.assign(/*#__PURE__*/Object.create(null),long$2,{default:long$3});const Long$2=long$3||LongExports$1;function hexToLong$1(e){return Long$2.fromString(e,!0,16)}const k0$1=hexToLong$1("c3a5c85c97cb3127"),k1$1=hexToLong$1("b492b66fbe98f273"),k2$1=hexToLong$1("9ae16a3b2f90404f");function shiftMix$1(e){return e.xor(e.shru(47))}function fetch$3(e,t,n){const r=e.slice(t,t+n);return Long$2.fromBytes(Array.from(r),!0,!0)}function fetch64$1(e,t){return fetch$3(e,t,8)}function fetch32$1(e,t){return fetch$3(e,t,4)}function rotate64$1(e,t){return 0===t?e:e.shru(t).or(e.shl(64-t))}function hashLen16$1(e,t,n=hexToLong$1("9ddfea08eb382d69")){let r=e.xor(t).mul(n);r=r.xor(r.shru(47));let a=t.xor(r).mul(n);return a=a.xor(a.shru(47)),a=a.mul(n),a}function weakHashLen32WithSeeds$1(e,t,n,r,a,s){a=a.add(e),s=rotate64$1(s.add(a).add(r),21);const o=a;return a=(a=a.add(t)).add(n),s=s.add(rotate64$1(a,44)),[a.add(r),s.add(o)]}function weakHashLen32WithSeedsStr$1(e,t,n,r){return weakHashLen32WithSeeds$1(fetch64$1(e,t),fetch64$1(e,t+8),fetch64$1(e,t+16),fetch64$1(e,t+24),n,r)}function hashLen0to16$1(e,t=e.length){if(t>=8){const n=k2$1.add(2*t),r=fetch64$1(e,0).add(k2$1),a=fetch64$1(e,t-8);return hashLen16$1(rotate64$1(a,37).mul(n).add(r),rotate64$1(r,25).add(a).mul(n),n)}if(t>=4){const n=k2$1.add(2*t);return hashLen16$1(fetch32$1(e,0).shl(3).add(t),fetch32$1(e,t-4),n)}if(t>0){const n=t+(e[t-1]<<2);return shiftMix$1(k2$1.mul(e[0]+(e[t>>1]<<8)).xor(k0$1.mul(n))).mul(k2$1)}return k2$1}function hashLen17to32$1(e,t=e.length){const n=k2$1.add(2*t),r=fetch64$1(e,0).mul(k1$1),a=fetch64$1(e,8),s=fetch64$1(e,t-8).mul(n),o=fetch64$1(e,t-16).mul(k2$1);return hashLen16$1(rotate64$1(r.add(a),43).add(rotate64$1(s,30)).add(o),r.add(rotate64$1(a.add(k2$1),18)).add(s),n)}function hashLen33to64$1(e,t=e.length){const n=k2$1.add(2*t),r=fetch64$1(e,0).mul(k2$1),a=fetch64$1(e,8),s=fetch64$1(e,t-8).mul(n),o=fetch64$1(e,t-16).mul(k2$1),i=rotate64$1(r.add(a),43).add(rotate64$1(s,30)).add(o),l=hashLen16$1(i,r.add(rotate64$1(a.add(k2$1),18)).add(s),n),u=fetch64$1(e,16).mul(n),c=fetch64$1(e,24),p=i.add(fetch64$1(e,t-32)).mul(n),d=l.add(fetch64$1(e,t-24)).mul(n);return hashLen16$1(rotate64$1(u.add(c),43).add(rotate64$1(p,30)).add(d),u.add(rotate64$1(c.add(r),18)).add(p),n)}function fingerPrint64$1(e,t=e.length){const n=Long$2.fromNumber(81,!0);if(t<=32)return t<=16?hashLen0to16$1(e,t):hashLen17to32$1(e,t);if(t<=64)return hashLen33to64$1(e,t);let r=n,a=n.mul(k1$1).add(113),s=shiftMix$1(a.mul(k2$1).add(113)).mul(k2$1),o=[Long$2.UZERO,Long$2.UZERO],i=[Long$2.UZERO,Long$2.UZERO];r=r.mul(k2$1).add(fetch64$1(e,0));let l=0;const u=64*(t-1>>6),c=u+(t-1&63)-63;do{r=rotate64$1(r.add(a).add(o[0]).add(fetch64$1(e,l+8)),37).mul(k1$1),a=rotate64$1(a.add(o[1]).add(fetch64$1(e,l+48)),42).mul(k1$1),r=r.xor(i[1]),a=a.add(o[0]).add(fetch64$1(e,l+40)),s=rotate64$1(s.add(i[0]),33).mul(k1$1),o=weakHashLen32WithSeedsStr$1(e,l,o[1].mul(k1$1),r.add(i[0])),i=weakHashLen32WithSeedsStr$1(e,l+32,s.add(i[1]),a.add(fetch64$1(e,l+16))),[s,r]=[r,s],l+=64}while(l!==u);const p=k1$1.add(s.and(255).shl(1));return l=c,i[0]=i[0].add(t-1&63),o[0]=o[0].add(i[0]),i[0]=i[0].add(o[0]),r=rotate64$1(r.add(a).add(o[0]).add(fetch64$1(e,l+8)),37).mul(p),a=rotate64$1(a.add(o[1]).add(fetch64$1(e,l+48)),42).mul(p),r=r.xor(i[1].mul(9)),a=a.add(o[0].mul(9).add(fetch64$1(e,l+40))),s=rotate64$1(s.add(i[0]),33).mul(p),o=weakHashLen32WithSeedsStr$1(e,l,o[1].mul(p),r.add(i[0])),i=weakHashLen32WithSeedsStr$1(e,l+32,s.add(i[1]),a.add(fetch64$1(e,l+16))),[s,r]=[r,s],hashLen16$1(hashLen16$1(o[0],i[0],p).add(shiftMix$1(a).mul(k0$1)).add(s),hashLen16$1(o[1],i[1],p).add(r),p)}function createScalarValue$1(e,t){return"string"===t?encodeString$1(e):toTypedArray$1([e],t)}function noConversionNeeded$1(e,t){return e instanceof Float32Array&&"float32"===t||e instanceof Int32Array&&"int32"===t||e instanceof Uint8Array&&"bool"===t}function toTypedArray$1(e,t){if("string"===t)throw new Error("Cannot convert a string[] to a TypedArray");if(Array.isArray(e)&&(e=flatten$6(e)),env$1().getBool("DEBUG")&&checkConversionForErrors$1(e,t),noConversionNeeded$1(e,t))return e;if(null==t||"float32"===t||"complex64"===t)return new Float32Array(e);if("int32"===t)return new Int32Array(e);if("bool"===t){const t=new Uint8Array(e.length);for(let n=0;n<t.length;++n)0!==Math.round(e[n])&&(t[n]=1);return t}throw new Error(`Unknown data type ${t}`)}function now$1(){return env$1().platform.now()}function encodeString$1(e,t="utf-8"){return t=t||"utf-8",env$1().platform.encode(e,t)}function decodeString$1(e,t="utf-8"){return t=t||"utf-8",env$1().platform.decode(e,t)}class Profiler$1{constructor(e,t){this.backendTimer=e,this.logger=t,null==t&&(this.logger=new Logger$1)}profileKernel(e,t,n){let r;const a=()=>{r=n()};let s;const o=now$1();if(this.backendTimer.timerAvailable())s=this.backendTimer.time(a);else{a();for(const e of r)e.dataSync();s=Promise.resolve({kernelMs:now$1()-o})}if(env$1().getBool("CHECK_COMPUTATION_FOR_ERRORS"))for(let t=0;t<r.length;t++){const n=r[t];n.data().then(t=>{checkComputationForErrors$1(t,n.dtype,e)})}return{kernelName:e,outputs:r,inputs:t,timeMs:s.then(e=>e.kernelMs),extraInfo:s.then(e=>null!=e.getExtraProfileInfo?e.getExtraProfileInfo():"")}}logKernelProfile(e){const{kernelName:t,outputs:n,timeMs:r,inputs:a,extraInfo:s}=e;n.forEach(e=>{Promise.all([e.data(),r,s]).then(n=>{this.logger.logKernelProfile(t,e,n[0],n[1],a,n[2])})})}}function checkComputationForErrors$1(e,t,n){if("float32"!==t)return!1;for(let t=0;t<e.length;t++){const r=e[t];if(isNaN(r)||!isFinite(r))return console.warn(`Found ${r} in the result of '${n}'`),!0}return!1}class Logger$1{logKernelProfile(e,t,n,r,a,s){const o="number"==typeof r?rightPad$1(`${r}ms`,9):r.error,i=rightPad$1(e,25),l=t.rank,u=t.size,c=rightPad$1(t.shape.toString(),14);let p="";for(const e in a){const n=a[e];if(null!=n){const r=n.shape||t.shape,a=r.length;p+=`${e}: ${a}D ${a>0?r:""} `}}console.log(`%c${i}\t%c${o}\t%c${l}D ${c}\t%c${u}\t%c${p}\t%c${s}`,"font-weight:bold","color:red","color:blue","color: orange","color: green","color: steelblue")}}function getFilteredNodesXToY$1(e,t,n){const r={},a={};for(let e=0;e<t.length;e++)r[t[e].id]=!0;for(let n=0;n<e.length;n++){const s=e[n],o=s.inputs;for(const e in o){const n=o[e];let i=!1;for(let e=0;e<t.length;e++)if(r[n.id]){s.outputs.forEach(e=>r[e.id]=!0),i=!0,a[s.id]=!0;break}if(i)break}}const s={};s[n.id]=!0;const o={};for(let t=e.length-1;t>=0;t--){const n=e[t],r=n.inputs;for(let e=0;e<n.outputs.length;e++)if(s[n.outputs[e].id]){for(const e in r)s[r[e].id]=!0,o[n.id]=!0;break}}const i=[];for(let t=0;t<e.length;t++){const n=e[t];if(a[n.id]&&o[n.id]){const e={};for(const t in n.inputs){const a=n.inputs[t];r[a.id]&&(e[t]=a)}const t=Object.assign({},n);t.inputs=e,t.outputs=n.outputs,i.push(t)}}return i}function backpropagateGradients$1(e,t,n,r){for(let a=t.length-1;a>=0;a--){const s=t[a],o=[];if(s.outputs.forEach(t=>{const n=e[t.id];o.push(null!=n?n:null)}),null==s.gradient)throw new Error(`Cannot compute gradient: gradient function not found for ${s.kernelName}.`);const i=s.gradient(o);for(const t in s.inputs){if(!(t in i))throw new Error(`Cannot backprop through input ${t}. Available gradients found: ${Object.keys(i)}.`);const a=n(()=>i[t]());if("float32"!==a.dtype)throw new Error(`Error in gradient for op ${s.kernelName}. The gradient of input ${t} must have 'float32' dtype, but has '${a.dtype}'`);const o=s.inputs[t];if(!arraysEqual$1(a.shape,o.shape))throw new Error(`Error in gradient for op ${s.kernelName}. The gradient of input '${t}' has shape '${a.shape}', which does not match the shape of the input '${o.shape}'`);if(null==e[o.id])e[o.id]=a;else{const t=e[o.id];e[o.id]=r(t,a),t.dispose()}}}}const FORMAT_LIMIT_NUM_VALS$1=20,FORMAT_NUM_FIRST_LAST_VALS$1=3,FORMAT_NUM_SIG_DIGITS$1=7;function tensorToString$1(e,t,n,r){const a=computeStrides$1(t),s=computeMaxSizePerColumn$1(e,t,n,a),o=t.length,i=subTensorToString$1(e,t,n,a,s),l=["Tensor"];return r&&(l.push(`  dtype: ${n}`),l.push(`  rank: ${o}`),l.push(`  shape: [${t}]`),l.push("  values:")),l.push(i.map(e=>"    "+e).join("\n")),l.join("\n")}function computeMaxSizePerColumn$1(e,t,n,r){const a=sizeFromShape$1(t),s=r[r.length-1],o=new Array(s).fill(0),i=t.length,l="complex64"===n?createComplexTuples$1(e):e;if(i>1)for(let e=0;e<a/s;e++){const t=e*s;for(let e=0;e<s;e++)o[e]=Math.max(o[e],valToString$1(l[t+e],0,n).length)}return o}function valToString$1(e,t,n){let r;return r=Array.isArray(e)?`${parseFloat(e[0].toFixed(FORMAT_NUM_SIG_DIGITS$1))} + ${parseFloat(e[1].toFixed(FORMAT_NUM_SIG_DIGITS$1))}j`:isString$1(e)?`'${e}'`:"bool"===n?boolNumToString$1(e):parseFloat(e.toFixed(FORMAT_NUM_SIG_DIGITS$1)).toString(),rightPad$1(r,t)}function boolNumToString$1(e){return 0===e?"false":"true"}function subTensorToString$1(e,t,n,r,a,s=!0){const o="complex64"===n?2:1,i=t[0],l=t.length;if(0===l)return"complex64"===n?[valToString$1(createComplexTuples$1(e)[0],0,n)]:"bool"===n?[boolNumToString$1(e[0])]:[e[0].toString()];if(1===l){if(i>FORMAT_LIMIT_NUM_VALS$1){let t=Array.from(e.slice(0,FORMAT_NUM_FIRST_LAST_VALS$1*o)),r=Array.from(e.slice((i-FORMAT_NUM_FIRST_LAST_VALS$1)*o,i*o));return"complex64"===n&&(t=createComplexTuples$1(t),r=createComplexTuples$1(r)),["["+t.map((e,t)=>valToString$1(e,a[t],n)).join(", ")+", ..., "+r.map((e,t)=>valToString$1(e,a[i-FORMAT_NUM_FIRST_LAST_VALS$1+t],n)).join(", ")+"]"]}return["["+("complex64"===n?createComplexTuples$1(e):Array.from(e)).map((e,t)=>valToString$1(e,a[t],n)).join(", ")+"]"]}const u=t.slice(1),c=r.slice(1),p=r[0]*o,d=[];if(i>FORMAT_LIMIT_NUM_VALS$1){for(let t=0;t<FORMAT_NUM_FIRST_LAST_VALS$1;t++){const r=t*p;d.push(...subTensorToString$1(e.slice(r,r+p),u,n,c,a,!1))}d.push("...");for(let t=i-FORMAT_NUM_FIRST_LAST_VALS$1;t<i;t++){const r=t*p;d.push(...subTensorToString$1(e.slice(r,r+p),u,n,c,a,t===i-1))}}else for(let t=0;t<i;t++){const r=t*p;d.push(...subTensorToString$1(e.slice(r,r+p),u,n,c,a,t===i-1))}const h=2===l?",":"";d[0]="["+d[0]+h;for(let e=1;e<d.length-1;e++)d[e]=" "+d[e]+h;let m=",\n";for(let e=2;e<l;e++)m+="\n";return d[d.length-1]=" "+d[d.length-1]+"]"+(s?"":m),d}function createComplexTuples$1(e){const t=[];for(let n=0;n<e.length;n+=2)t.push([e[n],e[n+1]]);return t}class TensorBuffer$1{constructor(e,t,n){if(this.dtype=t,this.shape=e.slice(),this.size=sizeFromShape$1(e),null!=n){const e=n.length;assert$6(e===this.size,()=>`Length of values '${e}' does not match the size inferred by the shape '${this.size}'.`)}if("complex64"===t)throw new Error("complex64 dtype TensorBuffers are not supported. Please create a TensorBuffer for the real and imaginary parts separately and call tf.complex(real, imag).");this.values=n||getArrayFromDType$1(t,this.size),this.strides=computeStrides$1(e)}set(e,...t){0===t.length&&(t=[0]),assert$6(t.length===this.rank,()=>`The number of provided coordinates (${t.length}) must match the rank (${this.rank})`);const n=this.locToIndex(t);this.values[n]=e}get(...e){0===e.length&&(e=[0]);let t=0;for(const n of e){if(n<0||n>=this.shape[t])throw new Error(`Requested out of range element at ${e}.   Buffer shape=${this.shape}`);t++}let n=e[e.length-1];for(let t=0;t<e.length-1;++t)n+=this.strides[t]*e[t];return this.values[n]}locToIndex(e){if(0===this.rank)return 0;if(1===this.rank)return e[0];let t=e[e.length-1];for(let n=0;n<e.length-1;++n)t+=this.strides[n]*e[n];return t}indexToLoc(e){if(0===this.rank)return[];if(1===this.rank)return[e];const t=new Array(this.shape.length);for(let n=0;n<t.length-1;++n)t[n]=Math.floor(e/this.strides[n]),e-=t[n]*this.strides[n];return t[t.length-1]=e,t}get rank(){return this.shape.length}toTensor(){return trackerFn$1().makeTensor(this.values,this.shape,this.dtype)}}let trackerFn$1=null,opHandler$3=null;function setTensorTracker$1(e){trackerFn$1=e}function setOpHandler$1(e){opHandler$3=e}class Tensor$1{constructor(e,t,n,r){this.kept=!1,this.isDisposedInternal=!1,this.shape=e.slice(),this.dtype=t||"float32",this.size=sizeFromShape$1(e),this.strides=computeStrides$1(e),this.dataId=n,this.id=r,this.rankType=this.rank<5?this.rank.toString():"higher"}get rank(){return this.shape.length}async buffer(){const e=await this.data();return opHandler$3.buffer(this.shape,this.dtype,e)}bufferSync(){return opHandler$3.buffer(this.shape,this.dtype,this.dataSync())}async array(){const e=await this.data();return toNestedArray$1(this.shape,e,"complex64"===this.dtype)}arraySync(){return toNestedArray$1(this.shape,this.dataSync(),"complex64"===this.dtype)}async data(){this.throwIfDisposed();const e=trackerFn$1().read(this.dataId);if("string"===this.dtype){const t=await e;try{return t.map(e=>decodeString$1(e))}catch(e){throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().")}}return e}dataSync(){this.throwIfDisposed();const e=trackerFn$1().readSync(this.dataId);if("string"===this.dtype)try{return e.map(e=>decodeString$1(e))}catch(e){throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().")}return e}async bytes(){this.throwIfDisposed();const e=await trackerFn$1().read(this.dataId);return"string"===this.dtype?e:new Uint8Array(e.buffer)}dispose(){this.isDisposed||(trackerFn$1().disposeTensor(this),this.isDisposedInternal=!0)}get isDisposed(){return this.isDisposedInternal}throwIfDisposed(){if(this.isDisposed)throw new Error("Tensor is disposed.")}print(e=!1){return opHandler$3.print(this,e)}clone(){return this.throwIfDisposed(),opHandler$3.clone(this)}toString(e=!1){return tensorToString$1(this.dataSync(),this.shape,this.dtype,e)}cast(e){return this.throwIfDisposed(),opHandler$3.cast(this,e)}variable(e=!0,t,n){return this.throwIfDisposed(),trackerFn$1().makeVariable(this,e,t,n)}}function getGlobalTensorClass$1(){return getGlobal$1("Tensor",()=>Tensor$1)}Object.defineProperty(Tensor$1,Symbol.hasInstance,{value:e=>!!e&&null!=e.data&&null!=e.dataSync&&null!=e.throwIfDisposed}),getGlobalTensorClass$1();class Variable$1 extends Tensor$1{constructor(e,t,n,r){super(e.shape,e.dtype,e.dataId,r),this.trainable=t,this.name=n}assign(e){if(e.dtype!==this.dtype)throw new Error(`dtype of the new value (${e.dtype}) and previous value (${this.dtype}) must match`);if(!arraysEqual$1(e.shape,this.shape))throw new Error(`shape of the new value (${e.shape}) and previous value (${this.shape}) must match`);trackerFn$1().disposeTensor(this),this.dataId=e.dataId,trackerFn$1().incRef(this,null)}dispose(){trackerFn$1().disposeVariable(this),this.isDisposedInternal=!0}}var Rank$1,UpcastInt32AndMap$1,UpcastBoolAndMap$1,UpcastFloat32AndMap$1,UpcastComplex64AndMap$1;Object.defineProperty(Variable$1,Symbol.hasInstance,{value:e=>e instanceof Tensor$1&&null!=e.assign&&e.assign instanceof Function}),function(e){e.R0="R0",e.R1="R1",e.R2="R2",e.R3="R3",e.R4="R4",e.R5="R5",e.R6="R6"}(Rank$1||(Rank$1={})),function(e){e.float32="float32",e.int32="int32",e.bool="int32",e.complex64="complex64"}(UpcastInt32AndMap$1||(UpcastInt32AndMap$1={})),function(e){e.float32="float32",e.int32="int32",e.bool="bool",e.complex64="complex64"}(UpcastBoolAndMap$1||(UpcastBoolAndMap$1={})),function(e){e.float32="float32",e.int32="float32",e.bool="float32",e.complex64="complex64"}(UpcastFloat32AndMap$1||(UpcastFloat32AndMap$1={})),function(e){e.float32="complex64",e.int32="complex64",e.bool="complex64",e.complex64="complex64"}(UpcastComplex64AndMap$1||(UpcastComplex64AndMap$1={}));const upcastTypeMap$1={float32:UpcastFloat32AndMap$1,int32:UpcastInt32AndMap$1,bool:UpcastBoolAndMap$1,complex64:UpcastComplex64AndMap$1};function upcastType$1(e,t){if("string"===e||"string"===t){if("string"===e&&"string"===t)return"string";throw new Error(`Can not upcast ${e} with ${t}`)}return upcastTypeMap$1[e][t]}function sumOutType$1(e){return upcastType$1(e,"int32")}function makeTypesMatch$1(e,t){if(e.dtype===t.dtype)return[e,t];const n=upcastType$1(e.dtype,t.dtype);return[e.cast(n),t.cast(n)]}function getTensorsInContainer$1(e){const t=[];return walkTensorContainer$1(e,t,new Set),t}function walkTensorContainer$1(e,t,n){if(null==e)return;if(e instanceof Tensor$1)return void t.push(e);if(!isIterable$2(e))return;const r=e;for(const e in r){const a=r[e];n.has(a)||(n.add(a),walkTensorContainer$1(a,t,n))}}function isIterable$2(e){return Array.isArray(e)||"object"==typeof e}function isRegisteredKernelInvocation$1(e){return null!=e.kernelName}class EngineState$1{constructor(){this.registeredVariables={},this.nextTapeNodeId=0,this.numBytes=0,this.numTensors=0,this.numStringTensors=0,this.numDataBuffers=0,this.gradientDepth=0,this.kernelDepth=0,this.scopeStack=[],this.numDataMovesStack=[],this.nextScopeId=0,this.tensorInfo=new WeakMap,this.profiling=!1,this.activeProfile={newBytes:0,newTensors:0,peakBytes:0,kernels:[],result:null,get kernelNames(){return Array.from(new Set(this.kernels.map(e=>e.name)))}}}dispose(){for(const e in this.registeredVariables)this.registeredVariables[e].dispose()}}class Engine$1{constructor(e){this.ENV=e,this.registry={},this.registryFactory={},this.pendingBackendInitId=0,this.state=new EngineState$1}async ready(){if(null!=this.pendingBackendInit)return this.pendingBackendInit.then(()=>{});if(null!=this.backendInstance)return;const e=this.getSortedBackends();for(let t=0;t<e.length;t++){const n=e[t];if(await this.initializeBackend(n).success)return void await this.setBackend(n)}throw new Error("Could not initialize any backends, all backend initializations failed.")}get backend(){if(null!=this.pendingBackendInit)throw new Error(`Backend '${this.backendName}' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods`);if(null==this.backendInstance){const{name:e,asyncInit:t}=this.initializeBackendsAndReturnBest();if(t)throw new Error(`The highest priority backend '${e}' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods`);this.setBackend(e)}return this.backendInstance}backendNames(){return Object.keys(this.registryFactory)}findBackend(e){if(!(e in this.registry)){if(!(e in this.registryFactory))return null;{const{asyncInit:t}=this.initializeBackend(e);if(t)return null}}return this.registry[e]}findBackendFactory(e){return e in this.registryFactory?this.registryFactory[e].factory:null}registerBackend(e,t,n=1){return e in this.registryFactory?(console.warn(`${e} backend was already registered. Reusing existing backend factory.`),!1):(this.registryFactory[e]={factory:t,priority:n},!0)}async setBackend(e){if(null==this.registryFactory[e])throw new Error(`Backend name '${e}' not found in registry`);if(this.backendName=e,null==this.registry[e]){this.backendInstance=null;const{success:t,asyncInit:n}=this.initializeBackend(e);if(!(n?await t:t))return!1}return this.backendInstance=this.registry[e],this.setupRegisteredKernels(),this.profiler=new Profiler$1(this.backendInstance),!0}setupRegisteredKernels(){getKernelsForBackend$1(this.backendName).forEach(e=>{null!=e.setupFunc&&e.setupFunc(this.backendInstance)})}disposeRegisteredKernels(e){getKernelsForBackend$1(e).forEach(t=>{null!=t.disposeFunc&&t.disposeFunc(this.registry[e])})}initializeBackend(e){const t=this.registryFactory[e];if(null==t)throw new Error(`Cannot initialize backend ${e}, no registration found.`);try{const n=t.factory();if(!n||n instanceof KernelBackend$1||"function"!=typeof n.then)return this.registry[e]=n,{success:!0,asyncInit:!1};{const t=++this.pendingBackendInitId,r=n.then(n=>!(t<this.pendingBackendInitId||(this.registry[e]=n,this.pendingBackendInit=null,0))).catch(n=>(t<this.pendingBackendInitId||(this.pendingBackendInit=null,console.warn(`Initialization of backend ${e} failed`),console.warn(n.stack||n.message)),!1));return this.pendingBackendInit=r,{success:r,asyncInit:!0}}}catch(t){return console.warn(`Initialization of backend ${e} failed`),console.warn(t.stack||t.message),{success:!1,asyncInit:!1}}}removeBackend(e){if(!(e in this.registryFactory))throw new Error(`${e} backend not found in registry`);this.backendName===e&&null!=this.pendingBackendInit&&this.pendingBackendInitId++,e in this.registry&&(this.disposeRegisteredKernels(e),this.registry[e].dispose(),delete this.registry[e]),delete this.registryFactory[e],this.backendName===e&&(this.pendingBackendInit=null,this.backendName=null,this.backendInstance=null)}getSortedBackends(){if(0===Object.keys(this.registryFactory).length)throw new Error("No backend found in registry.");return Object.keys(this.registryFactory).sort((e,t)=>this.registryFactory[t].priority-this.registryFactory[e].priority)}initializeBackendsAndReturnBest(){const e=this.getSortedBackends();for(let t=0;t<e.length;t++){const n=e[t],{success:r,asyncInit:a}=this.initializeBackend(n);if(a||r)return{name:n,asyncInit:a}}throw new Error("Could not initialize any backends, all backend initializations failed.")}moveData(e,t){const n=this.state.tensorInfo.get(t),r=n.backend,a=this.readSync(t),s=r.refCount(t);r.disposeData(t,!0),n.backend=e,e.move(t,a,n.shape,n.dtype,s),this.shouldCheckForMemLeaks()&&this.state.numDataMovesStack[this.state.numDataMovesStack.length-1]++}tidy(e,t){let n,r=null;if(null==t){if("function"!=typeof e)throw new Error("Please provide a function to tidy()");t=e}else{if("string"!=typeof e&&!(e instanceof String))throw new Error("When calling with two arguments, the first argument to tidy() must be a string");if("function"!=typeof t)throw new Error("When calling with two arguments, the 2nd argument to tidy() must be a function");r=e}return this.scopedRun(()=>this.startScope(r),()=>this.endScope(n),()=>(n=t(),n instanceof Promise&&console.error("Cannot return a Promise inside of tidy."),n))}scopedRun(e,t,n){e();try{const e=n();return t(),e}catch(e){throw t(),e}}nextTensorId(){return Engine$1.nextTensorId++}nextVariableId(){return Engine$1.nextVariableId++}clone(e){const t=ENGINE$1.runKernel(Identity$3,{x:e});return this.addTapeNode(this.state.activeScope.name,{x:e},[t],e=>({x:()=>ENGINE$1.runKernel(Cast$1,{x:e},{dtype:"float32"})}),[],{}),t}runKernel(e,t,n){if(null==getKernel$1(e,this.backendName))throw new Error(`Kernel '${e}' not registered for backend '${this.backendName}'`);return this.runKernelFunc({kernelName:e,inputs:t,attrs:n})}shouldCheckForMemLeaks(){return this.ENV.getBool("IS_TEST")}checkKernelForMemLeak(e,t,n){const r=this.backend.numDataIds();let a=0;n.forEach(e=>{a+="complex64"===e.dtype?3:1});const s=r-t-a-this.state.numDataMovesStack[this.state.numDataMovesStack.length-1];if(s>0)throw new Error(`Backend '${this.backendName}' has an internal memory leak (${s} data ids) after running '${e}'`)}runKernelFunc(e){let t,n=[];const r=this.isTapeOn(),a=this.state.numBytes,s=this.state.numTensors;let o,i;this.shouldCheckForMemLeaks()&&this.state.numDataMovesStack.push(0);const l=isRegisteredKernelInvocation$1(e)?e.kernelName:null!=this.state.activeScope?this.state.activeScope.name:"";if(isRegisteredKernelInvocation$1(e)){const{kernelName:t,inputs:a,attrs:s}=e,l=getKernel$1(t,this.backendName);assert$6(null!=l,()=>`Cannot find registered kernel '${t}' for backend '${this.backendName}'`),o=()=>{const e=this.backend.numDataIds();i=l.kernelFunc({inputs:a,attrs:s,backend:this.backend});const o=Array.isArray(i)?i:[i];this.shouldCheckForMemLeaks()&&this.checkKernelForMemLeak(t,e,o);const u=o.map(e=>{if(null!=e.rank)return e;const{dataId:t,shape:n,dtype:r}=e;return this.makeTensorFromDataId(t,n,r)});if(r){const e=this.getTensorsForGradient(t,a,u);n=this.saveTensorsForBackwardMode(e)}return u}}else{const{forwardFunc:t}=e,a=e=>{r&&(n=e.map(e=>this.keep(this.clone(e))))};o=()=>{const e=this.backend.numDataIds();i=this.tidy(()=>t(this.backend,a));const n=Array.isArray(i)?i:[i];return this.shouldCheckForMemLeaks()&&this.checkKernelForMemLeak(l,e,n),n}}const{inputs:u,attrs:c}=e,p=isRegisteredKernelInvocation$1(e)?null:e.backwardsFunc;let d;return this.scopedRun(()=>this.state.kernelDepth++,()=>this.state.kernelDepth--,()=>{this.ENV.getBool("DEBUG")||this.state.profiling?(d=this.profiler.profileKernel(l,u,()=>o()),this.ENV.getBool("DEBUG")&&this.profiler.logKernelProfile(d),t=d.outputs):t=o()}),r&&this.addTapeNode(l,u,t,p,n,c),this.state.profiling&&this.state.activeProfile.kernels.push({name:l,bytesAdded:this.state.numBytes-a,totalBytesSnapshot:this.state.numBytes,tensorsAdded:this.state.numTensors-s,totalTensorsSnapshot:this.state.numTensors,inputShapes:Object.keys(u).map(e=>null!=u[e]?u[e].shape:null),outputShapes:t.map(e=>e.shape),kernelTimeMs:d.timeMs,extraInfo:d.extraInfo}),Array.isArray(i)?t:t[0]}saveTensorsForBackwardMode(e){return e.map(e=>this.keep(this.clone(e)))}getTensorsForGradient(e,t,n){const r=getGradient$1(e);if(null!=r){const e=r.inputsToSave||[],a=r.outputsToSave||[];let s;r.saveAllInputs?(assert$6(Array.isArray(t),()=>"saveAllInputs is true, expected inputs to be an array."),s=Object.keys(t).map(e=>t[e])):s=e.map(e=>t[e]);const o=n.filter((e,t)=>a[t]);return s.concat(o)}return[]}makeTensor(e,t,n,r){if(null==e)throw new Error("Values passed to engine.makeTensor() are null");r=r||this.backend;let a=e;"string"===(n=n||"float32")&&isString$1(e[0])&&(a=e.map(e=>encodeString$1(e)));const s=r.write(a,t,n),o=new Tensor$1(t,n,s,this.nextTensorId());if(this.trackTensor(o,r),"string"===n){const e=this.state.tensorInfo.get(s),t=bytesFromStringArray$1(a);this.state.numBytes+=t-e.bytes,e.bytes=t}return o}makeTensorFromDataId(e,t,n,r){const a=new Tensor$1(t,n=n||"float32",e,this.nextTensorId());return this.trackTensor(a,r),a}makeVariable(e,t=!0,n,r){n=n||this.nextVariableId().toString(),null!=r&&r!==e.dtype&&(e=e.cast(r));const a=new Variable$1(e,t,n,this.nextTensorId());if(null!=this.state.registeredVariables[a.name])throw new Error(`Variable with name ${a.name} was already registered`);return this.state.registeredVariables[a.name]=a,this.incRef(a,this.backend),a}trackTensor(e,t){this.state.numTensors++,"string"===e.dtype&&this.state.numStringTensors++;let n=0;"complex64"!==e.dtype&&"string"!==e.dtype&&(n=e.size*bytesPerElement$1(e.dtype)),this.state.numBytes+=n,this.state.tensorInfo.has(e.dataId)||(this.state.numDataBuffers++,this.state.tensorInfo.set(e.dataId,{backend:t||this.backend,dtype:e.dtype,shape:e.shape,bytes:n})),e instanceof Variable$1||this.track(e)}incRef(e,t){this.trackTensor(e,t),this.backend.incRef(e.dataId)}removeDataId(e,t){this.state.tensorInfo.has(e)&&this.state.tensorInfo.get(e).backend===t&&(this.state.tensorInfo.delete(e),this.state.numDataBuffers--)}disposeTensor(e){if(!this.state.tensorInfo.has(e.dataId))return;const t=this.state.tensorInfo.get(e.dataId);if(this.state.numTensors--,"string"===e.dtype&&(this.state.numStringTensors--,this.state.numBytes-=t.bytes),"complex64"!==e.dtype&&"string"!==e.dtype){const t=e.size*bytesPerElement$1(e.dtype);this.state.numBytes-=t}t.backend.disposeData(e.dataId)&&this.removeDataId(e.dataId,t.backend)}disposeVariables(){for(const e in this.state.registeredVariables)this.disposeVariable(this.state.registeredVariables[e])}disposeVariable(e){this.disposeTensor(e),null!=this.state.registeredVariables[e.name]&&delete this.state.registeredVariables[e.name]}memory(){const e=this.backend.memory();return e.numTensors=this.state.numTensors,e.numDataBuffers=this.state.numDataBuffers,e.numBytes=this.state.numBytes,this.state.numStringTensors>0&&(e.unreliable=!0,null==e.reasons&&(e.reasons=[]),e.reasons.push("Memory usage by string tensors is approximate (2 bytes per character)")),e}async profile(e){this.state.profiling=!0;const t=this.state.numBytes,n=this.state.numTensors;this.state.activeProfile.kernels=[],this.state.activeProfile.result=await e(),this.state.profiling=!1,this.state.activeProfile.peakBytes=Math.max(...this.state.activeProfile.kernels.map(e=>e.totalBytesSnapshot)),this.state.activeProfile.newBytes=this.state.numBytes-t,this.state.activeProfile.newTensors=this.state.numTensors-n;for(const e of this.state.activeProfile.kernels)e.kernelTimeMs=await e.kernelTimeMs,e.extraInfo=await e.extraInfo;return this.state.activeProfile}isTapeOn(){return this.state.gradientDepth>0&&0===this.state.kernelDepth}addTapeNode(e,t,n,r,a,s){const o={id:this.state.nextTapeNodeId++,kernelName:e,inputs:t,outputs:n,saved:a},i=getGradient$1(e);null!=i&&(r=i.gradFunc),null!=r&&(o.gradient=e=>(e=e.map((e,t)=>{if(null==e){const e=n[t],r=makeZerosTypedArray$1(e.size,e.dtype);return this.makeTensor(r,e.shape,e.dtype)}return e}),r(e.length>1?e:e[0],a,s))),this.state.activeTape.push(o)}keep(e){return e.kept=!0,e}startTape(){0===this.state.gradientDepth&&(this.state.activeTape=[]),this.state.gradientDepth++}endTape(){this.state.gradientDepth--}startScope(e){const t={track:[],name:"unnamed scope",id:this.state.nextScopeId++};e&&(t.name=e),this.state.scopeStack.push(t),this.state.activeScope=t}endScope(e){const t=getTensorsInContainer$1(e),n=new Set(t.map(e=>e.id));for(let e=0;e<this.state.activeScope.track.length;e++){const t=this.state.activeScope.track[e];t.kept||n.has(t.id)||t.dispose()}const r=this.state.scopeStack.pop();this.state.activeScope=0===this.state.scopeStack.length?null:this.state.scopeStack[this.state.scopeStack.length-1],t.forEach(e=>{e.kept||e.scopeId!==r.id||this.track(e)})}gradients(e,t,n,r=!1){if(assert$6(t.length>0,()=>"gradients() received an empty list of xs."),null!=n&&"float32"!==n.dtype)throw new Error(`dy must have 'float32' dtype, but has '${n.dtype}'`);const a=this.scopedRun(()=>this.startTape(),()=>this.endTape(),()=>this.tidy("forward",e));assert$6(a instanceof Tensor$1,()=>"The result y returned by f() must be a tensor.");const s=getFilteredNodesXToY$1(this.state.activeTape,t,a);if(!r&&0===s.length&&t.length>0)throw new Error("Cannot compute gradient of y=f(x) with respect to x. Make sure that the f you passed encloses all operations that lead from x to y.");return this.tidy("backward",()=>{const e={};e[a.id]=null==n?ones$4(a.shape):n,backpropagateGradients$1(e,s,e=>this.tidy(e),add$6);const r=t.map(t=>e[t.id]);return 0===this.state.gradientDepth&&(this.state.activeTape.forEach(e=>{for(const t of e.saved)t.dispose()}),this.state.activeTape=null),{value:a,grads:r}})}customGrad(e){return assert$6(isFunction$1(e),()=>"The f passed in customGrad(f) must be a function."),(...t)=>{let n;assert$6(t.every(e=>e instanceof Tensor$1),()=>"The args passed in customGrad(f)(x1, x2,...) must all be tensors");const r={};return t.forEach((e,t)=>{r[t]=e}),this.runKernelFunc({forwardFunc:(r,a)=>(n=e(...t,a),assert$6(n.value instanceof Tensor$1,()=>"The function f passed in customGrad(f) must return an object where `obj.value` is a tensor"),assert$6(isFunction$1(n.gradFunc),()=>"The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function."),n.value),backwardsFunc:(e,r)=>{const a=n.gradFunc(e,r),s=Array.isArray(a)?a:[a];assert$6(s.length===t.length,()=>"The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns the same number of tensors as inputs passed to f(...)."),assert$6(s.every(e=>e instanceof Tensor$1),()=>"The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns a list of only tensors.");const o={};return s.forEach((e,t)=>{o[t]=()=>e}),o},inputs:r})}}readSync(e){return this.state.tensorInfo.get(e).backend.readSync(e)}read(e){return this.state.tensorInfo.get(e).backend.read(e)}async time(e){const t=now$1(),n=await this.backend.time(e);return n.wallMs=now$1()-t,n}track(e){return null!=this.state.activeScope&&(e.scopeId=this.state.activeScope.id,this.state.activeScope.track.push(e)),e}get registeredVariables(){return this.state.registeredVariables}reset(){this.pendingBackendInitId++,this.state.dispose(),this.ENV.reset(),this.state=new EngineState$1;for(const e in this.registry)this.disposeRegisteredKernels(e),this.registry[e].dispose(),delete this.registry[e];this.backendName=null,this.backendInstance=null,this.pendingBackendInit=null}}function ones$4(e){const t=makeOnesTypedArray$1(sizeFromShape$1(e),"float32");return ENGINE$1.makeTensor(t,e,"float32")}function getOrMakeEngine$1(){const e=getGlobalNamespace$1();if(null==e._tfengine){const t=new Environment$1(e);e._tfengine=new Engine$1(t)}return setEnvironmentGlobal$1(e._tfengine.ENV),setTensorTracker$1(()=>e._tfengine),e._tfengine}Engine$1.nextTensorId=0,Engine$1.nextVariableId=0;const ENGINE$1=getOrMakeEngine$1();function add$6(e,t){return ENGINE$1.runKernel(Add$3,{a:e,b:t})}function _isNavigatorDefined$1(){return"undefined"!=typeof navigator&&null!=navigator}function isMobile$1(e){if(e||_isNavigatorDefined$1()){if(e||(e=navigator),"ReactNative"===e.product)return!0;const t=e.userAgent||e.vendor||window.opera;return/(android|bb\d+|meego).+mobile|avantgo|bada\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\.(browser|link)|vodafone|wap|windows ce|xda|xiino/i.test(t)||/1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\-(n|u)|c55\/|capi|ccwa|cdm\-|cell|chtm|cldc|cmd\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\-s|devi|dica|dmob|do(c|p)o|ds(12|\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\-|_)|g1 u|g560|gene|gf\-5|g\-mo|go(\.w|od)|gr(ad|un)|haie|hcit|hd\-(m|p|t)|hei\-|hi(pt|ta)|hp( i|ip)|hs\-c|ht(c(\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\-(20|go|ma)|i230|iac( |\-|\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\/)|klon|kpt |kwc\-|kyo(c|k)|le(no|xi)|lg( g|\/(k|l|u)|50|54|\-[a-w])|libw|lynx|m1\-w|m3ga|m50\/|ma(te|ui|xo)|mc(01|21|ca)|m\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\-2|po(ck|rt|se)|prox|psio|pt\-g|qa\-a|qc(07|12|21|32|60|\-[2-7]|i\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\-|oo|p\-)|sdk\/|se(c(\-|0|1)|47|mc|nd|ri)|sgh\-|shar|sie(\-|m)|sk\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\-|v\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\-|tdg\-|tel(i|m)|tim\-|t\-mo|to(pl|sh)|ts(70|m\-|m3|m5)|tx\-9|up(\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\-|your|zeto|zte\-/i.test(t.substr(0,4))}return!1}function isBrowser$1(){return"undefined"!=typeof window&&null!=window.document||"undefined"!=typeof WorkerGlobalScope}const ENV$4=env$1();function inferShape$1(e,t){let n=e;if(isTypedArray$1(e))return"string"===t?[]:[e.length];if(!Array.isArray(e))return[];const r=[];for(;Array.isArray(n)||isTypedArray$1(n)&&"string"!==t;)r.push(n.length),n=n[0];return Array.isArray(e)&&env$1().getBool("TENSORLIKE_CHECK_SHAPE_CONSISTENCY")&&deepAssertShapeConsistency$1(e,r,[]),r}function deepAssertShapeConsistency$1(e,t,n){if(n=n||[],!Array.isArray(e)&&!isTypedArray$1(e))return void assert$6(0===t.length,()=>`Element arr[${n.join("][")}] is a primitive, but should be an array/TypedArray of ${t[0]} elements`);assert$6(t.length>0,()=>`Element arr[${n.join("][")}] should be a primitive, but is an array of ${e.length} elements`),assert$6(e.length===t[0],()=>`Element arr[${n.join("][")}] should have ${t[0]} elements, but has ${e.length} elements`);const r=t.slice(1);for(let t=0;t<e.length;++t)deepAssertShapeConsistency$1(e[t],r,n.concat(t))}function assertDtype$1(e,t,n,r){if("string_or_numeric"!==e){if(null==e)throw new Error("Expected dtype cannot be null.");if("numeric"!==e&&e!==t||"numeric"===e&&"string"===t)throw new Error(`Argument '${n}' passed to '${r}' must be ${e} tensor, but got ${t} tensor`)}}function convertToTensor$1(e,t,n,r="numeric"){if(e instanceof Tensor$1)return assertDtype$1(r,e.dtype,t,n),e;let a=inferDtype$1(e);if("string"!==a&&["bool","int32","float32"].indexOf(r)>=0&&(a=r),assertDtype$1(r,a,t,n),null==e||!isTypedArray$1(e)&&!Array.isArray(e)&&"number"!=typeof e&&"boolean"!=typeof e&&"string"!=typeof e)throw new Error(`Argument '${t}' passed to '${n}' must be a Tensor or TensorLike, but got '${null==e?"null":e.constructor.name}'`);const s=inferShape$1(e,a);isTypedArray$1(e)||Array.isArray(e)||(e=[e]);const o="string"!==a?toTypedArray$1(e,a):flatten$6(e,[],!0);return ENGINE$1.makeTensor(o,s,a)}function convertToTensorArray$1(e,t,n,r="numeric"){if(!Array.isArray(e))throw new Error(`Argument ${t} passed to ${n} must be a \`Tensor[]\` or \`TensorLike[]\``);return e.map((e,a)=>convertToTensor$1(e,`${t}[${a}]`,n,r))}ENV$4.registerFlag("DEBUG",()=>!1,e=>{e&&console.warn("Debugging mode is ON. The output of every math call will be downloaded to CPU and checked for NaNs. This significantly impacts performance.")}),ENV$4.registerFlag("IS_BROWSER",()=>isBrowser$1()),ENV$4.registerFlag("IS_NODE",()=>"undefined"!=typeof process&&void 0!==process.versions&&void 0!==process.versions.node),ENV$4.registerFlag("IS_CHROME",()=>"undefined"!=typeof navigator&&null!=navigator&&null!=navigator.userAgent&&/Chrome/.test(navigator.userAgent)&&/Google Inc/.test(navigator.vendor)),ENV$4.registerFlag("PROD",()=>!1),ENV$4.registerFlag("TENSORLIKE_CHECK_SHAPE_CONSISTENCY",()=>ENV$4.getBool("DEBUG")),ENV$4.registerFlag("DEPRECATION_WARNINGS_ENABLED",()=>!0),ENV$4.registerFlag("IS_TEST",()=>!1),ENV$4.registerFlag("CHECK_COMPUTATION_FOR_ERRORS",()=>!0),ENV$4.registerFlag("WRAP_TO_IMAGEBITMAP",()=>!1);const OP_SCOPE_SUFFIX$1="__op";function op$1(e){const t=Object.keys(e);if(1!==t.length)throw new Error(`Please provide an object with a single key (operation name) mapping to a function. Got an object with ${t.length} keys.`);let n=t[0];const r=e[n];n.endsWith("_")&&(n=n.substring(0,n.length-1)),n+=OP_SCOPE_SUFFIX$1;const a=(...e)=>{ENGINE$1.startScope(n);try{const t=r(...e);return isPromise$1(t)&&console.error("Cannot return a Promise inside of tidy."),ENGINE$1.endScope(t),t}catch(e){throw ENGINE$1.endScope(null),e}};return Object.defineProperty(a,"name",{value:n,configurable:!0}),a}function complex_$1(e,t){const n=convertToTensor$1(e,"real","complex"),r=convertToTensor$1(t,"imag","complex");return assertShapesMatch$1(n.shape,r.shape,`real and imag shapes, ${n.shape} and ${r.shape}, must match in call to tf.complex().`),ENGINE$1.runKernel(Complex$1,{real:n,imag:r})}const complex$5=op$1({complex_:complex_$1});function makeTensor$1(e,t,n,r){if(null==r&&(r=inferDtype$1(e)),"complex64"===r)throw new Error("Cannot construct a complex64 tensor directly. Please use tf.complex(real, imag).");if(!isTypedArray$1(e)&&!Array.isArray(e)&&"number"!=typeof e&&"boolean"!=typeof e&&"string"!=typeof e)throw new Error("values passed to tensor(values) must be a number/boolean/string or an array of numbers/booleans/strings, or a TypedArray");if(null!=t){assertNonNegativeIntegerDimensions$1(t);const e=sizeFromShape$1(t),r=sizeFromShape$1(n);assert$6(e===r,()=>`Based on the provided shape, [${t}], the tensor should have ${e} values but has ${r}`);for(let e=0;e<n.length;++e){const r=n[e],a=e!==n.length-1||r!==sizeFromShape$1(t.slice(e));assert$6(n[e]===t[e]||!a,()=>`Error creating a new Tensor. Inferred shape (${n}) does not match the provided shape (${t}). `)}}return isTypedArray$1(e)||Array.isArray(e)||(e=[e]),t=t||n,e="string"!==r?toTypedArray$1(e,r):flatten$6(e,[],!0),ENGINE$1.makeTensor(e,t,r)}function tensor$1(e,t,n){return makeTensor$1(e,t,inferShape$1(e,n),n)}const DTYPE_VALUE_SIZE_MAP$1={float32:4,float16:2,int32:4,uint16:2,uint8:1,bool:1,complex64:8},NUM_BYTES_STRING_LENGTH$1=4;async function encodeWeights$1(e,t){const n=[],r=[],a=Array.isArray(e)?e.map(e=>e.name):Object.keys(e);for(let s=0;s<a.length;++s){const o=a[s],i=Array.isArray(e)?e[s].tensor:e[o];if("float32"!==i.dtype&&"int32"!==i.dtype&&"bool"!==i.dtype&&"string"!==i.dtype&&"complex64"!==i.dtype)throw new Error(`Unsupported dtype in weight '${o}': ${i.dtype}`);const l={name:o,shape:i.shape,dtype:i.dtype};if("string"===i.dtype){const e=new Promise(async e=>{const t=await i.bytes(),n=t.reduce((e,t)=>e+t.length,0)+NUM_BYTES_STRING_LENGTH$1*t.length,r=new Uint8Array(n);let a=0;for(let e=0;e<t.length;e++){const n=t[e],s=new Uint8Array(new Uint32Array([n.length]).buffer);r.set(s,a),a+=NUM_BYTES_STRING_LENGTH$1,r.set(n,a),a+=n.length}e(r)});r.push(e)}else r.push(i.data());null!=t&&(l.group=t),n.push(l)}return{data:concatenateTypedArrays$1(await Promise.all(r)),specs:n}}function decodeWeights$1(e,t){const n={};let r,a=0;for(const s of t){const t=s.name,o=s.dtype,i=s.shape,l=sizeFromShape$1(i);let u;if("quantization"in s){const n=s.quantization;if("uint8"===n.dtype||"uint16"===n.dtype){if(!("min"in n)||!("scale"in n))throw new Error(`Weight ${s.name} with quantization ${n.dtype} doesn't have corresponding metadata min and scale.`)}else{if("float16"!==n.dtype)throw new Error(`Weight ${s.name} has unknown quantization dtype ${n.dtype}. Supported quantization dtypes are: 'uint8', 'uint16', and 'float16'.`);if("float32"!==o)throw new Error(`Weight ${s.name} is quantized with ${n.dtype} which only supports weights of type float32 not ${o}.`)}const i=DTYPE_VALUE_SIZE_MAP$1[n.dtype],c=e.slice(a,a+l*i),p="uint8"===n.dtype?new Uint8Array(c):new Uint16Array(c);if("float32"===o)if("uint8"===n.dtype||"uint16"===n.dtype){u=new Float32Array(p.length);for(let e=0;e<p.length;e++)u[e]=p[e]*n.scale+n.min}else{if("float16"!==n.dtype)throw new Error(`Unsupported quantization type ${n.dtype} for weight type float32.`);void 0===r&&(r=getFloat16Decoder$1()),u=r(p)}else{if("int32"!==o)throw new Error(`Unsupported dtype in weight '${t}': ${o}`);if("uint8"!==n.dtype&&"uint16"!==n.dtype)throw new Error(`Unsupported quantization type ${n.dtype} for weight type int32.`);u=new Int32Array(p.length);for(let e=0;e<p.length;e++)u[e]=Math.round(p[e]*n.scale+n.min)}a+=l*i}else if("string"===o){const t=sizeFromShape$1(s.shape);u=[];for(let n=0;n<t;n++){const t=new Uint32Array(e.slice(a,a+NUM_BYTES_STRING_LENGTH$1))[0];a+=NUM_BYTES_STRING_LENGTH$1;const n=new Uint8Array(e.slice(a,a+t));u.push(n),a+=t}}else{const r=DTYPE_VALUE_SIZE_MAP$1[o],s=e.slice(a,a+l*r);if("float32"===o)u=new Float32Array(s);else if("int32"===o)u=new Int32Array(s);else if("bool"===o)u=new Uint8Array(s);else{if("complex64"!==o)throw new Error(`Unsupported dtype in weight '${t}': ${o}`);{u=new Float32Array(s);const e=new Float32Array(u.length/2),r=new Float32Array(u.length/2);for(let t=0;t<e.length;t++)e[t]=u[2*t],r[t]=u[2*t+1];const a=tensor$1(e,i,"float32"),o=tensor$1(r,i,"float32");n[t]=complex$5(a,o),a.dispose(),o.dispose()}}a+=l*r}"complex64"!==o&&(n[t]=tensor$1(u,i,o))}return n}function concatenateTypedArrays$1(e){if(null===e)throw new Error(`Invalid input value: ${JSON.stringify(e)}`);let t=0;const n=[];e.forEach(e=>{if(t+=e.byteLength,n.push(e.byteLength===e.buffer.byteLength?e:new e.constructor(e)),!(e instanceof Float32Array||e instanceof Int32Array||e instanceof Uint8Array))throw new Error(`Unsupported TypedArray subtype: ${e.constructor.name}`)});const r=new Uint8Array(t);let a=0;return n.forEach(e=>{r.set(new Uint8Array(e.buffer),a),a+=e.byteLength}),r.buffer}const useNodeBuffer$1="undefined"!=typeof Buffer&&("undefined"==typeof Blob||"undefined"==typeof atob||"undefined"==typeof btoa);function stringByteLength$1(e){return useNodeBuffer$1?Buffer.byteLength(e):new Blob([e]).size}function arrayBufferToBase64String$1(e){if(useNodeBuffer$1)return Buffer.from(e).toString("base64");const t=new Uint8Array(e);let n="";for(let e=0,r=t.length;e<r;e++)n+=String.fromCharCode(t[e]);return btoa(n)}function base64StringToArrayBuffer$1(e){if(useNodeBuffer$1){const t=Buffer.from(e,"base64");return t.buffer.slice(t.byteOffset,t.byteOffset+t.byteLength)}const t=atob(e),n=new Uint8Array(t.length);for(let e=0;e<t.length;++e)n.set([t.charCodeAt(e)],e);return n.buffer}function concatenateArrayBuffers$1(e){if(1===e.length)return e[0];let t=0;e.forEach(e=>{t+=e.byteLength});const n=new Uint8Array(t);let r=0;return e.forEach(e=>{n.set(new Uint8Array(e),r),r+=e.byteLength}),n.buffer}function getModelJSONForModelArtifacts$1(e,t){const n={modelTopology:e.modelTopology,format:e.format,generatedBy:e.generatedBy,convertedBy:e.convertedBy,weightsManifest:t};return null!=e.signature&&(n.signature=e.signature),null!=e.userDefinedMetadata&&(n.userDefinedMetadata=e.userDefinedMetadata),null!=e.modelInitializer&&(n.modelInitializer=e.modelInitializer),null!=e.trainingConfig&&(n.trainingConfig=e.trainingConfig),n}async function getModelArtifactsForJSON$1(e,t){const n={modelTopology:e.modelTopology,format:e.format,generatedBy:e.generatedBy,convertedBy:e.convertedBy};if(null!=e.trainingConfig&&(n.trainingConfig=e.trainingConfig),null!=e.weightsManifest){const[r,a]=await t(e.weightsManifest);n.weightSpecs=r,n.weightData=a}return null!=e.signature&&(n.signature=e.signature),null!=e.userDefinedMetadata&&(n.userDefinedMetadata=e.userDefinedMetadata),null!=e.modelInitializer&&(n.modelInitializer=e.modelInitializer),n}function getModelArtifactsInfoForJSON$1(e){if(e.modelTopology instanceof ArrayBuffer)throw new Error("Expected JSON model topology, received ArrayBuffer.");return{dateSaved:new Date,modelTopologyType:"JSON",modelTopologyBytes:null==e.modelTopology?0:stringByteLength$1(JSON.stringify(e.modelTopology)),weightSpecsBytes:null==e.weightSpecs?0:stringByteLength$1(JSON.stringify(e.weightSpecs)),weightDataBytes:null==e.weightData?0:e.weightData.byteLength}}function computeFloat16MantisaTable$1(){const e=e=>{let t=e<<13,n=0;for(;0==(8388608&t);)n-=8388608,t<<=1;return t&=-8388609,n+=947912704,t|n},t=new Uint32Array(2048);t[0]=0;for(let n=1;n<1024;n++)t[n]=e(n);for(let e=1024;e<2048;e++)t[e]=939524096+(e-1024<<13);return t}function computeFloat16ExponentTable$1(){const e=new Uint32Array(64);e[0]=0,e[31]=1199570944,e[32]=2147483648,e[63]=3347054592;for(let t=1;t<31;t++)e[t]=t<<23;for(let t=33;t<63;t++)e[t]=2147483648+(t-32<<23);return e}function computeFloat16OffsetTable$1(){const e=new Uint32Array(64);for(let t=0;t<64;t++)e[t]=1024;return e[0]=e[32]=0,e}function getFloat16Decoder$1(){const e=computeFloat16MantisaTable$1(),t=computeFloat16ExponentTable$1(),n=computeFloat16OffsetTable$1();return r=>{const a=new ArrayBuffer(4*r.length),s=new Uint32Array(a);for(let a=0;a<r.length;a++){const o=r[a];s[a]=e[n[o>>10]+(1023&o)]+t[o>>10]}return new Float32Array(a)}}class IORouterRegistry$1{constructor(){this.saveRouters=[],this.loadRouters=[]}static getInstance(){return null==IORouterRegistry$1.instance&&(IORouterRegistry$1.instance=new IORouterRegistry$1),IORouterRegistry$1.instance}static registerSaveRouter(e){IORouterRegistry$1.getInstance().saveRouters.push(e)}static registerLoadRouter(e){IORouterRegistry$1.getInstance().loadRouters.push(e)}static getSaveHandlers(e){return IORouterRegistry$1.getHandlers(e,"save")}static getLoadHandlers(e,t){return IORouterRegistry$1.getHandlers(e,"load",t)}static getHandlers(e,t,n){const r=[];return("load"===t?IORouterRegistry$1.getInstance().loadRouters:IORouterRegistry$1.getInstance().saveRouters).forEach(t=>{const a=t(e,n);null!==a&&r.push(a)}),r}}const getSaveHandlers$1=e=>IORouterRegistry$1.getSaveHandlers(e),getLoadHandlers$1=(e,t)=>IORouterRegistry$1.getLoadHandlers(e,t),DATABASE_NAME$1="tensorflowjs",DATABASE_VERSION$1=1,MODEL_STORE_NAME$1="models_store",INFO_STORE_NAME$1="model_info_store";function getIndexedDBFactory$1(){if(!env$1().getBool("IS_BROWSER"))throw new Error("Failed to obtain IndexedDB factory because the current environmentis not a web browser.");const e="undefined"==typeof window?self:window,t=e.indexedDB||e.mozIndexedDB||e.webkitIndexedDB||e.msIndexedDB||e.shimIndexedDB;if(null==t)throw new Error("The current browser does not appear to support IndexedDB.");return t}function setUpDatabase$1(e){const t=e.result;t.createObjectStore(MODEL_STORE_NAME$1,{keyPath:"modelPath"}),t.createObjectStore(INFO_STORE_NAME$1,{keyPath:"modelPath"})}class BrowserIndexedDB$1{constructor(e){if(this.indexedDB=getIndexedDBFactory$1(),null==e||!e)throw new Error("For IndexedDB, modelPath must not be null, undefined or empty.");this.modelPath=e}async save(e){if(e.modelTopology instanceof ArrayBuffer)throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");return this.databaseAction(this.modelPath,e)}async load(){return this.databaseAction(this.modelPath)}databaseAction(e,t){return new Promise((e,n)=>{const r=this.indexedDB.open(DATABASE_NAME$1,DATABASE_VERSION$1);r.onupgradeneeded=()=>setUpDatabase$1(r),r.onsuccess=()=>{const a=r.result;if(null==t){const t=a.transaction(MODEL_STORE_NAME$1,"readonly"),r=t.objectStore(MODEL_STORE_NAME$1).get(this.modelPath);r.onsuccess=()=>{if(null==r.result)return a.close(),n(new Error(`Cannot find model with path '${this.modelPath}' in IndexedDB.`));e(r.result.modelArtifacts)},r.onerror=e=>(a.close(),n(r.error)),t.oncomplete=()=>a.close()}else{const r=getModelArtifactsInfoForJSON$1(t),s=a.transaction(INFO_STORE_NAME$1,"readwrite");let o=s.objectStore(INFO_STORE_NAME$1);const i=o.put({modelPath:this.modelPath,modelArtifactsInfo:r});let l;i.onsuccess=()=>{l=a.transaction(MODEL_STORE_NAME$1,"readwrite");const i=l.objectStore(MODEL_STORE_NAME$1).put({modelPath:this.modelPath,modelArtifacts:t,modelArtifactsInfo:r});i.onsuccess=()=>e({modelArtifactsInfo:r}),i.onerror=e=>{o=s.objectStore(INFO_STORE_NAME$1);const t=o.delete(this.modelPath);t.onsuccess=()=>(a.close(),n(i.error)),t.onerror=e=>(a.close(),n(i.error))}},i.onerror=e=>(a.close(),n(i.error)),s.oncomplete=()=>{null==l?a.close():l.oncomplete=()=>a.close()}}},r.onerror=e=>n(r.error)})}}BrowserIndexedDB$1.URL_SCHEME="indexeddb://";const indexedDBRouter$1=e=>env$1().getBool("IS_BROWSER")&&!Array.isArray(e)&&e.startsWith(BrowserIndexedDB$1.URL_SCHEME)?browserIndexedDB$1(e.slice(BrowserIndexedDB$1.URL_SCHEME.length)):null;function browserIndexedDB$1(e){return new BrowserIndexedDB$1(e)}function maybeStripScheme$3(e){return e.startsWith(BrowserIndexedDB$1.URL_SCHEME)?e.slice(BrowserIndexedDB$1.URL_SCHEME.length):e}IORouterRegistry$1.registerSaveRouter(indexedDBRouter$1),IORouterRegistry$1.registerLoadRouter(indexedDBRouter$1);class BrowserIndexedDBManager$1{constructor(){this.indexedDB=getIndexedDBFactory$1()}async listModels(){return new Promise((e,t)=>{const n=this.indexedDB.open(DATABASE_NAME$1,DATABASE_VERSION$1);n.onupgradeneeded=()=>setUpDatabase$1(n),n.onsuccess=()=>{const r=n.result,a=r.transaction(INFO_STORE_NAME$1,"readonly"),s=a.objectStore(INFO_STORE_NAME$1).getAll();s.onsuccess=()=>{const t={};for(const e of s.result)t[e.modelPath]=e.modelArtifactsInfo;e(t)},s.onerror=e=>(r.close(),t(s.error)),a.oncomplete=()=>r.close()},n.onerror=e=>t(n.error)})}async removeModel(e){return e=maybeStripScheme$3(e),new Promise((t,n)=>{const r=this.indexedDB.open(DATABASE_NAME$1,DATABASE_VERSION$1);r.onupgradeneeded=()=>setUpDatabase$1(r),r.onsuccess=()=>{const a=r.result,s=a.transaction(INFO_STORE_NAME$1,"readwrite"),o=s.objectStore(INFO_STORE_NAME$1),i=o.get(e);let l;i.onsuccess=()=>{if(null==i.result)return a.close(),n(new Error(`Cannot find model with path '${e}' in IndexedDB.`));{const r=o.delete(e),s=()=>{l=a.transaction(MODEL_STORE_NAME$1,"readwrite");const r=l.objectStore(MODEL_STORE_NAME$1).delete(e);r.onsuccess=()=>t(i.result.modelArtifactsInfo),r.onerror=e=>n(i.error)};r.onsuccess=s,r.onerror=e=>(s(),a.close(),n(i.error))}},i.onerror=e=>(a.close(),n(i.error)),s.oncomplete=()=>{null==l?a.close():l.oncomplete=()=>a.close()}},r.onerror=e=>n(r.error)})}}const PATH_SEPARATOR$1="/",PATH_PREFIX$1="tensorflowjs_models",INFO_SUFFIX$1="info",MODEL_TOPOLOGY_SUFFIX$1="model_topology",WEIGHT_SPECS_SUFFIX$1="weight_specs",WEIGHT_DATA_SUFFIX$1="weight_data",MODEL_METADATA_SUFFIX$1="model_metadata";function getModelKeys$1(e){return{info:[PATH_PREFIX$1,e,INFO_SUFFIX$1].join(PATH_SEPARATOR$1),topology:[PATH_PREFIX$1,e,MODEL_TOPOLOGY_SUFFIX$1].join(PATH_SEPARATOR$1),weightSpecs:[PATH_PREFIX$1,e,WEIGHT_SPECS_SUFFIX$1].join(PATH_SEPARATOR$1),weightData:[PATH_PREFIX$1,e,WEIGHT_DATA_SUFFIX$1].join(PATH_SEPARATOR$1),modelMetadata:[PATH_PREFIX$1,e,MODEL_METADATA_SUFFIX$1].join(PATH_SEPARATOR$1)}}function removeItems$1(e){for(const t of Object.values(e))window.localStorage.removeItem(t)}function getModelPathFromKey$1(e){const t=e.split(PATH_SEPARATOR$1);if(t.length<3)throw new Error(`Invalid key format: ${e}`);return t.slice(1,t.length-1).join(PATH_SEPARATOR$1)}function maybeStripScheme$2(e){return e.startsWith(BrowserLocalStorage$1.URL_SCHEME)?e.slice(BrowserLocalStorage$1.URL_SCHEME.length):e}class BrowserLocalStorage$1{constructor(e){if(!env$1().getBool("IS_BROWSER")||"undefined"==typeof window||void 0===window.localStorage)throw new Error("The current environment does not support local storage.");if(this.LS=window.localStorage,null==e||!e)throw new Error("For local storage, modelPath must not be null, undefined or empty.");this.modelPath=e,this.keys=getModelKeys$1(this.modelPath)}async save(e){if(e.modelTopology instanceof ArrayBuffer)throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");{const t=JSON.stringify(e.modelTopology),n=JSON.stringify(e.weightSpecs),r=getModelArtifactsInfoForJSON$1(e);try{return this.LS.setItem(this.keys.info,JSON.stringify(r)),this.LS.setItem(this.keys.topology,t),this.LS.setItem(this.keys.weightSpecs,n),this.LS.setItem(this.keys.weightData,arrayBufferToBase64String$1(e.weightData)),this.LS.setItem(this.keys.modelMetadata,JSON.stringify({format:e.format,generatedBy:e.generatedBy,convertedBy:e.convertedBy,signature:null!=e.signature?e.signature:void 0,userDefinedMetadata:null!=e.userDefinedMetadata?e.userDefinedMetadata:void 0,modelInitializer:null!=e.modelInitializer?e.modelInitializer:void 0,trainingConfig:null!=e.trainingConfig?e.trainingConfig:void 0})),{modelArtifactsInfo:r}}catch(e){throw removeItems$1(this.keys),new Error(`Failed to save model '${this.modelPath}' to local storage: size quota being exceeded is a possible cause of this failure: modelTopologyBytes=${r.modelTopologyBytes}, weightSpecsBytes=${r.weightSpecsBytes}, weightDataBytes=${r.weightDataBytes}.`)}}}async load(){const e=JSON.parse(this.LS.getItem(this.keys.info));if(null==e)throw new Error(`In local storage, there is no model with name '${this.modelPath}'`);if("JSON"!==e.modelTopologyType)throw new Error("BrowserLocalStorage does not support loading non-JSON model topology yet.");const t={},n=JSON.parse(this.LS.getItem(this.keys.topology));if(null==n)throw new Error(`In local storage, the topology of model '${this.modelPath}' is missing.`);t.modelTopology=n;const r=JSON.parse(this.LS.getItem(this.keys.weightSpecs));if(null==r)throw new Error(`In local storage, the weight specs of model '${this.modelPath}' are missing.`);t.weightSpecs=r;const a=this.LS.getItem(this.keys.modelMetadata);if(null!=a){const e=JSON.parse(a);t.format=e.format,t.generatedBy=e.generatedBy,t.convertedBy=e.convertedBy,null!=e.signature&&(t.signature=e.signature),null!=e.userDefinedMetadata&&(t.userDefinedMetadata=e.userDefinedMetadata),null!=e.modelInitializer&&(t.modelInitializer=e.modelInitializer),null!=e.trainingConfig&&(t.trainingConfig=e.trainingConfig)}const s=this.LS.getItem(this.keys.weightData);if(null==s)throw new Error(`In local storage, the binary weight values of model '${this.modelPath}' are missing.`);return t.weightData=base64StringToArrayBuffer$1(s),t}}BrowserLocalStorage$1.URL_SCHEME="localstorage://";const localStorageRouter$1=e=>env$1().getBool("IS_BROWSER")&&!Array.isArray(e)&&e.startsWith(BrowserLocalStorage$1.URL_SCHEME)?browserLocalStorage$1(e.slice(BrowserLocalStorage$1.URL_SCHEME.length)):null;function browserLocalStorage$1(e){return new BrowserLocalStorage$1(e)}IORouterRegistry$1.registerSaveRouter(localStorageRouter$1),IORouterRegistry$1.registerLoadRouter(localStorageRouter$1);class BrowserLocalStorageManager$1{constructor(){assert$6(env$1().getBool("IS_BROWSER"),()=>"Current environment is not a web browser"),assert$6("undefined"==typeof window||void 0!==window.localStorage,()=>"Current browser does not appear to support localStorage"),this.LS=window.localStorage}async listModels(){const e={},t=PATH_PREFIX$1+PATH_SEPARATOR$1,n=PATH_SEPARATOR$1+INFO_SUFFIX$1;for(let r=0;r<this.LS.length;++r){const a=this.LS.key(r);a.startsWith(t)&&a.endsWith(n)&&(e[getModelPathFromKey$1(a)]=JSON.parse(this.LS.getItem(a)))}return e}async removeModel(e){const t=getModelKeys$1(e=maybeStripScheme$2(e));if(null==this.LS.getItem(t.info))throw new Error(`Cannot find model at path '${e}'`);const n=JSON.parse(this.LS.getItem(t.info));return removeItems$1(t),n}}const URL_SCHEME_SUFFIX$1="://";class ModelStoreManagerRegistry$1{constructor(){this.managers={}}static getInstance(){return null==ModelStoreManagerRegistry$1.instance&&(ModelStoreManagerRegistry$1.instance=new ModelStoreManagerRegistry$1),ModelStoreManagerRegistry$1.instance}static registerManager(e,t){assert$6(null!=e,()=>"scheme must not be undefined or null."),e.endsWith(URL_SCHEME_SUFFIX$1)&&(e=e.slice(0,e.indexOf(URL_SCHEME_SUFFIX$1))),assert$6(e.length>0,()=>"scheme must not be an empty string.");const n=ModelStoreManagerRegistry$1.getInstance();assert$6(null==n.managers[e],()=>`A model store manager is already registered for scheme '${e}'.`),n.managers[e]=t}static getManager(e){const t=this.getInstance().managers[e];if(null==t)throw new Error(`Cannot find model manager for scheme '${e}'`);return t}static getSchemes(){return Object.keys(this.getInstance().managers)}}class PlatformBrowser$1{fetch(e,t){return fetch(e,t)}now(){return performance.now()}encode(e,t){if("utf-8"!==t&&"utf8"!==t)throw new Error(`Browser's encoder only supports utf-8, but got ${t}`);return null==this.textEncoder&&(this.textEncoder=new TextEncoder),this.textEncoder.encode(e)}decode(e,t){return new TextDecoder(t).decode(e)}}if(env$1().get("IS_BROWSER")){env$1().setPlatform("browser",new PlatformBrowser$1);try{ModelStoreManagerRegistry$1.registerManager(BrowserLocalStorage$1.URL_SCHEME,new BrowserLocalStorageManager$1)}catch(e){}try{ModelStoreManagerRegistry$1.registerManager(BrowserIndexedDB$1.URL_SCHEME,new BrowserIndexedDBManager$1)}catch(e){}}const getNodeFetch$1={importFetch:()=>require("node-fetch")};let systemFetch$1;class PlatformNode$1{constructor(){this.util=require("util"),this.textEncoder=new this.util.TextEncoder}fetch(e,t){return null!=env$1().global.fetch?env$1().global.fetch(e,t):(null==systemFetch$1&&(systemFetch$1=getNodeFetch$1.importFetch()),systemFetch$1(e,t))}now(){const e=process.hrtime();return 1e3*e[0]+e[1]/1e6}encode(e,t){if("utf-8"!==t&&"utf8"!==t)throw new Error(`Node built-in encoder only supports utf-8, but got ${t}`);return this.textEncoder.encode(e)}decode(e,t){return 0===e.length?"":new this.util.TextDecoder(t).decode(e)}}function buffer$1(e,t="float32",n){return t=t||"float32",assertNonNegativeIntegerDimensions$1(e),new TensorBuffer$1(e,t,n)}function cast_$1(e,t){const n=convertToTensor$1(e,"x","cast");if(!isValidDtype$1(t))throw new Error(`Failed to cast to unknown dtype ${t}`);if("string"===t&&"string"!==n.dtype||"string"!==t&&"string"===n.dtype)throw new Error("Only strings can be casted to strings");return ENGINE$1.runKernel(Cast$1,{x:n},{dtype:t})}env$1().get("IS_NODE")&&env$1().setPlatform("node",new PlatformNode$1);const cast$7=op$1({cast_:cast_$1});function clone_$1(e){const t=convertToTensor$1(e,"x","clone","string_or_numeric");return ENGINE$1.runKernel(Identity$3,{x:t})}const clone$1=op$1({clone_:clone_$1});function print$1(e,t=!1){console.log(e.toString(t))}getOrMakeEngine$1();const opHandler$2={buffer:buffer$1,cast:cast$7,clone:clone$1,print:print$1};setOpHandler$1(opHandler$2);const DEFAULT_FILE_NAME_PREFIX$1="model",DEFAULT_JSON_EXTENSION_NAME$1=".json",DEFAULT_WEIGHT_DATA_EXTENSION_NAME$1=".weights.bin";function defer$1(e){return new Promise(e=>setTimeout(e)).then(e)}class BrowserDownloads$1{constructor(e){if(!env$1().getBool("IS_BROWSER"))throw new Error("browserDownloads() cannot proceed because the current environment is not a browser.");e.startsWith(BrowserDownloads$1.URL_SCHEME)&&(e=e.slice(BrowserDownloads$1.URL_SCHEME.length)),null!=e&&0!==e.length||(e=DEFAULT_FILE_NAME_PREFIX$1),this.modelJsonFileName=e+DEFAULT_JSON_EXTENSION_NAME$1,this.weightDataFileName=e+DEFAULT_WEIGHT_DATA_EXTENSION_NAME$1}async save(e){if("undefined"==typeof document)throw new Error("Browser downloads are not supported in this environment since `document` is not present");const t=window.URL.createObjectURL(new Blob([e.weightData],{type:"application/octet-stream"}));if(e.modelTopology instanceof ArrayBuffer)throw new Error("BrowserDownloads.save() does not support saving model topology in binary formats yet.");{const n=getModelJSONForModelArtifacts$1(e,[{paths:["./"+this.weightDataFileName],weights:e.weightSpecs}]),r=window.URL.createObjectURL(new Blob([JSON.stringify(n)],{type:"application/json"})),a=null==this.modelJsonAnchor?document.createElement("a"):this.modelJsonAnchor;if(a.download=this.modelJsonFileName,a.href=r,await defer$1(()=>a.dispatchEvent(new MouseEvent("click"))),null!=e.weightData){const e=null==this.weightDataAnchor?document.createElement("a"):this.weightDataAnchor;e.download=this.weightDataFileName,e.href=t,await defer$1(()=>e.dispatchEvent(new MouseEvent("click")))}return{modelArtifactsInfo:getModelArtifactsInfoForJSON$1(e)}}}}BrowserDownloads$1.URL_SCHEME="downloads://";const browserDownloadsRouter$1=e=>env$1().getBool("IS_BROWSER")&&!Array.isArray(e)&&e.startsWith(BrowserDownloads$1.URL_SCHEME)?browserDownloads$1(e.slice(BrowserDownloads$1.URL_SCHEME.length)):null;function browserDownloads$1(e="model"){return new BrowserDownloads$1(e)}function monitorPromisesProgress$1(e,t,n,r){!function(e){assert$6(null!=e&&Array.isArray(e)&&e.length>0,()=>"promises must be a none empty array")}(e),function(e,t){assert$6(e>=0&&e<=1,()=>`Progress fraction must be in range [0, 1], but got startFraction ${e}`),assert$6(t>=0&&t<=1,()=>`Progress fraction must be in range [0, 1], but got endFraction ${t}`),assert$6(t>=e,()=>`startFraction must be no more than endFraction, but got startFraction ${e} and endFraction ${t}`)}(n=null==n?0:n,r=null==r?1:r);let a=0;return Promise.all(e.map(s=>(s.then(s=>{const o=n+ ++a/e.length*(r-n);return t(o),s}),s)))}async function loadWeightsAsArrayBuffer$1(e,t){null==t&&(t={});const n=null==t.fetchFunc?env$1().platform.fetch:t.fetchFunc,r=e.map(e=>n(e,t.requestInit,{isBinary:!0})),a=(null==t.onProgress?await Promise.all(r):await monitorPromisesProgress$1(r,t.onProgress,0,.5)).map(e=>e.arrayBuffer());return null==t.onProgress?await Promise.all(a):await monitorPromisesProgress$1(a,t.onProgress,.5,1)}IORouterRegistry$1.registerSaveRouter(browserDownloadsRouter$1);const OCTET_STREAM_MIME_TYPE$1="application/octet-stream",JSON_TYPE$1="application/json";class HTTPRequest$1{constructor(e,t){if(this.DEFAULT_METHOD="POST",null==t&&(t={}),this.weightPathPrefix=t.weightPathPrefix,this.onProgress=t.onProgress,this.weightUrlConverter=t.weightUrlConverter,null!=t.fetchFunc?(assert$6("function"==typeof t.fetchFunc,()=>"Must pass a function that matches the signature of `fetch` (see https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API)"),this.fetch=t.fetchFunc):this.fetch=env$1().platform.fetch,assert$6(null!=e&&e.length>0,()=>"URL path for http must not be null, undefined or empty."),Array.isArray(e)&&assert$6(2===e.length,()=>`URL paths for http must have a length of 2, (actual length is ${e.length}).`),this.path=e,null!=t.requestInit&&null!=t.requestInit.body)throw new Error("requestInit is expected to have no pre-existing body, but has one.");this.requestInit=t.requestInit||{}}async save(e){if(e.modelTopology instanceof ArrayBuffer)throw new Error("BrowserHTTPRequest.save() does not support saving model topology in binary formats yet.");const t=Object.assign({method:this.DEFAULT_METHOD},this.requestInit);t.body=new FormData;const n=getModelJSONForModelArtifacts$1(e,[{paths:["./model.weights.bin"],weights:e.weightSpecs}]);t.body.append("model.json",new Blob([JSON.stringify(n)],{type:JSON_TYPE$1}),"model.json"),null!=e.weightData&&t.body.append("model.weights.bin",new Blob([e.weightData],{type:OCTET_STREAM_MIME_TYPE$1}),"model.weights.bin");const r=await this.fetch(this.path,t);if(r.ok)return{modelArtifactsInfo:getModelArtifactsInfoForJSON$1(e),responses:[r]};throw new Error(`BrowserHTTPRequest.save() failed due to HTTP response status ${r.status}.`)}async load(){const e=await this.fetch(this.path,this.requestInit);if(!e.ok)throw new Error(`Request to ${this.path} failed with status code ${e.status}. Please verify this URL points to the model JSON of the model to load.`);let t;try{t=await e.json()}catch(e){let t=`Failed to parse model JSON of response from ${this.path}.`;throw this.path.endsWith(".pb")?t+=" Your path contains a .pb file extension. Support for .pb models have been removed in TensorFlow.js 1.0 in favor of .json models. You can re-convert your Python TensorFlow model using the TensorFlow.js 1.0 conversion scripts or you can convert your.pb models with the 'pb2json'NPM script in the tensorflow/tfjs-converter repository.":t+=" Please make sure the server is serving valid JSON for this request.",new Error(t)}if(null==t.modelTopology&&null==t.weightsManifest)throw new Error(`The JSON from HTTP path ${this.path} contains neither model topology or manifest for weights.`);return getModelArtifactsForJSON$1(t,e=>this.loadWeights(e))}async loadWeights(e){const t=Array.isArray(this.path)?this.path[1]:this.path,[n,r]=parseUrl$1(t),a=this.weightPathPrefix||n,s=[];for(const t of e)s.push(...t.weights);const o=[],i=[];for(const t of e)for(const e of t.paths)null!=this.weightUrlConverter?i.push(this.weightUrlConverter(e)):o.push(a+e+r);return this.weightUrlConverter&&o.push(...await Promise.all(i)),[s,concatenateArrayBuffers$1(await loadWeightsAsArrayBuffer$1(o,{requestInit:this.requestInit,fetchFunc:this.fetch,onProgress:this.onProgress}))]}}function parseUrl$1(e){const t=e.lastIndexOf("/"),n=e.lastIndexOf("?");return[e.substring(0,t)+"/",n>t?e.substring(n):""]}function isHTTPScheme$1(e){return null!=e.match(HTTPRequest$1.URL_SCHEME_REGEX)}HTTPRequest$1.URL_SCHEME_REGEX=/^https?:\/\//;const httpRouter$1=(e,t)=>{if("undefined"==typeof fetch&&(null==t||null==t.fetchFunc))return null;{let n=!0;if(n=Array.isArray(e)?e.every(e=>isHTTPScheme$1(e)):isHTTPScheme$1(e),n)return http$1(e,t)}return null};function http$1(e,t){return new HTTPRequest$1(e,t)}function browserHTTPRequest$1(e,t){return http$1(e,t)}function matMul_$1(e,t,n=!1,r=!1){let a=convertToTensor$1(e,"a","matMul"),s=convertToTensor$1(t,"b","matMul");return[a,s]=makeTypesMatch$1(a,s),ENGINE$1.runKernel(BatchMatMul$1,{a,b:s},{transposeA:n,transposeB:r})}IORouterRegistry$1.registerSaveRouter(httpRouter$1),IORouterRegistry$1.registerLoadRouter(httpRouter$1);const matMul$3=op$1({matMul_:matMul_$1});function oneHot_$1(e,t,n=1,r=0){if(t<2)throw new Error(`Error in oneHot: depth must be >=2, but it is ${t}`);const a=convertToTensor$1(e,"indices","oneHot","int32");return ENGINE$1.runKernel(OneHot$1,{indices:a},{depth:t,onValue:n,offValue:r})}const oneHot$5=op$1({oneHot_:oneHot_$1});function transpose_$1(e,t){const n=convertToTensor$1(e,"x","transpose");return null==t&&(t=n.shape.map((e,t)=>t).reverse()),assert$6(n.rank===t.length,()=>`Error in transpose: rank of input ${n.rank} must match length of perm ${t}.`),t.forEach(e=>{assert$6(e>=0&&e<n.rank,()=>"All entries in 'perm' must be between 0 and "+(n.rank-1)+` but got ${t}`)}),n.rank<=1?n.clone():ENGINE$1.runKernel(Transpose$1,{x:n},{perm:t})}const transpose$5=op$1({transpose_:transpose_$1});function tensor3d$1(e,t,n){if(assertNonNull$1(e),null!=t&&3!==t.length)throw new Error("tensor3d() requires shape to have three numbers");const r=inferShape$1(e,n);if(3!==r.length&&1!==r.length)throw new Error("tensor3d() requires values to be number[][][] or flat/TypedArray");if(1===r.length&&null==t)throw new Error("tensor3d() requires shape to be provided when `values` are a flat array");return makeTensor$1(e,t,r,n)}function prepareAndValidate$1(e,t){const n=e.shape.length,r=t.shape.length;if(n<1)throw new Error(`tf.gatherND() expects the input to be rank 1 or higher, but the rank was ${n}.`);if(r<1)throw new Error(`tf.gatherND() expects the indices to be rank 1 or higher, but the rank was ${r}.`);if("int32"!==t.dtype)throw new Error(`tf.gatherND() expects the indices to be int32 type, but the dtype was ${t.dtype}.`);if(t.shape[r-1]>n)throw new Error(`index innermost dimension length must be <= tensor rank; saw: ${t.shape[r-1]} vs. ${n}`);if(0===sizeFromShape$1(e.shape))throw new Error(`Requested more than 0 entries, but input is empty. Input shape: ${e.shape}.`);const a=t.shape,s=a[a.length-1];let o=1;for(let e=0;e<a.length-1;++e)o*=a[e];const i=e.shape,l=a.slice();l.pop();let u=1;for(let e=s;e<n;++e)u*=i[e],l.push(i[e]);const c=[...computeStrides$1(e.shape).map(e=>e/u),1].slice(0,s);return[l,o,u,c]}function validateUpdateShape$1(e,t,n){const r=t.rank>1?t.shape[t.rank-1]:1,a=t.rank>1?t.rank-1:1,s=`Must have updates.shape = indices.shape[:batchDim] + shape[sliceDim:], got updates.shape: ${n.shape}, indices.shape: ${t.shape}, shape: ${e}, sliceDim: ${r}, and batchDim: ${a}.`;if(n.rank<a)throw new Error(s+` update.rank < ${a}. `);if(e.length<r+(n.rank-a))throw new Error(s+` Output shape length < ${r+(n.rank-a)}`);if(n.rank!==a+e.length-r)throw new Error(s+" update.rank != "+(a+e.length-r));for(let e=0;e<a;++e)if(n.shape[e]!==t.shape[e])throw new Error(s+` updates.shape[${e}] (${n.shape[e]}) != indices.shape[${e}] (${t.shape[e]}).`);for(let t=0;t<n.rank-a;++t)if(n.shape[t+a]!==e[t+r])throw new Error(s+` updates.shape[${t+a}] (${n.shape[t+a]}) != shape[${t+a}] (${e[t+a]})`)}function validateInput$2(e,t,n){if(t.rank<1)throw new Error(`tf.scatterND() expects the indices to be rank 1 or higher, but the rank was ${t.rank}.`);if(e.rank<1)throw new Error(`tf.scatterND() expects the updates to be rank 1 or higher, but the rank was ${e.rank}.`);if("int32"!==t.dtype)throw new Error(`The dtype of 'indices' should be int32, but got dtype: ${t.dtype}`);if(n.length<1)throw new Error(`Output rank must be greater or equal to 1, but got shape: ${n}`);if(0===n.length){if(0===t.size)throw new Error(`Indices specified for empty output. indices shape: ${t.shape}`);if(0===e.size)throw new Error(`Updates specified for empty output. updates shape: ${e.shape}`)}validateUpdateShape$1(n,t,e)}function calculateShapes$1(e,t,n){const r=t.shape.length,a=r>1?t.shape[r-1]:1,s=n.length;let o=1;for(let e=a;e<s;++e)o*=n[e];const i=a<1?1:a;return{sliceRank:a,numUpdates:sizeFromShape$1(t.shape)/i,sliceSize:o,strides:[...computeStrides$1(n.slice(0,a)),1],outputSize:sizeFromShape$1(n)}}function assertParamsValid$1(e,t,n){const r=e.shape.length;assert$6(r===t.length,()=>`Error in slice${r}D: Length of begin ${t} must match the rank of the array (${r}).`),assert$6(r===n.length,()=>`Error in slice${r}D: Length of size ${n} must match the rank of the array (${r}).`);for(let a=0;a<r;++a)assert$6(t[a]+n[a]<=e.shape[a],()=>`Error in slice${r}D: begin[${a}] + size[${a}] (${t[a]+n[a]}) would overflow input.shape[${a}] (${e.shape[a]})`)}function maskToAxes$1(e){const t=[];let n=0;for(;e>0;)1&e&&t.push(n),e/=2,n++;return t}function computeOutShape$5(e,t,n){const r=[];for(let a=0;a<e.length;a++)r[a]=Math.ceil((t[a]-e[a])/n[a]);return r}function stridesWithElidedDims$1(e,t,n,r){const a=[...e];for(let e=a.length;e<r.length;e++)a.push(1);for(let e=0;e<n;e++)0===e?a[t]=1:(a.splice(t,0,1),a.pop());return a}function unnormalizeAxis$1(e,t,n){return n<=e?n:n-(t-1)}function getElidedAxes$1(e,t){const n=[];for(let r=0;r<e;r++)n.push(t+r);return n}function getNormalizedAxes$1(e,t,n,r,a,s,o,i,l){const u=e.length;let c=new Array(u),p=new Array(u),d=new Array(u);if(t.length&&n>0){const l=t[0],u=n+1;c=startIndicesWithElidedDims$1(o,l,u,r,e),p=stopIndicesWithElidedDims$1(i,l,u,a,e),d=stridesWithElidedDims$1(s,l,u,e)}else for(let t=0;t<u;t++)c[t]=startForAxis$1(o,r,s,e,t,l),p[t]=stopForAxis$1(i,a,s,e,t,l),d[t]=stridesForAxis$1(s,t,l);return{begin:c,end:p,strides:d}}function startIndicesWithElidedDims$1(e,t,n,r,a){const s=[...a],o=getElidedAxes$1(n,t);for(let a=0;a<s.length;a++)if(o.indexOf(a)>-1)s[a]=0;else{const o=unnormalizeAxis$1(t,n,a);let i=r[o];e&1<<o&&(i=0),s[a]=i}return s}function stopIndicesWithElidedDims$1(e,t,n,r,a){const s=[...a],o=getElidedAxes$1(n,t);for(let a=0;a<s.length;a++)if(o.indexOf(a)>-1)s[a]=Number.MAX_SAFE_INTEGER;else{const o=unnormalizeAxis$1(t,n,a);let i=r[o];e&1<<o&&(i=Number.MAX_SAFE_INTEGER),s[a]=i}for(let e=0;e<s.length;e++){const t=a[e];s[e]<0&&(s[e]+=t),s[e]=clamp$1(0,s[e],a[e])}return s}function stridesForAxis$1(e,t,n){let r=e[t];return(n&1<<t||null==r)&&(r=1),r}function startForAxis$1(e,t,n,r,a,s){let o=t[a];(e&1<<a||s&1<<a||null==o)&&(o=(n[a]||1)>0?Number.MIN_SAFE_INTEGER:Number.MAX_SAFE_INTEGER);const i=r[a];return o<0&&(o+=i),o=clamp$1(0,o,i-1),o}function stopForAxis$1(e,t,n,r,a,s){let o=t[a];const i=n[a]||1;(e&1<<a||s&1<<a||null==o)&&(o=i>0?Number.MAX_SAFE_INTEGER:Number.MIN_SAFE_INTEGER);const l=r[a];return o<0&&(o+=l),o=i>0?clamp$1(0,o,l):clamp$1(-1,o,l-1),o}function isSliceContinous$1(e,t,n){let r=n.length;for(let e=0;e<n.length;e++)if(n[e]>1){r=e;break}for(let a=r+1;a<n.length;a++)if(t[a]>0||n[a]!==e[a])return!1;return!0}function computeFlatOffset$1(e,t){let n=e.length>0?e[e.length-1]:1;for(let r=0;r<e.length-1;r++)n+=e[r]*t[r];return n}function parseSliceParams$1(e,t,n){let r;const a=e.shape.length;let s;return r="number"==typeof t?[t,...new Array(a-1).fill(0)]:t.length<a?t.concat(new Array(a-t.length).fill(0)):t.slice(),r.forEach(e=>{assert$6(-1!==e,()=>"slice() does not support negative begin indexing.")}),s=null==n?new Array(a).fill(-1):"number"==typeof n?[n,...new Array(a-1).fill(-1)]:n.length<a?n.concat(new Array(a-n.length).fill(-1)):n,s=s.map((t,n)=>t>=0?t:(assert$6(-1===t,()=>`Negative size values should be exactly -1 but got ${t} for the slice() size at index ${n}.`),e.shape[n]-r[n])),[r,s]}function sliceInfo$1(e,t,n,r,a,s,o,i,l){let u=t.slice(),c=n.slice(),p=r;null==r&&(p=new Array(u.length));const d=maskToAxes$1(o);if(d.length>1)throw new Error("Multiple ellipses in slice is not allowed.");if(0!==o&&0!==i)throw new Error("Using both ellipsisMask and newAxisMask is not yet supported.");if(0!==o&&0!==l)throw new Error("Using both ellipsisMask and shrinkAxisMask is not yet supported.");const h=e.length-u.length,m=maskToAxes$1(i),f=e.slice();m.forEach(e=>{u[e]=0,c[e]=1,f.splice(e,0,1)});const{begin:g,end:$,strides:y}=getNormalizedAxes$1(f,d,h,u,c,p,a,s,o);u=g,c=$,p=y;const b=maskToAxes$1(l);b.forEach(e=>{c[e]=u[e]+1,p[e]=1});const x=computeOutShape$5(u,c,p),v=x.filter((e,t)=>-1===b.indexOf(t));return{nonStrided:p.every(e=>1===e),$begin:u,$end:c,$strides:p,size:x,newShape:f,outShape:v}}var slice_util$1={__proto__:null,assertParamsValid:assertParamsValid$1,maskToAxes:maskToAxes$1,computeOutShape:computeOutShape$5,stridesWithElidedDims:stridesWithElidedDims$1,getNormalizedAxes:getNormalizedAxes$1,startIndicesWithElidedDims:startIndicesWithElidedDims$1,stopIndicesWithElidedDims:stopIndicesWithElidedDims$1,stridesForAxis:stridesForAxis$1,startForAxis:startForAxis$1,stopForAxis:stopForAxis$1,isSliceContinous:isSliceContinous$1,computeFlatOffset:computeFlatOffset$1,parseSliceParams:parseSliceParams$1,sliceInfo:sliceInfo$1};class Serializable$1{getClassName(){return this.constructor.className}static fromConfig(e,t){return new e(t)}}class SerializationMap$1{constructor(){this.classNameMap={}}static getMap(){return null==SerializationMap$1.instance&&(SerializationMap$1.instance=new SerializationMap$1),SerializationMap$1.instance}static register(e){SerializationMap$1.getMap().classNameMap[e.className]=[e,e.fromConfig]}}function registerClass$1(e){assert$6(null!=e.className,()=>"Class being registered does not have the static className property defined."),assert$6("string"==typeof e.className,()=>"className is required to be a string, but got type "+typeof e.className),assert$6(e.className.length>0,()=>"Class being registered has an empty-string as its className, which is disallowed."),SerializationMap$1.register(e)}const version$e="3.8.0";function engine$1(){return ENGINE$1}function memory$1(){return ENGINE$1.memory()}function tidy$1(e,t){return ENGINE$1.tidy(e,t)}function dispose$1(e){getTensorsInContainer$1(e).forEach(e=>e.dispose())}function keep$1(e){return ENGINE$1.keep(e)}function registerBackend$1(e,t,n=1){return ENGINE$1.registerBackend(e,t,n)}function backend$1(){return ENGINE$1.backend}function add_$1(e,t){let n=convertToTensor$1(e,"a","add"),r=convertToTensor$1(t,"b","add");return[n,r]=makeTypesMatch$1(n,r),ENGINE$1.runKernel(Add$3,{a:n,b:r})}const add$5=op$1({add_:add_$1});function floorDiv_$1(e,t){let n=convertToTensor$1(e,"a","floorDiv"),r=convertToTensor$1(t,"b","floorDiv");return[n,r]=makeTypesMatch$1(n,r),ENGINE$1.runKernel(FloorDiv$1,{a:n,b:r})}const floorDiv$5=op$1({floorDiv_:floorDiv_$1});function div_$1(e,t){let n=convertToTensor$1(e,"a","div"),r=convertToTensor$1(t,"b","div");return[n,r]=makeTypesMatch$1(n,r),"int32"===n.dtype&&"int32"===r.dtype?floorDiv$5(n,r):ENGINE$1.runKernel(RealDiv$1,{a:n,b:r},{})}const div$3=op$1({div_:div_$1});function mul_$1(e,t){let n=convertToTensor$1(e,"a","mul"),r=convertToTensor$1(t,"b","mul");return[n,r]=makeTypesMatch$1(n,r),ENGINE$1.runKernel(Multiply$3,{a:n,b:r})}const mul$1=op$1({mul_:mul_$1});function abs_$1(e){const t=convertToTensor$1(e,"x","abs");return ENGINE$1.runKernel("complex64"===t.dtype?ComplexAbs$1:Abs$1,{x:t})}const abs$5=op$1({abs_:abs_$1});function acos_$1(e){const t=convertToTensor$1(e,"x","acos");return ENGINE$1.runKernel(Acos$1,{x:t})}const acos$5=op$1({acos_:acos_$1});function acosh_$1(e){const t=convertToTensor$1(e,"x","acosh");return ENGINE$1.runKernel(Acosh$1,{x:t})}const acosh$5=op$1({acosh_:acosh_$1});function all_$1(e,t=null,n=!1){const r=convertToTensor$1(e,"x","all","bool");return ENGINE$1.runKernel(All$1,{x:r},{axis:t,keepDims:n})}const all$5=op$1({all_:all_$1});function any_$1(e,t=null,n=!1){const r=convertToTensor$1(e,"x","any","bool");return ENGINE$1.runKernel(Any$1,{x:r},{axis:t,keepDims:n})}const any$5=op$1({any_:any_$1});function argMax_$1(e,t=0){const n=convertToTensor$1(e,"x","argMax");return ENGINE$1.runKernel(ArgMax$1,{x:n},{axis:t})}const argMax$5=op$1({argMax_:argMax_$1});function argMin_$1(e,t=0){const n=convertToTensor$1(e,"x","argMin");return ENGINE$1.runKernel(ArgMin$1,{x:n},{axis:t})}const argMin$5=op$1({argMin_:argMin_$1});function asin_$1(e){const t=convertToTensor$1(e,"x","asin");return ENGINE$1.runKernel(Asin$1,{x:t})}const asin$5=op$1({asin_:asin_$1});function asinh_$1(e){const t=convertToTensor$1(e,"x","asinh");return ENGINE$1.runKernel(Asinh$1,{x:t})}const asinh$5=op$1({asinh_:asinh_$1});function atan_$1(e){const t=convertToTensor$1(e,"x","atan");return ENGINE$1.runKernel(Atan$1,{x:t})}const atan$5=op$1({atan_:atan_$1});function atan2_$1(e,t){let n=convertToTensor$1(e,"a","atan2"),r=convertToTensor$1(t,"b","atan2");return[n,r]=makeTypesMatch$1(n,r),ENGINE$1.runKernel(Atan2$1,{a:n,b:r})}const atan2$5=op$1({atan2_:atan2_$1});function atanh_$1(e){const t=convertToTensor$1(e,"x","atanh");return ENGINE$1.runKernel(Atanh$1,{x:t})}const atanh$5=op$1({atanh_:atanh_$1});function computeDilation2DInfo$1(e,t,n,r,a="NHWC",s){return computeConv2DInfo$1(e,[...t,e[3]],n,s,r,null,null,convertConv2DDataFormat$1(a))}function computePool2DInfo$1(e,t,n,r,a,s,o="channelsLast"){const[i,l]=parseTupleParam$1(t);let u;if("channelsLast"===o)u=[i,l,e[3],e[3]];else{if("channelsFirst"!==o)throw new Error(`Unknown dataFormat ${o}`);u=[i,l,e[1],e[1]]}return computeConv2DInfo$1(e,u,n,r,a,s,!1,o)}function computePool3DInfo$1(e,t,n,r,a,s,o="NDHWC"){const[i,l,u]=parse3TupleParam$1(t);let c,p;if("NDHWC"===o)p="channelsLast",c=[i,l,u,e[4],e[4]];else{if("NCDHW"!==o)throw new Error(`Unknown dataFormat ${o}`);p="channelsFirst",c=[i,l,u,e[1],e[1]]}return computeConv3DInfo$1(e,c,n,r,a,!1,p,s)}function computeConv2DInfo$1(e,t,n,r,a,s,o=!1,i="channelsLast"){let[l,u,c,p]=[-1,-1,-1,-1];if("channelsLast"===i)[l,u,c,p]=e;else{if("channelsFirst"!==i)throw new Error(`Unknown dataFormat ${i}`);[l,p,u,c]=e}const[d,h,,m]=t,[f,g]=parseTupleParam$1(n),[$,y]=parseTupleParam$1(r),b=getEffectiveFilterSize$1(d,$),x=getEffectiveFilterSize$1(h,y),{padInfo:v,outHeight:I,outWidth:C}=getPadAndOutInfo$1(a,u,c,f,g,b,x,s,i),S=o?m*p:m;let k;return"channelsFirst"===i?k=[l,S,I,C]:"channelsLast"===i&&(k=[l,I,C,S]),{batchSize:l,dataFormat:i,inHeight:u,inWidth:c,inChannels:p,outHeight:I,outWidth:C,outChannels:S,padInfo:v,strideHeight:f,strideWidth:g,filterHeight:d,filterWidth:h,effectiveFilterHeight:b,effectiveFilterWidth:x,dilationHeight:$,dilationWidth:y,inShape:e,outShape:k,filterShape:t}}function computeConv3DInfo$1(e,t,n,r,a,s=!1,o="channelsLast",i){let[l,u,c,p,d]=[-1,-1,-1,-1,-1];if("channelsLast"===o)[l,u,c,p,d]=e;else{if("channelsFirst"!==o)throw new Error(`Unknown dataFormat ${o}`);[l,d,u,c,p]=e}const[h,m,f,,g]=t,[$,y,b]=parse3TupleParam$1(n),[x,v,I]=parse3TupleParam$1(r),C=getEffectiveFilterSize$1(h,x),S=getEffectiveFilterSize$1(m,v),k=getEffectiveFilterSize$1(f,I),{padInfo:T,outDepth:N,outHeight:w,outWidth:E}=get3DPadAndOutInfo$1(a,u,c,p,$,y,b,C,S,k,i),A=s?g*d:g;let D;return"channelsFirst"===o?D=[l,A,N,w,E]:"channelsLast"===o&&(D=[l,N,w,E,A]),{batchSize:l,dataFormat:o,inDepth:u,inHeight:c,inWidth:p,inChannels:d,outDepth:N,outHeight:w,outWidth:E,outChannels:A,padInfo:T,strideDepth:$,strideHeight:y,strideWidth:b,filterDepth:h,filterHeight:m,filterWidth:f,effectiveFilterDepth:C,effectiveFilterHeight:S,effectiveFilterWidth:k,dilationDepth:x,dilationHeight:v,dilationWidth:I,inShape:e,outShape:D,filterShape:t}}function computeOutputShape2D$1(e,t,n,r,a){null==r&&(r=computeDefaultPad$1(e,t,n));const s=e[1];return[round$7((e[0]-t+2*r)/n+1,a),round$7((s-t+2*r)/n+1,a)]}function computeOutputShape4D$1(e,t,n,r,a,s){null==a&&(a=computeDefaultPad$1(e,t,r));const o=e[1],i=e[2];return[round$7((e[0]-t+2*a)/r+1,s),round$7((o-t+2*a)/r+1,s),round$7((i-t+2*a)/r+1,s),n]}function computeDefaultPad$1(e,t,n,r=1){const a=getEffectiveFilterSize$1(t,r);return Math.floor((e[0]*(n-1)-n+a)/2)}function parseTupleParam$1(e){return"number"==typeof e?[e,e,e]:2===e.length?[e[0],e[1],1]:e}function parse3TupleParam$1(e){return"number"==typeof e?[e,e,e]:e}function getEffectiveFilterSize$1(e,t){return t<=1?e:e+(e-1)*(t-1)}function getPadAndOutInfo$1(e,t,n,r,a,s,o,i,l){let u,c,p;if("number"==typeof e){u={top:e,bottom:e,left:e,right:e,type:0===e?"VALID":"NUMBER"};const a=computeOutputShape2D$1([t,n],s,r,e,i);c=a[0],p=a[1]}else if("same"===e){c=Math.ceil(t/r),p=Math.ceil(n/a);const e=Math.max(0,(c-1)*r+s-t),i=Math.max(0,(p-1)*a+o-n),l=Math.floor(e/2),d=e-l,h=Math.floor(i/2);u={top:l,bottom:d,left:h,right:i-h,type:"SAME"}}else if("valid"===e)u={top:0,bottom:0,left:0,right:0,type:"VALID"},c=Math.ceil((t-s+1)/r),p=Math.ceil((n-o+1)/a);else{if("object"!=typeof e)throw Error(`Unknown padding parameter: ${e}`);{const d="channelsLast"===l?e[1][0]:e[2][0],h="channelsLast"===l?e[1][1]:e[2][1],m="channelsLast"===l?e[2][0]:e[3][0],f="channelsLast"===l?e[2][1]:e[3][1];u={top:d,bottom:h,left:m,right:f,type:0===d&&0===h&&0===m&&0===f?"VALID":"EXPLICIT"},c=round$7((t-s+d+h)/r+1,i),p=round$7((n-o+m+f)/a+1,i)}}return{padInfo:u,outHeight:c,outWidth:p}}function get3DPadAndOutInfo$1(e,t,n,r,a,s,o,i,l,u,c){let p,d,h,m;if("number"==typeof e){p={top:e,bottom:e,left:e,right:e,front:e,back:e,type:0===e?"VALID":"NUMBER"};const s=computeOutputShape4D$1([t,n,r,1],i,1,a,e,c);d=s[0],h=s[1],m=s[2]}else if("same"===e){d=Math.ceil(t/a),h=Math.ceil(n/s),m=Math.ceil(r/o);const e=(d-1)*a+i-t,c=(h-1)*s+l-n,f=(m-1)*o+u-r,g=Math.floor(e/2),$=e-g,y=Math.floor(c/2),b=c-y,x=Math.floor(f/2);p={top:y,bottom:b,left:x,right:f-x,front:g,back:$,type:"SAME"}}else{if("valid"!==e)throw Error(`Unknown padding parameter: ${e}`);p={top:0,bottom:0,left:0,right:0,front:0,back:0,type:"VALID"},d=Math.ceil((t-i+1)/a),h=Math.ceil((n-l+1)/s),m=Math.ceil((r-u+1)/o)}return{padInfo:p,outDepth:d,outHeight:h,outWidth:m}}function round$7(e,t){if(!t)return Math.trunc(e);switch(t){case"round":return Math.round(e);case"ceil":return Math.ceil(e);case"floor":return Math.floor(e);default:throw new Error(`Unknown roundingMode ${t}`)}}function tupleValuesAreOne$1(e){const[t,n,r]=parseTupleParam$1(e);return 1===t&&1===n&&1===r}function eitherStridesOrDilationsAreOne$1(e,t){return tupleValuesAreOne$1(e)||tupleValuesAreOne$1(t)}function convertConv2DDataFormat$1(e){if("NHWC"===e)return"channelsLast";if("NCHW"===e)return"channelsFirst";throw new Error(`Unknown dataFormat ${e}`)}function reshape_$1(e,t){const n=convertToTensor$1(e,"x","reshape","string_or_numeric");return ENGINE$1.runKernel(Reshape$3,{x:n},{shape:t})}const reshape$6=op$1({reshape_:reshape_$1});function avgPool_$1(e,t,n,r,a){const s=convertToTensor$1(e,"x","avgPool","float32");assert$6(eitherStridesOrDilationsAreOne$1(n,1),()=>`Error in avgPool: Either strides or dilations must be 1. Got strides ${n} and dilations '1'`);let o=s,i=!1;3===s.rank&&(i=!0,o=reshape$6(s,[1,s.shape[0],s.shape[1],s.shape[2]])),assert$6(4===o.rank,()=>`Error in avgPool: x must be rank 4 but got rank ${o.rank}.`),null!=a&&assert$6(isInt$1(r),()=>`Error in avgPool: pad must be an integer when using, dimRoundingMode ${a} but got pad ${r}.`);let l=ENGINE$1.runKernel(AvgPool$1,{x:o},{filterSize:t,strides:n,pad:r,dimRoundingMode:a});return l=cast$7(l,s.dtype),i?reshape$6(l,[l.shape[1],l.shape[2],l.shape[3]]):l}const avgPool$5=op$1({avgPool_:avgPool_$1});function avgPool3d_$1(e,t,n,r,a,s="NDHWC"){const o=convertToTensor$1(e,"x","avgPool3d","float32");let i=o,l=!1;4===o.rank&&(l=!0,i=reshape$6(o,[1,o.shape[0],o.shape[1],o.shape[2],o.shape[3]])),assert$6(5===i.rank,()=>`Error in avgPool3d: x must be rank 5 but got rank ${i.rank}.`),assert$6("NDHWC"===s,()=>`Error in avgPool3d: Only NDHWC is currently supported, but got dataFormat of ${s}`),null!=a&&assert$6(isInt$1(r),()=>`Error in avgPool3d: pad must be an integer when using, dimRoundingMode ${a} but got pad ${r}.`);let u=ENGINE$1.runKernel(AvgPool3D$1,{x:i},{filterSize:t,strides:n,pad:r,dimRoundingMode:a,dataFormat:s});return u=cast$7(u,i.dtype),l?reshape$6(u,[u.shape[1],u.shape[2],u.shape[3],u.shape[4]]):u}const avgPool3d$2=op$1({avgPool3d_:avgPool3d_$1});function concat_$1(e,t=0){assert$6(e.length>=1,()=>"Pass at least one tensor to concat");const n=convertToTensorArray$1(e,"tensors","concat","string_or_numeric");return"complex64"===n[0].dtype&&n.forEach(e=>{if("complex64"!==e.dtype)throw new Error(`Cannot concatenate complex64 tensors with a tensor\n          with dtype ${e.dtype}. `)}),1===n.length?clone$1(n[0]):ENGINE$1.runKernel(Concat$1,n,{axis:t})}const concat$5=op$1({concat_:concat_$1});function sigmoid_$1(e){const t=convertToTensor$1(e,"x","sigmoid");return ENGINE$1.runKernel(Sigmoid$3,{x:t})}const sigmoid$5=op$1({sigmoid_:sigmoid_$1});function slice_$1(e,t,n){const r=convertToTensor$1(e,"x","slice","string_or_numeric");if(0===r.rank)throw new Error("Slicing scalar is not possible");return ENGINE$1.runKernel(Slice$1,{x:r},{begin:t,size:n})}const slice$5=op$1({slice_:slice_$1});function tanh_$1(e){const t=convertToTensor$1(e,"x","tanh");return ENGINE$1.runKernel(Tanh$3,{x:t})}const tanh$6=op$1({tanh_:tanh_$1});function batchToSpaceND_$1(e,t,n){const r=convertToTensor$1(e,"x","batchToSpaceND"),a=t.reduce((e,t)=>e*t);return assert$6(r.rank>=1+t.length,()=>`input rank is ${r.rank} but should be > than blockShape.length ${t.length}`),assert$6(n.length===t.length,()=>`crops.length is ${n.length} but should be equal to blockShape.length  ${t.length}`),assert$6(r.shape[0]%a==0,()=>`input tensor batch is ${r.shape[0]} but is not divisible by the product of the elements of blockShape ${t.join(" * ")} === ${a}`),ENGINE$1.runKernel(BatchToSpaceND$1,{x:r},{blockShape:t,crops:n})}const batchToSpaceND$5=op$1({batchToSpaceND_:batchToSpaceND_$1});function xAs4D$1(e){let t;return t=0===e.rank||1===e.rank?reshape$6(e,[1,1,1,e.size]):2===e.rank?reshape$6(e,[1,1,e.shape[0],e.shape[1]]):3===e.rank?reshape$6(e,[1,e.shape[0],e.shape[1],e.shape[2]]):e,t}function batchNorm_$1(e,t,n,r,a,s){null==s&&(s=.001);const o=convertToTensor$1(e,"x","batchNorm"),i=convertToTensor$1(t,"mean","batchNorm"),l=convertToTensor$1(n,"variance","batchNorm");let u,c;null!=a&&(u=convertToTensor$1(a,"scale","batchNorm")),null!=r&&(c=convertToTensor$1(r,"offset","batchNorm")),assert$6(i.rank===l.rank,()=>"Batch normalization gradient requires mean and variance to have equal ranks."),assert$6(null==c||i.rank===c.rank,()=>"Batch normalization gradient requires mean and offset to have equal ranks."),assert$6(null==u||i.rank===u.rank,()=>"Batch normalization gradient requires mean and scale to have equal ranks.");const p=xAs4D$1(o),d=ENGINE$1.runKernel(FusedBatchNorm$1,{x:p,scale:u,offset:c,mean:i,variance:l},{varianceEpsilon:s});return reshape$6(d,o.shape)}const batchNorm$5=op$1({batchNorm_:batchNorm_$1});function batchNorm2d_$1(e,t,n,r,a,s){const o=convertToTensor$1(e,"x","batchNorm"),i=convertToTensor$1(t,"mean","batchNorm"),l=convertToTensor$1(n,"variance","batchNorm");let u,c;return null!=a&&(u=convertToTensor$1(a,"scale","batchNorm")),null!=r&&(c=convertToTensor$1(r,"offset","batchNorm")),assert$6(2===o.rank,()=>`Error in batchNorm2D: x must be rank 2 but got rank ${o.rank}.`),assert$6(2===i.rank||1===i.rank,()=>`Error in batchNorm2D: mean must be rank 2 or rank 1 but got rank ${i.rank}.`),assert$6(2===l.rank||1===l.rank,()=>`Error in batchNorm2D: variance must be rank 2 or rank 1 but got rank ${l.rank}.`),null!=u&&assert$6(2===u.rank||1===u.rank,()=>`Error in batchNorm2D: scale must be rank 2 or rank 1 but got rank ${u.rank}.`),null!=c&&assert$6(2===c.rank||1===c.rank,()=>`Error in batchNorm2D: offset must be rank 2 or rank 1 but got rank ${c.rank}.`),batchNorm$5(o,i,l,c,u,s)}const batchNorm2d$1=op$1({batchNorm2d_:batchNorm2d_$1});function batchNorm3d_$1(e,t,n,r,a,s){const o=convertToTensor$1(e,"x","batchNorm"),i=convertToTensor$1(t,"mean","batchNorm"),l=convertToTensor$1(n,"variance","batchNorm");let u,c;return null!=a&&(u=convertToTensor$1(a,"scale","batchNorm")),null!=r&&(c=convertToTensor$1(r,"offset","batchNorm")),assert$6(3===o.rank,()=>`Error in batchNorm3D: x must be rank 3 but got rank ${o.rank}.`),assert$6(3===i.rank||1===i.rank,()=>`Error in batchNorm3D: mean must be rank 3 or rank 1 but got rank ${i.rank}.`),assert$6(3===l.rank||1===l.rank,()=>`Error in batchNorm3D: variance must be rank 3 or rank 1 but got rank ${l.rank}.`),null!=u&&assert$6(3===u.rank||1===u.rank,()=>`Error in batchNorm3D: scale must be rank 3 or rank 1 but got rank ${u.rank}.`),null!=c&&assert$6(3===c.rank||1===c.rank,()=>`Error in batchNorm3D: offset must be rank 3 or rank 1 but got rank ${c.rank}.`),batchNorm$5(o,i,l,c,u,s)}const batchNorm3d$1=op$1({batchNorm3d_:batchNorm3d_$1});function batchNorm4d_$1(e,t,n,r,a,s){const o=convertToTensor$1(e,"x","batchNorm"),i=convertToTensor$1(t,"mean","batchNorm"),l=convertToTensor$1(n,"variance","batchNorm");let u,c;return null!=a&&(u=convertToTensor$1(a,"scale","batchNorm")),null!=r&&(c=convertToTensor$1(r,"offset","batchNorm")),assert$6(4===o.rank,()=>`Error in batchNorm4D: x must be rank 4 but got rank ${o.rank}.`),assert$6(4===i.rank||1===i.rank,()=>`Error in batchNorm4D: mean must be rank 4 or rank 1 but got rank ${i.rank}.`),assert$6(4===l.rank||1===l.rank,()=>`Error in batchNorm4D: variance must be rank 4 or rank 1 but got rank ${l.rank}.`),null!=u&&assert$6(4===u.rank||1===u.rank,()=>`Error in batchNorm4D: scale must be rank 4 or rank 1 but got rank ${u.rank}.`),null!=c&&assert$6(4===c.rank||1===c.rank,()=>`Error in batchNorm4D: offset must be rank 4 or rank 1 but got rank ${c.rank}.`),batchNorm$5(o,i,l,c,u,s)}const batchNorm4d$1=op$1({batchNorm4d_:batchNorm4d_$1});function bincount_$1(e,t,n){const r=convertToTensor$1(e,"x","bincount"),a=convertToTensor$1(t,"weights","bincount");return assert$6("int32"===r.dtype,()=>`Error in bincount: input dtype must be int32, but got ${r.dtype}`),assert$6(n>=0,()=>`size must be non-negative, but got ${n}.`),assert$6(a.size===r.size||0===a.size,()=>`Error in bincount: weights must have the same size as input or0-length, but got input shape: ${r.shape}, weights shape: ${a.shape}.`),ENGINE$1.runKernel(Bincount$1,{x:r,weights:a},{size:n})}const bincount$5=op$1({bincount_:bincount_$1});function broadcastTo_$1(e,t){let n=convertToTensor$1(e,"broadcastTo","x");const r=n.shape;if(t.some(e=>!(e>0)||e%1!=0))throw new Error(`broadcastTo(): Invalid broadcast shape [${t}].`);if(t.length<n.rank)throw new Error(`broadcastTo(): shape.length=${t.length} < input.rank=${n.rank}.`);if(t.length>n.rank){const e=n.shape.slice();for(;e.length<t.length;)e.unshift(1);n=reshape$6(n,e)}const a=n.shape,s=Array.from(t);for(let e=t.length-1;e>=0;e--)if(a[e]===t[e])s[e]=1;else if(1!==n.shape[e])throw new Error(`broadcastTo(): [${r}] cannot be broadcast to [${t}].`);return 0===s.map((e,t)=>e>1?t:-1).filter(e=>e>=0).length?clone$1(n):ENGINE$1.runKernel(Tile$1,{x:n},{reps:s})}const broadcastTo$1=op$1({broadcastTo_:broadcastTo_$1});function ceil_$1(e){const t=convertToTensor$1(e,"x","ceil");return ENGINE$1.runKernel(Ceil$1,{x:t})}const ceil$5=op$1({ceil_:ceil_$1});function clipByValue_$1(e,t,n){const r=convertToTensor$1(e,"x","clipByValue");return assert$6(t<=n,()=>`Error in clip: min (${t}) must be less than or equal to max (${n}).`),ENGINE$1.runKernel(ClipByValue$1,{x:r},{clipValueMin:t,clipValueMax:n})}const clipByValue$3=op$1({clipByValue_:clipByValue_$1});function concat1d_$1(e){return concat$5(e,0)}const concat1d$1=op$1({concat1d_:concat1d_$1});function concat2d_$1(e,t){return concat$5(e,t)}const concat2d$1=op$1({concat2d_:concat2d_$1});function concat3d_$1(e,t){return concat$5(e,t)}const concat3d$1=op$1({concat3d_:concat3d_$1});function concat4d_$1(e,t){return concat$5(e,t)}const concat4d$1=op$1({concat4d_:concat4d_$1});function conv2d_$1(e,t,n,r,a="NHWC",s=[1,1],o){const i=convertToTensor$1(e,"x","conv2d"),l=convertToTensor$1(t,"filter","conv2d");let u=i,c=!1;3===i.rank&&(c=!0,u=reshape$6(i,[1,i.shape[0],i.shape[1],i.shape[2]])),assert$6(4===u.rank,()=>`Error in conv2d: input must be rank 4, but got rank ${u.rank}.`),assert$6(4===l.rank,()=>`Error in conv2d: filter must be rank 4, but got rank ${l.rank}.`),null!=o&&assert$6(isInt$1(r),()=>`Error in conv2d: pad must be an integer when using, dimRoundingMode ${o} but got pad ${r}.`);const p="NHWC"===a?u.shape[3]:u.shape[1];assert$6(p===l.shape[2],()=>`Error in conv2d: depth of input (${p}) must match input depth for filter ${l.shape[2]}.`),assert$6(eitherStridesOrDilationsAreOne$1(n,s),()=>`Error in conv2D: Either strides or dilations must be 1. Got strides ${n} and dilations '${s}'`);const d=ENGINE$1.runKernel(Conv2D$3,{x:u,filter:l},{strides:n,pad:r,dataFormat:a,dilations:s,dimRoundingMode:o});return c?reshape$6(d,[d.shape[1],d.shape[2],d.shape[3]]):d}const conv2d$7=op$1({conv2d_:conv2d_$1});function conv1d_$1(e,t,n,r,a="NWC",s=1,o){const i=convertToTensor$1(e,"x","conv1d"),l=convertToTensor$1(t,"filter","conv1d");let u=i,c=!1;2===i.rank&&(c=!0,u=reshape$6(i,[1,i.shape[0],i.shape[1]])),assert$6(3===u.rank,()=>`Error in conv1d: input must be rank 3, but got rank ${u.rank}.`),assert$6(3===l.rank,()=>`Error in conv1d: filter must be rank 3, but got rank ${l.rank}.`),null!=o&&assert$6(isInt$1(r),()=>`Error in conv1d: pad must be an integer when using, dimRoundingMode ${o} but got pad ${r}.`),assert$6(u.shape[2]===l.shape[1],()=>`Error in conv1d: depth of input (${u.shape[2]}) must match input depth for filter ${l.shape[1]}.`),assert$6(eitherStridesOrDilationsAreOne$1(n,s),()=>`Error in conv1D: Either stride or dilation must be 1. Got stride ${n} and dilation '${s}'`),assert$6("NWC"===a,()=>`Error in conv1d: got dataFormat of ${a} but only NWC is currently supported.`);const p=reshape$6(l,[1,l.shape[0],l.shape[1],l.shape[2]]),d=reshape$6(u,[u.shape[0],1,u.shape[1],u.shape[2]]),h=conv2d$7(d,p,[1,n],r,"NHWC",[1,s],o);return reshape$6(h,c?[h.shape[2],h.shape[3]]:[h.shape[0],h.shape[2],h.shape[3]])}const conv1d$3=op$1({conv1d_:conv1d_$1});function conv2DBackpropInput_$1(e,t,n,r,a,s="NHWC",o){assert$6(e.length===t.rank,()=>`Length of inShape (${e.length}) and rank of dy (${t.rank}) must match`);let i=e,l=t,u=!1;3===t.rank&&(u=!0,l=reshape$6(t,[1,t.shape[0],t.shape[1],t.shape[2]]),i=[1,e[0],e[1],e[2]]),assert$6(4===i.length,()=>`Error in conv2dDerInput: inShape must be length 4, but got length ${i.length}.`),assert$6(4===l.rank,()=>`Error in conv2dDerInput: dy must be rank 4, but got rank ${l.rank}`),assert$6(4===n.rank,()=>`Error in conv2dDerInput: filter must be rank 4, but got rank ${n.rank}`);const c="NHWC"===s?i[3]:i[1],p="NHWC"===s?l.shape[3]:l.shape[1];assert$6(c===n.shape[2],()=>`Error in conv2dDerInput: depth of input (${c}) must match input depth for filter ${n.shape[2]}.`),assert$6(p===n.shape[3],()=>`Error in conv2dDerInput: depth of output (${p}) must match output depth for filter ${n.shape[3]}.`),null!=o&&assert$6(isInt$1(a),()=>`Error in conv2dDerInput: pad must be an integer when using, dimRoundingMode ${o} but got pad ${a}.`);const d=ENGINE$1.runKernel(Conv2DBackpropInput$1,{dy:l,filter:n},{strides:r,pad:a,dataFormat:s,dimRoundingMode:o,inputShape:i});return u?reshape$6(d,[d.shape[1],d.shape[2],d.shape[3]]):d}const conv2DBackpropInput$5=op$1({conv2DBackpropInput_:conv2DBackpropInput_$1});function conv2dTranspose_$1(e,t,n,r,a,s){const o=convertToTensor$1(e,"x","conv2dTranspose"),i=convertToTensor$1(t,"filter","conv2dTranspose");return conv2DBackpropInput$5(n,o,i,r,a,"NHWC",s)}const conv2dTranspose$2=op$1({conv2dTranspose_:conv2dTranspose_$1});function conv3d_$1(e,t,n,r,a="NDHWC",s=[1,1,1]){const o=convertToTensor$1(e,"x","conv3d"),i=convertToTensor$1(t,"filter","conv3d");let l=o,u=!1;4===o.rank&&(u=!0,l=reshape$6(o,[1,o.shape[0],o.shape[1],o.shape[2],o.shape[3]])),assert$6(5===l.rank,()=>`Error in conv3d: input must be rank 5, but got rank ${l.rank}.`),assert$6(5===i.rank,()=>`Error in conv3d: filter must be rank 5, but got rank ${i.rank}.`),assert$6(l.shape[4]===i.shape[3],()=>`Error in conv3d: depth of input (${l.shape[4]}) must match input depth for filter ${i.shape[3]}.`),assert$6(eitherStridesOrDilationsAreOne$1(n,s),()=>`Error in conv3D: Either strides or dilations must be 1. Got strides ${n} and dilations '${s}'`),assert$6("NDHWC"===a,()=>`Error in conv3d: got dataFormat of ${a} but only NDHWC is currently supported.`);const c=ENGINE$1.runKernel(Conv3D$3,{x:l,filter:i},{strides:n,pad:r,dataFormat:a,dilations:s});return u?reshape$6(c,[c.shape[1],c.shape[2],c.shape[3],c.shape[4]]):c}const conv3d$2=op$1({conv3d_:conv3d_$1});function conv3DBackpropInput_$1(e,t,n,r,a){assert$6(e.length===t.rank,()=>`Length of inShape (${e.length}) and rank of dy (${t.rank}) must match`);let s=e,o=t,i=!1;4===t.rank&&(i=!0,o=reshape$6(t,[1,t.shape[0],t.shape[1],t.shape[2],t.shape[3]]),s=[1,e[0],e[1],e[2],e[3]]);const l=s[4],u=o.shape[4];assert$6(5===s.length,()=>`Error in conv3dDerInput: inShape must be length 5, but got length ${s.length}.`),assert$6(5===o.rank,()=>`Error in conv3dDerInput: dy must be rank 5, but got rank ${o.rank}`),assert$6(5===n.rank,()=>`Error in conv3dDerInput: filter must be rank 5, but got rank ${n.rank}`),assert$6(l===n.shape[3],()=>`Error in conv3dDerInput: depth of input (${l}) must match input depth for filter ${n.shape[3]}.`),assert$6(u===n.shape[4],()=>`Error in conv3dDerInput: depth of output (${u}) must match output depth for filter ${n.shape[4]}.`);const c=ENGINE$1.runKernel(Conv3DBackpropInputV2$1,{dy:o,filter:n},{pad:a,strides:r,inputShape:s});return i?reshape$6(c,[c.shape[1],c.shape[2],c.shape[3],c.shape[4]]):c}const conv3DBackpropInput$3=op$1({conv3DBackpropInput_:conv3DBackpropInput_$1});function conv3dTranspose_$1(e,t,n,r,a){const s=convertToTensor$1(e,"x","conv3dTranspose"),o=convertToTensor$1(t,"filter","conv3dTranspose");return conv3DBackpropInput$3(n,s,o,r,a)}const conv3dTranspose$2=op$1({conv3dTranspose_:conv3dTranspose_$1});function cos_$1(e){const t=convertToTensor$1(e,"x","cos");return ENGINE$1.runKernel(Cos$1,{x:t})}const cos$5=op$1({cos_:cos_$1});function cosh_$1(e){const t=convertToTensor$1(e,"x","cosh");return ENGINE$1.runKernel(Cosh$1,{x:t})}const cosh$5=op$1({cosh_:cosh_$1});function cumsum_$1(e,t=0,n=!1,r=!1){const a=convertToTensor$1(e,"x","cumsum");return ENGINE$1.runKernel(Cumsum$1,{x:a},{axis:t,exclusive:n,reverse:r})}const cumsum$5=op$1({cumsum_:cumsum_$1});function depthToSpace_$1(e,t,n="NHWC"){const r=convertToTensor$1(e,"x","depthToSpace"),a="NHWC"===n?r.shape[1]:r.shape[2],s="NHWC"===n?r.shape[2]:r.shape[3],o="NHWC"===n?r.shape[3]:r.shape[1];return assert$6(a*t>=0,()=>`Negative dimension size caused by overflow when multiplying\n    ${a} and ${t}  for depthToSpace with input shape\n    ${r.shape}`),assert$6(s*t>=0,()=>`Negative dimension size caused by overflow when multiplying\n    ${s} and ${t} for depthToSpace with input shape\n        ${r.shape}`),assert$6(o%(t*t)==0,()=>`Dimension size must be evenly divisible by ${t*t} but is ${o} for depthToSpace with input shape ${r.shape}`),ENGINE$1.runKernel(DepthToSpace$1,{x:r},{blockSize:t,dataFormat:n})}const depthToSpace$5=op$1({depthToSpace_:depthToSpace_$1});function depthwiseConv2d_$1(e,t,n,r,a="NHWC",s=[1,1],o){const i=convertToTensor$1(e,"x","depthwiseConv2d"),l=convertToTensor$1(t,"filter","depthwiseConv2d");let u=i,c=!1;3===i.rank&&(c=!0,u=reshape$6(i,[1,i.shape[0],i.shape[1],i.shape[2]])),assert$6(4===u.rank,()=>`Error in depthwiseConv2d: input must be rank 4, but got rank ${u.rank}.`),assert$6(4===l.rank,()=>`Error in depthwiseConv2d: filter must be rank 4, but got rank ${l.rank}.`),assert$6(u.shape[3]===l.shape[2],()=>`Error in depthwiseConv2d: number of input channels (${u.shape[3]}) must match the inChannels dimension in filter ${l.shape[2]}.`),null!=o&&assert$6(isInt$1(r),()=>`Error in depthwiseConv2d: pad must be an integer when using, dimRoundingMode ${o} but got pad ${r}.`);const p=ENGINE$1.runKernel(DepthwiseConv2dNative$1,{x:u,filter:l},{strides:n,pad:r,dataFormat:a,dilations:s,dimRoundingMode:o});return c?reshape$6(p,[p.shape[1],p.shape[2],p.shape[3]]):p}const depthwiseConv2d$5=op$1({depthwiseConv2d_:depthwiseConv2d_$1});function dilation2d_$1(e,t,n,r,a=[1,1],s="NHWC"){const o=convertToTensor$1(e,"x","dilation2d"),i=convertToTensor$1(t,"filter","dilation2d");assert$6(3===o.rank||4===o.rank,()=>`Error in dilation2d: input must be rank 3 or 4, but got rank ${o.rank}.`),assert$6(3===i.rank,()=>`Error in dilation2d: filter must be rank 3, but got rank ${i.rank}.`),assert$6("NHWC"===s,()=>`Error in dilation2d: Only NHWC is currently supported, but got dataFormat of ${s}`);let l=o,u=!1;3===o.rank&&(l=reshape$6(o,[1,o.shape[0],o.shape[1],o.shape[2]]),u=!0);const c=ENGINE$1.runKernel(Dilation2D$1,{x:l,filter:i},{strides:n,pad:r,dilations:a});return u?reshape$6(c,[c.shape[1],c.shape[2],c.shape[3]]):c}const dilation2d$1=op$1({dilation2d_:dilation2d_$1});function getBroadcastDims$3(e,t){const n=e.length,r=[];for(let a=0;a<n;a++){const s=n-1-a,o=e[s]||1;(t[t.length-1-a]||1)>1&&1===o&&r.unshift(s)}return r}function getReductionAxes$1(e,t){const n=[];for(let r=0;r<t.length;r++){const a=e[e.length-r-1],s=t.length-r-1,o=t[s];(null==a||1===a&&o>1)&&n.unshift(s)}return n}function assertAndGetBroadcastShape$1(e,t){const n=[],r=Math.max(e.length,t.length);for(let a=0;a<r;a++){let r=e[e.length-a-1];null==r&&(r=1);let s=t[t.length-a-1];if(null==s&&(s=1),1===r)n.unshift(s);else if(1===s)n.unshift(r);else{if(r!==s)throw Error(`Operands could not be broadcast together with shapes ${e} and ${t}.`);n.unshift(r)}}return n}function equal_$1(e,t){let n=convertToTensor$1(e,"a","equal","string_or_numeric"),r=convertToTensor$1(t,"b","equal","string_or_numeric");return[n,r]=makeTypesMatch$1(n,r),assertAndGetBroadcastShape$1(n.shape,r.shape),ENGINE$1.runKernel(Equal$1,{a:n,b:r})}const equal$5=op$1({equal_:equal_$1});function where_$1(e,t,n){const r=convertToTensor$1(t,"a","where"),a=convertToTensor$1(n,"b","where"),s=convertToTensor$1(e,"condition","where","bool"),o=assertAndGetBroadcastShape$1(assertAndGetBroadcastShape$1(s.shape,r.shape),a.shape),i=broadcastTo$1(s,o),l=broadcastTo$1(r,o),u=broadcastTo$1(a,o);return ENGINE$1.runKernel(Select$1,{condition:i,t:l,e:u})}const where$1=op$1({where_:where_$1});function zerosLike_$1(e){const t=convertToTensor$1(e,"x","zerosLike");return ENGINE$1.runKernel(ZerosLike$1,{x:t})}const zerosLike$5=op$1({zerosLike_:zerosLike_$1});function divNoNan_$1(e,t){let n=convertToTensor$1(e,"a","div"),r=convertToTensor$1(t,"b","div");[n,r]=makeTypesMatch$1(n,r);const a=div$3(n,r),s=zerosLike$5(a),o=equal$5(r,s);return where$1(o,s,a)}const divNoNan$1=op$1({divNoNan_:divNoNan_$1});function dot_$1(e,t){const n=convertToTensor$1(e,"t1","dot"),r=convertToTensor$1(t,"t2","dot");assert$6(!(1!==n.rank&&2!==n.rank||1!==r.rank&&2!==r.rank),()=>`Error in dot: inputs must all be rank 1 or 2, but got ranks ${n.rank} and ${r.rank}.`);const a=1===n.rank?n.size:n.shape[1],s=1===r.rank?r.size:r.shape[0];if(assert$6(a===s,()=>`Error in dot: inner dimensions of inputs must match, but got ${a} and ${s}.`),1===n.rank&&1===r.rank){const e=reshape$6(n,[1,-1]),t=reshape$6(r,[-1,1]),a=matMul$3(e,t);return reshape$6(a,[])}if(1===n.rank&&2===r.rank){const e=reshape$6(n,[1,-1]),t=reshape$6(r,[r.shape[0],r.shape[1]]),a=matMul$3(e,t);return reshape$6(a,[a.size])}if(2===n.rank&&1===r.rank){const e=reshape$6(r,[-1,1]),t=matMul$3(n,e);return reshape$6(t,[t.size])}{const e=reshape$6(r,[r.shape[0],r.shape[1]]);return matMul$3(n,e)}}const dot$4=op$1({dot_:dot_$1});function elu_$1(e){const t=convertToTensor$1(e,"x","elu");return ENGINE$1.runKernel(Elu$3,{x:t})}const elu$8=op$1({elu_:elu_$1});function erf_$1(e){let t=convertToTensor$1(e,"x","erf");return assert$6("int32"===t.dtype||"float32"===t.dtype,()=>"Input dtype must be `int32` or `float32`."),"int32"===t.dtype&&(t=cast$7(t,"float32")),ENGINE$1.runKernel(Erf$1,{x:t})}const erf$5=op$1({erf_:erf_$1});function exp_$1(e){const t=convertToTensor$1(e,"x","exp");return ENGINE$1.runKernel(Exp$1,{x:t})}const exp$5=op$1({exp_:exp_$1});function expandDims_$1(e,t=0){const n=convertToTensor$1(e,"x","expandDims","string_or_numeric");return assert$6(t<=n.rank,()=>"Axis must be <= rank of the tensor"),ENGINE$1.runKernel(ExpandDims$1,{input:n},{dim:t})}const expandDims$7=op$1({expandDims_:expandDims_$1});function expm1_$1(e){const t=convertToTensor$1(e,"x","expm1");return ENGINE$1.runKernel(Expm1$1,{x:t})}const expm1$5=op$1({expm1_:expm1_$1});function tile_$1(e,t){const n=convertToTensor$1(e,"x","tile","string_or_numeric");return assert$6(n.rank===t.length,()=>`Error in transpose: rank of input ${n.rank} must match length of reps ${t}.`),ENGINE$1.runKernel(Tile$1,{x:n},{reps:t})}const tile$7=op$1({tile_:tile_$1});function eye_$1(e,t,n,r="float32"){null==t&&(t=e);const a=buffer$1([e,t],r),s=e<=t?e:t;for(let e=0;e<s;++e)a.set(1,e,e);const o=reshape$6(a.toTensor(),[e,t]);if(null==n)return o;if(1===n.length)return tile$7(expandDims$7(o,0),[n[0],1,1]);if(2===n.length)return tile$7(expandDims$7(expandDims$7(o,0),0),[n[0],n[1],1,1]);if(3===n.length)return tile$7(expandDims$7(expandDims$7(expandDims$7(o,0),0),0),[n[0],n[1],n[2],1,1]);throw new Error(`eye() currently supports only 1D and 2D batchShapes, but received ${n.length}D.`)}const eye$1=op$1({eye_:eye_$1});function fill$5(e,t,n){return ENGINE$1.runKernel(Fill$1,{},{shape:e,value:t,dtype:n})}function floor_$1(e){const t=convertToTensor$1(e,"x","floor");return ENGINE$1.runKernel(Floor$1,{x:t})}const floor$5=op$1({floor_:floor_$1});function gather_$1(e,t,n=0,r=0){const a=convertToTensor$1(e,"x","gather"),s=convertToTensor$1(t,"indices","gather","int32");return ENGINE$1.runKernel(GatherV2$1,{x:a,indices:s},{axis:n,batchDims:r})}const gather$3=op$1({gather_:gather_$1});function greater_$1(e,t){let n=convertToTensor$1(e,"a","greater","string_or_numeric"),r=convertToTensor$1(t,"b","greater","string_or_numeric");return[n,r]=makeTypesMatch$1(n,r),assertAndGetBroadcastShape$1(n.shape,r.shape),ENGINE$1.runKernel(Greater$1,{a:n,b:r})}const greater$6=op$1({greater_:greater_$1});function greaterEqual_$1(e,t){let n=convertToTensor$1(e,"a","greaterEqual","string_or_numeric"),r=convertToTensor$1(t,"b","greaterEqual","string_or_numeric");return[n,r]=makeTypesMatch$1(n,r),assertAndGetBroadcastShape$1(n.shape,r.shape),ENGINE$1.runKernel(GreaterEqual$1,{a:n,b:r})}const greaterEqual$5=op$1({greaterEqual_:greaterEqual_$1});function imag_$1(e){const t=convertToTensor$1(e,"input","imag");return ENGINE$1.runKernel(Imag$1,{input:t})}const imag$5=op$1({imag_:imag_$1});function isFinite_$1(e){const t=convertToTensor$1(e,"x","isFinite");return ENGINE$1.runKernel(IsFinite$1,{x:t})}const isFinite$6=op$1({isFinite_:isFinite_$1});function isInf_$1(e){const t=convertToTensor$1(e,"x","isInf");return ENGINE$1.runKernel(IsInf$1,{x:t})}const isInf$5=op$1({isInf_:isInf_$1});function isNaN_$1(e){const t=convertToTensor$1(e,"x","isNaN");return ENGINE$1.runKernel(IsNan$1,{x:t})}const isNaN$6=op$1({isNaN_:isNaN_$1});function leakyRelu_$1(e,t=.2){const n=convertToTensor$1(e,"x","leakyRelu");return ENGINE$1.runKernel(LeakyRelu$1,{x:n},{alpha:t})}const leakyRelu$5=op$1({leakyRelu_:leakyRelu_$1});function less_$1(e,t){let n=convertToTensor$1(e,"a","less","string_or_numeric"),r=convertToTensor$1(t,"b","less","string_or_numeric");return[n,r]=makeTypesMatch$1(n,r),assertAndGetBroadcastShape$1(n.shape,r.shape),ENGINE$1.runKernel(Less$1,{a:n,b:r})}const less$6=op$1({less_:less_$1});function lessEqual_$1(e,t){let n=convertToTensor$1(e,"a","lessEqual","string_or_numeric"),r=convertToTensor$1(t,"b","lessEqual","string_or_numeric");return[n,r]=makeTypesMatch$1(n,r),assertAndGetBroadcastShape$1(n.shape,r.shape),ENGINE$1.runKernel(LessEqual$1,{a:n,b:r})}const lessEqual$5=op$1({lessEqual_:lessEqual_$1});function localResponseNormalization_$1(e,t=5,n=1,r=1,a=.5){const s=convertToTensor$1(e,"x","localResponseNormalization");assert$6(4===s.rank||3===s.rank,()=>`Error in localResponseNormalization: x must be rank 3 or 4 but got\n               rank ${s.rank}.`),assert$6(isInt$1(t),()=>`Error in localResponseNormalization: depthRadius must be an integer but got depthRadius ${t}.`);let o=s,i=!1;3===s.rank&&(i=!0,o=reshape$6(s,[1,s.shape[0],s.shape[1],s.shape[2]]));const l=ENGINE$1.runKernel(LRN$1,{x:o},{depthRadius:t,bias:n,alpha:r,beta:a});return i?reshape$6(l,[l.shape[1],l.shape[2],l.shape[3]]):l}const localResponseNormalization$1=op$1({localResponseNormalization_:localResponseNormalization_$1});function log_$1(e){const t=convertToTensor$1(e,"x","log");return ENGINE$1.runKernel(Log$1,{x:t})}const log$7=op$1({log_:log_$1});function log1p_$1(e){const t=convertToTensor$1(e,"x","log1p");return ENGINE$1.runKernel(Log1p$1,{x:t})}const log1p$5=op$1({log1p_:log1p_$1});function variableGrads$1(e,t){assert$6(isFunction$1(e),()=>"The f passed in variableGrads(f) must be a function"),assert$6(null==t||Array.isArray(t)&&t.every(e=>e instanceof Variable$1),()=>"The varList passed in variableGrads(f, varList) must be an array of variables");const n=null!=t;if(!n){t=[];for(const e in ENGINE$1.registeredVariables)t.push(ENGINE$1.registeredVariables[e])}const r=n?t.filter(e=>!e.trainable):null,a=t.length;assert$6((t=t.filter(e=>e.trainable)).length>0,()=>`variableGrads() expects at least one of the input variables to be trainable, but none of the ${a} variables is trainable.`);const{value:s,grads:o}=ENGINE$1.gradients(e,t,null,!0);assert$6(o.some(e=>null!=e),()=>"Cannot find a connection between any variable and the result of the loss function y=f(x). Please make sure the operations that use variables are inside the function f passed to minimize()."),assert$6(0===s.rank,()=>`The f passed in variableGrads(f) must return a scalar, but it returned a rank-${s.rank} tensor`);const i={};return t.forEach((e,t)=>{null!=o[t]&&(i[e.name]=o[t])}),null!=r&&r.forEach(e=>i[e.name]=null),{value:s,grads:i}}function customGrad$1(e){return ENGINE$1.customGrad(e)}function neg_$1(e){const t=convertToTensor$1(e,"x","neg");return ENGINE$1.runKernel(Neg$1,{x:t})}const neg$5=op$1({neg_:neg_$1});function softplus_$1(e){const t=convertToTensor$1(e,"x","softplus");return ENGINE$1.runKernel(Softplus$3,{x:t})}const softplus$5=op$1({softplus_:softplus_$1});function logSigmoid_$1(e){const t=convertToTensor$1(e,"x","logSigmoid");return customGrad$1(e=>({value:neg$5(softplus$5(neg$5(e))),gradFunc:t=>mul$1(t,sigmoid$5(neg$5(e)))}))(t)}const logSigmoid$1=op$1({logSigmoid_:logSigmoid_$1});function max_$1(e,t=null,n=!1){const r=convertToTensor$1(e,"x","max");return ENGINE$1.runKernel(Max$1,{x:r},{reductionIndices:t,keepDims:n})}const max$7=op$1({max_:max_$1});function sub_$1(e,t){let n=convertToTensor$1(e,"a","sub"),r=convertToTensor$1(t,"b","sub");return[n,r]=makeTypesMatch$1(n,r),ENGINE$1.runKernel(Sub$1,{a:n,b:r})}const sub$5=op$1({sub_:sub_$1});function sum_$1(e,t=null,n=!1){let r=convertToTensor$1(e,"x","sum");return"bool"===r.dtype&&(r=cast$7(r,"int32")),ENGINE$1.runKernel(Sum$1,{x:r},{axis:t,keepDims:n})}const sum$6=op$1({sum_:sum_$1});function logSoftmax_$1(e,t=-1){const n=convertToTensor$1(e,"logits","logSoftmax");if(-1===t&&(t=n.rank-1),t!==n.rank-1)throw Error(`Log Softmax along a non-last dimension is not yet supported. Logits was rank ${n.rank} and axis was ${t}`);return customGrad$1((e,n)=>{const r=max$7(e,t,!0),a=sub$5(e,r),s=sub$5(cast$7(a,"float32"),log$7(sum$6(exp$5(a),t,!0)));return n([s]),{value:s,gradFunc:(e,n)=>{const[r]=n,a=exp$5(r);return sub$5(e,mul$1(sum$6(e,t,!0),a))}}})(n)}const logSoftmax$1=op$1({logSoftmax_:logSoftmax_$1});function axesAreInnerMostDims$1(e,t){for(let n=0;n<e.length;++n)if(e[e.length-n-1]!==t-1-n)return!1;return!0}function combineLocations$1(e,t,n){const r=e.length+t.length,a=[];let s=0,o=0;for(let i=0;i<r;i++)-1===n.indexOf(i)?a.push(e[s++]):a.push(t[o++]);return a}function computeOutAndReduceShapes$1(e,t){const n=[],r=e.length;for(let a=0;a<r;a++)-1===t.indexOf(a)&&n.push(e[a]);return[n,t.map(t=>e[t])]}function expandShapeToKeepDim$1(e,t){return combineLocations$1(e,t.map(e=>1),t)}function assertAxesAreInnerMostDims$1(e,t,n){assert$6(axesAreInnerMostDims$1(t,n),()=>`${e} supports only inner-most axes for now. Got axes ${t} and rank-${n} input.`)}function getAxesPermutation$1(e,t){if(axesAreInnerMostDims$1(e,t))return null;const n=[];for(let r=0;r<t;++r)-1===e.indexOf(r)&&n.push(r);return e.forEach(e=>n.push(e)),n}function getUndoAxesPermutation$1(e){return e.map((e,t)=>[t,e]).sort((e,t)=>e[1]-t[1]).map(e=>e[0])}function getInnerMostAxes$1(e,t){const n=[];for(let r=t-e;r<t;++r)n.push(r);return n}function logSumExp_$1(e,t=null,n=!1){const r=convertToTensor$1(e,"x","logSumExp"),a=parseAxisParam$1(t,r.shape),s=max$7(r,a,!0),o=sub$5(r,s),i=exp$5(o),l=sum$6(i,a),u=log$7(l),c=add$5(reshape$6(s,u.shape),u);if(n){const e=expandShapeToKeepDim$1(c.shape,a);return reshape$6(c,e)}return c}const logSumExp$1=op$1({logSumExp_:logSumExp_$1});function logicalAnd_$1(e,t){const n=convertToTensor$1(e,"a","logicalAnd","bool"),r=convertToTensor$1(t,"b","logicalAnd","bool");return assertAndGetBroadcastShape$1(n.shape,r.shape),ENGINE$1.runKernel(LogicalAnd$1,{a:n,b:r})}const logicalAnd$5=op$1({logicalAnd_:logicalAnd_$1});function logicalNot_$1(e){const t=convertToTensor$1(e,"x","logicalNot","bool");return ENGINE$1.runKernel(LogicalNot$1,{x:t})}const logicalNot$5=op$1({logicalNot_:logicalNot_$1});function logicalOr_$1(e,t){const n=convertToTensor$1(e,"a","logicalOr","bool"),r=convertToTensor$1(t,"b","logicalOr","bool");return assertAndGetBroadcastShape$1(n.shape,r.shape),ENGINE$1.runKernel(LogicalOr$1,{a:n,b:r})}const logicalOr$5=op$1({logicalOr_:logicalOr_$1});function logicalXor_$1(e,t){const n=convertToTensor$1(e,"a","logicalXor","bool"),r=convertToTensor$1(t,"b","logicalXor","bool");return assertAndGetBroadcastShape$1(n.shape,r.shape),logicalAnd$5(logicalOr$5(e,t),logicalNot$5(logicalAnd$5(e,t)))}const logicalXor$1=op$1({logicalXor_:logicalXor_$1});function maxPool_$1(e,t,n,r,a){const s=convertToTensor$1(e,"x","maxPool");let o=s,i=!1;3===s.rank&&(i=!0,o=reshape$6(s,[1,s.shape[0],s.shape[1],s.shape[2]])),assert$6(4===o.rank,()=>`Error in maxPool: input must be rank 4 but got rank ${o.rank}.`),assert$6(eitherStridesOrDilationsAreOne$1(n,1),()=>`Error in maxPool: Either strides or dilations must be 1. Got strides ${n} and dilations '1'`),null!=a&&assert$6(isInt$1(r),()=>`Error in maxPool: pad must be an integer when using, dimRoundingMode ${a} but got pad ${r}.`);const l=ENGINE$1.runKernel(MaxPool$1,{x:o},{filterSize:t,strides:n,pad:r,dimRoundingMode:a});return i?reshape$6(l,[l.shape[1],l.shape[2],l.shape[3]]):l}const maxPool$5=op$1({maxPool_:maxPool_$1});function maxPool3d_$1(e,t=[1,1,1],n,r,a,s="NDHWC"){const o=convertToTensor$1(e,"x","maxPool3d");let i=o,l=!1;4===o.rank&&(l=!0,i=reshape$6(o,[1,o.shape[0],o.shape[1],o.shape[2],o.shape[3]])),assert$6(5===i.rank,()=>`Error in maxPool3d: x must be rank 5 but got rank ${i.rank}.`),assert$6("NDHWC"===s,()=>`Error in maxPool3d: Only NDHWC is currently supported, but got dataFormat of ${s}`),null!=a&&assert$6(isInt$1(r),()=>`Error in maxPool3d: pad must be an integer when using, dimRoundingMode ${a} but got pad ${r}.`);const u=ENGINE$1.runKernel(MaxPool3D$1,{x:i},{filterSize:t,strides:n,pad:r,dimRoundingMode:a,dataFormat:s});return l?reshape$6(u,[u.shape[1],u.shape[2],u.shape[3],u.shape[4]]):u}const maxPool3d$3=op$1({maxPool3d_:maxPool3d_$1});function maximum_$1(e,t){let n=convertToTensor$1(e,"a","maximum"),r=convertToTensor$1(t,"b","maximum");return[n,r]=makeTypesMatch$1(n,r),"bool"===n.dtype&&(n=cast$7(n,"int32"),r=cast$7(r,"int32")),assertAndGetBroadcastShape$1(n.shape,r.shape),ENGINE$1.runKernel(Maximum$3,{a:n,b:r})}const maximum$6=op$1({maximum_:maximum_$1});function mean_$1(e,t=null,n=!1){const r=convertToTensor$1(e,"x","mean");return ENGINE$1.runKernel(Mean$1,{x:r},{axis:t,keepDims:n})}const mean$3=op$1({mean_:mean_$1});function zeros$4(e,t="float32"){if("complex64"===t){const t=zeros$4(e,"float32"),n=zeros$4(e,"float32");return complex$5(t,n)}const n=makeZerosTypedArray$1(sizeFromShape$1(e),t);return ENGINE$1.makeTensor(n,e,t)}function ones$3(e,t="float32"){if("complex64"===t){const t=ones$3(e,"float32"),n=zeros$4(e,"float32");return complex$5(t,n)}const n=makeOnesTypedArray$1(sizeFromShape$1(e),t);return ENGINE$1.makeTensor(n,e,t)}function min_$1(e,t=null,n=!1){const r=convertToTensor$1(e,"x","min");return ENGINE$1.runKernel(Min$1,{x:r},{axis:t,keepDims:n})}const min$7=op$1({min_:min_$1});function minimum_$1(e,t){let n=convertToTensor$1(e,"a","minimum"),r=convertToTensor$1(t,"b","minimum");return[n,r]=makeTypesMatch$1(n,r),"bool"===n.dtype&&(n=cast$7(n,"int32"),r=cast$7(r,"int32")),assertAndGetBroadcastShape$1(n.shape,r.shape),ENGINE$1.runKernel(Minimum$3,{a:n,b:r})}const minimum$6=op$1({minimum_:minimum_$1});function mirrorPad_$1(e,t,n){assert$6("reflect"===n||"symmetric"===n,()=>`Invalid mode. Mode must be either reflect or symmetric. Got ${n}.`);const r=convertToTensor$1(e,"x","mirrorPad");if(0===r.rank)throw new Error("mirrorPad(scalar) is not defined. Pass non-scalar to mirrorPad");assert$6(t.length===r.rank,()=>`Padding doesn't match input. Must be ${r.rank}. Got ${t.length}.`);const a="reflect"===n?1:0;for(let e=0;e<r.rank;e++)assert$6(2===t[e].length,()=>"Invalid number of paddings. Must be length of 2 each."),assert$6(t[e][0]>=0&&t[e][0]<=r.shape[e]-a&&t[e][1]>=0&&t[e][1]<=r.shape[e]-a,()=>`Padding in dimension ${e} cannot be greater than or equal to ${r.shape[e]-a} or less than 0 for input of shape ${r.shape}`);return ENGINE$1.runKernel(MirrorPad$1,{x:r},{paddings:t,mode:n})}const mirrorPad$3=op$1({mirrorPad_:mirrorPad_$1});function mod_$1(e,t){let n=convertToTensor$1(e,"a","mod"),r=convertToTensor$1(t,"b","mod");return[n,r]=makeTypesMatch$1(n,r),ENGINE$1.runKernel(Mod$1,{a:n,b:r})}const mod$5=op$1({mod_:mod_$1});function square_$1(e){const t=convertToTensor$1(e,"x","square");return ENGINE$1.runKernel("Square",{x:t},{})}const square$5=op$1({square_:square_$1});function moments_$1(e,t=null,n=!1){const r=parseAxisParam$1(t,(e=convertToTensor$1(e,"x","moments")).shape),a=mean$3(e,r,n);let s=a.shape;n||(s=expandShapeToKeepDim$1(a.shape,r));const o=square$5(sub$5(cast$7(e,"float32"),reshape$6(a,s)));return{mean:a,variance:mean$3(o,r,n)}}const moments$1=op$1({moments_:moments_$1});function notEqual_$1(e,t){let n=convertToTensor$1(e,"a","notEqual","string_or_numeric"),r=convertToTensor$1(t,"b","notEqual","string_or_numeric");return[n,r]=makeTypesMatch$1(n,r),assertAndGetBroadcastShape$1(n.shape,r.shape),ENGINE$1.runKernel(NotEqual$1,{a:n,b:r})}const notEqual$5=op$1({notEqual_:notEqual_$1});function onesLike_$1(e){const t=convertToTensor$1(e,"x","onesLike");return ENGINE$1.runKernel(OnesLike$1,{x:t})}const onesLike$5=op$1({onesLike_:onesLike_$1});function pad_$1(e,t,n=0){const r=convertToTensor$1(e,"x","pad");if(0===r.rank)throw new Error("pad(scalar) is not defined. Pass non-scalar to pad");return ENGINE$1.runKernel(PadV2$1,{x:r},{paddings:t,constantValue:n})}const pad$1=op$1({pad_:pad_$1});function spaceToBatchND_$1(e,t,n){const r=convertToTensor$1(e,"x","spaceToBatchND");return assert$6(r.rank>=1+t.length,()=>`input rank ${r.rank} should be > than [blockShape] ${t.length}`),assert$6(n.length===t.length,()=>`paddings.shape[0] ${n.length} must be equal to [blockShape] ${t.length}`),assert$6(r.shape.reduce((e,r,a)=>a>0&&a<=t.length?e&&(r+n[a-1][0]+n[a-1][1])%t[a-1]==0:e,!0),()=>`input spatial dimensions ${r.shape.slice(1)} with paddings ${n.toString()} must be divisible by blockShapes ${t.toString()}`),ENGINE$1.runKernel(SpaceToBatchND$1,{x:r},{blockShape:t,paddings:n})}const spaceToBatchND$5=op$1({spaceToBatchND_:spaceToBatchND_$1});function pool_$1(e,t,n,r,a,s){null==a&&(a=[1,1]),null==s&&(s=1),0===r&&(r="valid");const o=convertToTensor$1(e,"x","maxPool");let i=o,l=!1;3===o.rank&&(l=!0,i=reshape$6(o,[1,o.shape[0],o.shape[1],o.shape[2]])),assert$6(eitherStridesOrDilationsAreOne$1(s,a),()=>`Error in pool: Either strides or dilations must be 1. Got strides ${s} and dilations '${a}'`);const u=computePool2DInfo$1(i.shape,t,s,a,r),c=[u.dilationHeight,u.dilationWidth];let p;p="same"===r?withSpaceToBatchBasePaddings$1([u.filterHeight,u.filterWidth],c):[[0,0],[0,0]];const d=1===c[0]&&1===c[1],[h,m]=requiredSpaceToBatchPaddings$1([u.inHeight,u.inWidth],c,p),f=d?r:"valid",g=d?i:spaceToBatchND$5(i,c,h),$=("avg"===n?()=>avgPool$5(g,t,s,f):()=>maxPool$5(g,t,s,f))(),y=d?$:batchToSpaceND$5($,c,m);return l?reshape$6(y,[y.shape[1],y.shape[2],y.shape[3]]):y}function requiredSpaceToBatchPaddings$1(e,t,n){const r=n.map(e=>e[0]),a=n.map(e=>e[1]),s=e.concat(r,a),o=t.map((e,t)=>(e-s[t]%e)%e),i=a.map((e,t)=>e+o[t]);return[t.map((e,t)=>[r[t],i[t]]),t.map((e,t)=>[0,o[t]])]}function withSpaceToBatchBasePaddings$1(e,t){const n=e.map((e,n)=>e+(e-1)*(t[n]-1)).map(e=>e-1),r=n.map(e=>Math.floor(e/2)),a=n.map((e,t)=>e-r[t]);return n.map((e,t)=>[r[t],a[t]])}const pool$3=op$1({pool_:pool_$1});function pow_$1(e,t){let n=convertToTensor$1(e,"base","pow"),r=convertToTensor$1(t,"exp","pow");return[n,r]=makeTypesMatch$1(n,r),ENGINE$1.runKernel(Pow$1,{a:n,b:r})}const pow$5=op$1({pow_:pow_$1});function prelu_$1(e,t){const n=convertToTensor$1(e,"x","prelu"),r=convertToTensor$1(t,"alpha","prelu");return ENGINE$1.runKernel(Prelu$1,{x:n,alpha:r})}const prelu$6=op$1({prelu_:prelu_$1});function prod_$1(e,t=null,n=!1){let r=convertToTensor$1(e,"x","prod");return"bool"===r.dtype&&(r=cast$7(r,"int32")),ENGINE$1.runKernel(Prod$1,{x:r},{axis:t,keepDims:n})}const prod$5=op$1({prod_:prod_$1});var commonjsGlobal="undefined"!=typeof globalThis?globalThis:"undefined"!=typeof window?window:"undefined"!=typeof global?global:"undefined"!=typeof self?self:{};function createCommonjsModule(e){var t={exports:{}};return e(t,t.exports),t.exports}var alea$1=createCommonjsModule(function(e){!function(e,t,n){function r(e){var t,n=this,r=(t=4022871197,function(e){e=e.toString();for(var n=0;n<e.length;n++){var r=.02519603282416938*(t+=e.charCodeAt(n));r-=t=r>>>0,t=(r*=t)>>>0,t+=4294967296*(r-=t)}return 2.3283064365386963e-10*(t>>>0)});n.next=function(){var e=2091639*n.s0+2.3283064365386963e-10*n.c;return n.s0=n.s1,n.s1=n.s2,n.s2=e-(n.c=0|e)},n.c=1,n.s0=r(" "),n.s1=r(" "),n.s2=r(" "),n.s0-=r(e),n.s0<0&&(n.s0+=1),n.s1-=r(e),n.s1<0&&(n.s1+=1),n.s2-=r(e),n.s2<0&&(n.s2+=1),r=null}function a(e,t){return t.c=e.c,t.s0=e.s0,t.s1=e.s1,t.s2=e.s2,t}function s(e,t){var n=new r(e),s=t&&t.state,o=n.next;return o.int32=function(){return 4294967296*n.next()|0},o.double=function(){return o()+11102230246251565e-32*(2097152*o()|0)},o.quick=o,s&&("object"==typeof s&&a(s,n),o.state=function(){return a(n,{})}),o}t&&t.exports?t.exports=s:this.alea=s}(0,e)}),xor128$1=createCommonjsModule(function(e){!function(e,t,n){function r(e){var t=this,n="";t.x=0,t.y=0,t.z=0,t.w=0,t.next=function(){var e=t.x^t.x<<11;return t.x=t.y,t.y=t.z,t.z=t.w,t.w^=t.w>>>19^e^e>>>8},e===(0|e)?t.x=e:n+=e;for(var r=0;r<n.length+64;r++)t.x^=0|n.charCodeAt(r),t.next()}function a(e,t){return t.x=e.x,t.y=e.y,t.z=e.z,t.w=e.w,t}function s(e,t){var n=new r(e),s=t&&t.state,o=function(){return(n.next()>>>0)/4294967296};return o.double=function(){do{var e=((n.next()>>>11)+(n.next()>>>0)/4294967296)/(1<<21)}while(0===e);return e},o.int32=n.next,o.quick=o,s&&("object"==typeof s&&a(s,n),o.state=function(){return a(n,{})}),o}t&&t.exports?t.exports=s:this.xor128=s}(0,e)}),xorwow$1=createCommonjsModule(function(e){!function(e,t,n){function r(e){var t=this,n="";t.next=function(){var e=t.x^t.x>>>2;return t.x=t.y,t.y=t.z,t.z=t.w,t.w=t.v,(t.d=t.d+362437|0)+(t.v=t.v^t.v<<4^e^e<<1)|0},t.x=0,t.y=0,t.z=0,t.w=0,t.v=0,e===(0|e)?t.x=e:n+=e;for(var r=0;r<n.length+64;r++)t.x^=0|n.charCodeAt(r),r==n.length&&(t.d=t.x<<10^t.x>>>4),t.next()}function a(e,t){return t.x=e.x,t.y=e.y,t.z=e.z,t.w=e.w,t.v=e.v,t.d=e.d,t}function s(e,t){var n=new r(e),s=t&&t.state,o=function(){return(n.next()>>>0)/4294967296};return o.double=function(){do{var e=((n.next()>>>11)+(n.next()>>>0)/4294967296)/(1<<21)}while(0===e);return e},o.int32=n.next,o.quick=o,s&&("object"==typeof s&&a(s,n),o.state=function(){return a(n,{})}),o}t&&t.exports?t.exports=s:this.xorwow=s}(0,e)}),xorshift7$1=createCommonjsModule(function(e){!function(e,t,n){function r(e){var t=this;t.next=function(){var e,n,r=t.x,a=t.i;return e=r[a],n=(e^=e>>>7)^e<<24,n^=(e=r[a+1&7])^e>>>10,n^=(e=r[a+3&7])^e>>>3,n^=(e=r[a+4&7])^e<<7,e=r[a+7&7],r[a]=n^=(e^=e<<13)^e<<9,t.i=a+1&7,n},function(e,t){var n,r=[];if(t===(0|t))r[0]=t;else for(t=""+t,n=0;n<t.length;++n)r[7&n]=r[7&n]<<15^t.charCodeAt(n)+r[n+1&7]<<13;for(;r.length<8;)r.push(0);for(n=0;n<8&&0===r[n];++n);for(8==n&&(r[7]=-1),e.x=r,e.i=0,n=256;n>0;--n)e.next()}(t,e)}function a(e,t){return t.x=e.x.slice(),t.i=e.i,t}function s(e,t){null==e&&(e=+new Date);var n=new r(e),s=t&&t.state,o=function(){return(n.next()>>>0)/4294967296};return o.double=function(){do{var e=((n.next()>>>11)+(n.next()>>>0)/4294967296)/(1<<21)}while(0===e);return e},o.int32=n.next,o.quick=o,s&&(s.x&&a(s,n),o.state=function(){return a(n,{})}),o}t&&t.exports?t.exports=s:this.xorshift7=s}(0,e)}),xor4096$1=createCommonjsModule(function(e){!function(e,t,n){function r(e){var t=this;t.next=function(){var e,n,r=t.w,a=t.X,s=t.i;return t.w=r=r+1640531527|0,n=a[s+34&127],e=a[s=s+1&127],n^=n<<13,e^=e<<17,n=a[s]=(n^=n>>>15)^(e^=e>>>12),t.i=s,n+(r^r>>>16)|0},function(e,t){var n,r,a,s,o,i=[],l=128;for(t===(0|t)?(r=t,t=null):(t+="\0",r=0,l=Math.max(l,t.length)),a=0,s=-32;s<l;++s)t&&(r^=t.charCodeAt((s+32)%t.length)),0===s&&(o=r),r^=r<<10,r^=r>>>15,r^=r<<4,r^=r>>>13,s>=0&&(a=0==(n=i[127&s]^=r+(o=o+1640531527|0))?a+1:0);for(a>=128&&(i[127&(t&&t.length||0)]=-1),a=127,s=512;s>0;--s)r=i[a+34&127],n=i[a=a+1&127],r^=r<<13,n^=n<<17,i[a]=(r^=r>>>15)^(n^=n>>>12);e.w=o,e.X=i,e.i=a}(t,e)}function a(e,t){return t.i=e.i,t.w=e.w,t.X=e.X.slice(),t}function s(e,t){null==e&&(e=+new Date);var n=new r(e),s=t&&t.state,o=function(){return(n.next()>>>0)/4294967296};return o.double=function(){do{var e=((n.next()>>>11)+(n.next()>>>0)/4294967296)/(1<<21)}while(0===e);return e},o.int32=n.next,o.quick=o,s&&(s.X&&a(s,n),o.state=function(){return a(n,{})}),o}t&&t.exports?t.exports=s:this.xor4096=s}(0,e)}),tychei$1=createCommonjsModule(function(e){!function(e,t,n){function r(e){var t=this,n="";t.next=function(){var e=t.b,n=t.c,r=t.d,a=t.a;return e=e<<25^e>>>7^n,n=n-r|0,r=r<<24^r>>>8^a,a=a-e|0,t.b=e=e<<20^e>>>12^n,t.c=n=n-r|0,t.d=r<<16^n>>>16^a,t.a=a-e|0},t.a=0,t.b=0,t.c=-1640531527,t.d=1367130551,e===Math.floor(e)?(t.a=e/4294967296|0,t.b=0|e):n+=e;for(var r=0;r<n.length+20;r++)t.b^=0|n.charCodeAt(r),t.next()}function a(e,t){return t.a=e.a,t.b=e.b,t.c=e.c,t.d=e.d,t}function s(e,t){var n=new r(e),s=t&&t.state,o=function(){return(n.next()>>>0)/4294967296};return o.double=function(){do{var e=((n.next()>>>11)+(n.next()>>>0)/4294967296)/(1<<21)}while(0===e);return e},o.int32=n.next,o.quick=o,s&&("object"==typeof s&&a(s,n),o.state=function(){return a(n,{})}),o}t&&t.exports?t.exports=s:this.tychei=s}(0,e)}),_nodeResolve_empty={},_nodeResolve_empty$1={__proto__:null,default:_nodeResolve_empty},seedrandom$3=createCommonjsModule(function(e){!function(t,n){var r,a=this,s=256,o=n.pow(s,6),i=n.pow(2,52),l=2*i,u=255;function c(e,u,c){var g=[],$=m(h((u=1==u?{entropy:!0}:u||{}).entropy?[e,f(t)]:null==e?function(){try{var e;return r&&(e=r.randomBytes)?e=e(s):(e=new Uint8Array(s),(a.crypto||a.msCrypto).getRandomValues(e)),f(e)}catch(e){var n=a.navigator,o=n&&n.plugins;return[+new Date,a,o,a.screen,f(t)]}}():e,3),g),y=new p(g),b=function(){for(var e=y.g(6),t=o,n=0;e<i;)e=(e+n)*s,t*=s,n=y.g(1);for(;e>=l;)e/=2,t/=2,n>>>=1;return(e+n)/t};return b.int32=function(){return 0|y.g(4)},b.quick=function(){return y.g(4)/4294967296},b.double=b,m(f(y.S),t),(u.pass||c||function(e,t,r,a){return a&&(a.S&&d(a,y),e.state=function(){return d(y,{})}),r?(n.random=e,t):e})(b,$,"global"in u?u.global:this==n,u.state)}function p(e){var t,n=e.length,r=this,a=0,o=r.i=r.j=0,i=r.S=[];for(n||(e=[n++]);a<s;)i[a]=a++;for(a=0;a<s;a++)i[a]=i[o=u&o+e[a%n]+(t=i[a])],i[o]=t;(r.g=function(e){for(var t,n=0,a=r.i,o=r.j,i=r.S;e--;)t=i[a=u&a+1],n=n*s+i[u&(i[a]=i[o=u&o+t])+(i[o]=t)];return r.i=a,r.j=o,n})(s)}function d(e,t){return t.i=e.i,t.j=e.j,t.S=e.S.slice(),t}function h(e,t){var n,r=[],a=typeof e;if(t&&"object"==a)for(n in e)try{r.push(h(e[n],t-1))}catch(e){}return r.length?r:"string"==a?e:e+"\0"}function m(e,t){for(var n,r=e+"",a=0;a<r.length;)t[u&a]=u&(n^=19*t[u&a])+r.charCodeAt(a++);return f(t)}function f(e){return String.fromCharCode.apply(0,e)}if(n.seedrandom=c,m(n.random(),t),e.exports){e.exports=c;try{r=_nodeResolve_empty$1}catch(e){}}}([],Math)});seedrandom$3.alea=alea$1,seedrandom$3.xor128=xor128$1,seedrandom$3.xorwow=xorwow$1,seedrandom$3.xorshift7=xorshift7$1,seedrandom$3.xor4096=xor4096$1,seedrandom$3.tychei=tychei$1;var seedrandom$2=seedrandom$3;class MPRandGauss$1{constructor(e,t,n,r,a){this.mean=e,this.stdDev=t,this.dtype=n,this.nextVal=NaN,this.truncated=r,this.truncated&&(this.upper=this.mean+2*this.stdDev,this.lower=this.mean-2*this.stdDev);const s=a||Math.random();this.random=seedrandom$2.alea(s.toString())}nextValue(){if(!isNaN(this.nextVal)){const e=this.nextVal;return this.nextVal=NaN,e}let e,t,n=!1;for(;!n;){let r,a,s;do{r=2*this.random()-1,a=2*this.random()-1,s=r*r+a*a}while(s>=1||0===s);const o=Math.sqrt(-2*Math.log(s)/s);e=this.mean+this.stdDev*r*o,t=this.mean+this.stdDev*a*o,this.truncated&&!this.isValidTruncated(e)||(n=!0)}return this.truncated&&!this.isValidTruncated(t)||(this.nextVal=this.convertValue(t)),this.convertValue(e)}convertValue(e){return null==this.dtype||"float32"===this.dtype?e:Math.round(e)}isValidTruncated(e){return e<=this.upper&&e>=this.lower}}class UniformRandom$1{constructor(e=0,t=1,n,r){if(this.canReturnFloat=()=>null==this.dtype||"float32"===this.dtype,this.min=e,this.range=t-e,this.dtype=n,null==r&&(r=Math.random()),"number"==typeof r&&(r=r.toString()),!this.canReturnFloat()&&this.range<=1)throw new Error(`The difference between ${e} - ${t} <= 1 and dtype is not float`);this.random=seedrandom$2.alea(r)}convertValue(e){return this.canReturnFloat()?e:Math.round(e)}nextValue(){return this.convertValue(this.min+this.range*this.random())}}function randomNormal_$1(e,t=0,n=1,r,a){if(null!=r&&"bool"===r)throw new Error(`Unsupported data type ${r}`);const s=new MPRandGauss$1(t,n,r,!1,a),o=buffer$1(e,r);for(let e=0;e<o.values.length;e++)o.values[e]=s.nextValue();return o.toTensor()}const randomNormal$4=op$1({randomNormal_:randomNormal_$1});function randomUniform_$1(e,t=0,n=1,r="float32",a){const s=buffer$1(e,r),o=new UniformRandom$1(t,n,null,a);for(let e=0;e<s.values.length;e++)s.values[e]=o.nextValue();return s.toTensor()}const randomUniform$2=op$1({randomUniform_:randomUniform_$1});function range$8(e,t,n=1,r="float32"){if(0===n)throw new Error("Cannot have a step of zero");return ENGINE$1.runKernel(Range$1,{},{start:e,stop:t,step:n,dtype:r})}function real_$1(e){const t=convertToTensor$1(e,"input","real");return ENGINE$1.runKernel(Real$1,{input:t})}const real$5=op$1({real_:real_$1});function reciprocal_$1(e){const t=convertToTensor$1(e,"x","reciprocal");return ENGINE$1.runKernel(Reciprocal$1,{x:t})}const reciprocal$5=op$1({reciprocal_:reciprocal_$1});function relu_$1(e){const t=convertToTensor$1(e,"x","relu");return ENGINE$1.runKernel(Relu$3,{x:t})}const relu$6=op$1({relu_:relu_$1});function relu6_$1(e){const t=convertToTensor$1(e,"x","relu6");return ENGINE$1.runKernel(Relu6$3,{x:t})}const relu6$5=op$1({relu6_:relu6_$1});function reverse_$1(e,t){const n=convertToTensor$1(e,"x","reverse");return ENGINE$1.runKernel(Reverse$1,{x:n},{dims:t})}const reverse$5=op$1({reverse_:reverse_$1});function round_$1(e){const t=convertToTensor$1(e,"x","round");return ENGINE$1.runKernel(Round$1,{x:t})}const round$6=op$1({round_:round_$1});function rsqrt_$1(e){const t=convertToTensor$1(e,"x","rsqrt");return ENGINE$1.runKernel(Rsqrt$1,{x:t})}const rsqrt$5=op$1({rsqrt_:rsqrt_$1});function scalar$1(e,t){if((isTypedArray$1(e)&&"string"!==t||Array.isArray(e))&&"complex64"!==t)throw new Error("Error creating a new Scalar: value must be a primitive (number|boolean|string)");if("string"===t&&isTypedArray$1(e)&&!(e instanceof Uint8Array))throw new Error("When making a scalar from encoded string, the value must be `Uint8Array`.");return makeTensor$1(e,[],[],t)}function selu_$1(e){const t=convertToTensor$1(e,"x","selu");return ENGINE$1.runKernel(Selu$3,{x:t})}const selu$5=op$1({selu_:selu_$1});function separableConv2d_$1(e,t,n,r,a,s=[1,1],o="NHWC"){const i=convertToTensor$1(e,"x","separableConv2d"),l=convertToTensor$1(t,"depthwiseFilter","separableConv2d"),u=convertToTensor$1(n,"pointwiseFilter","separableConv2d");let c=i,p=!1;if(3===i.rank&&(p=!0,c=reshape$6(i,[1,i.shape[0],i.shape[1],i.shape[2]])),"NCHW"===o)throw new Error("separableConv2d currently does not support dataFormat NCHW; only NHWC is supported");assert$6(4===c.rank,()=>`Error in separableConv2d: input must be rank 4, but got rank ${c.rank}.`),assert$6(4===l.rank,()=>`Error in separableConv2d: depthwise filter must be rank 4, but got rank ${l.rank}.`),assert$6(4===u.rank,()=>`Error in separableConv2d: pointwise filter must be rank 4, but got rank ${l.rank}.`),assert$6(1===u.shape[0],()=>`Error in separableConv2d: the first dimension of pointwise filter  must be 1, but got ${u.shape[0]}.`),assert$6(1===u.shape[1],()=>`Error in separableConv2d: the second dimension of pointwise filter must be 1, but got ${u.shape[1]}.`);const d=l.shape[2],h=l.shape[3];assert$6(u.shape[2]===d*h,()=>`Error in separableConv2d: the third dimension of pointwise filter must be ${d*h}, but got ${u.shape[2]}.`);const m=depthwiseConv2d$5(c,l,r,a,o,s),f=conv2d$7(m,u,1,"valid",o);return p?reshape$6(f,[f.shape[1],f.shape[2],f.shape[3]]):f}const separableConv2d$2=op$1({separableConv2d_:separableConv2d_$1});function sign_$1(e){const t=convertToTensor$1(e,"x","sign");return ENGINE$1.runKernel(Sign$1,{x:t})}const sign$5=op$1({sign_:sign_$1});function sin_$1(e){const t=convertToTensor$1(e,"x","sin");return ENGINE$1.runKernel(Sin$1,{x:t})}const sin$5=op$1({sin_:sin_$1});function sinh_$1(e){const t=convertToTensor$1(e,"x","sinh");return ENGINE$1.runKernel(Sinh$1,{x:t})}const sinh$5=op$1({sinh_:sinh_$1});function slice1d_$1(e,t,n){const r=convertToTensor$1(e,"x","slice1d");return assert$6(1===r.rank,()=>`slice1d expects a rank-1 tensor, but got a rank-${r.rank} tensor`),slice$5(r,[t],[n])}const slice1d$1=op$1({slice1d_:slice1d_$1});function slice2d_$1(e,t,n){const r=convertToTensor$1(e,"x","slice2d");return assert$6(2===r.rank,()=>`slice2d expects a rank-2 tensor, but got a rank-${r.rank} tensor`),slice$5(r,t,n)}const slice2d$1=op$1({slice2d_:slice2d_$1});function slice3d_$1(e,t,n){const r=convertToTensor$1(e,"x","slice3d");return assert$6(3===r.rank,()=>`slice3d expects a rank-3 tensor, but got a rank-${r.rank} tensor`),slice$5(r,t,n)}const slice3d$1=op$1({slice3d_:slice3d_$1});function slice4d_$1(e,t,n){const r=convertToTensor$1(e,"x","slice4d");return assert$6(4===r.rank,()=>`slice4d expects a rank-4 tensor, but got a rank-${r.rank} tensor`),slice$5(r,t,n)}const slice4d$1=op$1({slice4d_:slice4d_$1});function softmax_$1(e,t=-1){const n=convertToTensor$1(e,"logits","softmax","float32");if(-1===t&&(t=n.rank-1),t!==n.rank-1)throw Error(`Softmax along a non-last dimension is not yet supported. Logits was rank ${n.rank} and dim was ${t}`);return ENGINE$1.runKernel(Softmax$5,{logits:n},{dim:t})}const softmax$6=op$1({softmax_:softmax_$1});function fft_$1(e){return assert$6("complex64"===e.dtype,()=>`The dtype for tf.spectral.fft() must be complex64 but got ${e.dtype}.`),ENGINE$1.runKernel(FFT$1,{input:e})}const fft$5=op$1({fft_:fft_$1});function ifft_$1(e){return assert$6("complex64"===e.dtype,()=>`The dtype for tf.spectral.ifft() must be complex64 but got ${e.dtype}.`),ENGINE$1.runKernel(IFFT$1,{input:e})}const ifft$5=op$1({ifft_:ifft_$1});function irfft_$1(e){const t=e.shape[e.shape.length-1],n=e.size/t;let r;if(t<=2){const a=reshape$6(e,[n,t]);r=ifft$5(a)}else{const a=[n,2*(t-1)],s=reshape$6(real$5(e),[n,t]),o=reshape$6(imag$5(e),[n,t]),i=reverse$5(slice$5(s,[0,1],[n,t-2]),1),l=mul$1(reverse$5(slice$5(o,[0,1],[n,t-2]),1),scalar$1(-1)),u=concat$5([s,i],1),c=concat$5([o,l],1),p=reshape$6(complex$5(u,c),[a[0],a[1]]);r=ifft$5(p)}if(r=real$5(r),3===e.rank&&0!==e.shape[0]){const t=r,n=e.shape[0];r=reshape$6(r,[n,r.shape[0]/n,r.shape[1]]),t.dispose()}return r}const irfft$1=op$1({irfft_:irfft_$1});function split_$1(e,t,n=0){const r=convertToTensor$1(e,"x","split");return ENGINE$1.runKernel(SplitV$1,{x:r},{numOrSizeSplits:t,axis:n})}const split$4=op$1({split_:split_$1});function rfft_$1(e,t){assert$6("float32"===e.dtype,()=>`The dtype for rfft() must be real value but got ${e.dtype}`);let n=e.shape[e.shape.length-1];const r=e.size/n;let a;if(null!=t&&t<n){const r=e.shape.map(e=>0),s=e.shape.map(e=>e);s[e.shape.length-1]=t,a=slice$5(e,r,s),n=t}else if(null!=t&&t>n){const r=e.shape.map(e=>e);r[e.shape.length-1]=t-n,a=concat$5([e,zeros$4(r)],e.shape.length-1),n=t}else a=e;const s=zerosLike$5(a),o=reshape$6(complex$5(a,s),[r,n]),i=fft$5(o),l=Math.floor(n/2)+1,u=real$5(i),c=imag$5(i),p=split$4(u,[l,n-l],u.shape.length-1),d=split$4(c,[l,n-l],c.shape.length-1),h=a.shape.slice();return h[a.shape.length-1]=l,reshape$6(complex$5(p[0],d[0]),h)}const rfft$1=op$1({rfft_:rfft_$1});function sqrt_$1(e){const t=convertToTensor$1(e,"x","sqrt");return ENGINE$1.runKernel(Sqrt$1,{x:t})}const sqrt$5=op$1({sqrt_:sqrt_$1});function squaredDifference_$1(e,t){let n=convertToTensor$1(e,"a","squaredDifference"),r=convertToTensor$1(t,"b","squaredDifference");return[n,r]=makeTypesMatch$1(n,r),assertAndGetBroadcastShape$1(n.shape,r.shape),ENGINE$1.runKernel(SquaredDifference$1,{a:n,b:r},{})}const squaredDifference$5=op$1({squaredDifference_:squaredDifference_$1});function squeeze_$1(e,t){const n=convertToTensor$1(e,"x","squeeze");return reshape$6(n,squeezeShape$1(n.shape,t).newShape)}const squeeze$1=op$1({squeeze_:squeeze_$1});function stack_$1(e,t=0){const n=convertToTensorArray$1(e,"tensors","stack","string_or_numeric");return assert$6(n.length>=1,()=>"Pass at least one tensor to tf.stack"),n.length>0&&assert$6(t<=n[0].rank,()=>"Axis must be <= rank of the tensor"),ENGINE$1.runKernel(Pack$1,n,{axis:t})}const stack$1=op$1({stack_:stack_$1});function step_$1(e,t=0){const n=convertToTensor$1(e,"x","step");return ENGINE$1.runKernel(Step$1,{x:n},{alpha:t})}const step$5=op$1({step_:step_$1});function stridedSlice_$1(e,t,n,r,a=0,s=0,o=0,i=0,l=0){const u=convertToTensor$1(e,"x","stridedSlice","string_or_numeric");return ENGINE$1.runKernel(StridedSlice$1,{x:u},{begin:t,end:n,strides:r,beginMask:a,endMask:s,ellipsisMask:o,newAxisMask:i,shrinkAxisMask:l})}const stridedSlice$5=op$1({stridedSlice_:stridedSlice_$1});function tan_$1(e){const t=convertToTensor$1(e,"x","tan");return ENGINE$1.runKernel(Tan$1,{x:t})}const tan$5=op$1({tan_:tan_$1});function tensor1d$1(e,t){assertNonNull$1(e);const n=inferShape$1(e,t);if(1!==n.length)throw new Error("tensor1d() requires values to be a flat/TypedArray");return makeTensor$1(e,null,n,t)}function tensor2d$1(e,t,n){if(assertNonNull$1(e),null!=t&&2!==t.length)throw new Error("tensor2d() requires shape to have two numbers");const r=inferShape$1(e,n);if(2!==r.length&&1!==r.length)throw new Error("tensor2d() requires values to be number[][] or flat/TypedArray");if(1===r.length&&null==t)throw new Error("tensor2d() requires shape to be provided when `values` are a flat/TypedArray");return makeTensor$1(e,t,r,n)}function topk_$1(e,t=1,n=!0){const r=convertToTensor$1(e,"x","topk");if(0===r.rank)throw new Error("topk() expects the input to be of rank 1 or higher");const a=r.shape[r.shape.length-1];if(t<0)throw new Error(`'k' passed to topk() must be >= 0 but got ${t}`);if(t>a)throw new Error(`'k' passed to topk() must be <= the last dimension (${a}) but got ${t}`);const s={x:r},o={k:t,sorted:n},[i,l]=ENGINE$1.runKernel(TopK$1,s,o);return{values:i,indices:l}}const topk$1=op$1({topk_:topk_$1});function truncatedNormal_$1(e,t=0,n=1,r,a){if(null!=r&&"bool"===r)throw new Error("Unsupported data type $ { dtype }");const s=new MPRandGauss$1(t,n,r,!0,a),o=buffer$1(e,r);for(let e=0;e<o.values.length;e++)o.values[e]=s.nextValue();return o.toTensor()}const truncatedNormal$2=op$1({truncatedNormal_:truncatedNormal_$1});function unique_$1(e,t=0){const n=convertToTensor$1(e,"x","unique","string_or_numeric");assert$6(n.rank>0,()=>"The input tensor must be at least 1D");const r={x:n},a={axis:t},[s,o]=ENGINE$1.runKernel(Unique$1,r,a);return{values:s,indices:o}}const unique$7=op$1({unique_:unique_$1});function unsortedSegmentSum_$1(e,t,n){const r=convertToTensor$1(e,"x","unsortedSegmentSum"),a=convertToTensor$1(t,"segmentIds","unsortedSegmentSum","int32");return assert$6(isInt$1(n),()=>"numSegments must be of dtype int"),ENGINE$1.runKernel(UnsortedSegmentSum$1,{x:r,segmentIds:a},{numSegments:n})}const unsortedSegmentSum$5=op$1({unsortedSegmentSum_:unsortedSegmentSum_$1});function unstack_$1(e,t=0){const n=convertToTensor$1(e,"x","unstack","string_or_numeric");return assert$6(t>=-n.shape.length&&t<n.shape.length,()=>`Axis = ${t} is not in [-${n.shape.length}, ${n.shape.length})`),ENGINE$1.runKernel(Unpack$1,{value:n},{axis:t})}const unstack$1=op$1({unstack_:unstack_$1});function variable$1(e,t=!0,n,r){return ENGINE$1.makeVariable(e,t,n,r)}function whereImpl$5(e,t){const n=[];for(let e=0;e<t.length;e++)t[e]&&n.push(e);const r=buffer$1(e,"int32"),a=buffer$1([n.length,e.length],"int32");for(let t=0;t<n.length;t++){const s=r.indexToLoc(n[t]);a.values.set(s,t*e.length)}return a.toTensor()}function norm_$1(e,t="euclidean",n=null,r=!1){const a=normImpl$1(e=convertToTensor$1(e,"x","norm"),t,n);let s=a.shape;if(r){const t=parseAxisParam$1(n,e.shape);s=expandShapeToKeepDim$1(a.shape,t)}return reshape$6(a,s)}function normImpl$1(e,t,n=null){if(0===e.rank)return abs$5(e);if(1!==e.rank&&null===n)return normImpl$1(reshape$6(e,[-1]),t,n);if(1===e.rank||"number"==typeof n||Array.isArray(n)&&1===n.length){if(1===t)return sum$6(abs$5(e),n);if(Infinity===t)return max$7(abs$5(e),n);if(-Infinity===t)return min$7(abs$5(e),n);if("euclidean"===t||2===t)return sqrt$5(sum$6(pow$5(abs$5(e),scalar$1(2,"int32")),n));throw new Error(`Error in norm: invalid ord value: ${t}`)}if(Array.isArray(n)&&2===n.length){if(1===t)return max$7(sum$6(abs$5(e),n[0]),n[1]-1);if(Infinity===t)return max$7(sum$6(abs$5(e),n[1]),n[0]);if(-Infinity===t)return min$7(sum$6(abs$5(e),n[1]),n[0]);if("fro"===t||"euclidean"===t)return sqrt$5(sum$6(square$5(e),n));throw new Error(`Error in norm: invalid ord value: ${t}`)}throw new Error(`Error in norm: invalid axis: ${n}`)}const norm$1=op$1({norm_:norm_$1});function getNoiseShape$1(e,t){if(null==t)return e.shape.slice();if(arraysEqual$1(e.shape,t))return t;if(e.shape.length===t.length){const n=[];for(let r=0;r<e.shape.length;r++)n.push(null==t[r]&&null!=e.shape[r]?e.shape[r]:t[r]);return n}return t}function dropout_$1(e,t,n,r){const a=convertToTensor$1(e,"x","dropout");if(assert$6("float32"===a.dtype,()=>`x has to be a floating point tensor since it's going to be scaled, but got a ${a.dtype} tensor instead.`),assert$6(t>=0&&t<1,()=>`rate must be a float in the range [0, 1), but got ${t}.`),0===t)return e instanceof Tensor$1?a.clone():a;const s=getNoiseShape$1(a,n),o=1-t,i=div$3(floor$5(add$5(randomUniform$2(s,0,1,"float32",r),o)),o);return mul$1(a,i)}const dropout$5=op$1({dropout_:dropout_$1});function enclosingPowerOfTwo$1(e){return Math.floor(Math.pow(2,Math.ceil(Math.log(e)/Math.log(2))))}function cosineWindow$1(e,t,n){const r=1-e%2,a=new Float32Array(e);for(let s=0;s<e;++s){const o=2*Math.PI*s/(e+r-1);a[s]=t-n*Math.cos(o)}return tensor1d$1(a,"float32")}function conv2DBackpropFilter_$1(e,t,n,r,a,s="NHWC",o){let i=e;3===e.rank&&(i=reshape$6(e,[1,e.shape[0],e.shape[1],e.shape[2]]));let l=t;3===l.rank&&(l=reshape$6(t,[1,t.shape[0],t.shape[1],t.shape[2]])),assert$6(4===i.rank,()=>`Error in conv2dDerFilter: input must be rank 4, but got shape ${i.shape}.`),assert$6(4===l.rank,()=>`Error in conv2dDerFilter: dy must be rank 4, but got shape ${l.shape}.`),assert$6(4===n.length,()=>`Error in conv2dDerFilter: filterShape must be length 4, but got ${n}.`);const u="NHWC"===s?i.shape[3]:i.shape[1],c="NHWC"===s?l.shape[3]:l.shape[1];return assert$6(u===n[2],()=>`Error in conv2dDerFilter: depth of input ${u}) must match input depth in filter (${n[2]}.`),assert$6(c===n[3],()=>`Error in conv2dDerFilter: depth of dy (${c}) must match output depth for filter (${n[3]}).`),null!=o&&assert$6(isInt$1(a),()=>`Error in conv2dDerFilter: pad must be an integer when using, dimRoundingMode ${o} but got pad ${a}.`),ENGINE$1.runKernel(Conv2DBackpropFilter$1,{x:i,dy:l},{strides:r,pad:a,dataFormat:s,dimRoundingMode:o,filterShape:n})}const conv2DBackpropFilter$5=op$1({conv2DBackpropFilter_:conv2DBackpropFilter_$1});function getFusedDyActivation$1(e,t,n){if(null==n||"linear"===n)return e;if("relu"===n)return mul$1(e,step$5(t));throw new Error(`Cannot compute gradient for fused activation ${n}.`)}function getFusedBiasGradient$1(e,t){let n=t;const r=getReductionAxes$1(e.shape,t.shape);return r.length>0&&(n=sum$6(n,r)),reshape$6(n,e.shape)}function applyActivation$3(e,t,n,r){if("linear"===t)return e;if("relu"===t)return relu$6(e);if("elu"===t)return elu$8(e);if("relu6"===t)return relu6$5(e);if("prelu"===t)return prelu$6(e,n);if("leakyrelu"===t)return leakyRelu$5(e,r);if("sigmoid"===t)return sigmoid$5(e);throw new Error(`Unknown fused activation ${t}.`)}const shouldFuse$1=(e,t)=>!(e>0)||"linear"===t;function fusedConv2d_$1({x:e,filter:t,strides:n,pad:r,dataFormat:a="NHWC",dilations:s=[1,1],dimRoundingMode:o,bias:i,activation:l="linear",preluActivationWeights:u,leakyreluAlpha:c}){if(!1===shouldFuse$1(ENGINE$1.state.gradientDepth,l=l||"linear")){let p=conv2d$7(e,t,n,r,a,s,o);return null!=i&&(p=add$5(p,i)),applyActivation$3(p,l,u,c)}const p=convertToTensor$1(e,"x","conv2d"),d=convertToTensor$1(t,"filter","conv2d");let h=p,m=!1;3===p.rank&&(m=!0,h=reshape$6(p,[1,p.shape[0],p.shape[1],p.shape[2]])),assert$6(4===h.rank,()=>`Error in fused conv2d: input must be rank 4, but got rank ${h.rank}.`),assert$6(4===d.rank,()=>`Error in fused conv2d: filter must be rank 4, but got rank ${d.rank}.`),null!=o&&assert$6(isInt$1(r),()=>`Error in fused conv2d: pad must be an integer when using, dimRoundingMode ${o} but got pad ${r}.`),assert$6(h.shape[3]===d.shape[2],()=>`Error in conv2d: depth of input (${h.shape[3]}) must match input depth for filter ${d.shape[2]}.`),assert$6(eitherStridesOrDilationsAreOne$1(n,s),()=>`Error in conv2D: Either strides or dilations must be 1. Got strides ${n} and dilations '${s}'`),assert$6("NHWC"===a,()=>`Error in conv2d: got dataFormat of ${a} but only NHWC is currently supported.`);const f=computeConv2DInfo$1(h.shape,d.shape,n,s,r,o);let g,$;null!=i&&(g=convertToTensor$1(i,"bias","fused conv2d"),[g]=makeTypesMatch$1(g,p),assertAndGetBroadcastShape$1(f.outShape,g.shape)),null!=u&&($=convertToTensor$1(u,"prelu weights","fused conv2d"));const y=(e,t)=>{const[a,o,i,u]=t,c=getFusedDyActivation$1(e,i,l);assert$6(tupleValuesAreOne$1(s),()=>`Error in gradient of fused conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${s}'`);const p=[conv2DBackpropInput$5(o.shape,c,a,n,r),conv2DBackpropFilter$5(o,c,a.shape,n,r)];if(null!=u){const e=getFusedBiasGradient$1(u,c);p.push(e)}return p},b={x:h,filter:d,bias:g,preluActivationWeights:$},x={strides:n,pad:r,dataFormat:a,dilations:s,dimRoundingMode:o,activation:l,leakyreluAlpha:c};return null==i?customGrad$1((e,t,n)=>{let r=ENGINE$1.runKernel(FusedConv2D$1,b,x);return n([t,e,r]),m&&(r=reshape$6(r,[r.shape[1],r.shape[2],r.shape[3]])),{value:r,gradFunc:y}})(h,d):customGrad$1((e,t,n,r)=>{let a=ENGINE$1.runKernel(FusedConv2D$1,b,x);return r([t,e,a,n]),m&&(a=reshape$6(a,[a.shape[1],a.shape[2],a.shape[3]])),{value:a,gradFunc:y}})(h,d,g)}const conv2d$6=op$1({fusedConv2d_:fusedConv2d_$1});function depthwiseConv2dNativeBackpropFilter_$1(e,t,n,r,a,s=[1,1],o){let i=e;3===e.rank&&(i=reshape$6(e,[1,e.shape[0],e.shape[1],e.shape[2]]));let l=t;return 3===l.rank&&(l=reshape$6(t,[1,t.shape[0],t.shape[1],t.shape[2]])),ENGINE$1.runKernel(DepthwiseConv2dNativeBackpropFilter$1,{x:i,dy:l},{strides:r,pad:a,dimRoundingMode:o,dilations:s,filterShape:n})}const depthwiseConv2dNativeBackpropFilter$5=op$1({depthwiseConv2dNativeBackpropFilter_:depthwiseConv2dNativeBackpropFilter_$1});function depthwiseConv2dNativeBackpropInput_$1(e,t,n,r,a,s=[1,1],o){let i=t,l=!1;3===t.rank&&(l=!0,i=reshape$6(t,[1,t.shape[0],t.shape[1],t.shape[2]]));const u=ENGINE$1.runKernel(DepthwiseConv2dNativeBackpropInput$1,{dy:i,filter:n},{strides:r,pad:a,dimRoundingMode:o,dilations:s,inputShape:e});return l?reshape$6(u,[u.shape[1],u.shape[2],u.shape[3]]):u}const depthwiseConv2dNativeBackpropInput$5=op$1({depthwiseConv2dNativeBackpropInput_:depthwiseConv2dNativeBackpropInput_$1});function fusedMatMul_$1({a:e,b:t,transposeA:n=!1,transposeB:r=!1,bias:a,activation:s="linear",preluActivationWeights:o,leakyreluAlpha:i}){if(!1===shouldFuse$1(ENGINE$1.state.gradientDepth,s)){let l=matMul$3(e,t,n,r);return null!=a&&(l=add$5(l,a)),applyActivation$3(l,s,o,i)}let l=convertToTensor$1(e,"a","fused matMul"),u=convertToTensor$1(t,"b","fused matMul");[l,u]=makeTypesMatch$1(l,u);const c=n?l.shape[l.rank-2]:l.shape[l.rank-1],p=r?u.shape[u.rank-1]:u.shape[u.rank-2],d=n?l.shape[l.rank-1]:l.shape[l.rank-2],h=r?u.shape[u.rank-2]:u.shape[u.rank-1],m=l.shape.slice(0,-2),f=u.shape.slice(0,-2),g=sizeFromShape$1(m),$=sizeFromShape$1(f);assert$6(l.rank>=2&&u.rank>=2&&l.rank===u.rank,()=>`Error in fused matMul: inputs must have the same rank of at least 2, got ranks ${l.rank} and ${u.rank}.`),assert$6(arraysEqual$1(m,f),()=>`Error in fused matMul: outer dimensions (${m}) and (${f}) of Tensors with shapes ${l.shape} and ${u.shape} must match.`),assert$6(c===p,()=>`Error in fused matMul: inner shapes (${c}) and (${p}) of Tensors with shapes ${l.shape} and ${u.shape} and transposeA=${n} and transposeB=${r} must match.`);const y=l.shape.slice(0,-2).concat([d,h]),b=reshape$6(l,n?[g,c,d]:[g,d,c]),x=reshape$6(u,r?[$,h,p]:[$,p,h]);let v,I;null!=a&&(v=convertToTensor$1(a,"bias","fused matMul"),[v]=makeTypesMatch$1(v,l),assertAndGetBroadcastShape$1(y,v.shape)),null!=o&&(I=convertToTensor$1(o,"prelu weights","fused matMul"));const C=(e,t)=>{const[o,i,l,u]=t,c=getFusedDyActivation$1(reshape$6(e,l.shape),l,s);let p,d;return n||r?!n&&r?(p=matMul$3(c,i,!1,!1),d=matMul$3(c,o,!0,!1)):n&&!r?(p=matMul$3(i,c,!1,!0),d=matMul$3(o,c,!1,!1)):(p=matMul$3(i,c,!0,!0),d=matMul$3(c,o,!0,!0)):(p=matMul$3(c,i,!1,!0),d=matMul$3(o,c,!0,!1)),null!=a?[p,d,getFusedBiasGradient$1(u,c)]:[p,d]},S={a:b,b:x,bias:v,preluActivationWeights:I},k={transposeA:n,transposeB:r,activation:s,leakyreluAlpha:i};return null==a?customGrad$1((e,t,n)=>{const r=ENGINE$1.runKernel(_FusedMatMul$1,S,k);return n([e,t,r]),{value:reshape$6(r,y),gradFunc:C}})(b,x):customGrad$1((e,t,n,r)=>{const a=ENGINE$1.runKernel(_FusedMatMul$1,S,k);return r([e,t,a,n]),{value:reshape$6(a,y),gradFunc:C}})(b,x,v)}const matMul$2=op$1({fusedMatMul_:fusedMatMul_$1});function hammingWindow_$1(e){return cosineWindow$1(e,.54,.46)}const hammingWindow$1=op$1({hammingWindow_:hammingWindow_$1});function hannWindow_$1(e){return cosineWindow$1(e,.5,.5)}const hannWindow$1=op$1({hannWindow_:hannWindow_$1});function frame_$1(e,t,n,r=!1,a=0){let s=0;const o=[];for(;s+t<=e.size;)o.push(slice$5(e,s,t)),s+=n;if(r)for(;s<e.size;){const r=s+t-e.size,i=concat$5([slice$5(e,s,t-r),fill$5([r],a)]);o.push(i),s+=n}return 0===o.length?tensor2d$1([],[0,t]):reshape$6(concat$5(o),[o.length,t])}const frame$1=op$1({frame_:frame_$1});function stft_$1(e,t,n,r,a=hannWindow$1){null==r&&(r=enclosingPowerOfTwo$1(t));const s=frame$1(e,t,n),o=mul$1(s,a(t));return rfft$1(o,r)}const stft$1=op$1({stft_:stft_$1});function cropAndResize_$1(e,t,n,r,a="bilinear",s=0){const o=convertToTensor$1(e,"image","cropAndResize"),i=convertToTensor$1(t,"boxes","cropAndResize","float32"),l=convertToTensor$1(n,"boxInd","cropAndResize","int32"),u=i.shape[0];return assert$6(4===o.rank,()=>`Error in cropAndResize: image must be rank 4,but got rank ${o.rank}.`),assert$6(2===i.rank&&4===i.shape[1],()=>`Error in cropAndResize: boxes must be have size [${u},4] but had shape ${i.shape}.`),assert$6(1===l.rank&&l.shape[0]===u,()=>`Error in cropAndResize: boxInd must be have size [${u}] but had shape ${i.shape}.`),assert$6(2===r.length,()=>`Error in cropAndResize: cropSize must be of length 2, but got length ${r.length}.`),assert$6(r[0]>=1&&r[1]>=1,()=>`cropSize must be atleast [1,1], but was ${r}`),assert$6("bilinear"===a||"nearest"===a,()=>`method must be bilinear or nearest, but was ${a}`),ENGINE$1.runKernel(CropAndResize$1,{image:o,boxes:i,boxInd:l},{method:a,extrapolationValue:s,cropSize:r})}const cropAndResize$5=op$1({cropAndResize_:cropAndResize_$1});function flipLeftRight_$1(e){const t=convertToTensor$1(e,"image","flipLeftRight","float32");return assert$6(4===t.rank,()=>`Error in flipLeftRight: image must be rank 4,but got rank ${t.rank}.`),ENGINE$1.runKernel(FlipLeftRight$1,{image:t},{})}const flipLeftRight$1=op$1({flipLeftRight_:flipLeftRight_$1});function rotateWithOffset_$1(e,t,n=0,r=.5){const a=convertToTensor$1(e,"image","rotateWithOffset","float32");return assert$6(4===a.rank,()=>`Error in rotateWithOffset: image must be rank 4,but got rank ${a.rank}.`),ENGINE$1.runKernel(RotateWithOffset$1,{image:a},{radians:t,fillValue:n,center:r})}const rotateWithOffset$1=op$1({rotateWithOffset_:rotateWithOffset_$1});function nonMaxSuppSanityCheck$1(e,t,n,r,a,s){null==r&&(r=.5),null==a&&(a=Number.NEGATIVE_INFINITY),null==s&&(s=0);const o=e.shape[0];return n=Math.min(n,o),assert$6(0<=r&&r<=1,()=>`iouThreshold must be in [0, 1], but was '${r}'`),assert$6(2===e.rank,()=>`boxes must be a 2D tensor, but was of rank '${e.rank}'`),assert$6(4===e.shape[1],()=>`boxes must have 4 columns, but 2nd dimension was ${e.shape[1]}`),assert$6(1===t.rank,()=>"scores must be a 1D tensor"),assert$6(t.shape[0]===o,()=>`scores has incompatible shape with boxes. Expected ${o}, but was ${t.shape[0]}`),assert$6(0<=s&&s<=1,()=>`softNmsSigma must be in [0, 1], but was '${s}'`),{maxOutputSize:n,iouThreshold:r,scoreThreshold:a,softNmsSigma:s}}function nonMaxSuppression_$1(e,t,n,r=.5,a=Number.NEGATIVE_INFINITY){const s=convertToTensor$1(e,"boxes","nonMaxSuppression"),o=convertToTensor$1(t,"scores","nonMaxSuppression"),i=nonMaxSuppSanityCheck$1(s,o,n,r,a);return ENGINE$1.runKernel(NonMaxSuppressionV3$1,{boxes:s,scores:o},{maxOutputSize:n=i.maxOutputSize,iouThreshold:r=i.iouThreshold,scoreThreshold:a=i.scoreThreshold})}const nonMaxSuppression$1=op$1({nonMaxSuppression_:nonMaxSuppression_$1});function binaryInsert$1(e,t,n){const r=binarySearch$1(e,t,n);e.splice(r<0?-(r+1):r,0,t)}function binarySearch$1(e,t,n){return binarySearch_$1(e,t,n||defaultComparator$1)}function defaultComparator$1(e,t){return e>t?1:e<t?-1:0}function binarySearch_$1(e,t,n){let r=0,a=e.length,s=0,o=!1;for(;r<a;){s=r+(a-r>>>1);const i=n(t,e[s]);i>0?r=s+1:(a=s,o=!i)}return o?r:-r-1}function nonMaxSuppressionV3Impl$5(e,t,n,r,a){return nonMaxSuppressionImpl_$1(e,t,n,r,a,0)}function nonMaxSuppressionV4Impl$5(e,t,n,r,a,s){return nonMaxSuppressionImpl_$1(e,t,n,r,a,0,!1,s,!0)}function nonMaxSuppressionV5Impl$5(e,t,n,r,a,s){return nonMaxSuppressionImpl_$1(e,t,n,r,a,s,!0)}function nonMaxSuppressionImpl_$1(e,t,n,r,a,s,o=!1,i=!1,l=!1){const u=[];for(let e=0;e<t.length;e++)t[e]>a&&u.push({score:t[e],boxIndex:e,suppressBeginIndex:0});u.sort(ascendingComparator$1);const c=s>0?-.5/s:0,p=[],d=[];for(;p.length<n&&u.length>0;){const t=u.pop(),{score:n,boxIndex:s,suppressBeginIndex:o}=t;if(n<a)break;let i=!1;for(let n=p.length-1;n>=o;--n){const o=intersectionOverUnion$1(e,s,p[n]);if(o>=r){i=!0;break}if(t.score=t.score*suppressWeight$1(r,c,o),t.score<=a)break}t.suppressBeginIndex=p.length,i||(t.score===n?(p.push(s),d.push(t.score)):t.score>a&&binaryInsert$1(u,t,ascendingComparator$1))}const h=p.length,m=n-h;i&&m>0&&(p.push(...new Array(m).fill(0)),d.push(...new Array(m).fill(0)));const f={selectedIndices:p};return o&&(f.selectedScores=d),l&&(f.validOutputs=h),f}function intersectionOverUnion$1(e,t,n){const r=e.subarray(4*t,4*t+4),a=e.subarray(4*n,4*n+4),s=Math.min(r[0],r[2]),o=Math.min(r[1],r[3]),i=Math.max(r[0],r[2]),l=Math.max(r[1],r[3]),u=Math.min(a[0],a[2]),c=Math.min(a[1],a[3]),p=Math.max(a[0],a[2]),d=Math.max(a[1],a[3]),h=(i-s)*(l-o),m=(p-u)*(d-c);if(h<=0||m<=0)return 0;const f=Math.max(s,u),g=Math.max(o,c),$=Math.min(i,p),y=Math.min(l,d),b=Math.max($-f,0)*Math.max(y-g,0);return b/(h+m-b)}function suppressWeight$1(e,t,n){const r=Math.exp(t*n*n);return n<=e?r:0}function ascendingComparator$1(e,t){return e.score-t.score||e.score===t.score&&t.boxIndex-e.boxIndex}async function nonMaxSuppressionAsync_$1(e,t,n,r=.5,a=Number.NEGATIVE_INFINITY){const s=convertToTensor$1(e,"boxes","nonMaxSuppressionAsync"),o=convertToTensor$1(t,"scores","nonMaxSuppressionAsync"),i=nonMaxSuppSanityCheck$1(s,o,n,r,a);n=i.maxOutputSize,r=i.iouThreshold,a=i.scoreThreshold;const l=await Promise.all([s.data(),o.data()]),u=l[0],c=l[1],{selectedIndices:p}=nonMaxSuppressionV3Impl$5(u,c,n,r,a);return s!==e&&s.dispose(),o!==t&&o.dispose(),tensor1d$1(p,"int32")}const nonMaxSuppressionAsync$1=nonMaxSuppressionAsync_$1;function nonMaxSuppressionWithScore_$1(e,t,n,r=.5,a=Number.NEGATIVE_INFINITY,s=0){const o=convertToTensor$1(e,"boxes","nonMaxSuppression"),i=convertToTensor$1(t,"scores","nonMaxSuppression"),l=nonMaxSuppSanityCheck$1(o,i,n,r,a,s),u=ENGINE$1.runKernel(NonMaxSuppressionV5$1,{boxes:o,scores:i},{maxOutputSize:n=l.maxOutputSize,iouThreshold:r=l.iouThreshold,scoreThreshold:a=l.scoreThreshold,softNmsSigma:s=l.softNmsSigma});return{selectedIndices:u[0],selectedScores:u[1]}}const nonMaxSuppressionWithScore$1=op$1({nonMaxSuppressionWithScore_:nonMaxSuppressionWithScore_$1});async function nonMaxSuppressionWithScoreAsync_$1(e,t,n,r=.5,a=Number.NEGATIVE_INFINITY,s=0){const o=convertToTensor$1(e,"boxes","nonMaxSuppressionAsync"),i=convertToTensor$1(t,"scores","nonMaxSuppressionAsync"),l=nonMaxSuppSanityCheck$1(o,i,n,r,a,s);n=l.maxOutputSize,r=l.iouThreshold,a=l.scoreThreshold,s=l.softNmsSigma;const u=await Promise.all([o.data(),i.data()]),c=u[0],p=u[1],{selectedIndices:d,selectedScores:h}=nonMaxSuppressionV5Impl$5(c,p,n,r,a,s);return o!==e&&o.dispose(),i!==t&&i.dispose(),{selectedIndices:tensor1d$1(d,"int32"),selectedScores:tensor1d$1(h)}}const nonMaxSuppressionWithScoreAsync$1=nonMaxSuppressionWithScoreAsync_$1;function nonMaxSuppressionPadded_$1(e,t,n,r=.5,a=Number.NEGATIVE_INFINITY,s=!1){const o=convertToTensor$1(e,"boxes","nonMaxSuppression"),i=convertToTensor$1(t,"scores","nonMaxSuppression"),l=nonMaxSuppSanityCheck$1(o,i,n,r,a,null),u=ENGINE$1.runKernel(NonMaxSuppressionV4$1,{boxes:o,scores:i},{maxOutputSize:l.maxOutputSize,iouThreshold:l.iouThreshold,scoreThreshold:l.scoreThreshold,padToMaxOutputSize:s});return{selectedIndices:u[0],validOutputs:u[1]}}const nonMaxSuppressionPadded$1=op$1({nonMaxSuppressionPadded_:nonMaxSuppressionPadded_$1});async function nonMaxSuppressionPaddedAsync_$1(e,t,n,r=.5,a=Number.NEGATIVE_INFINITY,s=!1){const o=convertToTensor$1(e,"boxes","nonMaxSuppressionAsync"),i=convertToTensor$1(t,"scores","nonMaxSuppressionAsync"),l=nonMaxSuppSanityCheck$1(o,i,n,r,a,null),u=l.maxOutputSize,c=l.iouThreshold,p=l.scoreThreshold,[d,h]=await Promise.all([o.data(),i.data()]),{selectedIndices:m,validOutputs:f}=nonMaxSuppressionV4Impl$5(d,h,u,c,p,s);return o!==e&&o.dispose(),i!==t&&i.dispose(),{selectedIndices:tensor1d$1(m,"int32"),validOutputs:scalar$1(f,"int32")}}const nonMaxSuppressionPaddedAsync$1=nonMaxSuppressionPaddedAsync_$1;function resizeBilinear_$1(e,t,n=!1,r=!1){const a=convertToTensor$1(e,"images","resizeBilinear");assert$6(3===a.rank||4===a.rank,()=>`Error in resizeBilinear: x must be rank 3 or 4, but got rank ${a.rank}.`),assert$6(2===t.length,()=>`Error in resizeBilinear: new shape must 2D, but got shape ${t}.`),assert$6(!1===r||!1===n,()=>"Error in resizeBilinear: If halfPixelCenters is true, alignCorners must be false.");let s=a,o=!1;3===a.rank&&(o=!0,s=reshape$6(a,[1,a.shape[0],a.shape[1],a.shape[2]]));const i=ENGINE$1.runKernel(ResizeBilinear$1,{images:s},{alignCorners:n,halfPixelCenters:r,size:t});return o?reshape$6(i,[i.shape[1],i.shape[2],i.shape[3]]):i}const resizeBilinear$5=op$1({resizeBilinear_:resizeBilinear_$1});function resizeNearestNeighbor_$1(e,t,n=!1,r=!1){const a=convertToTensor$1(e,"images","resizeNearestNeighbor");assert$6(3===a.rank||4===a.rank,()=>`Error in resizeNearestNeighbor: x must be rank 3 or 4, but got rank ${a.rank}.`),assert$6(2===t.length,()=>`Error in resizeNearestNeighbor: new shape must 2D, but got shape ${t}.`),assert$6("float32"===a.dtype||"int32"===a.dtype,()=>"`images` must have `int32` or `float32` as dtype"),assert$6(!1===r||!1===n,()=>"Error in resizeNearestNeighbor: If halfPixelCenters is true, alignCorners must be false.");let s=a,o=!1;3===a.rank&&(o=!0,s=reshape$6(a,[1,a.shape[0],a.shape[1],a.shape[2]]));const i=ENGINE$1.runKernel(ResizeNearestNeighbor$1,{images:s},{alignCorners:n,halfPixelCenters:r,size:t});return o?reshape$6(i,[i.shape[1],i.shape[2],i.shape[3]]):i}const resizeNearestNeighbor$5=op$1({resizeNearestNeighbor_:resizeNearestNeighbor_$1});function threshold_$1(e,t="binary",n=!1,r=.5){const a=convertToTensor$1(e,"image","threshold"),s=a.shape[0]*a.shape[1];let o,i,l,u,c=mul$1(tensor1d$1([r]),255);if(assert$6(3===a.rank,()=>`Error in threshold: image must be rank 3,but got rank ${a.rank}.`),assert$6(3===a.shape[2]||1===a.shape[2],()=>`Error in threshold: image color channel must be equal to 3 or 1but got ${a.shape[2]}.`),assert$6("int32"===a.dtype||"float32"===a.dtype,()=>`Error in dtype: image dtype must be int32 or float32,but got dtype ${a.dtype}.`),assert$6("otsu"===t||"binary"===t,()=>`Method must be binary or otsu, but was ${t}`),3===a.shape[2]){[o,i,l]=split$4(a,[1,1,1],-1);const e=mul$1(o,.2989),t=mul$1(i,.587),n=mul$1(l,.114);u=add$5(add$5(e,t),n)}else u=e;"otsu"===t&&(c=otsu$1(bincount$5(cast$7(round$6(u),"int32"),tensor$1([]),256),s));const p=n?lessEqual$5(u,c):greater$6(u,c);return cast$7(mul$1(p,255),"int32")}function otsu$1(e,t){let n,r,a,s,o,i,l=tensor1d$1([-1]),u=tensor1d$1([0]),c=tensor1d$1([0]);for(let p=0;p<e.size-1;p++){n=slice$5(e,0,p+1),r=slice$5(e,p+1),o=div$3(sum$6(n),t),i=div$3(sum$6(r),t);const d=sum$6(mul$1(n,range$8(0,n.size)));a=div$3(d,sum$6(n));const h=fill$5(r.shape,n.size),m=add$5(range$8(0,r.size),h),f=mul$1(r,m);s=div$3(sum$6(f),sum$6(r));const g=sub$5(a,s),$=sub$5(a,s),y=mul$1(o,i);c=mul$1(mul$1(y,g),$);const b=greater$6(c,u);u=where$1(b,c,u),l=where$1(b,tensor1d$1([p]),l)}return l}const threshold$3=op$1({threshold_:threshold_$1});function transform_$1(e,t,n="nearest",r="constant",a=0,s){const o=convertToTensor$1(e,"image","transform","float32"),i=convertToTensor$1(t,"transforms","transform","float32");return assert$6(4===o.rank,()=>`Error in transform: image must be rank 4,but got rank ${o.rank}.`),assert$6(2===i.rank&&(i.shape[0]===o.shape[0]||1===i.shape[0])&&8===i.shape[1],()=>"Error in transform: Input transform should be batch x 8 or 1 x 8"),assert$6(null==s||2===s.length,()=>`Error in transform: outputShape must be [height, width] or null, but got ${s}.`),ENGINE$1.runKernel(Transform$1,{image:o,transforms:i},{interpolation:n,fillMode:r,fillValue:a,outputShape:s})}const transform$5=op$1({transform_:transform_$1});function bandPart_$1(e,t,n){assert$6(t%1==0,()=>`bandPart(): numLower must be an integer, got ${t}.`),assert$6(n%1==0,()=>`bandPart(): numUpper must be an integer, got ${n}.`);const r=convertToTensor$1(e,"a","bandPart");assert$6(r.rank>=2,()=>`bandPart(): Rank must be at least 2, got ${r.rank}.`);const a=r.shape,[s,o]=r.shape.slice(-2);if(!(t<=s))throw new Error(`bandPart(): numLower (${t}) must not be greater than the number of rows (${s}).`);if(!(n<=o))throw new Error(`bandPart(): numUpper (${n}) must not be greater than the number of columns (${o}).`);t<0&&(t=s),n<0&&(n=o);const i=reshape$6(range$8(0,s,1,"int32"),[-1,1]),l=range$8(0,o,1,"int32"),u=sub$5(i,l),c=logicalAnd$5(lessEqual$5(u,scalar$1(+t,"int32")),greaterEqual$5(u,scalar$1(-n,"int32"))),p=zeros$4([s,o],r.dtype);return reshape$6(stack$1(unstack$1(reshape$6(r,[-1,s,o])).map(e=>where$1(c,e,p))),a)}const bandPart$1=op$1({bandPart_:bandPart_$1});function gramSchmidt_$1(e){let t;if(Array.isArray(e)){t=!1,assert$6(null!=e&&e.length>0,()=>"Gram-Schmidt process: input must not be null, undefined, or empty");const n=e[0].shape[0];for(let t=1;t<e.length;++t)assert$6(e[t].shape[0]===n,()=>`Gram-Schmidt: Non-unique lengths found in the input vectors: (${e[t].shape[0]} vs. ${n})`)}else t=!0,e=split$4(e,e.shape[0],0).map(e=>squeeze$1(e,[0]));assert$6(e.length<=e[0].shape[0],()=>`Gram-Schmidt: Number of vectors (${e.length}) exceeds number of dimensions (${e[0].shape[0]}).`);const n=[],r=e;for(let t=0;t<e.length;++t)n.push(ENGINE$1.tidy(()=>{let e=r[t];if(t>0)for(let r=0;r<t;++r){const t=mul$1(sum$6(mul$1(n[r],e)),n[r]);e=sub$5(e,t)}return div$3(e,norm$1(e,"euclidean"))}));return t?stack$1(n,0):n}const gramSchmidt$1=op$1({gramSchmidt_:gramSchmidt_$1});function qr_$1(e,t=!1){if(assert$6(e.rank>=2,()=>`qr() requires input tensor to have a rank >= 2, but got rank ${e.rank}`),2===e.rank)return qr2d$1(e,t);{const n=e.shape.slice(0,e.shape.length-2).reduce((e,t)=>e*t),r=unstack$1(reshape$6(e,[n,e.shape[e.shape.length-2],e.shape[e.shape.length-1]]),0),a=[],s=[];return r.forEach(e=>{const[n,r]=qr2d$1(e,t);a.push(n),s.push(r)}),[reshape$6(stack$1(a,0),e.shape),reshape$6(stack$1(s,0),e.shape)]}}function qr2d$1(e,t=!1){return ENGINE$1.tidy(()=>{assert$6(2===e.shape.length,()=>`qr2d() requires a 2D Tensor, but got a ${e.shape.length}D Tensor.`);const n=e.shape[0],r=e.shape[1];let a=eye$1(n),s=clone$1(e);const o=tensor2d$1([[1]],[1,1]);let i=clone$1(o);const l=n>=r?r:n;for(let e=0;e<l;++e){const t=s,l=i,u=a;[i,s,a]=ENGINE$1.tidy(()=>{const t=slice$5(s,[e,e],[n-e,1]),l=norm$1(t),u=slice$5(s,[e,e],[1,1]),c=where$1(greater$6(u,0),tensor2d$1([[-1]]),tensor2d$1([[1]])),p=sub$5(u,mul$1(c,l)),d=div$3(t,p);i=1===d.shape[0]?clone$1(o):concat$5([o,slice$5(d,[1,0],[d.shape[0]-1,d.shape[1]])],0);const h=neg$5(div$3(matMul$3(c,p),l)),m=slice$5(s,[e,0],[n-e,r]),f=mul$1(h,i),g=transpose$5(i);if(0===e)s=sub$5(m,matMul$3(f,matMul$3(g,m)));else{const t=sub$5(m,matMul$3(f,matMul$3(g,m)));s=concat$5([slice$5(s,[0,0],[e,r]),t],0)}const $=transpose$5(f),y=slice$5(a,[0,e],[n,a.shape[1]-e]);if(0===e)a=sub$5(y,matMul$3(matMul$3(y,i),$));else{const t=sub$5(y,matMul$3(matMul$3(y,i),$));a=concat$5([slice$5(a,[0,0],[n,e]),t],1)}return[i,s,a]}),dispose$1([t,l,u])}return!t&&n>r&&(a=slice$5(a,[0,0],[n,r]),s=slice$5(s,[0,0],[r,r])),[a,s]})}const qr$1=op$1({qr_:qr_$1});var Reduction$1;function computeWeightedLoss_$1(e,t,n=Reduction$1.SUM_BY_NONZERO_WEIGHTS){const r=convertToTensor$1(e,"losses","computeWeightedLoss");let a=null;null!=t&&(a=convertToTensor$1(t,"weights","computeWeightedLoss"));const s=null==a?r:mul$1(r,a);if(n===Reduction$1.NONE)return s;if(n===Reduction$1.SUM)return sum$6(s);if(n===Reduction$1.MEAN){if(null==a)return mean$3(s);{const e=r.size/a.size,t=div$3(sum$6(s),sum$6(a));return e>1?div$3(t,scalar$1(e)):t}}if(n===Reduction$1.SUM_BY_NONZERO_WEIGHTS){if(null==a)return div$3(sum$6(s),scalar$1(r.size));{const e=mul$1(a,ones$3(r.shape)),t=cast$7(sum$6(notEqual$5(e,scalar$1(0))),"float32");return div$3(sum$6(s),t)}}throw Error(`Unknown reduction: ${n}`)}!function(e){e[e.NONE=0]="NONE",e[e.MEAN=1]="MEAN",e[e.SUM=2]="SUM",e[e.SUM_BY_NONZERO_WEIGHTS=3]="SUM_BY_NONZERO_WEIGHTS"}(Reduction$1||(Reduction$1={}));const computeWeightedLoss$3=op$1({computeWeightedLoss_:computeWeightedLoss_$1});function absoluteDifference_$1(e,t,n,r=Reduction$1.SUM_BY_NONZERO_WEIGHTS){const a=convertToTensor$1(e,"labels","absoluteDifference"),s=convertToTensor$1(t,"predictions","absoluteDifference");let o=null;null!=n&&(o=convertToTensor$1(n,"weights","absoluteDifference")),assertShapesMatch$1(a.shape,s.shape,"Error in absoluteDifference: ");const i=abs$5(sub$5(a,s));return computeWeightedLoss$3(i,o,r)}const absoluteDifference$1=op$1({absoluteDifference_:absoluteDifference_$1});function cosineDistance_$1(e,t,n,r,a=Reduction$1.SUM_BY_NONZERO_WEIGHTS){const s=convertToTensor$1(e,"labels","cosineDistance"),o=convertToTensor$1(t,"predictions","cosineDistance");let i=null;null!=r&&(i=convertToTensor$1(r,"weights","cosineDistance")),assertShapesMatch$1(s.shape,o.shape,"Error in cosineDistance: ");const l=scalar$1(1),u=sub$5(l,sum$6(mul$1(s,o),n,!0));return computeWeightedLoss$3(u,i,a)}const cosineDistance$1=op$1({cosineDistance_:cosineDistance_$1});function hingeLoss_$1(e,t,n,r=Reduction$1.SUM_BY_NONZERO_WEIGHTS){let a=convertToTensor$1(e,"labels","hingeLoss");const s=convertToTensor$1(t,"predictions","hingeLoss");let o=null;null!=n&&(o=convertToTensor$1(n,"weights","hingeLoss")),assertShapesMatch$1(a.shape,s.shape,"Error in hingeLoss: ");const i=scalar$1(1);a=sub$5(mul$1(scalar$1(2),a),i);const l=relu$6(sub$5(i,mul$1(a,s)));return computeWeightedLoss$3(l,o,r)}const hingeLoss$1=op$1({hingeLoss_:hingeLoss_$1});function huberLoss_$1(e,t,n,r=1,a=Reduction$1.SUM_BY_NONZERO_WEIGHTS){const s=convertToTensor$1(e,"labels","huberLoss"),o=convertToTensor$1(t,"predictions","huberLoss");let i=null;null!=n&&(i=convertToTensor$1(n,"weights","huberLoss")),assertShapesMatch$1(s.shape,o.shape,"Error in huberLoss: ");const l=scalar$1(r),u=abs$5(sub$5(o,s)),c=minimum$6(u,l),p=sub$5(u,c),d=add$5(mul$1(scalar$1(.5),square$5(c)),mul$1(l,p));return computeWeightedLoss$3(d,i,a)}const huberLoss$1=op$1({huberLoss_:huberLoss_$1});function logLoss_$1(e,t,n,r=1e-7,a=Reduction$1.SUM_BY_NONZERO_WEIGHTS){const s=convertToTensor$1(e,"labels","logLoss"),o=convertToTensor$1(t,"predictions","logLoss");let i=null;null!=n&&(i=convertToTensor$1(n,"weights","logLoss")),assertShapesMatch$1(s.shape,o.shape,"Error in logLoss: ");const l=scalar$1(1),u=scalar$1(r),c=neg$5(mul$1(s,log$7(add$5(o,u)))),p=mul$1(sub$5(l,s),log$7(add$5(sub$5(l,o),u))),d=sub$5(c,p);return computeWeightedLoss$3(d,i,a)}const logLoss$1=op$1({logLoss_:logLoss_$1});function meanSquaredError_$1(e,t,n,r=Reduction$1.SUM_BY_NONZERO_WEIGHTS){const a=convertToTensor$1(e,"labels","meanSquaredError"),s=convertToTensor$1(t,"predictions","meanSquaredError");let o=null;null!=n&&(o=convertToTensor$1(n,"weights","meanSquaredError")),assertShapesMatch$1(a.shape,s.shape,"Error in meanSquaredError: ");const i=squaredDifference$5(a,s);return computeWeightedLoss$3(i,o,r)}const meanSquaredError$4=op$1({meanSquaredError_:meanSquaredError_$1});function sigmoidCrossEntropyWithLogits_$1(e,t){const n=convertToTensor$1(e,"labels","sigmoidCrossEntropyWithLogits"),r=convertToTensor$1(t,"logits","sigmoidCrossEntropyWithLogits");assertShapesMatch$1(n.shape,r.shape,"Error in sigmoidCrossEntropyWithLogits: ");const a=relu$6(r),s=mul$1(r,n),o=log1p$5(exp$5(neg$5(abs$5(r))));return add$5(sub$5(a,s),o)}function sigmoidCrossEntropy_$1(e,t,n,r=0,a=Reduction$1.SUM_BY_NONZERO_WEIGHTS){let s=convertToTensor$1(e,"multiClassLabels","sigmoidCrossEntropy");const o=convertToTensor$1(t,"logits","sigmoidCrossEntropy");let i=null;if(null!=n&&(i=convertToTensor$1(n,"weights","sigmoidCrossEntropy")),assertShapesMatch$1(s.shape,o.shape,"Error in sigmoidCrossEntropy: "),r>0){const e=scalar$1(r),t=scalar$1(1),n=scalar$1(.5);s=add$5(mul$1(s,sub$5(t,e)),mul$1(n,e))}const l=sigmoidCrossEntropyWithLogits_$1(s,o);return computeWeightedLoss$3(l,i,a)}const sigmoidCrossEntropy$1=op$1({sigmoidCrossEntropy_:sigmoidCrossEntropy_$1});function softmaxCrossEntropyWithLogits_$1(e,t,n=-1){if(-1===n&&(n=t.rank-1),n!==t.rank-1)throw Error(`Softmax cross entropy along a non-last dimension is not yet supported. Labels / logits was rank ${t.rank} and dim was ${n}`);return customGrad$1((e,t,r)=>{const a=logSumExp$1(t,[n],!0),s=sub$5(cast$7(t,"float32"),a);r([e,s]);const o=neg$5(mul$1(s,e));return{value:sum$6(o,[n]),gradFunc:(e,t)=>{const[r,a]=t,s=expandShapeToKeepDim$1(e.shape,[n]);return[mul$1(reshape$6(e,s),sub$5(cast$7(r,"float32"),exp$5(a))),mul$1(reshape$6(e,s),sub$5(exp$5(a),cast$7(r,"float32")))]}}})(e,t)}function softmaxCrossEntropy_$1(e,t,n,r=0,a=Reduction$1.SUM_BY_NONZERO_WEIGHTS){let s=convertToTensor$1(e,"onehotLabels","softmaxCrossEntropy");const o=convertToTensor$1(t,"logits","softmaxCrossEntropy");let i=null;if(null!=n&&(i=convertToTensor$1(n,"weights","softmaxCrossEntropy")),assertShapesMatch$1(s.shape,o.shape,"Error in softmaxCrossEntropy: "),r>0){const e=scalar$1(r),t=scalar$1(1),n=scalar$1(s.shape[1]);s=add$5(mul$1(s,sub$5(t,e)),div$3(e,n))}const l=softmaxCrossEntropyWithLogits_$1(s,o);return computeWeightedLoss$3(l,i,a)}const softmaxCrossEntropy$1=op$1({softmaxCrossEntropy_:softmaxCrossEntropy_$1});function sparseFillEmptyRows_$1(e,t,n,r){const a=convertToTensor$1(e,"indices","sparseFillEmptyRows"),s=convertToTensor$1(t,"values","sparseFillEmptyRows"),o=convertToTensor$1(n,"denseShape","sparseFillEmptyRows"),i=convertToTensor$1(r,"defaultValue","sparseFillEmptyRows",s.dtype);if(2!==a.rank)throw new Error(`Indices should be Tensor2D but received shape\n        ${a.shape}`);if(1!==s.rank)throw new Error(`Values should be Tensor1D but received shape ${s.shape}`);if(1!==o.rank)throw new Error(`Dense shape should be Tensor1D but received shape ${o.shape}`);if(0!==i.rank)throw new Error(`Default value should be a scalar but received shape ${i.shape}`);const l=ENGINE$1.runKernel(SparseFillEmptyRows$1,{indices:a,values:s,denseShape:o,defaultValue:i});return{outputIndices:l[0],outputValues:l[1],emptyRowIndicator:l[2],reverseIndexMap:l[3]}}const sparseFillEmptyRows$5=op$1({sparseFillEmptyRows_:sparseFillEmptyRows_$1});function sparseReshape_$1(e,t,n){const r=convertToTensor$1(e,"inputIndices","sparseReshape"),a=convertToTensor$1(t,"inputShape","sparseReshape"),s=convertToTensor$1(n,"newShape","sparseReshape");if(2!==r.rank)throw new Error(`Input indices should be Tensor2D but received shape\n        ${r.shape}`);if(1!==a.rank)throw new Error(`Input shape should be Tensor1D but received shape ${a.shape}`);if(1!==s.rank)throw new Error(`New shape should be Tensor1D but received shape ${s.shape}`);const o=ENGINE$1.runKernel(SparseReshape$1,{inputIndices:r,inputShape:a,newShape:s});return{outputIndices:o[0],outputShape:o[1]}}const sparseReshape$5=op$1({sparseReshape_:sparseReshape_$1});function sparseSegmentMean_$1(e,t,n){const r=convertToTensor$1(e,"data","sparseSegmentMean"),a=convertToTensor$1(t,"indices","sparseSegmentMean"),s=convertToTensor$1(n,"segmentIds","sparseSegmentMean");if(r.rank<1)throw new Error("Data should be at least 1 dimensional but received scalar");if(1!==a.rank)throw new Error(`Indices should be Tensor1D but received shape\n          ${a.shape}`);if(1!==s.rank)throw new Error(`Segment ids should be Tensor1D but received shape\n          ${s.shape}`);return ENGINE$1.runKernel(SparseSegmentMean$1,{data:r,indices:a,segmentIds:s})}const sparseSegmentMean$5=op$1({sparseSegmentMean_:sparseSegmentMean_$1});function sparseSegmentSum_$1(e,t,n){const r=convertToTensor$1(e,"data","sparseSegmentSum"),a=convertToTensor$1(t,"indices","sparseSegmentSum"),s=convertToTensor$1(n,"segmentIds","sparseSegmentSum");if(r.rank<1)throw new Error("Data should be at least 1 dimensional but received scalar");if(1!==a.rank)throw new Error(`Indices should be Tensor1D but received shape\n         ${a.shape}`);if(1!==s.rank)throw new Error(`Segment ids should be Tensor1D but received shape\n         ${s.shape}`);return ENGINE$1.runKernel(SparseSegmentSum$1,{data:r,indices:a,segmentIds:s})}const sparseSegmentSum$5=op$1({sparseSegmentSum_:sparseSegmentSum_$1});function stringNGrams_$1(e,t,n,r,a,s,o,i){const l=convertToTensor$1(e,"data","stringNGrams","string");if("string"!==l.dtype)throw new Error("Data must be of datatype string");if(1!==l.shape.length)throw new Error(`Data must be a vector, saw: ${l.shape}`);const u=convertToTensor$1(t,"dataSplits","stringNGrams");if("int32"!==u.dtype)throw new Error("Data splits must be of datatype int32");const c=ENGINE$1.runKernel(StringNGrams$1,{data:l,dataSplits:u},{separator:n,nGramWidths:r,leftPad:a,rightPad:s,padWidth:o,preserveShortSequences:i});return{nGrams:c[0],nGramsSplits:c[1]}}const stringNGrams$5=op$1({stringNGrams_:stringNGrams_$1});function stringSplit_$1(e,t,n=!0){const r=convertToTensor$1(e,"input","stringSplit","string"),a=convertToTensor$1(t,"delimiter","stringSplit","string");if(1!==r.rank)throw new Error(`Input should be Tensor1D but received shape ${r.shape}`);if(0!==a.rank)throw new Error(`Delimiter should be a scalar but received shape ${a.shape}`);const s=ENGINE$1.runKernel(StringSplit$1,{input:r,delimiter:a},{skipEmpty:n});return{indices:s[0],values:s[1],shape:s[2]}}const stringSplit$5=op$1({stringSplit_:stringSplit_$1});function stringToHashBucketFast_$1(e,t){const n=convertToTensor$1(e,"input","stringToHashBucketFast","string"),r={numBuckets:t};if(t<=0)throw new Error("Number of buckets must be at least 1");return ENGINE$1.runKernel(StringToHashBucketFast$1,{input:n},r)}const stringToHashBucketFast$5=op$1({stringToHashBucketFast_:stringToHashBucketFast_$1}),image$2={flipLeftRight:flipLeftRight$1,resizeNearestNeighbor:resizeNearestNeighbor$5,resizeBilinear:resizeBilinear$5,rotateWithOffset:rotateWithOffset$1,cropAndResize:cropAndResize$5,nonMaxSuppression:nonMaxSuppression$1,nonMaxSuppressionAsync:nonMaxSuppressionAsync$1,nonMaxSuppressionWithScore:nonMaxSuppressionWithScore$1,nonMaxSuppressionWithScoreAsync:nonMaxSuppressionWithScoreAsync$1,nonMaxSuppressionPadded:nonMaxSuppressionPadded$1,nonMaxSuppressionPaddedAsync:nonMaxSuppressionPaddedAsync$1,threshold:threshold$3,transform:transform$5},linalg$1={bandPart:bandPart$1,gramSchmidt:gramSchmidt$1,qr:qr$1};class Optimizer$1 extends Serializable$1{minimize(e,t=!1,n){const{value:r,grads:a}=this.computeGradients(e,n);if(null!=n){const e=n.map(e=>({name:e.name,tensor:a[e.name]}));this.applyGradients(e)}else this.applyGradients(a);return dispose$1(a),t?r:(r.dispose(),null)}get iterations(){return null==this.iterations_&&(this.iterations_=0),this.iterations_}incrementIterations(){this.iterations_=this.iterations+1}computeGradients(e,t){return variableGrads$1(e,t)}dispose(){null!=this.iterations_&&dispose$1(this.iterations_)}async saveIterations(){return null==this.iterations_&&(this.iterations_=0),{name:"iter",tensor:scalar$1(this.iterations_,"int32")}}async getWeights(){throw new Error("getWeights() is not implemented for this optimizer yet.")}async setWeights(e){throw new Error(`setWeights() is not implemented for this optimizer class ${this.getClassName()}`)}async extractIterations(e){return this.iterations_=(await e[0].tensor.data())[0],e.slice(1)}}Object.defineProperty(Optimizer$1,Symbol.hasInstance,{value:e=>null!=e.minimize&&null!=e.computeGradients&&null!=e.applyGradients});class AdadeltaOptimizer$1 extends Optimizer$1{constructor(e,t,n=null){super(),this.learningRate=e,this.rho=t,this.epsilon=n,this.accumulatedGrads=[],this.accumulatedUpdates=[],null==n&&(this.epsilon=ENGINE$1.backend.epsilon())}applyGradients(e){(Array.isArray(e)?e.map(e=>e.name):Object.keys(e)).forEach((t,n)=>{const r=ENGINE$1.registeredVariables[t];null==this.accumulatedGrads[n]&&(this.accumulatedGrads[n]={originalName:`${t}/accum_grad`,variable:tidy$1(()=>zerosLike$5(r).variable(!1))}),null==this.accumulatedUpdates[n]&&(this.accumulatedUpdates[n]={originalName:`${t}/accum_var`,variable:tidy$1(()=>zerosLike$5(r).variable(!1))});const a=Array.isArray(e)?e[n].tensor:e[t];if(null==a)return;const s=this.accumulatedGrads[n].variable,o=this.accumulatedUpdates[n].variable;tidy$1(()=>{const e=add$5(mul$1(s,this.rho),mul$1(square$5(a),1-this.rho)),t=mul$1(div$3(sqrt$5(add$5(o,this.epsilon)),sqrt$5(add$5(s,this.epsilon))),a),n=add$5(mul$1(o,this.rho),mul$1(square$5(t),1-this.rho));s.assign(e),o.assign(n);const i=add$5(mul$1(t,-this.learningRate),r);r.assign(i)})}),this.incrementIterations()}dispose(){null!=this.accumulatedUpdates&&(dispose$1(this.accumulatedGrads.map(e=>e.variable)),dispose$1(this.accumulatedUpdates.map(e=>e.variable)))}async getWeights(){const e=[...this.accumulatedGrads,...this.accumulatedUpdates];return[await this.saveIterations()].concat(e.map(e=>({name:e.originalName,tensor:e.variable})))}async setWeights(e){const t=(e=await this.extractIterations(e)).length/2;this.accumulatedGrads=e.slice(0,t).map(e=>({originalName:e.name,variable:e.tensor.variable(!1)})),this.accumulatedUpdates=e.slice(t,2*t).map(e=>({originalName:e.name,variable:e.tensor.variable(!1)}))}getConfig(){return{learningRate:this.learningRate,rho:this.rho,epsilon:this.epsilon}}static fromConfig(e,t){return new e(t.learningRate,t.rho,t.epsilon)}}AdadeltaOptimizer$1.className="Adadelta",registerClass$1(AdadeltaOptimizer$1);class AdagradOptimizer$1 extends Optimizer$1{constructor(e,t=.1){super(),this.learningRate=e,this.initialAccumulatorValue=t,this.accumulatedGrads=[]}applyGradients(e){(Array.isArray(e)?e.map(e=>e.name):Object.keys(e)).forEach((t,n)=>{const r=ENGINE$1.registeredVariables[t];if(null==this.accumulatedGrads[n]){const e=!1;this.accumulatedGrads[n]={originalName:`${t}/accumulator`,variable:tidy$1(()=>fill$5(r.shape,this.initialAccumulatorValue).variable(e))}}const a=Array.isArray(e)?e[n].tensor:e[t];if(null==a)return;const s=this.accumulatedGrads[n].variable;tidy$1(()=>{const e=add$5(s,square$5(a));s.assign(e);const t=add$5(mul$1(div$3(a,sqrt$5(add$5(e,ENGINE$1.backend.epsilon()))),-this.learningRate),r);r.assign(t)})}),this.incrementIterations()}dispose(){null!=this.accumulatedGrads&&dispose$1(this.accumulatedGrads.map(e=>e.variable))}async getWeights(){return[await this.saveIterations()].concat(this.accumulatedGrads.map(e=>({name:e.originalName,tensor:e.variable})))}async setWeights(e){e=await this.extractIterations(e),this.accumulatedGrads=e.map(e=>({originalName:e.name,variable:e.tensor.variable(!1)}))}getConfig(){return{learningRate:this.learningRate,initialAccumulatorValue:this.initialAccumulatorValue}}static fromConfig(e,t){return new e(t.learningRate,t.initialAccumulatorValue)}}AdagradOptimizer$1.className="Adagrad",registerClass$1(AdagradOptimizer$1);class AdamOptimizer$1 extends Optimizer$1{constructor(e,t,n,r=null){super(),this.learningRate=e,this.beta1=t,this.beta2=n,this.epsilon=r,this.accumulatedFirstMoment=[],this.accumulatedSecondMoment=[],tidy$1(()=>{this.accBeta1=scalar$1(t).variable(),this.accBeta2=scalar$1(n).variable()}),null==r&&(this.epsilon=ENGINE$1.backend.epsilon())}applyGradients(e){const t=Array.isArray(e)?e.map(e=>e.name):Object.keys(e);tidy$1(()=>{const n=sub$5(1,this.accBeta1),r=sub$5(1,this.accBeta2);t.forEach((t,a)=>{const s=ENGINE$1.registeredVariables[t];null==this.accumulatedFirstMoment[a]&&(this.accumulatedFirstMoment[a]={originalName:`${t}/m`,variable:tidy$1(()=>zerosLike$5(s).variable(!1))}),null==this.accumulatedSecondMoment[a]&&(this.accumulatedSecondMoment[a]={originalName:`${t}/v`,variable:tidy$1(()=>zerosLike$5(s).variable(!1))});const o=Array.isArray(e)?e[a].tensor:e[t];if(null==o)return;const i=this.accumulatedFirstMoment[a].variable,l=this.accumulatedSecondMoment[a].variable,u=add$5(mul$1(i,this.beta1),mul$1(o,1-this.beta1)),c=add$5(mul$1(l,this.beta2),mul$1(square$5(o),1-this.beta2)),p=div$3(u,n),d=div$3(c,r);i.assign(u),l.assign(c);const h=add$5(mul$1(div$3(p,add$5(sqrt$5(d),this.epsilon)),-this.learningRate),s);s.assign(h)}),this.accBeta1.assign(mul$1(this.accBeta1,this.beta1)),this.accBeta2.assign(mul$1(this.accBeta2,this.beta2))}),this.incrementIterations()}dispose(){this.accBeta1.dispose(),this.accBeta2.dispose(),null!=this.accumulatedFirstMoment&&dispose$1(this.accumulatedFirstMoment.map(e=>e.variable)),null!=this.accumulatedSecondMoment&&dispose$1(this.accumulatedSecondMoment.map(e=>e.variable))}async getWeights(){const e=[...this.accumulatedFirstMoment,...this.accumulatedSecondMoment];return[await this.saveIterations()].concat(e.map(e=>({name:e.originalName,tensor:e.variable})))}async setWeights(e){e=await this.extractIterations(e),tidy$1(()=>{this.accBeta1.assign(pow$5(this.beta1,this.iterations_+1)),this.accBeta2.assign(pow$5(this.beta2,this.iterations_+1))});const t=e.length/2;this.accumulatedFirstMoment=e.slice(0,t).map(e=>({originalName:e.name,variable:e.tensor.variable(!1)})),this.accumulatedSecondMoment=e.slice(t,2*t).map(e=>({originalName:e.name,variable:e.tensor.variable(!1)}))}getConfig(){return{learningRate:this.learningRate,beta1:this.beta1,beta2:this.beta2,epsilon:this.epsilon}}static fromConfig(e,t){return new e(t.learningRate,t.beta1,t.beta2,t.epsilon)}}AdamOptimizer$1.className="Adam",registerClass$1(AdamOptimizer$1);class AdamaxOptimizer$1 extends Optimizer$1{constructor(e,t,n,r=null,a=0){super(),this.learningRate=e,this.beta1=t,this.beta2=n,this.epsilon=r,this.decay=a,this.accumulatedFirstMoment=[],this.accumulatedWeightedInfNorm=[],tidy$1(()=>{this.iteration=scalar$1(0).variable(),this.accBeta1=scalar$1(t).variable()}),null==r&&(this.epsilon=ENGINE$1.backend.epsilon())}applyGradients(e){const t=Array.isArray(e)?e.map(e=>e.name):Object.keys(e);tidy$1(()=>{const n=sub$5(1,this.accBeta1),r=div$3(-this.learningRate,add$5(mul$1(this.iteration,this.decay),1));t.forEach((t,a)=>{const s=ENGINE$1.registeredVariables[t];null==this.accumulatedFirstMoment[a]&&(this.accumulatedFirstMoment[a]={originalName:`${t}/m`,variable:zerosLike$5(s).variable(!1)}),null==this.accumulatedWeightedInfNorm[a]&&(this.accumulatedWeightedInfNorm[a]={originalName:`${t}/v`,variable:zerosLike$5(s).variable(!1)});const o=Array.isArray(e)?e[a].tensor:e[t];if(null==o)return;const i=this.accumulatedFirstMoment[a].variable,l=this.accumulatedWeightedInfNorm[a].variable,u=add$5(mul$1(i,this.beta1),mul$1(o,1-this.beta1)),c=mul$1(l,this.beta2),p=abs$5(o),d=maximum$6(c,p);i.assign(u),l.assign(d);const h=add$5(mul$1(div$3(r,n),div$3(u,add$5(d,this.epsilon))),s);s.assign(h)}),this.iteration.assign(add$5(this.iteration,1)),this.accBeta1.assign(mul$1(this.accBeta1,this.beta1))}),this.incrementIterations()}dispose(){this.accBeta1.dispose(),this.iteration.dispose(),null!=this.accumulatedFirstMoment&&dispose$1(this.accumulatedFirstMoment.map(e=>e.variable)),null!=this.accumulatedWeightedInfNorm&&dispose$1(this.accumulatedWeightedInfNorm.map(e=>e.variable))}async getWeights(){throw new Error("getWeights() is not implemented for Adamax yet.")}async setWeights(e){throw new Error("setWeights() is not implemented for Adamax yet.")}getConfig(){return{learningRate:this.learningRate,beta1:this.beta1,beta2:this.beta2,epsilon:this.epsilon,decay:this.decay}}static fromConfig(e,t){return new e(t.learningRate,t.beta1,t.beta2,t.epsilon,t.decay)}}AdamaxOptimizer$1.className="Adamax",registerClass$1(AdamaxOptimizer$1);class SGDOptimizer$1 extends Optimizer$1{constructor(e){super(),this.learningRate=e,this.setLearningRate(e)}applyGradients(e){(Array.isArray(e)?e.map(e=>e.name):Object.keys(e)).forEach((t,n)=>{const r=Array.isArray(e)?e[n].tensor:e[t];if(null==r)return;const a=ENGINE$1.registeredVariables[t];tidy$1(()=>{const e=add$5(mul$1(this.c,r),a);a.assign(e)})}),this.incrementIterations()}setLearningRate(e){this.learningRate=e,null!=this.c&&this.c.dispose(),this.c=keep$1(scalar$1(-e))}dispose(){this.c.dispose()}async getWeights(){return[await this.saveIterations()]}async setWeights(e){if(0!==(e=await this.extractIterations(e)).length)throw new Error("SGD optimizer does not have settable weights.")}getConfig(){return{learningRate:this.learningRate}}static fromConfig(e,t){return new e(t.learningRate)}}SGDOptimizer$1.className="SGD",registerClass$1(SGDOptimizer$1);class MomentumOptimizer$1 extends SGDOptimizer$1{constructor(e,t,n=!1){super(e),this.learningRate=e,this.momentum=t,this.useNesterov=n,this.accumulations=[],this.m=scalar$1(this.momentum)}applyGradients(e){(Array.isArray(e)?e.map(e=>e.name):Object.keys(e)).forEach((t,n)=>{const r=ENGINE$1.registeredVariables[t];if(null==this.accumulations[n]){const e=!1;this.accumulations[n]={originalName:`${t}/momentum`,variable:tidy$1(()=>zerosLike$5(r).variable(e))}}const a=this.accumulations[n].variable,s=Array.isArray(e)?e[n].tensor:e[t];null!=s&&tidy$1(()=>{let e;const t=add$5(mul$1(this.m,a),s);e=add$5(mul$1(this.c,this.useNesterov?add$5(s,mul$1(t,this.m)):t),r),a.assign(t),r.assign(e)})}),this.incrementIterations()}dispose(){this.m.dispose(),null!=this.accumulations&&dispose$1(this.accumulations.map(e=>e.variable))}setMomentum(e){this.momentum=e}async getWeights(){return[await this.saveIterations()].concat(this.accumulations.map(e=>({name:e.originalName,tensor:e.variable})))}async setWeights(e){e=await this.extractIterations(e),this.accumulations=e.map(e=>({originalName:e.name,variable:e.tensor.variable(!1)}))}getConfig(){return{learningRate:this.learningRate,momentum:this.momentum,useNesterov:this.useNesterov}}static fromConfig(e,t){return new e(t.learningRate,t.momentum,t.useNesterov)}}MomentumOptimizer$1.className="Momentum",registerClass$1(MomentumOptimizer$1);class RMSPropOptimizer$1 extends Optimizer$1{constructor(e,t=.9,n=0,r=null,a=!1){if(super(),this.learningRate=e,this.decay=t,this.momentum=n,this.epsilon=r,this.accumulatedMeanSquares=[],this.accumulatedMoments=[],this.accumulatedMeanGrads=[],this.centered=a,null==r&&(this.epsilon=ENGINE$1.backend.epsilon()),null==e)throw new Error("learningRate for RMSPropOptimizer must be defined.")}applyGradients(e){(Array.isArray(e)?e.map(e=>e.name):Object.keys(e)).forEach((t,n)=>{const r=ENGINE$1.registeredVariables[t],a=!1;null==this.accumulatedMeanSquares[n]&&(this.accumulatedMeanSquares[n]={originalName:`${t}/rms`,variable:tidy$1(()=>zerosLike$5(r).variable(a))}),null==this.accumulatedMoments[n]&&(this.accumulatedMoments[n]={originalName:`${t}/momentum`,variable:tidy$1(()=>zerosLike$5(r).variable(a))}),null==this.accumulatedMeanGrads[n]&&this.centered&&(this.accumulatedMeanGrads[n]={originalName:`${t}/mg`,variable:tidy$1(()=>zerosLike$5(r).variable(a))});const s=Array.isArray(e)?e[n].tensor:e[t];if(null==s)return;const o=this.accumulatedMeanSquares[n].variable,i=this.accumulatedMoments[n].variable;tidy$1(()=>{const e=add$5(mul$1(o,this.decay),mul$1(square$5(s),1-this.decay));if(this.centered){const t=this.accumulatedMeanGrads[n].variable,a=add$5(mul$1(t,this.decay),mul$1(s,1-this.decay)),l=div$3(mul$1(s,this.learningRate),sqrt$5(sub$5(e,add$5(square$5(a),this.epsilon)))),u=add$5(mul$1(i,this.momentum),l);o.assign(e),t.assign(a),i.assign(u);const c=sub$5(r,u);r.assign(c)}else{const e=add$5(mul$1(o,this.decay),mul$1(square$5(s),1-this.decay)),t=add$5(mul$1(i,this.momentum),div$3(mul$1(s,this.learningRate),sqrt$5(add$5(e,this.epsilon))));o.assign(e),i.assign(t);const n=sub$5(r,t);r.assign(n)}})}),this.incrementIterations()}dispose(){null!=this.accumulatedMeanSquares&&dispose$1(this.accumulatedMeanSquares.map(e=>e.variable)),null!=this.accumulatedMeanGrads&&this.centered&&dispose$1(this.accumulatedMeanGrads.map(e=>e.variable)),null!=this.accumulatedMoments&&dispose$1(this.accumulatedMoments.map(e=>e.variable))}async getWeights(){const e=[...this.accumulatedMeanSquares,...this.accumulatedMoments];return this.centered&&e.push(...this.accumulatedMeanGrads),[await this.saveIterations()].concat(e.map(e=>({name:e.originalName,tensor:e.variable})))}async setWeights(e){e=await this.extractIterations(e);const t=this.centered?e.length/3:e.length/2,n=!1;this.accumulatedMeanSquares=e.slice(0,t).map(e=>({originalName:e.name,variable:e.tensor.variable(n)})),this.accumulatedMoments=e.slice(t,2*t).map(e=>({originalName:e.name,variable:e.tensor.variable(n)})),this.centered&&(this.accumulatedMeanGrads=e.slice(2*t,3*t).map(e=>({originalName:e.name,variable:e.tensor.variable(n)})))}getConfig(){return{learningRate:this.learningRate,decay:this.decay,momentum:this.momentum,epsilon:this.epsilon,centered:this.centered}}static fromConfig(e,t){return new e(t.learningRate,t.decay,t.momentum,t.epsilon,t.centered)}}RMSPropOptimizer$1.className="RMSProp",registerClass$1(RMSPropOptimizer$1);class OptimizerConstructors$1{static sgd(e){return new SGDOptimizer$1(e)}static momentum(e,t,n=!1){return new MomentumOptimizer$1(e,t,n)}static rmsprop(e,t=.9,n=0,r=null,a=!1){return new RMSPropOptimizer$1(e,t,n,r,a)}static adam(e=.001,t=.9,n=.999,r=null){return new AdamOptimizer$1(e,t,n,r)}static adadelta(e=.001,t=.95,n=null){return new AdadeltaOptimizer$1(e,t,n)}static adamax(e=.002,t=.9,n=.999,r=null,a=0){return new AdamaxOptimizer$1(e,t,n,r,a)}static adagrad(e,t=.1){return new AdagradOptimizer$1(e,t)}}const train$1={sgd:OptimizerConstructors$1.sgd,momentum:OptimizerConstructors$1.momentum,adadelta:OptimizerConstructors$1.adadelta,adagrad:OptimizerConstructors$1.adagrad,rmsprop:OptimizerConstructors$1.rmsprop,adamax:OptimizerConstructors$1.adamax,adam:OptimizerConstructors$1.adam},delayCallback$1="undefined"!=typeof requestAnimationFrame?requestAnimationFrame:"undefined"!=typeof setImmediate?setImmediate:e=>e();function nextFrame$1(){return new Promise(e=>delayCallback$1(()=>e()))}function assertParamsConsistent$1(e,t){const n=e[0].length;e.forEach((e,t)=>{assert$6(e.length===n,()=>`Error in concat${n}D: rank of tensors[${t}] must be the same as the rank of the rest (${n})`)}),assert$6(t>=0&&t<n,()=>`Error in concat${n}D: axis must be between 0 and ${n-1}.`);const r=e[0];e.forEach((e,a)=>{for(let s=0;s<n;s++)assert$6(s===t||e[s]===r[s],()=>`Error in concat${n}D: Shape of tensors[${a}] (${e}) does not match the shape of the rest (${r}) along the non-concatenated axis ${a}.`)})}function computeOutShape$4(e,t){const n=e[0].slice();for(let r=1;r<e.length;r++)n[t]+=e[r][t];return n}const PARALLELIZE_THRESHOLD$1=30;function computeOptimalWindowSize$1(e){return e<=PARALLELIZE_THRESHOLD$1?e:nearestDivisor$1(e,Math.floor(Math.sqrt(e)))}function getImageCenter$1(e,t,n){return[n*("number"==typeof e?e:e[0]),t*("number"==typeof e?e:e[1])]}function getReshaped$1(e,t,n,r=!0){let a=[];if(r)a=a.concat(t.slice(0)),a.push(e[0]/n),a=a.concat(e.slice(1));else{a=a.concat(e[0]);const n=t.length;for(let r=0;r<n;++r)a=a.concat([e[r+1]/t[r],t[r]]);a=a.concat(e.slice(n+1))}return a}function getPermuted$1(e,t,n=!0){const r=[];if(n){r.push(t);for(let n=t+1;n<e;++n)n<=2*t?(r.push(n),r.push(n-(t+1))):r.push(n)}else{const n=[],a=[];for(let r=1;r<e;++r)r>=2*t+1||r%2==1?a.push(r):n.push(r);r.push(...n),r.push(0),r.push(...a)}return r}function getReshapedPermuted$1(e,t,n,r=!0){const a=[];a.push(r?e[0]/n:e[0]*n);for(let n=1;n<e.length;++n)a.push(n<=t.length?r?t[n-1]*e[n]:e[n]/t[n-1]:e[n]);return a}function getSliceBeginCoords$1(e,t){const n=[0];for(let r=0;r<t;++r)n.push(e[r][0]);return n}function getSliceSize$1(e,t,n){const r=e.slice(0,1);for(let a=0;a<n;++a)r.push(e[a+1]-t[a][0]-t[a][1]);return r}const SELU_SCALEALPHA$1=1.7580993408473768,SELU_SCALE$1=1.0507009873554805,ERF_P$1=.3275911,ERF_A1$1=.254829592,ERF_A2$1=-.284496736,ERF_A3$1=1.421413741,ERF_A4$1=-1.453152027,ERF_A5$1=1.061405429;function warn$1(...e){env$1().getBool("IS_TEST")||console.warn(...e)}function log$6(...e){env$1().getBool("IS_TEST")||console.log(...e)}function mergeRealAndImagArrays$1(e,t){if(e.length!==t.length)throw new Error(`Cannot merge real and imag arrays of different lengths. real:${e.length}, imag: ${t.length}.`);const n=new Float32Array(2*e.length);for(let r=0;r<n.length;r+=2)n[r]=e[r/2],n[r+1]=t[r/2];return n}function splitRealAndImagArrays$1(e){const t=new Float32Array(e.length/2),n=new Float32Array(e.length/2);for(let r=0;r<e.length;r+=2)t[r/2]=e[r],n[r/2]=e[r+1];return{real:t,imag:n}}function complexWithEvenIndex$1(e){const t=Math.ceil(e.length/4),n=new Float32Array(t),r=new Float32Array(t);for(let t=0;t<e.length;t+=4)n[Math.floor(t/4)]=e[t],r[Math.floor(t/4)]=e[t+1];return{real:n,imag:r}}function complexWithOddIndex$1(e){const t=Math.floor(e.length/4),n=new Float32Array(t),r=new Float32Array(t);for(let t=2;t<e.length;t+=4)n[Math.floor(t/4)]=e[t],r[Math.floor(t/4)]=e[t+1];return{real:n,imag:r}}function getComplexWithIndex$1(e,t){return{real:e[2*t],imag:e[2*t+1]}}function assignToTypedArray$1(e,t,n,r){e[2*r]=t,e[2*r+1]=n}function exponents$1(e,t){const n=new Float32Array(e/2),r=new Float32Array(e/2);for(let a=0;a<Math.ceil(e/2);a++){const s=(t?2:-2)*Math.PI*(a/e);n[a]=Math.cos(s),r[a]=Math.sin(s)}return{real:n,imag:r}}function exponent$1(e,t,n){const r=(n?2:-2)*Math.PI*(e/t);return{real:Math.cos(r),imag:Math.sin(r)}}const ARROW$1="->",ARROW_REGEX$1=/->/g,COMMA$1=",",ELLIPSIS$1="...";function decodeEinsumEquation$1(e,t){const n=((e=e.replace(/\s/g,"")).length-e.replace(ARROW_REGEX$1,"").length)/ARROW$1.length;if(n<1)throw new Error("Equations without an arrow are not supported.");if(n>1)throw new Error(`Equation must contain exactly one arrow ("${ARROW$1}").`);const[r,a]=e.split(ARROW$1);assert$6(-1===r.indexOf(ELLIPSIS$1),()=>`The ellipsis notation ("${ELLIPSIS$1}") is not supported yet.`);const s=r.split(COMMA$1),o=s.length;if(t!==o)throw new Error(`Expected ${o} input tensors, received ${t}`);if(o>2)throw new Error("Support for more than 2 input tensors is not implemented yet.");const i=[];for(let e=0;e<a.length;++e){const t=a[e];if(!s.some(e=>-1!==e.indexOf(t)))throw new Error(`Output subscripts contain the label ${t} not present in the input subscripts.`);-1===i.indexOf(t)&&i.push(t)}for(let e=0;e<r.length;++e){const t=r[e];-1===i.indexOf(t)&&t!==COMMA$1&&i.push(t)}const l=new Array(s.length);for(let e=0;e<o;++e){if(new Set(s[e].split("")).size!==s[e].length)throw new Error(`Found duplicate axes in input component ${s[e]}. Support for duplicate axes in input is not implemented yet.`);l[e]=[];for(let t=0;t<s[e].length;++t)l[e].push(i.indexOf(s[e][t]))}const u=i.length,c=[];for(let e=a.length;e<u;++e)c.push(e);return{allDims:i,summedDims:c,idDims:l}}function getEinsumPermutation$1(e,t){let n=new Array(e);n.fill(-1);for(let e=0;e<t.length;++e)n[t[e]]=e;const r=[];for(let t=0;t<e;++t)-1===n[t]&&r.push(t);return n=n.filter(e=>-1!==e),{permutationIndices:n,expandDims:r}}function checkEinsumDimSizes$1(e,t,n){const r=new Array(e);for(let e=0;e<n.length;++e){const a=n[e].shape;for(let n=0;n<t[e].length;++n)void 0===r[t[e][n]]?r[t[e][n]]=a[n]:assert$6(r[t[e][n]]===a[n],()=>`Expected dimension ${r[t[e][n]]} at axis ${n} of input shaped ${JSON.stringify(a)}, but got dimension ${a[n]}`)}}function getEinsumComputePath$1(e,t){const n=e,r=[];let a=0;0===e.length&&n.push(-1),a=e.length+1;for(let e=0;e<a;++e)r.push([]);const s=[];for(let e=0;e<n.length;++e){const a=findTermsWithDim$1(t,n[e]);for(const t of a)-1===s.indexOf(t)&&(r[e].push(t),s.push(t))}return{path:n,steps:r}}function isIdentityPermutation$1(e){return e.every((e,t)=>e===t)}function findTermsWithDim$1(e,t){const n=[];for(let r=0;r<e.length;++r)0!==e[r].length&&-1===e[r].indexOf(t)&&-1!==t||n.push(r);return n}function prepareSplitSize$1(e,t,n=0){let r=[];if("number"==typeof t)assert$6(e.shape[n]%t==0,()=>"Number of splits must evenly divide the axis."),r=new Array(t).fill(e.shape[n]/t);else{assert$6(t.reduce((e,t)=>(-1===t&&(e+=1),e),0)<=1,()=>"There should be only one negative value in split array.");const a=t.indexOf(-1);if(-1!==a){const r=t.reduce((e,t)=>t>0?e+t:e);t[a]=e.shape[n]-r}assert$6(e.shape[n]===t.reduce((e,t)=>e+t),()=>"The sum of sizes must match the size of the axis dimension."),r=t}return r}function segOpComputeOptimalWindowSize$1(e,t){let n,r=!1;for(e<=PARALLELIZE_THRESHOLD$1?(n=e,r=!0):n=nearestDivisor$1(e,Math.floor(Math.sqrt(e)));!r;)n>t||n===e?r=!0:n=nearestDivisor$1(e,n+1);return n}function computeOutShape$3(e,t,n){const r=[],a=e.length;for(let s=0;s<a;s++)r.push(s!==t?e[s]:n);return r}function collectGatherOpShapeInfo$1(e,t,n,r){const a=t.shape.length,s=e.shape.length;if(0!==r&&(r<-a||r>a))throw new Error(`Expect batchDims in the range of [-${a}, ${a}], but got ${r}`);if(r<0&&(r+=a),r>s)throw new Error(`batchDims (${r}) must be less than rank(x) (\n    ${s}).`);if(n<r)throw new Error(`batchDims (${r}) must be less than or equal to axis (${n}).`);for(let n=0;n<r;++n)if(e.shape[n]!==t.shape[n])throw new Error(`x.shape[${n}]: ${e.shape[n]} should be equal to indices.shape[${n}]: ${t.shape[n]}.`);const o=e.shape[n],i=[];let l=1,u=1,c=1;for(let t=0;t<r;++t)i.push(e.shape[t]),l*=e.shape[t];for(let t=r;t<n;t++)i.push(e.shape[t]),u*=e.shape[t];for(let e=r;e<a;e++)i.push(t.shape[e]);for(let t=n+1;t<s;t++)i.push(e.shape[t]),c*=e.shape[t];return{batchSize:l,sliceSize:c,outerSize:u,dimSize:o,outputShape:i}}var segment_util$1={__proto__:null,segOpComputeOptimalWindowSize:segOpComputeOptimalWindowSize$1,computeOutShape:computeOutShape$3,collectGatherOpShapeInfo:collectGatherOpShapeInfo$1};function fromUint8ToStringArray$1(e){try{return e.map(e=>decodeString$1(e))}catch(e){throw new Error(`Failed to decode encoded string bytes into utf-8, error: ${e}`)}}function fromStringArrayToUint8$1(e){return e.map(e=>encodeString$1(e))}var backend_util$1={__proto__:null,slice_util:slice_util$1,segment_util:segment_util$1,fromUint8ToStringArray:fromUint8ToStringArray$1,fromStringArrayToUint8:fromStringArrayToUint8$1,upcastType:upcastType$1,axesAreInnerMostDims:axesAreInnerMostDims$1,combineLocations:combineLocations$1,computeOutAndReduceShapes:computeOutAndReduceShapes$1,expandShapeToKeepDim:expandShapeToKeepDim$1,assertAxesAreInnerMostDims:assertAxesAreInnerMostDims$1,getAxesPermutation:getAxesPermutation$1,getUndoAxesPermutation:getUndoAxesPermutation$1,getInnerMostAxes:getInnerMostAxes$1,getBroadcastDims:getBroadcastDims$3,getReductionAxes:getReductionAxes$1,assertAndGetBroadcastShape:assertAndGetBroadcastShape$1,assertParamsConsistent:assertParamsConsistent$1,computeOutShape:computeOutShape$4,computeDilation2DInfo:computeDilation2DInfo$1,computePool2DInfo:computePool2DInfo$1,computePool3DInfo:computePool3DInfo$1,computeConv2DInfo:computeConv2DInfo$1,computeConv3DInfo:computeConv3DInfo$1,computeDefaultPad:computeDefaultPad$1,tupleValuesAreOne:tupleValuesAreOne$1,eitherStridesOrDilationsAreOne:eitherStridesOrDilationsAreOne$1,convertConv2DDataFormat:convertConv2DDataFormat$1,getFusedDyActivation:getFusedDyActivation$1,getFusedBiasGradient:getFusedBiasGradient$1,applyActivation:applyActivation$3,shouldFuse:shouldFuse$1,PARALLELIZE_THRESHOLD:PARALLELIZE_THRESHOLD$1,computeOptimalWindowSize:computeOptimalWindowSize$1,getImageCenter:getImageCenter$1,getReshaped:getReshaped$1,getPermuted:getPermuted$1,getReshapedPermuted:getReshapedPermuted$1,getSliceBeginCoords:getSliceBeginCoords$1,getSliceSize:getSliceSize$1,prepareAndValidate:prepareAndValidate$1,validateUpdateShape:validateUpdateShape$1,validateInput:validateInput$2,calculateShapes:calculateShapes$1,SELU_SCALEALPHA:SELU_SCALEALPHA$1,SELU_SCALE:SELU_SCALE$1,ERF_P:ERF_P$1,ERF_A1:ERF_A1$1,ERF_A2:ERF_A2$1,ERF_A3:ERF_A3$1,ERF_A4:ERF_A4$1,ERF_A5:ERF_A5$1,warn:warn$1,log:log$6,mergeRealAndImagArrays:mergeRealAndImagArrays$1,splitRealAndImagArrays:splitRealAndImagArrays$1,complexWithEvenIndex:complexWithEvenIndex$1,complexWithOddIndex:complexWithOddIndex$1,getComplexWithIndex:getComplexWithIndex$1,assignToTypedArray:assignToTypedArray$1,exponents:exponents$1,exponent:exponent$1,decodeEinsumEquation:decodeEinsumEquation$1,getEinsumPermutation:getEinsumPermutation$1,checkEinsumDimSizes:checkEinsumDimSizes$1,getEinsumComputePath:getEinsumComputePath$1,isIdentityPermutation:isIdentityPermutation$1,prepareSplitSize:prepareSplitSize$1};const absGradConfig$1={kernelName:Abs$1,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>mul$1(e,step$5(cast$7(n,"float32"),-1))}}},acosGradConfig$1={kernelName:Acos$1,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>{const t=square$5(cast$7(n,"float32")),r=sqrt$5(sub$5(scalar$1(1),t));return neg$5(div$3(e,r))}}}},acoshGradConfig$1={kernelName:Acosh$1,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>{const t=sqrt$5(sub$5(square$5(cast$7(n,"float32")),1));return div$3(e,t)}}}},addGradConfig$1={kernelName:Add$3,inputsToSave:["a","b"],gradFunc:(e,t)=>{const[n,r]=t,a=assertAndGetBroadcastShape$1(n.shape,r.shape);return{a:()=>{let t=e;const r=getReductionAxes$1(n.shape,a);return r.length>0&&(t=sum$6(t,r)),reshape$6(t,n.shape)},b:()=>{let t=e;const n=getReductionAxes$1(r.shape,a);return n.length>0&&(t=sum$6(t,n)),reshape$6(t,r.shape)}}}},addNGradConfig$1={kernelName:AddN$1,saveAllInputs:!0,gradFunc:(e,t)=>{const n={};return t.forEach((t,r)=>{n[r]=()=>e.clone()}),n}},argMaxGradConfig$1={kernelName:ArgMax$1,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>zerosLike$5(n)}}},argMinGradConfig$1={kernelName:ArgMin$1,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>zerosLike$5(n)}}},asinGradConfig$1={kernelName:Asin$1,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>div$3(e,sqrt$5(sub$5(scalar$1(1),square$5(cast$7(n,"float32")))))}}},asinhGradConfig$1={kernelName:Asinh$1,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>{const t=sqrt$5(add$5(scalar$1(1),square$5(cast$7(n,"float32"))));return div$3(e,t)}}}},atan2GradConfig$1={kernelName:Atan2$1,inputsToSave:["a","b"],gradFunc:(e,t)=>{const[n,r]=t,a=assertAndGetBroadcastShape$1(n.shape,r.shape);return{a:()=>{const t=add$5(square$5(n),square$5(r));let s=mul$1(e,div$3(r,t));const o=getReductionAxes$1(n.shape,a);return o.length>0&&(s=sum$6(s,o)),reshape$6(s,n.shape)},b:()=>{const t=add$5(square$5(n),square$5(r));let s=neg$5(mul$1(e,div$3(n,t)));const o=getReductionAxes$1(r.shape,a);return o.length>0&&(s=sum$6(s,o)),reshape$6(s,r.shape)}}}},atanGradConfig$1={kernelName:Atan$1,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>div$3(e,add$5(square$5(cast$7(n,"float32")),1))}}},atanhGradConfig$1={kernelName:Atanh$1,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>div$3(e,sub$5(scalar$1(1),square$5(cast$7(n,"float32"))))}}};function avgPool3dGrad_$1(e,t,n,r,a,s){const o=convertToTensor$1(e,"dy","avgPool3dGrad"),i=convertToTensor$1(t,"input","avgPool3dGrad");let l=o,u=i,c=!1;4===i.rank&&(c=!0,l=reshape$6(o,[1,o.shape[0],o.shape[1],o.shape[2],o.shape[3]]),u=reshape$6(i,[1,i.shape[0],i.shape[1],i.shape[2],i.shape[3]])),assert$6(5===l.rank,()=>`Error in avgPool3dGrad: dy must be rank 5 but got rank ${l.rank}.`),assert$6(5===u.rank,()=>`Error in avgPool3dGrad: input must be rank 5 but got rank ${u.rank}.`),null!=s&&assert$6(isInt$1(a),()=>`Error in avgPool3dGrad: pad must be an integer when using, dimRoundingMode ${s} but got pad ${a}.`);const p=ENGINE$1.runKernel(AvgPool3DGrad$1,{dy:l,input:u},{filterSize:n,strides:r,pad:a,dimRoundingMode:s});return c?reshape$6(p,[p.shape[1],p.shape[2],p.shape[3],p.shape[4]]):p}const avgPool3dGrad$1=op$1({avgPool3dGrad_:avgPool3dGrad_$1}),avgPool3DGradConfig$3={kernelName:AvgPool3D$1,inputsToSave:["x"],gradFunc:(e,t,n)=>{const[r]=t,{filterSize:a,strides:s,pad:o,dimRoundingMode:i}=n;return{x:()=>avgPool3dGrad$1(e,r,a,s,o,i)}}};function avgPoolGrad_$1(e,t,n,r,a){const s=convertToTensor$1(e,"dy","avgPoolGrad"),o=convertToTensor$1(t,"input","avgPoolGrad");assert$6(o.rank===s.rank,()=>`Rank of input (${o.rank}) does not match rank of dy (${s.rank})`);let i=o,l=s,u=!1;3===o.rank&&(u=!0,i=reshape$6(o,[1,o.shape[0],o.shape[1],o.shape[2]]),l=reshape$6(s,[1,s.shape[0],s.shape[1],s.shape[2]])),assert$6(4===l.rank,()=>`Error in avgPoolGrad: dy must be rank 4 but got rank ${l.rank}.`),assert$6(4===i.rank,()=>`Error in avgPoolGrad: input must be rank 4 but got rank ${i.rank}.`);const c=ENGINE$1.runKernel(AvgPoolGrad$1,{dy:l,input:i},{filterSize:n,strides:r,pad:a});return u?reshape$6(c,[c.shape[1],c.shape[2],c.shape[3]]):c}const avgPoolGrad$5=op$1({avgPoolGrad_:avgPoolGrad_$1}),avgPoolGradConfig$5={kernelName:AvgPool$1,inputsToSave:["x"],gradFunc:(e,t,n)=>{const[r]=t,{filterSize:a,strides:s,pad:o}=n;return{x:()=>avgPoolGrad$5(e,r,a,s,o)}}},batchMatMulGradConfig$1={kernelName:BatchMatMul$1,inputsToSave:["a","b"],gradFunc:(e,t,n)=>{const[r,a]=t,{transposeA:s,transposeB:o}=n;return s||o?!s&&o?{a:()=>matMul$3(e,a,!1,!1),b:()=>matMul$3(e,r,!0,!1)}:s&&!o?{a:()=>matMul$3(a,e,!1,!0),b:()=>matMul$3(r,e,!1,!1)}:{a:()=>matMul$3(a,e,!0,!0),b:()=>matMul$3(e,r,!0,!0)}:{a:()=>matMul$3(e,a,!1,!0),b:()=>matMul$3(r,e,!0,!1)}}},batchToSpaceNDGradConfig$1={kernelName:BatchToSpaceND$1,gradFunc:(e,t,n)=>{const{blockShape:r,crops:a}=n;return{x:()=>spaceToBatchND$5(e,r,a)}}},broadcastToGradConfig$1={kernelName:BroadcastTo$1,gradFunc:(e,t,n)=>{const r=n.inputShape,a=n.shape,s=Array.from(a);for(let e=r.length-1;e>=0;e--)if(r[e]===a[e])s[e]=1;else if(1!==r[e])throw new Error(`broadcastTo(): [${r}] cannot be broadcast to [${a}].`);const o=[];for(let e=0;e<s.length;e++)s[e]>1&&o.push(e);return{x:()=>sum$6(e,o,!0)}}},castGradConfig$1={kernelName:Cast$1,gradFunc:e=>({x:()=>e.clone()})},ceilGradConfig$1={kernelName:Ceil$1,gradFunc:e=>({x:()=>zerosLike$5(e)})},clipByValueGradConfig$1={kernelName:ClipByValue$1,inputsToSave:["x"],gradFunc:(e,t,n)=>{const[r]=t,{clipValueMin:a,clipValueMax:s}=n;return{x:()=>where$1(logicalAnd$5(greaterEqual$5(r,a),lessEqual$5(r,s)),e,zerosLike$5(e))}}},complexAbsGradConfig$1={kernelName:ComplexAbs$1,inputsToSave:["x"],gradFunc:absGradConfig$1.gradFunc},concatGradConfig$1={kernelName:Concat$1,saveAllInputs:!0,gradFunc:(e,t,n)=>{const r=t.map(e=>e.shape),{axis:a}=n,s=parseAxisParam$1(a,t[0].shape)[0],o=r.map(e=>e[s]);return split$4(e,o,s).map(e=>()=>e)}},conv2DGradConfig$1={kernelName:Conv2D$3,inputsToSave:["x","filter"],gradFunc:(e,t,n)=>{const[r,a]=t,{dilations:s,strides:o,pad:i,dataFormat:l}=n;return assert$6(tupleValuesAreOne$1(s),()=>`Error in gradient of conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${s}'`),{x:()=>conv2DBackpropInput$5(r.shape,e,a,o,i,l),filter:()=>conv2DBackpropFilter$5(r,e,a.shape,o,i,l)}}},conv2DBackpropInputGradConfig$1={kernelName:Conv2DBackpropInput$1,inputsToSave:["dy","filter"],gradFunc:(e,t,n)=>{const[r,a]=t,{strides:s,pad:o,dataFormat:i,dimRoundingMode:l}=n;return{dy:()=>conv2d$7(e,a,s,o,i,1,l),filter:()=>conv2DBackpropFilter$5(e,r,a.shape,s,o,i,l)}}};function conv3DBackpropFilter_$1(e,t,n,r,a){let s=e;4===e.rank&&(s=reshape$6(e,[1,e.shape[0],e.shape[1],e.shape[2],e.shape[3]]));let o=t;return 4===o.rank&&(o=reshape$6(t,[1,t.shape[0],t.shape[1],t.shape[2],t.shape[3]])),assert$6(5===s.rank,()=>`Error in conv3dDerFilter: input must be rank 5, but got shape ${s.shape}.`),assert$6(5===o.rank,()=>`Error in conv3dDerFilter: dy must be rank 5, but got shape ${o.shape}.`),assert$6(5===n.length,()=>`Error in conv3dDerFilter: filterShape must be length 5, but got ${n}.`),assert$6(s.shape[4]===n[3],()=>`Error in conv3dDerFilter: depth of input ${s.shape[4]}) must match input depth in filter (${n[3]}.`),assert$6(o.shape[4]===n[4],()=>`Error in conv3dDerFilter: depth of dy (${o.shape[4]}) must match output depth for filter (${n[4]}).`),ENGINE$1.runKernel(Conv3DBackpropFilterV2$1,{x:s,dy:o},{strides:r,pad:a,filterShape:n})}const conv3DBackpropFilter$1=op$1({conv3DBackpropFilter_:conv3DBackpropFilter_$1}),conv3DGradConfig$1={kernelName:Conv3D$3,inputsToSave:["x","filter"],gradFunc:(e,t,n)=>{const{dilations:r,strides:a,pad:s}=n;assert$6(tupleValuesAreOne$1(r),()=>`Error in gradient of conv3D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${r}'`);const[o,i]=t;return{x:()=>conv3DBackpropInput$3(o.shape,e,i,a,s),filter:()=>conv3DBackpropFilter$1(o,e,i.shape,a,s)}}},cosGradConfig$1={kernelName:Cos$1,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>mul$1(neg$5(sin$5(cast$7(n,"float32"))),e)}}},coshGradConfig$1={kernelName:Cosh$1,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>mul$1(sinh$5(cast$7(n,"float32")),e)}}},cumsumGradConfig$1={kernelName:Cumsum$1,inputsToSave:["x"],gradFunc:(e,t,n)=>{const[r]=t,{axis:a,exclusive:s,reverse:o}=n;return{x:()=>{const t=getAxesPermutation$1([a],r.rank);let n=cumsum$5(e,a,s,!o);return null!=t&&(n=transpose$5(n,t)),n}}}},depthwiseConv2dNativeGradConfig$1={kernelName:DepthwiseConv2dNative$1,inputsToSave:["x","filter"],gradFunc:(e,t,n)=>{const{dilations:r,strides:a,pad:s,dimRoundingMode:o}=n,i=null==r?[1,1]:r;assert$6(tupleValuesAreOne$1(i),()=>`Error in gradient of depthwiseConv2dNative: dilation rates greater than 1 are not yet supported. Got dilations '${i}'`);const[l,u]=t;return assert$6(4===l.rank,()=>`Error in gradient of depthwiseConv2dNative: input must be rank 4, but got rank ${l.rank}.`),assert$6(4===u.rank,()=>`Error in gradient of depthwiseConv2dNative: filter must be rank 4, but got rank ${u.rank}.`),assert$6(l.shape[3]===u.shape[2],()=>`Error in gradient of depthwiseConv2d: number of input channels (${l.shape[3]}) must match the inChannels dimension in filter ${u.shape[2]}.`),assert$6(eitherStridesOrDilationsAreOne$1(a,i),()=>`Error in gradient of depthwiseConv2d: Either strides or dilations must be  1. Got strides ${a} and dilations '${i}'.`),null!=o&&assert$6(isInt$1(s),()=>`Error in depthwiseConv2d: pad must be an integer when using, dimRoundingMode ${o} but got pad ${s}.`),{x:()=>depthwiseConv2dNativeBackpropInput$5(l.shape,e,u,a,s,r,o),filter:()=>depthwiseConv2dNativeBackpropFilter$5(l,e,u.shape,a,s,r,o)}}},dilation2dGradConfig$1={kernelName:Dilation2D$1,inputsToSave:["x","filter"],gradFunc:(e,t,n)=>{const[r,a]=t,s={x:r,filter:a,dy:e},o={x:r,filter:a,dy:e};return{x:()=>ENGINE$1.runKernel(Dilation2DBackpropInput$1,s,n),filter:()=>ENGINE$1.runKernel(Dilation2DBackpropFilter$1,o,n)}}},eluGradConfig$5={kernelName:Elu$3,outputsToSave:[!0],gradFunc:(e,t)=>{const[n]=t,r={dy:e,y:n};return{x:()=>ENGINE$1.runKernel(EluGrad$1,r)}}},erfGradConfig$1={kernelName:Erf$1,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t,r=mul$1(exp$5(neg$5(square$5(n))),2/Math.sqrt(Math.PI));return{x:()=>mul$1(e,r)}}},expGradConfig$1={kernelName:Exp$1,outputsToSave:[!0],gradFunc:(e,t)=>{const[n]=t;return{x:()=>mul$1(e,n)}}},expandDimsGradConfig$1={kernelName:ExpandDims$1,inputsToSave:["input"],gradFunc:(e,t)=>{const[n]=t;return{input:()=>reshape$6(e,n.shape)}}},expm1GradConfig$1={kernelName:Expm1$1,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>mul$1(e,exp$5(n))}}},floorGradConfig$1={kernelName:Floor$1,gradFunc:e=>({x:()=>zerosLike$5(e)})},floorDivGradConfig$1={kernelName:FloorDiv$1,inputsToSave:["a","b"],gradFunc:(e,t)=>{const[n,r]=t,a=assertAndGetBroadcastShape$1(n.shape,r.shape);return{a:()=>{const t=div$3(e,cast$7(r,"float32")),s=getReductionAxes$1(n.shape,a);return s.length>0?reshape$6(sum$6(t,s),n.shape):t},b:()=>{let t=mul$1(e,cast$7(n,"float32"));const s=getReductionAxes$1(r.shape,a);s.length>0&&(t=reshape$6(sum$6(t,s),r.shape));const o=square$5(r);return neg$5(div$3(t,cast$7(o,"float32")))}}}},fusedBatchNormGradConfig$1={kernelName:FusedBatchNorm$1,inputsToSave:["x","mean","variance","scale"],gradFunc:(e,t,n)=>{const{varianceEpsilon:r}=n,[a,s,o,i]=t,l=null==i?scalar$1(1):i,u=getReductionAxes$1(s.shape,a.shape),c=[];if(1===s.rank){for(let e=0;e<a.shape.length-1;++e)c.push(a.shape[e]);c.push(1)}const p=sub$5(a,s),d=mul$1(e,l),h=rsqrt$5(add$5(o,scalar$1(r))),m=mul$1(mul$1(mul$1(h,h),h),scalar$1(-.5));return{x:()=>reshape$6(mul$1(mul$1(e,1===s.rank?tile$7(reshape$6(h,[1,1,1,s.shape[0]]),c):h),l),a.shape),mean:()=>{let e=mul$1(mul$1(h,scalar$1(-1)),d);return 1===s.rank&&(e=sum$6(e,u)),reshape$6(e,s.shape)},variance:()=>{let e=mul$1(mul$1(m,p),d);return 1===s.rank&&(e=sum$6(e,u)),reshape$6(e,s.shape)},scale:()=>{const t=mul$1(p,h);let n=mul$1(e,t);return 1===s.rank&&(n=sum$6(n,u)),reshape$6(n,s.shape)},offset:()=>{let t=e;return 1===s.rank&&(t=sum$6(t,u)),reshape$6(t,s.shape)}}}},gatherGradConfig$1={kernelName:GatherV2$1,inputsToSave:["x","indices"],gradFunc:(e,t,n)=>{const[r,a]=t,{axis:s}=n,o=parseAxisParam$1(s,r.shape)[0];return{x:()=>{const t=r.shape,n=a.size,i=t.slice(0,o),l=i.length,u=t.slice(s,t.length).slice(1),c=u.length,p=arrayRange$1(0,l),d=arrayRange$1(l+1,l+1+c),h=arrayConcat$1([i,[n],u]),m=reshape$6(e,h),f=reshape$6(a,[n]),g=arrayConcat$1([[l],p,d]),$=transpose$5(m,g);let y=unsortedSegmentSum$5($,f,r.shape[o]);const b=getUndoAxesPermutation$1(g);return y=transpose$5(y,b),y},indices:()=>a}}};function arrayRange$1(e,t){const n=[];for(let r=e;r<t;++r)n.push(r);return n}function arrayConcat$1(e){const t=[];for(let n=0;n<e.length;++n)for(let r=0;r<e[n].length;++r)t.push(e[n][r]);return t}const greaterEqualGradConfig$1={kernelName:GreaterEqual$1,inputsToSave:["a","b"],gradFunc:(e,t)=>{const[n,r]=t;return{a:()=>zerosLike$5(n),b:()=>zerosLike$5(r)}}},identityGradConfig$1={kernelName:Identity$3,gradFunc:e=>({x:()=>cast$7(e,"float32")})},isFiniteGradConfig$1={kernelName:IsFinite$1,gradFunc:e=>({x:()=>zerosLike$5(e)})},isInfGradConfig$1={kernelName:IsInf$1,gradFunc:e=>({x:()=>zerosLike$5(e)})},isNanGradConfig$1={kernelName:IsNan$1,gradFunc:e=>({x:()=>zerosLike$5(e)})},leakyReluGradConfig$1={kernelName:LeakyRelu$1,inputsToSave:["x"],gradFunc:(e,t,n)=>{const[r]=t,{alpha:a}=n,s=greater$6(r,0);return{x:()=>where$1(s,e,mul$1(e,a))}}},log1pGradConfig$1={kernelName:Log1p$1,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>div$3(e,add$5(n,1))}}},logGradConfig$1={kernelName:Log$1,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>div$3(e,cast$7(n,"float32"))}}},logSoftmaxGradConfig$1={kernelName:LogSoftmax$3,inputsToSave:[],outputsToSave:[!0],gradFunc:(e,t,n)=>{const[r]=t,{axis:a}=n;return{logits:()=>{const t=exp$5(r);return sub$5(e,mul$1(sum$6(e,a,!0),t))}}}};function localResponseNormalizationBackprop_$1(e,t,n,r=5,a=1,s=1,o=.5){return ENGINE$1.runKernel(LRNGrad$1,{x:e,y:t,dy:n},{depthRadius:r,bias:a,alpha:s,beta:o})}const localResponseNormalizationBackprop$1=op$1({localResponseNormalizationBackprop_:localResponseNormalizationBackprop_$1}),lrnGradConfig$1={kernelName:LRN$1,inputsToSave:["x"],outputsToSave:[!0],gradFunc:(e,t,n)=>{const[r,a]=t,{depthRadius:s,bias:o,alpha:i,beta:l}=n;return{x:()=>localResponseNormalizationBackprop$1(r,a,e,s,o,i,l)}}};function gradForMinAndMax$1(e,t,n,r){return t.rank<n.rank&&(t=reshape$6(t,expandShapeToKeepDim$1(t.shape,r))),e.rank<n.rank&&(e=reshape$6(e,expandShapeToKeepDim$1(e.shape,r))),{x:()=>mul$1(e,cast$7(equal$5(n,t),e.dtype))}}const maxGradConfig$1={kernelName:Max$1,inputsToSave:["x"],outputsToSave:[!0],gradFunc:(e,t,n)=>{const r=n,{reductionIndices:a}=r,s=t[0],o=gradForMinAndMax$1(e,t[1],s,parseAxisParam$1(a,s.shape));return{x:()=>o.x()}}},maximumGradConfig$1={kernelName:Maximum$3,inputsToSave:["a","b"],gradFunc:(e,t)=>{const[n,r]=t;return{a:()=>mul$1(e,cast$7(greaterEqual$5(n,r),"float32")),b:()=>mul$1(e,cast$7(less$6(n,r),"float32"))}}};function maxPool3dGrad_$1(e,t,n,r,a,s,o){const i=convertToTensor$1(e,"dy","maxPool3dGrad"),l=convertToTensor$1(t,"input","maxPool3dGrad"),u=convertToTensor$1(n,"output","maxPool3dGrad");let c=i,p=l,d=u,h=!1;4===l.rank&&(h=!0,c=reshape$6(i,[1,i.shape[0],i.shape[1],i.shape[2],i.shape[3]]),p=reshape$6(l,[1,l.shape[0],l.shape[1],l.shape[2],l.shape[3]]),d=reshape$6(u,[1,u.shape[0],u.shape[1],u.shape[2],u.shape[3]])),assert$6(5===c.rank,()=>`Error in maxPool3dGrad: dy must be rank 5 but got rank ${c.rank}.`),assert$6(5===p.rank,()=>`Error in maxPool3dGrad: input must be rank 5 but got rank ${p.rank}.`),assert$6(5===d.rank,()=>`Error in maxPool3dGrad: output must be rank 5 but got rank ${d.rank}.`),null!=o&&assert$6(isInt$1(s),()=>`Error in maxPool3dGrad: pad must be an integer when using, dimRoundingMode ${o} but got pad ${s}.`);const m=ENGINE$1.runKernel(MaxPool3DGrad$1,{dy:c,input:p,output:d},{filterSize:r,strides:a,pad:s,dimRoundingMode:o});return h?reshape$6(m,[m.shape[1],m.shape[2],m.shape[3],m.shape[4]]):m}const maxPool3dGrad$1=op$1({maxPool3dGrad_:maxPool3dGrad_$1}),maxPool3DGradConfig$3={kernelName:MaxPool3D$1,inputsToSave:["x"],outputsToSave:[!0],gradFunc:(e,t,n)=>{const[r,a]=t,{filterSize:s,strides:o,pad:i,dimRoundingMode:l}=n;return{x:()=>maxPool3dGrad$1(e,r,a,s,o,i,l)}}};function maxPoolGrad_$1(e,t,n,r,a,s,o){const i=convertToTensor$1(e,"dy","maxPoolGrad"),l=convertToTensor$1(t,"input","maxPoolGrad"),u=convertToTensor$1(n,"output","maxPoolGrad");return assert$6(l.rank===i.rank,()=>`Rank of input (${l.rank}) does not match rank of dy (${i.rank})`),assert$6(4===i.rank,()=>`Error in maxPoolGrad: dy must be rank 4 but got rank ${i.rank}.`),assert$6(4===l.rank,()=>`Error in maxPoolGrad: input must be rank 4 but got rank ${l.rank}.`),null!=o&&assert$6(isInt$1(s),()=>`Error in maxPoolGrad: pad must be an integer when using, dimRoundingMode ${o} but got pad ${s}.`),ENGINE$1.runKernel(MaxPoolGrad$1,{dy:i,input:l,output:u},{filterSize:r,strides:a,pad:s,dimRoundingMode:o})}const maxPoolGrad$5=op$1({maxPoolGrad_:maxPoolGrad_$1}),maxPoolGradConfig$5={kernelName:MaxPool$1,inputsToSave:["x"],outputsToSave:[!0],gradFunc:(e,t,n)=>{const[r,a]=t,{filterSize:s,strides:o,pad:i}=n;return{x:()=>maxPoolGrad$5(e,r,a,s,o,i)}}},meanGradConfig$1={kernelName:Mean$1,inputsToSave:["x"],gradFunc:(e,t,n)=>{const[r]=t,{axis:a}=n,s=parseAxisParam$1(a,r.shape),o=sizeFromShape$1(computeOutAndReduceShapes$1(r.shape,s)[1]);return{x:()=>{const t=r.shape.slice();s.forEach(e=>{t[e]=1});const n=reshape$6(e,t);return div$3(mul$1(n,ones$3(r.shape,"float32")),o)}}}},minGradConfig$1={kernelName:Min$1,inputsToSave:["x"],outputsToSave:[!0],gradFunc:(e,t,n)=>{const r=n,{axis:a}=r,[s,o]=t,i=gradForMinAndMax$1(e,o,s,parseAxisParam$1(a,s.shape));return{x:()=>i.x()}}},minimumGradConfig$1={kernelName:Minimum$3,inputsToSave:["a","b"],gradFunc:(e,t)=>{const[n,r]=t;return{a:()=>mul$1(e,cast$7(lessEqual$5(n,r),"float32")),b:()=>mul$1(e,cast$7(greater$6(n,r),"float32"))}}},mirrorPadGradConfig$1={kernelName:MirrorPad$1,inputsToSave:["x"],gradFunc:(e,t,n)=>{const r=t[0],{paddings:a}=n,s=a.map(e=>e[0]);return{x:()=>slice$5(e,s,r.shape)}}},modGradConfig$1={kernelName:Mod$1,inputsToSave:["a","b"],gradFunc:(e,t)=>{const[n,r]=t,a=assertAndGetBroadcastShape$1(n.shape,r.shape);return{a:()=>{const t=getReductionAxes$1(n.shape,a);return t.length>0?reshape$6(sum$6(e,t),n.shape):e},b:()=>{const t=mul$1(e,neg$5(floor$5(div$3(n,r)))),s=getReductionAxes$1(r.shape,a);return s.length>0?reshape$6(sum$6(t,s),r.shape):t}}}},multiplyGradConfig$1={kernelName:Multiply$3,inputsToSave:["a","b"],gradFunc:(e,t)=>{const[n,r]=t,a=assertAndGetBroadcastShape$1(n.shape,r.shape);return{a:()=>{const t=mul$1(e,cast$7(r,"float32")),s=getReductionAxes$1(n.shape,a);return s.length>0?reshape$6(sum$6(t,s),n.shape):t},b:()=>{const t=mul$1(e,cast$7(n,"float32")),s=getReductionAxes$1(r.shape,a);return s.length>0?reshape$6(sum$6(t,s),r.shape):t}}}},negGradConfig$1={kernelName:Neg$1,gradFunc:e=>({x:()=>neg$5(e)})},oneHotGradConfig$1={kernelName:OneHot$1,inputsToSave:["indices"],gradFunc:(e,t)=>{const n=t[0];return{indices:()=>zeros$4(n.shape,"float32")}}},onesLikeGradConfig$1={kernelName:OnesLike$1,gradFunc:e=>({x:()=>zerosLike$5(e)})},packGradConfig$1={kernelName:Pack$1,saveAllInputs:!0,gradFunc:(e,t,n)=>{const{axis:r}=n;return unstack$1(e,r).map(e=>()=>e)}},padV2GradConfig$1={kernelName:PadV2$1,inputsToSave:["x"],gradFunc:(e,t,n)=>{const r=t[0],{paddings:a}=n,s=a.map(e=>e[0]);return{x:()=>slice$5(e,s,r.shape)}}},powGradConfig$1={kernelName:Pow$1,inputsToSave:["a","b"],outputsToSave:[!0],gradFunc:(e,t)=>{const[n,r,a]=t,s=n,o=r,i=assertAndGetBroadcastShape$1(s.shape,o.shape);return{a:()=>{const t=cast$7(o,"float32");let n=mul$1(e,mul$1(t,pow$5(s,sub$5(t,scalar$1(1)))));const r=getReductionAxes$1(s.shape,i);return r.length>0&&(n=sum$6(n,r)),reshape$6(n,s.shape)},b:()=>{const t=greater$6(s,0),n=where$1(t,log$7(s),zerosLike$5(s));let r=mul$1(e,mul$1(a,n));const l=getReductionAxes$1(o.shape,i);return l.length>0&&(r=sum$6(r,l)),reshape$6(r,o.shape)}}}},preluGradConfig$1={kernelName:Prelu$1,inputsToSave:["x","alpha"],gradFunc:(e,t)=>{const[n,r]=t,a=greater$6(n,0);return{x:()=>where$1(a,e,mul$1(e,r)),alpha:()=>{let t=where$1(a,zerosLike$5(e),mul$1(e,n));const s=getReductionAxes$1(r.shape,e.shape);return s.length>0&&(t=sum$6(t,s)),reshape$6(t,r.shape)}}}},divGradConfig$1={kernelName:RealDiv$1,inputsToSave:["a","b"],gradFunc:(e,t)=>{const[n,r]=t,a=assertAndGetBroadcastShape$1(n.shape,r.shape);return{a:()=>{const t=div$3(e,cast$7(r,"float32")),s=getReductionAxes$1(n.shape,a);return s.length>0?reshape$6(sum$6(t,s),n.shape):t},b:()=>{let t=mul$1(e,cast$7(n,"float32"));const s=getReductionAxes$1(r.shape,a);s.length>0&&(t=reshape$6(sum$6(t,s),r.shape));const o=square$5(r);return neg$5(div$3(t,cast$7(o,"float32")))}}}},reciprocalGradConfig$1={kernelName:Reciprocal$1,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>div$3(e,neg$5(square$5(n)))}}},relu6GradConfig$1={kernelName:Relu6$3,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t,r=mul$1(lessEqual$5(n,6),step$5(n));return{x:()=>mul$1(e,cast$7(r,"float32"))}}},reluGradConfig$1={kernelName:Relu$3,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>mul$1(e,cast$7(step$5(n),"float32"))}}},reshapeGradConfig$1={kernelName:Reshape$3,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>reshape$6(e,n.shape)}}},resizeBilinearGradConfig$5={kernelName:ResizeBilinear$1,inputsToSave:["images"],gradFunc:(e,t,n)=>{const[r]=t,a={dy:e,images:r};return{images:()=>ENGINE$1.runKernel(ResizeBilinearGrad$1,a,n)}}},resizeNearestNeighborGradConfig$5={kernelName:ResizeNearestNeighbor$1,inputsToSave:["images"],gradFunc:(e,t,n)=>{const[r]=t,a={dy:e,images:r};return{images:()=>ENGINE$1.runKernel(ResizeNearestNeighborGrad$1,a,n)}}},reverseGradConfig$1={kernelName:Reverse$1,gradFunc:(e,t,n)=>{const{dims:r}=n,a=parseAxisParam$1(r,e.shape);return{x:()=>reverse$5(e,a)}}},roundGradConfig$1={kernelName:Round$1,gradFunc:e=>({x:()=>zerosLike$5(e)})},rsqrtGradConfig$1={kernelName:Rsqrt$1,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>neg$5(div$3(e,mul$1(pow$5(n,1.5),2)))}}},selectGradConfig$1={kernelName:Select$1,inputsToSave:["condition"],gradFunc:(e,t)=>{const[n]=t;return{condition:()=>cast$7(zerosLike$5(n),"float32"),t:()=>mul$1(e,cast$7(n,e.dtype)),e:()=>mul$1(e,cast$7(logicalNot$5(n),e.dtype))}}},seluGradConfig$1={kernelName:Selu$3,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>{const t=greater$6(n,scalar$1(0)),r=scalar$1(SELU_SCALEALPHA$1),a=scalar$1(SELU_SCALE$1),s=mul$1(e,a),o=mul$1(mul$1(e,r),exp$5(cast$7(n,"float32")));return where$1(t,s,o)}}}},sigmoidGradConfig$1={kernelName:Sigmoid$3,outputsToSave:[!0],gradFunc:(e,t)=>{const[n]=t;return{x:()=>mul$1(e,mul$1(n,sub$5(scalar$1(1),n)))}}},signGradConfig$1={kernelName:Sign$1,gradFunc:e=>({x:()=>zerosLike$5(e)})},sinGradConfig$1={kernelName:Sin$1,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>mul$1(cos$5(cast$7(n,"float32")),e)}}},sinhGradConfig$1={kernelName:Sinh$1,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>mul$1(cosh$5(cast$7(n,"float32")),e)}}},sliceGradConfig$1={kernelName:Slice$1,inputsToSave:["x"],gradFunc:(e,t,n)=>{const[r]=t,{begin:a,size:s}=n,o=r.shape,[i,l]=parseSliceParams$1(r,a,s),u=[];for(let t=0;t<e.rank;t++)u.push([i[t],o[t]-i[t]-l[t]]);return{x:()=>pad$1(e,u)}}},softmaxGradConfig$1={kernelName:Softmax$5,outputsToSave:[!0],gradFunc:(e,t,n)=>{const[r]=t,{dim:a}=n,s=mul$1(e,r);return{logits:()=>sub$5(s,mul$1(sum$6(s,[a],!0),r))}}},softplusGradConfig$1={kernelName:Softplus$3,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>mul$1(e,sigmoid$5(n))}}},spaceToBatchNDGradConfig$1={kernelName:SpaceToBatchND$1,gradFunc:(e,t,n)=>{const{blockShape:r,paddings:a}=n;return{x:()=>batchToSpaceND$5(e,r,a)}}},splitVGradConfig$1={kernelName:SplitV$1,gradFunc:(e,t,n)=>{const{axis:r}=n;return{x:()=>concat$5(e,r)}}},sqrtGradConfig$1={kernelName:Sqrt$1,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>div$3(e,mul$1(sqrt$5(cast$7(n,"float32")),2))}}},squareGradConfig$1={kernelName:Square$1,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>mul$1(e,mul$1(cast$7(n,"float32"),2))}}},squaredDifferenceGradConfig$1={kernelName:SquaredDifference$1,inputsToSave:["a","b"],gradFunc:(e,t)=>{const[n,r]=t,a=scalar$1(2);return{a:()=>mul$1(e,mul$1(a,sub$5(n,r))),b:()=>mul$1(e,mul$1(a,sub$5(r,n)))}}},stepGradConfig$1={kernelName:Step$1,gradFunc:e=>({x:()=>zerosLike$5(e)})},subGradConfig$1={kernelName:Sub$1,inputsToSave:["a","b"],gradFunc:(e,t)=>{const[n,r]=t,a=assertAndGetBroadcastShape$1(n.shape,r.shape);return{a:()=>{let t=e;const r=getReductionAxes$1(n.shape,a);return r.length>0&&(t=sum$6(t,r)),reshape$6(t,n.shape)},b:()=>{let t=e;const n=getReductionAxes$1(r.shape,a);return n.length>0&&(t=sum$6(t,n)),reshape$6(neg$5(t),r.shape)}}}},sumGradConfig$1={kernelName:Sum$1,inputsToSave:["x"],gradFunc:(e,t,n)=>{const[r]=t,a=r.shape.slice(),{axis:s}=n;parseAxisParam$1(s,r.shape).forEach(e=>{a[e]=1});const o=reshape$6(e,a),i=mul$1(o,ones$3(r.shape,"float32"));return{x:()=>i}}},tanGradConfig$1={kernelName:Tan$1,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>div$3(e,square$5(cos$5(n)))}}},tanhGradConfig$1={kernelName:Tanh$3,outputsToSave:[!0],gradFunc:(e,t)=>{const[n]=t;return{x:()=>mul$1(sub$5(scalar$1(1),square$5(n)),e)}}},tileGradConfig$1={kernelName:Tile$1,inputsToSave:["x"],gradFunc:(e,t,n)=>{const[r]=t,{reps:a}=n;return{x:()=>{let t=zerosLike$5(r);if(1===r.rank)for(let n=0;n<a[0];++n)t=add$5(t,slice$5(e,[n*r.shape[0]],[r.shape[0]]));else if(2===r.rank)for(let n=0;n<a[0];++n)for(let s=0;s<a[1];++s)t=add$5(t,slice$5(e,[n*r.shape[0],s*r.shape[1]],[r.shape[0],r.shape[1]]));else if(3===r.rank)for(let n=0;n<a[0];++n)for(let s=0;s<a[1];++s)for(let o=0;o<a[2];++o)t=add$5(t,slice$5(e,[n*r.shape[0],s*r.shape[1],o*r.shape[2]],[r.shape[0],r.shape[1],r.shape[2]]));else{if(4!==r.rank)throw new Error(`Gradient for tile operation is not implemented for rank-${r.rank} tensors yet.`);for(let n=0;n<a[0];++n)for(let s=0;s<a[1];++s)for(let o=0;o<a[2];++o)for(let i=0;i<a[3];++i)t=add$5(t,slice$5(e,[n*r.shape[0],s*r.shape[1],o*r.shape[2],i*r.shape[3]],[r.shape[0],r.shape[1],r.shape[2],r.shape[3]]))}return t}}}},transposeGradConfig$1={kernelName:Transpose$1,gradFunc:(e,t,n)=>{const r=n,{perm:a}=r,s=getUndoAxesPermutation$1(a);return{x:()=>transpose$5(e,s)}}},unpackGradConfig$1={kernelName:Unpack$1,gradFunc:(e,t,n)=>{const r=n,{axis:a}=r;return{value:()=>stack$1(e,a)}}},unsortedSegmentSumGradConfig$1={kernelName:UnsortedSegmentSum$1,inputsToSave:["segmentIds"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>gatherDropNegatives$1(e,n)}}};function gatherDropNegatives$1(e,t){const n=maximum$6(t,zerosLike$5(t)),r=gather$3(e,n);let a=greaterEqual$5(t,scalar$1(0,"int32"));const s=r.rank-a.rank;for(let e=0;e<s;++e)a=expandDims$7(a,e+1);a=logicalAnd$5(a,ones$3(r.shape,"bool"));const o=zerosLike$5(r);return where$1(a,r,o)}const zerosLikeGradConfig$1={kernelName:ZerosLike$1,gradFunc:e=>({x:()=>zerosLike$5(e)})},gradConfigs$1=[absGradConfig$1,acosGradConfig$1,acoshGradConfig$1,addGradConfig$1,addNGradConfig$1,argMaxGradConfig$1,argMinGradConfig$1,asinGradConfig$1,asinhGradConfig$1,atan2GradConfig$1,atanGradConfig$1,atanhGradConfig$1,avgPool3DGradConfig$3,avgPoolGradConfig$5,batchMatMulGradConfig$1,batchToSpaceNDGradConfig$1,broadcastToGradConfig$1,castGradConfig$1,ceilGradConfig$1,clipByValueGradConfig$1,complexAbsGradConfig$1,concatGradConfig$1,conv2DBackpropInputGradConfig$1,conv2DGradConfig$1,conv3DGradConfig$1,cosGradConfig$1,coshGradConfig$1,cumsumGradConfig$1,depthwiseConv2dNativeGradConfig$1,dilation2dGradConfig$1,divGradConfig$1,eluGradConfig$5,erfGradConfig$1,expGradConfig$1,expandDimsGradConfig$1,expm1GradConfig$1,floorDivGradConfig$1,floorGradConfig$1,fusedBatchNormGradConfig$1,gatherGradConfig$1,greaterEqualGradConfig$1,identityGradConfig$1,isFiniteGradConfig$1,isInfGradConfig$1,isNanGradConfig$1,leakyReluGradConfig$1,log1pGradConfig$1,logGradConfig$1,logSoftmaxGradConfig$1,lrnGradConfig$1,maxGradConfig$1,maxGradConfig$1,maximumGradConfig$1,maxPool3DGradConfig$3,maxPoolGradConfig$5,meanGradConfig$1,minGradConfig$1,minimumGradConfig$1,mirrorPadGradConfig$1,modGradConfig$1,multiplyGradConfig$1,negGradConfig$1,oneHotGradConfig$1,onesLikeGradConfig$1,packGradConfig$1,padV2GradConfig$1,padV2GradConfig$1,powGradConfig$1,preluGradConfig$1,reciprocalGradConfig$1,relu6GradConfig$1,reluGradConfig$1,reshapeGradConfig$1,resizeBilinearGradConfig$5,resizeNearestNeighborGradConfig$5,reverseGradConfig$1,roundGradConfig$1,rsqrtGradConfig$1,selectGradConfig$1,seluGradConfig$1,sigmoidGradConfig$1,signGradConfig$1,sinGradConfig$1,sinhGradConfig$1,sliceGradConfig$1,softmaxGradConfig$1,softplusGradConfig$1,spaceToBatchNDGradConfig$1,spaceToBatchNDGradConfig$1,splitVGradConfig$1,splitVGradConfig$1,sqrtGradConfig$1,squaredDifferenceGradConfig$1,squareGradConfig$1,stepGradConfig$1,subGradConfig$1,sumGradConfig$1,tanGradConfig$1,tanhGradConfig$1,tileGradConfig$1,transposeGradConfig$1,unpackGradConfig$1,unsortedSegmentSumGradConfig$1,zerosLikeGradConfig$1];for(const e of gradConfigs$1)registerGradient$1(e);let _epsilon$1;function epsilon$3(){return null==_epsilon$1&&(_epsilon$1=backend$1().epsilon()),_epsilon$1}function imageDataFormat$1(){return"channelsLast"}getGlobalTensorClass$1().prototype.abs=function(){return this.throwIfDisposed(),abs$5(this)},getGlobalTensorClass$1().prototype.acos=function(){return this.throwIfDisposed(),acos$5(this)},getGlobalTensorClass$1().prototype.acosh=function(){return this.throwIfDisposed(),acosh$5(this)},getGlobalTensorClass$1().prototype.add=function(e){return this.throwIfDisposed(),add$5(this,e)},getGlobalTensorClass$1().prototype.all=function(e,t){return this.throwIfDisposed(),all$5(this,e,t)},getGlobalTensorClass$1().prototype.any=function(e,t){return this.throwIfDisposed(),any$5(this,e,t)},getGlobalTensorClass$1().prototype.argMax=function(e){return this.throwIfDisposed(),argMax$5(this,e)},getGlobalTensorClass$1().prototype.argMin=function(e){return this.throwIfDisposed(),argMin$5(this,e)},getGlobalTensorClass$1().prototype.asScalar=function(){return this.throwIfDisposed(),assert$6(1===this.size,()=>"The array must have only 1 element."),reshape$6(this,[])},getGlobalTensorClass$1().prototype.asType=function(e){return this.throwIfDisposed(),cast$7(this,e)},getGlobalTensorClass$1().prototype.as1D=function(){return this.throwIfDisposed(),reshape$6(this,[this.size])},getGlobalTensorClass$1().prototype.as2D=function(e,t){return this.throwIfDisposed(),reshape$6(this,[e,t])},getGlobalTensorClass$1().prototype.as3D=function(e,t,n){return this.throwIfDisposed(),reshape$6(this,[e,t,n])},getGlobalTensorClass$1().prototype.as4D=function(e,t,n,r){return this.throwIfDisposed(),reshape$6(this,[e,t,n,r])},getGlobalTensorClass$1().prototype.as5D=function(e,t,n,r,a){return this.throwIfDisposed(),reshape$6(this,[e,t,n,r,a])},getGlobalTensorClass$1().prototype.asin=function(){return this.throwIfDisposed(),asin$5(this)},getGlobalTensorClass$1().prototype.asinh=function(){return this.throwIfDisposed(),asinh$5(this)},getGlobalTensorClass$1().prototype.atan=function(){return this.throwIfDisposed(),atan$5(this)},getGlobalTensorClass$1().prototype.atan2=function(e){return this.throwIfDisposed(),atan2$5(this,e)},getGlobalTensorClass$1().prototype.atanh=function(){return this.throwIfDisposed(),atanh$5(this)},getGlobalTensorClass$1().prototype.avgPool=function(e,t,n,r){return this.throwIfDisposed(),avgPool$5(this,e,t,n,r)},getGlobalTensorClass$1().prototype.batchToSpaceND=function(e,t){return this.throwIfDisposed(),batchToSpaceND$5(this,e,t)},getGlobalTensorClass$1().prototype.batchNorm=function(e,t,n,r,a){return this.throwIfDisposed(),batchNorm$5(this,e,t,n,r,a)},getGlobalTensorClass$1().prototype.broadcastTo=function(e){return this.throwIfDisposed(),broadcastTo$1(this,e)},getGlobalTensorClass$1().prototype.cast=function(e){return this.throwIfDisposed(),cast$7(this,e)},getGlobalTensorClass$1().prototype.ceil=function(){return this.throwIfDisposed(),ceil$5(this)},getGlobalTensorClass$1().prototype.clipByValue=function(e,t){return this.throwIfDisposed(),clipByValue$3(this,e,t)},getGlobalTensorClass$1().prototype.concat=function(e,t){return this.throwIfDisposed(),e instanceof Tensor$1&&(e=[e]),concat$5([this,...e],t)},getGlobalTensorClass$1().prototype.conv1d=function(e,t,n,r,a,s){return this.throwIfDisposed(),conv1d$3(this,e,t,n,r,a,s)},getGlobalTensorClass$1().prototype.conv2dTranspose=function(e,t,n,r,a){return this.throwIfDisposed(),conv2dTranspose$2(this,e,t,n,r,a)},getGlobalTensorClass$1().prototype.conv2d=function(e,t,n,r,a,s){return this.throwIfDisposed(),conv2d$7(this,e,t,n,r,a,s)},getGlobalTensorClass$1().prototype.cos=function(){return this.throwIfDisposed(),cos$5(this)},getGlobalTensorClass$1().prototype.cosh=function(){return this.throwIfDisposed(),cosh$5(this)},getGlobalTensorClass$1().prototype.cumsum=function(e,t,n){return this.throwIfDisposed(),cumsum$5(this,e,t,n)},getGlobalTensorClass$1().prototype.depthToSpace=function(e,t){return this.throwIfDisposed(),depthToSpace$5(this,e,t)},getGlobalTensorClass$1().prototype.depthwiseConv2d=function(e,t,n,r,a,s){return this.throwIfDisposed(),depthwiseConv2d$5(this,e,t,n,r,a,s)},getGlobalTensorClass$1().prototype.dilation2d=function(e,t,n,r,a){return this.throwIfDisposed(),dilation2d$1(this,e,t,n,r,a)},getGlobalTensorClass$1().prototype.divNoNan=function(e){return this.throwIfDisposed(),divNoNan$1(this,e)},getGlobalTensorClass$1().prototype.div=function(e){return this.throwIfDisposed(),div$3(this,e)},getGlobalTensorClass$1().prototype.dot=function(e){return this.throwIfDisposed(),dot$4(this,e)},getGlobalTensorClass$1().prototype.elu=function(){return this.throwIfDisposed(),elu$8(this)},getGlobalTensorClass$1().prototype.equal=function(e){return this.throwIfDisposed(),equal$5(this,e)},getGlobalTensorClass$1().prototype.erf=function(){return this.throwIfDisposed(),erf$5(this)},getGlobalTensorClass$1().prototype.exp=function(){return this.throwIfDisposed(),exp$5(this)},getGlobalTensorClass$1().prototype.expandDims=function(e){return this.throwIfDisposed(),expandDims$7(this,e)},getGlobalTensorClass$1().prototype.expm1=function(){return this.throwIfDisposed(),expm1$5(this)},getGlobalTensorClass$1().prototype.fft=function(){return this.throwIfDisposed(),fft$5(this)},getGlobalTensorClass$1().prototype.flatten=function(){return this.throwIfDisposed(),reshape$6(this,[this.size])},getGlobalTensorClass$1().prototype.floor=function(){return this.throwIfDisposed(),floor$5(this)},getGlobalTensorClass$1().prototype.floorDiv=function(e){return this.throwIfDisposed(),floorDiv$5(this,e)},getGlobalTensorClass$1().prototype.gather=function(e,t){return this.throwIfDisposed(),gather$3(this,e,t)},getGlobalTensorClass$1().prototype.greaterEqual=function(e){return this.throwIfDisposed(),greaterEqual$5(this,e)},getGlobalTensorClass$1().prototype.greater=function(e){return this.throwIfDisposed(),greater$6(this,e)},getGlobalTensorClass$1().prototype.ifft=function(){return this.throwIfDisposed(),ifft$5(this)},getGlobalTensorClass$1().prototype.irfft=function(){return this.throwIfDisposed(),irfft$1(this)},getGlobalTensorClass$1().prototype.isFinite=function(){return this.throwIfDisposed(),isFinite$6(this)},getGlobalTensorClass$1().prototype.isInf=function(){return this.throwIfDisposed(),isInf$5(this)},getGlobalTensorClass$1().prototype.isNaN=function(){return this.throwIfDisposed(),isNaN$6(this)},getGlobalTensorClass$1().prototype.leakyRelu=function(e){return this.throwIfDisposed(),leakyRelu$5(this,e)},getGlobalTensorClass$1().prototype.lessEqual=function(e){return this.throwIfDisposed(),lessEqual$5(this,e)},getGlobalTensorClass$1().prototype.less=function(e){return this.throwIfDisposed(),less$6(this,e)},getGlobalTensorClass$1().prototype.localResponseNormalization=function(e,t,n,r){return this.throwIfDisposed(),localResponseNormalization$1(this,e,t,n,r)},getGlobalTensorClass$1().prototype.logSigmoid=function(){return this.throwIfDisposed(),logSigmoid$1(this)},getGlobalTensorClass$1().prototype.logSoftmax=function(e){return this.throwIfDisposed(),logSoftmax$1(this,e)},getGlobalTensorClass$1().prototype.logSumExp=function(e,t){return this.throwIfDisposed(),logSumExp$1(this,e,t)},getGlobalTensorClass$1().prototype.log=function(){return this.throwIfDisposed(),log$7(this)},getGlobalTensorClass$1().prototype.log1p=function(){return this.throwIfDisposed(),log1p$5(this)},getGlobalTensorClass$1().prototype.logicalAnd=function(e){return this.throwIfDisposed(),logicalAnd$5(this,e)},getGlobalTensorClass$1().prototype.logicalNot=function(){return this.throwIfDisposed(),logicalNot$5(this)},getGlobalTensorClass$1().prototype.logicalOr=function(e){return this.throwIfDisposed(),logicalOr$5(this,e)},getGlobalTensorClass$1().prototype.logicalXor=function(e){return this.throwIfDisposed(),logicalXor$1(this,e)},getGlobalTensorClass$1().prototype.matMul=function(e,t,n){return this.throwIfDisposed(),matMul$3(this,e,t,n)},getGlobalTensorClass$1().prototype.maxPool=function(e,t,n,r){return this.throwIfDisposed(),maxPool$5(this,e,t,n,r)},getGlobalTensorClass$1().prototype.max=function(e,t){return this.throwIfDisposed(),max$7(this,e,t)},getGlobalTensorClass$1().prototype.maximum=function(e){return this.throwIfDisposed(),maximum$6(this,e)},getGlobalTensorClass$1().prototype.mean=function(e,t){return this.throwIfDisposed(),mean$3(this,e,t)},getGlobalTensorClass$1().prototype.min=function(e,t){return this.throwIfDisposed(),min$7(this,e,t)},getGlobalTensorClass$1().prototype.minimum=function(e){return this.throwIfDisposed(),minimum$6(this,e)},getGlobalTensorClass$1().prototype.mirrorPad=function(e,t){return this.throwIfDisposed(),mirrorPad$3(this,e,t)},getGlobalTensorClass$1().prototype.mod=function(e){return this.throwIfDisposed(),mod$5(this,e)},getGlobalTensorClass$1().prototype.mul=function(e){return this.throwIfDisposed(),mul$1(this,e)},getGlobalTensorClass$1().prototype.neg=function(){return this.throwIfDisposed(),neg$5(this)},getGlobalTensorClass$1().prototype.norm=function(e,t,n){return this.throwIfDisposed(),norm$1(this,e,t,n)},getGlobalTensorClass$1().prototype.notEqual=function(e){return this.throwIfDisposed(),notEqual$5(this,e)},getGlobalTensorClass$1().prototype.oneHot=function(e,t=1,n=0){return this.throwIfDisposed(),oneHot$5(this,e,t,n)},getGlobalTensorClass$1().prototype.onesLike=function(){return this.throwIfDisposed(),onesLike$5(this)},getGlobalTensorClass$1().prototype.pad=function(e,t){return this.throwIfDisposed(),pad$1(this,e,t)},getGlobalTensorClass$1().prototype.pool=function(e,t,n,r,a){return this.throwIfDisposed(),pool$3(this,e,t,n,r,a)},getGlobalTensorClass$1().prototype.pow=function(e){return this.throwIfDisposed(),pow$5(this,e)},getGlobalTensorClass$1().prototype.prelu=function(e){return this.throwIfDisposed(),prelu$6(this,e)},getGlobalTensorClass$1().prototype.prod=function(e,t){return this.throwIfDisposed(),prod$5(this,e,t)},getGlobalTensorClass$1().prototype.reciprocal=function(){return this.throwIfDisposed(),reciprocal$5(this)},getGlobalTensorClass$1().prototype.relu=function(){return this.throwIfDisposed(),relu$6(this)},getGlobalTensorClass$1().prototype.relu6=function(){return this.throwIfDisposed(),relu6$5(this)},getGlobalTensorClass$1().prototype.reshapeAs=function(e){return this.throwIfDisposed(),reshape$6(this,e.shape)},getGlobalTensorClass$1().prototype.reshape=function(e){return this.throwIfDisposed(),reshape$6(this,e)},getGlobalTensorClass$1().prototype.resizeBilinear=function(e,t,n){return this.throwIfDisposed(),resizeBilinear$5(this,e,t,n)},getGlobalTensorClass$1().prototype.resizeNearestNeighbor=function(e,t,n){return this.throwIfDisposed(),resizeNearestNeighbor$5(this,e,t,n)},getGlobalTensorClass$1().prototype.reverse=function(e){return this.throwIfDisposed(),reverse$5(this,e)},getGlobalTensorClass$1().prototype.rfft=function(){return this.throwIfDisposed(),rfft$1(this)},getGlobalTensorClass$1().prototype.round=function(){return this.throwIfDisposed(),round$6(this)},getGlobalTensorClass$1().prototype.rsqrt=function(){return this.throwIfDisposed(),rsqrt$5(this)},getGlobalTensorClass$1().prototype.selu=function(){return this.throwIfDisposed(),selu$5(this)},getGlobalTensorClass$1().prototype.separableConv2d=function(e,t,n,r,a,s){return this.throwIfDisposed(),separableConv2d$2(this,e,t,n,r,a,s)},getGlobalTensorClass$1().prototype.sigmoid=function(){return this.throwIfDisposed(),sigmoid$5(this)},getGlobalTensorClass$1().prototype.sign=function(){return this.throwIfDisposed(),sign$5(this)},getGlobalTensorClass$1().prototype.sin=function(){return this.throwIfDisposed(),sin$5(this)},getGlobalTensorClass$1().prototype.sinh=function(){return this.throwIfDisposed(),sinh$5(this)},getGlobalTensorClass$1().prototype.slice=function(e,t){return this.throwIfDisposed(),slice$5(this,e,t)},getGlobalTensorClass$1().prototype.softmax=function(e){return this.throwIfDisposed(),softmax$6(this,e)},getGlobalTensorClass$1().prototype.softplus=function(){return this.throwIfDisposed(),softplus$5(this)},getGlobalTensorClass$1().prototype.spaceToBatchND=function(e,t){return this.throwIfDisposed(),spaceToBatchND$5(this,e,t)},getGlobalTensorClass$1().prototype.split=function(e,t){return this.throwIfDisposed(),split$4(this,e,t)},getGlobalTensorClass$1().prototype.sqrt=function(){return this.throwIfDisposed(),sqrt$5(this)},getGlobalTensorClass$1().prototype.square=function(){return this.throwIfDisposed(),square$5(this)},getGlobalTensorClass$1().prototype.squaredDifference=function(e){return this.throwIfDisposed(),squaredDifference$5(this,e)},getGlobalTensorClass$1().prototype.squeeze=function(e){return this.throwIfDisposed(),squeeze$1(this,e)},getGlobalTensorClass$1().prototype.stack=function(e,t){this.throwIfDisposed();const n=e instanceof Tensor$1?[this,e]:[this,...e];return stack$1(n,t)},getGlobalTensorClass$1().prototype.step=function(e){return this.throwIfDisposed(),step$5(this,e)},getGlobalTensorClass$1().prototype.stridedSlice=function(e,t,n,r,a,s,o,i){return this.throwIfDisposed(),stridedSlice$5(this,e,t,n,r,a,s,o,i)},getGlobalTensorClass$1().prototype.sub=function(e){return this.throwIfDisposed(),sub$5(this,e)},getGlobalTensorClass$1().prototype.sum=function(e,t){return this.throwIfDisposed(),sum$6(this,e,t)},getGlobalTensorClass$1().prototype.tan=function(){return this.throwIfDisposed(),tan$5(this)},getGlobalTensorClass$1().prototype.tanh=function(){return this.throwIfDisposed(),tanh$6(this)},getGlobalTensorClass$1().prototype.tile=function(e){return this.throwIfDisposed(),tile$7(this,e)},getGlobalTensorClass$1().prototype.toBool=function(){return this.throwIfDisposed(),cast$7(this,"bool")},getGlobalTensorClass$1().prototype.toFloat=function(){return this.throwIfDisposed(),cast$7(this,"float32")},getGlobalTensorClass$1().prototype.toInt=function(){return this.throwIfDisposed(),cast$7(this,"int32")},getGlobalTensorClass$1().prototype.topk=function(e,t){return this.throwIfDisposed(),topk$1(this,e,t)},getGlobalTensorClass$1().prototype.transpose=function(e){return this.throwIfDisposed(),transpose$5(this,e)},getGlobalTensorClass$1().prototype.unique=function(e){return this.throwIfDisposed(),unique$7(this,e)},getGlobalTensorClass$1().prototype.unsortedSegmentSum=function(e,t){return this.throwIfDisposed(),unsortedSegmentSum$5(this,e,t)},getGlobalTensorClass$1().prototype.unstack=function(e){return this.throwIfDisposed(),unstack$1(this,e)},getGlobalTensorClass$1().prototype.where=function(e,t){return this.throwIfDisposed(),where$1(e,this,t)},getGlobalTensorClass$1().prototype.zerosLike=function(){return this.throwIfDisposed(),zerosLike$5(this)};class AttributeError$1 extends Error{constructor(e){super(e),Object.setPrototypeOf(this,AttributeError$1.prototype)}}class RuntimeError$1 extends Error{constructor(e){super(e),Object.setPrototypeOf(this,RuntimeError$1.prototype)}}class ValueError$1 extends Error{constructor(e){super(e),Object.setPrototypeOf(this,ValueError$1.prototype)}}class NotImplementedError$1 extends Error{constructor(e){super(e),Object.setPrototypeOf(this,NotImplementedError$1.prototype)}}class AssertionError$1 extends Error{constructor(e){super(e),Object.setPrototypeOf(this,AssertionError$1.prototype)}}function pyListRepeat$1(e,t){if(Array.isArray(e)){let n=[];for(let r=0;r<t;r++)n=n.concat(e);return n}{const n=new Array(t);return n.fill(e),n}}function assert$5(e,t){if(!e)throw new AssertionError$1(t)}function count$1(e,t){let n=0;for(const r of e)r===t&&n++;return n}function singletonOrArray$1(e){return 1===e.length?e[0]:e}function toList$1(e){return Array.isArray(e)?e:[e]}function toSnakeCase$1(e){const t=e.replace(/(.)([A-Z][a-z0-9]+)/g,"$1_$2").replace(/([a-z])([A-Z])/g,"$1_$2").toLowerCase();return"_"!==t[0]?t:"private"+t}function toCamelCase$1(e){return e.length<=1||-1===e.indexOf("_")?e:e.replace(/[_]+(\w|$)/g,(e,t)=>t.toUpperCase())}let _GLOBAL_CUSTOM_OBJECTS$1={};function serializeKerasObject$1(e){if(null==e)return null;const t={};return t.className=e.getClassName(),t.config=e.getConfig(),t}function convertNDArrayScalarsInConfig$1(e){if(null!=e&&"object"==typeof e)if(Array.isArray(e))e.forEach(e=>convertNDArrayScalarsInConfig$1(e));else{const t=Object.keys(e);for(const n of t){const t=e[n];null!=t&&"object"==typeof t&&(Array.isArray(t)||"ndarray"!==t.type||"number"!=typeof t.value?convertNDArrayScalarsInConfig$1(t):e[n]=t.value)}}}function deserializeKerasObject$1(e,t={},n={},r="object",a=!1){if("string"==typeof e){const a=e;let s;if(a in n)s=n[a];else if(a in _GLOBAL_CUSTOM_OBJECTS$1)s=_GLOBAL_CUSTOM_OBJECTS$1[a];else if(s=t[a],null==s)throw new ValueError$1(`Unknown ${r}: ${e}. This may be due to one of the following reasons:\n1. The ${r} is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.\n2. The custom ${r} is defined in JavaScript, but is not registered properly with tf.serialization.registerClass().`);return s}{const s=e;if(null==s.className||null==s.config)throw new ValueError$1(`${r}: Improper config format: ${JSON.stringify(s)}.\n'className' and 'config' must set.`);const o=s.className;let i,l;if(o in n?[i,l]=n[o]:o in _GLOBAL_CUSTOM_OBJECTS$1?[i,l]=_GLOBAL_CUSTOM_OBJECTS$1.className:o in t&&([i,l]=t[o]),null==i)throw new ValueError$1(`Unknown ${r}: ${o}. This may be due to one of the following reasons:\n1. The ${r} is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.\n2. The custom ${r} is defined in JavaScript, but is not registered properly with tf.serialization.registerClass().`);if(null!=l){const e={};for(const t of Object.keys(_GLOBAL_CUSTOM_OBJECTS$1))e[t]=_GLOBAL_CUSTOM_OBJECTS$1[t];for(const t of Object.keys(n))e[t]=n[t];s.config.customObjects=e;const t=Object.assign({},_GLOBAL_CUSTOM_OBJECTS$1);for(const e of Object.keys(n))_GLOBAL_CUSTOM_OBJECTS$1[e]=n[e];convertNDArrayScalarsInConfig$1(s.config);const r=l(i,s.config,n,a);return _GLOBAL_CUSTOM_OBJECTS$1=Object.assign({},t),r}{const e=Object.assign({},_GLOBAL_CUSTOM_OBJECTS$1);for(const e of Object.keys(n))_GLOBAL_CUSTOM_OBJECTS$1[e]=n[e];const t=new i(s.config);return _GLOBAL_CUSTOM_OBJECTS$1=Object.assign({},e),t}}}function numberCompare$1(e,t){return e<t?-1:e>t?1:0}function reverseNumberCompare$1(e,t){return-1*numberCompare$1(e,t)}function unique$6(e){if(null==e)return e;const t=[];for(const n of e)-1===t.indexOf(n)&&t.push(n);return t}function isObjectEmpty$1(e){if(null==e)throw new ValueError$1(`Invalid value in obj: ${JSON.stringify(e)}`);for(const t in e)if(e.hasOwnProperty(t))return!1;return!0}function checkStringTypeUnionValue$1(e,t,n){if(null!=n&&e.indexOf(n)<0)throw new ValueError$1(`${n} is not a valid ${t}.  Valid values are ${e} or null/undefined.`)}function checkArrayTypeAndLength$1(e,t,n=0,r=Infinity){return assert$5(n>=0),assert$5(r>=n),Array.isArray(e)&&e.length>=n&&e.length<=r&&e.every(e=>typeof e===t)}function assertPositiveInteger$1(e,t){Array.isArray(e)?(assert$6(e.length>0,()=>`${t} is unexpectedly an empty array.`),e.forEach((e,n)=>assertPositiveInteger$1(e,`element ${n+1} of ${t}`))):assert$6(Number.isInteger(e)&&e>0,()=>`Expected ${t} to be a positive integer, but got ${formatAsFriendlyString$1(e)}.`)}function formatAsFriendlyString$1(e){return null===e?"null":Array.isArray(e)?"["+e.map(e=>formatAsFriendlyString$1(e)).join(",")+"]":"string"==typeof e?`"${e}"`:`${e}`}function debounce$1(e,t){let n,r=now$1();return(...a)=>{const s=now$1();return s-r<t||(r=s,n=e(...a)),n}}function mapActivationToFusedKernel$1(e){return"relu"===e?"relu":"linear"===e?"linear":"elu"===e?"elu":null}function calcL2Norms$1(e,t){return tidy$1(()=>sqrt$5(sum$6(mul$1(e,e),t,!0)))}class Constraint$1 extends Serializable$1{getConfig(){return{}}}class MaxNorm$1 extends Constraint$1{constructor(e){super(),this.defaultMaxValue=2,this.defaultAxis=0,this.maxValue=null!=e.maxValue?e.maxValue:this.defaultMaxValue,this.axis=null!=e.axis?e.axis:this.defaultAxis}apply(e){return tidy$1(()=>{const t=calcL2Norms$1(e,this.axis),n=clipByValue$3(t,0,this.maxValue);return mul$1(e,div$3(n,add$5(epsilon$3(),t)))})}getConfig(){return{maxValue:this.maxValue,axis:this.axis}}}MaxNorm$1.className="MaxNorm",registerClass$1(MaxNorm$1);class UnitNorm$1 extends Constraint$1{constructor(e){super(),this.defaultAxis=0,this.axis=null!=e.axis?e.axis:this.defaultAxis}apply(e){return tidy$1(()=>div$3(e,add$5(epsilon$3(),calcL2Norms$1(e,this.axis))))}getConfig(){return{axis:this.axis}}}UnitNorm$1.className="UnitNorm",registerClass$1(UnitNorm$1);class NonNeg$1 extends Constraint$1{apply(e){return relu$6(e)}}NonNeg$1.className="NonNeg",registerClass$1(NonNeg$1);class MinMaxNorm$1 extends Constraint$1{constructor(e){super(),this.defaultMinValue=0,this.defaultMaxValue=1,this.defaultRate=1,this.defaultAxis=0,this.minValue=null!=e.minValue?e.minValue:this.defaultMinValue,this.maxValue=null!=e.maxValue?e.maxValue:this.defaultMaxValue,this.rate=null!=e.rate?e.rate:this.defaultRate,this.axis=null!=e.axis?e.axis:this.defaultAxis}apply(e){return tidy$1(()=>{const t=calcL2Norms$1(e,this.axis),n=add$5(mul$1(this.rate,clipByValue$3(t,this.minValue,this.maxValue)),mul$1(1-this.rate,t));return mul$1(e,div$3(n,add$5(epsilon$3(),t)))})}getConfig(){return{minValue:this.minValue,maxValue:this.maxValue,rate:this.rate,axis:this.axis}}}MinMaxNorm$1.className="MinMaxNorm",registerClass$1(MinMaxNorm$1);const CONSTRAINT_IDENTIFIER_REGISTRY_SYMBOL_MAP$1={maxNorm:"MaxNorm",minMaxNorm:"MinMaxNorm",nonNeg:"NonNeg",unitNorm:"UnitNorm"};function serializeConstraint$1(e){return serializeKerasObject$1(e)}function deserializeConstraint$1(e,t={}){return deserializeKerasObject$1(e,SerializationMap$1.getMap().classNameMap,t,"constraint")}function getConstraint$1(e){return null==e?null:"string"==typeof e?deserializeConstraint$1({className:e in CONSTRAINT_IDENTIFIER_REGISTRY_SYMBOL_MAP$1?CONSTRAINT_IDENTIFIER_REGISTRY_SYMBOL_MAP$1[e]:e,config:{}}):e instanceof Constraint$1?e:deserializeConstraint$1(e)}const VALID_DATA_FORMAT_VALUES$1=["channelsFirst","channelsLast"],VALID_INTERPOLATION_FORMAT_VALUES$1=["nearest","bilinear"],VALID_PADDING_MODE_VALUES$1=["valid","same","causal"],VALID_POOL_MODE_VALUES$1=["max","avg"],VALID_BIDIRECTIONAL_MERGE_MODES$1=["sum","mul","concat","ave"],nameMap$1=new Map;function checkDataFormat$1(e){checkStringTypeUnionValue$1(VALID_DATA_FORMAT_VALUES$1,"DataFormat",e)}function checkInterpolationFormat$1(e){checkStringTypeUnionValue$1(VALID_INTERPOLATION_FORMAT_VALUES$1,"InterpolationFormat",e)}function checkPaddingMode$1(e){checkStringTypeUnionValue$1(VALID_PADDING_MODE_VALUES$1,"PaddingMode",e)}function checkPoolMode$1(e){checkStringTypeUnionValue$1(VALID_POOL_MODE_VALUES$1,"PoolMode",e)}const _nameScopeStack$1=[],_nameScopeDivider$1="/";function nameScope$1(e,t){_nameScopeStack$1.push(e);try{const e=t();return _nameScopeStack$1.pop(),e}catch(e){throw _nameScopeStack$1.pop(),e}}function currentNameScopePrefix$1(){return 0===_nameScopeStack$1.length?"":_nameScopeStack$1.join(_nameScopeDivider$1)+_nameScopeDivider$1}function getScopedTensorName$1(e){if(!isValidTensorName$1(e))throw new Error("Not a valid tensor name: '"+e+"'");return currentNameScopePrefix$1()+e}function getUniqueTensorName$1(e){if(!isValidTensorName$1(e))throw new Error("Not a valid tensor name: '"+e+"'");nameMap$1.has(e)||nameMap$1.set(e,0);const t=nameMap$1.get(e);if(nameMap$1.set(e,nameMap$1.get(e)+1),t>0){const n=`${e}_${t}`;return nameMap$1.set(n,1),n}return e}const tensorNameRegex$1=new RegExp(/^[A-Za-z0-9][-A-Za-z0-9\._\/]*$/);function isValidTensorName$1(e){return!!e.match(tensorNameRegex$1)}function isInteger$1(e){return e===parseInt(e.toString(),10)}function arrayProd$1(e,t,n){null==t&&(t=0),null==n&&(n=e.length);let r=1;for(let a=t;a<n;++a)r*=e[a];return r}function min$6(e){if(0===e.length)return Number.NaN;let t=Number.POSITIVE_INFINITY;for(let n=0;n<e.length;n++){const r=e[n];r<t&&(t=r)}return t}function max$6(e){if(0===e.length)return Number.NaN;let t=Number.NEGATIVE_INFINITY;for(let n=0;n<e.length;n++){const r=e[n];r>t&&(t=r)}return t}function range$7(e,t){if(t<e)throw new ValueError$1(`end (${t}) < begin (${e}) is forbidden.`);const n=[];for(let r=e;r<t;++r)n.push(r);return n}function cast$6(e,t){return cast$7(e,t)}function expandDims$6(e,t=-1){const n=e.shape.slice();return t<0&&(t=n.length+t+1),n.splice(t,0,1),reshape$6(e,n)}function repeat$2(e,t){return tidy$1(()=>{if(2!==e.shape.length)throw new ValueError$1(`repeat() expects a rank-2 tensor, but received a rank-${e.shape.length} tensor.`);return tile$6(expandDims$6(e,1),[1,t,1])})}function flatten$5(e){const t=[arrayProd$1(e.shape)];return reshape$6(e,t)}function batchFlatten$1(e){if(e.rank<=1)throw new ValueError$1(`batchFlatten requires a minimum rank of 2. Got rank: ${e.rank}.`);const t=[e.shape[0],arrayProd$1(e.shape,1)];return reshape$6(e,t)}function sliceAlongFirstAxis$1(e,t,n){return tidy$1(()=>{switch(e.rank){case 1:return slice1d$1(e,t,n);case 2:return slice2d$1(e,[t,0],[n,e.shape[1]]);case 3:return slice3d$1(e,[t,0,0],[n,e.shape[1],e.shape[2]]);case 4:return slice4d$1(e,[t,0,0,0],[n,e.shape[1],e.shape[2],e.shape[3]]);case 5:return slice$5(e,[t,0,0,0,0],[n,e.shape[1],e.shape[2],e.shape[3],e.shape[4]]);case 6:return slice$5(e,[t,0,0,0,0,0],[n,e.shape[1],e.shape[2],e.shape[3],e.shape[4],e.shape[5]]);default:throw new ValueError$1(`sliceAlongFirstAxis() received an unsupported tensor rank: ${e.rank}`)}})}function sliceAlongLastAxis$1(e,t,n){return tidy$1(()=>{switch(e.rank){case 1:return slice1d$1(e,t,n);case 2:return slice2d$1(e,[0,t],[e.shape[0],n]);case 3:return slice3d$1(e,[0,0,t],[e.shape[0],e.shape[1],n]);case 4:return slice4d$1(e,[0,0,0,t],[e.shape[0],e.shape[1],e.shape[2],n]);default:throw new ValueError$1(`sliceAlongLastAxis() received an unsupported tensor rank: ${e.rank}`)}})}function sliceAlongAxis$1(e,t,n,r){return tidy$1(()=>{switch(e.rank){case 1:return slice1d$1(e,t,n);case 2:switch(r){case 1:return sliceAlongFirstAxis$1(e,t,n);case 2:return sliceAlongLastAxis$1(e,t,n);default:throw new ValueError$1(`The axis is not within the rank of the tensor ${r}`)}case 3:switch(r){case 1:return sliceAlongFirstAxis$1(e,t,n);case 2:return slice3d$1(e,[0,t,0],[e.shape[0],n,e.shape[2]]);case 3:return sliceAlongLastAxis$1(e,t,n);default:throw new ValueError$1(`The axis is not within the rank of the tensor ${r}`)}case 4:switch(r){case 1:return sliceAlongFirstAxis$1(e,t,n);case 2:return slice4d$1(e,[0,t,0,0],[e.shape[0],n,e.shape[2],e.shape[3]]);case 3:return slice4d$1(e,[0,0,t,0],[e.shape[0],e.shape[1],n,e.shape[3]]);case 4:return sliceAlongLastAxis$1(e,t,n);default:throw new ValueError$1(`The axis is not within the rank of the tensor ${r}`)}default:throw new ValueError$1(`sliceAlongLastAxis() received an unsupported tensor rank: ${e.rank}`)}})}function concatenate$2(e,t=-1){let n;return t<0&&(n=e[0].rank,t=0!==n?n:0),t===e[0].rank&&(t=-1),concat$5(e,t)}function concatAlongFirstAxis$1(e,t){switch(e.rank){case 1:return concat1d$1([e,t]);case 2:return concat2d$1([e,t],0);case 3:return concat3d$1([e,t],0);case 4:return concat4d$1([e,t],0);default:throw new ValueError$1(`concatAlongFirstAxis() received an unsupported tensor rank: ${e.rank}`)}}function tile$6(e,t){if(Array.isArray(t)||(t=[t]),e.rank!==t.length)throw new ValueError$1(`The length of input n (${t.length}) does not match the number of dimensions in input x (${e.rank})`);return tile$7(e,t)}function randomNormal$3(e,t=0,n=1,r,a){return randomNormal$4(e,t,n,r,a)}function dot$3(e,t,n,r){if(e.rank<2||t.rank<2)throw new NotImplementedError$1(`dot requires both inputs to be rank >= 2 but got x shape = ${e.shape} and y shape = ${t.shape}`);if(t.rank>=3&&e.shape.slice(-1)[0]!==t.shape.slice(-2)[0])throw new NotImplementedError$1(`If rank y >= 3, then the second last dim of y must equal the last dim of x but got x shape = ${e.shape} and  y shape = ${t.shape}`);if(2===e.rank&&2===t.rank)return matMul$2({a:e,b:t,transposeA:!1,transposeB:!1,bias:r?reshapeBias$1(e.rank,r,imageDataFormat$1()):null,activation:n});{const a=e.shape.slice(),s=a.pop();e=reshape$6(e,[-1,s]);const o=t.shape.slice(),i=o.pop(),l=o.pop(),u=[...o,i],c=Array.from({length:t.rank},(e,n)=>0===n?t.rank-2:n<=t.rank-2?n-1:n);t=reshape$6(transpose$5(t,c),[l,-1]);const p=[...a,...u];return reshape$6(matMul$2({a:e,b:t,transposeA:!1,transposeB:!1,bias:r?reshapeBias$1(e.rank,r,imageDataFormat$1()):null,activation:n}),p)}}function gather$2(e,t,n){return tidy$1(()=>(t=Array.isArray(t)?tensor1d$1(t,"int32"):cast$7(t,"int32"),gather$3(e,t,n)))}function square$4(e){return mul$1(e,e)}function reshapeBias$1(e,t,n){const r=t.shape;if(1!==t.rank&&t.rank!==e)throw new ValueError$1(`Unexpected bias dimensions: ${t.rank}; expected it to be 1 or ${e}`);if(5===e){if("channelsFirst"===n)return reshape$6(t,1===r.length?[1,r[0],1,1,1]:[1,r[3],r[0],r[1],r[2]]);if("channelsLast"===n)return reshape$6(t,1===r.length?[1,1,1,1,r[0]]:[1].concat(r))}else if(4===e){if("channelsFirst"===n)return reshape$6(t,1===r.length?[1,r[0],1,1]:[1,r[2],r[0],r[1]]);if("channelsLast"===n)return reshape$6(t,1===r.length?[1,1,1,r[0]]:[1].concat(r))}else if(3===e){if("channelsFirst"===n)return reshape$6(t,1===r.length?[1,r[0],1]:[1,r[1],r[0]]);if("channelsLast"===n)return reshape$6(t,1===r.length?[1,1,r[0]]:[1].concat(r))}else if(e<3)return t;throw new ValueError$1(`Unsupported input rank by biasAdd: ${t.rank}`)}function biasAdd$1(e,t,n){return tidy$1(()=>(null==n&&(n=imageDataFormat$1()),checkDataFormat$1(n),add$5(e,reshapeBias$1(e.rank,t,n))))}function elu$7(e,t=1){if(1!==t)throw new NotImplementedError$1(`Support for alpha values other than 1 (${t}) is not implemented yet.`);return elu$8(e)}function softsign$1(e){return tidy$1(()=>div$3(e,add$5(abs$5(e),1)))}function dropout$4(e,t,n,r){return tidy$1(()=>dropout$5(e,t,n,r))}function hardSigmoid$1(e){return tidy$1(()=>{const t=add$5(.5,mul$1(.2,e));return clipByValue$3(t,0,1)})}function inTrainPhase$1(e,t,n=!1){return n?e():t()}const VALID_FAN_MODE_VALUES$1=["fanIn","fanOut","fanAvg"],VALID_DISTRIBUTION_VALUES$1=["normal","uniform","truncatedNormal"];function checkFanMode$1(e){checkStringTypeUnionValue$1(VALID_FAN_MODE_VALUES$1,"FanMode",e)}function checkDistribution$1(e){checkStringTypeUnionValue$1(VALID_DISTRIBUTION_VALUES$1,"Distribution",e)}class Initializer$1 extends Serializable$1{fromConfigUsesCustomObjects(){return!1}getConfig(){return{}}}class Zeros$1 extends Initializer$1{apply(e,t){return zeros$4(e,t)}}Zeros$1.className="Zeros",registerClass$1(Zeros$1);class Ones$1 extends Initializer$1{apply(e,t){return ones$3(e,t)}}Ones$1.className="Ones",registerClass$1(Ones$1);class Constant$1 extends Initializer$1{constructor(e){if(super(),"object"!=typeof e)throw new ValueError$1(`Expected argument of type ConstantConfig but got ${e}`);if(void 0===e.value)throw new ValueError$1(`config must have value set but got ${e}`);this.value=e.value}apply(e,t){return tidy$1(()=>mul$1(scalar$1(this.value),ones$3(e,t)))}getConfig(){return{value:this.value}}}Constant$1.className="Constant",registerClass$1(Constant$1);class RandomUniform$1 extends Initializer$1{constructor(e){super(),this.DEFAULT_MINVAL=-.05,this.DEFAULT_MAXVAL=.05,this.minval=e.minval||this.DEFAULT_MINVAL,this.maxval=e.maxval||this.DEFAULT_MAXVAL,this.seed=e.seed}apply(e,t){return randomUniform$2(e,this.minval,this.maxval,t)}getConfig(){return{minval:this.minval,maxval:this.maxval,seed:this.seed}}}RandomUniform$1.className="RandomUniform",registerClass$1(RandomUniform$1);class RandomNormal$1 extends Initializer$1{constructor(e){super(),this.DEFAULT_MEAN=0,this.DEFAULT_STDDEV=.05,this.mean=e.mean||this.DEFAULT_MEAN,this.stddev=e.stddev||this.DEFAULT_STDDEV,this.seed=e.seed}apply(e,t){if("float32"!==(t=t||"float32")&&"int32"!==t)throw new NotImplementedError$1(`randomNormal does not support dType ${t}.`);return randomNormal$3(e,this.mean,this.stddev,t,this.seed)}getConfig(){return{mean:this.mean,stddev:this.stddev,seed:this.seed}}}RandomNormal$1.className="RandomNormal",registerClass$1(RandomNormal$1);class TruncatedNormal$1 extends Initializer$1{constructor(e){super(),this.DEFAULT_MEAN=0,this.DEFAULT_STDDEV=.05,this.mean=e.mean||this.DEFAULT_MEAN,this.stddev=e.stddev||this.DEFAULT_STDDEV,this.seed=e.seed}apply(e,t){if("float32"!==(t=t||"float32")&&"int32"!==t)throw new NotImplementedError$1(`truncatedNormal does not support dType ${t}.`);return truncatedNormal$2(e,this.mean,this.stddev,t,this.seed)}getConfig(){return{mean:this.mean,stddev:this.stddev,seed:this.seed}}}TruncatedNormal$1.className="TruncatedNormal",registerClass$1(TruncatedNormal$1);class Identity$2 extends Initializer$1{constructor(e){super(),this.gain=null!=e.gain?e.gain:1}apply(e,t){return tidy$1(()=>{if(2!==e.length||e[0]!==e[1])throw new ValueError$1("Identity matrix initializer can only be used for 2D square matrices.");return mul$1(this.gain,eye$1(e[0]))})}getConfig(){return{gain:this.gain}}}function computeFans$1(e,t="channelsLast"){let n,r;if(checkDataFormat$1(t),2===e.length)n=e[0],r=e[1];else if(-1!==[3,4,5].indexOf(e.length)){if("channelsFirst"===t){const t=arrayProd$1(e,2);n=e[1]*t,r=e[0]*t}else if("channelsLast"===t){const t=arrayProd$1(e,0,e.length-2);n=e[e.length-2]*t,r=e[e.length-1]*t}}else{const t=arrayProd$1(e);n=Math.sqrt(t),r=Math.sqrt(t)}return[n,r]}Identity$2.className="Identity",registerClass$1(Identity$2);class VarianceScaling$1 extends Initializer$1{constructor(e){if(super(),e.scale<0)throw new ValueError$1(`scale must be a positive float. Got: ${e.scale}`);this.scale=null==e.scale?1:e.scale,this.mode=null==e.mode?"fanIn":e.mode,checkFanMode$1(this.mode),this.distribution=null==e.distribution?"normal":e.distribution,checkDistribution$1(this.distribution),this.seed=e.seed}apply(e,t){const n=computeFans$1(e),r=n[0],a=n[1];let s=this.scale;if(s/="fanIn"===this.mode?Math.max(1,r):"fanOut"===this.mode?Math.max(1,a):Math.max(1,(r+a)/2),"normal"===this.distribution){const n=Math.sqrt(s);if("float32"!==(t=t||"float32")&&"int32"!==t)throw new NotImplementedError$1(`${this.getClassName()} does not support dType ${t}.`);return truncatedNormal$2(e,0,n,t,this.seed)}{const n=Math.sqrt(3*s);return randomUniform$2(e,-n,n,t)}}getConfig(){return{scale:this.scale,mode:this.mode,distribution:this.distribution,seed:this.seed}}}VarianceScaling$1.className="VarianceScaling",registerClass$1(VarianceScaling$1);class GlorotUniform$1 extends VarianceScaling$1{constructor(e){super({scale:1,mode:"fanAvg",distribution:"uniform",seed:null==e?null:e.seed})}getClassName(){return VarianceScaling$1.className}}GlorotUniform$1.className="GlorotUniform",registerClass$1(GlorotUniform$1);class GlorotNormal$1 extends VarianceScaling$1{constructor(e){super({scale:1,mode:"fanAvg",distribution:"normal",seed:null==e?null:e.seed})}getClassName(){return VarianceScaling$1.className}}GlorotNormal$1.className="GlorotNormal",registerClass$1(GlorotNormal$1);class HeNormal$1 extends VarianceScaling$1{constructor(e){super({scale:2,mode:"fanIn",distribution:"normal",seed:null==e?null:e.seed})}getClassName(){return VarianceScaling$1.className}}HeNormal$1.className="HeNormal",registerClass$1(HeNormal$1);class HeUniform$1 extends VarianceScaling$1{constructor(e){super({scale:2,mode:"fanIn",distribution:"uniform",seed:null==e?null:e.seed})}getClassName(){return VarianceScaling$1.className}}HeUniform$1.className="HeUniform",registerClass$1(HeUniform$1);class LeCunNormal$1 extends VarianceScaling$1{constructor(e){super({scale:1,mode:"fanIn",distribution:"normal",seed:null==e?null:e.seed})}getClassName(){return VarianceScaling$1.className}}LeCunNormal$1.className="LeCunNormal",registerClass$1(LeCunNormal$1);class LeCunUniform$1 extends VarianceScaling$1{constructor(e){super({scale:1,mode:"fanIn",distribution:"uniform",seed:null==e?null:e.seed})}getClassName(){return VarianceScaling$1.className}}LeCunUniform$1.className="LeCunNormal",registerClass$1(LeCunUniform$1);class Orthogonal$1 extends Initializer$1{constructor(e){if(super(),this.DEFAULT_GAIN=1,this.gain=null==e.gain?this.DEFAULT_GAIN:e.gain,this.seed=e.seed,null!=this.seed)throw new NotImplementedError$1("Random seed is not implemented for Orthogonal Initializer yet.")}apply(e,t){return tidy$1(()=>{if(e.length<2)throw new NotImplementedError$1("Shape must be at least 2D.");e[0]*e[1]>2e3&&console.warn(`Orthogonal initializer is being called on a matrix with more than 2000 (${e[0]*e[1]}) elements: Slowness may result.`);const t=randomNormal$3(e[0]>e[1]?[e[1],e[0]]:e,0,1,"float32");let n=linalg$1.gramSchmidt(t);return e[0]>e[1]&&(n=transpose$5(n)),mul$1(this.gain,n)})}getConfig(){return{gain:this.gain,seed:this.seed}}}Orthogonal$1.className="Orthogonal",registerClass$1(Orthogonal$1);const INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP$1={constant:"Constant",glorotNormal:"GlorotNormal",glorotUniform:"GlorotUniform",heNormal:"HeNormal",heUniform:"HeUniform",identity:"Identity",leCunNormal:"LeCunNormal",leCunUniform:"LeCunUniform",ones:"Ones",orthogonal:"Orthogonal",randomNormal:"RandomNormal",randomUniform:"RandomUniform",truncatedNormal:"TruncatedNormal",varianceScaling:"VarianceScaling",zeros:"Zeros"};function deserializeInitializer$1(e,t={}){return deserializeKerasObject$1(e,SerializationMap$1.getMap().classNameMap,t,"initializer")}function serializeInitializer$1(e){return serializeKerasObject$1(e)}function getInitializer$1(e){if("string"==typeof e){const t=e in INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP$1?INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP$1[e]:e;if("GlorotNormal"===t)return new GlorotNormal$1;if("GlorotUniform"===t)return new GlorotUniform$1;if("HeNormal"===t)return new HeNormal$1;if("HeUniform"===t)return new HeUniform$1;if("LeCunNormal"===t)return new LeCunNormal$1;if("LeCunUniform"===t)return new LeCunUniform$1;{const e={};return e.className=t,e.config={},deserializeInitializer$1(e)}}return e instanceof Initializer$1?e:deserializeInitializer$1(e)}let _nextUniqueTensorId$1=0;function getNextUniqueTensorId$1(){return _nextUniqueTensorId$1++}const _uidPrefixes$1={};function getUid$1(e=""){return e in _uidPrefixes$1||(_uidPrefixes$1[e]=0),_uidPrefixes$1[e]+=1,e+_uidPrefixes$1[e].toString()}function isArrayOfShapes$1(e){return Array.isArray(e)&&Array.isArray(e[0])}function normalizeShapeList$1(e){return 0===e.length?[]:Array.isArray(e[0])?e:[e]}function getExactlyOneTensor$1(e){let t;if(Array.isArray(e)){if(1!==e.length)throw new ValueError$1(`Expected Tensor length to be 1; got ${e.length}`);t=e[0]}else t=e;return t}function getExactlyOneShape$1(e){if(Array.isArray(e)&&Array.isArray(e[0])){if(1===e.length)return(e=e)[0];throw new ValueError$1(`Expected exactly 1 Shape; got ${e.length}`)}return e}function countParamsInWeights$1(e){let t=0;for(const n of e)t+=0===n.shape.length?1:n.shape.reduce((e,t)=>e*t);return t}const DEFAULT_VARIABLE_NAME_PREFIX$1="Variable";class LayerVariable$1{constructor(e,t="float32",n=DEFAULT_VARIABLE_NAME_PREFIX$1,r=!0,a=null){this.dtype=null==t?"float32":t,this.shape=e.shape,this.id=getNextUniqueTensorId$1(),this.originalName=getScopedTensorName$1(n=null==n?DEFAULT_VARIABLE_NAME_PREFIX$1:n),this.name=getUniqueTensorName$1(this.originalName),this.trainable_=r,this.constraint=a,this.val=variable$1(e,this.trainable_,this.name,this.dtype)}read(){return this.assertNotDisposed(),this.val}write(e){return this.assertNotDisposed(),checkShapesMatch$1(this.val,e),this.val.id!==e.id&&(this.val.assign(e),null!=this.constraint&&this.val.assign(this.constraint.apply(this.val))),this}dispose(){this.assertNotDisposed(),this.val.dispose()}assertNotDisposed(){if(this.val.isDisposed)throw new Error(`LayersVariable ${this.name} is already disposed.`)}get trainable(){return this.trainable_}set trainable(e){this.trainable_=e,this.val.trainable=e}}function checkShapesMatch$1(e,t){if(e.shape.toString()!==t.shape.toString())throw new Error("Shape mismatch: "+JSON.stringify(e.shape)+" vs. "+JSON.stringify(t.shape))}function batchGetValue$1(e){return e.map(e=>e.read())}function batchSetValue$1(e){e.forEach(e=>{e[0].write(e[1])})}class InputSpec$1{constructor(e){this.dtype=e.dtype,this.shape=e.shape,this.ndim=null!=e.shape?e.shape.length:e.ndim,this.maxNDim=e.maxNDim,this.minNDim=e.minNDim,this.axes=e.axes||{}}}class SymbolicTensor$1{constructor(e,t,n,r,a,s,o){this.dtype=e,this.shape=t,this.sourceLayer=n,this.inputs=r,this.callArgs=a,this.outputTensorIndex=o,this.id=getNextUniqueTensorId$1(),null!=s&&(this.originalName=getScopedTensorName$1(s),this.name=getUniqueTensorName$1(this.originalName)),this.rank=t.length}}let _nextNodeID$1=0;class Node$1{constructor(e,t){this.callArgs=t,this.id=_nextNodeID$1++,this.outboundLayer=e.outboundLayer,this.inboundLayers=e.inboundLayers,this.nodeIndices=e.nodeIndices,this.tensorIndices=e.tensorIndices,this.inputTensors=e.inputTensors,this.outputTensors=e.outputTensors,this.inputMasks=e.inputMasks,this.outputMasks=e.outputMasks,this.inputShapes=e.inputShapes,this.outputShapes=e.outputShapes;for(const t of e.inboundLayers)null!=t&&t.outboundNodes.push(this);e.outboundLayer.inboundNodes.push(this)}getConfig(){const e=[];for(const t of this.inboundLayers)e.push(null!=t?t.name:null);return{outboundLayer:this.outboundLayer?this.outboundLayer.name:null,inboundLayers:e,nodeIndices:this.nodeIndices,tensorIndices:this.tensorIndices}}}let _nextLayerID$1=0;class Layer$1 extends Serializable$1{constructor(e={}){super(),this._callHook=null,this._addedWeightNames=[],this._stateful=!1,this.id=_nextLayerID$1++,this.activityRegularizer=null,this.inputSpec=null,this.supportsMasking=!1,this._trainableWeights=[],this._nonTrainableWeights=[],this._losses=[],this._updates=[],this._built=!1,this.inboundNodes=[],this.outboundNodes=[];let t=e.name;if(!t){const e=this.getClassName();t=toSnakeCase$1(e)+"_"+getUid$1(e)}if(this.name=t,this.trainable_=null==e.trainable||e.trainable,null!=e.inputShape||null!=e.batchInputShape){let t;if(null!=e.batchInputShape)t=e.batchInputShape;else if(null!=e.inputShape){let n=null;null!=e.batchSize&&(n=e.batchSize),t=[n].concat(e.inputShape)}this.batchInputShape=t;let n=e.dtype;null==n&&(n=e.inputDType),null==n&&(n="float32"),this.dtype=n}this.initialWeights=null!=e.weights?e.weights:null,this._refCount=null,this.fastWeightInitDuringBuild=!1}static nodeKey(e,t){return e.name+"_ib-"+t.toString()}getNodeAtIndex(e,t){if(0===this.inboundNodes.length)throw new RuntimeError$1(`The layer has never been called and thus has no defined ${t}.`);if(this.inboundNodes.length<=e)throw new ValueError$1(`Asked to get ${t} at node ${e}, but the layer has only ${this.inboundNodes.length} inbound nodes.`);return this.inboundNodes[e]}getInputAt(e){return singletonOrArray$1(this.getNodeAtIndex(e,"input").inputTensors)}getOutputAt(e){return singletonOrArray$1(this.getNodeAtIndex(e,"output").outputTensors)}get input(){if(this.inboundNodes.length>1)throw new AttributeError$1(`Layer ${this.name} has multiple inbound nodes, hence the notion of "layer input" is ill-defined. Use \`getInputAt(nodeIndex)\` instead.`);if(0===this.inboundNodes.length)throw new AttributeError$1(`Layer ${this.name} is not connected, no input to return.`);return singletonOrArray$1(this.getNodeAtIndex(0,"input").inputTensors)}get output(){if(0===this.inboundNodes.length)throw new AttributeError$1(`Layer ${this.name} has no inbound nodes.`);if(this.inboundNodes.length>1)throw new AttributeError$1(`Layer ${this.name} has multiple inbound nodes, hence the notion of "layer output" is ill-defined. Use \`getOutputAt(nodeIndex)\` instead.`);return singletonOrArray$1(this.getNodeAtIndex(0,"output").outputTensors)}get losses(){return this._losses}calculateLosses(){return this.losses.map(e=>e())}get updates(){return this._updates}get built(){return this._built}set built(e){this._built=e}get trainable(){return this.trainable_}set trainable(e){this._trainableWeights.forEach(t=>t.trainable=e),this.trainable_=e}get trainableWeights(){return this.trainable_?this._trainableWeights.filter(e=>e.trainable):[]}set trainableWeights(e){this._trainableWeights=e}get nonTrainableWeights(){return this.trainable?this._trainableWeights.filter(e=>!e.trainable).concat(this._nonTrainableWeights):this._trainableWeights.concat(this._nonTrainableWeights)}set nonTrainableWeights(e){this._nonTrainableWeights=e}get weights(){return this.trainableWeights.concat(this.nonTrainableWeights)}get stateful(){return this._stateful}resetStates(){if(!this.stateful)throw new Error("Cannot call the resetStates() method of a non-stateful Layer object.")}assertInputCompatibility(e){if(e=toList$1(e),null==this.inputSpec||0===this.inputSpec.length)return;const t=toList$1(this.inputSpec);if(e.length!==t.length)throw new ValueError$1(`Layer ${this.name} expects ${t.length} inputs, but it received ${e.length} input tensors. Input received: ${e}`);for(let n=0;n<e.length;n++){const r=e[n],a=t[n];if(null==a)continue;const s=r.rank;if(null!=a.ndim&&s!==a.ndim)throw new ValueError$1(`Input ${n} is incompatible with layer ${this.name}: expected ndim=${a.ndim}, found ndim=${s}`);if(null!=a.maxNDim&&s>a.maxNDim)throw new ValueError$1(`Input ${n} is incompatible with layer ${this.name}: expected max_ndim=${a.maxNDim}, found ndim=${s}`);if(null!=a.minNDim&&s<a.minNDim)throw new ValueError$1(`Input ${n} is incompatible with layer ${this.name}: expected min_ndim=${a.minNDim}, found ndim=${s}.`);if(null!=a.dtype&&r.dtype!==a.dtype)throw new ValueError$1(`Input ${n} is incompatible with layer ${this.name} : expected dtype=${a.dtype}, found dtype=${r.dtype}.`);if(a.axes){const e=r.shape;for(const t in a.axes){const r=Number(t),s=a.axes[t],o=r>=0?e[r]:e[e.length+r];if(null!=s&&-1===[s,null].indexOf(o))throw new ValueError$1(`Input ${n} is incompatible with layer ${this.name}: expected axis ${r} of input shape to have value ${s} but got shape ${e}.`)}}if(null!=a.shape)for(let e=0;e<a.shape.length;++e){const t=a.shape[e],s=r.shape[e];if(null!=t&&null!=s&&t!==s)throw new ValueError$1(`Input ${n} is incompatible with layer ${this.name}: expected shape=${a.shape}, found shape=${r.shape}.`)}}}call(e,t){return e}invokeCallHook(e,t){null!=this._callHook&&this._callHook(e,t)}setCallHook(e){this._callHook=e}clearCallHook(){this._callHook=null}apply(e,t){t=t||{},this.assertNotDisposed();const n=toList$1(e);let r=!0;for(const e of n)if(!(e instanceof SymbolicTensor$1)){r=!1;break}let a=!0;for(const e of n)if(e instanceof SymbolicTensor$1){a=!1;break}if(r===a)throw new ValueError$1("Arguments to apply() must be all SymbolicTensors or all Tensors");return nameScope$1(this.name,()=>{if(!this.built){this.assertInputCompatibility(e);const t=[];for(const n of toList$1(e))t.push(n.shape);this.build(singletonOrArray$1(t)),this.built=!0,this.initialWeights&&this.setWeights(this.initialWeights),null===this._refCount&&a&&(this._refCount=1)}if(this.assertInputCompatibility(e),a){let r=this.call(e,t);const a=toList$1(r),s=[];for(let e of a)-1!==n.indexOf(e)&&(e=e.clone()),s.push(e);if(r=singletonOrArray$1(s),null!=this.activityRegularizer)throw new NotImplementedError$1("Layer invocation in the presence of activity regularizer(s) is not supported yet.");return r}{const n=collectInputShape$1(e),r=this.computeOutputShape(n);let a;const s=guessOutputDType$1(e);if(this.warnOnIncompatibleInputShape(Array.isArray(e)?n[0]:n),a=null!=r&&r.length>0&&Array.isArray(r[0])?r.map((n,r)=>new SymbolicTensor$1(s,n,this,toList$1(e),t,this.name,r)):new SymbolicTensor$1(s,r,this,toList$1(e),t,this.name),this.addInboundNode(e,a,null,null,n,r,t),this._refCount++,null!=this.activityRegularizer)throw new NotImplementedError$1("Layer invocation in the presence of activity regularizer(s) is not supported yet.");return a}})}warnOnIncompatibleInputShape(e){if(null!=this.batchInputShape)if(e.length!==this.batchInputShape.length)console.warn(`The rank of the input tensor provided (shape: ${JSON.stringify(e)}) does not match that of the batchInputShape (${JSON.stringify(this.batchInputShape)}) of the layer ${this.name}`);else{let t=!1;this.batchInputShape.forEach((n,r)=>{null!=n&&null!=e[r]&&e[r]!==n&&(t=!0)}),t&&console.warn(`The shape of the input tensor (${JSON.stringify(e)}) does not match the expectation of layer ${this.name}: ${JSON.stringify(this.batchInputShape)}`)}}get outputShape(){if(null==this.inboundNodes||0===this.inboundNodes.length)throw new AttributeError$1(`The layer ${this.name} has never been called and thus has no defined output shape.`);const e=[];for(const t of this.inboundNodes){const n=JSON.stringify(t.outputShapes);-1===e.indexOf(n)&&e.push(n)}if(1===e.length){const e=this.inboundNodes[0].outputShapes;return Array.isArray(e)&&Array.isArray(e[0])&&1===e.length?e[0]:e}throw new AttributeError$1(`The layer ${this.name} has multiple inbound nodes with different output shapes. Hence the notion of "output shape" is ill-defined for the layer.`)}countParams(){if(!this.built)throw new RuntimeError$1(`You tried to call countParams() on ${this.name}, but the layer is not built yet. Build it first by calling build(batchInputShape).`);return countParamsInWeights$1(this.weights)}build(e){this.built=!0}getWeights(e=!1){return batchGetValue$1(e?this.trainableWeights:this.weights)}setWeights(e){tidy$1(()=>{const t=this.weights;if(t.length!==e.length)throw new ValueError$1(`You called setWeights(weights) on layer "${this.name}" with a weight list of length ${e.length}, but the layer was expecting ${t.length} weights. Provided weights: ${e}...`);if(0===t.length)return;const n=[],r=batchGetValue$1(t);for(let a=0;a<r.length;++a){const s=r[a],o=t[a],i=e[a];if(!arraysEqual$1(s.shape,i.shape))throw new ValueError$1(`Layer weight shape ${s.shape} not compatible with provided weight shape ${i.shape}`);n.push([o,i])}batchSetValue$1(n)})}addWeight(e,t,n,r,a,s,o){if(-1!==this._addedWeightNames.indexOf(e))throw new ValueError$1(`Duplicate weight name ${e} for layer ${this.name}`);this._addedWeightNames.push(e),null==n&&(n="float32"),this.fastWeightInitDuringBuild&&(r=getInitializer$1("zeros"));const i=r.apply(t,n),l=new LayerVariable$1(i,n,e,s,o);return i.dispose(),null!=a&&this.addLoss(()=>a.apply(l.read())),null==s&&(s=!0),s?this._trainableWeights.push(l):this._nonTrainableWeights.push(l),l}setFastWeightInitDuringBuild(e){this.fastWeightInitDuringBuild=e}addLoss(e){null==e||Array.isArray(e)&&0===e.length||(e=toList$1(e),null!=this._losses&&this.losses.push(...e))}computeOutputShape(e){return e}computeMask(e,t){if(!this.supportsMasking){if(null!=t){if(!Array.isArray(t))throw new TypeError(`Layer ${this.name} does not support masking, but was passed an inputMask.`);t.forEach(e=>{if(null!=e)throw new TypeError(`Layer ${this.name} does not support masking, but was passed an inputMask.`)})}return null}return t}addInboundNode(e,t,n,r,a,s,o=null){const i=toList$1(e);t=toList$1(t),n=toList$1(n),r=toList$1(r),a=normalizeShapeList$1(a),s=normalizeShapeList$1(s);const l=[],u=[],c=[];for(const e of i)l.push(e.sourceLayer),u.push(e.nodeIndex),c.push(e.tensorIndex);new Node$1({outboundLayer:this,inboundLayers:l,nodeIndices:u,tensorIndices:c,inputTensors:i,outputTensors:t,inputMasks:n,outputMasks:r,inputShapes:a,outputShapes:s},o);for(let e=0;e<t.length;e++)t[e].sourceLayer=this,t[e].nodeIndex=this.inboundNodes.length-1,t[e].tensorIndex=e}getConfig(){const e={name:this.name,trainable:this.trainable};return null!=this.batchInputShape&&(e.batchInputShape=this.batchInputShape),null!=this.dtype&&(e.dtype=this.dtype),e}disposeWeights(){return this.weights.forEach(e=>e.dispose()),this.weights.length}assertNotDisposed(){if(0===this._refCount)throw new Error(`Layer '${this.name}' is already disposed.`)}dispose(){if(!this.built)throw new Error(`Cannot dispose Layer ${this.name} because it has not been built yet.`);if(null===this._refCount)throw new Error(`Cannot dispose Layer ${this.name} because it has not been used yet.`);this.assertNotDisposed();let e=0;return 0==--this._refCount&&(e=this.disposeWeights()),{refCountAfterDispose:this._refCount,numDisposedVariables:e}}}function collectInputShape$1(e){e=toList$1(e);const t=[];for(const n of e)t.push(n.shape);return singletonOrArray$1(t)}function guessOutputDType$1(e){return"float32"}function getSourceInputs$1(e,t,n){if((null==t||null!=n&&n>0)&&(t=e.sourceLayer,n=e.nodeIndex),0===t.inboundNodes.length)return[e];{const e=t.inboundNodes[n];if(0===e.inboundLayers.length)return e.inputTensors;{const t=[];for(let n=0;n<e.inboundLayers.length;n++){const r=getSourceInputs$1(e.inputTensors[n],e.inboundLayers[n],e.nodeIndices[n]);for(const e of r)-1===t.indexOf(e)&&t.push(e)}return t}}}class InputLayer$1 extends Layer$1{constructor(e){if(super({dtype:e.dtype,name:null!=e.name?e.name:getUid$1("input").toString()}),null==e.batchSize&&(e.batchSize=null),null==e.sparse&&(e.sparse=!1),this.trainable=!1,this.built=!0,this.sparse=e.sparse,null!=e.inputShape&&null!=e.batchInputShape)throw new ValueError$1("Only provide the inputShape OR batchInputShape argument to inputLayer, not both at the same time.");let t=e.batchInputShape;if(null==t){if(null==e.inputShape)throw new ValueError$1("An InputLayer should be passed either a `batchInputShape` or an `inputShape`.");t=[e.batchSize].concat(e.inputShape)}else if(null!=e.batchSize)throw new ValueError$1("Cannot specify batchSize if batchInputShape is specified when creating an InputLayer.");const n=e.dtype||"float32";this.batchInputShape=t,this.dtype=n,this.inputSpec=[{shape:t}];const r=new SymbolicTensor$1(this.dtype,this.batchInputShape,this,[],{},this.name);r.nodeIndex=0,r.tensorIndex=0,new Node$1({outboundLayer:this,inboundLayers:[],nodeIndices:[],tensorIndices:[],inputTensors:[r],outputTensors:[r],inputMasks:[null],outputMasks:[null],inputShapes:[t],outputShapes:[t]})}apply(e,t){throw new ValueError$1(`Cannot pass any input to an InputLayer's apply() method. InputLayer name: ${this.name}`)}dispose(){return{refCountAfterDispose:this._refCount,numDisposedVariables:0}}getConfig(){return{batchInputShape:this.batchInputShape,dtype:this.dtype,sparse:this.sparse,name:this.name}}}function Input$1(e){if(null==e.batchShape&&null==e.shape)throw new Error("Please provide to Input either a `shape` or a `batchShape` argument. Note that `shape` does not include the batch dimension.");if(null!=e.batchShape&&null!=e.shape)throw new ValueError$1("Please provide either a `shape` or `batchShape` argument to Input, but not both.");let t=e.batchShape;null!=e.shape&&null==t&&(t=[null].concat(e.shape));let n=e.dtype;return null==n&&(n="float32"),new InputLayer$1({batchInputShape:t,name:e.name,dtype:n,sparse:e.sparse}).inboundNodes[0].outputTensors[0]}async function resolveScalarsInLogs$1(e){if(null==e)return;const t=[],n=[],r=[];for(const a in e){const s=e[a];if("number"!=typeof s){const e=s;t.push(e.data()),n.push(a),r.push(e)}}if(t.length>0){const a=await Promise.all(t);for(let t=0;t<a.length;++t)e[n[t]]=a[t][0];dispose$1(r)}}function disposeTensorsInLogs$1(e){if(null!=e)for(const t in e){const n=e[t];"number"!=typeof n&&n.dispose()}}var ModelLoggingVerbosity$1;InputLayer$1.className="InputLayer",registerClass$1(InputLayer$1),function(e){e[e.SILENT=0]="SILENT",e[e.VERBOSE=1]="VERBOSE"}(ModelLoggingVerbosity$1||(ModelLoggingVerbosity$1={}));const DEFAULT_YIELD_EVERY_MS$1=125;class BaseCallback$1{constructor(){this.validationData=null}setParams(e){this.params=e}async onEpochBegin(e,t){}async onEpochEnd(e,t){}async onBatchBegin(e,t){}async onBatchEnd(e,t){}async onTrainBegin(e){}async onTrainEnd(e){}setModel(e){}}class CallbackList$1{constructor(e,t=10){null==e&&(e=[]),this.callbacks=e,this.queueLength=t}append(e){this.callbacks.push(e)}setParams(e){for(const t of this.callbacks)t.setParams(e)}setModel(e){for(const t of this.callbacks)t.setModel(e)}async onEpochBegin(e,t){null==t&&(t={});for(const n of this.callbacks)await n.onEpochBegin(e,t)}async onEpochEnd(e,t){null==t&&(t={});for(const n of this.callbacks)await n.onEpochEnd(e,t)}async onBatchBegin(e,t){null==t&&(t={});for(const n of this.callbacks)await n.onBatchBegin(e,t)}async onBatchEnd(e,t){null==t&&(t={});for(const n of this.callbacks)await n.onBatchEnd(e,t)}async onTrainBegin(e){null==e&&(e={});for(const t of this.callbacks)await t.onTrainBegin(e)}async onTrainEnd(e){null==e&&(e={});for(const t of this.callbacks)await t.onTrainEnd(e)}}class BaseLogger$1 extends BaseCallback$1{constructor(){super()}async onEpochBegin(e){this.seen=0,this.totals={}}async onBatchEnd(e,t){null==t&&(t={});const n=null==t.size?0:t.size;this.seen+=n;for(const e in t){const r=t[e];if("number"==typeof r)this.totals.hasOwnProperty(e)||(this.totals[e]=0),this.totals[e]=this.totals[e]+r*n;else{let t;e in this.totals?t=this.totals[e]:this.totals[e]=0;const a=tidy$1(()=>add$5(this.totals[e],mul$1(r,n)));this.totals[e]=a,null!=t&&t.dispose()}}}async onEpochEnd(e,t){if(null!=t)for(const e of this.params.metrics)null!=this.totals[e]&&("number"==typeof this.totals[e]?t[e]=this.totals[e]/this.seen:tidy$1(()=>{const n=mul$1(div$3(1,this.seen),this.totals[e]);t[e]=n,this.totals[e].dispose(),keep$1(t[e])}))}}class History$1 extends BaseCallback$1{async onTrainBegin(e){this.epoch=[],this.history={}}async onEpochEnd(e,t){null==t&&(t={}),this.epoch.push(e);for(const e in t)null==this.history[e]&&(this.history[e]=[]),this.history[e].push(t[e])}async syncData(){const e=[],t=[],n=[];for(const r in this.history){const a=this.history[r];for(let s=0;s<a.length;++s)"number"!=typeof a[s]&&(e.push(a[s].data()),t.push(r),n.push(s))}const r=await Promise.all(e);for(let e=0;e<r.length;++e)this.history[t[e]][n[e]].dispose(),this.history[t[e]][n[e]]=r[e][0]}}class CustomCallback$1 extends BaseCallback$1{constructor(e,t){if(super(),this.currentEpoch=0,this.yieldEvery=t||"auto","auto"===this.yieldEvery&&(this.yieldEvery=DEFAULT_YIELD_EVERY_MS$1),"never"===this.yieldEvery&&null!=e.onYield)throw new Error("yieldEvery is `never` but you provided an `onYield` callback. Either change `yieldEvery` or remove the callback");isNumber$1(this.yieldEvery)&&(this.maybeWait=debounce$1(this.maybeWait.bind(this),this.yieldEvery)),this.trainBegin=e.onTrainBegin,this.trainEnd=e.onTrainEnd,this.epochBegin=e.onEpochBegin,this.epochEnd=e.onEpochEnd,this.batchBegin=e.onBatchBegin,this.batchEnd=e.onBatchEnd,this.yield=e.onYield}async maybeWait(e,t,n){const r=[];null!=this.yield&&(await resolveScalarsInLogs$1(n),r.push(this.yield(e,t,n))),r.push(nextFrame$1()),await Promise.all(r)}async onEpochBegin(e,t){this.currentEpoch=e,null!=this.epochBegin&&(await resolveScalarsInLogs$1(t),await this.epochBegin(e,t))}async onEpochEnd(e,t){const n=[];null!=this.epochEnd&&(await resolveScalarsInLogs$1(t),n.push(this.epochEnd(e,t))),"epoch"===this.yieldEvery&&n.push(nextFrame$1()),await Promise.all(n)}async onBatchBegin(e,t){null!=this.batchBegin&&(await resolveScalarsInLogs$1(t),await this.batchBegin(e,t))}async onBatchEnd(e,t){const n=[];null!=this.batchEnd&&(await resolveScalarsInLogs$1(t),n.push(this.batchEnd(e,t))),"batch"===this.yieldEvery?n.push(nextFrame$1()):isNumber$1(this.yieldEvery)&&n.push(this.maybeWait(this.currentEpoch,e,t)),await Promise.all(n)}async onTrainBegin(e){null!=this.trainBegin&&(await resolveScalarsInLogs$1(e),await this.trainBegin(e))}async onTrainEnd(e){null!=this.trainEnd&&(await resolveScalarsInLogs$1(e),await this.trainEnd(e))}}function standardizeCallbacks$1(e,t){return null==e&&(e={}),e instanceof BaseCallback$1?[e]:Array.isArray(e)&&e[0]instanceof BaseCallback$1?e:toList$1(e).map(e=>new CustomCallback$1(e,t))}class CallbackConstructorRegistry$1{constructor(){}static registerCallbackConstructor(e,t){assert$6(e>=0&&Number.isInteger(e),()=>`Verbosity level is expected to be an integer >= 0, but got ${e}`),CallbackConstructorRegistry$1.checkForDuplicate(t),null==CallbackConstructorRegistry$1.constructors[e]&&(CallbackConstructorRegistry$1.constructors[e]=[]),CallbackConstructorRegistry$1.constructors[e].push(t)}static checkForDuplicate(e){for(const t in CallbackConstructorRegistry$1.constructors)CallbackConstructorRegistry$1.constructors[+t].forEach(t=>{if(t===e)throw new ValueError$1("Duplicate callback constructor.")})}static clear(){CallbackConstructorRegistry$1.constructors={}}static createCallbacks(e){const t=[];for(const n in CallbackConstructorRegistry$1.constructors){const r=+n;e>=r&&t.push(...CallbackConstructorRegistry$1.constructors[r])}return t.map(e=>new e)}}function configureCallbacks$1(e,t,n,r,a,s,o,i,l){const u=new History$1,c=[new BaseLogger$1,...CallbackConstructorRegistry$1.createCallbacks(t)];null!=e&&c.push(...e),c.push(u);const p=new CallbackList$1(c);return p.setParams({epochs:n,initialEpoch:r,samples:a,steps:s,batchSize:o,verbose:t,doValidation:i,metrics:l}),{callbackList:p,history:u}}function deserialize$1(e,t={},n=!1){return deserializeKerasObject$1(e,SerializationMap$1.getMap().classNameMap,t,"layer",n)}function l2Normalize$1(e,t){return tidy$1(()=>{"float32"!==e.dtype&&(e=cast$7(e,"float32"));const n=sum$6(square$4(e),t,!0),r=fill$5(n.shape,epsilon$3()),a=sqrt$5(maximum$6(n,r));return div$3(e,a)})}function meanSquaredError$3(e,t){return tidy$1(()=>mean$3(square$4(sub$5(t,e)),-1))}function meanAbsoluteError$2(e,t){return tidy$1(()=>mean$3(abs$5(sub$5(t,e)),-1))}function meanAbsolutePercentageError$2(e,t){return tidy$1(()=>{const n=sub$5(e,t),r=clipByValue$3(abs$5(e),epsilon$3(),Number.MAX_VALUE),a=abs$5(div$3(n,r));return mul$1(100,mean$3(a,-1))})}function meanSquaredLogarithmicError$1(e,t){return tidy$1(()=>{const n=clipByValue$3(t,epsilon$3(),Number.MAX_VALUE),r=log$7(add$5(1,n)),a=clipByValue$3(e,epsilon$3(),Number.MAX_VALUE),s=log$7(add$5(1,a));return mean$3(square$4(sub$5(r,s)),-1)})}function squaredHinge$1(e,t){return tidy$1(()=>{const n=maximum$6(0,sub$5(1,mul$1(e,t)));return mean$3(square$4(n),-1)})}function hinge$1(e,t){return tidy$1(()=>{const n=maximum$6(0,sub$5(1,mul$1(e,t)));return mean$3(n,-1)})}function categoricalHinge$1(e,t){return tidy$1(()=>{const n=sum$6(mul$1(e,t),-1),r=max$7(mul$1(sub$5(1,e),t),-1);return maximum$6(0,add$5(1,sub$5(r,n)))})}function logcosh$1(e,t){return tidy$1(()=>{const n=Math.log(2),r=sub$5(t,e),a=sub$5(add$5(r,softplus$5(mul$1(-2,r))),n);return mean$3(a,-1)})}function categoricalCrossentropy$4(e,t,n=!1){return tidy$1(()=>{if(n)t=softmax$6(t);else{const e=sum$6(t,t.shape.length-1,!0);t=div$3(t,e)}return t=clipByValue$3(t,epsilon$3(),1-epsilon$3()),neg$5(sum$6(mul$1(cast$7(e,"float32"),log$7(t)),t.shape.length-1))})}function sparseCategoricalCrossentropy$3(e,t,n=!1){return tidy$1(()=>{const r=cast$7(floor$5(flatten$5(e)),"int32"),a=(t=clipByValue$3(t,epsilon$3(),1-epsilon$3())).shape;return categoricalCrossentropy$4(reshape$6(oneHot$5(r,a[a.length-1]),a),t,n)})}function sigmoidCrossEntropyWithLogits$1(e,t){if(!arraysEqual$1(e.shape,t.shape))throw new ValueError$1(`logits and labels must have the same shape, but got shapes ${JSON.stringify(e.shape)} and ${JSON.stringify(t.shape)}`);return tidy$1(()=>{const n=relu$6(t),r=neg$5(abs$5(t));return add$5(sub$5(n,mul$1(t,e)),log1p$5(exp$5(r)))})}function binaryCrossentropy$4(e,t){return tidy$1(()=>{let n;return n=clipByValue$3(t,epsilon$3(),1-epsilon$3()),n=log$7(div$3(n,sub$5(1,n))),mean$3(sigmoidCrossEntropyWithLogits$1(e,n),-1)})}function kullbackLeiblerDivergence$1(e,t){return tidy$1(()=>{const n=clipByValue$3(e,epsilon$3(),1),r=clipByValue$3(t,epsilon$3(),1);return sum$6(mul$1(e,log$7(div$3(n,r))),-1)})}function poisson$1(e,t){return tidy$1(()=>{const n=log$7(add$5(epsilon$3(),t));return mean$3(sub$5(t,mul$1(e,n)),-1)})}function cosineProximity$2(e,t){return tidy$1(()=>{const n=l2Normalize$1(e,-1),r=l2Normalize$1(t,-1),a=mul$1(n,r);return neg$5(sum$6(a,-1))})}CallbackConstructorRegistry$1.constructors={};const lossesMap$1={meanSquaredError:meanSquaredError$3,meanAbsoluteError:meanAbsoluteError$2,meanAbsolutePercentageError:meanAbsolutePercentageError$2,meanSquaredLogarithmicError:meanSquaredLogarithmicError$1,squaredHinge:squaredHinge$1,hinge:hinge$1,categoricalHinge:categoricalHinge$1,logcosh:logcosh$1,categoricalCrossentropy:categoricalCrossentropy$4,sparseCategoricalCrossentropy:sparseCategoricalCrossentropy$3,binaryCrossentropy:binaryCrossentropy$4,kullbackLeiblerDivergence:kullbackLeiblerDivergence$1,poisson:poisson$1,cosineProximity:cosineProximity$2};function get$3(e){if("string"==typeof e){if(e in lossesMap$1)return lossesMap$1[e];let t=`Unknown loss ${e}`;throw e.toLowerCase().includes("softmaxcrossentropy")&&(t=`Unknown loss ${e}. Use "categoricalCrossentropy" as the string name for tf.losses.softmaxCrossEntropy`),new ValueError$1(t)}return e}function binaryAccuracy$2(e,t){return tidy$1(()=>{const n=mul$1(.5,onesLike$5(t)),r=cast$6(greater$6(t,n),e.dtype);return mean$3(equal$5(e,r),-1)})}function categoricalAccuracy$2(e,t){return tidy$1(()=>cast$6(equal$5(argMax$5(e,-1),argMax$5(t,-1)),"float32"))}function truePositives$1(e,t){return tidy$1(()=>cast$7(sum$6(logicalAnd$5(equal$5(e,1),equal$5(t,1))),"float32"))}function falsePositives$1(e,t){return tidy$1(()=>cast$7(sum$6(logicalAnd$5(equal$5(e,0),equal$5(t,1))),"float32"))}function precision$2(e,t){return tidy$1(()=>{const n=truePositives$1(e,t),r=falsePositives$1(e,t),a=add$5(n,r);return cast$7(where$1(greater$6(a,0),div$3(n,a),0),"float32")})}function binaryCrossentropy$3(e,t){return binaryCrossentropy$4(e,t)}function sparseCategoricalAccuracy$2(e,t){return e.rank===t.rank&&(e=squeeze$1(e,[e.rank-1])),(t=argMax$5(t,-1)).dtype!==e.dtype&&(t=cast$7(t,e.dtype)),cast$7(equal$5(e,t),"float32")}const mse$2=meanSquaredError$3,MSE$2=meanSquaredError$3,mae$1=meanAbsoluteError$2,MAE$1=meanAbsoluteError$2,mape$2=meanAbsolutePercentageError$2,MAPE$2=meanAbsolutePercentageError$2,categoricalCrossentropy$3=categoricalCrossentropy$4,cosine$1=cosineProximity$2,sparseCategoricalCrossentropy$2=sparseCategoricalCrossentropy$3,metricsMap$1={binaryAccuracy:binaryAccuracy$2,categoricalAccuracy:categoricalAccuracy$2,precision:precision$2,categoricalCrossentropy:categoricalCrossentropy$3,sparseCategoricalCrossentropy:sparseCategoricalCrossentropy$2,mse:mse$2,MSE:MSE$2,mae:mae$1,MAE:MAE$1,mape:mape$2,MAPE:MAPE$2,cosine:cosine$1};function get$2(e){if("string"==typeof e&&e in metricsMap$1)return metricsMap$1[e];if("string"!=typeof e&&null!=e)return e;throw new ValueError$1(`Unknown metric ${e}`)}function getLossOrMetricName$1(e){if(assert$5(null!==e,`Unknown LossOrMetricFn ${e}`),"string"==typeof e)return e;{let t;for(const n of Object.keys(lossesMap$1))if(lossesMap$1[n]===e){t=n;break}if(void 0!==t)return t;for(const n of Object.keys(metricsMap$1))if(metricsMap$1[n]===e){t=n;break}return void 0!==t?t:e.name}}function getOptimizer$1(e){const t={Adagrad:()=>train$1.adagrad(.01),Adadelta:()=>train$1.adadelta(1,.95,epsilon$3()),Adam:()=>train$1.adam(.001,.9,.999,epsilon$3()),Adamax:()=>train$1.adamax(.002,.9,.999,epsilon$3(),0),RMSProp:()=>train$1.rmsprop(.001,.9,0,epsilon$3()),SGD:()=>train$1.sgd(.01)};if(t.adagrad=t.Adagrad,t.adadelta=t.Adadelta,t.adam=t.Adam,t.adamax=t.Adamax,t.rmsprop=t.RMSProp,t.sgd=t.SGD,e in t)return t[e]();throw new ValueError$1(`Unknown Optimizer ${e}`)}const MAX_USER_DEFINED_METADATA_SERIALIZED_LENGTH$1=1048576;function checkUserDefinedMetadata$1(e,t,n=!1){if(null==e||"object"!=typeof e||Object.getPrototypeOf(e)!==Object.prototype||!plainObjectCheck$1(e))throw new Error("User-defined metadata is expected to be a JSON object, but is not.");if(n){const n=JSON.stringify(e);n.length>MAX_USER_DEFINED_METADATA_SERIALIZED_LENGTH$1&&console.warn(`User-defined metadata of model "${t}" is too large in size (length=${n.length} when serialized). It is not recommended to store such large objects in user-defined metadata. Please make sure its serialized length is <= ${MAX_USER_DEFINED_METADATA_SERIALIZED_LENGTH$1}.`)}}function plainObjectCheck$1(e){if(null===e)return!0;if("object"==typeof e){if(Object.getPrototypeOf(e)===Object.prototype){const t=Object.keys(e);for(const n of t){if("string"!=typeof n)return!1;if(!plainObjectCheck$1(e[n]))return!1}return!0}if(Array.isArray(e)){for(const t of e)if(!plainObjectCheck$1(t))return!1;return!0}return!1}{const t=typeof e;return"string"===t||"number"===t||"boolean"===t}}function printSummary$1(e,t,n,r=console.log){const a=isModelSequentialLike$1(e),s=["Layer (type)","Output shape","Param #"];let o;if(a?(t=t||65,n=n||[.45,.85,1]):(t=t||98,n=n||[.33,.55,.67,1]),n[n.length-1]<=1&&(n=n.map(e=>Math.floor(t*e))),!a){s.push("Receives inputs"),o=[];for(const t in e.nodesByDepth)o.push(...e.nodesByDepth[t])}r("_".repeat(t)),printRow$1(s,n,r),r("=".repeat(t));const i=e.layers;for(let e=0;e<i.length;++e)a?printLayerSummary$1(i[e],n,r):printLayerSummaryWithConnections$1(i[e],n,o,r),r((e===i.length-1?"=":"_").repeat(t));e.checkTrainableWeightsConsistency();const l=countTrainableParams$1(e),u=countParamsInWeights$1(e.nonTrainableWeights);r(`Total params: ${l+u}`),r(`Trainable params: ${l}`),r(`Non-trainable params: ${u}`),r("_".repeat(t))}function countTrainableParams$1(e){let t;return t=countParamsInWeights$1(null!=e.collectedTrainableWeights?e.collectedTrainableWeights:e.trainableWeights),t}function isModelSequentialLike$1(e){let t=!0;const n=[],r=[];for(const t in e.nodesByDepth)n.push(e.nodesByDepth[t]);for(const e of n){if(e.length>1||1===e.length&&e[0].inboundLayers.length>1){t=!1;break}r.push(...e)}if(t)for(const n of e.layers){let e=!1;for(const a of n.inboundNodes)if(-1!==r.indexOf(a)){if(e){t=!1;break}e=!0}if(!t)break}return t}function printRow$1(e,t,n=console.log){let r="";for(let n=0;n<e.length;++n)n>0&&(r=r.slice(0,r.length-1)+" "),r+=e[n],r=r.slice(0,t[n]),r+=" ".repeat(t[n]-r.length);n(r)}function printLayerSummary$1(e,t,n){let r;try{r=JSON.stringify(e.outputShape)}catch(e){r="multiple"}printRow$1([`${e.name} (${e.getClassName()})`,r,e.countParams().toString()],t,n)}function printLayerSummaryWithConnections$1(e,t,n,r){let a;try{a=JSON.stringify(e.outputShape)}catch(e){a="multiple"}const s=[];for(const t of e.inboundNodes)if(!(null!=n&&n.length>0&&-1===n.indexOf(t)))for(let e=0;e<t.inboundLayers.length;++e)s.push(`${t.inboundLayers[e].name}[${t.nodeIndices[e]}][${t.tensorIndices[e]}]`);const o=e.name,i=e.getClassName(),l=0===s.length?"":s[0];printRow$1([`${o} (${i})`,a,e.countParams().toString(),l],t,r);for(let e=1;e<s.length;++e)printRow$1(["","","",s[e]],t,r)}function isArrayItemInputOrOutputName$1(e,t,n){return("inboundNodes"===e||"outputLayers"===e||"inputLayers"===e)&&0===t&&"string"==typeof n}function convertPythonicToTs$1(e,t){if(null===e)return null;if("string"==typeof e)return toCamelCase$1(e);if("number"==typeof e||"boolean"==typeof e)return e;if(e instanceof Array){const n=[],r=e.length;for(let a=0;a<r;++a){const r=e[a];isArrayItemInputOrOutputName$1(t,a,r)?n.push(r):n.push(convertPythonicToTs$1(r,t))}return n}{const t={};for(const n of Object.keys(e)){const r=e[n];if("name"===n&&"string"==typeof r)t[n]=r;else{const e=toCamelCase$1(n);t[e]=convertPythonicToTs$1(r,e)}}return t}}function convertTsToPythonic$1(e,t){if(null==e)return null;if("string"==typeof e)return toSnakeCase$1(e);if("number"==typeof e||"boolean"==typeof e)return e;if(e instanceof Array){const n=[],r=e.length;for(let a=0;a<r;++a){const r=e[a];isArrayItemInputOrOutputName$1(t,a,r)?n.push(r):n.push(convertTsToPythonic$1(r,t))}return n}{const t={};for(const n of Object.keys(e)){const r=e[n];t[toSnakeCase$1(n)]="name"!==n&&"className"!==n||"string"!=typeof r?convertTsToPythonic$1(r,n):r}return t}}const version$d="3.8.0";function assertFeedCompatibility$1(e,t){if(null==e.dtype||e.dtype===t.dtype)return t;try{return cast$7(t,e.dtype)}catch(n){throw new ValueError$1(`The dtype of the feed (${t.dtype}) can not be cast to the dtype of the key '${e.name}' (${e.dtype}).`)}}class FeedDict$1{constructor(e){if(this.id2Value={},this.id2Mask={},this.name2Id={},e instanceof FeedDict$1)for(const t in e.id2Value)this.id2Value[t]=e.id2Value[t],t in e.id2Mask&&(this.id2Mask[t]=e.id2Mask[t]);else{if(null==e)return;for(const t of e)this.add(t.key,t.value)}}add(e,t,n){if(null!=this.id2Value[e.id])throw new ValueError$1(`Duplicate key: name=${e.name}, id=${e.id}`);return this.id2Value[e.id]=assertFeedCompatibility$1(e,t),this.name2Id[e.name]=e.id,null!=n&&(this.id2Mask[e.id]=n),this}addFeed(e){this.add(e.key,e.value)}hasKey(e){return null!=this.id2Value[e.id]}names(){return Object.keys(this.name2Id)}getValue(e){if(e instanceof SymbolicTensor$1){if(null==this.id2Value[e.id])throw new ValueError$1(`Nonexistent key: ${e.name}`);return this.id2Value[e.id]}{const t=this.name2Id[e];if(null==t)throw new ValueError$1(`Feed dict has no SymbolicTensor name: ${e}`);return this.id2Value[t]}}getMask(e){if(e instanceof SymbolicTensor$1){if(null==this.id2Value[e.id])throw new ValueError$1(`Nonexistent key: ${e.name}`);return this.id2Mask[e.id]}{const t=this.name2Id[e];if(null==t)throw new ValueError$1(`Feed dict has no SymbolicTensor name: ${e}`);return this.id2Mask[t]}}disposeMasks(){null!=this.id2Mask&&dispose$1(this.id2Mask)}}const cachedSorted$1={},cachedRecipientCounts$1={};function execute$1(e,t,n,r){const a=null!=n&&n.training,s=Array.isArray(e),o=s?e:[e],i=o.map(e=>e.name),l=[],u=t.names();for(const e of i)-1!==u.indexOf(e)?l.push(t.getValue(e)):l.push(null);null!=r&&(r.maxNumTensors=-Infinity,r.minNumTensors=Infinity);const c=i.join(",")+"|"+t.names().join(",");let p,d;if(null==cachedSorted$1[c]){const e=getTopologicalSortAndRecipientCounts$1(o,t);p=e.sorted,d=e.recipientCounts,cachedSorted$1[c]=p,cachedRecipientCounts$1[c]=d}p=cachedSorted$1[c],d={},a||Object.assign(d,cachedRecipientCounts$1[c]);const h=new FeedDict$1(t);for(let e=0;e<p.length;++e){if(null!=r){const e=memory$1().numTensors;e>r.maxNumTensors&&(r.maxNumTensors=e),e<r.minNumTensors&&(r.minNumTensors=e)}const s=p[e],o=s.sourceLayer;if(o instanceof InputLayer$1)continue;const u=[],c=[],m=[];let f=!1;for(const e of s.inputs){const n=h.getValue(e),r=h.getMask(e);u.push(n),c.push(r),null!=r&&(f=!0),a||(d[e.name]--,0!==d[e.name]||t.hasKey(e)||-1!==i.indexOf(e.name)||n.isDisposed||!0===e.sourceLayer.stateful||m.push(n))}f&&((n=n||{}).mask=c[0]);const g=toList$1(o.apply(u,n));let $=null;o.supportsMasking&&($=o.computeMask(u,c));const y=getNodeOutputs$1(s),b=Array.isArray(y)?y:[y];for(let e=0;e<b.length;++e){h.hasKey(b[e])||h.add(b[e],g[e],Array.isArray($)?$[0]:$);const t=i.indexOf(b[e].name);-1!==t&&(l[t]=g[e])}a||dispose$1(m)}return h.disposeMasks(),s?l:l[0]}function getTopologicalSortAndRecipientCounts$1(e,t){assert$6(null!=e&&e.length>0,()=>"Expected at least one fetch, got none");let n=[],r={};if(1===e.length){const a=getTopologicalSortAndRecipientCountsForOneFetch$1(e[0],t);n=a.sorted,r=a.recipientMap}else{const a=new Set;for(const s of e){const{sorted:e,recipientMap:o}=getTopologicalSortAndRecipientCountsForOneFetch$1(s,t);for(const t of e)a.has(t.name)||(n.push(t),a.add(t.name));for(const e in o)null==r[e]&&(r[e]=new Set),o[e].forEach(t=>r[e].add(t))}}return{sorted:n,recipientCounts:recipientMap2Counts$1(r)}}function recipientMap2Counts$1(e){const t={};for(const n in e)t[n]=e[n].size;return t}function getTopologicalSortAndRecipientCountsForOneFetch$1(e,t){const n=new Set,r=[],a={};for(const e of t.names())n.add(e);const s=[],o=[];for(s.push(e);s.length>0;){const e=s[s.length-1];if(n.has(e.name)){s.pop();continue}const t=o[o.length-1]===s.length-1;if(0===e.inputs.length||t)s.pop(),r.push(e),n.add(e.name),t&&o.pop();else{o.push(s.length-1);for(const t of e.inputs)null==a[t.name]&&(a[t.name]=new Set),a[t.name].add(e.name),n.has(t.name)||s.push(t)}}return{sorted:r,recipientMap:a}}function getNodeOutputs$1(e){let t;if(1===e.sourceLayer.inboundNodes.length)t=e.sourceLayer.output;else{let n=null;for(let t=0;t<e.sourceLayer.inboundNodes.length;++t)for(const r of e.sourceLayer.inboundNodes[t].outputTensors)if(r.id===e.id){n=t;break}t=e.sourceLayer.getOutputAt(n)}return t}class Container$1 extends Layer$1{constructor(e){if(super({}),this.containerNodes=new Set,this.name=e.name,null==this.name){const e=this.getClassName().toLowerCase();this.name=getUid$1(e)}if(this.supportsMasking=!1,this.trainable_=!0,this.inputs=Array.isArray(e.inputs)?e.inputs.slice():[e.inputs],this.outputs=Array.isArray(e.outputs)?e.outputs.slice():[e.outputs],unique$6(this.inputs).length!==this.inputs.length)throw new ValueError$1(`The list of inputs passed to the model is redundant. All inputs should only appear once. Found: ${this.inputs.map(e=>e.name)}`);unique$6(this.outputs).length!==this.outputs.length&&console.warn(`The list of outputs passed to the model is redundant. All outputs should only appear once. Found: ${this.outputs.map(e=>e.name)}`),this.inputLayers=[],this.inputLayersNodeIndices=[],this.inputLayersTensorIndices=[],this.outputLayers=[],this.outputLayersNodeIndices=[],this.outputLayersTensorIndices=[],this.layers=[],this.internalContainerRefs=[];for(const e of this.outputs){const t=e.nodeIndex,n=e.tensorIndex;this.outputLayers.push(e.sourceLayer),this.outputLayersNodeIndices.push(t),this.outputLayersTensorIndices.push(n)}for(const e of this.inputs){const t=e.sourceLayer,n=e.nodeIndex,r=e.tensorIndex;assert$5(0===n,"input layer has >1 nodes"),assert$5(0===r,"input layer has >1 tensors"),this.inputLayers.push(t),this.inputLayersNodeIndices.push(n),this.inputLayersTensorIndices.push(r)}this.inputNames=[],this.outputNames=[],this.feedInputShapes=[],this.feedInputNames=[],this.feedOutputNames=[];for(let t=0;t<this.inputLayers.length;t++){const n=this.inputLayers[t];if(!(n instanceof InputLayer$1))throw new TypeError(`Input layers to a LayersModel must be InputLayer objects. Received inputs: ${e.inputs}. Input ${t} (0-based) originates from layer type ${n.getClassName()}.`);this.inputNames.push(n.name),this.feedInputShapes.push(n.batchInputShape),this.feedInputNames.push(n.name)}for(const e of this.outputLayers)this.outputNames.push(e.name);this.internalInputShapes=this.inputs.map(e=>e.shape),this.internalOutputShapes=this.outputs.map(e=>e.shape);const t={},n={},r={},a={},s={},o=[],i=(e,t,n,r,a,l)=>{null!=r&&null!=a&&null!=l||(r=e.sourceLayer,a=e.nodeIndex,l=e.tensorIndex);const u=r.inboundNodes[a];if(-1!==n.indexOf(u))throw new RuntimeError$1(`The tensor ${e.name} at layer "${r.name}" is part of a cycle.`);if(-1!==t.indexOf(u))return;this.containerNodes.add(Container$1.nodeKey(r,a)),r.id in s||(s[r.id]=Object.keys(s).length),-1===n.indexOf(u)&&n.push(u);const c=u.inboundLayers.length;for(let e=0;e<c;e++)i(u.inputTensors[e],t,n,u.inboundLayers[e],u.nodeIndices[e],u.tensorIndices[e]);for(t.push(u);n.indexOf(u)>=0;)n.splice(n.indexOf(u),1);o.push(u)},l=[],u=[];for(const e of this.outputs)i(e,l,u);const c=o.slice().reverse();for(const e of c){n[e.id]=e,e.id in t||(t[e.id]=0);let s=t[e.id];s=Math.max(s,null==r[e.outboundLayer.id]?0:r[e.outboundLayer.id]),r[e.outboundLayer.id]=s,a[e.outboundLayer.id]=e.outboundLayer,t[e.id]=s;for(let r=0;r<e.inboundLayers.length;r++){const a=e.inboundLayers[r].inboundNodes[e.nodeIndices[r]];t[a.id]=Math.max(s+1,null==t[a.id]?0:t[a.id]),n[a.id]=a}}const p={};for(const e in t){const r=t[e];r in p||(p[r]=[]),p[r].push(n[e])}const d={};for(const e in r){const t=r[e];t in d||(d[t]=[]),d[t].push(a[e])}let h=Object.keys(d).map(e=>parseInt(e,10)).sort(reverseNumberCompare$1);this.layers=[];for(const e of h){const t=d[e];t.sort((e,t)=>{const n=s[e.id],r=s[t.id];return n<r?-1:n>r?1:0});for(const e of t)e instanceof Container$1&&this.internalContainerRefs.push(e),this.layers.push(e)}this.layersByDepth=d,h=Object.keys(p).map(e=>parseInt(e,10)).sort(reverseNumberCompare$1);const m=this.inputs.slice(),f=[];for(const e of h)for(const t of p[e]){const e=t.outboundLayer;if(null!=e){for(const n of t.inputTensors)if(-1===m.indexOf(n))throw new RuntimeError$1(`Graph disconnected: cannot obtain value for tensor ${n} at layer "${e.name}". The following previous layers were accessed without issue: ${f}`);for(const e of t.outputTensors)m.push(e);f.push(e.name)}}this.nodesByDepth=p;const g=this.layers.map(e=>e.name);for(const e of g){const t=g.filter(t=>t===e).length;if(1!==t)throw new RuntimeError$1(`The name "${e}" is used ${t} times in the model. All layer names should be unique. Layer names: `+JSON.stringify(g))}this.outboundNodes=[],this.inboundNodes=[],new Node$1({outboundLayer:this,inboundLayers:[],nodeIndices:[],tensorIndices:[],inputTensors:this.inputs,outputTensors:this.outputs,inputMasks:this.inputs.map(e=>null),outputMasks:this.outputs.map(e=>null),inputShapes:this.inputs.map(e=>e.shape),outputShapes:this.outputs.map(e=>e.shape)}),this.built=!0,this._refCount=1}assertNotDisposed(){if(0===this._refCount)throw new Error(`Container '${this.name}' is already disposed.`)}dispose(){this.assertNotDisposed();const e={refCountAfterDispose:null,numDisposedVariables:0};if(0==--this._refCount){for(const t of this.layers)e.numDisposedVariables+=t.dispose().numDisposedVariables;for(const t of this.internalContainerRefs)e.numDisposedVariables+=t.dispose().numDisposedVariables}return e.refCountAfterDispose=this._refCount,e}get trainable(){return this.trainable_}set trainable(e){this.layers.forEach(t=>{t._trainableWeights.forEach(t=>t.trainable=e)}),this.trainable_=e}get trainableWeights(){if(this._trainableWeights.length>0)throw new ValueError$1("Container instance unexpectedly contains _trainableWeights.The trainable weights of a Container are a union of the trainable weights of its consituent Layers. Its own _trainableWeights must remain an empty Array.");if(!this.trainable)return[];let e=[];for(const t of this.layers)e=e.concat(t.trainableWeights);return e}get nonTrainableWeights(){const e=[];for(const t of this.layers)e.push(...t.nonTrainableWeights);if(!this.trainable){const t=[];for(const e of this.layers)t.push(...e.trainableWeights);return t.concat(e)}return e}get weights(){return this.trainableWeights.concat(this.nonTrainableWeights)}loadWeights(e,t=!0){const n={};let r=0;for(const e of this.layers)for(const t of e.weights){if(null!=n[t.originalName])throw new ValueError$1(`Duplicate weight name: ${t.originalName}`);n[t.originalName]=t,r++}const a=[];for(const r in e){let s=r;if(null==n[r]){const e=r.split("/");s=e.slice(0,-2).concat([e[e.length-1]]).join("/")}if(null!=n[s])a.push([n[s],e[r]]);else if(t)throw new ValueError$1(`Provided weight data has no target variable: ${r}`);delete n[s]}if(t){const e=[];for(const t in n)e.push(t);if(e.length>0)throw new ValueError$1(`${e.length} of ${r} weights are not set: ${e}`)}batchSetValue$1(a)}updatedConfig(){const e=this.getConfig(),t={};return t.className=this.getClassName(),t.config=e,t.kerasVersion=`tfjs-layers ${version$d}`,t.backend="TensorFlow.js",t}toJSON(e,t=!0){const n=convertTsToPythonic$1(this.updatedConfig());return t?JSON.stringify(n):n}call(e,t){return tidy$1(()=>{e=toList$1(e);const n=new FeedDict$1;for(let t=0;t<this.inputs.length;++t)n.add(this.inputs[t],e[t]);return execute$1(this.outputs,n,t)})}computeMask(e,t){return tidy$1(()=>{let n;return e=toList$1(e),n=null==t?pyListRepeat$1(null,e.length):toList$1(t),this.runInternalGraph(e,n)[1]})}computeOutputShape(e){const t=normalizeShapeList$1(e);if(t.length!==this.inputLayers.length)throw new ValueError$1(`Invalid inputShape argument ${e}: model has ${this.inputLayers.length} tensor inputs.`);const n={};for(let e=0;e<t.length;e++)n[this.inputLayers[e].name+"_0_0"]=t[e];const r=Object.keys(this.nodesByDepth).map(e=>parseInt(e,10)).sort(reverseNumberCompare$1);if(r.length>1)for(const e of r){const t=this.nodesByDepth[e];for(const e of t){const t=e.outboundLayer;if(-1!==this.inputLayers.map(e=>e.id).indexOf(t.id))continue;const r=[];for(let t=0;t<e.inboundLayers.length;t++)r.push(n[`${e.inboundLayers[t].name}_${e.nodeIndices[t]}_${e.tensorIndices[t]}`]);const a=normalizeShapeList$1(t.computeOutputShape(singletonOrArray$1(r))),s=t.inboundNodes.indexOf(e);for(let e=0;e<a.length;e++)n[`${t.name}_${s}_${e}`]=a[e]}}const a=[],s=[];for(let e=0;e<this.outputLayers.length;e++)s.push(`${this.outputLayers[e].name}_${this.outputLayersNodeIndices[e]}_${this.outputLayersTensorIndices[e]}`);for(let e=0;e<s.length;e++){const t=s[e];assert$5(t in n),a.push(n[t])}return singletonOrArray$1(a)}runInternalGraph(e,t){null==t&&(t=pyListRepeat$1(null,e.length));const n={};for(let r=0;r<this.inputs.length;++r)n[this.inputs[r].id]=[e[r],t[r]];const r=Object.keys(this.nodesByDepth).map(e=>parseInt(e,10)).sort(reverseNumberCompare$1);for(const e of r){const t=this.nodesByDepth[e];for(const e of t){const t=e.outboundLayer,r=e.inputTensors,a=e.outputTensors,s=new Array;for(const e of r)e.id in n&&s.push(n[e.id]);if(s.length===r.length){let r,o,i,l,u={};if(null!=e.callArgs&&(u=e.callArgs),1===s.length){const[e,n]=s[0];null==u.mask&&(u.mask=n),i=toList$1(t.call(e,u)),l=toList$1(t.computeMask(e,n)),r=[e],o=[n]}else r=s.map(e=>e[0]),o=s.map(e=>e[1]),null==u.mask&&(u.mask=o),i=toList$1(t.call(r,u)),l=toList$1(t.computeMask(r,o));if(t.activityRegularizer)throw new NotImplementedError$1("LayersModel invocation with concrete Tensor value(s) in the presence of activity regularizer(s) is not supported yet.");for(let e=0;e<a.length;++e)n[a[e].id]=[i[e],l[e]]}}}const a=[],s=[],o=[];for(const e of this.outputs){assert$5(e.id in n,`Could not compute output ${e.name} : ${e.id}`);const[t,r]=n[e.id];o.push(t.shape),a.push(t),s.push(r)}return[a,s,o]}buildNodeConversionMap(e){const t={};let n;for(const e of this.layers){n=e instanceof Container$1?1:0;for(let r=0;r<e.inboundNodes.length;r++){const a=Container$1.nodeKey(e,r);this.containerNodes.has(a)&&(t[a]=n,n+=1)}}return t}getLayer(e,t){if(null!=t){if(this.layers.length<=t)throw new ValueError$1(`Was asked to retrieve layer at index ${t}, but model only has ${this.layers.length} layer(s).`);return this.layers[t]}if(null==e)throw new ValueError$1("Provide either a layer name or layer index");for(const t of this.layers)if(t.name===e)return t;throw new ValueError$1(`No such layer: ${e}`)}calculateLosses(){return tidy$1(()=>{const e=[];for(const t of this.layers)for(let n=0;n<t.inboundNodes.length;++n){const r=Container$1.nodeKey(t,n);this.containerNodes.has(r)&&e.push(...t.calculateLosses())}return e})}getConfig(){const e={name:this.name},t=this.buildNodeConversionMap(this.layers),n=[];for(const e of this.layers){const r=e.getClassName(),a=e.getConfig(),s=[];for(let n=0;n<e.inboundNodes.length;n++){const r=e.inboundNodes[n],a=Container$1.nodeKey(e,n);let o={};if(this.containerNodes.has(a)){if(r.callArgs)try{JSON.stringify(r.callArgs),o=r.callArgs}catch(t){console.warn(`Layer ${e.name} was passed non-serializable keyword arguments: ${r.callArgs}. They will not be included in the serialized model (and thus will be missing at deserialization time).`),o={}}if(r.inboundLayers.length>0){const e=[];for(let n=0;n<r.inboundLayers.length;n++){const a=r.inboundLayers[n],s=r.tensorIndices[n];let i=t[Container$1.nodeKey(a,r.nodeIndices[n])];null==i&&(i=0),e.push([a.name,i,s,o])}s.push(e)}}}const o={};o.name=e.name,o.className=r,o.config=a,o.inboundNodes=s,n.push(o)}e.layers=n;const r=[];for(let e=0;e<this.inputLayers.length;e++){const n=this.inputLayers[e],a=Container$1.nodeKey(n,this.inputLayersNodeIndices[e]);if(!this.containerNodes.has(a))continue;let s=t[a];null==s&&(s=0),r.push([n.name,s,this.inputLayersTensorIndices[e]])}e.inputLayers=r;const a=[];for(let e=0;e<this.outputLayers.length;e++){const n=this.outputLayers[e],r=Container$1.nodeKey(n,this.outputLayersNodeIndices[e]);if(!this.containerNodes.has(r))continue;let s=t[r];null==s&&(s=0),a.push([n.name,s,this.outputLayersTensorIndices[e]])}return e.outputLayers=a,e}static fromConfig(e,t,n={},r=!1){const a={},s={};function o(e,t){e.name in s?s[e.name].push(t):s[e.name]=[t]}function i(e,t){const n=[];let r;for(const s of t){const i=s[0],l=s[1],u=s[2];if(r=null==s[3]?{}:s[3],!(i in a))return void o(e,t);const c=a[i];if(c.inboundNodes.length<=l)return void o(e,t);n.push(c.inboundNodes[l].outputTensors[u])}n.length>0&&e.apply(singletonOrArray$1(n),r)}function l(e){const n=e.name,s=deserialize$1(e,null!=t.customObjects?t.customObjects:{});s.setFastWeightInitDuringBuild(r),a[n]=s,e.inboundNodes.forEach(e=>{if(!(e instanceof Array))throw new ValueError$1(`Corrupted configuration, expected array for nodeData: ${e}`);o(s,e)})}const u=t.name,c=t.layers;for(const e of c)l(e);for(;!isObjectEmpty$1(s);)for(const e of c){const t=a[e.name];if(t.name in s){const e=s[t.name];delete s[t.name];for(const n of e)i(t,n)}}const p=[],d=[],h=t.inputLayers;for(const e of h){const t=e[0],n=e[1],r=e[2];assert$5(t in a),p.push(a[t].inboundNodes[n].outputTensors[r])}const m=t.outputLayers;for(const e of m){const t=e[0],n=e[1],r=e[2];assert$5(t in a),d.push(a[t].inboundNodes[n].outputTensors[r])}return new e({inputs:p,outputs:d,name:u})}get stateful(){if(this._stateful)throw new ValueError$1("Container instance unexpectedly has _stateful = true. The statefulness of a Container is determined by the Layers it contains. Its _stateful property must remain the default false.");for(const e of this.layers)if(e.stateful)return!0;return!1}resetStates(){tidy$1(()=>{this.layers.forEach(e=>{e.stateful&&e.resetStates()})})}}function standardizeSampleOrClassWeights$1(e,t,n){const r=t.length;if(null==e||Array.isArray(e)&&0===e.length)return t.map(e=>null);if(1===r)return Array.isArray(e)&&1===e.length?e:"object"==typeof e&&t[0]in e?[e[t[0]]]:[e];if(Array.isArray(e)){if(e.length!==r)throw new Error(`Provided ${n} is an array of ${e.length} element(s), but the model has ${r} outputs. Make sure a set of weights is provided for each model output.`);return e}if("object"==typeof e&&Object.keys(e).length>0&&"object"==typeof e[Object.keys(e)[0]]){const n=[];return t.forEach(t=>{n.push(t in e?e[t]:null)}),n}throw new Error(`The model has multiple (${r}) outputs, so ${n} must be either an array with ${r} elements or an object with ${t} keys. Provided ${n} not understood: ${JSON.stringify(e)}`)}function standardizeClassWeights$1(e,t){return standardizeSampleOrClassWeights$1(e,t,"classWeight")}async function standardizeWeights$1(e,t,n,r){if(null!=t||null!=r)throw new Error("Support sampleWeight is not implemented yet");if(null!=n){const t=tidy$1(()=>{if(1===e.shape.length)return clone$1(e);if(2===e.shape.length){if(e.shape[1]>1)return argMax$5(e,1);if(1===e.shape[1])return reshape$6(e,[e.shape[0]]);throw new Error(`Encountered unexpected last-dimension size (${e.shape[1]}) during handling of class weights. The size is expected to be >= 1.`)}throw new Error(`Unexpected rank of target (y) tensor (${e.rank}) during handling of class weights. The rank is expected to be 1 or 2.`)}),r=Array.from(await t.data());dispose$1(t);const a=[];return r.forEach(e=>{if(null==n[e])throw new Error(`classWeight must contain all classes in the training data. The class ${e} exists in the data but not in classWeight`);a.push(n[e])}),tensor1d$1(a,"float32")}return null}function computeWeightedLoss$2(e,t){return mul$1(e,t)}const DEFAULT_VALIDATION_BATCH_SIZE$1=32;function standardizeDataIteratorOutput$1(e,t){let n,r;n=t.xs,r=t.ys,assert$6(null!=n&&null!=r,()=>`A Dataset iterator for fitDataset() is expected to generate objects of the form \`{xs: xVal, ys: yVal}\`, where the two values may be \`tf.Tensor\`, an array of Tensors, or a map of string to Tensor.  The provided Dataset instead generates ${t}`);const a=flattenTensorOrArrayOrMap$1("input",e.inputNames,n),s=flattenTensorOrArrayOrMap$1("output",e.outputNames,r),o=a[0].shape[0];assert$6(a.length===e.inputs.length,()=>`LayersModel has ${e.inputs.length} inputs, but the dataset provides ${a.length} inputs.  (Expected input keys: ${JSON.stringify(e.inputNames)})`),assert$6(s.length===e.outputs.length,()=>`LayersModel has ${e.outputs.length} outputs, but the dataset provides ${s.length} outputs.  (Expected output keys: ${JSON.stringify(e.outputNames)})`);for(let t=0;t<a.length;t++)assert$6(a[t].shape[0]===o,()=>`Batch size mismatch: input ${e.inputNames[t]} has ${a[t].shape[0]}; expected  ${o} based on input ${e.inputNames[0]}.`);for(let t=0;t<s.length;t++)assert$6(s[t].shape[0]===o,()=>`Batch size mismatch: output ${e.outputNames[t]} has ${s[t].shape[0]}; expected  ${o} based on input ${e.inputNames[0]}.`);return{xs:a,ys:s}}function flattenTensorOrArrayOrMap$1(e,t,n){if(n instanceof Tensor$1)return[n];if(Array.isArray(n))return assert$6(n.length===t.length,()=>`Received an array of ${n.length} Tensors, but expected ${t.length} to match the ${e} keys ${t}.`),n;{const r=[];for(const a of t){if(null==n[a])throw new ValueError$1(`The feature data generated by the dataset lacks the required ${e} key '${a}'.`);r.push(n[a])}return r}}function standardizeTensorValidationData$1(e){if(3===e.length)throw new NotImplementedError$1("Validation with sample weights is not implemented yet.");return{xs:e[0],ys:e[1]}}async function fitDataset$1(e,t,n){const r=null!=n.batchesPerEpoch;if(assert$6(null!=e.optimizer,()=>"You must compile a model before training/testing. Use LayersModel.compile(modelCompileConfig)."),assert$6(null!=n,()=>"For fitDataset(), the 2nd argument (config) is required, but it is not provided in this call."),assert$6(null!=n.epochs&&n.epochs>0&&Number.isInteger(n.epochs),()=>`For fitDataset(), config.epochs is expected to be a positive integer, but got ${n.epochs}`),assert$6(!r||n.batchesPerEpoch>0&&Number.isInteger(n.batchesPerEpoch),()=>`For fitDataset(), config.batchesPerEpoch is expected to be a positive integer if specified, but got ${n.batchesPerEpoch}`),assert$6(null==n.validationSplit,()=>"`validationSplit` is not supported by `fitDataset()`. Use validationData instead."),e.isTraining)throw new Error("Cannot start training because another fit() call is ongoing.");e.isTraining=!0;try{const a=null!=n.validationData;let s,o;if(a)if(isDatasetObject$1(n.validationData))assert$6(null==n.validationBatches||n.validationBatches>0&&Number.isInteger(n.validationBatches),()=>`For fitDataset() with dataset-based validation, config.validationBatches is expected not to be provided, or to be a positive integer, but got ${n.validationBatches}`);else{const e=standardizeTensorValidationData$1(n.validationData);s=e.xs,o=e.ys}const i=e.makeTrainFunction(),l=e.getDedupedMetricsNames();let u;u=a?l.slice().concat(l.map(e=>"val_"+e)):l.slice();const c=standardizeCallbacks$1(n.callbacks,n.yieldEvery),p=null==n.verbose?1:n.verbose,{callbackList:d,history:h}=configureCallbacks$1(c,p,n.epochs,null,null,getStepsPerEpoch$1(t,n),null,a,u);d.setModel(e),e.history=h,await d.onTrainBegin(),e.stopTraining_=!1;let m=null==n.initialEpoch?0:n.initialEpoch,f=await t.iterator();for(;m<n.epochs;){const u={};await d.onEpochBegin(m);let c=0,p=0;for(r||(f=await t.iterator());!r||c<n.batchesPerEpoch;){const t=await f.next();if(r&&t.done){console.warn(`You provided \`batchesPerEpoch\` as ${n.batchesPerEpoch}, but your dataset iterator ran out of data after ${c} batches; interrupting training. Make sure that your dataset can generate at least \`batchesPerEpoch * epochs\` batches (in this case, `+n.batchesPerEpoch*n.epochs+" batches). You may need to use the repeat() function when building your dataset.");break}if(null!=t.value){const{xs:r,ys:a}=standardizeDataIteratorOutput$1(e,t.value),s={};s.batch=p,s.size=r[0].shape[0],await d.onBatchBegin(p,s);const o=[];if(null!=n.classWeight){const t=standardizeClassWeights$1(n.classWeight,e.outputNames);for(let e=0;e<t.length;++e)o.push(await standardizeWeights$1(a[e],null,t[e]))}const u=r.concat(a).concat(o),h=i(u);dispose$1(u);for(let e=0;e<l.length;++e){const t=h[e];s[l[e]]=t,keep$1(t)}await d.onBatchEnd(p,s),disposeTensorsInLogs$1(s),p++,c++}if(r?c>=n.batchesPerEpoch:t.done){if(a){let t;t=isDatasetObject$1(n.validationData)?toList$1(await e.evaluateDataset(n.validationData,{batches:n.validationBatches})):toList$1(e.evaluate(s,o,{batchSize:null==n.validationBatchSize?DEFAULT_VALIDATION_BATCH_SIZE$1:n.validationBatchSize,verbose:0}));for(let n=0;n<e.metricsNames.length;++n)u[`val_${e.metricsNames[n]}`]=t[n]}break}if(e.stopTraining_)break}if(await d.onEpochEnd(m,u),m++,e.stopTraining_)break}return await d.onTrainEnd(),await e.history.syncData(),e.history}finally{e.isTraining=!1}}function getStepsPerEpoch$1(e,t){let n=null;return null!=t.batchesPerEpoch?n=t.batchesPerEpoch:Number.isFinite(e.size)&&(n=e.size),n}function isDatasetObject$1(e){return"function"==typeof e.iterator}function isLazyIteratorObject$1(e){return"function"==typeof e.next}async function evaluateDataset$1(e,t,n){const r=null!=(n=n||{}).batches,a=e.testFunction;let s=[];if(n.verbose>0)throw new NotImplementedError$1("Verbose mode is not implemented yet.");assert$6(!r||n.batches>0&&Number.isInteger(n.batches),()=>`Test loop expects \`batches\` to be a positive integer, but received ${JSON.stringify(n.batches)}`);const o=isLazyIteratorObject$1(t)?t:await t.iterator();let i=0,l=0;for(;!r||l<n.batches;){const t=await o.next();if(s=tidy$1(()=>{if(t.value){const{xs:n,ys:r}=standardizeDataIteratorOutput$1(e,t.value),o=n.concat(r),u=tidy$1(()=>a(o));if(dispose$1(o),0===l)for(let e=0;e<u.length;++e)s.push(scalar$1(0));const c=o[0].shape[0];for(let e=0;e<u.length;++e){const t=u[e],n=s[e];s[e]=tidy$1(()=>add$5(s[e],mul$1(c,t))),l>0&&dispose$1(n)}dispose$1(u),i+=c,++l}return s}),t.done){r&&console.warn(`Your dataset iterator ran out of data during evaluateDataset(). Interrupting evalution. Make sure that your dataset can generate at least \`batches\` batches (in this case, ${n.batches} batches). You may need to use the repeat() function when building your dataset.`);break}}for(let e=0;e<s.length;++e){const t=s[e];s[e]=div$3(s[e],i),dispose$1(t)}return singletonOrArray$1(s)}function checkBatchSize$1(e){assert$6(e>0&&Number.isInteger(e),()=>`batchSize is required to be a positive integer, but got ${e}`)}function sliceArrays$1(e,t,n){return null==e?[null]:Array.isArray(e)?e.map(e=>sliceAlongFirstAxis$1(e,t,n-t)):sliceAlongFirstAxis$1(e,t,n-t)}function sliceArraysByIndices$1(e,t){return tidy$1(()=>null==e?null:Array.isArray(e)?e.map(e=>sliceArraysByIndices$1(e,t)):gather$2(e,"int32"===t.dtype?t:cast$7(t,"int32")))}function makeBatches$1(e,t){const n=[];let r=0,a=null;for(;r<e;)a=r+t,a>=e&&(a=e),n.push([r,a]),r=a;return n}async function fitLoop$1(e,t,n,r,a,s,o,i,l,u,c,p,d,h,m){null==a&&(a=32),null==s&&(s=1),null==c&&(c=!0),null==d&&(d=0);let f=!1;if(null!=l&&null!=u&&(f=!0),null!=m&&(f=!0,null==h))throw new ValueError$1("Can only use `validationSteps` when doing step-wise training, i.e., `stepsPerEpoch` must be set.");const g=e.checkNumSamples(n,a,h,"steps_per_epoch");let $;null!=g&&($=range$7(0,g)),null==o&&(o=1);const{callbackList:y,history:b}=configureCallbacks$1(i,o,s,d,g,h,a,f,p);y.setModel(e),e.history=b,await y.onTrainBegin(),e.stopTraining_=!1;for(let o=d;o<s;++o){await y.onEpochBegin(o);const s={};if(null!=h)throw new NotImplementedError$1("stepsPerEpoch mode is not implemented yet.");{if("batch"===c)throw new NotImplementedError$1("batch shuffling is not implemneted yet");c&&shuffle$1($);const o=tensor1d$1($),i=makeBatches$1(g,a);for(let c=0;c<i.length;++c){const p={};if(await y.onBatchBegin(c,p),tidy$1(()=>{const d=i[c][0],h=i[c][1],m=sliceAlongFirstAxis$1(o,d,h-d);p.batch=c,p.size=h-d;const g=sliceArraysByIndices$1(n,m),$=t(g);for(let e=0;e<r.length;++e){const t=$[e];p[r[e]]=t,keep$1(t)}if(c===i.length-1&&f){const t=e.testLoop(l,u,a);for(let e=0;e<r.length;++e){const n=r[e],a=t[e];keep$1(a),s["val_"+n]=a}}}),await y.onBatchEnd(c,p),disposeTensorsInLogs$1(p),e.stopTraining_)break}o.dispose()}if(await y.onEpochEnd(o,s),e.stopTraining_)break}return await y.onTrainEnd(),await e.history.syncData(),e.history}async function fitTensors$1(e,t,n,r={}){if(e.isTraining)throw new Error("Cannot start training because another fit() call is ongoing.");let a,s,o,i,l,u,c;e.isTraining=!0;try{const p=null==r.batchSize?32:r.batchSize;checkBatchSize$1(p);const d=!1,h=await e.standardizeUserData(t,n,r.sampleWeight,r.classWeight,d,p);a=h[0],s=h[1],c=h[2];let m,f=!1;if(null!=r.validationData&&r.validationData.length>0){if(f=!0,2!==r.validationData.length)throw 3===r.validationData.length?new NotImplementedError$1("validationData including sample weights is not supported yet."):new ValueError$1(`When passing validation data, it must contain 2 (valX, valY) or 3 (valX, valY, valSampleWeight) items; ${r.validationData} is invalid.`);o=r.validationData[0],i=r.validationData[1];const t=!0,n=await e.standardizeUserData(o,i,null,null,t,p);l=n[0],u=n[1],m=l.concat(u)}else if(null!=r.validationSplit&&r.validationSplit>0&&r.validationSplit<1){f=!0;const e=Math.floor(a[0].shape[0]*(1-r.validationSplit)),t=a[0].shape[0];l=sliceArrays$1(a,e,t),a=sliceArrays$1(a,0,e),u=sliceArrays$1(s,e,t),s=sliceArrays$1(s,0,e),m=l.concat(u)}else null!=r.validationSteps&&(f=!0);const g=a.concat(s).concat(c);e.checkTrainableWeightsConsistency();const $=e.makeTrainFunction(),y=e.getDedupedMetricsNames();let b,x;f?(e.makeTestFunction(),b=e.testFunction,x=y.slice().concat(y.map(e=>"val_"+e))):(b=null,m=[],x=y.slice());const v=standardizeCallbacks$1(r.callbacks,r.yieldEvery);return await fitLoop$1(e,$,g,y,p,r.epochs,r.verbose,v,b,m,r.shuffle,x,r.initialEpoch,null,null)}finally{e.isTraining=!1,disposeNewTensors$1(a,t),disposeNewTensors$1(s,n),disposeNewTensors$1(l,o),disposeNewTensors$1(u,i),null!=c&&dispose$1(c)}}function ensureTensorsRank2OrHigher$1(e){const t=[];e instanceof Tensor$1&&(e=[e]);for(let n=0;n<e.length;++n){const r=e[n];if(1===r.rank)t.push(expandDims$6(r,1));else{if(0===r.rank)throw new Error("Expected tensor to be at least 1D, but received a 0D tensor (scalar).");t.push(r)}}return t}function disposeNewTensors$1(e,t){if(null==e)return;const n=[];if(t instanceof Tensor$1)n.push(t.id);else if(Array.isArray(t))t.forEach(e=>n.push(e.id));else if(null!=t)for(const e in t)n.push(t[e].id);const r=[];if(e instanceof Tensor$1)-1===n.indexOf(e.id)&&r.push(e);else if(Array.isArray(e))e.forEach(e=>{-1===n.indexOf(e.id)&&r.push(e)});else if(null!=e)for(const t in e){const a=e[t];-1===n.indexOf(a.id)&&r.push(a)}r.forEach(e=>{e.isDisposed||e.dispose()})}function isDataTensor$1(e){return e instanceof Tensor$1}function isDataArray$1(e){return Array.isArray(e)}function isDataDict$1(e){return!isDataTensor$1(e)&&!isDataArray$1(e)}function standardizeInputData$1(e,t,n,r=!0,a=""){if(null==t||0===t.length){if(null!=e){let t=!1;if(isDataArray$1(e)&&e.length>0)t=!0;else if(isDataDict$1(e)){for(const n in e)if(e.hasOwnProperty(n)){t=!0;break}}else t=!0;if(t)throw new ValueError$1(`Error when checking model ${a} expected no data, but got ${e}`)}return[]}if(null==e)return t.map(e=>null);let s;if(isDataDict$1(e)){e=e,s=[];for(const n of t){if(null==e[n])throw new ValueError$1(`No data provided for "${n}". Need data for each key in: ${t}`);s.push(e[n])}}else if(isDataArray$1(e)){if((e=e).length!==t.length)throw new ValueError$1(`Error when checking model ${a}: the Array of Tensors that you are passing to your model is not the size the model expected. Expected to see ${t.length} Tensor(s), but instead got the following list of Tensor(s): ${e}`);s=e}else{if(e=e,t.length>1)throw new ValueError$1(`The model ${a} expects ${t.length} Tensor(s), but only received one Tensor. Found: Tensor with shape ${e.shape}`);s=[e]}if(s=ensureTensorsRank2OrHigher$1(s),null!=n)for(let e=0;e<t.length;++e){if(null==n[e])continue;const o=s[e];if(o.shape.length!==n[e].length)throw new ValueError$1(`Error when checking ${a}: expected ${t[e]} to have ${n[e].length} dimension(s). but got array with shape ${o.shape}`);for(let s=0;s<n[e].length;++s){if(0===s&&!r)continue;const i=o.shape[s],l=n[e][s];if(null!=l&&l>=0&&i!==l)throw new ValueError$1(`Error when checking ${a}: expected ${t[e]} to have shape [${n[e]}], but got array with shape [${o.shape}].`)}}return s}function checkArrayLengths$1(e,t,n){const r=unique$6(e.map(e=>e.shape[0]));r.sort();const a=unique$6(t.map(e=>e.shape[0]));if(a.sort(),r.length>1)throw new ValueError$1(`All input Tensors (x) should have the same number of samples. Got array shapes: ${JSON.stringify(e.map(e=>e.shape))}`);if(a.length>1)throw new ValueError$1(`All target Tensors (y) should have the same number of samples. Got array shapes: ${JSON.stringify(t.map(e=>e.shape))}`);if(r.length>0&&a.length>0&&!arraysEqual$1(r,a))throw new ValueError$1(`Input Tensors should have the same number of samples as target Tensors. Found ${r[0]} input sample(s) and ${a[0]} target sample(s).`)}function checkLossAndTargetCompatibility$1(e,t,n){const r=[meanSquaredError$3,binaryCrossentropy$4,categoricalCrossentropy$4];for(let a=0;a<e.length;++a){const s=e[a],o=t[a],i=n[a];if(null!=o){if(o===categoricalCrossentropy$4&&1===s.shape[s.shape.length-1])throw new ValueError$1(`You are passing a target array of shape ${s.shape} while using a loss 'categorical_crossentropy'. 'categorical_crossentropy'expects targets to be binary matrices (1s and 0s) of shape [samples, classes].`);if(-1!==r.indexOf(o)){const e=s.shape.slice(1),t=i.slice(1);for(let n=0;n<e.length;++n){const r=e[n],a=t[n];if(null!=a&&r!==a)throw new ValueError$1(`A target Tensor with shape ${s.shape} was passed for an output of shape ${i}, while using a loss function that expects targets to have the same shape as the output.`)}}}}}function checkInputData$1(e,t,n,r=!0,a=""){let s;if(Array.isArray(e)){if(e.length!==t.length)throw new ValueError$1(`Error when checking model ${a}: the Array of Tensors that you are passing to your model is not the size the the model expected. Expected to see ${t.length} Tensor(s), but instead got ${e.length} Tensors(s).`);s=e}else{if(t.length>1)throw new ValueError$1(`The model expects ${t.length} ${a} Tensors, but only received one Tensor. Found: array with shape ${JSON.stringify(e.shape)}.`);s=[e]}if(null!=n)for(let e=0;e<t.length;++e){if(null==n[e])continue;const o=s[e];if(o.shape.length!==n[e].length)throw new ValueError$1(`Error when checking ${a}: expected ${t[e]} to have ${n[e].length} dimension(s), but got array with shape ${JSON.stringify(o.shape)}`);for(let s=0;s<n[e].length;++s){if(0===s&&!r)continue;const i=o.shape[s],l=n[e][s];if(null!=l&&l!==i)throw new ValueError$1(`Error when checking ${a}: expected ${t[e]} to have shape ${JSON.stringify(n[e])} but got array with shape ${JSON.stringify(o.shape)}.`)}}}function collectMetrics$1(e,t){if(null==e||Array.isArray(e)&&0===e.length)return t.map(e=>[]);let n;if("string"==typeof e||"function"==typeof e)n=[e];else{if(!Array.isArray(e)&&"object"!=typeof e)throw new TypeError(`Type of metrics argument not understood. Expected an string,function, Array, or Object, found: ${e}`);n=e}if(Array.isArray(n))return t.map(e=>n);{const e=[];for(const r of t){let t=n.hasOwnProperty(r)?n[r]:[];Array.isArray(t)||(t=[t]),e.push(t)}return e}}const LAYERS_MODEL_FORMAT_NAME$1="layers-model";class LayersModel$1 extends Container$1{constructor(e){super(e),this.isTraining=!1}summary(e,t,n=console.log){if(!this.built)throw new ValueError$1("This model has never been called, thus its weights have not been created yet. So no summary can be displayed. Build the model first (e.g., by calling it on some test data).");printSummary$1(this,e,t,n)}compile(e){if(null==e.loss&&(e.loss=[]),this.loss=e.loss,"string"==typeof e.optimizer)this.optimizer_=getOptimizer$1(e.optimizer),this.isOptimizerOwned=!0;else{if(!(e.optimizer instanceof Optimizer$1))throw new ValueError$1("User-defined optimizer must be an instance of tf.Optimizer.");this.optimizer_=e.optimizer,this.isOptimizerOwned=!1}let t=[];if(Array.isArray(e.loss)||"string"==typeof e.loss||"function"==typeof e.loss)if(Array.isArray(e.loss)){if(e.loss.length!==this.outputs.length)throw new ValueError$1(`When passing an Array as loss, it should have one entry per model output. The model has ${this.outputs.length} output(s), but you passed loss=${e.loss}.`);t=e.loss.map(e=>get$3(e))}else{const n=get$3(e.loss);this.outputs.forEach(e=>{t.push(n)})}else{e.loss=e.loss;for(const t in e.loss)if(-1===this.outputNames.indexOf(t))throw new ValueError$1(`Unknown entry in loss dictionary: "${t}". Only expected the following keys: ${this.outputNames}`);for(const n of this.outputNames)null==e.loss[n]&&console.warn(`Output "${n}" is missing from loss dictionary. We assume this was done on purpose, and we will not be expecting data to be passed to ${n} during training`),t.push(get$3(e.loss[n]))}this.lossFunctions=t,this.feedOutputNames=[],this.feedOutputShapes=[],this.feedLossFns=[];for(let e=0;e<this.outputs.length;++e){const t=this.internalOutputShapes[e];this.feedOutputNames.push(this.outputNames[e]),this.feedOutputShapes.push(t),this.feedLossFns.push(this.lossFunctions[e])}const n=[];this.metrics=e.metrics,this.metricsNames=["loss"],this.metricsTensors=[],nameScope$1("loss",()=>{for(let e=0;e<this.outputs.length;++e){if(-1!==n.indexOf(e))continue;const t=this.lossFunctions[e];this.outputs.length>1&&(this.metricsTensors.push([t,e]),this.metricsNames.push(this.outputNames[e]+"_loss"))}});const r=collectMetrics$1(e.metrics,this.outputNames),a=(e,t,n)=>{this.outputNames.length>1&&(t=this.outputNames[e]+"_"+t),this.metricsNames.push(t),this.metricsTensors.push([n,e])};nameScope$1("metric",()=>{for(let e=0;e<this.outputs.length;++e)-1===n.indexOf(e)&&(t=>{let n,r,s;for(const o of t){if("string"==typeof o&&-1!==["accuracy","acc","crossentropy","ce"].indexOf(o)){const t=this.internalOutputShapes[e];let a;1===t[t.length-1]||this.lossFunctions[e]===binaryCrossentropy$4?-1!==["accuracy","acc"].indexOf(o)?r=binaryAccuracy$2:-1!==["crossentropy","ce"].indexOf(o)&&(r=binaryCrossentropy$3):this.lossFunctions[e]===sparseCategoricalCrossentropy$3?-1!==["accuracy","acc"].indexOf(o)?r=sparseCategoricalAccuracy$2:-1!==["crossentropy","ce"].indexOf(o)&&(r=sparseCategoricalCrossentropy$2):-1!==["accuracy","acc"].indexOf(o)?r=categoricalAccuracy$2:-1!==["crossentropy","ce"].indexOf(o)&&(r=categoricalCrossentropy$3),-1!==["accuracy","acc"].indexOf(o)?a="acc":-1!==["crossentropy","ce"].indexOf(o)&&(a="ce"),s=r,n=""+a}else{const e=get$2(o);s=e,n=""+getLossOrMetricName$1(o)}let t;nameScope$1(n,()=>{t=s}),a(e,n,t)}})(r[e])}),this.collectedTrainableWeights=this.trainableWeights}checkTrainableWeightsConsistency(){null!=this.collectedTrainableWeights&&this.trainableWeights.length!==this.collectedTrainableWeights.length&&console.warn("Discrepancy between trainableweights and collected trainable weights. Did you set `model.trainable` without calling `model.compile()` afterwards?")}evaluate(e,t,n={}){const r=null==n.batchSize?32:n.batchSize;checkBatchSize$1(r);const a=this.standardizeUserDataXY(e,t,!0,r);try{const s=a[0].concat(a[1]);return this.makeTestFunction(),singletonOrArray$1(this.testLoop(this.testFunction,s,r,n.verbose,n.steps))}finally{disposeNewTensors$1(a[0],e),disposeNewTensors$1(a[1],t)}}async evaluateDataset(e,t){return this.makeTestFunction(),evaluateDataset$1(this,e,t)}checkNumSamples(e,t,n,r="steps"){let a;if(null!=n){if(a=null,null!=t)throw new ValueError$1(`If ${r} is set, batchSize must be null or undefined.Got batchSize = ${t}`)}else{if(null==e)throw new ValueError$1(`Either the input data should have a defined shape, or ${r} shoud be specified.`);a=Array.isArray(e)?e[0].shape[0]:e.shape[0]}return a}execute(e,t){if(Array.isArray(t)&&0===t.length)throw new ValueError$1("`outputs` is an empty Array, which is not allowed.");const n=Array.isArray(t),r=this.retrieveSymbolicTensors(n?t:[t]),a=new FeedDict$1;if(e instanceof Tensor$1&&(e=[e]),Array.isArray(e)){if(e.length!==this.inputs.length)throw new ValueError$1(`The number of inputs provided (${e.length}) does not match the number of inputs of this model (${this.inputs.length}).`);for(let t=0;t<this.inputs.length;++t)a.add(this.inputs[t],e[t])}else for(const t of this.inputs){const n=e[t.name];if(null==n)throw new ValueError$1(`No value is provided for the model's input ${t.name}`);a.add(t,n)}const s=execute$1(r,a);return n?s:s[0]}retrieveSymbolicTensors(e){const t=pyListRepeat$1(null,e.length);let n=e.length;for(const r of this.layers){const a=Array.isArray(r.output)?r.output:[r.output],s=a.map(e=>e.name);for(let r=0;r<e.length;++r){const o=s.indexOf(e[r]);if(-1!==o&&(t[r]=a[o],n--),0===n)break}if(0===n)break}if(n>0){const n=[];throw t.forEach((t,r)=>{null==t&&n.push(e[r])}),new ValueError$1(`Cannot find SymbolicTensors for output name(s): ${JSON.stringify(n)}`)}return t}predictLoop(e,t=32,n=!1){return tidy$1(()=>{const r=this.checkNumSamples(e);if(n)throw new NotImplementedError$1("Verbose predictLoop() is not implemented yet.");const a=makeBatches$1(r,t),s=this.outputs.map(e=>[]);for(let t=0;t<a.length;++t)tidy$1(()=>{const n=sliceArrays$1(e,a[t][0],a[t][1]),r=[];if(Array.isArray(n))for(let e=0;e<n.length;++e)r.push({key:this.inputs[e],value:n[e]});else r.push({key:this.inputs[0],value:n});const s=new FeedDict$1(r);return execute$1(this.outputs,s)}).forEach((e,t)=>s[t].push(e));return singletonOrArray$1(s.map(e=>concat$5(e,0)))})}predict(e,t={}){const n=ensureTensorsRank2OrHigher$1(e);checkInputData$1(n,this.inputNames,this.feedInputShapes,!1);try{const r=null==t.batchSize?32:t.batchSize;return checkBatchSize$1(r),this.predictLoop(n,r)}finally{disposeNewTensors$1(n,e)}}predictOnBatch(e){checkInputData$1(e,this.inputNames,this.feedInputShapes,!0);const t=(Array.isArray(e)?e[0]:e).shape[0];return this.predictLoop(e,t)}standardizeUserDataXY(e,t,n=!0,r){if(null==this.optimizer_)throw new RuntimeError$1("You must compile a model before training/testing. Use LayersModel.compile(modelCompileArgs).");const a=[];for(let e=0;e<this.feedOutputShapes.length;++e){const t=this.feedOutputShapes[e];a.push(this.feedLossFns[e]===sparseCategoricalCrossentropy$3?t.slice(0,t.length-1).concat([1]):t)}if(checkArrayLengths$1(e=standardizeInputData$1(e,this.feedInputNames,this.feedInputShapes,!1,"input"),t=standardizeInputData$1(t,this.feedOutputNames,a,!1,"target")),checkLossAndTargetCompatibility$1(t,this.feedLossFns,this.feedOutputShapes),this.stateful&&null!=r&&r>0&&e[0].shape[0]%r!=0)throw new ValueError$1(`In a stateful network, you should only pass inputs with a number of samples that is divisible by the batch size ${r}. Found: ${e[0].shape[0]} sample(s).`);return[e,t]}async standardizeUserData(e,t,n,r,a=!0,s){const[o,i]=this.standardizeUserDataXY(e,t,a,s);if(null!=n)throw new Error("sample weight is not supported yet.");let l=null;if(null!=r){const e=standardizeClassWeights$1(r,this.outputNames);l=[];for(let t=0;t<e.length;++t)l.push(await standardizeWeights$1(i[t],null,e[t]))}return[o,i,l]}testLoop(e,t,n,r=0,a){return tidy$1(()=>{const s=this.checkNumSamples(t,n,a,"steps"),o=[];if(r>0)throw new NotImplementedError$1("Verbose mode is not implemented yet.");if(null!=a)throw new NotImplementedError$1("steps mode in testLoop() is not implemented yet");{const r=makeBatches$1(s,n),a=tensor1d$1(range$7(0,s));for(let n=0;n<r.length;++n){const s=r[n][0],i=r[n][1],l=sliceAlongFirstAxis$1(a,s,i-s),u=sliceArraysByIndices$1(t,l),c=e(u);if(0===n)for(let e=0;e<c.length;++e)o.push(scalar$1(0));for(let e=0;e<c.length;++e)o[e]=add$5(o[e],mul$1(i-s,c[e]))}for(let e=0;e<o.length;++e)o[e]=div$3(o[e],s)}return o})}getDedupedMetricsNames(){const e=this.metricsNames,t=[];for(let n=0;n<e.length;++n){const r=e[n];let a=r;count$1(e,r)>1&&(a+=`_${count$1(e.slice(0,n),r)}`),t.push(a)}return t}makeTrainFunction(){return e=>{const t=[],n=e.slice(0,this.inputs.length),r=e.slice(this.inputs.length,this.inputs.length+this.outputs.length),a=e.slice(this.inputs.length+this.outputs.length,this.inputs.length+2*this.outputs.length),s=[],o=this.collectedTrainableWeights.map(e=>e.read());return[this.optimizer_.minimize(()=>{const e=[];for(let t=0;t<this.inputs.length;++t)e.push({key:this.inputs[t],value:n[t]});const o=new FeedDict$1(e),i=execute$1(this.outputs,o,{training:!0});let l;for(let e=0;e<this.lossFunctions.length;++e){let n=(0,this.lossFunctions[e])(r[e],i[e]);null!=a[e]&&(n=computeWeightedLoss$2(n,a[e]));const s=mean$3(n);t.push(s),l=0===e?n:add$5(l,n)}for(let e=0;e<this.metricsTensors.length;++e){let n;if(this.outputs.length>1&&e<this.outputs.length)n=t[e];else{const t=this.metricsTensors[e][1];n=mean$3((0,this.metricsTensors[e][0])(r[t],i[t]))}keep$1(n),s.push(n)}return l=mean$3(l),this.calculateLosses().forEach(e=>{l=add$5(l,e)}),l},!0,o)].concat(s)}}makeTestFunction(){this.testFunction=e=>tidy$1(()=>{const t=[];let n;const r=e.slice(0,this.inputs.length),a=e.slice(this.inputs.length,this.inputs.length+this.outputs.length),s=[];for(let e=0;e<this.inputs.length;++e)s.push({key:this.inputs[e],value:r[e]});const o=new FeedDict$1(s),i=execute$1(this.outputs,o);for(let e=0;e<this.lossFunctions.length;++e){const r=mean$3((0,this.lossFunctions[e])(a[e],i[e]));n=0===e?r:add$5(n,r),t.push(n)}for(let e=0;e<this.metricsTensors.length;++e){const n=this.metricsTensors[e][1],r=mean$3((0,this.metricsTensors[e][0])(a[n],i[n]));t.push(r)}return t})}async fit(e,t,n={}){return fitTensors$1(this,e,t,n)}async fitDataset(e,t){return fitDataset$1(this,e,t)}async trainOnBatch(e,t){const n=await this.standardizeUserData(e,t),r=n[0],a=n[1],s=this.makeTrainFunction()(r.concat(a)),o=[];for(const e of s){const t=await e.data();o.push(t[0])}return dispose$1(s),singletonOrArray$1(o)}getNamedWeights(e){const t=[],n=null!=e&&e.trainableOnly,r=n?this.trainableWeights:this.weights,a=this.getWeights(n);for(let e=0;e<r.length;++e)n&&!r[e].trainable||t.push({name:r[e].originalName,tensor:a[e]});return t}set stopTraining(e){this.stopTraining_=e}get stopTraining(){return this.stopTraining_}get optimizer(){return this.optimizer_}set optimizer(e){this.optimizer_!==e&&(this.optimizer_=e,this.isOptimizerOwned=!1)}dispose(){const e=super.dispose();if(0===e.refCountAfterDispose&&null!=this.optimizer&&this.isOptimizerOwned){const t=memory$1().numTensors;this.optimizer_.dispose(),e.numDisposedVariables+=t-memory$1().numTensors}return e}getLossIdentifiers(){let e;if("string"==typeof this.loss)e=toSnakeCase$1(this.loss);else if(Array.isArray(this.loss)){for(const e of this.loss)if("string"!=typeof e)throw new Error("Serialization of non-string loss is not supported.");e=this.loss.map(e=>toSnakeCase$1(e))}else{const t=Object.keys(this.loss);e={};const n=this.loss;for(const r of t){if("string"!=typeof n[r])throw new Error("Serialization of non-string loss is not supported.");e[r]=toSnakeCase$1(n[r])}}return e}getMetricIdentifiers(){if("string"==typeof this.metrics||"function"==typeof this.metrics)return[toSnakeCase$1(getLossOrMetricName$1(this.metrics))];if(Array.isArray(this.metrics))return this.metrics.map(e=>toSnakeCase$1(getLossOrMetricName$1(e)));{const e={};for(const t in this.metrics)e[t]=toSnakeCase$1(getLossOrMetricName$1(this.metrics[t]));return e}}getTrainingConfig(){return{loss:this.getLossIdentifiers(),metrics:this.getMetricIdentifiers(),optimizer_config:{class_name:this.optimizer.getClassName(),config:this.optimizer.getConfig()}}}loadTrainingConfig(e){if(null!=e.weighted_metrics)throw new Error("Loading weight_metrics is not supported yet.");if(null!=e.loss_weights)throw new Error("Loading loss_weights is not supported yet.");if(null!=e.sample_weight_mode)throw new Error("Loading sample_weight_mode is not supported yet.");const t=deserialize$1(convertPythonicToTs$1(e.optimizer_config));let n,r;if("string"==typeof e.loss)n=toCamelCase$1(e.loss);else if(Array.isArray(e.loss))n=e.loss.map(e=>toCamelCase$1(e));else if(null!=e.loss){n={};for(const t in e.loss)n[t]=toCamelCase$1(e.loss[t])}if(Array.isArray(e.metrics))r=e.metrics.map(e=>toCamelCase$1(e));else if(null!=e.metrics){r={};for(const t in e.metrics)r[t]=toCamelCase$1(e.metrics[t])}this.compile({loss:n,metrics:r,optimizer:t})}async save(e,t){if("string"==typeof e){const t=getSaveHandlers$1(e);if(0===t.length)throw new ValueError$1(`Cannot find any save handlers for URL '${e}'`);if(t.length>1)throw new ValueError$1(`Found more than one (${t.length}) save handlers for URL '${e}'`);e=t[0]}if(null==e.save)throw new ValueError$1("LayersModel.save() cannot proceed because the IOHandler provided does not have the `save` attribute defined.");const n=await encodeWeights$1(this.getNamedWeights(t)),r={modelTopology:this.toJSON(null,!1),format:LAYERS_MODEL_FORMAT_NAME$1,generatedBy:`TensorFlow.js tfjs-layers v${version$d}`,convertedBy:null};if(null!=t&&t.includeOptimizer&&null!=this.optimizer){r.trainingConfig=this.getTrainingConfig();const e="optimizer",{data:t,specs:a}=await encodeWeights$1(await this.optimizer.getWeights(),e);n.specs.push(...a),n.data=concatenateArrayBuffers$1([n.data,t])}return null!=this.userDefinedMetadata&&(checkUserDefinedMetadata$1(this.userDefinedMetadata,this.name,!0),r.userDefinedMetadata=this.userDefinedMetadata),r.weightData=n.data,r.weightSpecs=n.specs,e.save(r)}setUserDefinedMetadata(e){checkUserDefinedMetadata$1(e,this.name),this.userDefinedMetadata=e}getUserDefinedMetadata(){return this.userDefinedMetadata}}LayersModel$1.className="Model",registerClass$1(LayersModel$1);class Functional$1 extends LayersModel$1{}async function loadLayersModelInternal$1(e,t){if(null==t&&(t={}),"string"==typeof e){const n=getLoadHandlers$1(e,t);if(0===n.length)n.push(browserHTTPRequest$1(e,t));else if(n.length>1)throw new ValueError$1(`Found more than one (${n.length}) load handlers for URL '${e}'`);e=n[0]}return loadLayersModelFromIOHandler$1(e,void 0,t)}async function loadLayersModelFromIOHandler$1(e,t,n){if(null==n&&(n={}),null==e.load)throw new ValueError$1("Cannot proceed with model loading because the IOHandler provided does not have the `load` method implemented.");const r=await e.load();let a=r.modelTopology;null!=a.model_config&&(a=a.model_config);const s=null==n.strict||n.strict,o=null!=r.weightData&&null!=r.weightSpecs&&s,i=deserialize$1(convertPythonicToTs$1(a),t,o),l=r.trainingConfig;if(null!=l&&i.loadTrainingConfig(l),null!=r.userDefinedMetadata&&i.setUserDefinedMetadata(r.userDefinedMetadata),null!=r.weightData){if(null==r.weightSpecs)throw new ValueError$1("LayersModel artifacts contains weight data, but not weight specs. Therefore loading of weights cannot proceed.");const{modelWeights:e,optimizerWeights:t}=decodeModelAndOptimizerWeights$1(r.weightData,r.weightSpecs);i.loadWeights(e,s),null!=i.optimizer&&t.length>0&&await i.optimizer.setWeights(t),dispose$1(e),dispose$1(t.map(e=>e.tensor))}return i}function decodeModelAndOptimizerWeights$1(e,t){const n=decodeWeights$1(e,t),r={},a=[];return t.forEach(e=>{"optimizer"===e.group?a.push({name:e.name,tensor:n[e.name]}):r[e.name]=n[e.name]}),{modelWeights:r,optimizerWeights:a}}Functional$1.className="Functional",registerClass$1(Functional$1);class Sequential$1 extends LayersModel$1{constructor(e){if(super({inputs:[],outputs:[]}),e=e||{},this.trainable=!0,this.built=!1,this.name=null!=e.name?e.name:getUid$1("sequential_"),null!=e.layers)for(const t of e.layers)this.add(t)}checkShape(e){if(e.inboundNodes[0].outputTensors[0].shape.some(e=>e<0))throw new ValueError$1(`Negative dimension size caused by adding layer ${e.name} with input shape [${e.inboundNodes[0].inputTensors[0].shape}]`)}add(e){const t=e instanceof Sequential$1||e instanceof LayersModel$1;let n;if(t){if(n=e,1!==n.outputs.length)throw new ValueError$1("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");if(1!==n.inputs.length)throw new ValueError$1("All layers in a Sequential model should have a single input tensor. For multi-input layers, use the functional API.")}if(0===this.outputs.length){if(0===e.inboundNodes.length){if(null==e.batchInputShape)throw new ValueError$1("The first layer in a Sequential model must get an `inputShape` or `batchInputShape` argument.");const t=Input$1({batchShape:e.batchInputShape,dtype:e.dtype,name:e.name+"_input"});e.apply(t)}if(t)this.outputs=n.outputs,this.inputs=n.inputs;else{if(1!==e.inboundNodes.length)throw new ValueError$1(`A layer added to a Sequential model must not already be connected somewhere else. LayersModel received layer ${e.name} which has ${e.inboundNodes.length} pre-existing inbound connections.`);if(1!==e.inboundNodes[0].outputTensors.length)throw new ValueError$1("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");this.checkShape(e),this.outputs=[e.inboundNodes[0].outputTensors[0]],this.inputs=getSourceInputs$1(this.outputs[0])}this.inboundNodes=[],new Node$1({outboundLayer:this,inboundLayers:[],nodeIndices:[],tensorIndices:[],inputTensors:this.inputs,outputTensors:this.outputs,inputMasks:pyListRepeat$1(null,this.inputs.length),outputMasks:[null],inputShapes:this.inputs.map(e=>e.shape),outputShapes:this.outputs[0].shape})}else{const t=e.apply(this.outputs[0]);if(Array.isArray(t))throw new TypeError("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");this.checkShape(e),this.outputs=[t],this.inboundNodes[0].outputTensors=this.outputs,this.inboundNodes[0].outputShapes=[this.outputs[0].shape]}this.layers.push(e),this.built=!1}pop(){if(0===this.layers.length)throw new TypeError("There are no layers in the model.");if(this.layers.pop(),0===this.layers.length)this.outputs=[],this.inboundNodes=[],this.outboundNodes=[];else{const e=this.layers.length-1;this.layers[e].outboundNodes=[],this.outputs=[this.layers[e].output],this.inboundNodes[0].outputTensors=this.outputs,this.inboundNodes[0].outputShapes=[this.outputs[0].shape]}}call(e,t){return null==this.model&&this.build(),this.model.call(e,t)}build(e){if(getExactlyOneShape$1(e),0===this.inputs.length||0===this.outputs.length)throw new TypeError("Sequential model cannot be built: model is empty. Add some layers first.");this.model=new LayersModel$1({inputs:this.inputs,outputs:this.outputs[0],name:this.name+"_model"}),this.model.trainable=this.trainable,this.supportsMasking=this.model.supportsMasking,this.inputLayers=this.model.inputLayers,this.inputLayersNodeIndices=this.model.inputLayersNodeIndices,this.inputLayersTensorIndices=this.model.inputLayersTensorIndices,this.outputLayers=this.model.outputLayers,this.outputLayersNodeIndices=this.model.outputLayersNodeIndices,this.outputLayersTensorIndices=this.model.outputLayersTensorIndices,this.nodesByDepth=this.model.nodesByDepth,this.containerNodes=this.model.containerNodes,this.outputNames=this.model.outputNames,this.inputNames=this.model.inputNames,this.built=!0}countParams(){return this.built||this.build(),super.countParams()}summary(e,t,n=console.log){this.built||this.build(),super.summary(e,t,n)}setWeights(e){null==this.model&&this.build(),this.model.setWeights(e)}evaluate(e,t,n={}){if(!this.built)throw new RuntimeError$1("The model needs to be compiled before being used.");return this.model.evaluate(e,t,n)}async evaluateDataset(e,t){if(!this.built)throw new RuntimeError$1("The model needs to be compiled before being used.");return this.model.evaluateDataset(e,t)}predict(e,t={}){return null==this.model&&this.build(),this.model.predict(e,t)}predictOnBatch(e){return null==this.model&&this.build(),this.model.predictOnBatch(e)}compile(e){this.build(),this.model.compile(e),this.optimizer_=this.model.optimizer,this.isOptimizerOwned=this.model.isOptimizerOwned,this.loss=this.model.loss,this.metrics=this.model.metrics,this.metricsTensors=this.model.metricsTensors,this.metricsNames=this.model.metricsNames}get optimizer(){return null==this.model?void 0:this.model.optimizer}set optimizer(e){this.model.optimizer=e}async fit(e,t,n={}){if(!this.built)throw new RuntimeError$1("The model needs to be compiled before being used.");return this.model.fit(e,t,n)}async fitDataset(e,t){if(!this.built)throw new RuntimeError$1("The model needs to be compiled before being used.");return this.model.fitDataset(e,t)}async trainOnBatch(e,t){return this.model.trainOnBatch(e,t)}static fromConfig(e,t,n={},r=!1){let a,s={};if(t instanceof Array){if(null==t[0].className||"Merge"===t[0].className)throw new ValueError$1("Legacy serialization format not supported yet.");a=t}else assert$6(null!=t.layers,()=>"When the config data for a Sequential model is not an Array, it must be an Object that contains the 'layers' field."),a=t.layers,delete t.layers,s=t;const o=new e(s);if(!(o instanceof Sequential$1))throw new NotImplementedError$1(`Sequential.fromConfig called on non-Sequential input: ${o}`);for(const e of a){const t=deserialize$1(e,void 0,r);r&&t.setFastWeightInitDuringBuild(!0),o.add(t)}return o}set stopTraining(e){if(null==this.model)throw new ValueError$1("Cannot set the stopTraining property of a sequential model before it is compiled.");this.model.stopTraining=e}get stopTraining(){if(null==this.model)throw new ValueError$1("Cannot get the stopTraining property of a sequential model before it is compiled.");return this.model.stopTraining}getConfig(){const e=[];for(const t of this.layers){const n={};n.className=t.getClassName(),n.config=t.getConfig(),e.push(n)}return{name:this.name,layers:e}}}function sequential$1(e){return new Sequential$1(e)}function loadLayersModel$1(e,t){return null==t&&(t={}),loadLayersModelInternal$1(e,t)}Sequential$1.className="Sequential",registerClass$1(Sequential$1);class Activation$3 extends Serializable$1{getConfig(){return{}}}class Elu$2 extends Activation$3{apply(e,t=1){return elu$7(e,t)}}Elu$2.className="elu",registerClass$1(Elu$2);class Selu$2 extends Activation$3{apply(e){return selu$5(e)}}Selu$2.className="selu",registerClass$1(Selu$2);class Relu$2 extends Activation$3{apply(e){return relu$6(e)}}Relu$2.className="relu",registerClass$1(Relu$2);class Relu6$2 extends Activation$3{apply(e){return tidy$1(()=>minimum$6(6,relu$6(e)))}}Relu6$2.className="relu6",registerClass$1(Relu6$2);class Linear$1 extends Activation$3{apply(e){return e}}Linear$1.className="linear",registerClass$1(Linear$1);class Sigmoid$2 extends Activation$3{apply(e){return sigmoid$5(e)}}Sigmoid$2.className="sigmoid",registerClass$1(Sigmoid$2);class HardSigmoid$1 extends Activation$3{apply(e){return hardSigmoid$1(e)}}HardSigmoid$1.className="hardSigmoid",registerClass$1(HardSigmoid$1);class Softplus$2 extends Activation$3{apply(e){return softplus$5(e)}}Softplus$2.className="softplus",registerClass$1(Softplus$2);class Softsign$1 extends Activation$3{apply(e){return softsign$1(e)}}Softsign$1.className="softsign",registerClass$1(Softsign$1);class Tanh$2 extends Activation$3{apply(e){return tanh$6(e)}}Tanh$2.className="tanh",registerClass$1(Tanh$2);class Softmax$4 extends Activation$3{apply(e,t=-1){return softmax$6(e,t)}}Softmax$4.className="softmax",registerClass$1(Softmax$4);class LogSoftmax$2 extends Activation$3{apply(e,t=-1){return logSoftmax$1(e,t)}}LogSoftmax$2.className="logSoftmax",registerClass$1(LogSoftmax$2);class Swish$1 extends Activation$3{apply(e,t=1){return tidy$1(()=>mul$1(sigmoid$5(mul$1(e,t)),e))}}Swish$1.className="swish",registerClass$1(Swish$1);class Mish$1 extends Activation$3{apply(e){return tidy$1(()=>mul$1(e,tanh$6(softplus$5(e))))}}function serializeActivation$1(e){return e.getClassName()}function deserializeActivation$1(e,t={}){return deserializeKerasObject$1(e,SerializationMap$1.getMap().classNameMap,t,"activation")}function getActivation$1(e){if(null==e)return deserializeActivation$1({className:"linear",config:{}});if("string"==typeof e){const t={};return t.className=e,t.config={},deserializeActivation$1(t)}return e instanceof Activation$3?e:deserializeActivation$1(e)}function assertObjectArgs$1(e){if(null!=e&&"object"!=typeof e)throw new Error(`Argument to L1L2 regularizer's constructor is expected to be an object, but received: ${e}`)}Mish$1.className="mish",registerClass$1(Mish$1);class Regularizer$1 extends Serializable$1{}class L1L2$1 extends Regularizer$1{constructor(e){super(),assertObjectArgs$1(e),this.l1=null==e||null==e.l1?.01:e.l1,this.l2=null==e||null==e.l2?.01:e.l2,this.hasL1=0!==this.l1,this.hasL2=0!==this.l2}apply(e){return tidy$1(()=>{let t=zeros$4([1]);return this.hasL1&&(t=add$5(t,sum$6(mul$1(this.l1,abs$5(e))))),this.hasL2&&(t=add$5(t,sum$6(mul$1(this.l2,square$4(e))))),reshape$6(t,[])})}getConfig(){return{l1:this.l1,l2:this.l2}}static fromConfig(e,t){return new e({l1:t.l1,l2:t.l2})}}L1L2$1.className="L1L2",registerClass$1(L1L2$1);const REGULARIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP$1={l1l2:"L1L2"};function serializeRegularizer$1(e){return serializeKerasObject$1(e)}function deserializeRegularizer$1(e,t={}){return deserializeKerasObject$1(e,SerializationMap$1.getMap().classNameMap,t,"regularizer")}function getRegularizer$1(e){return null==e?null:"string"==typeof e?deserializeRegularizer$1({className:e in REGULARIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP$1?REGULARIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP$1[e]:e,config:{}}):e instanceof Regularizer$1?e:deserializeRegularizer$1(e)}class ReLU$1 extends Layer$1{constructor(e){super(null==e?{}:e),this.supportsMasking=!0,null!=e&&(this.maxValue=e.maxValue)}call(e,t){e=getExactlyOneTensor$1(e);let n=relu$6(e);return null!=this.maxValue&&(n=clipByValue$3(n,0,this.maxValue)),n}computeOutputShape(e){return e}getConfig(){const e={maxValue:this.maxValue},t=super.getConfig();return Object.assign(e,t),e}}ReLU$1.className="ReLU",registerClass$1(ReLU$1);class LeakyReLU$1 extends Layer$1{constructor(e){super(null==e?{}:e),this.DEFAULT_ALPHA=.3,null==e&&(e={}),this.alpha=null==e.alpha?this.DEFAULT_ALPHA:e.alpha}call(e,t){const n=getExactlyOneTensor$1(e);return leakyRelu$5(n,this.alpha)}computeOutputShape(e){return e}getConfig(){const e={alpha:this.alpha},t=super.getConfig();return Object.assign(e,t),e}}LeakyReLU$1.className="LeakyReLU",registerClass$1(LeakyReLU$1);class PReLU$1 extends Layer$1{constructor(e){if(super(null==e?{}:e),this.DEFAULT_ALPHA_INITIALIZER="zeros",null==e&&(e={}),this.supportsMasking=!0,this.alphaInitializer=getInitializer$1(e.alphaInitializer||this.DEFAULT_ALPHA_INITIALIZER),this.alphaRegularizer=getRegularizer$1(e.alphaRegularizer),this.alphaConstraint=getConstraint$1(e.alphaConstraint),null==e.sharedAxes)this.sharedAxes=null;else if(Array.isArray(e.sharedAxes))this.sharedAxes=e.sharedAxes;else{if("number"!=typeof e.sharedAxes)throw new ValueError$1(`Expected sharedAxes to be a number or an array of numbers, but got ${e.sharedAxes}`);this.sharedAxes=[e.sharedAxes]}}build(e){const t=(e=getExactlyOneShape$1(e)).slice(1);if(null!=this.sharedAxes)for(const e of this.sharedAxes)t[e-1]=1;this.alpha=this.addWeight("alpha",t,"float32",this.alphaInitializer,this.alphaRegularizer,!0,this.alphaConstraint);const n={};if(null!=this.sharedAxes)for(let t=1;t<e.length;++t)n[t]=e[t];this.inputSpec=[new InputSpec$1({ndim:e.length,axes:n})],this.built=!0}call(e,t){return e=getExactlyOneTensor$1(e),prelu$6(e,this.alpha.read())}getConfig(){const e={alphaInitializer:serializeInitializer$1(this.alphaInitializer),alphaRegularizer:serializeRegularizer$1(this.alphaRegularizer),alphaConstraint:serializeConstraint$1(this.alphaConstraint),sharedAxes:this.sharedAxes},t=super.getConfig();return Object.assign(e,t),e}}PReLU$1.className="PReLU",registerClass$1(PReLU$1);class ELU$7 extends Layer$1{constructor(e){if(super(null==e?{}:e),this.DEFAULT_ALPHA=1,null==e&&(e={}),null!=e.alpha&&e.alpha!==this.DEFAULT_ALPHA)throw new NotImplementedError$1(`Non-default alpha value (${e.alpha}) is not supported by the ELU layer yet.`);this.alpha=null==e.alpha?this.DEFAULT_ALPHA:e.alpha}call(e,t){const n=getExactlyOneTensor$1(e);return elu$8(n)}computeOutputShape(e){return e}getConfig(){const e={alpha:this.alpha},t=super.getConfig();return Object.assign(e,t),e}}ELU$7.className="ELU",registerClass$1(ELU$7);class ThresholdedReLU$1 extends Layer$1{constructor(e){super(null==e?{}:e),this.DEFAULT_THETA=1,null==e&&(e={}),this.theta=null==e.theta?this.DEFAULT_THETA:e.theta}call(e,t){const n=getExactlyOneTensor$1(e);return mul$1(n,cast$7(greater$6(n,this.theta),"float32"))}computeOutputShape(e){return e}getConfig(){const e={theta:this.theta},t=super.getConfig();return Object.assign(e,t),e}}ThresholdedReLU$1.className="ThresholdedReLU",registerClass$1(ThresholdedReLU$1);class Softmax$3 extends Layer$1{constructor(e){super(null==e?{}:e),this.DEFAULT_AXIS=1,null==e&&(e={}),this.softmax=(new Softmax$4).apply,this.axis=null==e.axis?this.DEFAULT_AXIS:e.axis}call(e,t){const n=getExactlyOneTensor$1(e);return this.softmax(n,this.axis)}computeOutputShape(e){return e}getConfig(){const e={axis:this.axis},t=super.getConfig();return Object.assign(e,t),e}}function normalizeArray$1(e,t,n){if("number"==typeof e)return pyListRepeat$1(e,t);if(e.length!==t)throw new ValueError$1(`The ${n} argument must be an integer or tuple of ${t} integers. Received: ${e.length} elements.`);for(let r=0;r<t;++r){const a=e[r];if(!isInteger$1(a))throw new ValueError$1(`The ${n} argument must be an integer or tuple of ${t} integers. Received: ${JSON.stringify(e)} including a non-integer number ${a}`)}return e}function convOutputLength$1(e,t,n,r,a=1){if(null==e)return e;let s;return s="same"===n?e:e-(t+(t-1)*(a-1))+1,Math.floor((s+r-1)/r)}function deconvLength$1(e,t,n,r){if(null==e)return null;if("valid"===r)e=e*t+max$6([n-t,0]);else{if("same"!==r)throw new ValueError$1(`Unsupport padding mode: ${r}.`);e*=t}return e}function preprocessConv2DInput$1(e,t){return tidy$1(()=>(checkDataFormat$1(t),"channelsFirst"===t?transpose$5(e,[0,2,3,1]):e))}function preprocessConv3DInput$1(e,t){return tidy$1(()=>(checkDataFormat$1(t),"channelsFirst"===t?transpose$5(e,[0,2,3,4,1]):e))}function conv1dWithBias$1(e,t,n,r=1,a="valid",s,o=1){return tidy$1(()=>{if(null==s&&(s=imageDataFormat$1()),checkDataFormat$1(s),3!==e.shape.length)throw new ValueError$1(`The input of a conv1dWithBias operation should be 3, but is ${e.shape.length} instead.`);if(3!==t.shape.length)throw new ValueError$1(`The kernel for a conv1dWithBias operation should be 3, but is ${t.shape.length} instead`);if(null!=n&&1!==n.shape.length)throw new ValueError$1(`The bias for a conv1dWithBias operation should be 1, but is ${t.shape.length} instead`);if("channelsFirst"===s&&(e=transpose$5(e,[0,2,1])),"causal"===a)throw new NotImplementedError$1("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");let i=conv1d$3(e,t,r,"same"===a?"same":"valid","NWC",o);return null!=n&&(i=biasAdd$1(i,n)),i})}function conv2dWithBiasActivation$1(e,t,n,r=[1,1],a="valid",s,o,i=null){return tidy$1(()=>{if(null==s&&(s=imageDataFormat$1()),checkDataFormat$1(s),3!==e.rank&&4!==e.rank)throw new ValueError$1(`conv2dWithBiasActivation expects input to be of rank 3 or 4, but received ${e.rank}.`);if(3!==t.rank&&4!==t.rank)throw new ValueError$1(`conv2dWithBiasActivation expects kernel to be of rank 3 or 4, but received ${e.rank}.`);let l=preprocessConv2DInput$1(e,s);if("causal"===a)throw new NotImplementedError$1("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");return l=conv2d$6({x:l,filter:t,strides:r,pad:"same"===a?"same":"valid",dilations:o,dataFormat:"NHWC",bias:n,activation:i}),"channelsFirst"===s&&(l=transpose$5(l,[0,3,1,2])),l})}function conv3dWithBias$1(e,t,n,r=[1,1,1],a="valid",s,o){return tidy$1(()=>{if(null==s&&(s=imageDataFormat$1()),checkDataFormat$1(s),4!==e.rank&&5!==e.rank)throw new ValueError$1(`conv3dWithBias expects input to be of rank 4 or 5, but received ${e.rank}.`);if(4!==t.rank&&5!==t.rank)throw new ValueError$1(`conv3dWithBias expects kernel to be of rank 4 or 5, but received ${e.rank}.`);let i=preprocessConv3DInput$1(e,s);if("causal"===a)throw new NotImplementedError$1("The support for CAUSAL padding mode in conv3dWithBias is not implemented yet.");return i=conv3d$2(i,t,r,"same"===a?"same":"valid","NDHWC",o),null!=n&&(i=biasAdd$1(i,n)),"channelsFirst"===s&&(i=transpose$5(i,[0,4,1,2,3])),i})}Softmax$3.className="Softmax",registerClass$1(Softmax$3);class BaseConv$1 extends Layer$1{constructor(e,t){if(super(t),this.bias=null,this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_BIAS_INITIALIZER="zeros",BaseConv$1.verifyArgs(t),this.rank=e,assertPositiveInteger$1(this.rank,"rank"),1!==this.rank&&2!==this.rank&&3!==this.rank)throw new NotImplementedError$1(`Convolution layer for rank other than 1, 2, or 3 (${this.rank}) is not implemented yet.`);if(this.kernelSize=normalizeArray$1(t.kernelSize,e,"kernelSize"),this.strides=normalizeArray$1(null==t.strides?1:t.strides,e,"strides"),this.padding=null==t.padding?"valid":t.padding,checkPaddingMode$1(this.padding),this.dataFormat=null==t.dataFormat?"channelsLast":t.dataFormat,checkDataFormat$1(this.dataFormat),this.activation=getActivation$1(t.activation),this.useBias=null==t.useBias||t.useBias,this.biasInitializer=getInitializer$1(t.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.biasConstraint=getConstraint$1(t.biasConstraint),this.biasRegularizer=getRegularizer$1(t.biasRegularizer),this.activityRegularizer=getRegularizer$1(t.activityRegularizer),this.dilationRate=normalizeArray$1(null==t.dilationRate?1:t.dilationRate,e,"dilationRate"),1===this.rank&&Array.isArray(this.dilationRate)&&1!==this.dilationRate.length)throw new ValueError$1(`dilationRate must be a number or an array of a single number for 1D convolution, but received ${JSON.stringify(this.dilationRate)}`);if(2===this.rank){if("number"==typeof this.dilationRate)this.dilationRate=[this.dilationRate,this.dilationRate];else if(2!==this.dilationRate.length)throw new ValueError$1(`dilationRate must be a number or array of two numbers for 2D convolution, but received ${JSON.stringify(this.dilationRate)}`)}else if(3===this.rank)if("number"==typeof this.dilationRate)this.dilationRate=[this.dilationRate,this.dilationRate,this.dilationRate];else if(3!==this.dilationRate.length)throw new ValueError$1(`dilationRate must be a number or array of three numbers for 3D convolution, but received ${JSON.stringify(this.dilationRate)}`)}static verifyArgs(e){if(assert$5("kernelSize"in e,"required key 'kernelSize' not in config"),"number"!=typeof e.kernelSize&&!checkArrayTypeAndLength$1(e.kernelSize,"number",1,3))throw new ValueError$1(`BaseConv expects config.kernelSize to be number or number[] with length 1, 2, or 3, but received ${JSON.stringify(e.kernelSize)}.`)}getConfig(){const e={kernelSize:this.kernelSize,strides:this.strides,padding:this.padding,dataFormat:this.dataFormat,dilationRate:this.dilationRate,activation:serializeActivation$1(this.activation),useBias:this.useBias,biasInitializer:serializeInitializer$1(this.biasInitializer),biasRegularizer:serializeRegularizer$1(this.biasRegularizer),activityRegularizer:serializeRegularizer$1(this.activityRegularizer),biasConstraint:serializeConstraint$1(this.biasConstraint)},t=super.getConfig();return Object.assign(e,t),e}}class Conv$1 extends BaseConv$1{constructor(e,t){super(e,t),this.kernel=null,Conv$1.verifyArgs(t),this.filters=t.filters,assertPositiveInteger$1(this.filters,"filters"),this.kernelInitializer=getInitializer$1(t.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.kernelConstraint=getConstraint$1(t.kernelConstraint),this.kernelRegularizer=getRegularizer$1(t.kernelRegularizer)}build(e){e=getExactlyOneShape$1(e);const t="channelsFirst"===this.dataFormat?1:e.length-1;if(null==e[t])throw new ValueError$1(`The channel dimension of the input should be defined. Found ${e[t]}`);const n=e[t],r=this.kernelSize.concat([n,this.filters]);this.kernel=this.addWeight("kernel",r,null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.filters],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[{ndim:this.rank+2,axes:{[t]:n}}],this.built=!0}call(e,t){return tidy$1(()=>{let t;e=getExactlyOneTensor$1(e);const n=null==this.bias?null:this.bias.read(),r=mapActivationToFusedKernel$1(this.activation.getClassName());if(null!=r&&2===this.rank)t=conv2dWithBiasActivation$1(e,this.kernel.read(),n,this.strides,this.padding,this.dataFormat,this.dilationRate,r);else{if(1===this.rank)t=conv1dWithBias$1(e,this.kernel.read(),n,this.strides[0],this.padding,this.dataFormat,this.dilationRate[0]);else if(2===this.rank)t=conv2dWithBiasActivation$1(e,this.kernel.read(),n,this.strides,this.padding,this.dataFormat,this.dilationRate);else{if(3!==this.rank)throw new NotImplementedError$1("convolutions greater than 3D are not implemented yet.");t=conv3dWithBias$1(e,this.kernel.read(),n,this.strides,this.padding,this.dataFormat,this.dilationRate)}null!=this.activation&&(t=this.activation.apply(t))}return t})}computeOutputShape(e){e=getExactlyOneShape$1(e);const t=[],n="channelsLast"===this.dataFormat?e.slice(1,e.length-1):e.slice(2);for(let e=0;e<n.length;++e){const r=convOutputLength$1(n[e],this.kernelSize[e],this.padding,this.strides[e],"number"==typeof this.dilationRate?this.dilationRate:this.dilationRate[e]);t.push(r)}let r=[e[0]];return"channelsLast"===this.dataFormat?(r=r.concat(t),r.push(this.filters)):(r.push(this.filters),r=r.concat(t)),r}getConfig(){const e={filters:this.filters,kernelInitializer:serializeInitializer$1(this.kernelInitializer),kernelRegularizer:serializeRegularizer$1(this.kernelRegularizer),kernelConstraint:serializeConstraint$1(this.kernelConstraint)},t=super.getConfig();return Object.assign(e,t),e}static verifyArgs(e){if(!("filters"in e)||"number"!=typeof e.filters||e.filters<1)throw new ValueError$1(`Convolution layer expected config.filters to be a 'number' > 0 but got ${JSON.stringify(e.filters)}`)}}class Conv2D$2 extends Conv$1{constructor(e){super(2,e),Conv2D$2.verifyArgs(e)}getConfig(){const e=super.getConfig();return delete e.rank,e}static verifyArgs(e){if("number"!=typeof e.kernelSize&&!checkArrayTypeAndLength$1(e.kernelSize,"number",1,2))throw new ValueError$1(`Conv2D expects config.kernelSize to be number or number[] with length 1 or 2, but received ${JSON.stringify(e.kernelSize)}.`)}}Conv2D$2.className="Conv2D",registerClass$1(Conv2D$2);class Conv3D$2 extends Conv$1{constructor(e){super(3,e),Conv3D$2.verifyArgs(e)}getConfig(){const e=super.getConfig();return delete e.rank,e}static verifyArgs(e){if("number"!=typeof e.kernelSize&&(!Array.isArray(e.kernelSize)||1!==e.kernelSize.length&&3!==e.kernelSize.length))throw new ValueError$1(`Conv3D expects config.kernelSize to be number or [number, number, number], but received ${JSON.stringify(e.kernelSize)}.`)}}Conv3D$2.className="Conv3D",registerClass$1(Conv3D$2);class Conv2DTranspose$1 extends Conv2D$2{constructor(e){if(super(e),this.inputSpec=[new InputSpec$1({ndim:4})],"same"!==this.padding&&"valid"!==this.padding)throw new ValueError$1(`Conv2DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode ${this.padding}`)}build(e){if(4!==(e=getExactlyOneShape$1(e)).length)throw new ValueError$1("Input should have rank 4; Received input shape: "+JSON.stringify(e));const t="channelsFirst"===this.dataFormat?1:e.length-1;if(null==e[t])throw new ValueError$1("The channel dimension of the inputs should be defined. Found `None`.");const n=e[t],r=this.kernelSize.concat([this.filters,n]);this.kernel=this.addWeight("kernel",r,"float32",this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.filters],"float32",this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[new InputSpec$1({ndim:4,axes:{[t]:n}})],this.built=!0}call(e,t){return tidy$1(()=>{let t=getExactlyOneTensor$1(e);if(4!==t.shape.length)throw new ValueError$1(`Conv2DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-${t.shape.length}`);const n=t.shape;let r,a;"channelsFirst"===this.dataFormat?(r=2,a=3):(r=1,a=2);const s=n[a],o=this.kernelSize[1],i=this.strides[1],l=[n[0],deconvLength$1(n[r],this.strides[0],this.kernelSize[0],this.padding),deconvLength$1(s,i,o,this.padding),this.filters];"channelsLast"!==this.dataFormat&&(t=transpose$5(t,[0,2,3,1]));let u=conv2dTranspose$2(t,this.kernel.read(),l,this.strides,this.padding);return"channelsLast"!==this.dataFormat&&(u=transpose$5(u,[0,3,1,2])),null!=this.bias&&(u=biasAdd$1(u,this.bias.read(),this.dataFormat)),null!=this.activation&&(u=this.activation.apply(u)),u})}computeOutputShape(e){const t=(e=getExactlyOneShape$1(e)).slice();let n,r,a;"channelsFirst"===this.dataFormat?(n=1,r=2,a=3):(n=3,r=1,a=2);const s=this.kernelSize[0],o=this.kernelSize[1],i=this.strides[0],l=this.strides[1];return t[n]=this.filters,t[r]=deconvLength$1(t[r],i,s,this.padding),t[a]=deconvLength$1(t[a],l,o,this.padding),t}getConfig(){const e=super.getConfig();return delete e.dilationRate,e}}Conv2DTranspose$1.className="Conv2DTranspose",registerClass$1(Conv2DTranspose$1);class Conv3DTranspose$1 extends Conv3D$2{constructor(e){if(super(e),this.inputSpec=[new InputSpec$1({ndim:5})],"same"!==this.padding&&"valid"!==this.padding)throw new ValueError$1(`Conv3DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode ${this.padding}`)}build(e){if(5!==(e=getExactlyOneShape$1(e)).length)throw new ValueError$1("Input should have rank 5; Received input shape: "+JSON.stringify(e));const t="channelsFirst"===this.dataFormat?1:e.length-1;if(null==e[t])throw new ValueError$1("The channel dimension of the inputs should be defined. Found `None`.");const n=e[t],r=this.kernelSize.concat([this.filters,n]);this.kernel=this.addWeight("kernel",r,"float32",this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.filters],"float32",this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[new InputSpec$1({ndim:5,axes:{[t]:n}})],this.built=!0}call(e,t){return tidy$1(()=>{let t=getExactlyOneTensor$1(e);if(5!==t.shape.length)throw new ValueError$1(`Conv3DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-${t.shape.length}`);const n=t.shape;let r,a,s;"channelsFirst"===this.dataFormat?(s=2,r=3,a=4):(s=1,r=2,a=3);const o=n[r],i=n[a],l=this.kernelSize[1],u=this.kernelSize[2],c=this.strides[1],p=this.strides[2],d=[n[0],deconvLength$1(n[s],this.strides[0],this.kernelSize[0],this.padding),deconvLength$1(o,c,l,this.padding),deconvLength$1(i,p,u,this.padding),this.filters];"channelsLast"!==this.dataFormat&&(t=transpose$5(t,[0,2,3,4,1]));let h=conv3dTranspose$2(t,this.kernel.read(),d,this.strides,this.padding);return"channelsLast"!==this.dataFormat&&(h=transpose$5(h,[0,4,1,2,3])),null!==this.bias&&(h=biasAdd$1(h,this.bias.read(),this.dataFormat)),null!==this.activation&&(h=this.activation.apply(h)),h})}computeOutputShape(e){const t=(e=getExactlyOneShape$1(e)).slice();let n,r,a,s;"channelsFirst"===this.dataFormat?(n=1,r=2,a=3,s=4):(n=4,r=1,a=2,s=3);const o=this.kernelSize[0],i=this.kernelSize[1],l=this.kernelSize[2],u=this.strides[0],c=this.strides[1],p=this.strides[2];return t[n]=this.filters,t[r]=deconvLength$1(t[r],u,o,this.padding),t[a]=deconvLength$1(t[a],c,i,this.padding),t[s]=deconvLength$1(t[s],p,l,this.padding),t}getConfig(){const e=super.getConfig();return delete e.dilationRate,e}}Conv3DTranspose$1.className="Conv3DTranspose",registerClass$1(Conv3DTranspose$1);class SeparableConv$1 extends Conv$1{constructor(e,t){if(super(e,t),this.DEFAULT_DEPTHWISE_INITIALIZER="glorotUniform",this.DEFAULT_POINTWISE_INITIALIZER="glorotUniform",this.depthwiseKernel=null,this.pointwiseKernel=null,null==t.filters)throw new ValueError$1("The `filters` configuration field is required by SeparableConv, but is unspecified.");if(null!=t.kernelInitializer||null!=t.kernelRegularizer||null!=t.kernelConstraint)throw new ValueError$1("Fields kernelInitializer, kernelRegularizer and kernelConstraint are invalid for SeparableConv2D. Use depthwiseInitializer, depthwiseRegularizer, depthwiseConstraint, pointwiseInitializer, pointwiseRegularizer and pointwiseConstraint instead.");if(null!=t.padding&&"same"!==t.padding&&"valid"!==t.padding)throw new ValueError$1(`SeparableConv${this.rank}D supports only padding modes: 'same' and 'valid', but received ${JSON.stringify(t.padding)}`);this.depthMultiplier=null==t.depthMultiplier?1:t.depthMultiplier,this.depthwiseInitializer=getInitializer$1(t.depthwiseInitializer||this.DEFAULT_DEPTHWISE_INITIALIZER),this.depthwiseRegularizer=getRegularizer$1(t.depthwiseRegularizer),this.depthwiseConstraint=getConstraint$1(t.depthwiseConstraint),this.pointwiseInitializer=getInitializer$1(t.depthwiseInitializer||this.DEFAULT_POINTWISE_INITIALIZER),this.pointwiseRegularizer=getRegularizer$1(t.pointwiseRegularizer),this.pointwiseConstraint=getConstraint$1(t.pointwiseConstraint)}build(e){if((e=getExactlyOneShape$1(e)).length<this.rank+2)throw new ValueError$1(`Inputs to SeparableConv${this.rank}D should have rank ${this.rank+2}, but received input shape: ${JSON.stringify(e)}`);const t="channelsFirst"===this.dataFormat?1:e.length-1;if(null==e[t]||e[t]<0)throw new ValueError$1(`The channel dimension of the inputs should be defined, but found ${JSON.stringify(e[t])}`);const n=e[t],r=this.kernelSize.concat([n,this.depthMultiplier]),a=[];for(let e=0;e<this.rank;++e)a.push(1);a.push(n*this.depthMultiplier,this.filters);const s=!0;this.depthwiseKernel=this.addWeight("depthwise_kernel",r,"float32",this.depthwiseInitializer,this.depthwiseRegularizer,s,this.depthwiseConstraint),this.pointwiseKernel=this.addWeight("pointwise_kernel",a,"float32",this.pointwiseInitializer,this.pointwiseRegularizer,s,this.pointwiseConstraint),this.bias=this.useBias?this.addWeight("bias",[this.filters],"float32",this.biasInitializer,this.biasRegularizer,s,this.biasConstraint):null,this.inputSpec=[new InputSpec$1({ndim:this.rank+2,axes:{[t]:n}})],this.built=!0}call(e,t){return tidy$1(()=>{let t;if(e=getExactlyOneTensor$1(e),1===this.rank)throw new NotImplementedError$1("1D separable convolution is not implemented yet.");return 2===this.rank&&("channelsFirst"===this.dataFormat&&(e=transpose$5(e,[0,2,3,1])),t=separableConv2d$2(e,this.depthwiseKernel.read(),this.pointwiseKernel.read(),this.strides,this.padding,this.dilationRate,"NHWC")),this.useBias&&(t=biasAdd$1(t,this.bias.read(),this.dataFormat)),null!=this.activation&&(t=this.activation.apply(t)),"channelsFirst"===this.dataFormat&&(t=transpose$5(t,[0,3,1,2])),t})}getConfig(){const e=super.getConfig();return delete e.rank,delete e.kernelInitializer,delete e.kernelRegularizer,delete e.kernelConstraint,e.depthwiseInitializer=serializeInitializer$1(this.depthwiseInitializer),e.pointwiseInitializer=serializeInitializer$1(this.pointwiseInitializer),e.depthwiseRegularizer=serializeRegularizer$1(this.depthwiseRegularizer),e.pointwiseRegularizer=serializeRegularizer$1(this.pointwiseRegularizer),e.depthwiseConstraint=serializeConstraint$1(this.depthwiseConstraint),e.pointwiseConstraint=serializeConstraint$1(this.pointwiseConstraint),e}}SeparableConv$1.className="SeparableConv";class SeparableConv2D$1 extends SeparableConv$1{constructor(e){super(2,e)}}SeparableConv2D$1.className="SeparableConv2D",registerClass$1(SeparableConv2D$1);class Conv1D$1 extends Conv$1{constructor(e){super(1,e),Conv1D$1.verifyArgs(e),this.inputSpec=[{ndim:3}]}getConfig(){const e=super.getConfig();return delete e.rank,delete e.dataFormat,e}static verifyArgs(e){if("number"!=typeof e.kernelSize&&!checkArrayTypeAndLength$1(e.kernelSize,"number",1,1))throw new ValueError$1(`Conv1D expects config.kernelSize to be number or number[] with length 1, but received ${JSON.stringify(e.kernelSize)}.`)}}Conv1D$1.className="Conv1D",registerClass$1(Conv1D$1);class Cropping2D$1 extends Layer$1{constructor(e){super(e),this.cropping="number"==typeof e.cropping?[[e.cropping,e.cropping],[e.cropping,e.cropping]]:"number"==typeof e.cropping[0]?[[e.cropping[0],e.cropping[0]],[e.cropping[1],e.cropping[1]]]:e.cropping,this.dataFormat=void 0===e.dataFormat?"channelsLast":e.dataFormat,this.inputSpec=[{ndim:4}]}computeOutputShape(e){return"channelsFirst"===this.dataFormat?[e[0],e[1],e[2]-this.cropping[0][0]-this.cropping[0][1],e[3]-this.cropping[1][0]-this.cropping[1][1]]:[e[0],e[1]-this.cropping[0][0]-this.cropping[0][1],e[2]-this.cropping[1][0]-this.cropping[1][1],e[3]]}call(e,t){return tidy$1(()=>{if(e=getExactlyOneTensor$1(e),"channelsLast"===this.dataFormat){const t=sliceAlongAxis$1(e,this.cropping[0][0],e.shape[1]-this.cropping[0][0]-this.cropping[0][1],2);return sliceAlongAxis$1(t,this.cropping[1][0],e.shape[2]-this.cropping[1][1]-this.cropping[1][0],3)}{const t=sliceAlongAxis$1(e,this.cropping[0][0],e.shape[2]-this.cropping[0][0]-this.cropping[0][1],3);return sliceAlongAxis$1(t,this.cropping[1][0],e.shape[3]-this.cropping[1][1]-this.cropping[1][0],4)}})}getConfig(){const e={cropping:this.cropping,dataFormat:this.dataFormat},t=super.getConfig();return Object.assign(e,t),e}}Cropping2D$1.className="Cropping2D",registerClass$1(Cropping2D$1);class UpSampling2D$1 extends Layer$1{constructor(e){super(e),this.DEFAULT_SIZE=[2,2],this.inputSpec=[{ndim:4}],this.size=null==e.size?this.DEFAULT_SIZE:e.size,this.dataFormat=null==e.dataFormat?"channelsLast":e.dataFormat,checkDataFormat$1(this.dataFormat),this.interpolation=null==e.interpolation?"nearest":e.interpolation,checkInterpolationFormat$1(this.interpolation)}computeOutputShape(e){return"channelsFirst"===this.dataFormat?[e[0],e[1],null==e[2]?null:this.size[0]*e[2],null==e[3]?null:this.size[1]*e[3]]:[e[0],null==e[1]?null:this.size[0]*e[1],null==e[2]?null:this.size[1]*e[2],e[3]]}call(e,t){return tidy$1(()=>{let t=getExactlyOneTensor$1(e);const n=t.shape;if("channelsFirst"===this.dataFormat){t=transpose$5(t,[0,2,3,1]);const e=this.size[0]*n[2],r=this.size[1]*n[3],a="nearest"===this.interpolation?image$2.resizeNearestNeighbor(t,[e,r]):image$2.resizeBilinear(t,[e,r]);return transpose$5(a,[0,3,1,2])}{const e=this.size[0]*n[1],r=this.size[1]*n[2];return"nearest"===this.interpolation?image$2.resizeNearestNeighbor(t,[e,r]):image$2.resizeBilinear(t,[e,r])}})}getConfig(){const e={size:this.size,dataFormat:this.dataFormat},t=super.getConfig();return Object.assign(e,t),e}}function depthwiseConv2d$4(e,t,n=[1,1],r="valid",a,s){return tidy$1(()=>{null==a&&(a=imageDataFormat$1()),checkDataFormat$1(a);let o=preprocessConv2DInput$1(e,a);if(4!==e.rank)throw new ValueError$1(`Input for depthwiseConv2d is required to be 4-D, but is instead ${e.rank}-D`);if(4!==t.rank)throw new ValueError$1(`depthwiseKernel is required to be 4-D, but is instead ${t.rank}-D`);return o=depthwiseConv2d$5(o,t,n,"same"===r?"same":"valid","NHWC",s),"channelsFirst"===a&&(o=transpose$5(o,[0,3,1,2])),o})}UpSampling2D$1.className="UpSampling2D",registerClass$1(UpSampling2D$1);class DepthwiseConv2D$1 extends BaseConv$1{constructor(e){super(2,e),this.depthwiseKernel=null,this.depthMultiplier=null==e.depthMultiplier?1:e.depthMultiplier,this.depthwiseInitializer=getInitializer$1(e.depthwiseInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.depthwiseConstraint=getConstraint$1(e.depthwiseConstraint),this.depthwiseRegularizer=getRegularizer$1(e.depthwiseRegularizer)}build(e){if((e=getExactlyOneShape$1(e)).length<4)throw new ValueError$1(`Inputs to DepthwiseConv2D should have rank 4. Received input shape: ${JSON.stringify(e)}.`);const t="channelsFirst"===this.dataFormat?1:3;if(null==e[t]||e[t]<0)throw new ValueError$1(`The channel dimension of the inputs to DepthwiseConv2D should be defined, but is not (${e[t]}).`);const n=e[t];this.depthwiseKernel=this.addWeight("depthwise_kernel",[this.kernelSize[0],this.kernelSize[1],n,this.depthMultiplier],null,this.depthwiseInitializer,this.depthwiseRegularizer,!0,this.depthwiseConstraint),this.bias=this.useBias?this.addWeight("bias",[n*this.depthMultiplier],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint):null,this.built=!0}call(e,t){return tidy$1(()=>{let t=depthwiseConv2d$4(e=getExactlyOneTensor$1(e),this.depthwiseKernel.read(),this.strides,this.padding,this.dataFormat,null);return this.useBias&&(t=biasAdd$1(t,this.bias.read(),this.dataFormat)),null!=this.activation&&(t=this.activation.apply(t)),t})}computeOutputShape(e){e=getExactlyOneShape$1(e);const t="channelsFirst"===this.dataFormat?e[3]:e[2],n="channelsFirst"===this.dataFormat?e[1]*this.depthMultiplier:e[3]*this.depthMultiplier,r=convOutputLength$1("channelsFirst"===this.dataFormat?e[2]:e[1],this.kernelSize[0],this.padding,this.strides[0]),a=convOutputLength$1(t,this.kernelSize[1],this.padding,this.strides[1]);return"channelsFirst"===this.dataFormat?[e[0],n,r,a]:[e[0],r,a,n]}getConfig(){const e=super.getConfig();return e.depthMultiplier=this.depthMultiplier,e.depthwiseInitializer=serializeInitializer$1(this.depthwiseInitializer),e.depthwiseRegularizer=serializeRegularizer$1(this.depthwiseRegularizer),e.depthwiseConstraint=serializeConstraint$1(this.depthwiseRegularizer),e}}function standardizeArgs$1(e,t,n,r){if(Array.isArray(e)){if(null!=t||null!=n)throw new ValueError$1("When inputs is an array, neither initialState or constants should be provided");null!=r&&(n=e.slice(e.length-r,e.length),e=e.slice(0,e.length-r)),e.length>1&&(t=e.slice(1,e.length)),e=e[0]}function a(e){return null==e||Array.isArray(e)?e:[e]}return{inputs:e,initialState:t=a(t),constants:n=a(n)}}function rnn$2(e,t,n,r=!1,a,s,o=!1,i=!1){return tidy$1(()=>{const l=t.shape.length;if(l<3)throw new ValueError$1(`Input should be at least 3D, but is ${l}D.`);const u=[1,0].concat(range$7(2,l));if(t=transpose$5(t,u),null!=s)throw new NotImplementedError$1("The rnn() functoin of the deeplearn.js backend does not support constants yet.");o&&console.warn("Backend rnn(): the unroll = true option is not applicable to the imperative deeplearn.js backend."),null!=a&&((a=cast$7(cast$7(a,"bool"),"float32")).rank===l-1&&(a=expandDims$7(a,-1)),a=transpose$5(a,u)),r&&(t=reverse$5(t,0),null!=a&&(a=reverse$5(a,0)));const c=[];let p,d=n;const h=t.shape[0],m=unstack$1(t);let f,g;null!=a&&(f=unstack$1(a));for(let t=0;t<h;++t){const n=m[t],r=tidy$1(()=>e(n,d));if(null==a)p=r[0],d=r[1];else{const e=tidy$1(()=>{const e=f[t],n=sub$5(onesLike$5(e),e);return{output:add$5(mul$1(r[0],e),mul$1(d[0],n)),newStates:d.map((t,a)=>add$5(mul$1(r[1][a],e),mul$1(t,n)))}});p=e.output,d=e.newStates}i&&c.push(p)}return i&&(g=stack$1(c,1)),[p,g,d]})}DepthwiseConv2D$1.className="DepthwiseConv2D",registerClass$1(DepthwiseConv2D$1);class RNN$1 extends Layer$1{constructor(e){let t;if(super(e),null==e.cell)throw new ValueError$1("cell property is missing for the constructor of RNN.");if(t=Array.isArray(e.cell)?new StackedRNNCells$1({cells:e.cell}):e.cell,null==t.stateSize)throw new ValueError$1("The RNN cell should have an attribute `stateSize` (tuple of integers, one integer per RNN state).");this.cell=t,this.returnSequences=null!=e.returnSequences&&e.returnSequences,this.returnState=null!=e.returnState&&e.returnState,this.goBackwards=null!=e.goBackwards&&e.goBackwards,this._stateful=null!=e.stateful&&e.stateful,this.unroll=null!=e.unroll&&e.unroll,this.supportsMasking=!0,this.inputSpec=[new InputSpec$1({ndim:3})],this.stateSpec=null,this.states_=null,this.numConstants=null,this.keptStates=[]}getStates(){return null==this.states_?range$7(0,Array.isArray(this.cell.stateSize)?this.cell.stateSize.length:1).map(e=>null):this.states_}setStates(e){this.states_=e}computeOutputShape(e){isArrayOfShapes$1(e)&&(e=e[0]),e=e;let t=this.cell.stateSize;Array.isArray(t)||(t=[t]);const n=t[0];let r;if(r=this.returnSequences?[e[0],e[1],n]:[e[0],n],this.returnState){const n=[];for(const r of t)n.push([e[0],r]);return[r].concat(n)}return r}computeMask(e,t){return tidy$1(()=>{Array.isArray(t)&&(t=t[0]);const e=this.returnSequences?t:null;if(this.returnState){const t=this.states.map(e=>null);return[e].concat(t)}return e})}get states(){if(null==this.states_){const e=Array.isArray(this.cell.stateSize)?this.cell.stateSize.length:1,t=[];for(let n=0;n<e;++n)t.push(null);return t}return this.states_}set states(e){this.states_=e}build(e){if(null!=this.numConstants)throw new NotImplementedError$1("Constants support is not implemented in RNN yet.");isArrayOfShapes$1(e)&&(e=e[0]),e=e;const t=this.stateful?e[0]:null,n=e.slice(2);this.inputSpec[0]=new InputSpec$1({shape:[t,null,...n]});const r=[e[0]].concat(e.slice(2));let a;if(this.cell.build(r),a=Array.isArray(this.cell.stateSize)?this.cell.stateSize:[this.cell.stateSize],null!=this.stateSpec){if(!arraysEqual$1(this.stateSpec.map(e=>e.shape[e.shape.length-1]),a))throw new ValueError$1(`An initialState was passed that is not compatible with cell.stateSize. Received stateSpec=${this.stateSpec}; However cell.stateSize is ${this.cell.stateSize}`)}else this.stateSpec=a.map(e=>new InputSpec$1({shape:[null,e]}));this.stateful&&this.resetStates()}resetStates(e,t=!1){tidy$1(()=>{if(!this.stateful)throw new AttributeError$1("Cannot call resetStates() on an RNN Layer that is not stateful.");const n=this.inputSpec[0].shape[0];if(null==n)throw new ValueError$1("If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.");if(null==this.states_)this.states_=Array.isArray(this.cell.stateSize)?this.cell.stateSize.map(e=>zeros$4([n,e])):[zeros$4([n,this.cell.stateSize])];else if(null==e)dispose$1(this.states_),null!=this.keptStates&&(dispose$1(this.keptStates),this.keptStates=[]),Array.isArray(this.cell.stateSize)?this.states_=this.cell.stateSize.map(e=>zeros$4([n,e])):this.states_[0]=zeros$4([n,this.cell.stateSize]);else{if(Array.isArray(e)||(e=[e]),e.length!==this.states_.length)throw new ValueError$1(`Layer ${this.name} expects ${this.states_.length} state(s), but it received ${e.length} state value(s). Input received: ${e}`);!0===t?this.keptStates.push(this.states_.slice()):dispose$1(this.states_);for(let t=0;t<this.states_.length;++t){const r=e[t],a=Array.isArray(this.cell.stateSize)?this.cell.stateSize[t]:this.cell.stateSize,s=[n,a];if(!arraysEqual$1(r.shape,s))throw new ValueError$1(`State ${t} is incompatible with layer ${this.name}: expected shape=${s}, received shape=${r.shape}`);this.states_[t]=r}}this.states_=this.states_.map(e=>keep$1(e.clone()))})}apply(e,t){let n=null==t?null:t.initialState,r=null==t?null:t.constants;null==t&&(t={});const a=standardizeArgs$1(e,n,r,this.numConstants);e=a.inputs,n=a.initialState,r=a.constants;let s=[],o=[];if(null!=n){t.initialState=n,s=s.concat(n),this.stateSpec=[];for(const e of n)this.stateSpec.push(new InputSpec$1({shape:e.shape}));o=o.concat(this.stateSpec)}if(null!=r&&(t.constants=r,s=s.concat(r),this.numConstants=r.length),s[0]instanceof SymbolicTensor$1){const n=[e].concat(s),r=this.inputSpec.concat(o),a=this.inputSpec;this.inputSpec=r;const i=super.apply(n,t);return this.inputSpec=a,i}return super.apply(e,t)}call(e,t){return tidy$1(()=>{const n=null==t?null:t.mask,r=null==t?null:t.training;let a=null==t?null:t.initialState;e=getExactlyOneTensor$1(e),null==a&&(a=this.stateful?this.states_:this.getInitialState(e));const s=Array.isArray(this.cell.stateSize)?this.cell.stateSize.length:1;if(a.length!==s)throw new ValueError$1(`RNN Layer has ${s} state(s) but was passed ${a.length} initial state(s).`);this.unroll&&console.warn("Ignoring unroll = true for RNN layer, due to imperative backend.");const o={training:r},i=rnn$2((e,t)=>{const n=this.cell.call([e].concat(t),o);return[n[0],n.slice(1)]},e,a,this.goBackwards,n,null,this.unroll,this.returnSequences),l=i[0],u=i[1],c=i[2];this.stateful&&this.resetStates(c,r);const p=this.returnSequences?u:l;return this.returnState?[p].concat(c):p})}getInitialState(e){return tidy$1(()=>{let t=zeros$4(e.shape);return t=sum$6(t,[1,2]),t=expandDims$6(t),Array.isArray(this.cell.stateSize)?this.cell.stateSize.map(e=>e>1?tile$6(t,[1,e]):t):this.cell.stateSize>1?[tile$6(t,[1,this.cell.stateSize])]:[t]})}get trainableWeights(){return this.trainable?this.cell.trainableWeights:[]}get nonTrainableWeights(){return this.trainable?this.cell.nonTrainableWeights:this.cell.weights}setFastWeightInitDuringBuild(e){super.setFastWeightInitDuringBuild(e),null!=this.cell&&this.cell.setFastWeightInitDuringBuild(e)}getConfig(){const e=super.getConfig(),t={returnSequences:this.returnSequences,returnState:this.returnState,goBackwards:this.goBackwards,stateful:this.stateful,unroll:this.unroll};null!=this.numConstants&&(t.numConstants=this.numConstants);const n=this.cell.getConfig();return this.getClassName()===RNN$1.className&&(t.cell={className:this.cell.getClassName(),config:n}),Object.assign({},n,e,t)}static fromConfig(e,t,n={}){const r=deserialize$1(t.cell,n);return new e(Object.assign(t,{cell:r}))}}RNN$1.className="RNN",registerClass$1(RNN$1);class RNNCell$1 extends Layer$1{}class SimpleRNNCell$1 extends RNNCell$1{constructor(e){super(e),this.DEFAULT_ACTIVATION="tanh",this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_RECURRENT_INITIALIZER="orthogonal",this.DEFAULT_BIAS_INITIALIZER="zeros",this.units=e.units,assertPositiveInteger$1(this.units,"units"),this.activation=getActivation$1(null==e.activation?this.DEFAULT_ACTIVATION:e.activation),this.useBias=null==e.useBias||e.useBias,this.kernelInitializer=getInitializer$1(e.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.recurrentInitializer=getInitializer$1(e.recurrentInitializer||this.DEFAULT_RECURRENT_INITIALIZER),this.biasInitializer=getInitializer$1(e.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.kernelRegularizer=getRegularizer$1(e.kernelRegularizer),this.recurrentRegularizer=getRegularizer$1(e.recurrentRegularizer),this.biasRegularizer=getRegularizer$1(e.biasRegularizer),this.kernelConstraint=getConstraint$1(e.kernelConstraint),this.recurrentConstraint=getConstraint$1(e.recurrentConstraint),this.biasConstraint=getConstraint$1(e.biasConstraint),this.dropout=min$6([1,max$6([0,null==e.dropout?0:e.dropout])]),this.recurrentDropout=min$6([1,max$6([0,null==e.recurrentDropout?0:e.recurrentDropout])]),this.stateSize=this.units,this.dropoutMask=null,this.recurrentDropoutMask=null}build(e){e=getExactlyOneShape$1(e),this.kernel=this.addWeight("kernel",[e[e.length-1],this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.recurrentKernel=this.addWeight("recurrent_kernel",[this.units,this.units],null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.bias=this.useBias?this.addWeight("bias",[this.units],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint):null,this.built=!0}call(e,t){return tidy$1(()=>{if(2!==(e=e).length)throw new ValueError$1(`SimpleRNNCell expects 2 input Tensors, got ${e.length}.`);let n=e[1];e=e[0];const r=null!=t.training&&t.training;let a;0<this.dropout&&this.dropout<1&&null==this.dropoutMask&&(this.dropoutMask=generateDropoutMask$1({ones:()=>onesLike$5(e),rate:this.dropout,training:r})),0<this.recurrentDropout&&this.recurrentDropout<1&&null==this.recurrentDropoutMask&&(this.recurrentDropoutMask=generateDropoutMask$1({ones:()=>onesLike$5(n),rate:this.recurrentDropout,training:r}));const s=this.dropoutMask,o=this.recurrentDropoutMask;a=dot$3(null!=s?mul$1(e,s):e,this.kernel.read()),null!=this.bias&&(a=biasAdd$1(a,this.bias.read())),null!=o&&(n=mul$1(n,o));let i=add$5(a,dot$3(n,this.recurrentKernel.read()));return null!=this.activation&&(i=this.activation.apply(i)),[i,i]})}getConfig(){const e=super.getConfig(),t={units:this.units,activation:serializeActivation$1(this.activation),useBias:this.useBias,kernelInitializer:serializeInitializer$1(this.kernelInitializer),recurrentInitializer:serializeInitializer$1(this.recurrentInitializer),biasInitializer:serializeInitializer$1(this.biasInitializer),kernelRegularizer:serializeRegularizer$1(this.kernelRegularizer),recurrentRegularizer:serializeRegularizer$1(this.recurrentRegularizer),biasRegularizer:serializeRegularizer$1(this.biasRegularizer),activityRegularizer:serializeRegularizer$1(this.activityRegularizer),kernelConstraint:serializeConstraint$1(this.kernelConstraint),recurrentConstraint:serializeConstraint$1(this.recurrentConstraint),biasConstraint:serializeConstraint$1(this.biasConstraint),dropout:this.dropout,recurrentDropout:this.recurrentDropout};return Object.assign({},e,t)}}SimpleRNNCell$1.className="SimpleRNNCell",registerClass$1(SimpleRNNCell$1);class SimpleRNN$1 extends RNN$1{constructor(e){e.cell=new SimpleRNNCell$1(e),super(e)}call(e,t){return tidy$1(()=>(null!=this.cell.dropoutMask&&(dispose$1(this.cell.dropoutMask),this.cell.dropoutMask=null),null!=this.cell.recurrentDropoutMask&&(dispose$1(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null),super.call(e,{mask:null==t?null:t.mask,training:null==t?null:t.training,initialState:null==t?null:t.initialState})))}static fromConfig(e,t){return new e(t)}}SimpleRNN$1.className="SimpleRNN",registerClass$1(SimpleRNN$1);class GRUCell$1 extends RNNCell$1{constructor(e){if(super(e),this.DEFAULT_ACTIVATION="tanh",this.DEFAULT_RECURRENT_ACTIVATION="hardSigmoid",this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_RECURRENT_INITIALIZER="orthogonal",this.DEFAULT_BIAS_INITIALIZER="zeros",e.resetAfter)throw new ValueError$1("GRUCell does not support reset_after parameter set to true.");this.units=e.units,assertPositiveInteger$1(this.units,"units"),this.activation=getActivation$1(void 0===e.activation?this.DEFAULT_ACTIVATION:e.activation),this.recurrentActivation=getActivation$1(void 0===e.recurrentActivation?this.DEFAULT_RECURRENT_ACTIVATION:e.recurrentActivation),this.useBias=null==e.useBias||e.useBias,this.kernelInitializer=getInitializer$1(e.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.recurrentInitializer=getInitializer$1(e.recurrentInitializer||this.DEFAULT_RECURRENT_INITIALIZER),this.biasInitializer=getInitializer$1(e.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.kernelRegularizer=getRegularizer$1(e.kernelRegularizer),this.recurrentRegularizer=getRegularizer$1(e.recurrentRegularizer),this.biasRegularizer=getRegularizer$1(e.biasRegularizer),this.kernelConstraint=getConstraint$1(e.kernelConstraint),this.recurrentConstraint=getConstraint$1(e.recurrentConstraint),this.biasConstraint=getConstraint$1(e.biasConstraint),this.dropout=min$6([1,max$6([0,null==e.dropout?0:e.dropout])]),this.recurrentDropout=min$6([1,max$6([0,null==e.recurrentDropout?0:e.recurrentDropout])]),this.implementation=e.implementation,this.stateSize=this.units,this.dropoutMask=null,this.recurrentDropoutMask=null}build(e){e=getExactlyOneShape$1(e),this.kernel=this.addWeight("kernel",[e[e.length-1],3*this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.recurrentKernel=this.addWeight("recurrent_kernel",[this.units,3*this.units],null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.bias=this.useBias?this.addWeight("bias",[3*this.units],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint):null,this.built=!0}call(e,t){return tidy$1(()=>{if(2!==(e=e).length)throw new ValueError$1(`GRUCell expects 2 input Tensors (inputs, h, c), got ${e.length}.`);const n=null!=t.training&&t.training;let r=e[1];e=e[0],0<this.dropout&&this.dropout<1&&null==this.dropoutMask&&(this.dropoutMask=generateDropoutMask$1({ones:()=>onesLike$5(e),rate:this.dropout,training:n,count:3})),0<this.recurrentDropout&&this.recurrentDropout<1&&null==this.recurrentDropoutMask&&(this.recurrentDropoutMask=generateDropoutMask$1({ones:()=>onesLike$5(r),rate:this.recurrentDropout,training:n,count:3}));const a=this.recurrentDropoutMask;let s,o,i;0<this.dropout&&this.dropout<1&&(e=mul$1(e,this.dropoutMask[0]));let l=dot$3(e,this.kernel.read());this.useBias&&(l=biasAdd$1(l,this.bias.read())),0<this.recurrentDropout&&this.recurrentDropout<1&&(r=mul$1(r,a[0]));const u=this.recurrentKernel.read(),[c,p]=split$4(u,[2*this.units,this.units],u.rank-1),d=dot$3(r,c),[h,m,f]=split$4(l,3,l.rank-1),[g,$]=split$4(d,2,d.rank-1);s=this.recurrentActivation.apply(add$5(h,g)),o=this.recurrentActivation.apply(add$5(m,$));const y=dot$3(mul$1(o,r),p);i=this.activation.apply(add$5(f,y));const b=add$5(mul$1(s,r),mul$1(add$5(1,neg$5(s)),i));return[b,b]})}getConfig(){const e=super.getConfig(),t={units:this.units,activation:serializeActivation$1(this.activation),recurrentActivation:serializeActivation$1(this.recurrentActivation),useBias:this.useBias,kernelInitializer:serializeInitializer$1(this.kernelInitializer),recurrentInitializer:serializeInitializer$1(this.recurrentInitializer),biasInitializer:serializeInitializer$1(this.biasInitializer),kernelRegularizer:serializeRegularizer$1(this.kernelRegularizer),recurrentRegularizer:serializeRegularizer$1(this.recurrentRegularizer),biasRegularizer:serializeRegularizer$1(this.biasRegularizer),activityRegularizer:serializeRegularizer$1(this.activityRegularizer),kernelConstraint:serializeConstraint$1(this.kernelConstraint),recurrentConstraint:serializeConstraint$1(this.recurrentConstraint),biasConstraint:serializeConstraint$1(this.biasConstraint),dropout:this.dropout,recurrentDropout:this.recurrentDropout,implementation:this.implementation,resetAfter:!1};return Object.assign({},e,t)}}GRUCell$1.className="GRUCell",registerClass$1(GRUCell$1);class GRU$1 extends RNN$1{constructor(e){0===e.implementation&&console.warn("`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call."),e.cell=new GRUCell$1(e),super(e)}call(e,t){return tidy$1(()=>(null!=this.cell.dropoutMask&&(dispose$1(this.cell.dropoutMask),this.cell.dropoutMask=null),null!=this.cell.recurrentDropoutMask&&(dispose$1(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null),super.call(e,{mask:null==t?null:t.mask,training:null==t?null:t.training,initialState:null==t?null:t.initialState})))}static fromConfig(e,t){return 0===t.implmentation&&(t.implementation=1),new e(t)}}GRU$1.className="GRU",registerClass$1(GRU$1);class LSTMCell$1 extends RNNCell$1{constructor(e){super(e),this.DEFAULT_ACTIVATION="tanh",this.DEFAULT_RECURRENT_ACTIVATION="hardSigmoid",this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_RECURRENT_INITIALIZER="orthogonal",this.DEFAULT_BIAS_INITIALIZER="zeros",this.units=e.units,assertPositiveInteger$1(this.units,"units"),this.activation=getActivation$1(void 0===e.activation?this.DEFAULT_ACTIVATION:e.activation),this.recurrentActivation=getActivation$1(void 0===e.recurrentActivation?this.DEFAULT_RECURRENT_ACTIVATION:e.recurrentActivation),this.useBias=null==e.useBias||e.useBias,this.kernelInitializer=getInitializer$1(e.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.recurrentInitializer=getInitializer$1(e.recurrentInitializer||this.DEFAULT_RECURRENT_INITIALIZER),this.biasInitializer=getInitializer$1(e.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.unitForgetBias=e.unitForgetBias,this.kernelRegularizer=getRegularizer$1(e.kernelRegularizer),this.recurrentRegularizer=getRegularizer$1(e.recurrentRegularizer),this.biasRegularizer=getRegularizer$1(e.biasRegularizer),this.kernelConstraint=getConstraint$1(e.kernelConstraint),this.recurrentConstraint=getConstraint$1(e.recurrentConstraint),this.biasConstraint=getConstraint$1(e.biasConstraint),this.dropout=min$6([1,max$6([0,null==e.dropout?0:e.dropout])]),this.recurrentDropout=min$6([1,max$6([0,null==e.recurrentDropout?0:e.recurrentDropout])]),this.implementation=e.implementation,this.stateSize=[this.units,this.units],this.dropoutMask=null,this.recurrentDropoutMask=null}build(e){var t;let n;if(e=getExactlyOneShape$1(e),this.kernel=this.addWeight("kernel",[e[e.length-1],4*this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.recurrentKernel=this.addWeight("recurrent_kernel",[this.units,4*this.units],null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.useBias){if(this.unitForgetBias){const e=this.biasInitializer,r=this.units;n=new((t=class extends Initializer$1{apply(t,n){const a=e.apply([r]),s=(new Ones$1).apply([r]),o=e.apply([2*r]);return concatAlongFirstAxis$1(concatAlongFirstAxis$1(a,s),o)}}).className="CustomInit",t)}else n=this.biasInitializer;this.bias=this.addWeight("bias",[4*this.units],null,n,this.biasRegularizer,!0,this.biasConstraint)}else this.bias=null;this.built=!0}call(e,t){return tidy$1(()=>{const n=null!=t.training&&t.training;if(3!==(e=e).length)throw new ValueError$1(`LSTMCell expects 3 input Tensors (inputs, h, c), got ${e.length}.`);let r=e[1];const a=e[2];e=e[0],0<this.dropout&&this.dropout<1&&null==this.dropoutMask&&(this.dropoutMask=generateDropoutMask$1({ones:()=>onesLike$5(e),rate:this.dropout,training:n,count:4})),0<this.recurrentDropout&&this.recurrentDropout<1&&null==this.recurrentDropoutMask&&(this.recurrentDropoutMask=generateDropoutMask$1({ones:()=>onesLike$5(r),rate:this.recurrentDropout,training:n,count:4}));const s=this.recurrentDropoutMask;let o,i,l,u;0<this.dropout&&this.dropout<1&&(e=mul$1(e,this.dropoutMask[0]));let c=dot$3(e,this.kernel.read());0<this.recurrentDropout&&this.recurrentDropout<1&&(r=mul$1(r,s[0])),c=add$5(c,dot$3(r,this.recurrentKernel.read())),this.useBias&&(c=biasAdd$1(c,this.bias.read()));const[p,d,h,m]=split$4(c,4,c.rank-1);o=this.recurrentActivation.apply(p),i=this.recurrentActivation.apply(d),l=add$5(mul$1(i,a),mul$1(o,this.activation.apply(h))),u=this.recurrentActivation.apply(m);const f=mul$1(u,this.activation.apply(l));return[f,f,l]})}getConfig(){const e=super.getConfig(),t={units:this.units,activation:serializeActivation$1(this.activation),recurrentActivation:serializeActivation$1(this.recurrentActivation),useBias:this.useBias,kernelInitializer:serializeInitializer$1(this.kernelInitializer),recurrentInitializer:serializeInitializer$1(this.recurrentInitializer),biasInitializer:serializeInitializer$1(this.biasInitializer),unitForgetBias:this.unitForgetBias,kernelRegularizer:serializeRegularizer$1(this.kernelRegularizer),recurrentRegularizer:serializeRegularizer$1(this.recurrentRegularizer),biasRegularizer:serializeRegularizer$1(this.biasRegularizer),activityRegularizer:serializeRegularizer$1(this.activityRegularizer),kernelConstraint:serializeConstraint$1(this.kernelConstraint),recurrentConstraint:serializeConstraint$1(this.recurrentConstraint),biasConstraint:serializeConstraint$1(this.biasConstraint),dropout:this.dropout,recurrentDropout:this.recurrentDropout,implementation:this.implementation};return Object.assign({},e,t)}}LSTMCell$1.className="LSTMCell",registerClass$1(LSTMCell$1);class LSTM$1 extends RNN$1{constructor(e){0===e.implementation&&console.warn("`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call."),e.cell=new LSTMCell$1(e),super(e)}call(e,t){return tidy$1(()=>(null!=this.cell.dropoutMask&&(dispose$1(this.cell.dropoutMask),this.cell.dropoutMask=null),null!=this.cell.recurrentDropoutMask&&(dispose$1(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null),super.call(e,{mask:null==t?null:t.mask,training:null==t?null:t.training,initialState:null==t?null:t.initialState})))}static fromConfig(e,t){return 0===t.implmentation&&(t.implementation=1),new e(t)}}LSTM$1.className="LSTM",registerClass$1(LSTM$1);class StackedRNNCells$1 extends RNNCell$1{constructor(e){super(e),this.cells=e.cells}get stateSize(){const e=[];for(const t of this.cells.slice().reverse())Array.isArray(t.stateSize)?e.push(...t.stateSize):e.push(t.stateSize);return e}call(e,t){return tidy$1(()=>{let n=(e=e).slice(1);const r=[];for(const e of this.cells.slice().reverse())Array.isArray(e.stateSize)?r.push(n.splice(0,e.stateSize.length)):r.push(n.splice(0,1));r.reverse();const a=[];let s;for(let o=0;o<this.cells.length;++o){const i=this.cells[o];n=r[o],s=0===o?[e[0]].concat(n):[s[0]].concat(n),s=i.call(s,t),a.push(s.slice(1))}n=[];for(const e of a.slice().reverse())n.push(...e);return[s[0]].concat(n)})}build(e){let t;isArrayOfShapes$1(e)&&(e=e[0]),e=e,this.cells.forEach((n,r)=>{nameScope$1(`RNNCell_${r}`,()=>{n.build(e),t=Array.isArray(n.stateSize)?n.stateSize[0]:n.stateSize,e=[e[0],t]})}),this.built=!0}getConfig(){const e=super.getConfig(),t=this.cells.map(e=>({className:e.getClassName(),config:e.getConfig()}));return Object.assign({},e,{cells:t})}static fromConfig(e,t,n={}){const r=[];for(const e of t.cells)r.push(deserialize$1(e,n));return new e({cells:r})}get trainableWeights(){if(!this.trainable)return[];const e=[];for(const t of this.cells)e.push(...t.trainableWeights);return e}get nonTrainableWeights(){const e=[];for(const t of this.cells)e.push(...t.nonTrainableWeights);if(!this.trainable){const t=[];for(const e of this.cells)t.push(...e.trainableWeights);return t.concat(e)}return e}getWeights(){const e=[];for(const t of this.cells)e.push(...t.weights);return batchGetValue$1(e)}setWeights(e){const t=[];for(const n of this.cells){const r=e.splice(n.weights.length);for(let e=0;e<n.weights.length;++e)t.push([n.weights[e],r[e]])}batchSetValue$1(t)}}function generateDropoutMask$1(e){const{ones:t,rate:n,training:r=!1,count:a=1}=e,s=()=>dropout$4(t(),n),o=()=>inTrainPhase$1(s,t,r);return!a||a<=1?keep$1(o().clone()):Array(a).fill(void 0).map(o).map(e=>keep$1(e.clone()))}StackedRNNCells$1.className="StackedRNNCells",registerClass$1(StackedRNNCells$1);var __rest$1=function(e,t){var n={};for(var r in e)Object.prototype.hasOwnProperty.call(e,r)&&t.indexOf(r)<0&&(n[r]=e[r]);if(null!=e&&"function"==typeof Object.getOwnPropertySymbols){var a=0;for(r=Object.getOwnPropertySymbols(e);a<r.length;a++)t.indexOf(r[a])<0&&Object.prototype.propertyIsEnumerable.call(e,r[a])&&(n[r[a]]=e[r[a]])}return n};class ConvRNN2D$1 extends RNN$1{constructor(e){if(e.unroll)throw new NotImplementedError$1("Unrolling is not possible with convolutional RNNs.");if(Array.isArray(e.cell))throw new NotImplementedError$1("It is not possible at the moment to stack convolutional cells.");super(e),this.inputSpec=[new InputSpec$1({ndim:5})]}call(e,t){return tidy$1(()=>{if(null!=this.cell.dropoutMask&&(dispose$1(this.cell.dropoutMask),this.cell.dropoutMask=null),null!=this.cell.recurrentDropoutMask&&(dispose$1(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null),t&&t.constants)throw new ValueError$1("ConvRNN2D cell does not support constants");return super.call(e,{mask:null==t?null:t.mask,training:null==t?null:t.training,initialState:null==t?null:t.initialState})})}computeOutputShape(e){let t=this.computeSingleOutputShape(e);return this.returnSequences||(t=[t[0],...t.slice(2)]),this.returnState&&(t=[t,...Array(2).fill([e[0],...t.slice(-3)])]),t}getInitialState(e){return tidy$1(()=>{const{stateSize:t}=this.cell,n=this.computeSingleOutputShape(e.shape),r=zeros$4([n[0],...n.slice(2)]);return Array.isArray(t)?Array(t.length).fill(r):[r]})}resetStates(e,t=!1){tidy$1(()=>{if(!this.stateful)throw new AttributeError$1("Cannot call resetStates() on an RNN Layer that is not stateful.");const n=this.inputSpec[0].shape,r=this.computeSingleOutputShape(n),a=[r[0],...r.slice(2)];if(null==n[0])throw new ValueError$1("If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.");if(null==this.getStates())this.states_=Array.isArray(this.cell.stateSize)?this.cell.stateSize.map(()=>zeros$4(a)):[zeros$4(a)];else if(null==e)dispose$1(this.states_),null!=this.keptStates&&(dispose$1(this.keptStates),this.keptStates=[]),Array.isArray(this.cell.stateSize)?this.states_=this.cell.stateSize.map(()=>zeros$4(a)):this.states_[0]=zeros$4(a);else{if(Array.isArray(e)||(e=[e]),e.length!==this.states_.length)throw new ValueError$1(`Layer ${this.name} expects ${this.states_.length} state(s), but it received ${e.length} state value(s). Input received: ${e}`);t?this.keptStates.push(this.states_.slice()):dispose$1(this.states_);for(let t=0;t<this.states_.length;++t){const n=e[t],r=a;if(!arraysEqual$1(n.shape,r))throw new ValueError$1(`State ${t} is incompatible with layer ${this.name}: expected shape=${r}, received shape=${n.shape}`);this.states_[t]=n}}this.states_=this.states_.map(e=>keep$1(e.clone()))})}computeSingleOutputShape(e){const{dataFormat:t,filters:n,kernelSize:r,padding:a,strides:s,dilationRate:o}=this.cell,i="channelsFirst"===t,l=e[i?4:3],u=convOutputLength$1(e[i?3:2],r[0],a,s[0],o[0]),c=convOutputLength$1(l,r[1],a,s[1],o[1]);return[...e.slice(0,2),...i?[n,u,c]:[u,c,n]]}}ConvRNN2D$1.className="ConvRNN2D";class ConvLSTM2DCell$1 extends LSTMCell$1{constructor(e){const{filters:t,kernelSize:n,strides:r,padding:a,dataFormat:s,dilationRate:o}=e;super(Object.assign({},e,{units:t})),this.filters=t,assertPositiveInteger$1(this.filters,"filters"),this.kernelSize=normalizeArray$1(n,2,"kernelSize"),this.kernelSize.forEach(e=>assertPositiveInteger$1(e,"kernelSize")),this.strides=normalizeArray$1(r||1,2,"strides"),this.strides.forEach(e=>assertPositiveInteger$1(e,"strides")),this.padding=a||"valid",checkPaddingMode$1(this.padding),this.dataFormat=s||"channelsLast",checkDataFormat$1(this.dataFormat),this.dilationRate=normalizeArray$1(o||1,2,"dilationRate"),this.dilationRate.forEach(e=>assertPositiveInteger$1(e,"dilationRate"))}build(e){var t;e=getExactlyOneShape$1(e);const n="channelsFirst"===this.dataFormat?1:e.length-1;if(null==e[n])throw new ValueError$1(`The channel dimension of the input should be defined. Found ${e[n]}`);const r=this.kernelSize.concat([e[n],4*this.filters]);this.kernel=this.addWeight("kernel",r,null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint);const a=this.kernelSize.concat([this.filters,4*this.filters]);if(this.recurrentKernel=this.addWeight("recurrent_kernel",a,null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.useBias){let e;if(this.unitForgetBias){const n=this.biasInitializer,r=this.filters;e=new((t=class extends Initializer$1{apply(e,t){return concatenate$2([n.apply([r]),ones$3([r]),n.apply([2*r])])}}).className="CustomInit",t)}else e=this.biasInitializer;this.bias=this.addWeight("bias",[4*this.filters],null,e,this.biasRegularizer,!0,this.biasConstraint)}this.built=!0}call(e,t){return tidy$1(()=>{if(3!==e.length)throw new ValueError$1(`ConvLSTM2DCell expects 3 input Tensors (inputs, h, c), got ${e.length}.`);const n=t.training||!1,r=e[0],a=e[1],s=e[2];0<this.dropout&&this.dropout<1&&null==this.dropoutMask&&(this.dropoutMask=generateDropoutMask$1({ones:()=>onesLike$5(r),rate:this.dropout,training:n,count:4}));const o=this.dropoutMask,i=(e,t,n)=>t&&t[n]?mul$1(t[n],e):e;let l=i(r,o,0),u=i(r,o,1),c=i(r,o,2),p=i(r,o,3);0<this.recurrentDropout&&this.recurrentDropout<1&&null==this.recurrentDropoutMask&&(this.recurrentDropoutMask=generateDropoutMask$1({ones:()=>onesLike$5(a),rate:this.recurrentDropout,training:n,count:4}));const d=this.recurrentDropoutMask;let h=i(a,d,0),m=i(a,d,1),f=i(a,d,2),g=i(a,d,3);const[$,y,b,x]=split$4(this.kernel.read(),4,3),[v,I,C,S]=this.useBias?split$4(this.bias.read(),4):[null,null,null,null];l=this.inputConv(l,$,v,this.padding),u=this.inputConv(u,y,I,this.padding),c=this.inputConv(c,b,C,this.padding),p=this.inputConv(p,x,S,this.padding);const[k,T,N,w]=split$4(this.recurrentKernel.read(),4,3);h=this.recurrentConv(h,k),m=this.recurrentConv(m,T),f=this.recurrentConv(f,N),g=this.recurrentConv(g,w);const E=this.recurrentActivation.apply(add$5(l,h)),A=this.recurrentActivation.apply(add$5(u,m)),D=add$5(mul$1(A,s),mul$1(E,this.activation.apply(add$5(c,f)))),R=mul$1(this.recurrentActivation.apply(add$5(p,g)),this.activation.apply(D));return[R,R,D]})}getConfig(){const e=super.getConfig(),t=__rest$1(e,["units"]);return Object.assign({},t,{filters:this.filters,kernelSize:this.kernelSize,padding:this.padding,dataFormat:this.dataFormat,dilationRate:this.dilationRate,strides:this.strides})}inputConv(e,t,n,r){const a=conv2d$7(e,t,this.strides,r||"valid","channelsFirst"===this.dataFormat?"NCHW":"NHWC",this.dilationRate);return n?biasAdd$1(a,n,this.dataFormat):a}recurrentConv(e,t){return conv2d$7(e,t,1,"same","channelsFirst"===this.dataFormat?"NCHW":"NHWC")}}ConvLSTM2DCell$1.className="ConvLSTM2DCell",registerClass$1(ConvLSTM2DCell$1);class ConvLSTM2D$1 extends ConvRNN2D$1{constructor(e){const t=new ConvLSTM2DCell$1(e);super(Object.assign({},e,{cell:t}))}static fromConfig(e,t){return new e(t)}}ConvLSTM2D$1.className="ConvLSTM2D",registerClass$1(ConvLSTM2D$1);class Dropout$1 extends Layer$1{constructor(e){super(e),this.rate=Math.max(Math.min(e.rate,1),0),this.noiseShape=e.noiseShape,this.seed=e.seed,this.supportsMasking=!0}getNoiseShape(e){if(null==this.noiseShape)return this.noiseShape;const t=e.shape,n=[];for(let e=0;e<this.noiseShape.length;++e)n.push(null==this.noiseShape[e]?t[e]:this.noiseShape[e]);return n}call(e,t){return tidy$1(()=>{this.invokeCallHook(e,t);const n=getExactlyOneTensor$1(e);if(0<this.rate&&this.rate<1){const e=null!=t.training&&t.training,r=this.getNoiseShape(n);return inTrainPhase$1(()=>dropout$4(n,this.rate,r,this.seed),()=>n,e)}return e})}getConfig(){const e={rate:this.rate,noiseShape:this.noiseShape,seed:this.seed},t=super.getConfig();return Object.assign(e,t),e}dispose(){return super.dispose()}}Dropout$1.className="Dropout",registerClass$1(Dropout$1);class SpatialDropout1D$1 extends Dropout$1{constructor(e){super(e),this.inputSpec=[{ndim:3}]}getNoiseShape(e){const t=e.shape;return[t[0],1,t[2]]}}SpatialDropout1D$1.className="SpatialDropout1D",registerClass$1(SpatialDropout1D$1);class Dense$1 extends Layer$1{constructor(e){if(super(e),this.activation=null,this.useBias=!0,this.kernel=null,this.bias=null,this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_BIAS_INITIALIZER="zeros",null==e.batchInputShape&&null==e.inputShape&&null!=e.inputDim){let t=null;null!=e.batchSize&&(t=e.batchSize),this.batchInputShape=[t,e.inputDim]}this.units=e.units,assertPositiveInteger$1(this.units,"units"),this.activation=getActivation$1(e.activation),null!=e.useBias&&(this.useBias=e.useBias),this.kernelInitializer=getInitializer$1(e.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.biasInitializer=getInitializer$1(e.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.kernelConstraint=getConstraint$1(e.kernelConstraint),this.biasConstraint=getConstraint$1(e.biasConstraint),this.kernelRegularizer=getRegularizer$1(e.kernelRegularizer),this.biasRegularizer=getRegularizer$1(e.biasRegularizer),this.activityRegularizer=getRegularizer$1(e.activityRegularizer),this.supportsMasking=!0,this.inputSpec=[{minNDim:2}]}build(e){const t=(e=getExactlyOneShape$1(e))[e.length-1];null==this.kernel&&(this.kernel=this.addWeight("kernel",[t,this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.units],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint))),this.inputSpec=[{minNDim:2,axes:{[-1]:t}}],this.built=!0}computeOutputShape(e){const t=(e=getExactlyOneShape$1(e)).slice();return t[t.length-1]=this.units,t}call(e,t){return tidy$1(()=>{this.invokeCallHook(e,t);const n=getExactlyOneTensor$1(e),r=mapActivationToFusedKernel$1(this.activation.getClassName());let a;return null!=r?a=dot$3(n,this.kernel.read(),r,this.bias?this.bias.read():null):(a=dot$3(n,this.kernel.read()),null!=this.bias&&(a=biasAdd$1(a,this.bias.read())),null!=this.activation&&(a=this.activation.apply(a))),a})}getConfig(){const e={units:this.units,activation:serializeActivation$1(this.activation),useBias:this.useBias,kernelInitializer:serializeInitializer$1(this.kernelInitializer),biasInitializer:serializeInitializer$1(this.biasInitializer),kernelRegularizer:serializeRegularizer$1(this.kernelRegularizer),biasRegularizer:serializeRegularizer$1(this.biasRegularizer),activityRegularizer:serializeRegularizer$1(this.activityRegularizer),kernelConstraint:serializeConstraint$1(this.kernelConstraint),biasConstraint:serializeConstraint$1(this.biasConstraint)},t=super.getConfig();return Object.assign(e,t),e}}Dense$1.className="Dense",registerClass$1(Dense$1);class Flatten$1 extends Layer$1{constructor(e){super(e=e||{}),this.inputSpec=[{minNDim:3}],this.dataFormat=e.dataFormat}computeOutputShape(e){e=getExactlyOneShape$1(e);for(const t of e.slice(1))if(null==t)throw new ValueError$1(`The shape of the input to "Flatten" is not fully defined (got ${e.slice(1)}). Make sure to pass a complete "input_shape" or "batch_input_shape" argument to the first layer in your model.`);return[e[0],arrayProd$1(e,1)]}call(e,t){return tidy$1(()=>{this.invokeCallHook(e,t);let n=getExactlyOneTensor$1(e);if("channelsFirst"===this.dataFormat&&n.rank>1){const e=[0];for(let t=2;t<n.rank;++t)e.push(t);e.push(1),n=transpose$5(n,e)}return batchFlatten$1(n)})}getConfig(){const e={};null!=this.dataFormat&&(e.dataFormat=this.dataFormat);const t=super.getConfig();return Object.assign(e,t),e}}Flatten$1.className="Flatten",registerClass$1(Flatten$1);class Activation$2 extends Layer$1{constructor(e){super(e),this.supportsMasking=!0,this.activation=getActivation$1(e.activation)}call(e,t){return tidy$1(()=>{this.invokeCallHook(e,t);const n=getExactlyOneTensor$1(e);return this.activation.apply(n)})}getConfig(){const e={activation:serializeActivation$1(this.activation)},t=super.getConfig();return Object.assign(e,t),e}}Activation$2.className="Activation",registerClass$1(Activation$2);class RepeatVector$1 extends Layer$1{constructor(e){super(e),this.n=e.n,this.inputSpec=[{ndim:2}]}computeOutputShape(e){return[e[0],this.n,e[1]]}call(e,t){return tidy$1(()=>repeat$2(e=getExactlyOneTensor$1(e),this.n))}getConfig(){const e={n:this.n},t=super.getConfig();return Object.assign(e,t),e}}RepeatVector$1.className="RepeatVector",registerClass$1(RepeatVector$1);class Reshape$2 extends Layer$1{constructor(e){super(e),this.targetShape=e.targetShape;for(let e=0;e<this.targetShape.length;++e)this.isUnknown(this.targetShape[e])&&(this.targetShape[e]=null)}isUnknown(e){return e<0||null==e}fixUnknownDimension(e,t){const n="Total size of new array must be unchanged.",r=t.slice();let a=1,s=null;for(let e=0;e<r.length;++e){const t=r[e];if(this.isUnknown(t)){if(null!==s)throw new ValueError$1("Can only specifiy one unknown dimension.");s=e}else a*=t}const o=arrayProd$1(e);if(null!==s){if(0===a||o%a!=0)throw new ValueError$1(n);r[s]=o/a}else if(o!==a)throw new ValueError$1(n);return r}computeOutputShape(e){let t=!1;for(let n=0;n<e.length;++n)if(this.isUnknown(e[n])){t=!0;break}return t?e.slice(0,1).concat(this.targetShape):e.slice(0,1).concat(this.fixUnknownDimension(e.slice(1),this.targetShape))}call(e,t){return tidy$1(()=>{this.invokeCallHook(e,t);const n=getExactlyOneTensor$1(e),r=n.shape,a=r.slice(0,1).concat(this.fixUnknownDimension(r.slice(1),this.targetShape));return reshape$6(n,a)})}getConfig(){const e={targetShape:this.targetShape},t=super.getConfig();return Object.assign(e,t),e}}Reshape$2.className="Reshape",registerClass$1(Reshape$2);class Permute$1 extends Layer$1{constructor(e){if(super(e),null==e.dims)throw new Error("Required configuration field `dims` is missing during Permute constructor call.");if(!Array.isArray(e.dims))throw new Error(`Permute constructor requires \`dims\` to be an Array, but received ${e.dims} instead.`);const t=range$7(1,e.dims.length+1);if(!arraysEqual$1(e.dims.slice().sort(),t))throw new Error("Invalid permutation `dims`: "+JSON.stringify(e.dims)+" `dims` must contain consecutive integers starting from 1.");this.dims=e.dims,this.dimsIncludingBatch=[0].concat(this.dims),this.inputSpec=[new InputSpec$1({ndim:this.dims.length+1})]}computeOutputShape(e){const t=(e=getExactlyOneShape$1(e)).slice();return this.dims.forEach((n,r)=>{t[r+1]=e[n]}),t}call(e,t){return transpose$5(getExactlyOneTensor$1(e),this.dimsIncludingBatch)}getConfig(){const e={dims:this.dims},t=super.getConfig();return Object.assign(e,t),e}}Permute$1.className="Permute",registerClass$1(Permute$1);class Masking$1 extends Layer$1{constructor(e){super(null==e?{}:e),this.supportsMasking=!0,this.maskValue=null!=e?null==e.maskValue?0:e.maskValue:0}computeOutputShape(e){return e}getConfig(){const e=super.getConfig(),t={maskValue:this.maskValue};return Object.assign(t,e),t}computeMask(e,t){const n=getExactlyOneTensor$1(e);return any$5(notEqual$5(n,this.maskValue),-1)}call(e,t){return tidy$1(()=>{this.invokeCallHook(e,t);const n=getExactlyOneTensor$1(e),r=any$5(notEqual$5(n,this.maskValue),-1,!0);return mul$1(n,cast$7(r,n.dtype))})}}Masking$1.className="Masking",registerClass$1(Masking$1);class Embedding$1 extends Layer$1{constructor(e){if(super(e),this.embeddings=null,this.DEFAULT_EMBEDDINGS_INITIALIZER="randomUniform",null==e.batchInputShape&&null==e.inputShape){let t=null;null!=e.batchSize&&(t=e.batchSize),this.batchInputShape=null==e.inputLength?[t,null]:[t].concat(toList$1(e.inputLength))}this.inputDim=e.inputDim,assertPositiveInteger$1(this.inputDim,"inputDim"),this.outputDim=e.outputDim,assertPositiveInteger$1(this.outputDim,"outputDim"),this.embeddingsInitializer=getInitializer$1(e.embeddingsInitializer||this.DEFAULT_EMBEDDINGS_INITIALIZER),this.embeddingsRegularizer=getRegularizer$1(e.embeddingsRegularizer),this.activityRegularizer=getRegularizer$1(e.activityRegularizer),this.embeddingsConstraint=getConstraint$1(e.embeddingsConstraint),this.maskZero=e.maskZero,this.supportsMasking=e.maskZero,this.inputLength=e.inputLength}build(e){this.embeddings=this.addWeight("embeddings",[this.inputDim,this.outputDim],this.dtype,this.embeddingsInitializer,this.embeddingsRegularizer,!0,this.embeddingsConstraint),this.built=!0}warnOnIncompatibleInputShape(e){}computeMask(e,t){return tidy$1(()=>this.maskZero?(e=getExactlyOneTensor$1(e),notEqual$5(e,zerosLike$5(e))):null)}computeOutputShape(e){if(e=getExactlyOneShape$1(e),null==this.inputLength)return[...e,this.outputDim];const t=toList$1(this.inputLength);if(t.length!==e.length-1)throw new ValueError$1(`"inputLength" is ${this.inputLength}, but received input shape has shape ${e}`);{let n=0;for(let r=0;r<t.length;++r){const a=t[r],s=e[r+1];if(null!=a&&null!=s&&a!==s)throw new ValueError$1(`"inputLength" is ${this.inputLength}, but received input shape has shape ${e}`);null==a&&(t[n]=s),n++}}return[e[0],...t,this.outputDim]}call(e,t){return tidy$1(()=>{this.invokeCallHook(e,t);let n=getExactlyOneTensor$1(e);"int32"!==n.dtype&&(n=cast$6(n,"int32"));const r=gather$2(this.embeddings.read(),reshape$6(n,[n.size]));return reshape$6(r,getExactlyOneShape$1(this.computeOutputShape(n.shape)))})}getConfig(){const e={inputDim:this.inputDim,outputDim:this.outputDim,embeddingsInitializer:serializeInitializer$1(this.embeddingsInitializer),embeddingsRegularizer:serializeRegularizer$1(this.embeddingsRegularizer),activityRegularizer:serializeRegularizer$1(this.activityRegularizer),embeddingsConstraint:serializeConstraint$1(this.embeddingsConstraint),maskZero:this.maskZero,inputLength:this.inputLength},t=super.getConfig();return Object.assign(e,t),e}}Embedding$1.className="Embedding",registerClass$1(Embedding$1);class Merge$1 extends Layer$1{constructor(e){super(e||{}),this.supportsMasking=!0}mergeFunction(e){throw new NotImplementedError$1}computeElementwiseOpOutputShape(e,t){if(null==e||null==t)return null;if(e.length<t.length)return this.computeElementwiseOpOutputShape(t,e);if(0===t.length)return e;const n=e.slice(0,e.length-t.length);for(let r=0;r<t.length;++r){const a=e[e.length-t.length+r],s=t[r];if(null==a||null==s||a<0||s<0)n.push(null);else if(1===a)n.push(s);else if(1===s)n.push(a);else{if(a!==s)throw new ValueError$1("Operands could not be broadcast together with shapes "+JSON.stringify(e)+" "+JSON.stringify(t));n.push(a)}}return n}build(e){if(Array.isArray(e)&&!Array.isArray(e[0])&&(e=[getExactlyOneShape$1(e)]),(e=e).length<2)throw new ValueError$1(`A merge layer should be called on an Array of at least 2 inputs. Got ${e.length} input(s).`);let t=[];for(const n of e)null!=n&&null!==n[0]&&t.push(n[0]);if(t=unique$6(t),t.length>1)throw new ValueError$1(`Can not merge tensors with different batch sizes. Got tensors with shapes: ${JSON.stringify(e)}.`);let n=null==e[0]?null:e[0].slice(1);for(let t=1;t<e.length;++t){const r=null==e[t]?null:e[t].slice(1);n=this.computeElementwiseOpOutputShape(n,r)}const r=e.map(e=>e.length);this.reshapeRequired=-1!==e.indexOf(null)||1!==unique$6(r).length}call(e,t){return tidy$1(()=>{if(e=e,this.reshapeRequired){const t=[],n=e.map(e=>e.rank);if(-1===n.indexOf(null)){const r=max$6(n);for(let n of e){const e=n.rank;for(let t=0;t<r-e;++t)n=expandDims$6(n,1);t.push(n)}return this.mergeFunction(t)}{let n=!1;for(const r of e){const e=r.rank;if(null==e){const e=r.shape,a=e[0],s=e.slice(1).concat([a]);let o=reshape$6(r,[a].concat(arrayProd$1(e.slice(1))));o=transpose$5(o,[1,0]),o=reshape$6(o,s),t.push(o),n=!0}else if(e>1){const a=range$7(1,e).concat([0]);t.push(transpose$5(r,a)),n=!0}else t.push(r)}let r=this.mergeFunction(t);const a=r.rank;if(n)if(null==a){const e=r.shape,t=e[e.length-1],n=[t].concat(e.slice(0,e.length-1));r=reshape$6(transpose$5(reshape$6(r,[-1,t]),[1,0]),n)}else if(a>1){const e=[a-1].concat(range$7(0,a-1));r=transpose$5(r,e)}return r}}return this.mergeFunction(e)})}computeOutputShape(e){let t;t=null==(e=e)[0]?null:e[0].slice(1);for(let n=1;n<e.length;++n){const r=null==e[n]?null:e[n].slice(1);t=this.computeElementwiseOpOutputShape(t,r)}let n=[];for(const t of e)null!=t&&null!==t[0]&&n.push(t[0]);return n=unique$6(n),t=1===n.length?n.concat(t):[null].concat(t),t}computeMask(e,t){return tidy$1(()=>{if(null==t)return null;if(!Array.isArray(t))throw new ValueError$1("`mask` should be an Array");if(!Array.isArray(e))throw new ValueError$1("`inputs` should be an Array");if(t.length!==e.length)throw new ValueError$1(`The Array 'inputs' and 'mask' are expected to have the same length, but have different lengths (${e.length} vs ${t.length})`);if(t.every(e=>null==e))return null;let n=(t=t.map(e=>null==e?e:expandDims$7(e,0)))[0];for(let e=1;e<t.length-1;++e)n=logicalAnd$5(n,t[e]);return n})}}class Add$2 extends Merge$1{constructor(e){super(e)}mergeFunction(e){return tidy$1(()=>{let t=e[0].clone();for(let n=1;n<e.length;++n)t=add$5(t,e[n]);return t})}}Add$2.className="Add",registerClass$1(Add$2);class Multiply$2 extends Merge$1{constructor(e){super(e)}mergeFunction(e){return tidy$1(()=>{let t=e[0].clone();for(let n=1;n<e.length;++n)t=mul$1(t,e[n]);return t})}}Multiply$2.className="Multiply",registerClass$1(Multiply$2);class Average$1 extends Merge$1{constructor(e){super(e)}mergeFunction(e){return tidy$1(()=>{let t=e[0].clone();for(let n=1;n<e.length;++n)t=add$5(t,e[n]);return mul$1(1/e.length,t)})}}Average$1.className="Average",registerClass$1(Average$1);class Maximum$2 extends Merge$1{constructor(e){super(e)}mergeFunction(e){return tidy$1(()=>{let t=e[0];for(let n=1;n<e.length;++n)t=maximum$6(t,e[n]);return t})}}Maximum$2.className="Maximum",registerClass$1(Maximum$2);class Minimum$2 extends Merge$1{constructor(e){super(e)}mergeFunction(e){return tidy$1(()=>{let t=e[0];for(let n=1;n<e.length;++n)t=minimum$6(t,e[n]);return t})}}Minimum$2.className="Minimum",registerClass$1(Minimum$2);class Concatenate$1 extends Merge$1{constructor(e){super(e),this.DEFAULT_AXIS=-1,null==e&&(e={}),this.axis=null==e.axis?this.DEFAULT_AXIS:e.axis,this.supportsMasking=!0,this.reshapeRequired=!1}build(e){if(!Array.isArray(e)||!Array.isArray(e[0])||1===e.length)throw new ValueError$1("A `Concatenate` layer should be called on a list of at least 2 inputs");e=e;let t=!0;for(const n of e)if(null!=n){t=!1;break}if(t)return;const n=[];for(let t=0;t<e.length;++t){const r=e[t].slice();r.splice(this.axis,1);let a=!1;for(const e of n)if(arraysEqual$1(e,r)){a=!0;break}a||n.push(r)}if(n.length>1)throw new ValueError$1("A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got input shapes: "+JSON.stringify(e))}mergeFunction(e){return tidy$1(()=>concatenate$2(e,this.axis))}computeOutputShape(e){if(!Array.isArray(e)||!Array.isArray(e[0]))throw new ValueError$1("A `Concatenate` layer should be called on a list of inputs.");const t=e,n=t[0].slice(),r=this.axis<0?n.length+this.axis:this.axis;for(const e of t.slice(1)){if(null==n[r]||null==e[r]){n[r]=null;break}n[r]+=e[r]}return n}computeMask(e,t){if(null==t)return null;if(!Array.isArray(t))throw new ValueError$1("`mask` should be an array for Concatenate");if(!Array.isArray(e))throw new ValueError$1("`inputs` should be an array for Concatenate");if(t.length!==e.length)throw new ValueError$1(`Mismatch in the length of mask (${t.length}) and the legnth of inputs (${e.length})`);return tidy$1(()=>{let n=!0;if(t.forEach(e=>{null==e||(n=!1)}),n)return null;const r=[];for(let n=0;n<e.length;++n)r.push(null==t[n]?cast$7(onesLike$5(e[n]),"bool"):t[n].rank<e[n].rank?expandDims$7(t[n],-1):t[n]);const a=concat$5(r,this.axis);return all$5(a,-1,!1)})}getConfig(){const e={axis:this.axis},t=super.getConfig();return Object.assign(e,t),e}}function interpretAxis$1(e,t){for(;e<0;)e+=t;return e}function batchDot$1(e,t,n){if(e.shape.length>3||t.shape.length>3)throw new NotImplementedError$1("batchDot is not implemented for tensors of 4D or higher rank yet");if(assert$6(e.shape.length>=2,()=>`batchDot requires the rank of x to be >= 2, but got ${e.shape.length}`),assert$6(e.shape.length>=2,()=>`batchDot requires the rank of y to be >= 2, but got ${t.shape.length}`),"number"==typeof n&&(n=[n,n]),"complex64"===e.dtype||"complex64"===t.dtype)throw new NotImplementedError$1("batchDot is not implemented for complex64-type Tensors yet.");const r=e.shape.length,a=t.shape.length;null==n&&(n=[r-1,a-2]);const s=n;return tidy$1(()=>{let n,o;if(r>a){n=r-a;const e=[];for(let t=0;t<n;++t)e.push(1);t=reshape$6(t,t.shape.concat(e))}else if(a>r){n=a-r;const t=[];for(let e=0;e<n;++e)t.push(1);e=reshape$6(e,e.shape.concat(t))}else n=0;if(o=2===e.shape.length&&2===t.shape.length?s[0]===s[1]?sum$6(mul$1(e,t),s[0]):sum$6(mul$1(transpose$5(e,[1,0]),t),s[1]):matMul$3(e,t,s[0]!==e.shape.length-1,s[1]===t.shape.length-1),n>0){let e;e=r>a?r+a-3:r-1;const t=[];for(let r=e;r<e+n;++r)t.push(r);o=squeeze$1(o,t)}return 1===o.shape.length&&(o=expandDims$7(o,1)),o})}Concatenate$1.className="Concatenate",registerClass$1(Concatenate$1);class Dot$1 extends Merge$1{constructor(e){super(e),this.axes=e.axes,this.normalize=null!=e.normalize&&e.normalize,this.supportsMasking=!0,this.reshapeRequired=!1}build(e){assert$6(Array.isArray(e)&&2===e.length&&Array.isArray(e[0])&&Array.isArray(e[1]),()=>"A `Dot` layer should be called on a list of exactly 2 inputs.");const t=e[0],n=e[1];if(t.length>3||n.length>3)throw new NotImplementedError$1("Dot layer does not support tensors of 4D or higher rank yet.");const r=this.interpretAxes(t,n);if(t[r[0]]!==n[r[1]])throw new ValueError$1(`Dimension incompatibility: ${t[r[0]]} !== ${n[r[1]]}`)}mergeFunction(e){if(2!==e.length)throw new ValueError$1(`A \`Dot\` layer must be called on exactly 2 inputs, but received ${e.length} input(s).`);let t,n=e[0],r=e[1];return t=Array.isArray(this.axes)?this.axes.map((t,n)=>interpretAxis$1(t,e[n].shape.length)):[interpretAxis$1(this.axes,n.shape.length),interpretAxis$1(this.axes,r.shape.length)],this.normalize&&(n=l2Normalize$1(n,t[0]),r=l2Normalize$1(r,t[1])),batchDot$1(n,r,t)}interpretAxes(e,t){let n;return n=Array.isArray(this.axes)?this.axes:[interpretAxis$1(this.axes,e.length),interpretAxis$1(this.axes,t.length)],n}computeOutputShape(e){assert$6(Array.isArray(e)&&2===e.length&&Array.isArray(e[0])&&Array.isArray(e[1]),()=>"A `Dot` layer should be called on a list of exactly 2 inputs.");const t=e[0].slice(),n=e[1].slice();if(t.length>3||n.length>3)throw new NotImplementedError$1("Dot layer does not support tensors of 4D or higher rank yet.");const r=this.interpretAxes(t,n);t.splice(r[0],1),n.splice(r[1],1),n.splice(0,1);const a=t.concat(n);return 1===a.length&&a.push(1),a}computeMask(e,t){return null}getConfig(){const e={axes:this.axes,normalize:this.normalize},t=super.getConfig();return Object.assign(e,t),e}}Dot$1.className="Dot",registerClass$1(Dot$1);class GaussianNoise$1 extends Layer$1{constructor(e){super(e),this.supportsMasking=!0,this.stddev=e.stddev}computeOutputShape(e){return e}getConfig(){const e=super.getConfig(),t={stddev:this.stddev};return Object.assign(t,e),t}call(e,t){return tidy$1(()=>{this.invokeCallHook(e,t);const n=getExactlyOneTensor$1(e);return inTrainPhase$1(()=>add$5(randomNormal$3(n.shape,0,this.stddev),n),()=>n,t.training||!1)})}}GaussianNoise$1.className="GaussianNoise",registerClass$1(GaussianNoise$1);class GaussianDropout$1 extends Layer$1{constructor(e){super(e),this.supportsMasking=!0,this.rate=e.rate}computeOutputShape(e){return e}getConfig(){const e=super.getConfig(),t={rate:this.rate};return Object.assign(t,e),t}call(e,t){return tidy$1(()=>{this.invokeCallHook(e,t);const n=getExactlyOneTensor$1(e);return this.rate>0&&this.rate<1?inTrainPhase$1(()=>{const e=Math.sqrt(this.rate/(1-this.rate));return mul$1(n,randomNormal$3(n.shape,1,e))},()=>n,t.training||!1):n})}}GaussianDropout$1.className="GaussianDropout",registerClass$1(GaussianDropout$1);class AlphaDropout$1 extends Layer$1{constructor(e){super(e),this.supportsMasking=!0,this.rate=e.rate,this.noiseShape=e.noiseShape}_getNoiseShape(e){return this.noiseShape||getExactlyOneTensor$1(e).shape}computeOutputShape(e){return e}getConfig(){const e=super.getConfig(),t={rate:this.rate};return Object.assign(t,e),t}call(e,t){return tidy$1(()=>{if(this.rate<1&&this.rate>0){const n=this._getNoiseShape(e);return inTrainPhase$1(()=>{const t=getExactlyOneTensor$1(e),r=-1.7580993408473766;let a=greaterEqual$5(randomUniform$2(n),this.rate);a=cast$6(a,"float32");const s=((1-this.rate)*(1+this.rate*r**2))**-.5,o=-s*r*this.rate,i=add$5(mul$1(t,a),mul$1(add$5(a,-1),r));return add$5(mul$1(i,s),o)},()=>getExactlyOneTensor$1(e),t.training||!1)}return e})}}function batchNormalization$2(e,t,n,r,a,s=.001){let o;if(2===e.rank)o=batchNorm2d$1(e,t,n,r,a,s);else if(3===e.rank)o=batchNorm3d$1(e,t,n,r,a,s);else{if(4!==e.rank)throw new NotImplementedError$1(`batchNormalization is not implemented for array of rank ${e.rank} yet`);o=batchNorm4d$1(e,t,n,r,a,s)}return o}function regularNormalizeBatchInTraining$1(e,t,n,r,a=.001){return tidy$1(()=>{const s=moments$1(e,r),o=s.mean,i=s.variance;return[batchNormalization$2(e,o,i,n,t,a),o,i]})}function broadcastNormalizeBatchInTraining$1(e,t,n,r,a=.001){return tidy$1(()=>{const s=moments$1(e,r),o=s.mean,i=s.variance,l=[];for(const t of range$7(0,e.rank))-1!==r.indexOf(t)?l.push(1):l.push(e.shape[t]);const u=reshape$6(o,l),c=reshape$6(i,l),p=null==t?null:reshape$6(t,l),d=null==n?null:reshape$6(n,l);return[batchNormalization$2(e,u,c,d,p,a),o,i]})}function normalizeBatchInTraining$1(e,t,n,r,a=.001){return arraysEqual$1(r.slice().sort(),range$7(0,e.rank-1))?regularNormalizeBatchInTraining$1(e,t,n,r,a):broadcastNormalizeBatchInTraining$1(e,t,n,r,a)}AlphaDropout$1.className="AlphaDropout",registerClass$1(AlphaDropout$1);class BatchNormalization$1 extends Layer$1{constructor(e){null==e&&(e={}),super(e),this.supportsMasking=!0,this.axis=null==e.axis?-1:e.axis,this.momentum=null==e.momentum?.99:e.momentum,this.epsilon=null==e.epsilon?.001:e.epsilon,this.center=null==e.center||e.center,this.scale=null==e.scale||e.scale,this.betaInitializer=getInitializer$1(e.betaInitializer||"zeros"),this.gammaInitializer=getInitializer$1(e.gammaInitializer||"ones"),this.movingMeanInitializer=getInitializer$1(e.movingMeanInitializer||"zeros"),this.movingVarianceInitializer=getInitializer$1(e.movingVarianceInitializer||"ones"),this.betaConstraint=getConstraint$1(e.betaConstraint),this.gammaConstraint=getConstraint$1(e.gammaConstraint),this.betaRegularizer=getRegularizer$1(e.betaRegularizer),this.gammaRegularizer=getRegularizer$1(e.gammaRegularizer)}build(e){e=getExactlyOneShape$1(e);const t=this.axis>=0?this.axis:this.axis+e.length,n=e[t];if(null==n)throw new ValueError$1(`Axis ${t} of input tensor should have a defined dimension but the layer received an input with shape ${JSON.stringify(e)}.`);this.inputSpec=[new InputSpec$1({ndim:e.length,axes:{[t]:n}})];const r=[n];this.scale&&(this.gamma=this.addWeight("gamma",r,null,this.gammaInitializer,this.gammaRegularizer,!0,this.gammaConstraint)),this.center&&(this.beta=this.addWeight("beta",r,null,this.betaInitializer,this.betaRegularizer,!0,this.betaConstraint)),this.movingMean=this.addWeight("moving_mean",r,null,this.movingMeanInitializer,null,!1),this.movingVariance=this.addWeight("moving_variance",r,null,this.movingVarianceInitializer,null,!1),this.built=!0}call(e,t){return tidy$1(()=>{const n=null!=t.training&&t.training,r=getExactlyOneTensor$1(e),a=r.shape,s=a.length,o=range$7(0,s),i=this.axis>=0?this.axis:this.axis+s;o.splice(i,1);const l=pyListRepeat$1(1,s);l[i]=a[i];const u=o.slice();u.sort();const c=!arraysEqual$1(u,range$7(0,s).slice(0,s-1));if(!n)return(()=>{if(c){const e=reshape$6(this.movingMean.read(),l),t=reshape$6(this.movingVariance.read(),l),n=this.center?reshape$6(this.beta.read(),l):null,a=this.scale?reshape$6(this.gamma.read(),l):null;return batchNormalization$2(r,e,t,n,a,this.epsilon)}return batchNormalization$2(r,this.movingMean.read(),this.movingVariance.read(),null==this.beta?null:this.beta.read(),null==this.gamma?null:this.gamma.read(),this.epsilon)})();const[p,d,h]=normalizeBatchInTraining$1(r,this.gamma.read(),this.beta.read(),o,this.epsilon),m=(e,t,n)=>{tidy$1(()=>{const r=1-n,a=e.read(),s=mul$1(sub$5(a,t),r);e.write(sub$5(a,s))})};return(()=>{m(this.movingMean,d,this.momentum),m(this.movingVariance,h,this.momentum)})(),p})}getConfig(){const e={axis:this.axis,momentum:this.momentum,epsilon:this.epsilon,center:this.center,scale:this.scale,betaInitializer:serializeInitializer$1(this.betaInitializer),gammaInitializer:serializeInitializer$1(this.gammaInitializer),movingMeanInitializer:serializeInitializer$1(this.movingMeanInitializer),movingVarianceInitializer:serializeInitializer$1(this.movingVarianceInitializer),betaRegularizer:serializeRegularizer$1(this.betaRegularizer),gammaRegularizer:serializeRegularizer$1(this.gammaRegularizer),betaConstraint:serializeConstraint$1(this.betaConstraint),gammaConstraint:serializeConstraint$1(this.gammaConstraint)},t=super.getConfig();return Object.assign(e,t),e}}BatchNormalization$1.className="BatchNormalization",registerClass$1(BatchNormalization$1);class LayerNormalization$1 extends Layer$1{constructor(e){if(null==e&&(e={}),super(e),this.axis=null==e.axis?-1:e.axis,"number"==typeof this.axis){if(!Number.isInteger(this.axis))throw new Error(`Expected axis to be an integer, but received ${this.axis}`)}else{if(!Array.isArray(this.axis))throw new Error(`Expected axis to be an integer or an array of integers, but received ${JSON.stringify(this.axis)}`);for(const e of this.axis)if(!Number.isInteger(e))throw new Error(`Expected axis to be an array of integers, but received ${JSON.stringify(this.axis)}`)}this.epsilon=null==e.epsilon?.001:e.epsilon,this.center=null==e.center||e.center,this.scale=null==e.scale||e.scale,this.betaInitializer=getInitializer$1(e.betaInitializer||"zeros"),this.gammaInitializer=getInitializer$1(e.gammaInitializer||"ones"),this.betaRegularizer=getRegularizer$1(e.betaRegularizer),this.gammaRegularizer=getRegularizer$1(e.gammaRegularizer),this.supportsMasking=!0}build(e){const t=(e=getExactlyOneShape$1(e)).length;"number"==typeof this.axis&&(this.axis=[this.axis]);for(let e=0;e<this.axis.length;++e)this.axis[e]<0&&(this.axis[e]+=t);for(const e of this.axis)if(e<0||e>=t)throw new Error(`Invalid axis: ${e}`);if(this.axis.length!==unique$6(this.axis).length)throw new Error(`Found duplicate axes in: ${this.axis}`);const n=this.axis.map(t=>e[t]);this.gamma=this.scale?this.addWeight("gamma",n,"float32",this.gammaInitializer,this.gammaRegularizer,!0):null,this.beta=this.center?this.addWeight("beta",n,"float32",this.betaInitializer,this.betaRegularizer,!0):null,this.built=!0}call(e,t){const n=getExactlyOneTensor$1(e),r=n.shape,a=r.length;return tidy$1(()=>{let{mean:e,variance:t}=moments$1(n,this.axis,!0);const s=pyListRepeat$1(1,a);for(const e of this.axis)s[e]=r[e];const o=e=>null!=e&&e.shape.length!==a&&this.axis!==[a-1]?reshape$6(e,s):e;let i=o(this.gamma.read()),l=o(this.beta.read());const u=[],c=[];for(let e=0;e<a;++e)-1!==this.axis.indexOf(e)?(u.push(r[e]),c.push(1)):(u.push(1),c.push(r[e]));return e=tile$7(e,u),t=tile$7(t,u),i=tile$7(i,c),l=tile$7(l,c),batchNormalization$2(n,e,t,l,i,this.epsilon)})}getConfig(){const e={axis:this.axis,epsilon:this.epsilon,center:this.center,scale:this.scale,betaInitializer:serializeInitializer$1(this.betaInitializer),gammaInitializer:serializeInitializer$1(this.gammaInitializer),betaRegularizer:serializeRegularizer$1(this.betaRegularizer),gammaRegularizer:serializeRegularizer$1(this.gammaRegularizer)},t=super.getConfig();return Object.assign(e,t),e}}function spatial2dPadding$1(e,t,n){return tidy$1(()=>{if(4!==e.rank)throw new ValueError$1(`temporalPadding expects input tensor to be 4-D, but received a ${e.rank}-D tensor.`);if(null==t&&(t=[[1,1],[1,1]]),2!==t.length||2!==t[0].length||2!==t[1].length)throw new ValueError$1("spatial2dPadding expects `padding` to be an Array of two Arrays, each of which is an Array of two integers.");if(null==n&&(n=imageDataFormat$1()),"channelsLast"!==n&&"channelsFirst"!==n)throw new ValueError$1(`Unknown data format: ${n}. Supported data formats are 'channelsLast' and 'channelsFirst.`);let r;return r="channelsFirst"===n?[[0,0],[0,0],t[0],t[1]]:[[0,0],t[0],t[1],[0,0]],pad$1(e,r)})}LayerNormalization$1.className="LayerNormalization",registerClass$1(LayerNormalization$1);class ZeroPadding2D$1 extends Layer$1{constructor(e){if(null==e&&(e={}),super(e),this.dataFormat=null==e.dataFormat?imageDataFormat$1():e.dataFormat,null==e.padding)this.padding=[[1,1],[1,1]];else if("number"==typeof e.padding)this.padding=[[e.padding,e.padding],[e.padding,e.padding]];else{if(e.padding=e.padding,2!==e.padding.length)throw new ValueError$1(`ZeroPadding2D expects padding to be a length-2 array, but received a length-${e.padding.length} array.`);let t,n;if("number"==typeof e.padding[0])t=[e.padding[0],e.padding[0]],n=[e.padding[1],e.padding[1]];else{if(e.padding=e.padding,2!==e.padding[0].length)throw new ValueError$1(`ZeroPadding2D expects height padding to be a length-2 array, but received a length-${e.padding[0].length} array.`);if(t=e.padding[0],2!==e.padding[1].length)throw new ValueError$1(`ZeroPadding2D expects width padding to be a length-2 array, but received a length-${e.padding[1].length} array.`);n=e.padding[1]}this.padding=[t,n]}this.inputSpec=[new InputSpec$1({ndim:4})]}computeOutputShape(e){let t,n;return e=getExactlyOneShape$1(e),"channelsFirst"===this.dataFormat?(t=null!=e[2]&&e[2]>=0?e[2]+this.padding[0][0]+this.padding[0][1]:null,n=null!=e[3]&&e[3]>=0?e[3]+this.padding[1][0]+this.padding[1][1]:null,[e[0],e[1],t,n]):(t=null!=e[1]&&e[1]>=0?e[1]+this.padding[0][0]+this.padding[0][1]:null,n=null!=e[2]&&e[2]>=0?e[2]+this.padding[1][0]+this.padding[1][1]:null,[e[0],t,n,e[3]])}call(e,t){return tidy$1(()=>spatial2dPadding$1(getExactlyOneTensor$1(e),this.padding,this.dataFormat))}getConfig(){const e={padding:this.padding,dataFormat:this.dataFormat},t=super.getConfig();return Object.assign(e,t),e}}function pool2d$1(e,t,n,r,a,s){return tidy$1(()=>{let o;checkDataFormat$1(a),checkPoolMode$1(s),checkPaddingMode$1(r),null==n&&(n=[1,1]),null==r&&(r="valid"),null==a&&(a=imageDataFormat$1()),null==s&&(s="max"),e=preprocessConv2DInput$1(e,a);const i="same"===r?"same":"valid";return o="max"===s?maxPool$5(e,t,n,i):avgPool$5(e,t,n,i),"channelsFirst"===a&&(o=transpose$5(o,[0,3,1,2])),o})}function pool3d$3(e,t,n,r,a,s){return tidy$1(()=>{let o;checkDataFormat$1(a),checkPoolMode$1(s),checkPaddingMode$1(r),null==n&&(n=[1,1,1]),null==r&&(r="valid"),null==a&&(a=imageDataFormat$1()),null==s&&(s="max"),e=preprocessConv3DInput$1(e,a);const i="same"===r?"same":"valid";return o="max"===s?maxPool3d$3(e,t,n,i):avgPool3d$2(e,t,n,i),"channelsFirst"===a&&(o=transpose$5(o,[0,4,1,2,3])),o})}ZeroPadding2D$1.className="ZeroPadding2D",registerClass$1(ZeroPadding2D$1);class Pooling1D$1 extends Layer$1{constructor(e){if(null==e.poolSize&&(e.poolSize=2),super(e),"number"==typeof e.poolSize)this.poolSize=[e.poolSize];else{if(!Array.isArray(e.poolSize)||1!==e.poolSize.length||"number"!=typeof e.poolSize[0])throw new ValueError$1(`poolSize for 1D convolutional layer must be a number or an Array of a single number, but received ${JSON.stringify(e.poolSize)}`);this.poolSize=e.poolSize}if(assertPositiveInteger$1(this.poolSize,"poolSize"),null==e.strides)this.strides=this.poolSize;else if("number"==typeof e.strides)this.strides=[e.strides];else{if(!Array.isArray(e.strides)||1!==e.strides.length||"number"!=typeof e.strides[0])throw new ValueError$1(`strides for 1D convolutional layer must be a number or an Array of a single number, but received ${JSON.stringify(e.strides)}`);this.strides=e.strides}assertPositiveInteger$1(this.strides,"strides"),this.padding=null==e.padding?"valid":e.padding,checkPaddingMode$1(this.padding),this.inputSpec=[new InputSpec$1({ndim:3})]}computeOutputShape(e){const t=convOutputLength$1((e=getExactlyOneShape$1(e))[1],this.poolSize[0],this.padding,this.strides[0]);return[e[0],t,e[2]]}call(e,t){return tidy$1(()=>{this.invokeCallHook(e,t),e=expandDims$6(getExactlyOneTensor$1(e),2);const n=this.poolingFunction(getExactlyOneTensor$1(e),[this.poolSize[0],1],[this.strides[0],1],this.padding,"channelsLast");return squeeze$1(n,[2])})}getConfig(){const e={poolSize:this.poolSize,padding:this.padding,strides:this.strides},t=super.getConfig();return Object.assign(e,t),e}}class MaxPooling1D$1 extends Pooling1D$1{constructor(e){super(e)}poolingFunction(e,t,n,r,a){return checkDataFormat$1(a),checkPaddingMode$1(r),pool2d$1(e,t,n,r,a,"max")}}MaxPooling1D$1.className="MaxPooling1D",registerClass$1(MaxPooling1D$1);class AveragePooling1D$1 extends Pooling1D$1{constructor(e){super(e)}poolingFunction(e,t,n,r,a){return checkDataFormat$1(a),checkPaddingMode$1(r),pool2d$1(e,t,n,r,a,"avg")}}AveragePooling1D$1.className="AveragePooling1D",registerClass$1(AveragePooling1D$1);class Pooling2D$1 extends Layer$1{constructor(e){if(null==e.poolSize&&(e.poolSize=[2,2]),super(e),this.poolSize=Array.isArray(e.poolSize)?e.poolSize:[e.poolSize,e.poolSize],null==e.strides)this.strides=this.poolSize;else if(Array.isArray(e.strides)){if(2!==e.strides.length)throw new ValueError$1(`If the strides property of a 2D pooling layer is an Array, it is expected to have a length of 2, but received length ${e.strides.length}.`);this.strides=e.strides}else this.strides=[e.strides,e.strides];assertPositiveInteger$1(this.poolSize,"poolSize"),assertPositiveInteger$1(this.strides,"strides"),this.padding=null==e.padding?"valid":e.padding,this.dataFormat=null==e.dataFormat?"channelsLast":e.dataFormat,checkDataFormat$1(this.dataFormat),checkPaddingMode$1(this.padding),this.inputSpec=[new InputSpec$1({ndim:4})]}computeOutputShape(e){e=getExactlyOneShape$1(e);let t="channelsFirst"===this.dataFormat?e[2]:e[1],n="channelsFirst"===this.dataFormat?e[3]:e[2];return t=convOutputLength$1(t,this.poolSize[0],this.padding,this.strides[0]),n=convOutputLength$1(n,this.poolSize[1],this.padding,this.strides[1]),"channelsFirst"===this.dataFormat?[e[0],e[1],t,n]:[e[0],t,n,e[3]]}call(e,t){return tidy$1(()=>(this.invokeCallHook(e,t),this.poolingFunction(getExactlyOneTensor$1(e),this.poolSize,this.strides,this.padding,this.dataFormat)))}getConfig(){const e={poolSize:this.poolSize,padding:this.padding,strides:this.strides,dataFormat:this.dataFormat},t=super.getConfig();return Object.assign(e,t),e}}class MaxPooling2D$1 extends Pooling2D$1{constructor(e){super(e)}poolingFunction(e,t,n,r,a){return checkDataFormat$1(a),checkPaddingMode$1(r),pool2d$1(e,t,n,r,a,"max")}}MaxPooling2D$1.className="MaxPooling2D",registerClass$1(MaxPooling2D$1);class AveragePooling2D$1 extends Pooling2D$1{constructor(e){super(e)}poolingFunction(e,t,n,r,a){return checkDataFormat$1(a),checkPaddingMode$1(r),pool2d$1(e,t,n,r,a,"avg")}}AveragePooling2D$1.className="AveragePooling2D",registerClass$1(AveragePooling2D$1);class Pooling3D$1 extends Layer$1{constructor(e){if(null==e.poolSize&&(e.poolSize=[2,2,2]),super(e),this.poolSize=Array.isArray(e.poolSize)?e.poolSize:[e.poolSize,e.poolSize,e.poolSize],null==e.strides)this.strides=this.poolSize;else if(Array.isArray(e.strides)){if(3!==e.strides.length)throw new ValueError$1(`If the strides property of a 3D pooling layer is an Array, it is expected to have a length of 3, but received length ${e.strides.length}.`);this.strides=e.strides}else this.strides=[e.strides,e.strides,e.strides];assertPositiveInteger$1(this.poolSize,"poolSize"),assertPositiveInteger$1(this.strides,"strides"),this.padding=null==e.padding?"valid":e.padding,this.dataFormat=null==e.dataFormat?"channelsLast":e.dataFormat,checkDataFormat$1(this.dataFormat),checkPaddingMode$1(this.padding),this.inputSpec=[new InputSpec$1({ndim:5})]}computeOutputShape(e){e=getExactlyOneShape$1(e);let t="channelsFirst"===this.dataFormat?e[2]:e[1],n="channelsFirst"===this.dataFormat?e[3]:e[2],r="channelsFirst"===this.dataFormat?e[4]:e[3];return t=convOutputLength$1(t,this.poolSize[0],this.padding,this.strides[0]),n=convOutputLength$1(n,this.poolSize[1],this.padding,this.strides[1]),r=convOutputLength$1(r,this.poolSize[2],this.padding,this.strides[2]),"channelsFirst"===this.dataFormat?[e[0],e[1],t,n,r]:[e[0],t,n,r,e[4]]}call(e,t){return tidy$1(()=>(this.invokeCallHook(e,t),this.poolingFunction(getExactlyOneTensor$1(e),this.poolSize,this.strides,this.padding,this.dataFormat)))}getConfig(){const e={poolSize:this.poolSize,padding:this.padding,strides:this.strides,dataFormat:this.dataFormat},t=super.getConfig();return Object.assign(e,t),e}}class MaxPooling3D$1 extends Pooling3D$1{constructor(e){super(e)}poolingFunction(e,t,n,r,a){return checkDataFormat$1(a),checkPaddingMode$1(r),pool3d$3(e,t,n,r,a,"max")}}MaxPooling3D$1.className="MaxPooling3D",registerClass$1(MaxPooling3D$1);class AveragePooling3D$1 extends Pooling3D$1{constructor(e){super(e)}poolingFunction(e,t,n,r,a){return checkDataFormat$1(a),checkPaddingMode$1(r),pool3d$3(e,t,n,r,a,"avg")}}AveragePooling3D$1.className="AveragePooling3D",registerClass$1(AveragePooling3D$1);class GlobalPooling1D$1 extends Layer$1{constructor(e){super(e),this.inputSpec=[new InputSpec$1({ndim:3})]}computeOutputShape(e){return[e[0],e[2]]}call(e,t){throw new NotImplementedError$1}}class GlobalAveragePooling1D$1 extends GlobalPooling1D$1{constructor(e){super(e||{})}call(e,t){return tidy$1(()=>{const t=getExactlyOneTensor$1(e);return mean$3(t,1)})}}GlobalAveragePooling1D$1.className="GlobalAveragePooling1D",registerClass$1(GlobalAveragePooling1D$1);class GlobalMaxPooling1D$1 extends GlobalPooling1D$1{constructor(e){super(e||{})}call(e,t){return tidy$1(()=>{const t=getExactlyOneTensor$1(e);return max$7(t,1)})}}GlobalMaxPooling1D$1.className="GlobalMaxPooling1D",registerClass$1(GlobalMaxPooling1D$1);class GlobalPooling2D$1 extends Layer$1{constructor(e){super(e),this.dataFormat=null==e.dataFormat?"channelsLast":e.dataFormat,checkDataFormat$1(this.dataFormat),this.inputSpec=[new InputSpec$1({ndim:4})]}computeOutputShape(e){return e=e,"channelsLast"===this.dataFormat?[e[0],e[3]]:[e[0],e[1]]}call(e,t){throw new NotImplementedError$1}getConfig(){const e={dataFormat:this.dataFormat},t=super.getConfig();return Object.assign(e,t),e}}class GlobalAveragePooling2D$1 extends GlobalPooling2D$1{call(e,t){return tidy$1(()=>{const t=getExactlyOneTensor$1(e);return mean$3(t,"channelsLast"===this.dataFormat?[1,2]:[2,3])})}}GlobalAveragePooling2D$1.className="GlobalAveragePooling2D",registerClass$1(GlobalAveragePooling2D$1);class GlobalMaxPooling2D$1 extends GlobalPooling2D$1{call(e,t){return tidy$1(()=>{const t=getExactlyOneTensor$1(e);return max$7(t,"channelsLast"===this.dataFormat?[1,2]:[2,3])})}}GlobalMaxPooling2D$1.className="GlobalMaxPooling2D",registerClass$1(GlobalMaxPooling2D$1);class Wrapper$1 extends Layer$1{constructor(e){super(e),this.layer=e.layer}build(e){this.built=!0}get trainable(){return null!=this.layer&&this.layer.trainable}set trainable(e){null!=this.layer&&(this.layer.trainable=e)}get trainableWeights(){return this.layer.trainableWeights}get nonTrainableWeights(){return this.layer.nonTrainableWeights}get updates(){return this.layer._updates}get losses(){return this.layer.losses}getWeights(){return this.layer.getWeights()}setWeights(e){this.layer.setWeights(e)}getConfig(){const e={layer:{className:this.layer.getClassName(),config:this.layer.getConfig()}},t=super.getConfig();return Object.assign(e,t),e}setFastWeightInitDuringBuild(e){super.setFastWeightInitDuringBuild(e),null!=this.layer&&this.layer.setFastWeightInitDuringBuild(e)}static fromConfig(e,t,n={}){const r=deserialize$1(t.layer,n);delete t.layer;const a={layer:r};return Object.assign(a,t),new e(a)}}class TimeDistributed$1 extends Wrapper$1{constructor(e){super(e),this.supportsMasking=!0}build(e){if((e=getExactlyOneShape$1(e)).length<3)throw new ValueError$1(`TimeDistributed layer expects an input shape >= 3D, but received input shape ${JSON.stringify(e)}`);this.inputSpec=[{shape:e}];const t=[e[0]].concat(e.slice(2));this.layer.built||(this.layer.build(t),this.layer.built=!0),super.build(e)}computeOutputShape(e){const t=[(e=getExactlyOneShape$1(e))[0]].concat(e.slice(2)),n=this.layer.computeOutputShape(t);return[n[0],e[1]].concat(n.slice(1))}call(e,t){return tidy$1(()=>rnn$2((e,n)=>[getExactlyOneTensor$1(this.layer.call(e,t)),[]],e=getExactlyOneTensor$1(e),[],!1,null,null,!1,!0)[1])}}function checkBidirectionalMergeMode$1(e){checkStringTypeUnionValue$1(VALID_BIDIRECTIONAL_MERGE_MODES$1,"BidirectionalMergeMode",e)}TimeDistributed$1.className="TimeDistributed",registerClass$1(TimeDistributed$1);const DEFAULT_BIDIRECTIONAL_MERGE_MODE$1="concat";class Bidirectional$1 extends Wrapper$1{constructor(e){super(e);const t=e.layer.getConfig(),n={};n.className=e.layer.getClassName(),n.config=t,this.forwardLayer=deserialize$1(n),t.goBackwards=!0!==t.goBackwards;const r={};if(r.className=e.layer.getClassName(),r.config=t,this.backwardLayer=deserialize$1(r),this.forwardLayer.name="forward_"+this.forwardLayer.name,this.backwardLayer.name="backward_"+this.backwardLayer.name,this.mergeMode=void 0===e.mergeMode?DEFAULT_BIDIRECTIONAL_MERGE_MODE$1:e.mergeMode,checkBidirectionalMergeMode$1(this.mergeMode),e.weights)throw new NotImplementedError$1("weights support is not implemented for Bidirectional layer yet.");this._stateful=e.layer.stateful,this.returnSequences=e.layer.returnSequences,this.returnState=e.layer.returnState,this.supportsMasking=!0,this._trainable=!0,this.inputSpec=e.layer.inputSpec,this.numConstants=null}get trainable(){return this._trainable}set trainable(e){this._trainable=e,null!=this.forwardLayer&&(this.forwardLayer.trainable=e),null!=this.backwardLayer&&(this.backwardLayer.trainable=e)}getWeights(){return this.forwardLayer.getWeights().concat(this.backwardLayer.getWeights())}setWeights(e){const t=Math.floor(e.length/2);this.forwardLayer.setWeights(e.slice(0,t)),this.backwardLayer.setWeights(e.slice(t))}computeOutputShape(e){let t,n,r,a=this.forwardLayer.computeOutputShape(e);return Array.isArray(a)&&Array.isArray(a[0])||(a=[a]),a=a,this.returnState?(r=a.slice(1),t=a[0]):t=a[0],t=t,"concat"===this.mergeMode?(t[t.length-1]*=2,n=[t]):n=null==this.mergeMode?[t,t.slice()]:[t],this.returnState?null==this.mergeMode?n.concat(r).concat(r.slice()):[t].concat(r).concat(r.slice()):singletonOrArray$1(n)}apply(e,t){let n=null==t?null:t.initialState,r=null==t?null:t.constants;null==t&&(t={});const a=standardizeArgs$1(e,n,r,this.numConstants);if(e=a.inputs,n=a.initialState,r=a.constants,Array.isArray(e)&&(n=e.slice(1),e=e[0]),(null==n||0===n.length)&&null==r)return super.apply(e,t);const s=[],o=[];if(null!=n){const e=n.length;if(e%2>0)throw new ValueError$1("When passing `initialState` to a Bidrectional RNN, the state should be an Array containing the states of the underlying RNNs.");t.initialState=n,s.push(...n);const r=n.map(e=>new InputSpec$1({shape:e.shape}));this.forwardLayer.stateSpec=r.slice(0,e/2),this.backwardLayer.stateSpec=r.slice(e/2),o.push(...r)}if(null!=r)throw new NotImplementedError$1("Support for constants in Bidirectional layers is not implemented yet.");const i=s[0]instanceof SymbolicTensor$1;for(const e of s)if(e instanceof SymbolicTensor$1!==i)throw new ValueError$1("The initial state of a Bidirectional layer cannot be specified as a mix of symbolic and non-symbolic tensors");if(i){const n=[e].concat(s),r=this.inputSpec.concat(o),a=this.inputSpec;this.inputSpec=r;const i=super.apply(n,t);return this.inputSpec=a,i}return super.apply(e,t)}call(e,t){return tidy$1(()=>{const n=t.initialState;let r,a,s,o;if(null==n)r=this.forwardLayer.call(e,t),a=this.backwardLayer.call(e,t);else{const s=n.slice(0,n.length/2),o=n.slice(n.length/2);r=this.forwardLayer.call(e,Object.assign(t,{initialState:s})),a=this.backwardLayer.call(e,Object.assign(t,{initialState:o}))}return this.returnState&&(Array.isArray(r)&&(s=r.slice(1).concat(a.slice(1))),r=r[0],a=a[0]),this.returnSequences&&(a=reverse$5(a,1)),"concat"===this.mergeMode?o=concatenate$2([r,a]):"sum"===this.mergeMode?o=add$5(r,a):"ave"===this.mergeMode?o=mul$1(.5,add$5(r,a)):"mul"===this.mergeMode?o=mul$1(r,a):null==this.mergeMode&&(o=[r,a]),this.returnState?null==this.mergeMode?o.concat(s):[o].concat(s):o})}resetStates(e){this.forwardLayer.resetStates(),this.backwardLayer.resetStates()}build(e){nameScope$1(this.forwardLayer.name,()=>{this.forwardLayer.build(e)}),nameScope$1(this.backwardLayer.name,()=>{this.backwardLayer.build(e)}),this.built=!0}computeMask(e,t){let n;if(Array.isArray(t)&&(t=t[0]),n=this.returnSequences?null==this.mergeMode?[t,t]:t:null==this.mergeMode?[null,null]:null,this.returnState){const e=this.forwardLayer.states.map(e=>null);return Array.isArray(n)?n.concat(e).concat(e):[n].concat(e).concat(e)}return n}get trainableWeights(){return this.forwardLayer.trainableWeights.concat(this.backwardLayer.trainableWeights)}get nonTrainableWeights(){return this.forwardLayer.nonTrainableWeights.concat(this.backwardLayer.nonTrainableWeights)}setFastWeightInitDuringBuild(e){super.setFastWeightInitDuringBuild(e),null!=this.forwardLayer&&this.forwardLayer.setFastWeightInitDuringBuild(e),null!=this.backwardLayer&&this.backwardLayer.setFastWeightInitDuringBuild(e)}getConfig(){const e={mergeMode:this.mergeMode},t=super.getConfig();return Object.assign(e,t),e}static fromConfig(e,t){const n=deserialize$1(t.layer);if(delete t.layer,null!=t.numConstants)throw new NotImplementedError$1("Deserialization of a Bidirectional layer with numConstants present is not supported yet.");const r=t;return r.layer=n,new e(r)}}function conv1d$2(e){return new Conv1D$1(e)}function conv2d$5(e){return new Conv2D$2(e)}function dense$1(e){return new Dense$1(e)}function dropout$3(e){return new Dropout$1(e)}function flatten$4(e){return new Flatten$1(e)}function maxPooling1d$1(e){return new MaxPooling1D$1(e)}function maxPooling2d$1(e){return new MaxPooling2D$1(e)}var DataType$1,SaverDef$1;Bidirectional$1.className="Bidirectional",registerClass$1(Bidirectional$1),function(e){e[e.DT_INVALID=0]="DT_INVALID",e[e.DT_FLOAT=1]="DT_FLOAT",e[e.DT_DOUBLE=2]="DT_DOUBLE",e[e.DT_INT32=3]="DT_INT32",e[e.DT_UINT8=4]="DT_UINT8",e[e.DT_INT16=5]="DT_INT16",e[e.DT_INT8=6]="DT_INT8",e[e.DT_STRING=7]="DT_STRING",e[e.DT_COMPLEX64=8]="DT_COMPLEX64",e[e.DT_INT64=9]="DT_INT64",e[e.DT_BOOL=10]="DT_BOOL",e[e.DT_QINT8=11]="DT_QINT8",e[e.DT_QUINT8=12]="DT_QUINT8",e[e.DT_QINT32=13]="DT_QINT32",e[e.DT_BFLOAT16=14]="DT_BFLOAT16",e[e.DT_FLOAT_REF=101]="DT_FLOAT_REF",e[e.DT_DOUBLE_REF=102]="DT_DOUBLE_REF",e[e.DT_INT32_REF=103]="DT_INT32_REF",e[e.DT_UINT8_REF=104]="DT_UINT8_REF",e[e.DT_INT16_REF=105]="DT_INT16_REF",e[e.DT_INT8_REF=106]="DT_INT8_REF",e[e.DT_STRING_REF=107]="DT_STRING_REF",e[e.DT_COMPLEX64_REF=108]="DT_COMPLEX64_REF",e[e.DT_INT64_REF=109]="DT_INT64_REF",e[e.DT_BOOL_REF=110]="DT_BOOL_REF",e[e.DT_QINT8_REF=111]="DT_QINT8_REF",e[e.DT_QUINT8_REF=112]="DT_QUINT8_REF",e[e.DT_QINT32_REF=113]="DT_QINT32_REF",e[e.DT_BFLOAT16_REF=114]="DT_BFLOAT16_REF"}(DataType$1||(DataType$1={})),function(e){var t;(t=e.CheckpointFormatVersion||(e.CheckpointFormatVersion={}))[t.LEGACY=0]="LEGACY",t[t.V1=1]="V1",t[t.V2=2]="V2"}(SaverDef$1||(SaverDef$1={}));const version$c="3.8.0";var ZipMismatchMode$1;!function(e){e[e.FAIL=0]="FAIL",e[e.SHORTEST=1]="SHORTEST",e[e.LONGEST=2]="LONGEST"}(ZipMismatchMode$1||(ZipMismatchMode$1={}));const version$b="3.8.0";function assertNotComplex$3(e,t){Array.isArray(e)||(e=[e]),e.forEach(e=>{null!=e&&assert$6("complex64"!==e.dtype,()=>`${t} does not support complex64 tensors in the CPU backend.`)})}const whereImpl$4=whereImpl$5;class MathBackendCPU$1 extends KernelBackend$1{constructor(){super(),this.blockSize=48,this.firstUse=!0,this.data=new DataStorage$1(this,engine$1())}nextDataId(){return MathBackendCPU$1.nextDataId++}write(e,t,n){this.firstUse&&(this.firstUse=!1,env$1().get("IS_NODE")&&warn$1("\n============================\nHi there 👋. Looks like you are running TensorFlow.js in Node.js. To speed things up dramatically, install our node backend, which binds to TensorFlow C++, by running npm i @tensorflow/tfjs-node, or npm i @tensorflow/tfjs-node-gpu if you have CUDA. Then call require('@tensorflow/tfjs-node'); (-gpu suffix for CUDA) at the start of your program. Visit https://github.com/tensorflow/tfjs-node for more details.\n============================"));const r={id:this.nextDataId()};return this.data.set(r,{values:e,dtype:n,refCount:1}),r}makeTensorInfo(e,t,n){let r;if("string"===t&&null!=n&&n.length>0&&isString$1(n[0])){const a=n.map(e=>encodeString$1(e));r=this.write(a,e,t)}else r=this.write(n,e,t);return{dataId:r,shape:e,dtype:t}}refCount(e){return this.data.has(e)?this.data.get(e).refCount:0}incRef(e){this.data.get(e).refCount++}decRef(e){this.data.has(e)&&this.data.get(e).refCount--}move(e,t,n,r,a){this.data.set(e,{values:t,dtype:r,refCount:a})}numDataIds(){return this.data.numDataIds()}async read(e){return this.readSync(e)}readSync(e){const{dtype:t,complexTensorInfos:n}=this.data.get(e);return"complex64"===t?mergeRealAndImagArrays$1(this.readSync(n.real.dataId),this.readSync(n.imag.dataId)):this.data.get(e).values}bufferSync(e){const t=this.readSync(e.dataId);let n=t;if("string"===e.dtype)try{n=t.map(e=>decodeString$1(e))}catch(e){throw new Error("Failed to decode encoded string bytes into utf-8")}return buffer$1(e.shape,e.dtype,n)}makeOutput(e,t,n){const r=this.write(e,t,n);return engine$1().makeTensorFromDataId(r,t,n,this)}disposeData(e,t=!1){if(this.data.has(e)){if(this.data.get(e).refCount--,!t&&this.data.get(e).refCount>0)return!1;const{complexTensorInfos:n}=this.data.get(e);null!=n&&(this.disposeData(n.real.dataId,!0),this.disposeData(n.imag.dataId,!0)),this.data.delete(e)}return!0}disposeIntermediateTensorInfo(e){this.disposeData(e.dataId)}async time(e){const t=now$1();return e(),{kernelMs:now$1()-t}}memory(){return{unreliable:!0,reasons:["The reported memory is an upper bound. Due to automatic garbage collection, the true allocated memory may be less."]}}where(e){assertNotComplex$3([e],"where");const t=this.readSync(e.dataId);return whereImpl$4(e.shape,t)}dispose(){}floatPrecision(){return 32}epsilon(){return super.epsilon()}}function simpleAbsImpl$1(e){const t=new Float32Array(e.length);for(let n=0;n<e.length;++n)t[n]=Math.abs(e[n]);return t}MathBackendCPU$1.nextDataId=0;const abs$4=e=>{const{x:t}=e.inputs,n=e.backend;assertNotComplex$3(t,"abs");let r=new Float32Array(sizeFromShape$1(t.shape));return r=simpleAbsImpl$1(n.data.get(t.dataId).values),n.makeOutput(r,t.shape,"float32")},absConfig$3={kernelName:Abs$1,backendName:"cpu",kernelFunc:abs$4};function createSimpleBinaryKernelImpl$1(e){return(t,n,r,a,s)=>{const o=assertAndGetBroadcastShape$1(t,n),i=o.length,l=computeStrides$1(o),u=getTypedArrayFromDType$1(s,sizeFromShape$1(o)),c=t.length,p=n.length,d=computeStrides$1(t),h=computeStrides$1(n),m=getBroadcastDims$3(t,o),f=getBroadcastDims$3(n,o);if(m.length+f.length===0)for(let t=0;t<u.length;++t)u[t]=e(r[t%r.length],a[t%a.length]);else for(let t=0;t<u.length;++t){const n=indexToLoc$1(t,i,l),s=n.slice(-c);m.forEach(e=>s[e]=0);const o=locToIndex$1(s,c,d),g=n.slice(-p);f.forEach(e=>g[e]=0);const $=locToIndex$1(g,p,h);u[t]=e(r[o],a[$])}return[u,o]}}function complex$4(e){const{inputs:t,backend:n}=e,{real:r,imag:a}=t,s=n.data.get(r.dataId).values,o=n.data.get(a.dataId).values,i=n.makeTensorInfo(r.shape,"complex64");return n.data.get(i.dataId).complexTensorInfos={real:n.makeTensorInfo(r.shape,"float32",s),imag:n.makeTensorInfo(a.shape,"float32",o)},i}const complexConfig$3={kernelName:Complex$1,backendName:"cpu",kernelFunc:complex$4};function zeros$3(e,t,n="float32"){if("complex64"===n)return complex$4({inputs:{real:zeros$3(e,t,"float32"),imag:zeros$3(e,t,"float32")},backend:e});const r=makeZerosTypedArray$1(sizeFromShape$1(t),n);return e.makeTensorInfo(t,n,r)}function identity$4(e){const{inputs:t,backend:n}=e,{x:r}=t;return n.incRef(r.dataId),{dataId:r.dataId,shape:r.shape,dtype:r.dtype}}const identityConfig$3={kernelName:Identity$3,backendName:"cpu",kernelFunc:identity$4};function real$4(e){const{inputs:t,backend:n}=e,{input:r}=t,a=n.data.get(r.dataId).complexTensorInfos.real,s=n.data.get(a.dataId).values;return n.makeTensorInfo(a.shape,a.dtype,s)}const realConfig$3={kernelName:Real$1,backendName:"cpu",kernelFunc:real$4};function cast$5(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{dtype:s}=r;if("complex64"===s){if("complex64"===a.dtype)return identity$4({inputs:{x:a},backend:n});const e=zeros$3(n,a.shape,a.dtype),t=cast$5({inputs:{x:a},backend:n,attrs:{dtype:"float32"}}),r=complex$4({inputs:{real:t,imag:e},backend:n});return n.disposeIntermediateTensorInfo(e),n.disposeIntermediateTensorInfo(t),r}if("complex64"===a.dtype){const e=real$4({inputs:{input:a},backend:n}),t=cast$5({inputs:{x:e},backend:n,attrs:{dtype:s}});return n.disposeIntermediateTensorInfo(e),t}if(!hasEncodingLoss$1(a.dtype,s)){const e=identity$4({inputs:{x:a},backend:n});return{dataId:e.dataId,shape:e.shape,dtype:s}}if("int32"===s){const e=n.data.get(a.dataId).values,t=Int32Array.from(e);return n.makeTensorInfo(a.shape,"int32",t)}if("bool"===s){const e=n.data.get(a.dataId).values,t=toTypedArray$1([0],a.dtype),[r,s]=createSimpleBinaryKernelImpl$1((e,t)=>e!==t?1:0)(a.shape,[],e,t,"bool");return n.makeTensorInfo(s,"bool",r)}throw new Error(`Error in Cast: failed to cast ${a.dtype} to ${s}`)}const castConfig$3={kernelName:Cast$1,backendName:"cpu",kernelFunc:cast$5};function binaryKernelFunc$3(e,t,n,r){return null==n?({inputs:n,backend:a})=>{const{a:s,b:o}=n,i=a;assertNotComplex$3([s,o],e);const l=i.data.get(s.dataId).values,u=i.data.get(o.dataId).values,c="string"===s.dtype?fromUint8ToStringArray$1(l):l,p="string"===s.dtype?fromUint8ToStringArray$1(u):u,d=r||s.dtype,[h,m]=t(s.shape,o.shape,c,p,d);return i.makeTensorInfo(m,d,h)}:({inputs:e,backend:a})=>{const{a:s,b:o}=e,i=a;if("complex64"===s.dtype||"complex64"===o.dtype){const e=cast$5({inputs:{x:s},backend:i,attrs:{dtype:"complex64"}}),t=i.data.get(e.dataId),r=t.complexTensorInfos.imag,a=i.data.get(t.complexTensorInfos.real.dataId).values,l=i.data.get(r.dataId).values,u=cast$5({inputs:{x:o},backend:i,attrs:{dtype:"complex64"}}),c=i.data.get(u.dataId),p=c.complexTensorInfos.imag,d=i.data.get(c.complexTensorInfos.real.dataId).values,h=i.data.get(p.dataId).values,[m,f,g]=n(s.shape,o.shape,a,l,d,h),$=i.makeTensorInfo(g,"float32",m),y=i.makeTensorInfo(g,"float32",f),b=complex$4({inputs:{real:$,imag:y},backend:i});return i.disposeIntermediateTensorInfo(e),i.disposeIntermediateTensorInfo(u),i.disposeIntermediateTensorInfo($),i.disposeIntermediateTensorInfo(y),b}{const e=i.data.get(s.dataId).values,n=i.data.get(o.dataId).values,a=r||s.dtype,[l,u]=t(s.shape,o.shape,e,n,a);return i.makeTensorInfo(u,a,l)}}}function createComplexBinaryKernelImpl$1(e){return(t,n,r,a,s,o)=>{const i=assertAndGetBroadcastShape$1(t,n),l=sizeFromShape$1(i),u=i.length,c=computeStrides$1(i),p=getTypedArrayFromDType$1("float32",l),d=getTypedArrayFromDType$1("float32",l),h=getBroadcastDims$3(t,i),m=getBroadcastDims$3(n,i),f=mergeRealAndImagArrays$1(r,a),g=mergeRealAndImagArrays$1(s,o),$=t.length,y=computeStrides$1(t),b=n.length,x=computeStrides$1(n);if(h.length+m.length===0)for(let t=0;t<p.length;t++){const n=t%f.length,r=t%g.length,a=e(f[2*n],f[2*n+1],g[2*r],g[2*r+1]);p[t]=a.real,d[t]=a.imag}else for(let t=0;t<p.length;t++){const n=indexToLoc$1(t,u,c),r=n.slice(-$);h.forEach(e=>r[e]=0);const a=locToIndex$1(r,$,y),s=n.slice(-b);m.forEach(e=>s[e]=0);const o=locToIndex$1(s,b,x),i=e(f[2*a],f[2*a+1],g[2*o],g[2*o+1]);p[t]=i.real,d[t]=i.imag}return[p,d,i]}}const addImpl$1=createSimpleBinaryKernelImpl$1((e,t)=>e+t),addComplexImpl$1=createComplexBinaryKernelImpl$1((e,t,n,r)=>({real:e+n,imag:t+r})),add$4=binaryKernelFunc$3(Add$3,addImpl$1,addComplexImpl$1),addConfig$3={kernelName:Add$3,backendName:"cpu",kernelFunc:add$4};function bincountImpl$1(e,t,n,r,a){const s=sizeFromShape$1(r),o=makeZerosTypedArray$1(a,n);for(let n=0;n<e.length;n++){const r=e[n];if(r<0)throw new Error("Input x must be non-negative!");r>=a||(o[r]+=s>0?t[n]:1)}return o}function bincountReduceImpl$1(e,t,n,r=!1){const a=e.shape[0],s=e.shape[1],o=buffer$1([a,n],t.dtype);for(let i=0;i<a;i++)for(let a=0;a<s;a++){const s=e.get(i,a);if(s<0)throw new Error("Input x must be non-negative!");s>=n||o.set(r?1:t.size>0?o.get(i,s)+t.get(i,a):o.get(i,s)+1,i,s)}return o}function createSimpleUnaryImpl$1(e){return(t,n,r)=>{const a=getTypedArrayFromDType$1(n,t.length);for(let n=0;n<t.length;++n)a[n]=e(t[n],r);return a}}function unaryKernelFunc$3(e,t,n){return({inputs:r,attrs:a,backend:s})=>{const{x:o}=r;if(assertNotComplex$3(o,e),"string"===o.dtype||"string"===n)throw new Error("unaryKernelFunc does not support string input/output");const i=s,l=i.data.get(o.dataId).values,u=sizeFromShape$1(o.shape),c=n||o.dtype,p=getArrayFromDType$1(c,u);for(let e=0;e<u;++e)p[e]=t(l[e],a);return i.makeTensorInfo(o.shape,c,p)}}function unaryKernelFuncFromImpl$1(e,t,n){return({inputs:r,attrs:a,backend:s})=>{const{x:o}=r;if(assertNotComplex$3(o,e),"string"===o.dtype||"string"===n)throw new Error("unaryKernelFunc does not support string input/output");const i=s,l=i.data.get(o.dataId).values,u=n||o.dtype,c=t(l,u,a);return i.makeTensorInfo(o.shape,u,c)}}const ceilImpl$1=createSimpleUnaryImpl$1(e=>Math.ceil(e)),ceil$4=unaryKernelFuncFromImpl$1(Ceil$1,ceilImpl$1),ceilConfig$3={kernelName:Ceil$1,backendName:"cpu",kernelFunc:ceil$4};function concatImpl$3(e,t,n,r){const a=getArrayFromDType$1(n,sizeFromShape$1(t));if(r&&"string"!==n){let t=0;e.forEach(e=>{const n=sizeFromShape$1(e.shape);a.set(e.vals,t),t+=n})}else{let r=0;e.forEach(e=>{const s="string"===n?fromUint8ToStringArray$1(e.vals):e.vals;let o=0;for(let n=0;n<e.shape[0];++n){const i=n*t[1]+r;for(let t=0;t<e.shape[1];++t)a[i+t]=s[o++]}r+=e.shape[1]})}return a}const equalImpl$1=createSimpleBinaryKernelImpl$1((e,t)=>e===t?1:0),equal$4=binaryKernelFunc$3(Equal$1,equalImpl$1,null,"bool"),equalConfig$3={kernelName:Equal$1,backendName:"cpu",kernelFunc:equal$4},expImpl$1=createSimpleUnaryImpl$1(e=>Math.exp(e)),exp$4=unaryKernelFuncFromImpl$1(Exp$1,expImpl$1),expConfig$3={kernelName:Exp$1,backendName:"cpu",kernelFunc:exp$4},expm1Impl$1=createSimpleUnaryImpl$1(e=>Math.expm1(e)),expm1$4=unaryKernelFuncFromImpl$1(Expm1$1,expm1Impl$1),expm1Config$3={kernelName:Expm1$1,backendName:"cpu",kernelFunc:expm1$4},floorImpl$1=createSimpleUnaryImpl$1(e=>Math.floor(e)),floor$4=unaryKernelFuncFromImpl$1(Floor$1,floorImpl$1),floorConfig$3={kernelName:Floor$1,backendName:"cpu",kernelFunc:floor$4};function gatherNdImpl$1(e,t,n,r,a,s,o,i,l){const u=buffer$1([r,s],n);for(let n=0;n<r;n++){const r=[];let c=0;for(let t=0;t<a;t++){const s=e[n*a+t];c+=s*o[t],r.push(s)}if(c<0||c>=l/s)throw new Error(`Invalid indices: ${r} does not index into ${i}`);for(let e=0;e<s;e++)u.values[n*s+e]=t.get(...t.indexToLoc(c*s+e))}return u}function gatherV2Impl$1(e,t,n){const r=buffer$1(n,e.dtype);for(let n=0;n<r.size;++n){const a=r.indexToLoc(n).slice(),s=t.locToIndex([a[0],a[2]]);a[2]=t.values[s];const o=e.locToIndex(a);r.values[n]=e.values[o]}return r}const greaterImpl$1=createSimpleBinaryKernelImpl$1((e,t)=>e>t?1:0),greater$5=binaryKernelFunc$3(Greater$1,greaterImpl$1,null,"bool"),greaterConfig$3={kernelName:Greater$1,backendName:"cpu",kernelFunc:greater$5},greaterEqualImpl$1=createSimpleBinaryKernelImpl$1((e,t)=>e>=t?1:0),greaterEqual$4=binaryKernelFunc$3(GreaterEqual$1,greaterEqualImpl$1,null,"bool"),greaterEqualConfig$3={kernelName:GreaterEqual$1,backendName:"cpu",kernelFunc:greaterEqual$4},lessImpl$1=createSimpleBinaryKernelImpl$1((e,t)=>e<t?1:0),less$5=binaryKernelFunc$3(Less$1,lessImpl$1,null,"bool"),lessConfig$3={kernelName:Less$1,backendName:"cpu",kernelFunc:less$5},lessEqualImpl$1=createSimpleBinaryKernelImpl$1((e,t)=>e<=t?1:0),lessEqual$4=binaryKernelFunc$3(LessEqual$1,lessEqualImpl$1,null,"bool"),lessEqualConfig$3={kernelName:LessEqual$1,backendName:"cpu",kernelFunc:lessEqual$4};function linSpaceImpl$1(e,t,n){const r=(t-e)/(n-1),a=makeZerosTypedArray$1(n,"float32");a[0]=e;for(let e=1;e<a.length;e++)a[e]=a[e-1]+r;return a}const logImpl$1=createSimpleUnaryImpl$1(e=>Math.log(e)),log$5=unaryKernelFuncFromImpl$1(Log$1,logImpl$1),logConfig$3={kernelName:Log$1,backendName:"cpu",kernelFunc:log$5};function maxImpl$3(e,t,n,r){const a=getTypedArrayFromDType$1(r,sizeFromShape$1(n));for(let n=0;n<a.length;++n){const r=n*t;let s=e[r];for(let n=0;n<t;++n){const t=e[r+n];(Number.isNaN(t)||t>s)&&(s=t)}a[n]=s}return a}const maximumImpl$1=createSimpleBinaryKernelImpl$1((e,t)=>Math.max(e,t)),maximum$5=binaryKernelFunc$3(Maximum$3,maximumImpl$1),maximumConfig$3={kernelName:Maximum$3,backendName:"cpu",kernelFunc:maximum$5},minimumImpl$1=createSimpleBinaryKernelImpl$1((e,t)=>Math.min(e,t)),minimum$5=binaryKernelFunc$3(Minimum$3,minimumImpl$1),minimumConfig$3={kernelName:Minimum$3,backendName:"cpu",kernelFunc:minimum$5},multiplyImpl$1=createSimpleBinaryKernelImpl$1((e,t)=>e*t),multiplyComplexImpl$1=createComplexBinaryKernelImpl$1((e,t,n,r)=>({real:e*n-t*r,imag:e*r+t*n})),multiply$4=binaryKernelFunc$3(Multiply$3,multiplyImpl$1,multiplyComplexImpl$1),multiplyConfig$3={kernelName:Multiply$3,backendName:"cpu",kernelFunc:multiply$4};function negImpl$1(e,t,n){const r=createScalarValue$1(-1,n);return multiplyImpl$1([],t,r,e,n)}function neg$4(e){const{inputs:t,backend:n}=e,{x:r}=t;assertNotComplex$3(r,"neg");const a=n.data.get(r.dataId).values,[s,o]=negImpl$1(a,r.shape,r.dtype);return n.makeTensorInfo(o,r.dtype,s)}const negConfig$3={kernelName:Neg$1,backendName:"cpu",kernelFunc:neg$4},notEqualImpl$1=createSimpleBinaryKernelImpl$1((e,t)=>e!==t?1:0),notEqual$4=binaryKernelFunc$3(NotEqual$1,notEqualImpl$1,null,"bool"),notEqualConfig$3={kernelName:NotEqual$1,backendName:"cpu",kernelFunc:notEqual$4};function transposeImpl$3(e,t,n,r,a){const s=t.length,o=sizeFromShape$1(t),i=computeStrides$1(t),l=computeStrides$1(a),u=getTypedArrayFromDType$1(n,sizeFromShape$1(a));for(let t=0;t<o;++t){const n=indexToLoc$1(t,s,i),a=new Array(n.length);for(let e=0;e<a.length;e++)a[e]=n[r[e]];u[locToIndex$1(a,s,l)]=e[t]}return u}function transpose$4(e){const{inputs:t,attrs:n,backend:r}=e,{x:a}=t,{perm:s}=n;assertNotComplex$3(a,"transpose");const o=new Array(a.shape.length);for(let e=0;e<o.length;e++)o[e]=a.shape[s[e]];const i=transposeImpl$3(r.data.get(a.dataId).values,a.shape,a.dtype,s,o);return{dataId:r.write(i,o,a.dtype),shape:o,dtype:a.dtype}}const transposeConfig$3={kernelName:Transpose$1,backendName:"cpu",kernelFunc:transpose$4};function prodImpl$1(e,t,n,r){const[a,s]=computeOutAndReduceShapes$1(e,r),o=upcastType$1(t,"int32"),i=makeZerosTypedArray$1(sizeFromShape$1(a),o),l=sizeFromShape$1(s);for(let e=0;e<i.length;++e){const t=e*l;let r=1;for(let e=0;e<l;++e)r*=n[t+e];i[e]=r}return{outVals:i,outShape:a,outDtype:o}}function prod$4(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{axis:s,keepDims:o}=r;assertNotComplex$3(a,"prod");const i=a.shape.length,l=parseAxisParam$1(s,a.shape),u=getAxesPermutation$1(l,i);let c=l,p=a;const d=[];null!=u&&(p=transpose$4({inputs:{x:a},backend:n,attrs:{perm:u}}),d.push(p),c=getInnerMostAxes$1(c.length,i));const h=n.data.get(p.dataId).values,{outVals:m,outShape:f,outDtype:g}=prodImpl$1(p.shape,p.dtype,h,c);let $=f;return o&&($=expandShapeToKeepDim$1(f,l)),d.forEach(e=>n.disposeIntermediateTensorInfo(e)),n.makeTensorInfo($,g,m)}const prodConfig$3={kernelName:Prod$1,backendName:"cpu",kernelFunc:prod$4};function rangeImpl$1(e,t,n,r){if(e===t||e<t&&n<0||t<e&&n>1)return makeZerosTypedArray$1(0,r);const a=makeZerosTypedArray$1(Math.abs(Math.ceil((t-e)/n)),r);t<e&&1===n&&(n=-1),a[0]=e;for(let e=1;e<a.length;e++)a[e]=a[e-1]+n;return a}const rsqrtImpl$1=createSimpleUnaryImpl$1(e=>1/Math.sqrt(e)),rsqrt$4=unaryKernelFuncFromImpl$1(Rsqrt$1,rsqrtImpl$1),rsqrtConfig$3={kernelName:Rsqrt$1,backendName:"cpu",kernelFunc:rsqrt$4};function sliceImpl$1(e,t,n,r,a){const s=isSliceContinous$1(r,t,n),o=sizeFromShape$1(n),i=computeStrides$1(r);if(s){const n=computeFlatOffset$1(t,i);return"string"===a?e.slice(n,n+o):e.subarray(n,n+o)}const l=buffer$1(r,a,"string"===a?fromUint8ToStringArray$1(e):e),u=buffer$1(n,a);for(let e=0;e<u.size;++e){const n=u.indexToLoc(e),r=n.map((e,n)=>e+t[n]);u.set(l.get(...r),...n)}return"string"===a?fromStringArrayToUint8$1(u.values):u.values}function slice$4(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{begin:s,size:o}=r;assertNotComplex$3(a,"slice");const[i,l]=parseSliceParams$1(a,s,o);assertParamsValid$1(a,i,l);const u=sliceImpl$1(n.data.get(a.dataId).values,i,l,a.shape,a.dtype);return n.makeTensorInfo(l,a.dtype,u)}const sliceConfig$3={kernelName:Slice$1,backendName:"cpu",kernelFunc:slice$4};function sparseFillEmptyRowsImpl$1(e,t,n,r,a,s,o){const i=t[0],l=s[0],u=new Array(l),c=new Array(i),p=t[1];if(0===l){if(0!==i)throw new Error(`Received SparseTensor with denseShape[0] = 0 but\n         indices.shape[0] = ${i}`);return[getArrayFromDType$1(n,0),[0,p],getArrayFromDType$1(a,0),u,c]}let d=!0,h=0;const m=new Array(l).fill(0);for(let t=0;t<i;++t){const n=e[t*p];if(n<0)throw new Error(`indices(${t}, 0) is invalid: ${n} < 0`);if(n>=l)throw new Error(`indices(${t}, 0) is invalid: ${n} >= ${l}`);++m[n],d=d&&n>=h,h=n}let f=!0;for(let e=0;e<l;++e){const t=0===m[e];u[e]=t,f=f&&!t,m[e]=Math.max(m[e],1),e>0&&(m[e]+=m[e-1])}if(f&&d){const t=e,n=r;for(let e=0;e<i;++e)c[e]=e;return[t,[i,p],n,u,c]}{const t=m[l-1],s=getArrayFromDType$1(n,t*p),d=getArrayFromDType$1(a,t),h=new Array(l).fill(0);for(let t=0;t<i;++t){const n=e[t*p],a=(0===n?0:m[n-1])+h[n];h[n]++;for(let n=0;n<p;++n)s[a*p+n]=e[t*p+n];d[a]=r[t],c[t]=a}for(let e=0;e<l;++e)if(0===h[e]){const t=0===e?0:m[e-1];s[t*p+0]=e;for(let e=1;e<p;++e)s[t*p+e]=0;d[t]=o}return[s,[t,p],d,u,c]}}function sparseReshapeImpl$1(e,t,n,r,a){const s=sizeFromShape$1(r),o=t[0],i=a.length,l=[];let u=1,c=-1;for(let e=0;e<i;++e){const t=a[e];if(-1===t){if(-1!==c)throw new Error(`only one output dimension may be -1, not both ${c} and ${e}`);c=e,l.push(1)}else{if(t<0)throw new Error(`size ${e} must be non-negative, not ${t}`);u*=t,l.push(t)}}if(-1!==c){if(u<=0)throw new Error("reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero");const e=Math.trunc(s/u);if(u*e!==s)throw new Error(`Input to reshape is a SparseTensor with ${s}\n          dense values, but the requested shape requires a multiple of ${u}. inputShape=${r} outputShape= ${l}`);l[c]=e}const p=sizeFromShape$1(l);if(p!==s)throw new Error(`Input to reshape is a tensor with ${s} dense values, but the requested shape has ${p}. inputShape=${r} outputShape=${l}`);const d=r.length,h=[];if(d>0){h[d-1]=1;for(let e=d-2;e>=0;--e)h[e]=h[e+1]*r[e+1]}const m=[];if(i>0){m[i-1]=1;for(let e=i-2;e>=0;--e)m[e]=m[e+1]*l[e+1]}const f=getArrayFromDType$1(n,o*i);for(let t=0;t<o;++t){let n=0;for(let r=0;r<d;++r)n+=e[t*d+r]*h[r];for(let e=0;e<i;++e)f[t*i+e]=Math.trunc(n/m[e]),n%=m[e]}return[f,[o,i],l]}function sparseSegmentReductionImpl$1(e,t,n,r,a,s=!1,o=0){const i=r.length;if(i!==a.length)throw new Error("segmentIds and indices should have same size.");const l=[t[0],e.length/t[0]],u=l[1],c=i>0?a[i-1]+1:0;if(c<0)throw new Error("segment ids must be >= 0");const p=t.slice();p[0]=c;const d=getArrayFromDType$1(n,p.reduce((e,t)=>e*t,1));if(0===i)return c>0&&d.fill(o),[d,p];if(c<=0)throw new Error("segment ids must be >= 0");let h=0,m=1,f=0,g=a[h];for(;;){let t=0;if(m<i){if(t=a[m],g===t){++m;continue}if(g>=t)throw new Error("segment ids are not increasing")}if(g<0||g>=c)throw new Error(`Segment id ${g} out of range [0, ${c}), possibly because segmentIds input is not sorted.`);g>f&&d.fill(o,f*u,g*u);for(let t=h;t<m;++t){const n=r[t];if(n<0||n>=l[0])throw new Error(`Bad: indices[${t}] == ${r[t]} out of range [0, ${l[0]})`);for(let t=0;t<u;t++)d[g*u+t]+=e[n*u+t]}if(s)for(let e=0;e<u;e++)d[g*u+e]/=m-h;if(h=m,++m,f=g+1,g=t,m>i)break}return f<c&&d.fill(o,f*u,c*u),[d,p]}const squaredDifferenceImpl$1=createSimpleBinaryKernelImpl$1((e,t)=>{const n=e-t;return n*n}),squaredDifference$4=binaryKernelFunc$3(SquaredDifference$1,squaredDifferenceImpl$1),squaredDifferenceConfig$3={kernelName:SquaredDifference$1,backendName:"cpu",kernelFunc:squaredDifference$4};function stridedSliceImpl$1(e,t,n,r){const a=buffer$1(e,t.dtype);for(let e=0;e<a.size;e++){const s=a.indexToLoc(e),o=new Array(s.length);for(let e=0;e<o.length;e++)o[e]=s[e]*n[e]+r[e];a.set(t.get(...o),...s)}return a}class StringNGramsOp$1{constructor(e,t,n,r,a,s){this.separator=encodeString$1(e),this.nGramWidths=t,this.leftPad=encodeString$1(n),this.rightPad=encodeString$1(r),this.padWidth=a,this.preserveShort=s}getPadWidth(e){return Math.min(this.padWidth<0?e-1:this.padWidth,e-1)}getNumNGrams(e,t){const n=this.getPadWidth(t);return Math.max(0,e+2*n-t+1)}createNGrams(e,t,n,r,a,s){for(let o=0;o<a;++o){const i=this.getPadWidth(s),l=Math.max(0,i-o),u=Math.max(0,i-(a-(o+1))),c=s-(l+u),p=t+(l>0?0:o-i);let d=0;d+=l*this.leftPad.length;for(let t=0;t<c;++t)d+=e[p+t].length;d+=u*this.rightPad.length,d+=(l+u+c-1)*this.separator.length,n[r+o]=new Uint8Array(d);const h=n[r+o];let m=0;const f=e=>e.forEach(e=>h[m++]=e);for(let e=0;e<l;++e)f(this.leftPad),f(this.separator);for(let t=0;t<c-1;++t)f(e[p+t]),f(this.separator);if(c>0){f(e[p+c-1]);for(let e=0;e<u;++e)f(this.separator),f(this.rightPad)}else{for(let e=0;e<u-1;++e)f(this.rightPad),f(this.separator);f(this.rightPad)}}}compute(e,t){const n=e.length,r=t.length;if(r>0){let e=t[0];if(0!==e)throw new Error(`First split value must be 0, got ${e}`);for(let a=1;a<r;++a){let r=t[a]>=e;if(r=r&&t[a]<=n,!r)throw new Error(`Invalid split value ${t[a]}, must be in [${e}, ${n}]`);e=t[a]}if(e!==n)throw new Error(`Last split value must be data size. Expected ${n}, got ${e}`)}const a=r-1,s=getArrayFromDType$1("int32",r);if(0===n||0===r){const e=new Array(n);for(let e=0;e<=a;++e)s[e]=0;return[e,s]}s[0]=0;for(let e=1;e<=a;++e){const n=t[e]-t[e-1];let r=0;this.nGramWidths.forEach(e=>{r+=this.getNumNGrams(n,e)}),this.preserveShort&&n>0&&0===r&&(r=1),s[e]=s[e-1]+r}const o=new Array(s[a]);for(let n=0;n<a;++n){const r=t[n];let a=s[n];if(this.nGramWidths.forEach(s=>{const i=this.getNumNGrams(t[n+1]-t[n],s);this.createNGrams(e,r,o,a,i,s),a+=i}),this.preserveShort&&a===s[n]){const s=t[n+1]-t[n];if(0===s)continue;this.createNGrams(e,r,o,a,1,s+2*this.padWidth)}}return[o,s]}}function stringNGramsImpl$1(e,t,n,r,a,s,o,i){return new StringNGramsOp$1(n,r,a,s,o,i).compute(e,t)}function split$3(e,t,n){if(!e.length)return[];if(0===t.length){const t=new Array(e.length);for(let n=0;n<e.length;++n)t[n]=e.subarray(n,n+1);return t}if(1===t.length){const r=t[0],a=[];let s=e.indexOf(r);for(;-1!==s;){const t=e.subarray(0,s);n&&0===t.length||a.push(t),s=(e=e.subarray(s+1)).indexOf(r)}return n&&0===e.length||a.push(e),a}const r=[];let a=0;for(let s=0;s<e.length+1;s++)if(s===e.length||-1!==t.indexOf(e[s])){const t=e.subarray(a,s);n&&0===t.length||r.push(t),a=s+1}return r}function stringSplitImpl$1(e,t,n){const r=e.length,a=[];let s=0,o=0;const i=new Array(r);for(let l=0;l<r;++l){const r=split$3(e[l],t,n),u=r.length;i[l]=u,s+=u,o=Math.max(o,u),a.push(...r)}const l=getArrayFromDType$1("int32",2*s),u=new Array(s),c=[r,o];let p=0;for(let e=0;e<r;++e)for(let t=0;t<i[e];++t)l[2*p]=e,l[2*p+1]=t,u[p]=a[p],++p;return[l,u,c]}function stringToHashBucketFastImpl$1(e,t){const n=getArrayFromDType$1("int32",e.length);for(let r=0;r<e.length;++r)n[r]=fingerPrint64$1(e[r]).modulo(t).getLowBitsUnsigned();return n}const subImpl$1=createSimpleBinaryKernelImpl$1((e,t)=>e-t),subComplexImpl$1=createComplexBinaryKernelImpl$1((e,t,n,r)=>({real:e-n,imag:t-r})),sub$4=binaryKernelFunc$3(Sub$1,subImpl$1,subComplexImpl$1),subConfig$3={kernelName:Sub$1,backendName:"cpu",kernelFunc:sub$4};function tileImpl$1(e,t){const n=new Array(e.rank);for(let r=0;r<n.length;r++)n[r]=e.shape[r]*t[r];const r=buffer$1(n,e.dtype);for(let t=0;t<r.values.length;++t){const n=r.indexToLoc(t),a=new Array(e.rank);for(let t=0;t<a.length;t++)a[t]=n[t]%e.shape[t];const s=e.locToIndex(a);r.values[t]=e.values[s]}return r}const comparePair$1=(e,t)=>{const n=t.value-e.value;return 0===n?e.index-t.index:n};function select$5(e,t,n=0,r=e.length-1){for(;r>n;){if(r-n>600){const a=r-n+1,s=t-n+1,o=Math.log(a),i=.5*Math.exp(2*o/3),l=.5*Math.sqrt(o*i*(a-i)/a)*Math.sign(s-a/2);select$5(e,t,Math.max(n,Math.floor(t-s*i/a+l)),Math.min(r,Math.floor(t+(a-s)*i/a+l)))}const a=e[t];let s=n,o=r;for(swap$1(e,n,t),comparePair$1(e[r],a)>0&&swap$1(e,n,r);s<o;){for(swap$1(e,s,o),s++,o--;comparePair$1(e[s],a)<0;)s+=1;for(;comparePair$1(e[o],a)>0;)o-=1}0===comparePair$1(e[n],a)?swap$1(e,n,o):(o+=1,swap$1(e,o,r)),o<=t&&(n=o+1),t<=o&&(r=o-1)}}function topKImpl$1(e,t,n,r,a){const s=t[t.length-1],[o,i]=[e.length/s,s],l=getTypedArrayFromDType$1(n,o*r),u=getTypedArrayFromDType$1("int32",o*r);for(let t=0;t<o;t++){const n=t*i,s=e.subarray(n,n+i);let o=new Array(s.length);s.forEach((e,t)=>o[t]={value:e,index:t}),r<o.length&&(select$5(o,r),o=o.slice(0,r)),a&&o.sort(comparePair$1);const c=t*r,p=l.subarray(c,c+r),d=u.subarray(c,c+r);for(let e=0;e<r;e++)p[e]=o[e].value,d[e]=o[e].index}const c=t.slice();return c[c.length-1]=r,[buffer$1(c,n,l),buffer$1(c,"int32",u)]}function uniqueImpl$1(e,t,n,r){const a=parseAxisParam$1(t,n)[0],s=[1,n[0],1];for(let e=0;e<a;e++)s[0]*=n[e];s[1]=n[a];for(let e=a+1;e<n.length;e++)s[2]*=n[e];const o={},i=new Int32Array(n[a]),l=new TensorBuffer$1(s,r,e),u=[],c=1===s[0]&&1===s[2];for(let t=0;t<n[a];t++){let n;if(c)n=e[t].toString();else{const e=[];for(let n=0;n<s[0];n++)for(let r=0;r<s[2];r++)e.push(l.get(n,t,r));n=e.join(",")}if(void 0!==o[n])i[t]=o[n];else{const e=Object.keys(o).length;o[n]=e,i[t]=e,u.push(t)}}const p=s.slice();p[1]=Object.keys(o).length;const d=new TensorBuffer$1(p,r);u.forEach((e,t)=>{for(let n=0;n<s[0];n++)for(let r=0;r<s[2];r++)d.set(l.get(n,e,r),n,t,r)});const h=n.slice();return h[a]=p[1],{outputValues:d.values,outputShape:h,indices:i}}var shared$1={__proto__:null,simpleAbsImpl:simpleAbsImpl$1,addImpl:addImpl$1,bincountImpl:bincountImpl$1,bincountReduceImpl:bincountReduceImpl$1,ceilImpl:ceilImpl$1,concatImpl:concatImpl$3,equalImpl:equalImpl$1,expImpl:expImpl$1,expm1Impl:expm1Impl$1,floorImpl:floorImpl$1,gatherNdImpl:gatherNdImpl$1,gatherV2Impl:gatherV2Impl$1,greaterImpl:greaterImpl$1,greaterEqualImpl:greaterEqualImpl$1,lessImpl:lessImpl$1,lessEqualImpl:lessEqualImpl$1,linSpaceImpl:linSpaceImpl$1,logImpl:logImpl$1,maxImpl:maxImpl$3,maximumImpl:maximumImpl$1,minimumImpl:minimumImpl$1,multiplyImpl:multiplyImpl$1,negImpl:negImpl$1,notEqualImpl:notEqualImpl$1,prodImpl:prodImpl$1,rangeImpl:rangeImpl$1,rsqrtImpl:rsqrtImpl$1,sliceImpl:sliceImpl$1,sparseFillEmptyRowsImpl:sparseFillEmptyRowsImpl$1,sparseReshapeImpl:sparseReshapeImpl$1,sparseSegmentReductionImpl:sparseSegmentReductionImpl$1,squaredDifferenceImpl:squaredDifferenceImpl$1,stridedSliceImpl:stridedSliceImpl$1,stringNGramsImpl:stringNGramsImpl$1,stringSplitImpl:stringSplitImpl$1,stringToHashBucketFastImpl:stringToHashBucketFastImpl$1,subImpl:subImpl$1,tileImpl:tileImpl$1,topKImpl:topKImpl$1,transposeImpl:transposeImpl$3,uniqueImpl:uniqueImpl$1};const version$a="3.8.0";registerBackend$1("cpu",()=>new MathBackendCPU$1,1);const elu$6=unaryKernelFunc$3(Elu$3,e=>e>=0?e:Math.exp(e)-1),eluConfig$3={kernelName:Elu$3,backendName:"cpu",kernelFunc:elu$6};function leakyRelu$4(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{alpha:s}=r;assertNotComplex$3([a],"leakyRelu");const o=sizeFromShape$1(a.shape),i=n.data.get(a.dataId).values,l=getTypedArrayFromDType$1("float32",o);for(let e=0;e<i.length;e++)l[e]=i[e]<0?s*i[e]:i[e];return n.makeTensorInfo(a.shape,"float32",l)}const leakyReluConfig$3={kernelName:LeakyRelu$1,backendName:"cpu",kernelFunc:leakyRelu$4},preluImpl$1=createSimpleBinaryKernelImpl$1((e,t)=>e<0?t*e:e);function prelu$5(e){const{inputs:t,backend:n}=e,{x:r,alpha:a}=t;assertNotComplex$3([r,a],"prelu");const s=n.data.get(r.dataId).values,o=n.data.get(a.dataId).values,[i,l]=preluImpl$1(r.shape,a.shape,s,o,r.dtype);return n.makeTensorInfo(l,r.dtype,i)}const preluConfig$3={kernelName:Prelu$1,backendName:"cpu",kernelFunc:prelu$5},relu$5=unaryKernelFunc$3(Relu$3,e=>Math.max(0,e)),reluConfig$3={kernelName:Relu$3,backendName:"cpu",kernelFunc:relu$5},relu6$4=unaryKernelFunc$3(Relu6$3,e=>Math.min(Math.max(0,e),6)),relu6Config$3={kernelName:Relu6$3,backendName:"cpu",kernelFunc:relu6$4},sigmoid$4=unaryKernelFunc$3(Sigmoid$3,e=>1/(1+Math.exp(-e))),sigmoidConfig$3={kernelName:Sigmoid$3,backendName:"cpu",kernelFunc:sigmoid$4};function applyActivation$2(e,t,n,r,a){if("linear"===n)return identity$4({inputs:{x:t},backend:e});if("relu"===n)return relu$5({inputs:{x:t},backend:e});if("elu"===n)return elu$6({inputs:{x:t},backend:e});if("relu6"===n)return relu6$4({inputs:{x:t},backend:e});if("prelu"===n)return prelu$5({inputs:{x:t,alpha:r},backend:e});if("leakyrelu"===n)return leakyRelu$4({inputs:{x:t},backend:e,attrs:{alpha:a}});if("sigmoid"===n)return sigmoid$4({inputs:{x:t},backend:e});throw new Error(`Activation ${n} has not been implemented for the CPU backend.`)}function reshape$5(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{shape:s}=r,o=sizeFromShape$1(a.shape),i=inferFromImplicitShape$1(s,o),l=sizeFromShape$1(i);assert$6(o===l,()=>`The new shape (${i}) has ${l} elements and the old shape (${a.shape}) has ${o} elements. The new shape and old shape must have the same number of elements.`),n.incRef(a.dataId);const u=n.data.get(a.dataId);if(null!=u.complexTensorInfos){const e=u.complexTensorInfos.imag;u.complexTensorInfos.real.shape=i,e.shape=i}return{dataId:a.dataId,shape:i,dtype:a.dtype}}const reshapeConfig$3={kernelName:Reshape$3,backendName:"cpu",kernelFunc:reshape$5};function batchMatMul$3(e){const{inputs:t,backend:n,attrs:r}=e,{a,b:s}=t,{transposeA:o,transposeB:i}=r;assertNotComplex$3([a,s],"matMul");const l=a.shape.length,u=s.shape.length,c=o?a.shape[l-2]:a.shape[l-1],p=i?s.shape[u-1]:s.shape[u-2],d=o?a.shape[l-1]:a.shape[l-2],h=i?s.shape[u-2]:s.shape[u-1],m=a.shape.slice(0,-2),f=s.shape.slice(0,-2),g=sizeFromShape$1(m),$=sizeFromShape$1(f);assert$6(l>=2&&u>=2&&(g===$||1===g||1===$),()=>`Error in matMul: the input batch dimensions must either be the same or at least one input batch dimension must be 1. Got input batch dimensions of (${m}) and (${f}).`);const y=(g>$?a.shape.slice(0,-2):s.shape.slice(0,-2)).concat([d,h]);assert$6(c===p,()=>`Error in matMul: inner shapes (${c}) and (${p}) of Tensors with shapes ${a.shape} and ${s.shape} and transposeA=${o} and transposeB=${i} must match.`);const b=i?[$,h,p]:[$,p,h],x=reshape$5({inputs:{x:a},backend:n,attrs:{shape:o?[g,c,d]:[g,d,c]}}),v=reshape$5({inputs:{x:s},backend:n,attrs:{shape:b}}),I=o?x.shape[1]:x.shape[2],C=o?x.shape[2]:x.shape[1],S=i?v.shape[1]:v.shape[2],k=Math.max(g,$),T=n.data.get(x.dataId).values,N=n.data.get(v.dataId).values,w=computeStrides$1(x.shape),E=computeStrides$1(v.shape),[A,D,R]=o?[w[0],1,w[1]]:[w[0],w[1],1],[_,F,P]=i?[1,E[1],E[0]]:[E[1],1,E[0]],O=C*S,M=buffer$1([k,C,S],x.dtype),L=M.values,z=n.blockSize;for(let e=0;e<k;e++)for(let t=0;t<C;t+=z)for(let n=0;n<S;n+=z)for(let r=0;r<I;r+=z){const a=Math.min(t+z,C),s=Math.min(n+z,S),o=Math.min(r+z,I);for(let i=t;i<a;i++)for(let t=n;t<s;t++){let n=0;for(let a=r;a<o;a++){const r=Math.min(e,g-1)*A,s=Math.min(e,$-1)*P;n+=T[r+i*D+a*R]*N[a*_+t*F+s]}L[e*O+(i*S+t)]+=n}}return n.disposeIntermediateTensorInfo(x),n.disposeIntermediateTensorInfo(v),n.makeTensorInfo(y,M.dtype,M.values)}const batchMatMulConfig$3={kernelName:BatchMatMul$1,backendName:"cpu",kernelFunc:batchMatMul$3};function _fusedMatMul$3(e){const{inputs:t,backend:n,attrs:r}=e,{a,b:s,bias:o,preluActivationWeights:i}=t,{transposeA:l,transposeB:u,activation:c,leakyreluAlpha:p}=r;let d,h,m;const f=[];d=batchMatMul$3({inputs:{a,b:s},attrs:{transposeA:l,transposeB:u},backend:n}),o&&(h=add$4({inputs:{a:d,b:o},backend:n}),f.push(d),d=h),c&&(m=applyActivation$2(n,d,c,i,p),f.push(d),d=m);for(const e of f)n.disposeIntermediateTensorInfo(e);return d}const _fusedMatMulConfig$3={kernelName:_FusedMatMul$1,backendName:"cpu",kernelFunc:_fusedMatMul$3},acos$4=unaryKernelFunc$3(Acos$1,e=>Math.acos(e)),acosConfig$3={kernelName:Acos$1,backendName:"cpu",kernelFunc:acos$4},acosh$4=unaryKernelFunc$3(Acosh$1,e=>Math.acosh(e)),acoshConfig$3={kernelName:Acosh$1,backendName:"cpu",kernelFunc:acosh$4};function addN$4(e){const{inputs:t,backend:n}=e,r=t;assertNotComplex$3(t,"addN");const a=r.map(e=>n.data.get(e.dataId).values),s=buffer$1(r[0].shape,r[0].dtype),o=s.values;for(let e=0;e<r.length;e++){const t=a[e];for(let e=0;e<o.length;e++)o[e]+=t[e]}return n.makeTensorInfo(s.shape,s.dtype,s.values)}const addNConfig$3={kernelName:AddN$1,backendName:"cpu",kernelFunc:addN$4};function all$4(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{axis:s,keepDims:o}=r;assertNotComplex$3(a,"all");const i=parseAxisParam$1(s,a.shape);let l=i;const u=getAxesPermutation$1(l,a.shape.length);let c=a;null!=u&&(c=transpose$4({inputs:{x:a},backend:n,attrs:{perm:u}}),l=getInnerMostAxes$1(l.length,a.shape.length)),assertAxesAreInnerMostDims$1("all",l,c.shape.length);const[p,d]=computeOutAndReduceShapes$1(c.shape,l),h=sizeFromShape$1(d),m=makeZerosTypedArray$1(sizeFromShape$1(p),c.dtype),f=n.data.get(c.dataId).values;for(let e=0;e<m.length;++e){const t=e*h;let n=f[t];for(let e=0;e<h;++e){const r=f[t+e];n=n&&r}m[e]=n}null!=u&&n.disposeIntermediateTensorInfo(c);const g=n.makeTensorInfo(p,c.dtype,m);if(o){const e=reshape$5({inputs:{x:g},backend:n,attrs:{shape:expandShapeToKeepDim$1(p,i)}});return n.disposeIntermediateTensorInfo(g),e}return g}const allConfig$3={kernelName:All$1,backendName:"cpu",kernelFunc:all$4};function any$4(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{axis:s,keepDims:o}=r;assertNotComplex$3(a,"any");const i=parseAxisParam$1(s,a.shape);let l=i;const u=getAxesPermutation$1(l,a.shape.length);let c=a;null!=u&&(c=transpose$4({inputs:{x:a},backend:n,attrs:{perm:u}}),l=getInnerMostAxes$1(l.length,a.shape.length)),assertAxesAreInnerMostDims$1("any",l,c.shape.length);const[p,d]=computeOutAndReduceShapes$1(c.shape,l),h=sizeFromShape$1(d),m=makeZerosTypedArray$1(sizeFromShape$1(p),c.dtype),f=n.data.get(c.dataId).values;for(let e=0;e<m.length;++e){const t=e*h;let n=f[t];for(let e=0;e<h;++e){const r=f[t+e];n=n||r}m[e]=n}null!=u&&n.disposeIntermediateTensorInfo(c);const g=n.makeTensorInfo(p,c.dtype,m);if(o){const e=reshape$5({inputs:{x:g},backend:n,attrs:{shape:expandShapeToKeepDim$1(p,i)}});return n.disposeIntermediateTensorInfo(g),e}return g}const anyConfig$3={kernelName:Any$1,backendName:"cpu",kernelFunc:any$4};function argMax$4(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{axis:s}=r;assertNotComplex$3(a,"argMax");let o=parseAxisParam$1(s,a.shape);const i=getAxesPermutation$1(o,a.shape.length);let l=a;const u=[];null!=i&&(l=transpose$4({inputs:{x:a},backend:n,attrs:{perm:i}}),u.push(l),o=getInnerMostAxes$1(o.length,l.shape.length)),o=[o[0]],assertAxesAreInnerMostDims$1("argMax",o,l.shape.length);const[c,p]=computeOutAndReduceShapes$1(l.shape,o),d=makeZerosTypedArray$1(sizeFromShape$1(c),"int32"),h=sizeFromShape$1(p),m=n.data.get(l.dataId).values;for(let e=0;e<d.length;++e){const t=e*h;let n=m[t],r=0;for(let e=0;e<h;++e){const a=m[t+e];a>n&&(n=a,r=e)}d[e]=r}return u.forEach(e=>n.disposeIntermediateTensorInfo(e)),n.makeTensorInfo(c,"int32",d)}const argMaxConfig$3={kernelName:ArgMax$1,backendName:"cpu",kernelFunc:argMax$4};function argMin$4(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{axis:s}=r;assertNotComplex$3(a,"argMin");let o=parseAxisParam$1(s,a.shape);const i=getAxesPermutation$1(o,a.shape.length);let l=a;const u=[];null!=i&&(l=transpose$4({inputs:{x:a},backend:n,attrs:{perm:i}}),u.push(l),o=getInnerMostAxes$1(o.length,l.shape.length)),o=[o[0]],assertAxesAreInnerMostDims$1("argMin",o,l.shape.length);const[c,p]=computeOutAndReduceShapes$1(l.shape,o),d=makeZerosTypedArray$1(sizeFromShape$1(c),"int32"),h=sizeFromShape$1(p),m=n.data.get(l.dataId).values;for(let e=0;e<d.length;++e){const t=e*h;let n=m[t],r=0;for(let e=0;e<h;++e){const a=m[t+e];a<n&&(n=a,r=e)}d[e]=r}return u.forEach(e=>n.disposeIntermediateTensorInfo(e)),n.makeTensorInfo(c,"int32",d)}const argMinConfig$3={kernelName:ArgMin$1,backendName:"cpu",kernelFunc:argMin$4},asin$4=unaryKernelFunc$3(Asin$1,e=>Math.asin(e)),asinConfig$3={kernelName:Asin$1,backendName:"cpu",kernelFunc:asin$4},asinh$4=unaryKernelFunc$3(Asinh$1,e=>Math.asinh(e)),asinhConfig$3={kernelName:Asinh$1,backendName:"cpu",kernelFunc:asinh$4},atan$4=unaryKernelFunc$3(Atan$1,e=>Math.atan(e)),atanConfig$3={kernelName:Atan$1,backendName:"cpu",kernelFunc:atan$4},atan2Impl$1=createSimpleBinaryKernelImpl$1((e,t)=>Math.atan2(e,t)),atan2$4=binaryKernelFunc$3(Atan2$1,atan2Impl$1),atan2Config$3={kernelName:Atan2$1,backendName:"cpu",kernelFunc:atan2$4},atanh$4=unaryKernelFunc$3(Atanh$1,e=>Math.atanh(e)),atanhConfig$3={kernelName:Atanh$1,backendName:"cpu",kernelFunc:atanh$4};function pool$2(e,t,n,r,a,s){const o=a.strideHeight,i=a.strideWidth,l=a.dilationHeight,u=a.dilationWidth,c=a.effectiveFilterHeight,p=a.effectiveFilterWidth,d=a.padInfo.top,h=a.padInfo.left,m="max"===s?Number.NEGATIVE_INFINITY:Number.POSITIVE_INFINITY,f=buffer$1(a.outShape,n),g=f.values,$=a.outShape[1]*a.outShape[2]*a.outShape[3],y=a.outShape[2]*a.outShape[3],b=a.outShape[3];for(let t=0;t<a.batchSize;++t){const n=t*$,f=t*r[0];for(let t=0;t<a.inChannels;++t)for(let $=0;$<a.outHeight;++$){const x=$*o-d,v=Math.max(0,x),I=Math.min(a.inHeight,c+x),C=n+$*y;for(let n=0;n<a.outWidth;++n){const o=n*i-h,c=Math.max(0,o),d=Math.min(a.inWidth,p+o);let $=m,y=0,x=0;for(let n=v;n<I;n+=l){const a=f+n*r[1];for(let n=c;n<d;n+=u){const o=e[a+n*r[2]+t];"max"===s&&o>$?$=o:"avg"===s&&(y+=o,x++)}if(isNaN($))break}g[C+n*b+t]="avg"===s?y/x:$}}}return f}function maxPoolPositions$1(e,t,n,r,a=!1,s=!1){const o=buffer$1(r.outShape,"int32"),i=r.strideHeight,l=r.strideWidth,u=r.dilationHeight,c=r.dilationWidth,p=r.effectiveFilterHeight,d=r.effectiveFilterWidth,h=r.padInfo.top,m=r.padInfo.left,f=buffer$1(t,n,e);for(let e=0;e<r.batchSize;++e)for(let t=0;t<r.inChannels;++t)for(let n=0;n<r.outHeight;++n){const g=n*i-h;let $=g;for(;$<0;)$+=u;const y=Math.min(r.inHeight,p+g);for(let i=0;i<r.outWidth;++i){const p=i*l-m;let h=p;for(;h<0;)h+=c;const b=Math.min(r.inWidth,d+p);let x=Number.NEGATIVE_INFINITY,v=-1;for(let n=$;n<y;n+=u){const o=n-g;for(let i=h;i<b;i+=c){const l=i-p,u=f.get(e,n,i,t);u>x&&(x=u,v=a?s?((e*r.inHeight+n)*r.inWidth+i)*r.inChannels+t:(n*r.inWidth+i)*r.inChannels+t:o*d+l)}}o.set(v,e,n,i,t)}}return o}function pool3d$2(e,t,n,r,a,s){const o=a.strideDepth,i=a.strideHeight,l=a.strideWidth,u=a.dilationDepth,c=a.dilationHeight,p=a.dilationWidth,d=a.effectiveFilterDepth,h=a.effectiveFilterHeight,m=a.effectiveFilterWidth,f=a.padInfo.front,g=a.padInfo.top,$=a.padInfo.left,y="max"===s?Number.NEGATIVE_INFINITY:Number.POSITIVE_INFINITY,b=buffer$1(a.outShape,n),x=b.values,v=a.outShape[1]*a.outShape[2]*a.outShape[3]*a.outShape[4],I=a.outShape[2]*a.outShape[3]*a.outShape[4],C=a.outShape[3]*a.outShape[4],S=a.outShape[4];for(let t=0;t<a.batchSize;++t){const n=t*v,b=t*r[0];for(let t=0;t<a.inChannels;++t)for(let v=0;v<a.outDepth;++v){const k=v*o-f;let T=k;for(;T<0;)T+=u;const N=Math.min(a.inDepth,d+k),w=n+v*I;for(let n=0;n<a.outHeight;++n){const o=n*i-g;let d=o;for(;d<0;)d+=c;const f=Math.min(a.inHeight,h+o),v=w+n*C;for(let n=0;n<a.outWidth;++n){const o=n*l-$;let i=o;for(;i<0;)i+=p;const h=Math.min(a.inWidth,m+o),g=v+n*S;let I=y,C=0,k=0;for(let n=T;n<N;n+=u){const a=b+n*r[1];for(let n=d;n<f;n+=c){const o=a+n*r[2];for(let n=i;n<h;n+=p){const a=e[o+n*r[3]+t];if("max"===s&&a>I?I=a:"avg"===s&&(C+=a,k++),isNaN(I))break}if(isNaN(I))break}if(isNaN(I))break}x[g+t]="avg"===s?C/k:I}}}}return b}function maxPool3dPositions$1(e,t){const n=buffer$1(t.outShape,"int32"),r=t.strideDepth,a=t.strideHeight,s=t.strideWidth,o=t.dilationDepth,i=t.dilationHeight,l=t.dilationWidth,u=t.effectiveFilterDepth,c=t.effectiveFilterHeight,p=t.effectiveFilterWidth,d=t.padInfo.front,h=t.padInfo.top,m=t.padInfo.left;for(let f=0;f<t.batchSize;++f)for(let g=0;g<t.inChannels;++g)for(let $=0;$<t.outDepth;++$){const y=$*r-d;let b=y;for(;b<0;)b+=o;const x=Math.min(t.inDepth,u+y);for(let r=0;r<t.outHeight;++r){const u=r*a-h;let d=u;for(;d<0;)d+=i;const v=Math.min(t.inHeight,c+u);for(let a=0;a<t.outWidth;++a){const h=a*s-m;let I=h;for(;I<0;)I+=l;const C=Math.min(t.inWidth,p+h);let S=Number.NEGATIVE_INFINITY,k=-1;for(let t=b;t<x;t+=o){const n=t-y;for(let r=d;r<v;r+=i){const a=r-u;for(let s=I;s<C;s+=l){const o=s-h,i=e.get(f,t,r,s,g);i>=S&&(S=i,k=n*c*p+a*c+o)}}}n.set(k,f,$,r,a,g)}}}return n}function avgPool$4(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t;assertNotComplex$3(a,"avgPool");const{filterSize:s,strides:o,pad:i,dimRoundingMode:l}=r;assert$6(eitherStridesOrDilationsAreOne$1(o,1),()=>`Error in avgPool: Either strides or dilations must be 1. Got strides ${o} and dilations '1'`);const u=computePool2DInfo$1(a.shape,s,o,1,i,l);let c;if(1===u.filterWidth&&1===u.filterHeight&&arraysEqual$1(u.inShape,u.outShape))c=identity$4({inputs:{x:a},backend:n});else{const e=n.data.get(a.dataId).values,t=computeStrides$1(a.shape),r=pool$2(e,a.shape,a.dtype,t,u,"avg");c=n.makeTensorInfo(u.outShape,a.dtype,r.values)}return c}const avgPoolConfig$3={kernelName:AvgPool$1,backendName:"cpu",kernelFunc:avgPool$4};function avgPool3D$3(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{filterSize:s,strides:o,pad:i,dimRoundingMode:l,dataFormat:u}=r;assertNotComplex$3(a,"avgPool3d");const c=computePool3DInfo$1(a.shape,s,o,1,i,l,u),p=pool3d$2(n.data.get(a.dataId).values,a.shape,a.dtype,computeStrides$1(a.shape),c,"avg");return n.makeTensorInfo(p.shape,"float32",p.values)}const avgPool3DConfig$3={kernelName:AvgPool3D$1,backendName:"cpu",kernelFunc:avgPool3D$3};function avgPool3DGrad$3(e){const{inputs:t,backend:n,attrs:r}=e,{dy:a,input:s}=t,{filterSize:o,strides:i,pad:l,dimRoundingMode:u}=r;assertNotComplex$3([a,s],"avgPool3DGrad");const c=computePool3DInfo$1(s.shape,o,i,1,l,u),p=c.strideDepth,d=c.strideHeight,h=c.strideWidth,m=c.filterDepth,f=c.filterHeight,g=c.filterWidth,$=c.dilationDepth,y=c.dilationHeight,b=c.dilationWidth,x=c.effectiveFilterDepth,v=c.effectiveFilterHeight,I=c.effectiveFilterWidth,C=x-1-c.padInfo.front,S=I-1-c.padInfo.left,k=v-1-c.padInfo.top,T=buffer$1(s.shape,"float32"),N=1/(m*f*g),w=n.bufferSync(a);for(let e=0;e<c.batchSize;++e)for(let t=0;t<c.inChannels;++t)for(let n=0;n<c.inDepth;++n)for(let r=0;r<c.inHeight;++r)for(let a=0;a<c.inWidth;++a){const s=n-C,o=r-k,i=a-S;let l=0;for(let n=0;n<x;n+=$){const r=(s+n)/p;if(!(r<0||r>=c.outDepth||Math.floor(r)!==r))for(let n=0;n<v;n+=y){const a=(o+n)/d;if(!(a<0||a>=c.outHeight||Math.floor(a)!==a))for(let n=0;n<I;n+=b){const s=(i+n)/h;s<0||s>=c.outWidth||Math.floor(s)!==s||(l+=w.get(e,r,a,s,t))}}}T.set(l*N,e,n,r,a,t)}return n.makeTensorInfo(T.shape,T.dtype,T.values)}const avgPool3DGradConfig$2={kernelName:AvgPool3DGrad$1,backendName:"cpu",kernelFunc:avgPool3DGrad$3};function avgPoolGrad$4(e){const{inputs:t,backend:n,attrs:r}=e,{dy:a,input:s}=t,o=s;assertNotComplex$3([a,s],"avgPoolGrad");const{filterSize:i,strides:l,pad:u}=r,c=computePool2DInfo$1(o.shape,i,l,1,u),p=c.strideHeight,d=c.strideWidth,h=c.filterHeight,m=c.filterWidth,f=c.dilationHeight,g=c.dilationWidth,$=c.effectiveFilterHeight,y=c.effectiveFilterWidth,b=y-1-c.padInfo.left,x=$-1-c.padInfo.top,v=buffer$1(o.shape,"float32"),I=1/(h*m),C=n.data.get(a.dataId).values,S=buffer$1(a.shape,"float32",C);for(let e=0;e<c.batchSize;++e)for(let t=0;t<c.inChannels;++t)for(let n=0;n<c.inHeight;++n)for(let r=0;r<c.inWidth;++r){const a=n-x,s=r-b;let o=0;for(let n=0;n<$;n+=f){const r=(a+n)/p;if(!(r<0||r>=c.outHeight||Math.floor(r)!==r))for(let n=0;n<y;n+=g){const a=(s+n)/d;a<0||a>=c.outWidth||Math.floor(a)!==a||(o+=S.get(e,r,a,t))}}v.set(o*I,e,n,r,t)}return n.makeTensorInfo(v.shape,v.dtype,v.values)}const avgPoolGradConfig$4={kernelName:AvgPoolGrad$1,backendName:"cpu",kernelFunc:avgPoolGrad$4};function batchNorm$4(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,scale:s,offset:o,mean:i,variance:l}=t;assert$6(i.shape.length===l.shape.length,()=>"Batch normalization gradient requires mean and variance to have equal ranks."),assert$6(null==o||i.shape.length===o.shape.length,()=>"Batch normalization gradient requires mean and offset to have equal ranks."),assert$6(null==s||i.shape.length===s.shape.length,()=>"Batch normalization gradient requires mean and scale to have equal ranks."),assertNotComplex$3([a,i,l,s,o],"batchNorm");let{varianceEpsilon:u}=r;null==u&&(u=.001);const c=n.data.get(a.dataId).values,p=n.data.get(i.dataId).values,d=n.data.get(l.dataId).values,h=s?n.data.get(s.dataId).values:new Float32Array([1]),m=o?n.data.get(o.dataId).values:new Float32Array([0]),f=new Float32Array(c.length),g=m.length,$=h.length,y=d.length,b=p.length;let x=0,v=0,I=0,C=0;for(let e=0;e<c.length;++e)f[e]=m[x++]+(c[e]-p[v++])*h[I++]/Math.sqrt(d[C++]+u),x>=g&&(x=0),v>=b&&(v=0),I>=$&&(I=0),C>=y&&(C=0);return n.makeTensorInfo(a.shape,a.dtype,f)}const batchNormConfig$3={kernelName:FusedBatchNorm$1,backendName:"cpu",kernelFunc:batchNorm$4};function batchToSpaceND$4(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{blockShape:s,crops:o}=r;assertNotComplex$3([a],"batchToSpaceND");const i=s.reduce((e,t)=>e*t),l=getReshaped$1(a.shape,s,i),u=getPermuted$1(l.length,s.length),c=getReshapedPermuted$1(a.shape,s,i),p=getSliceBeginCoords$1(o,s.length),d=getSliceSize$1(c,o,s.length),h=reshape$5({inputs:{x:a},backend:n,attrs:{shape:l}}),m=transpose$4({inputs:{x:h},backend:n,attrs:{perm:u}}),f=reshape$5({inputs:{x:m},backend:n,attrs:{shape:c}}),g=slice$4({inputs:{x:f},backend:n,attrs:{begin:p,size:d}});return n.disposeIntermediateTensorInfo(h),n.disposeIntermediateTensorInfo(m),n.disposeIntermediateTensorInfo(f),g}const batchToSpaceNDConfig$3={kernelName:BatchToSpaceND$1,backendName:"cpu",kernelFunc:batchToSpaceND$4};function bincount$4(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,weights:s}=t,{size:o}=r,i=bincountImpl$1(n.data.get(a.dataId).values,n.data.get(s.dataId).values,s.dtype,s.shape,o);return n.makeTensorInfo([o],s.dtype,i)}const bincountConfig$3={kernelName:Bincount$1,backendName:"cpu",kernelFunc:bincount$4},clip$1=unaryKernelFunc$3(ClipByValue$1,(e,t)=>e>t.clipValueMax?t.clipValueMax:e<t.clipValueMin?t.clipValueMin:e),clipConfig$1={kernelName:ClipByValue$1,backendName:"cpu",kernelFunc:clip$1},complexAbs$3=e=>{const{x:t}=e.inputs,n=e.backend,r=new Float32Array(sizeFromShape$1(t.shape)),a=n.data.get(t.dataId),s=a.complexTensorInfos.imag,o=n.data.get(a.complexTensorInfos.real.dataId).values,i=n.data.get(s.dataId).values;for(let e=0;e<o.length;e++)r[e]=Math.hypot(o[e],i[e]);return n.makeOutput(r,t.shape,"float32")},complexAbsConfig$3={kernelName:ComplexAbs$1,backendName:"cpu",kernelFunc:complexAbs$3};function imag$4(e){const{inputs:t,backend:n}=e,{input:r}=t,a=n.data.get(r.dataId).complexTensorInfos.imag,s=n.data.get(a.dataId).values;return n.makeTensorInfo(a.shape,a.dtype,s)}const imagConfig$3={kernelName:Imag$1,backendName:"cpu",kernelFunc:imag$4};function concat$4(e){const{inputs:t,backend:n,attrs:r}=e,{axis:a}=r,s=parseAxisParam$1(a,t[0].shape)[0];let o=computeOutShape$4(t.map(e=>e.shape),s);if(0===sizeFromShape$1(o))return n.makeTensorInfo(o,t[0].dtype,[]);const i=t.filter(e=>sizeFromShape$1(e.shape)>0);if(1===i.length)return identity$4({inputs:{x:i[0]},backend:n});if(assertParamsConsistent$1(i.map(e=>e.shape),s),"complex64"===i[0].dtype){const e=i.map(e=>real$4({inputs:{input:e},backend:n})),t=i.map(e=>imag$4({inputs:{input:e},backend:n})),r=concat$4({inputs:e,backend:n,attrs:{axis:s}}),a=concat$4({inputs:t,backend:n,attrs:{axis:s}}),o=complex$4({inputs:{real:r,imag:a},backend:n});return e.forEach(e=>n.disposeIntermediateTensorInfo(e)),t.forEach(e=>n.disposeIntermediateTensorInfo(e)),n.disposeIntermediateTensorInfo(r),n.disposeIntermediateTensorInfo(a),o}const l=i.map(e=>{const t=sizeFromShape$1(e.shape.slice(s));return reshape$5({inputs:{x:e},backend:n,attrs:{shape:[-1,t]}})}),u=l.map(e=>({vals:n.data.get(e.dataId).values,shape:e.shape}));o=computeOutShape$4(l.map(e=>e.shape),1);const c=concatImpl$3(u,o,t[0].dtype,1===l[0].shape[0]),p=computeOutShape$4(i.map(e=>e.shape),s),d=n.makeTensorInfo(p,t[0].dtype,c);return l.forEach(e=>n.disposeIntermediateTensorInfo(e)),d}const concatConfig$3={kernelName:Concat$1,backendName:"cpu",kernelFunc:concat$4};function conv2D$1(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,filter:s}=t,{strides:o,pad:i,dataFormat:l,dilations:u,dimRoundingMode:c}=r;assertNotComplex$3([a,s],"conv2d");const p=convertConv2DDataFormat$1(l),d=computeConv2DInfo$1(a.shape,s.shape,o,u,i,c,!1,p),h=d.filterHeight,m=d.filterWidth,f=d.dilationHeight,g=d.dilationWidth,$=d.padInfo.left,y=d.padInfo.top,b="channelsLast"===d.dataFormat,x=new TensorBuffer$1(d.outShape,a.dtype),v=computeStrides$1(a.shape),I=computeStrides$1(s.shape),C=v[0],S=b?v[1]:v[2],k=b?v[2]:1,T=b?1:v[1],N=x.strides[0],w=b?x.strides[1]:x.strides[2],E=b?x.strides[2]:1,A=b?1:x.strides[1],D=n.data.get(a.dataId).values,R=n.data.get(s.dataId).values,_=x.values;for(let e=0;e<d.batchSize;++e){const t=e*C,n=e*N;for(let e=0;e<d.outHeight;++e){const r=n+e*w,a=e*d.strideHeight-y;for(let e=0;e<h;++e){const n=a+e*f;if(n<0||n>=d.inHeight)continue;const s=e*I[0],o=t+n*S;for(let e=0;e<d.outWidth;++e){const t=r+e*E,n=e*d.strideWidth-$;for(let e=0;e<m;++e){const r=n+e*g;if(r<0||r>=d.inWidth)continue;const a=o+r*k;let i=s+e*I[1];for(let e=0;e<d.inChannels;++e){const n=D[a+e*T];for(let e=0;e<d.outChannels;++e)_[t+e*A]+=n*R[i+e];i+=d.outChannels}}}}}}return n.makeTensorInfo(x.shape,x.dtype,_)}const conv2DConfig$3={kernelName:Conv2D$3,backendName:"cpu",kernelFunc:conv2D$1};function conv2DBackpropFilter$4(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,dy:s}=t,{strides:o,pad:i,dataFormat:l,dimRoundingMode:u,filterShape:c}=r;assertNotComplex$3([a,s],"conv2dBackpropFilter");const p=convertConv2DDataFormat$1(l),d=computeConv2DInfo$1(a.shape,c,o,1,i,u,!1,p),{strideHeight:h,strideWidth:m,filterHeight:f,filterWidth:g}=d,$="channelsLast"===d.dataFormat,y=new TensorBuffer$1(d.filterShape,"float32"),b=d.padInfo.left,x=d.padInfo.top,v=n.data.get(a.dataId).values,I=n.data.get(s.dataId).values,C=new TensorBuffer$1(a.shape,a.dtype,v),S=new TensorBuffer$1(s.shape,s.dtype,I);for(let e=0;e<f;++e){const t=Math.max(0,Math.ceil((x-e)/h)),n=Math.min(d.outHeight,(d.inHeight+x-e)/h);for(let r=0;r<g;++r){const a=Math.max(0,Math.ceil((b-r)/m)),s=Math.min(d.outWidth,(d.inWidth+b-r)/m);for(let o=0;o<d.inChannels;++o)for(let i=0;i<d.outChannels;++i){let l=0;for(let u=0;u<d.batchSize;++u)for(let c=t;c<n;++c){const t=e+c*h-x;for(let e=a;e<s;++e){const n=r+e*m-b;l+=$?C.get(u,t,n,o)*S.get(u,c,e,i):C.get(u,o,t,n)*S.get(u,i,c,e)}}y.set(l,e,r,o,i)}}}return n.makeTensorInfo(y.shape,y.dtype,y.values)}const conv2DBackpropFilterConfig$3={kernelName:Conv2DBackpropFilter$1,backendName:"cpu",kernelFunc:conv2DBackpropFilter$4};function conv2DBackpropInput$4(e){const{inputs:t,backend:n,attrs:r}=e,{dy:a,filter:s}=t,{inputShape:o,strides:i,pad:l,dataFormat:u,dimRoundingMode:c}=r;assertNotComplex$3([a,s],"conv2dBackpropInput");const p=computeStrides$1(s.shape),d=computeStrides$1(a.shape);let h=convertConv2DDataFormat$1(u);const m=computeConv2DInfo$1(o,s.shape,i,1,l,c,!1,h),f=new TensorBuffer$1(m.inShape,"float32"),g=f.values,$=n.data.get(a.dataId).values,y=n.data.get(s.dataId).values,[b,x,v]=p,{batchSize:I,filterHeight:C,filterWidth:S,inChannels:k,inHeight:T,inWidth:N,outChannels:w,outHeight:E,outWidth:A,strideHeight:D,strideWidth:R}=m;h=m.dataFormat;const _=C-1-m.padInfo.top,F=S-1-m.padInfo.left,P="channelsLast"===h,O=f.strides[0],M=P?f.strides[1]:f.strides[2],L=P?f.strides[2]:1,z=P?1:f.strides[1],B=d[0],V=P?d[1]:d[2],G=P?d[2]:1,U=P?1:d[1];for(let e=0;e<I;++e)for(let t=0;t<k;++t)for(let n=0;n<T;++n){const r=n-_,a=Math.max(0,Math.ceil(r/D)),s=Math.min(E,(C+r)/D);for(let o=0;o<N;++o){const i=o-F,l=Math.max(0,Math.ceil(i/R)),u=Math.min(A,(S+i)/R);let c=0;for(let n=a;n<s;++n){const a=n*D-r;for(let r=l;r<u;++r){const s=B*e+V*n+G*r,o=b*(C-1-a)+x*(S-1-(r*R-i))+v*t;for(let e=0;e<w;++e)c+=$[s+U*e]*y[o+e]}}g[O*e+M*n+L*o+z*t]=c}}return n.makeTensorInfo(f.shape,f.dtype,f.values)}const conv2DBackpropInputConfig$3={kernelName:Conv2DBackpropInput$1,backendName:"cpu",kernelFunc:conv2DBackpropInput$4};function conv3D$3(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,filter:s}=t,{strides:o,pad:i,dilations:l}=r;assertNotComplex$3([a,s],"conv3d");const u=computeConv3DInfo$1(a.shape,s.shape,o,l,i),{filterDepth:c,filterHeight:p,filterWidth:d,dilationDepth:h,dilationHeight:m,dilationWidth:f,padInfo:g}=u,$=g.front,y=g.left,b=g.top,x=new TensorBuffer$1(u.outShape,a.dtype),v=n.data.get(a.dataId).values,I=n.data.get(s.dataId).values,C=x.values,S=computeStrides$1(a.shape),k=computeStrides$1(s.shape);for(let e=0;e<u.batchSize;++e){const t=e*S[0],n=e*x.strides[0];for(let e=0;e<u.outDepth;++e){const r=n+e*x.strides[1],a=e*u.strideDepth-$;for(let e=0;e<c;++e){const n=a+e*h;if(n<0||n>=u.inDepth)continue;const s=e*k[0],o=t+n*S[1];for(let e=0;e<u.outHeight;++e){const t=r+e*x.strides[2],n=e*u.strideHeight-b;for(let e=0;e<p;++e){const r=n+e*m;if(r<0||r>=u.inHeight)continue;const a=s+e*k[1],i=o+r*S[2];for(let e=0;e<u.outWidth;++e){const n=t+e*u.outChannels,r=e*u.strideWidth-y;for(let e=0;e<d;++e){const t=r+e*f;if(t<0||t>=u.inWidth)continue;const s=i+t*u.inChannels;let o=a+e*k[2];for(let e=0;e<u.inChannels;++e){const t=v[s+e];for(let e=0;e<u.outChannels;++e)C[n+e]+=t*I[o+e];o+=u.outChannels}}}}}}}}return n.makeTensorInfo(x.shape,x.dtype,x.values)}const conv3DConfig$3={kernelName:Conv3D$3,backendName:"cpu",kernelFunc:conv3D$3};function conv3DBackpropFilterV2$3(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,dy:s}=t,{strides:o,pad:i,filterShape:l}=r;assertNotComplex$3([a,s],"conv3dBackpropFilterV2");const u=computeStrides$1(a.shape),c=computeStrides$1(s.shape),p=computeConv3DInfo$1(a.shape,l,o,1,i),d=p.strideDepth,h=p.strideHeight,m=p.strideWidth,f=p.filterDepth,g=p.filterHeight,$=p.filterWidth,y=new TensorBuffer$1(p.filterShape,"float32"),b=y.values,[x,v,I,C]=y.strides,S=n.data.get(s.dataId).values,[k,T,N,w]=c,E=n.data.get(a.dataId).values,[A,D,R,_]=u,F=p.padInfo.front,P=p.padInfo.left,O=p.padInfo.top;for(let e=0;e<f;++e){const t=Math.max(0,Math.ceil((F-e)/d)),n=Math.min(p.outDepth,(p.inDepth+F-e)/d),r=e*x;for(let a=0;a<g;++a){const s=Math.max(0,Math.ceil((O-a)/h)),o=Math.min(p.outHeight,(p.inHeight+O-a)/h),i=a*v+r;for(let r=0;r<$;++r){const l=Math.max(0,Math.ceil((P-r)/m)),u=Math.min(p.outWidth,(p.inWidth+P-r)/m),c=r*I+i;for(let i=0;i<p.inChannels;++i){const f=i*C+c;for(let c=0;c<p.outChannels;++c){let g=0;for(let f=0;f<p.batchSize;++f){const p=f*A,$=f*k;for(let f=t;f<n;++f){const t=(e+f*d-F)*D+p,n=f*T+$;for(let e=s;e<o;++e){const s=(a+e*h-O)*R+t,o=e*N+n;for(let e=l;e<u;++e)g+=E[(r+e*m-P)*_+s+i]*S[e*w+o+c]}}}b[f+c]=g}}}}}return n.makeTensorInfo(y.shape,y.dtype,y.values)}const conv3DBackpropFilterV2Config$3={kernelName:Conv3DBackpropFilterV2$1,backendName:"cpu",kernelFunc:conv3DBackpropFilterV2$3};function conv3DBackpropInputV2$1(e){const{inputs:t,backend:n,attrs:r}=e,{dy:a,filter:s}=t,{pad:o,strides:i,inputShape:l}=r;assertNotComplex$3([a],"conv3dBackpropInputV2");const u=computeStrides$1(a.shape),c=computeStrides$1(s.shape),p=computeConv3DInfo$1(l,s.shape,i,1,o),d=new TensorBuffer$1(p.inShape,"float32"),h=d.values,[m,f,g,$]=d.strides,y=n.data.get(a.dataId).values,[b,x,v,I]=u,C=n.data.get(s.dataId).values,[S,k,T,N]=c,{batchSize:w,filterDepth:E,filterHeight:A,filterWidth:D,inChannels:R,inDepth:_,inHeight:F,inWidth:P,outChannels:O,outDepth:M,outHeight:L,outWidth:z,strideDepth:B,strideHeight:V,strideWidth:G}=p,U=E-1-p.padInfo.front,W=A-1-p.padInfo.top,q=D-1-p.padInfo.left;for(let e=0;e<w;++e)for(let t=0;t<R;++t)for(let n=0;n<_;++n){const r=n-U,a=Math.max(0,Math.ceil(r/B)),s=Math.min(M,(E+r)/B);for(let o=0;o<F;++o){const i=o-W,l=Math.max(0,Math.ceil(i/V)),u=Math.min(L,(A+i)/V);for(let c=0;c<P;++c){const p=c-q,d=Math.max(0,Math.ceil(p/G)),w=Math.min(z,(D+p)/G);let R=0;for(let n=a;n<s;++n){const a=n*B-r;for(let r=l;r<u;++r){const s=r*V-i;for(let o=d;o<w;++o){const i=b*e+x*n+v*r+I*o,l=S*(E-1-a)+k*(A-1-s)+T*(D-1-(o*G-p))+N*t;for(let e=0;e<O;++e)R+=y[i+e]*C[l+e]}}}h[m*e+f*n+g*o+$*c+t]=R}}}return n.makeTensorInfo(d.shape,d.dtype,d.values)}const conv3DBackpropInputV2Config$1={kernelName:Conv3DBackpropInputV2$1,backendName:"cpu",kernelFunc:conv3DBackpropInputV2$1},cos$4=unaryKernelFunc$3(Cos$1,e=>Math.cos(e)),cosConfig$3={kernelName:Cos$1,backendName:"cpu",kernelFunc:cos$4},cosh$4=unaryKernelFunc$3(Cosh$1,e=>Math.cosh(e)),coshConfig$3={kernelName:Cosh$1,backendName:"cpu",kernelFunc:cosh$4};function cropAndResize$4(e){const{inputs:t,backend:n,attrs:r}=e,{image:a,boxes:s,boxInd:o}=t,{cropSize:i,method:l,extrapolationValue:u}=r,[c,p,d,h]=a.shape,m=s.shape[0],[f,g]=i,$=buffer$1([m,f,g,h],"float32"),y=n.data.get(s.dataId).values,b=n.data.get(o.dataId).values,x=n.data.get(a.dataId).values,v=computeStrides$1(a.shape),I=computeStrides$1($.shape);for(let e=0;e<m;e++){const t=4*e,n=y[t],r=y[t+1],a=y[t+2],s=y[t+3],o=b[e];if(o>=c)continue;const i=f>1?(a-n)*(p-1)/(f-1):0,m=g>1?(s-r)*(d-1)/(g-1):0;for(let t=0;t<f;t++){const c=f>1?n*(p-1)+t*i:.5*(n+a)*(p-1);if(c<0||c>p-1)for(let n=0;n<g;n++)for(let r=0;r<h;r++)$.values[r+n*I[2]+t*I[1]+e*I[0]]=u;else if("bilinear"===l){const n=Math.floor(c),a=Math.ceil(c),i=c-n;for(let l=0;l<g;l++){const c=g>1?r*(d-1)+l*m:.5*(r+s)*(d-1);if(c<0||c>d-1){for(let n=0;n<h;n++)$.values[n+l*I[2]+t*I[1]+e*I[0]]=u;continue}const p=Math.floor(c),f=Math.ceil(c),y=c-p;for(let r=0;r<h;r++){let s=r+p*v[2]+n*v[1]+o*v[0];const u=x[s];s=r+f*v[2]+n*v[1]+o*v[0];const c=x[s];s=r+p*v[2]+a*v[1]+o*v[0];const d=x[s];s=r+f*v[2]+a*v[1]+o*v[0];const h=x[s],m=u+(c-u)*y;s=r+l*I[2]+t*I[1]+e*I[0],$.values[s]=m+(d+(h-d)*y-m)*i}}}else for(let n=0;n<g;++n){const a=g>1?r*(d-1)+n*m:.5*(r+s)*(d-1);if(a<0||a>d-1){for(let r=0;r<h;r++)$.values[r+n*I[2]+t*I[1]+e*I[0]]=u;continue}const i=Math.round(a),l=Math.round(c);for(let r=0;r<h;r++)$.values[r+n*I[2]+t*I[1]+e*I[0]]=x[r+i*v[2]+l*v[1]+o*v[0]]}}}return n.makeTensorInfo($.shape,$.dtype,$.values)}const cropAndResizeConfig$3={kernelName:CropAndResize$1,backendName:"cpu",kernelFunc:cropAndResize$4};function cumsum$4(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{axis:s,exclusive:o,reverse:i}=r;assertNotComplex$3(a,"cumsum");const l=getAxesPermutation$1([s],a.shape.length);let u=a;null!=l&&(u=transpose$4({inputs:{x:a},backend:n,attrs:{perm:l}}));const c=getInnerMostAxes$1(1,a.shape.length)[0];if(c!==u.shape.length-1)throw new Error(`backend.cumsum in CPU expects an inner-most axis=${u.shape.length-1} but got axis=${c}`);const p=upcastType$1(u.dtype,"int32"),d=makeZerosTypedArray$1(sizeFromShape$1(u.shape),p),h=n.data.get(u.dataId).values,m=u.shape[u.shape.length-1],f=i?(e,t)=>e+m-t-1:(e,t)=>e+t;for(let e=0;e<h.length;e+=m)for(let t=0;t<m;t++){const n=f(e,t);if(0===t)d[n]=o?0:h[n];else{const r=f(e,t-1);d[n]=o?h[r]+d[r]:h[n]+d[r]}}const g=n.makeTensorInfo(u.shape,p,d);if(null!=l){const e=transpose$4({inputs:{x:g},backend:n,attrs:{perm:getUndoAxesPermutation$1(l)}});return n.disposeIntermediateTensorInfo(g),n.disposeIntermediateTensorInfo(u),e}return g}const cumsumConfig$3={kernelName:Cumsum$1,backendName:"cpu",kernelFunc:cumsum$4};function denseBincount$4(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,weights:s}=t,{size:o,binaryOutput:i}=r;if(1===a.shape.length){const e=bincountImpl$1(n.data.get(a.dataId).values,n.data.get(s.dataId).values,s.dtype,s.shape,o);return n.makeTensorInfo([o],s.dtype,e)}if(2===a.shape.length){const e=bincountReduceImpl$1(n.bufferSync(a),n.bufferSync(s),o,i);return n.makeTensorInfo(e.shape,s.dtype,e.values)}throw new Error(`Error in denseBincount: input must be at most rank 2, but got rank${a.shape.length}.`)}const denseBincountConfig$3={kernelName:DenseBincount$1,backendName:"cpu",kernelFunc:denseBincount$4};function depthToSpace$4(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{blockSize:s,dataFormat:o}=r;assert$6("NHWC"===o,()=>`Only NHWC dataFormat supported on CPU for depthToSpace. Got ${o}`),assert$6(s>1,()=>`blockSize should be > 1 for depthToSpace, but was: ${s}`);const i=a.shape[0],l=a.shape[1],u=a.shape[2],c=a.shape[3],p=l*s,d=u*s,h=c/(s*s),m=n.data.get(a.dataId).values,f=new Float32Array(i*p*d*h);let g=0;for(let e=0;e<i;++e)for(let t=0;t<p;++t){const n=Math.floor(t/s),r=t%s;for(let t=0;t<d;++t){const a=Math.floor(t/s),o=(r*s+t%s)*h;for(let t=0;t<h;++t)f[g++]=m[t+o+c*(a+u*(n+l*e))]}}return n.makeTensorInfo([i,p,d,h],a.dtype,f)}const depthToSpaceConfig$3={kernelName:DepthToSpace$1,backendName:"cpu",kernelFunc:depthToSpace$4};function depthwiseConv2dNative$3(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,filter:s}=t,{strides:o,pad:i,dilations:l,dimRoundingMode:u}=r;assertNotComplex$3([a,s],"depthwiseConv2DNative");const c=computeStrides$1(a.shape),p=computeStrides$1(s.shape);let d=l;null==d&&(d=[1,1]),assert$6(eitherStridesOrDilationsAreOne$1(o,d),()=>`Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ${o} and dilations '${d}'`);const h=computeConv2DInfo$1(a.shape,s.shape,o,d,i,u,!0),{filterHeight:m,filterWidth:f,dilationHeight:g,dilationWidth:$,padInfo:y}=h,b=y.left,x=y.top,v=h.outChannels/h.inChannels,I=new TensorBuffer$1(h.outShape,a.dtype),C=n.data.get(a.dataId).values,S=n.data.get(s.dataId).values,k=I.values;for(let e=0;e<h.batchSize;++e){const t=e*c[0],n=e*I.strides[0];for(let e=0;e<h.outHeight;++e){const r=n+e*I.strides[1],a=e*h.strideHeight-x;for(let e=0;e<m;++e){const n=a+e*g;if(n<0||n>=h.inHeight)continue;const s=e*p[0],o=t+n*c[1];for(let e=0;e<h.outWidth;++e){const t=r+e*I.strides[2],n=e*h.strideWidth-b;for(let e=0;e<f;++e){const r=n+e*$;if(r<0||r>=h.inWidth)continue;const a=o+r*h.inChannels;let i=t,l=s+e*p[1];for(let e=0;e<h.inChannels;++e){const t=C[a+e];for(let e=0;e<v;++e)k[i+e]+=t*S[l+e];i+=v,l+=v}}}}}}return n.makeTensorInfo(I.shape,I.dtype,I.values)}const depthwiseConv2dNativeConfig$3={kernelName:DepthwiseConv2dNative$1,backendName:"cpu",kernelFunc:depthwiseConv2dNative$3};function depthwiseConv2dNativeBackpropFilter$4(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,dy:s}=t,{strides:o,dilations:i,pad:l,dimRoundingMode:u,filterShape:c}=r;assertNotComplex$3([a,s],"depthwiseConv2dNativeBackpropFilter");const p=computeConv2DInfo$1(a.shape,c,o,i,l,u,!0),{strideHeight:d,strideWidth:h,filterHeight:m,filterWidth:f}=p,g=new TensorBuffer$1(p.filterShape,"float32"),$=p.padInfo.left,y=p.padInfo.top,b=p.outChannels/p.inChannels,x=n.data.get(a.dataId).values,v=new TensorBuffer$1(a.shape,a.dtype,x),I=n.data.get(s.dataId).values,C=new TensorBuffer$1(s.shape,s.dtype,I);for(let e=0;e<m;++e){const t=Math.max(0,Math.ceil((y-e)/d)),n=Math.min(p.outHeight,(p.inHeight+y-e)/d);for(let r=0;r<f;++r){const a=Math.max(0,Math.ceil(($-r)/h)),s=Math.min(p.outWidth,(p.inWidth+$-r)/h);for(let o=0;o<p.outChannels;++o){const i=Math.trunc(o/b),l=o%b;let u=0;for(let l=0;l<p.batchSize;++l)for(let c=t;c<n;++c){const t=e+c*d-y;for(let e=a;e<s;++e)u+=v.get(l,t,r+e*h-$,i)*C.get(l,c,e,o)}g.set(u,e,r,i,l)}}}return n.makeTensorInfo(g.shape,g.dtype,g.values)}const depthwiseConv2dNativeBackpropFilterConfig$3={kernelName:DepthwiseConv2dNativeBackpropFilter$1,backendName:"cpu",kernelFunc:depthwiseConv2dNativeBackpropFilter$4};function depthwiseConv2dNativeBackpropInput$4(e){const{inputs:t,backend:n,attrs:r}=e,{dy:a,filter:s}=t,{strides:o,dilations:i,pad:l,dimRoundingMode:u,inputShape:c}=r;assertNotComplex$3([a,s],"depthwiseConv2DNativeBackpropInput");const p=computeStrides$1(a.shape),d=computeStrides$1(s.shape),h=computeConv2DInfo$1(c,s.shape,o,i,l,u,!0),m=new TensorBuffer$1(h.inShape,"float32"),f=m.values,[g,$,y]=m.strides,b=n.data.get(a.dataId).values,[x,v,I]=p,C=n.data.get(s.dataId).values,[S,k,T]=d,{batchSize:N,filterHeight:w,filterWidth:E,inChannels:A,inHeight:D,inWidth:R,outChannels:_,outHeight:F,outWidth:P,strideHeight:O,strideWidth:M}=h,L=w-1-h.padInfo.top,z=E-1-h.padInfo.left,B=_/A;for(let e=0;e<N;++e)for(let t=0;t<A;++t)for(let n=0;n<D;++n){const r=n-L,a=Math.max(0,Math.ceil(r/O)),s=Math.min(F,(w+r)/O);for(let o=0;o<R;++o){const i=o-z,l=Math.max(0,Math.ceil(i/M)),u=Math.min(P,(E+i)/M);let c=0;for(let n=a;n<s;++n){const a=n*O-r;for(let r=l;r<u;++r){const s=x*e+v*n+I*r,o=S*(w-1-a)+k*(E-1-(r*M-i))+T*t;for(let e=0;e<B;++e)c+=b[s+(t*B+e)]*C[o+e]}}f[g*e+$*n+y*o+t]=c}}return n.makeTensorInfo(m.shape,m.dtype,m.values)}const depthwiseConv2dNativeBackpropInputConfig$3={kernelName:DepthwiseConv2dNativeBackpropInput$1,backendName:"cpu",kernelFunc:depthwiseConv2dNativeBackpropInput$4};function diag$4(e){const{inputs:t,backend:n}=e,{x:r}=t,a=sizeFromShape$1(r.shape),s=n.data.get(r.dataId).values,o=buffer$1([a,a],r.dtype),i=o.values;for(let e=0;e<s.length;e++)i[e*a+e]=s[e];const l=[...r.shape,...r.shape];return n.makeTensorInfo(l,o.dtype,o.values)}const diagConfig$3={kernelName:Diag$1,backendName:"cpu",kernelFunc:diag$4},dilation2dConfig$1={kernelName:Dilation2D$1,backendName:"cpu",kernelFunc:({inputs:e,backend:t,attrs:n})=>{const{x:r,filter:a}=e,{strides:s,pad:o,dilations:i}=n,l=t,u=l.data.get(r.dataId).values,c=r.shape.length,p=l.data.get(a.dataId).values,d=a.shape.length,{batchSize:h,inHeight:m,inWidth:f,inChannels:g,outHeight:$,outWidth:y,padInfo:b,strideHeight:x,strideWidth:v,filterHeight:I,filterWidth:C,dilationHeight:S,dilationWidth:k,outShape:T}=computeDilation2DInfo$1(r.shape,a.shape,s,o,"NHWC",i),N=sizeFromShape$1(T),w=T.length,E=getArrayFromDType$1(r.dtype,N);for(let e=0;e<h;++e)for(let t=0;t<$;++t){const n=t*x-b.top;for(let s=0;s<y;++s){const o=s*v-b.left;for(let i=0;i<g;++i){let l=Number.MIN_SAFE_INTEGER;for(let t=0;t<I;++t){const s=n+t*S;if(s>=0&&s<m)for(let n=0;n<C;++n){const h=o+n*k;if(h>=0&&h<f){const o=locToIndex$1([e,s,h,i],c,computeStrides$1(r.shape)),m=locToIndex$1([t,n,i],d,computeStrides$1(a.shape)),f=u[o]+p[m];f>l&&(l=f)}}}E[locToIndex$1([e,t,s,i],w,computeStrides$1(T))]=l}}}return{dataId:l.write(toTypedArray$1(E,r.dtype),T,r.dtype),shape:T,dtype:r.dtype}}},dilation2dBackpropFilterConfig$1={kernelName:Dilation2DBackpropFilter$1,backendName:"cpu",kernelFunc:({inputs:e,backend:t,attrs:n})=>{const{x:r,filter:a,dy:s}=e,{strides:o,pad:i,dilations:l}=n,u=t,c=toNestedArray$1(r.shape,u.data.get(r.dataId).values),p=toNestedArray$1(a.shape,u.data.get(a.dataId).values),{batchSize:d,inHeight:h,inWidth:m,inChannels:f,outHeight:g,outWidth:$,padInfo:y,strideHeight:b,strideWidth:x,filterHeight:v,filterWidth:I,dilationHeight:C,dilationWidth:S,outShape:k}=computeDilation2DInfo$1(r.shape,a.shape,o,i,"NHWC",l);assert$6(s.rank===k.length,()=>`Error in ${Dilation2DBackpropFilter$1}, dy must have the same rank as output ${k.length}, but got ${s.rank}`);const T=toNestedArray$1(k,u.data.get(s.dataId).values),N=makeZerosNestedTypedArray$1(a.shape,a.dtype);for(let e=0;e<d;++e)for(let t=0;t<g;++t){const n=t*b-y.top;for(let r=0;r<$;++r){const a=r*x-y.left;for(let s=0;s<f;++s){let o=Number.MIN_SAFE_INTEGER,i=0,l=0;for(let t=0;t<v;++t){const r=n+t*C;if(r>=0&&r<h)for(let n=0;n<I;++n){const u=a+n*S;if(u>=0&&u<m){const a=c[e][r][u][s]+p[t][n][s];a>o&&(o=a,i=t,l=n)}}}N[i][l][s]+=T[e][t][r][s]}}}return{dataId:u.write(toTypedArray$1(N,r.dtype),a.shape,a.dtype),shape:a.shape,dtype:a.dtype}}},dilation2dBackpropInputConfig$1={kernelName:Dilation2DBackpropInput$1,backendName:"cpu",kernelFunc:({inputs:e,backend:t,attrs:n})=>{const{x:r,filter:a,dy:s}=e,{strides:o,pad:i,dilations:l}=n,u=t,c=toNestedArray$1(r.shape,u.data.get(r.dataId).values),p=toNestedArray$1(a.shape,u.data.get(a.dataId).values),{batchSize:d,inHeight:h,inWidth:m,inChannels:f,outHeight:g,outWidth:$,padInfo:y,strideHeight:b,strideWidth:x,filterHeight:v,filterWidth:I,dilationHeight:C,dilationWidth:S,outShape:k}=computeDilation2DInfo$1(r.shape,a.shape,o,i,"NHWC",l);assert$6(s.rank===k.length,()=>`Error in ${Dilation2DBackpropInput$1}, dy must have the same rank as output ${k.length}, but got ${s.rank}`);const T=toNestedArray$1(k,u.data.get(s.dataId).values),N=makeZerosNestedTypedArray$1(r.shape,r.dtype);for(let e=0;e<d;++e)for(let t=0;t<g;++t){const n=t*b-y.top;for(let r=0;r<$;++r){const a=r*x-y.left;for(let s=0;s<f;++s){let o=Number.MIN_SAFE_INTEGER,i=n<0?0:n,l=a<0?0:a;for(let t=0;t<v;++t){const r=n+t*C;if(r>=0&&r<h)for(let n=0;n<I;++n){const u=a+n*S;if(u>=0&&u<m){const a=c[e][r][u][s]+p[t][n][s];a>o&&(o=a,i=r,l=u)}}}N[e][i][l][s]+=T[e][t][r][s]}}}return{dataId:u.write(toTypedArray$1(N,r.dtype),r.shape,r.dtype),shape:r.shape,dtype:r.dtype}}};function sum$5(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{axis:s,keepDims:o}=r;let i;assertNotComplex$3(a,"sum"),i="bool"===a.dtype?cast$5({inputs:{x:a},backend:n,attrs:{dtype:"int32"}}):identity$4({inputs:{x:a},backend:n});const l=i.shape.length,u=parseAxisParam$1(s,i.shape),c=getAxesPermutation$1(u,l);let p=u,d=i;null!=c&&(d=transpose$4({inputs:{x:i},backend:n,attrs:{perm:c}}),p=getInnerMostAxes$1(p.length,l)),assertAxesAreInnerMostDims$1("sum",p,d.shape.length);const[h,m]=computeOutAndReduceShapes$1(d.shape,p);let f=zeros$3(n,h,upcastType$1(d.dtype,"int32"));const g=sizeFromShape$1(m),$=n.data.get(f.dataId).values,y=n.data.get(d.dataId).values;for(let e=0;e<$.length;++e){const t=e*g;let n=0;for(let e=0;e<g;++e)n+=y[t+e];$[e]=n}if(o){const e=f;f=reshape$5({inputs:{x:f},backend:n,attrs:{shape:expandShapeToKeepDim$1(f.shape,u)}}),n.disposeIntermediateTensorInfo(e)}return n.disposeIntermediateTensorInfo(i),null!=c&&n.disposeIntermediateTensorInfo(d),f}const sumConfig$3={kernelName:Sum$1,backendName:"cpu",kernelFunc:sum$5};function einsum$4(e){const{inputs:t,backend:n,attrs:r}=e,{equation:a}=r,s=t,{allDims:o,summedDims:i,idDims:l}=decodeEinsumEquation$1(a,s.length);checkEinsumDimSizes$1(o.length,l,s);const{path:u,steps:c}=getEinsumComputePath$1(i,l),p=c.length;let d=null,h=o.length;const m=[];for(let e=0;e<p;++e){for(const t of c[e]){const{permutationIndices:e,expandDims:r}=getEinsumPermutation$1(h,l[t]);let a;isIdentityPermutation$1(e)?a=s[t]:(a=transpose$4({inputs:{x:s[t]},backend:n,attrs:{perm:e}}),m.push(a));const o=a.shape.slice();for(let e=0;e<r.length;++e)o.splice(r[e],0,1);arraysEqual$1(a.shape,o)||(a=reshape$5({inputs:{x:a},backend:n,attrs:{shape:o}}),m.push(a)),null===d?d=a:(d=multiply$4({inputs:{a,b:d},backend:n}),m.push(d))}e<p-1&&(u[e]>=0&&(d=sum$5({inputs:{x:d},backend:n,attrs:{axis:u[e]-(o.length-h),keepDims:!1}}),m.push(d)),h--)}for(const e of m)e!==d&&n.disposeIntermediateTensorInfo(e);return d}const einsumConfig$3={kernelName:Einsum$1,backendName:"cpu",kernelFunc:einsum$4};function eluGrad$3(e){const{inputs:t,backend:n}=e,{dy:r,y:a}=t;assertNotComplex$3([r,a],"eluGrad");const s=new Float32Array(sizeFromShape$1(a.shape)),o=n.data.get(a.dataId).values,i=n.data.get(r.dataId).values;for(let e=0;e<o.length;++e){const t=o[e];s[e]=t>=1?i[e]:i[e]*(t+1)}return n.makeTensorInfo(a.shape,"float32",s)}const eluGradConfig$4={kernelName:EluGrad$1,backendName:"cpu",kernelFunc:eluGrad$3},p$1=ERF_P$1,a1$1=ERF_A1$1,a2$1=ERF_A2$1,a3$1=ERF_A3$1,a4$1=ERF_A4$1,a5$1=ERF_A5$1,erf$4=unaryKernelFunc$3(Erf$1,e=>{const t=Math.sign(e),n=Math.abs(e),r=1/(1+p$1*n);return t*(1-((((a5$1*r+a4$1)*r+a3$1)*r+a2$1)*r+a1$1)*r*Math.exp(-n*n))}),erfConfig$3={kernelName:Erf$1,backendName:"cpu",kernelFunc:erf$4};function expandDims$5(e){const{inputs:t,backend:n,attrs:r}=e,{input:a}=t,{dim:s}=r,o=a.shape.length,i=a.shape.slice();let l=s;return s<0&&(assert$6(-(o+1)<=s,()=>`Axis must be in the interval [${-(o+1)}, ${o}]`),l=o+s+1),i.splice(l,0,1),reshape$5({inputs:{x:a},backend:n,attrs:{shape:i}})}const expandDimsConfig$3={kernelName:ExpandDims$1,backendName:"cpu",kernelFunc:expandDims$5},realDivImpl$1=createSimpleBinaryKernelImpl$1((e,t)=>e/t),div$2=binaryKernelFunc$3(RealDiv$1,realDivImpl$1),realDivConfig$3={kernelName:RealDiv$1,backendName:"cpu",kernelFunc:div$2};function fftBatch$1(e,t,n){const r=e.shape,a=r[0],s=r[1],o=n.data.get(e.dataId),i=o.complexTensorInfos.real,l=o.complexTensorInfos.imag,u=[a,s],c=sizeFromShape$1(u),p=getTypedArrayFromDType$1("float32",c),d=getTypedArrayFromDType$1("float32",c);for(let e=0;e<a;e++){const r=slice$4({inputs:{x:i},backend:n,attrs:{begin:[e,0],size:[1,s]}}),a=slice$4({inputs:{x:l},backend:n,attrs:{begin:[e,0],size:[1,s]}}),o=complex$4({inputs:{real:r,imag:a},backend:n}),{real:u,imag:c}=fftImpl$3(o,t,n),h=mergeRealAndImagArrays$1(u,c);for(let t=0;t<s;t++){const n=getComplexWithIndex$1(h,t);p[e*s+t]=n.real,d[e*s+t]=n.imag}n.disposeIntermediateTensorInfo(r),n.disposeIntermediateTensorInfo(a),n.disposeIntermediateTensorInfo(o)}const h=n.makeTensorInfo(u,"float32",p),m=n.makeTensorInfo(u,"float32",d),f=complex$4({inputs:{real:h,imag:m},backend:n});return n.disposeIntermediateTensorInfo(h),n.disposeIntermediateTensorInfo(m),f}function fftImpl$3(e,t,n){const r=sizeFromShape$1(e.shape),a=n.data.get(e.dataId),s=n.data.get(a.complexTensorInfos.real.dataId).values,o=n.data.get(a.complexTensorInfos.imag.dataId).values;if(isExponentOf2$1(r)){const a=fftRadix2$1(s,o,r,t,n),i=[e.shape[0],e.shape[1]];if(t){const e=n.makeTensorInfo(i,"float32",a.real),t=n.makeTensorInfo(i,"float32",a.imag),s=n.makeTensorInfo([],"float32",createScalarValue$1(r,"float32")),o=identity$4({inputs:{x:s},backend:n}),l=realDivConfig$3.kernelFunc({inputs:{a:e,b:s},backend:n}),u=realDivConfig$3.kernelFunc({inputs:{a:t,b:o},backend:n}),c=n.data.get(l.dataId).values,p=n.data.get(u.dataId).values;return n.disposeIntermediateTensorInfo(e),n.disposeIntermediateTensorInfo(t),n.disposeIntermediateTensorInfo(s),n.disposeIntermediateTensorInfo(o),n.disposeIntermediateTensorInfo(l),n.disposeIntermediateTensorInfo(u),{real:c,imag:p}}return a}return splitRealAndImagArrays$1(fourierTransformByMatmul$1(mergeRealAndImagArrays$1(s,o),r,t))}function isExponentOf2$1(e){return 0==(e&e-1)}function fftRadix2$1(e,t,n,r,a){if(1===n)return{real:e,imag:t};const s=mergeRealAndImagArrays$1(e,t),o=n/2,i=complexWithEvenIndex$1(s),l=i.real,u=i.imag,c=[l.length],p=a.makeTensorInfo(c,"float32",l),d=a.makeTensorInfo(c,"float32",u),h=complex$4({inputs:{real:p,imag:d},backend:a}),m=complexWithOddIndex$1(s),f=m.real,g=m.imag,$=[f.length],y=a.makeTensorInfo($,"float32",f),b=a.makeTensorInfo($,"float32",g),x=complex$4({inputs:{real:y,imag:b},backend:a}),v=fftRadix2$1(l,u,o,r,a),I=v.real,C=v.imag,S=[I.length],k=a.makeTensorInfo(S,"float32",I),T=a.makeTensorInfo(S,"float32",C),N=complex$4({inputs:{real:k,imag:T},backend:a}),w=fftRadix2$1(f,g,o,r,a),E=w.real,A=w.imag,D=[E.length],R=a.makeTensorInfo(D,"float32",E),_=a.makeTensorInfo(D,"float32",A),F=complex$4({inputs:{real:R,imag:_},backend:a}),P=exponents$1(n,r),O=[P.real.length],M=a.makeTensorInfo(O,"float32",P.real),L=a.makeTensorInfo(O,"float32",P.imag),z=complex$4({inputs:{real:M,imag:L},backend:a}),B=multiply$4({inputs:{a:z,b:F},backend:a}),V=add$4({inputs:{a:N,b:B},backend:a}),G=sub$4({inputs:{a:N,b:B},backend:a}),U=real$4({inputs:{input:V},backend:a}),W=real$4({inputs:{input:G},backend:a}),q=imag$4({inputs:{input:V},backend:a}),H=imag$4({inputs:{input:G},backend:a}),K=concat$4({inputs:[U,W],backend:a,attrs:{axis:0}}),j=concat$4({inputs:[q,H],backend:a,attrs:{axis:0}}),X=a.data.get(K.dataId).values,Y=a.data.get(j.dataId).values;return a.disposeIntermediateTensorInfo(p),a.disposeIntermediateTensorInfo(d),a.disposeIntermediateTensorInfo(h),a.disposeIntermediateTensorInfo(y),a.disposeIntermediateTensorInfo(b),a.disposeIntermediateTensorInfo(x),a.disposeIntermediateTensorInfo(k),a.disposeIntermediateTensorInfo(T),a.disposeIntermediateTensorInfo(N),a.disposeIntermediateTensorInfo(R),a.disposeIntermediateTensorInfo(_),a.disposeIntermediateTensorInfo(F),a.disposeIntermediateTensorInfo(M),a.disposeIntermediateTensorInfo(L),a.disposeIntermediateTensorInfo(z),a.disposeIntermediateTensorInfo(B),a.disposeIntermediateTensorInfo(V),a.disposeIntermediateTensorInfo(G),a.disposeIntermediateTensorInfo(U),a.disposeIntermediateTensorInfo(q),a.disposeIntermediateTensorInfo(W),a.disposeIntermediateTensorInfo(H),a.disposeIntermediateTensorInfo(K),a.disposeIntermediateTensorInfo(j),{real:X,imag:Y}}function fourierTransformByMatmul$1(e,t,n){const r=new Float32Array(2*t);for(let a=0;a<t;a++){let s=0,o=0;for(let r=0;r<t;r++){const i=exponent$1(a*r,t,n),l=getComplexWithIndex$1(e,r);s+=l.real*i.real-l.imag*i.imag,o+=l.real*i.imag+l.imag*i.real}n&&(s/=t,o/=t),assignToTypedArray$1(r,s,o,a)}return r}function fft$4(e){const{inputs:t,backend:n}=e,{input:r}=t,a=sizeFromShape$1(r.shape),s=r.shape[r.shape.length-1],o=reshape$5({inputs:{x:r},backend:n,attrs:{shape:[a/s,s]}}),i=fftBatch$1(o,!1,n),l=reshape$5({inputs:{x:i},backend:n,attrs:{shape:r.shape}});return n.disposeIntermediateTensorInfo(o),n.disposeIntermediateTensorInfo(i),l}const fftConfig$3={kernelName:FFT$1,backendName:"cpu",kernelFunc:fft$4};function fill$4(e){const{backend:t,attrs:n}=e,{shape:r,value:a,dtype:s}=n,o=s||inferDtype$1(a),i=getArrayFromDType$1(o,sizeFromShape$1(r));return fillValues$1(i,a,o),t.makeTensorInfo(r,o,i)}const fillConfig$3={kernelName:Fill$1,backendName:"cpu",kernelFunc:fill$4};function fillValues$1(e,t,n){e.fill(t)}const flipLeftRightConfig$3={kernelName:FlipLeftRight$1,backendName:"cpu",kernelFunc:({inputs:e,backend:t})=>{const{image:n}=e,r=t,a=getTypedArrayFromDType$1(n.dtype,sizeFromShape$1(n.shape)),[s,o,i,l]=n.shape,u=r.data.get(n.dataId).values;for(let e=0;e<s;e++){const t=e*i*o*l;for(let e=0;e<o;e++){const n=e*(i*l);for(let e=0;e<i;e++){const r=e*l;for(let s=0;s<l;s++){const o=Math.round(i-e-1),c=t+n+r+s;let p=u[c];o>=0&&o<i&&(p=u[t+n+o*l+s]),a[c]=p}}}}return{dataId:r.write(a,n.shape,n.dtype),shape:n.shape,dtype:n.dtype}}},floorDivImpl$1=createSimpleBinaryKernelImpl$1((e,t)=>Math.floor(e/t)),floorDiv$4=binaryKernelFunc$3(FloorDiv$1,floorDivImpl$1,null,"int32"),floorDivConfig$3={kernelName:FloorDiv$1,backendName:"cpu",kernelFunc:floorDiv$4};function fusedConv2D$1(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,filter:s,bias:o,preluActivationWeights:i}=t,{strides:l,pad:u,dataFormat:c,dilations:p,dimRoundingMode:d,activation:h,leakyreluAlpha:m}=r;let f=conv2D$1({inputs:{x:a,filter:s},backend:n,attrs:{strides:l,pad:u,dataFormat:c,dilations:p,dimRoundingMode:d}});if(o){const e=f;f=add$4({inputs:{a:f,b:o},backend:n}),n.disposeIntermediateTensorInfo(e)}if(h){const e=f;f=applyActivation$2(n,f,h,i,m),n.disposeIntermediateTensorInfo(e)}return f}const fusedConv2DConfig$3={kernelName:FusedConv2D$1,backendName:"cpu",kernelFunc:fusedConv2D$1};function fusedDepthwiseConv2D$3(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,filter:s,bias:o,preluActivationWeights:i}=t,{strides:l,pad:u,dataFormat:c,dilations:p,dimRoundingMode:d,activation:h,leakyreluAlpha:m}=r;let f=depthwiseConv2dNative$3({inputs:{x:a,filter:s},backend:n,attrs:{strides:l,pad:u,dataFormat:c,dilations:p,dimRoundingMode:d}});if(o){const e=f;f=add$4({inputs:{a:f,b:o},backend:n}),n.disposeIntermediateTensorInfo(e)}if(h){const e=f;f=applyActivation$2(n,f,h,i,m),n.disposeIntermediateTensorInfo(e)}return f}const fusedDepthwiseConv2DConfig$3={kernelName:FusedDepthwiseConv2D$1,backendName:"cpu",kernelFunc:fusedDepthwiseConv2D$3};function gatherNd$3(e){const{inputs:t,backend:n}=e,{params:r,indices:a}=t,s=sizeFromShape$1(r.shape),o=a.shape,i=o[o.length-1],[l,u,c,p]=prepareAndValidate$1(r,a);if(0===u)return n.makeTensorInfo(l,r.dtype,[]);const d=gatherNdImpl$1(n.data.get(a.dataId).values,n.bufferSync(r),r.dtype,u,i,c,p,r.shape,s);return n.makeTensorInfo(l,r.dtype,d.values)}const gatherNdConfig$3={kernelName:GatherNd$1,backendName:"cpu",kernelFunc:gatherNd$3};function gatherV2$3(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,indices:s}=t,{axis:o,batchDims:i}=r;assertNotComplex$3([a,s],"gatherV2");let l=i;null==i&&(l=0);const u=sizeFromShape$1(s.shape),c=collectGatherOpShapeInfo$1(a,s,parseAxisParam$1(o,a.shape)[0],l),p=reshape$5({inputs:{x:a},backend:n,attrs:{shape:[c.batchSize,c.outerSize,c.dimSize,c.sliceSize]}}),d=reshape$5({inputs:{x:s},backend:n,attrs:{shape:[c.batchSize,u/c.batchSize]}}),h=[c.batchSize,c.outerSize,u/c.batchSize,c.sliceSize],m=n.bufferSync(d),f=gatherV2Impl$1(n.bufferSync(p),m,h);return n.disposeIntermediateTensorInfo(p),n.disposeIntermediateTensorInfo(d),n.makeTensorInfo(c.outputShape,f.dtype,f.values)}const gatherV2Config$3={kernelName:GatherV2$1,backendName:"cpu",kernelFunc:gatherV2$3};function ifft$4(e){const{inputs:t,backend:n}=e,{input:r}=t,a=sizeFromShape$1(r.shape),s=r.shape[r.shape.length-1],o=reshape$5({inputs:{x:r},backend:n,attrs:{shape:[a/s,s]}}),i=fftBatch$1(o,!0,n),l=reshape$5({inputs:{x:i},backend:n,attrs:{shape:r.shape}});return n.disposeIntermediateTensorInfo(o),n.disposeIntermediateTensorInfo(i),l}const ifftConfig$3={kernelName:IFFT$1,backendName:"cpu",kernelFunc:ifft$4},isFinite$5=unaryKernelFunc$3(IsFinite$1,e=>Number.isFinite(e)?1:0,"bool"),isFiniteConfig$3={kernelName:IsFinite$1,backendName:"cpu",kernelFunc:isFinite$5},isInf$4=unaryKernelFunc$3(IsInf$1,e=>Infinity===Math.abs(e)?1:0,"bool"),isInfConfig$3={kernelName:IsInf$1,backendName:"cpu",kernelFunc:isInf$4},isNaN$5=unaryKernelFunc$3(IsNan$1,e=>Number.isNaN(e)?1:0,"bool"),isNaNConfig$3={kernelName:IsNan$1,backendName:"cpu",kernelFunc:isNaN$5};function linSpace$3(e){const{backend:t,attrs:n}=e,{start:r,stop:a,num:s}=n,o=linSpaceImpl$1(r,a,s);return t.makeTensorInfo([o.length],"float32",o)}const linSpaceConfig$3={kernelName:LinSpace$1,backendName:"cpu",kernelFunc:linSpace$3},log1p$4=unaryKernelFunc$3(Log1p$1,e=>Math.log1p(e)),log1pConfig$3={kernelName:Log1p$1,backendName:"cpu",kernelFunc:log1p$4},logicalAndImpl$1=createSimpleBinaryKernelImpl$1((e,t)=>e&&t),logicalAnd$4=binaryKernelFunc$3(LogicalAnd$1,logicalAndImpl$1,null,"bool"),logicalAndConfig$3={kernelName:LogicalAnd$1,backendName:"cpu",kernelFunc:logicalAnd$4},logicalNot$4=unaryKernelFunc$3(LogicalNot$1,e=>e?0:1,"bool"),logicalNotConfig$3={kernelName:LogicalNot$1,backendName:"cpu",kernelFunc:logicalNot$4},logicalOrImpl$1=createSimpleBinaryKernelImpl$1((e,t)=>e||t),logicalOr$4=binaryKernelFunc$3(LogicalOr$1,logicalOrImpl$1,null,"bool"),logicalOrConfig$3={kernelName:LogicalOr$1,backendName:"cpu",kernelFunc:logicalOr$4};function lRN$1(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{depthRadius:s,bias:o,alpha:i,beta:l}=r;assertNotComplex$3(a,"LRN");const u=a.shape[3],c=u-1,p=n.data.get(a.dataId).values,d=sizeFromShape$1(a.shape),h=new Float32Array(d);function m(e){const t=e%u;let n=e-t+Math.max(0,t-s);const r=e-t+Math.min(t+s,c);let a=0;for(;n<=r;n++){const e=p[n];a+=e*e}return a}for(let e=0;e<d;e++){const t=m(e),n=p[e]*Math.pow(o+i*t,-l);h[e]=n}return n.makeTensorInfo(a.shape,a.dtype,h)}const lRNConfig$1={kernelName:LRN$1,backendName:"cpu",kernelFunc:lRN$1};function lRNGrad$1(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,y:s,dy:o}=t,{depthRadius:i,bias:l,alpha:u,beta:c}=r;assertNotComplex$3(o,"LRNGrad");const p=sizeFromShape$1(o.shape),d=o.shape[3],h=n.data.get(o.dataId).values,m=n.data.get(a.dataId).values,f=n.data.get(s.dataId).values,g=new Float32Array(p),$=p;for(let e=0;e<$;e++){const t=e%d,n=e-t+Math.max(0,t-i),r=e-t+Math.min(d,t+i+1);let a=0;for(let e=n;e<r;e++)a+=Math.pow(m[e],2);a=u*a+l;for(let t=n;t<r;t++){let n=-2*u*c*m[t]*f[e]/a;e===t&&(n+=Math.pow(a,-c)),n*=h[e],g[t]+=n}}return n.makeTensorInfo(o.shape,a.dtype,g)}const lRNGradConfig$1={kernelName:LRNGrad$1,backendName:"cpu",kernelFunc:lRNGrad$1};function max$5(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{reductionIndices:s,keepDims:o}=r,i=n;let l=a.shape;const u=l.length,c=parseAxisParam$1(s,l);let p=c;const d=getAxesPermutation$1(p,u);let h=i.data.get(a.dataId).values;if(null!=d){const e=new Array(u);for(let t=0;t<e.length;t++)e[t]=l[d[t]];h=transposeImpl$3(h,l,a.dtype,d,e),p=getInnerMostAxes$1(p.length,u),l=e}assertNotComplex$3(a,"max"),assertAxesAreInnerMostDims$1("max",p,u);const[m,f]=computeOutAndReduceShapes$1(l,p),g=maxImpl$3(h,sizeFromShape$1(f),m,a.dtype),$=i.write(g,m,a.dtype);let y=m;return o&&(y=expandShapeToKeepDim$1(m,c)),{dataId:$,shape:y,dtype:a.dtype}}const maxConfig$3={kernelName:Max$1,backendName:"cpu",kernelFunc:max$5};function maxPool$4(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t;assertNotComplex$3(a,"maxPool");const{filterSize:s,strides:o,pad:i,dimRoundingMode:l}=r;assert$6(eitherStridesOrDilationsAreOne$1(o,1),()=>`Error in maxPool: Either strides or dilations must be 1. Got strides ${o} and dilations '1'`);const u=computePool2DInfo$1(a.shape,s,o,1,i,l);let c;if(1===u.filterWidth&&1===u.filterHeight&&arraysEqual$1(u.inShape,u.outShape))c=identity$4({inputs:{x:a},backend:n});else{const e=n.data.get(a.dataId).values,t=computeStrides$1(a.shape),r=pool$2(e,a.shape,a.dtype,t,u,"max");c=n.makeTensorInfo(u.outShape,a.dtype,r.values)}return c}const maxPoolConfig$3={kernelName:MaxPool$1,backendName:"cpu",kernelFunc:maxPool$4};function maxPool3D$1(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{filterSize:s,strides:o,pad:i,dimRoundingMode:l,dataFormat:u}=r;assertNotComplex$3(a,"maxPool3d");const c=computePool3DInfo$1(a.shape,s,o,1,i,l,u),p=pool3d$2(n.data.get(a.dataId).values,a.shape,a.dtype,computeStrides$1(a.shape),c,"max");return n.makeTensorInfo(p.shape,"float32",p.values)}const maxPool3DConfig$3={kernelName:MaxPool3D$1,backendName:"cpu",kernelFunc:maxPool3D$1};function maxPool3DGrad$3(e){const{inputs:t,backend:n,attrs:r}=e,{dy:a,input:s}=t,{filterSize:o,strides:i,pad:l,dimRoundingMode:u}=r;assertNotComplex$3([a,s],"maxPool3DGrad");const c=computePool3DInfo$1(s.shape,o,i,1,l,u),p=maxPool3dPositions$1(n.bufferSync(s),c),d=c.strideDepth,h=c.strideHeight,m=c.strideWidth,f=c.dilationDepth,g=c.dilationHeight,$=c.dilationWidth,y=c.effectiveFilterDepth,b=c.effectiveFilterHeight,x=c.effectiveFilterWidth,v=y-1-c.padInfo.front,I=x-1-c.padInfo.left,C=b-1-c.padInfo.top,S=buffer$1(s.shape,"float32"),k=n.bufferSync(a);for(let e=0;e<c.batchSize;++e)for(let t=0;t<c.inChannels;++t)for(let n=0;n<c.inDepth;++n)for(let r=0;r<c.inHeight;++r)for(let a=0;a<c.inWidth;++a){const s=n-v,o=r-C,i=a-I;let l=0;for(let n=0;n<y;n+=f){const r=(s+n)/d;if(!(r<0||r>=c.outDepth||Math.floor(r)!==r))for(let a=0;a<b;a+=g){const s=(o+a)/h;if(!(s<0||s>=c.outHeight||Math.floor(s)!==s))for(let o=0;o<x;o+=$){const u=(i+o)/m;if(u<0||u>=c.outWidth||Math.floor(u)!==u)continue;const d=y*b*x-1-p.get(e,r,s,u,t)===n*b*x+a*x+o?1:0;0!==d&&(l+=k.get(e,r,s,u,t)*d)}}}S.set(l,e,n,r,a,t)}return n.makeTensorInfo(S.shape,S.dtype,S.values)}const maxPool3DGradConfig$2={kernelName:MaxPool3DGrad$1,backendName:"cpu",kernelFunc:maxPool3DGrad$3};function maxPoolGrad$4(e){const{inputs:t,backend:n,attrs:r}=e,{dy:a,input:s,output:o}=t,i=s;assertNotComplex$3([s,o],"maxPoolGrad");const{filterSize:l,strides:u,pad:c,dimRoundingMode:p}=r,d=computePool2DInfo$1(i.shape,l,u,1,c,p),h=n.data.get(i.dataId).values,m=buffer$1(d.outShape,i.dtype,maxPoolPositions$1(h,i.shape,i.dtype,d).values),f=d.strideHeight,g=d.strideWidth,$=d.dilationHeight,y=d.dilationWidth,b=d.effectiveFilterHeight,x=d.effectiveFilterWidth,v=x-1-d.padInfo.left,I=b-1-d.padInfo.top,C=buffer$1(i.shape,"float32"),S=n.data.get(a.dataId).values,k=buffer$1(a.shape,"float32",S);for(let e=0;e<d.batchSize;++e)for(let t=0;t<d.inChannels;++t)for(let n=0;n<d.inHeight;++n)for(let r=0;r<d.inWidth;++r){const a=n-I,s=r-v;let o=0;for(let n=0;n<b;n+=$){const r=(a+n)/f;if(!(r<0||r>=d.outHeight||Math.floor(r)!==r))for(let a=0;a<x;a+=y){const i=(s+a)/g;if(i<0||i>=d.outWidth||Math.floor(i)!==i)continue;const l=b*x-1-m.get(e,r,i,t)===n*x+a?1:0;0!==l&&(o+=k.get(e,r,i,t)*l)}}C.set(o,e,n,r,t)}return n.makeTensorInfo(C.shape,C.dtype,C.values)}const maxPoolGradConfig$4={kernelName:MaxPoolGrad$1,backendName:"cpu",kernelFunc:maxPoolGrad$4};function maxPoolWithArgmaxImpl$3(e,t,n,r,a){const s=pool$2(e,t,n,computeStrides$1(t),a,"max"),o=maxPoolPositions$1(e,t,n,a,!0,r);return[s.values,o.values]}const maxPoolWithArgmaxConfig$3={kernelName:MaxPoolWithArgmax$1,backendName:"cpu",kernelFunc:({inputs:e,attrs:t,backend:n})=>{const{x:r}=e,{filterSize:a,strides:s,pad:o,includeBatchInIndex:i}=t,l=n;assertNotComplex$3(r,"MaxPoolWithArgmax");const u=l.data.get(r.dataId).values,c=computePool2DInfo$1(r.shape,a,s,[1,1],o),[p,d]=maxPoolWithArgmaxImpl$3(u,r.shape,r.dtype,i,c),h=l.write(p,c.outShape,r.dtype),m=l.write(d,c.outShape,r.dtype);return[{dataId:h,shape:c.outShape,dtype:r.dtype},{dataId:m,shape:c.outShape,dtype:"int32"}]}};function mean$2(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{axis:s,keepDims:o}=r,i=parseAxisParam$1(s,a.shape),l=sizeFromShape$1(computeOutAndReduceShapes$1(a.shape,i)[1]),u=[],c=n.makeTensorInfo([],"float32",new Float32Array([l]));u.push(c);const p=cast$5({inputs:{x:a},backend:n,attrs:{dtype:"float32"}});u.push(p);const d=div$2({inputs:{a:p,b:c},backend:n});u.push(d);const h=sum$5({inputs:{x:d},backend:n,attrs:{axis:s,keepDims:o}});return u.forEach(e=>n.disposeIntermediateTensorInfo(e)),h}const meanConfig$3={kernelName:Mean$1,backendName:"cpu",kernelFunc:mean$2};function min$5(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{axis:s,keepDims:o}=r;assertNotComplex$3(a,"min");const i=parseAxisParam$1(s,a.shape);let l=i;const u=getAxesPermutation$1(l,a.shape.length);let c=a;null!=u&&(c=transpose$4({inputs:{x:a},backend:n,attrs:{perm:u}}),l=getInnerMostAxes$1(l.length,a.shape.length)),assertAxesAreInnerMostDims$1("min",l,c.shape.length);const[p,d]=computeOutAndReduceShapes$1(c.shape,l),h=sizeFromShape$1(d),m=makeZerosTypedArray$1(sizeFromShape$1(p),c.dtype),f=n.data.get(c.dataId).values;for(let e=0;e<m.length;++e){const t=e*h;let n=f[t];for(let e=0;e<h;++e){const r=f[t+e];(Number.isNaN(r)||r<n)&&(n=r)}m[e]=n}null!=u&&n.disposeIntermediateTensorInfo(c);const g=n.makeTensorInfo(p,c.dtype,m);if(o){const e=reshape$5({inputs:{x:g},backend:n,attrs:{shape:expandShapeToKeepDim$1(p,i)}});return n.disposeIntermediateTensorInfo(g),e}return g}const minConfig$3={kernelName:Min$1,backendName:"cpu",kernelFunc:min$5};function mirrorPad$2(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{paddings:s,mode:o}=r;assertNotComplex$3(a,"mirrorPad");const i=s.map((e,t)=>e[0]+a.shape[t]+e[1]),l=s.map(e=>e[0]),u=s.map((e,t)=>e[0]+a.shape[t]),c="reflect"===o?0:1,p=n.data.get(a.dataId).values,d=a.shape.length,h=computeStrides$1(a.shape),m=sizeFromShape$1(i),f=i.length,g=computeStrides$1(i),$=getTypedArrayFromDType$1(a.dtype,m);for(let e=0;e<m;e++){let t=indexToLoc$1(e,f,g);for(let e=0;e<f;e++)t[e]<l[e]?t[e]=2*l[e]-t[e]-c:t[e]>=u[e]&&(t[e]=2*(u[e]-1)-t[e]+c);t=t.map((e,t)=>e-l[t]);const n=locToIndex$1(t,d,h);$[e]=p[n]}return{dataId:n.write($,i,a.dtype),shape:i,dtype:a.dtype}}const mirrorPadConfig$3={kernelName:MirrorPad$1,backendName:"cpu",kernelFunc:mirrorPad$2},modImpl$1=createSimpleBinaryKernelImpl$1((e,t)=>{const n=e%t;return e<0&&t<0||e>=0&&t>=0?n:(n+t)%t}),mod$4=binaryKernelFunc$3(Mod$1,modImpl$1),modConfig$3={kernelName:Mod$1,backendName:"cpu",kernelFunc:mod$4};function softmax$5(e){const{inputs:t,backend:n,attrs:r}=e,{logits:a}=t,{dim:s}=r,o=a.shape.length;let i=s;if(-1===i&&(i=o-1),i!==o-1)throw Error(`Softmax along a non-last dimension is not yet supported. Logits was rank ${o} and dim was ${i}`);const l=parseAxisParam$1([i],a.shape),u=max$5({inputs:{x:a},backend:n,attrs:{reductionIndices:l,keepDims:!1}}),c=expandShapeToKeepDim$1(u.shape,l),p=reshape$5({inputs:{x:u},backend:n,attrs:{shape:c}}),d=sub$4({inputs:{a,b:p},backend:n}),h=exp$4({inputs:{x:d},backend:n}),m=sum$5({inputs:{x:h},backend:n,attrs:{axis:l,keepDims:!1}}),f=reshape$5({inputs:{x:m},backend:n,attrs:{shape:c}}),g=div$2({inputs:{a:h,b:f},backend:n});return n.disposeIntermediateTensorInfo(u),n.disposeIntermediateTensorInfo(p),n.disposeIntermediateTensorInfo(d),n.disposeIntermediateTensorInfo(h),n.disposeIntermediateTensorInfo(m),n.disposeIntermediateTensorInfo(f),g}const softmaxConfig$3={kernelName:Softmax$5,backendName:"cpu",kernelFunc:softmax$5};function multinomial$4(e){const{inputs:t,backend:n,attrs:r}=e,{logits:a}=t,{numSamples:s,seed:o,normalized:i}=r;assertNotComplex$3(a,"multinomial");const l=i?a:softmax$5({inputs:{logits:a},backend:n,attrs:{dim:-1}}),u=l.shape[0],c=l.shape[1],p=n.data.get(l.dataId).values,d=[u,s],h=makeZerosTypedArray$1(sizeFromShape$1(d),"int32");for(let e=0;e<u;++e){const t=e*c,n=new Float32Array(c-1);n[0]=p[t];for(let e=1;e<n.length;++e)n[e]=n[e-1]+p[t+e];const r=seedrandom$2.alea(o.toString()),a=e*s;for(let e=0;e<s;++e){const t=r();h[a+e]=n.length;for(let r=0;r<n.length;r++)if(t<n[r]){h[a+e]=r;break}}}return i||n.disposeIntermediateTensorInfo(l),n.makeTensorInfo(d,"int32",h)}const multinomialConfig$3={kernelName:Multinomial$1,backendName:"cpu",kernelFunc:multinomial$4},nonMaxSuppressionV3Impl$4=nonMaxSuppressionV3Impl$5;function nonMaxSuppressionV3$3(e){const{inputs:t,backend:n,attrs:r}=e,{boxes:a,scores:s}=t,{maxOutputSize:o,iouThreshold:i,scoreThreshold:l}=r;assertNotComplex$3(a,"NonMaxSuppression");const u=n.data.get(a.dataId).values,c=n.data.get(s.dataId).values,{selectedIndices:p}=nonMaxSuppressionV3Impl$4(u,c,o,i,l);return n.makeTensorInfo([p.length],"int32",new Int32Array(p))}const nonMaxSuppressionV3Config$3={kernelName:NonMaxSuppressionV3$1,backendName:"cpu",kernelFunc:nonMaxSuppressionV3$3},nonMaxSuppressionV4Impl$4=nonMaxSuppressionV4Impl$5;function nonMaxSuppressionV4$3(e){const{inputs:t,backend:n,attrs:r}=e,{boxes:a,scores:s}=t,{maxOutputSize:o,iouThreshold:i,scoreThreshold:l,padToMaxOutputSize:u}=r;assertNotComplex$3(a,"NonMaxSuppressionPadded");const c=n.data.get(a.dataId).values,p=n.data.get(s.dataId).values,{selectedIndices:d,validOutputs:h}=nonMaxSuppressionV4Impl$4(c,p,o,i,l,u);return[n.makeTensorInfo([d.length],"int32",new Int32Array(d)),n.makeTensorInfo([],"int32",new Int32Array([h]))]}const nonMaxSuppressionV4Config$3={kernelName:NonMaxSuppressionV4$1,backendName:"cpu",kernelFunc:nonMaxSuppressionV4$3},nonMaxSuppressionV5Impl$4=nonMaxSuppressionV5Impl$5;function nonMaxSuppressionV5$3(e){const{inputs:t,backend:n,attrs:r}=e,{boxes:a,scores:s}=t,{maxOutputSize:o,iouThreshold:i,scoreThreshold:l,softNmsSigma:u}=r;assertNotComplex$3(a,"NonMaxSuppressionWithScore");const c=n.data.get(a.dataId).values,p=n.data.get(s.dataId).values,d=o,h=i,m=l,f=u,{selectedIndices:g,selectedScores:$}=nonMaxSuppressionV5Impl$4(c,p,d,h,m,f);return[n.makeTensorInfo([g.length],"int32",new Int32Array(g)),n.makeTensorInfo([$.length],"float32",new Float32Array($))]}const nonMaxSuppressionV5Config$3={kernelName:NonMaxSuppressionV5$1,backendName:"cpu",kernelFunc:nonMaxSuppressionV5$3};function oneHot$4(e){const{inputs:t,backend:n,attrs:r}=e,{indices:a}=t,{depth:s,onValue:o,offValue:i}=r;assertNotComplex$3(a,"oneHot");const l=sizeFromShape$1(a.shape),u=new Float32Array(l*s);u.fill(i);const c=n.data.get(a.dataId).values;for(let e=0;e<l;++e)c[e]>=0&&c[e]<s&&(u[e*s+c[e]]=o);return n.makeTensorInfo([...a.shape,s],"int32",u)}const oneHotConfig$3={kernelName:OneHot$1,backendName:"cpu",kernelFunc:oneHot$4};function zerosLike$4(e){const{inputs:t,backend:n}=e,{x:r}=t;if("string"===r.dtype)throw new Error("zerosLike is not supported for string tensors");if("complex64"===r.dtype){const e=real$4({inputs:{input:r},backend:n}),t=zerosLike$4({inputs:{x:e},backend:n}),a=imag$4({inputs:{input:r},backend:n}),s=zerosLike$4({inputs:{x:a},backend:n}),o=complex$4({inputs:{real:t,imag:s},backend:n});return n.disposeIntermediateTensorInfo(e),n.disposeIntermediateTensorInfo(t),n.disposeIntermediateTensorInfo(a),n.disposeIntermediateTensorInfo(s),o}return fill$4({backend:n,attrs:{shape:r.shape,value:0,dtype:r.dtype}})}const zerosLikeConfig$3={kernelName:ZerosLike$1,backendName:"cpu",kernelFunc:zerosLike$4};function onesLike$4(e){const{inputs:t,backend:n}=e,{x:r}=t;if("string"===r.dtype)throw new Error("onesLike is not supported for string tensors");if("complex64"===r.dtype){const e=real$4({inputs:{input:r},backend:n}),t=onesLike$4({inputs:{x:e},backend:n}),a=imag$4({inputs:{input:r},backend:n}),s=zerosLike$4({inputs:{x:a},backend:n}),o=complex$4({inputs:{real:t,imag:s},backend:n});return n.disposeIntermediateTensorInfo(e),n.disposeIntermediateTensorInfo(t),n.disposeIntermediateTensorInfo(a),n.disposeIntermediateTensorInfo(s),o}return fill$4({backend:n,attrs:{shape:r.shape,value:1,dtype:r.dtype}})}const onesLikeConfig$3={kernelName:OnesLike$1,backendName:"cpu",kernelFunc:onesLike$4};function pack$3(e){const{inputs:t,backend:n,attrs:r}=e,{axis:a}=r;if(1===t.length)return expandDims$5({inputs:{input:t[0]},backend:n,attrs:{dim:a}});const s=t[0].shape,o=t[0].dtype;t.forEach(e=>{assertShapesMatch$1(s,e.shape,"All tensors passed to stack must have matching shapes"),assert$6(o===e.dtype,()=>"All tensors passed to stack must have matching dtypes")});const i=[],l=concat$4({inputs:t.map(e=>{const t=expandDims$5({inputs:{input:e},backend:n,attrs:{dim:a}});return i.push(t),t}),backend:n,attrs:{axis:a}});return i.forEach(e=>n.disposeIntermediateTensorInfo(e)),l}const packConfig$3={kernelName:Pack$1,backendName:"cpu",kernelFunc:pack$3};function padV2$3(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{paddings:s,constantValue:o}=r;assertNotComplex$3(a,"pad");const i=s.map((e,t)=>e[0]+a.shape[t]+e[1]),l=s.map(e=>e[0]),u=n.data.get(a.dataId).values,c=sizeFromShape$1(a.shape),p=a.shape.length,d=computeStrides$1(a.shape),h=sizeFromShape$1(i),m=i.length,f=computeStrides$1(i),g=getTypedArrayFromDType$1(a.dtype,h);0!==o&&g.fill(o);for(let e=0;e<c;e++)g[locToIndex$1(indexToLoc$1(e,p,d).map((e,t)=>e+l[t]),m,f)]=u[e];return{dataId:n.write(g,i,a.dtype),shape:i,dtype:a.dtype}}const padV2Config$3={kernelName:PadV2$1,backendName:"cpu",kernelFunc:padV2$3},powImpl$1=createSimpleBinaryKernelImpl$1((e,t)=>Math.pow(e,t)),pow$4=binaryKernelFunc$3(Pow$1,powImpl$1),powConfig$3={kernelName:Pow$1,backendName:"cpu",kernelFunc:pow$4};function range$6(e){const{backend:t,attrs:n}=e,{start:r,stop:a,dtype:s,step:o}=n,i=rangeImpl$1(r,a,o,s);return t.makeTensorInfo([i.length],s,i)}const rangeConfig$3={kernelName:Range$1,backendName:"cpu",kernelFunc:range$6},reciprocal$4=unaryKernelFunc$3(Reciprocal$1,e=>1/e),reciprocalConfig$3={kernelName:Reciprocal$1,backendName:"cpu",kernelFunc:reciprocal$4};function resizeBilinear$4(e){const{inputs:t,backend:n,attrs:r}=e,{images:a}=t,{alignCorners:s,halfPixelCenters:o,size:i}=r;assertNotComplex$3(a,"resizeBilinear");const l=computeStrides$1(a.shape),[u,c]=i,[p,d,h,m]=a.shape,f=n.data.get(a.dataId).values,g=new Float32Array(sizeFromShape$1([p,u,c,m])),$=[s&&u>1?d-1:d,s&&c>1?h-1:h],y=[s&&u>1?u-1:u,s&&c>1?c-1:c];let b=0;const x=$[0]/y[0],v=$[1]/y[1];for(let e=0;e<p;e++)for(let t=0;t<u;t++){let n;n=o?x*(t+.5)-.5:x*t;const r=Math.max(0,Math.floor(n)),a=n-r,s=Math.min(d-1,Math.ceil(n)),i=e*l[0]+r*l[1],u=e*l[0]+s*l[1];for(let e=0;e<c;e++){let t;t=o?v*(e+.5)-.5:v*e;const n=Math.max(0,Math.floor(t)),r=t-n,s=Math.min(h-1,Math.ceil(t)),c=i+n*l[2],p=u+n*l[2],d=i+s*l[2],$=u+s*l[2];for(let e=0;e<m;e++){const t=f[c+e],n=f[p+e],s=t+(f[d+e]-t)*r;g[b++]=s+(n+(f[$+e]-n)*r-s)*a}}}return n.makeTensorInfo([p,u,c,m],"float32",g)}const resizeBilinearConfig$3={kernelName:ResizeBilinear$1,backendName:"cpu",kernelFunc:resizeBilinear$4};function resizeBilinearGrad$3(e){const{inputs:t,backend:n,attrs:r}=e,{images:a,dy:s}=t,{alignCorners:o}=r;assertNotComplex$3([s,a],"resizeBilinearGrad");const i=computeStrides$1(a.shape),[l,u,c,p]=a.shape,[,d,h]=s.shape,m=new Float32Array(l*u*c*p),f=[o&&d>1?u-1:u,o&&h>1?c-1:c],g=[o&&d>1?d-1:d,o&&h>1?h-1:h],$=f[0]/g[0],y=f[1]/g[1],b=n.data.get(s.dataId).values;let x=0;for(let e=0;e<l;e++){const t=e*i[0];for(let e=0;e<d;e++){const n=e*$,r=Math.floor(n),a=Math.min(Math.ceil(n),u-1),s=t+r*i[1],o=t+a*i[1],l=n-r,d=1-l;for(let e=0;e<h;e++){const t=e*y,n=Math.floor(t),r=Math.min(Math.ceil(t),c-1),a=t-n,u=1-a,h=s+n*i[2],f=s+r*i[2],g=o+n*i[2],$=o+r*i[2],v=d*u,I=d*a,C=l*u,S=l*a;for(let e=0;e<p;e++){const t=b[x++];m[h+e]+=t*v,m[f+e]+=t*I,m[g+e]+=t*C,m[$+e]+=t*S}}}}return n.makeTensorInfo([l,c,u,p],"float32",m)}const resizeBilinearGradConfig$4={kernelName:ResizeBilinearGrad$1,backendName:"cpu",kernelFunc:resizeBilinearGrad$3};function resizeNearestNeighbor$4(e){const{inputs:t,backend:n,attrs:r}=e,{images:a}=t,{alignCorners:s,halfPixelCenters:o,size:i}=r;assertNotComplex$3(a,"resizeNearestNeighbor");const l=computeStrides$1(a.shape),[u,c]=i,[p,d,h,m]=a.shape,f=n.data.get(a.dataId).values,g=new Float32Array(p*u*c*m),$=[s&&u>1?d-1:d,s&&c>1?h-1:h],y=[s&&u>1?u-1:u,s&&c>1?c-1:c],b=$[0]/y[0],x=$[1]/y[1];let v=0;for(let e=0;e<p;e++){const t=e*l[0];for(let e=0;e<u;e++){const n=o?b*(e+.5):b*e;let r=Math.min(d-1,s?Math.round(n):Math.floor(n));o&&(r=Math.max(0,r));const a=t+r*l[1];for(let e=0;e<c;e++){const t=o?x*(e+.5):x*e;let n=Math.min(h-1,s?Math.round(t):Math.floor(t));o&&(n=Math.max(0,n));const r=a+n*l[2];for(let e=0;e<m;e++)g[v++]=f[r+e]}}}return n.makeTensorInfo([p,u,c,m],a.dtype,g)}const resizeNearestNeighborConfig$3={kernelName:ResizeNearestNeighbor$1,backendName:"cpu",kernelFunc:resizeNearestNeighbor$4};function resizeNearestNeighborGrad$3(e){const{inputs:t,backend:n,attrs:r}=e,{images:a,dy:s}=t,{alignCorners:o}=r;assertNotComplex$3([s,a],"resizeNearestNeighborGrad");const i=computeStrides$1(a.shape),l=computeStrides$1(s.shape),[u,c,p,d]=a.shape,[,h,m]=s.shape,f=new Float32Array(u*c*p*d),g=n.data.get(s.dataId).values,$=[o&&h>1?c-1:c,o&&m>1?p-1:p],y=[o&&h>1?h-1:h,o&&m>1?m-1:m],b=$[0]/y[0],x=$[1]/y[1],v=1/b,I=1/x,C=2*Math.ceil(v)+2,S=2*Math.ceil(I)+2;for(let e=0;e<u;e++){const t=e*i[0];for(let e=0;e<c;e++){const n=t+e*i[1],r=Math.floor(e*v),a=Math.floor(r-C/2);for(let r=0;r<p;r++){const s=n+r*i[2],u=Math.floor(r*I),$=Math.floor(u-S/2);for(let n=0;n<d;n++){let i=0;for(let s=0;s<C;s++){const u=s+a;if(u<0||u>=h)continue;const d=t+u*l[1],f=u*b;if(e===Math.min(c-1,o?Math.round(f):Math.floor(f)))for(let e=0;e<S;e++){const t=e+$;if(t<0||t>=m)continue;const a=d+t*l[2],s=t*x;r===Math.min(p-1,o?Math.round(s):Math.floor(s))&&(i+=g[a+n])}}f[s+n]=i}}}}return n.makeTensorInfo(a.shape,a.dtype,f)}const resizeNearestNeighborGradConfig$4={kernelName:ResizeNearestNeighborGrad$1,backendName:"cpu",kernelFunc:resizeNearestNeighborGrad$3};function reverse$4(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{dims:s}=r;assertNotComplex$3(a,"reverse");const o=a.shape.length,i=parseAxisParam$1(s,a.shape);if(0===o)return identity$4({inputs:{x:a},backend:n});const l=new TensorBuffer$1(a.shape,a.dtype),u=n.bufferSync(a);for(let e=0;e<l.size;e++){const t=l.indexToLoc(e),n=t.slice();i.forEach(e=>n[e]=a.shape[e]-1-n[e]),l.set(u.get(...n),...t)}return n.makeTensorInfo(l.shape,l.dtype,l.values)}const reverseConfig$3={kernelName:Reverse$1,backendName:"cpu",kernelFunc:reverse$4},rotateWithOffsetConfig$3={kernelName:RotateWithOffset$1,backendName:"cpu",kernelFunc:({inputs:e,attrs:t,backend:n})=>{const{image:r}=e,{radians:a,fillValue:s,center:o}=t,i=n,l=getTypedArrayFromDType$1(r.dtype,sizeFromShape$1(r.shape)),[u,c,p,d]=r.shape,[h,m]=getImageCenter$1(o,c,p),f=Math.sin(a),g=Math.cos(a),$=i.data.get(r.dataId).values;for(let e=0;e<u;e++){const t=e*p*c*d;for(let e=0;e<c;e++){const n=e*(p*d);for(let r=0;r<p;r++){const a=r*d;for(let o=0;o<d;o++){const i=[u,e,r,o],y=i[2],b=i[1];let x=(y-h)*g-(b-m)*f,v=(y-h)*f+(b-m)*g;x=Math.round(x+h),v=Math.round(v+m);let I=s;"number"!=typeof s&&(I=3===o?255:s[o]),x>=0&&x<p&&v>=0&&v<c&&(I=$[t+v*(p*d)+x*d+o]),l[t+n+a+o]=I}}}}return{dataId:i.write(l,r.shape,r.dtype),shape:r.shape,dtype:r.dtype}}},round$5=unaryKernelFunc$3(Round$1,e=>{const t=Math.floor(e);return e-t<.5?Math.floor(e):e-t>.5?Math.ceil(e):t%2==0?t:t+1}),roundConfig$3={kernelName:Round$1,backendName:"cpu",kernelFunc:round$5};function scatterImpl$1(e,t,n,r,a,s,o,i,l,u){const c=[r/a,a],p=e.values,d=t.values;if(0===r)return buffer$1(n,t.dtype);const h=buffer$1(c,t.dtype);h.values.fill(l);for(let e=0;e<s;e++){const s=[];let l=0;for(let t=0;t<o;t++){const n=p[e*o+t];s.push(n),l+=n*i[t]}if(l<0||l>=r/a)throw new Error(`Invalid indices: ${s} does not index into ${n}`);for(let n=0;n<a;n++)u?h.values[l*a+n]+=d[e*a+n]:h.values[l*a+n]=0===t.rank?d[0]:d[e*a+n]}return h}function scatterNd$3(e){const{inputs:t,backend:n,attrs:r}=e,{indices:a,updates:s}=t,{shape:o}=r,{sliceRank:i,numUpdates:l,sliceSize:u,strides:c,outputSize:p}=calculateShapes$1(s,a,o),d=scatterImpl$1(n.bufferSync(a),n.bufferSync(s),o,p,u,l,i,c,0,!0);return n.makeTensorInfo(o,d.dtype,d.values)}const scatterNdConfig$3={kernelName:ScatterNd$1,backendName:"cpu",kernelFunc:scatterNd$3};function select$4(e){const{inputs:t,backend:n}=e,{condition:r,t:a,e:s}=t;assertNotComplex$3([r,a,s],"select");const o=r.shape.length,i=n.data.get(r.dataId).values,l=n.data.get(a.dataId).values,u=n.data.get(s.dataId).values,c=upcastType$1(a.dtype,s.dtype),p=makeZerosTypedArray$1(sizeFromShape$1(a.shape),c);let d=0;const h=0===o||o>1||1===a.shape.length?1:sizeFromShape$1(a.shape.slice(1));for(let e=0;e<i.length;e++)for(let t=0;t<h;t++)p[d++]=1===i[e]?l[e]:u[e];return n.makeTensorInfo(a.shape,c,p)}const selectConfig$3={kernelName:Select$1,backendName:"cpu",kernelFunc:select$4},scaleAlpha$1=SELU_SCALEALPHA$1,scale$1=SELU_SCALE$1,selu$4=unaryKernelFunc$3(Selu$3,e=>e>=0?scale$1*e:scaleAlpha$1*(Math.exp(e)-1)),seluConfig$3={kernelName:Selu$3,backendName:"cpu",kernelFunc:selu$4},sign$4=unaryKernelFunc$3(Sign$1,e=>e<0?-1:e>0?1:0),signConfig$3={kernelName:Sign$1,backendName:"cpu",kernelFunc:sign$4},sin$4=unaryKernelFunc$3(Sin$1,e=>Math.sin(e)),sinConfig$3={kernelName:Sin$1,backendName:"cpu",kernelFunc:sin$4},sinh$4=unaryKernelFunc$3(Sinh$1,e=>Math.sinh(e)),sinhConfig$3={kernelName:Sinh$1,backendName:"cpu",kernelFunc:sinh$4},epsilon$2=1.1920928955078125e-7,threshold$2=Math.log(epsilon$2)+2,softplus$4=unaryKernelFunc$3(Softplus$3,e=>{const t=e>-threshold$2,n=e<threshold$2,r=Math.exp(e);let a;return a=n?r:t?e:Math.log(1+r),a}),softplusConfig$3={kernelName:Softplus$3,backendName:"cpu",kernelFunc:softplus$4};function spaceToBatchND$4(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{blockShape:s,paddings:o}=r;assertNotComplex$3([a],"spaceToBatchND");const i=sizeFromShape$1(s),l=[[0,0]];l.push(...o);for(let e=1+s.length;e<a.shape.length;++e)l.push([0,0]);const u=padV2Config$3.kernelFunc({inputs:{x:a},backend:n,attrs:{paddings:l,constantValue:0}}),c=getReshaped$1(u.shape,s,i,!1),p=getPermuted$1(c.length,s.length,!1),d=getReshapedPermuted$1(u.shape,s,i,!1),h=reshape$5({inputs:{x:u},backend:n,attrs:{shape:c}}),m=transpose$4({inputs:{x:h},backend:n,attrs:{perm:p}}),f=reshape$5({inputs:{x:m},backend:n,attrs:{shape:d}});return n.disposeIntermediateTensorInfo(u),n.disposeIntermediateTensorInfo(h),n.disposeIntermediateTensorInfo(m),f}const spaceToBatchNDConfig$3={kernelName:SpaceToBatchND$1,backendName:"cpu",kernelFunc:spaceToBatchND$4};function sparseFillEmptyRows$4(e){const{inputs:t,backend:n}=e,{indices:r,values:a,denseShape:s,defaultValue:o}=t;if(1!==s.shape.length)throw new Error(`Dense shape must be a vector, saw:\n        ${s.shape}`);if(2!==r.shape.length)throw new Error(`Indices must be a matrix, saw:\n        ${r.shape}`);if(1!==a.shape.length)throw new Error(`Values must be a vector, saw:\n        ${a.shape}`);if(0!==o.shape.length)throw new Error(`Default value must be a scalar, saw:\n        ${o.shape}`);const i=n.data.get(r.dataId).values,l=n.data.get(a.dataId).values,u=n.data.get(s.dataId).values,c=n.data.get(o.dataId).values[0],[p,d,h,m,f]=sparseFillEmptyRowsImpl$1(i,r.shape,r.dtype,l,a.dtype,u,c);return[n.makeTensorInfo(d,r.dtype,p),n.makeTensorInfo([d[0]],a.dtype,h),n.makeTensorInfo([m.length],"bool",new Uint8Array(m.map(e=>Number(e)))),n.makeTensorInfo([f.length],r.dtype,new Int32Array(f))]}const sparseFillEmptyRowsConfig$3={kernelName:SparseFillEmptyRows$1,backendName:"cpu",kernelFunc:sparseFillEmptyRows$4};function sparseReshape$4(e){const{inputs:t,backend:n}=e,{inputIndices:r,inputShape:a,newShape:s}=t;if(2!==r.shape.length)throw new Error(`Input indices should be a matrix but received shape\n        ${r.shape}`);if(1!==a.shape.length)throw new Error(`Input shape should be a vector but received shape\n        ${a.shape}`);if(1!==s.shape.length)throw new Error(`Target shape should be a vector but received shape ${s.shape}`);const o=Array.from(n.data.get(a.dataId).values),i=n.data.get(r.dataId).values,l=Array.from(n.data.get(s.dataId).values),[u,c,p]=sparseReshapeImpl$1(i,r.shape,r.dtype,o,l);return[n.makeTensorInfo(c,r.dtype,u),n.makeTensorInfo([p.length],s.dtype,new Int32Array(p))]}const sparseReshapeConfig$3={kernelName:SparseReshape$1,backendName:"cpu",kernelFunc:sparseReshape$4};function sparseSegmentMean$4(e){const{inputs:t,backend:n}=e,{data:r,indices:a,segmentIds:s}=t;if(r.shape.length<1)throw new Error("Data should be at least 1 dimensional but received scalar");if(1!==a.shape.length)throw new Error(`Indices should be a vector but received shape\n          ${a.shape}`);if(1!==s.shape.length)throw new Error(`Segment ids should be a vector but received shape\n          ${s.shape}`);const o=n.data.get(r.dataId).values,i=n.data.get(a.dataId).values,l=n.data.get(s.dataId).values,[u,c]=sparseSegmentReductionImpl$1(o,r.shape,r.dtype,i,l,!0);return n.makeTensorInfo(c,r.dtype,u)}const sparseSegmentMeanConfig$3={kernelName:SparseSegmentMean$1,backendName:"cpu",kernelFunc:sparseSegmentMean$4};function sparseSegmentSum$4(e){const{inputs:t,backend:n}=e,{data:r,indices:a,segmentIds:s}=t;if(r.shape.length<1)throw new Error("Data should be at least 1 dimensional but received scalar");if(1!==a.shape.length)throw new Error(`Indices should be a vector but received shape\n         ${a.shape}`);if(1!==s.shape.length)throw new Error(`Segment ids should be a vector but received shape\n         ${s.shape}`);const o=n.data.get(r.dataId).values,i=n.data.get(a.dataId).values,l=n.data.get(s.dataId).values,[u,c]=sparseSegmentReductionImpl$1(o,r.shape,r.dtype,i,l);return n.makeTensorInfo(c,r.dtype,u)}const sparseSegmentSumConfig$3={kernelName:SparseSegmentSum$1,backendName:"cpu",kernelFunc:sparseSegmentSum$4};function sparseToDense$4(e){const{inputs:t,backend:n,attrs:r}=e,{sparseIndices:a,sparseValues:s,defaultValue:o}=t,{outputShape:i}=r,{sliceRank:l,numUpdates:u,sliceSize:c,strides:p,outputSize:d}=calculateShapes$1(s,a,i),h=scatterImpl$1(n.bufferSync(a),n.bufferSync(s),i,d,c,u,l,p,n.data.get(o.dataId).values[0],!1);return n.makeTensorInfo(i,h.dtype,h.values)}const sparseToDenseConfig$3={kernelName:SparseToDense$1,backendName:"cpu",kernelFunc:sparseToDense$4};function splitV$3(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{numOrSizeSplits:s,axis:o}=r,i=parseAxisParam$1(o,a.shape)[0],l=prepareSplitSize$1(a,s,i),u=new Array(a.shape.length).fill(0),c=a.shape.slice();return l.map(e=>{const t=[...c];t[i]=e;const r=slice$4({inputs:{x:a},backend:n,attrs:{begin:u,size:t}});return u[i]+=e,r})}const splitVConfig$3={kernelName:SplitV$1,backendName:"cpu",kernelFunc:splitV$3},sqrt$4=unaryKernelFunc$3(Sqrt$1,e=>Math.sqrt(e)),sqrtConfig$3={kernelName:Sqrt$1,backendName:"cpu",kernelFunc:sqrt$4},squareConfig$3={kernelName:Square$1,backendName:"cpu",kernelFunc:({inputs:e,backend:t})=>{const{x:n}=e,r=t;assertNotComplex$3(n,"square");const a=r.data.get(n.dataId).values,s=new Float32Array(a.length);for(let e=0;e<a.length;++e){const t=a[e];s[e]=t*t}return{dataId:r.write(s,n.shape,n.dtype),shape:n.shape,dtype:n.dtype}}},step$4=unaryKernelFunc$3(Step$1,(e,t)=>{const n=t;return isNaN(e)?NaN:e>0?1:n.alpha}),stepConfig$3={kernelName:Step$1,backendName:"cpu",kernelFunc:step$4};function stridedSlice$4(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{begin:s,end:o,strides:i,beginMask:l,endMask:u,ellipsisMask:c,newAxisMask:p,shrinkAxisMask:d}=r;assertNotComplex$3(a,"stridedSlice");const{nonStrided:h,$begin:m,$strides:f,size:g,newShape:$,outShape:y}=sliceInfo$1(a.shape,s,o,i,l,u,c,p,d),b=reshape$5({inputs:{x:a},backend:n,attrs:{shape:$}});let x;if(h){const e=slice$4({inputs:{x:b},backend:n,attrs:{begin:m,size:g}});x=reshape$5({inputs:{x:e},backend:n,attrs:{shape:y}}),n.disposeIntermediateTensorInfo(e)}else if(y.some(e=>0===e))x=n.makeTensorInfo(y,a.dtype,[]);else{const e=stridedSliceImpl$1(y,n.bufferSync(b),f,m);x=n.makeTensorInfo(e.shape,e.dtype,e.values)}const v=reshape$5({inputs:{x},backend:n,attrs:{shape:y}});return n.disposeIntermediateTensorInfo(b),n.disposeIntermediateTensorInfo(x),v}const stridedSliceConfig$3={kernelName:StridedSlice$1,backendName:"cpu",kernelFunc:stridedSlice$4};function stringNGrams$4(e){const{inputs:t,backend:n,attrs:r}=e,{separator:a,nGramWidths:s,leftPad:o,rightPad:i,padWidth:l,preserveShortSequences:u}=r,{data:c,dataSplits:p}=t,d=n.data.get(c.dataId).values,h=n.data.get(p.dataId).values,[m,f]=stringNGramsImpl$1(d,h,a,s,o,i,l,u);return[n.makeTensorInfo([m.length],"string",m),n.makeTensorInfo(p.shape,"int32",f)]}const stringNGramsConfig$3={kernelName:StringNGrams$1,backendName:"cpu",kernelFunc:stringNGrams$4};function stringSplit$4(e){const{inputs:t,backend:n,attrs:r}=e,{skipEmpty:a}=r,{input:s,delimiter:o}=t;if("string"!==s.dtype)throw new Error("Input must be of datatype string");if(1!==s.shape.length)throw new Error(`Input must be a vector, got shape: ${s.shape}`);if(0!==o.shape.length)throw new Error(`Delimiter must be a scalar, got shape: ${o.shape}`);const i=n.data.get(s.dataId).values,l=n.data.get(o.dataId).values[0],[u,c,p]=stringSplitImpl$1(i,l,a),d=c.length;return[n.makeTensorInfo([d,2],"int32",u),n.makeTensorInfo([d],"string",c),n.makeTensorInfo([2],"int32",new Int32Array(p))]}const stringSplitConfig$3={kernelName:StringSplit$1,backendName:"cpu",kernelFunc:stringSplit$4};function stringToHashBucketFast$4(e){const{inputs:t,backend:n,attrs:r}=e,{numBuckets:a}=r,{input:s}=t;if("string"!==s.dtype)throw new Error("Input must be of datatype string");if(a<=0)throw new Error("Number of buckets must be at least 1");const o=stringToHashBucketFastImpl$1(n.data.get(s.dataId).values,a);return n.makeTensorInfo(s.shape,"int32",o)}const stringToHashBucketFastConfig$3={kernelName:StringToHashBucketFast$1,backendName:"cpu",kernelFunc:stringToHashBucketFast$4},tan$4=unaryKernelFunc$3(Tan$1,e=>Math.tan(e)),tanConfig$3={kernelName:Tan$1,backendName:"cpu",kernelFunc:tan$4},tanh$5=unaryKernelFunc$3(Tanh$3,e=>Math.tanh(e)),tanhConfig$3={kernelName:Tanh$3,backendName:"cpu",kernelFunc:tanh$5};function tile$5(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{reps:s}=r;assertNotComplex$3(a,"tile");const o=tileImpl$1(n.bufferSync(a),s);return n.makeTensorInfo(o.shape,o.dtype,o.values)}const tileConfig$3={kernelName:Tile$1,backendName:"cpu",kernelFunc:tile$5};function topK$3(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{k:s,sorted:o}=r;assertNotComplex$3(a,"topk");const i=n.data.get(a.dataId).values,[l,u]=topKImpl$1(i,a.shape,a.dtype,s,o);return[n.makeTensorInfo(l.shape,l.dtype,l.values),n.makeTensorInfo(u.shape,u.dtype,u.values)]}const topKConfig$3={kernelName:TopK$1,backendName:"cpu",kernelFunc:topK$3};function transform$4(e){const{inputs:t,attrs:n,backend:r}=e,{image:a,transforms:s}=t,{interpolation:o,fillMode:i,fillValue:l,outputShape:u}=n,[c,p,d,h]=a.shape,[m,f]=null!=u?u:[p,d],g=[c,m,f,h],$=computeStrides$1(a.shape),y=$[0],b=$[1],x=$[2],v=getTypedArrayFromDType$1(a.dtype,sizeFromShape$1(g));v.fill(l);const I=r.data.get(a.dataId).values,C=r.data.get(s.dataId).values;for(let e=0;e<c;++e){const t=1===s.shape[0]?C:C.subarray(8*e,8*e+8);for(let n=0;n<m;++n)for(let r=0;r<f;++r)for(let a=0;a<h;++a){let s;const u=t[6]*r+t[7]*n+1;if(0===u)continue;const c=(t[3]*r+t[4]*n+t[5])/u,h=mapCoord$1((t[0]*r+t[1]*n+t[2])/u,d,i),m=mapCoord$1(c,p,i);switch(o){case"nearest":s=nearestInterpolation$1(I,p,d,y,b,x,e,m,h,a,l);break;case"bilinear":s=bilinearInterpolation$1(I,p,d,y,b,x,e,m,h,a,l);break;default:throw new Error(`Error in Transform: Expect 'nearest' or 'bilinear', but got ${o}`)}v[e*y+n*b+r*x+a]=s}return r.makeTensorInfo(g,a.dtype,v)}return{dataId:r.write(v,g,a.dtype),shape:a.shape,dtype:a.dtype}}const transformConfig$3={kernelName:Transform$1,backendName:"cpu",kernelFunc:transform$4};function mapCoord$1(e,t,n){switch(n){case"reflect":return mapCoordReflect$1(e,t);case"wrap":return mapCoordWrap$1(e,t);case"nearest":return mapCoordNearest$1(e,t);case"constant":default:return mapCoordConstant$1(e)}}function mapCoordReflect$1(e,t){let n=e;if(n<0)if(t<=1)n=0;else{const e=2*t;n<e&&(n=e*Math.trunc(-n/e)+n),n=n<-t?n+e:-n-1}else if(n>t-1)if(t<=1)n=0;else{const e=2*t;n-=e*Math.trunc(n/e),n>=t&&(n=e-n-1)}return clamp$1(0,n,t-1)}function mapCoordWrap$1(e,t){let n=e;return n<0?t<=1?n=0:n+=t*(Math.trunc(-n/(t-1))+1):n>t-1&&(t<=1?n=0:n-=t*Math.trunc(n/(t-1))),clamp$1(0,n,t-1)}function mapCoordConstant$1(e,t){return e}function mapCoordNearest$1(e,t){return clamp$1(0,e,t-1)}function readWithFillValue$1(e,t,n,r,a,s,o,i,l,u,c){return 0<=i&&i<t&&0<=l&&l<n?e[o*r+i*a+l*s+u]:c}function nearestInterpolation$1(e,t,n,r,a,s,o,i,l,u,c){return readWithFillValue$1(e,t,n,r,a,s,o,Math.round(i),Math.round(l),u,c)}function bilinearInterpolation$1(e,t,n,r,a,s,o,i,l,u,c){const p=Math.floor(i),d=Math.floor(l),h=p+1,m=d+1;return(h-i)*((m-l)*readWithFillValue$1(e,t,n,r,a,s,o,p,d,u,c)+(l-d)*readWithFillValue$1(e,t,n,r,a,s,o,p,m,u,c))+(i-p)*((m-l)*readWithFillValue$1(e,t,n,r,a,s,o,h,d,u,c)+(l-d)*readWithFillValue$1(e,t,n,r,a,s,o,h,m,u,c))}function unique$5(e){const{inputs:t,attrs:n,backend:r}=e,{axis:a}=n,{x:s}=t;assertNotComplex$3(s,"unique");const o=r.data.get(s.dataId).values,{outputValues:i,outputShape:l,indices:u}=uniqueImpl$1(o,a,s.shape,s.dtype);return[r.makeTensorInfo(l,s.dtype,i),r.makeTensorInfo([u.length],"int32",u)]}const uniqueConfig$3={kernelName:Unique$1,backendName:"cpu",kernelFunc:unique$5};function unpack$3(e){const{inputs:t,backend:n,attrs:r}=e,{value:a}=t;let{axis:s}=r;s<0&&(s+=a.shape.length);const o=a.shape.length,i=a.shape[s],l=new Array(o-1);let u=0;for(let e=0;e<o;e++)e!==s&&(l[u++]=a.shape[e]);const c=new Array(o).fill(0),p=a.shape.slice();p[s]=1;const d=new Array(i);for(let e=0;e<d.length;e++){c[s]=e;const t=slice$4({inputs:{x:a},backend:n,attrs:{begin:c,size:p}});d[e]=reshape$5({inputs:{x:t},backend:n,attrs:{shape:l}}),n.disposeIntermediateTensorInfo(t)}return d}const unpackConfig$3={kernelName:Unpack$1,backendName:"cpu",kernelFunc:unpack$3};function unsortedSegmentSum$4(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,segmentIds:s}=t,{numSegments:o}=r;assertNotComplex$3(a,"unsortedSegmentSum");const i=[],l=[],u=a.shape.length-s.shape.length;let c=s;for(let e=0;e<u;++e){const t=expandDims$5({inputs:{input:c},backend:n,attrs:{dim:e+1}});c=t,l.push(t)}for(let e=0;e<o;++e){const t=createScalarValue$1(e,"int32"),r=n.makeTensorInfo([],"int32",t),s=equal$4({inputs:{a:r,b:c},backend:n}),o=cast$5({inputs:{x:s},backend:n,attrs:{dtype:"float32"}}),u=multiply$4({inputs:{a:o,b:a},backend:n}),p=sum$5({inputs:{x:u},backend:n,attrs:{axis:0,keepDims:!1}});i.push(p),l.push(r),l.push(s),l.push(o),l.push(u),l.push(p)}const p=pack$3({inputs:i,backend:n,attrs:{axis:0}});return l.forEach(e=>n.disposeIntermediateTensorInfo(e)),p}const unsortedSegmentSumConfig$3={kernelName:UnsortedSegmentSum$1,backendName:"cpu",kernelFunc:unsortedSegmentSum$4},kernelConfigs$3=[_fusedMatMulConfig$3,absConfig$3,acosConfig$3,acoshConfig$3,addConfig$3,addNConfig$3,allConfig$3,anyConfig$3,argMaxConfig$3,argMinConfig$3,asinConfig$3,asinhConfig$3,atanConfig$3,atan2Config$3,atanhConfig$3,avgPoolConfig$3,avgPool3DConfig$3,avgPool3DGradConfig$2,avgPoolGradConfig$4,batchMatMulConfig$3,batchNormConfig$3,batchToSpaceNDConfig$3,bincountConfig$3,castConfig$3,ceilConfig$3,clipConfig$1,complexConfig$3,complexAbsConfig$3,concatConfig$3,conv2DBackpropFilterConfig$3,conv2DBackpropInputConfig$3,conv2DConfig$3,conv3DBackpropFilterV2Config$3,conv3DBackpropInputV2Config$1,conv3DConfig$3,cosConfig$3,coshConfig$3,cropAndResizeConfig$3,cumsumConfig$3,denseBincountConfig$3,depthToSpaceConfig$3,depthwiseConv2dNativeConfig$3,depthwiseConv2dNativeBackpropFilterConfig$3,depthwiseConv2dNativeBackpropInputConfig$3,diagConfig$3,dilation2dConfig$1,dilation2dBackpropInputConfig$1,dilation2dBackpropFilterConfig$1,realDivConfig$3,einsumConfig$3,eluConfig$3,eluGradConfig$4,equalConfig$3,erfConfig$3,expConfig$3,expandDimsConfig$3,expm1Config$3,fftConfig$3,fillConfig$3,flipLeftRightConfig$3,floorConfig$3,floorDivConfig$3,fusedConv2DConfig$3,fusedDepthwiseConv2DConfig$3,gatherNdConfig$3,gatherV2Config$3,greaterConfig$3,greaterEqualConfig$3,identityConfig$3,ifftConfig$3,imagConfig$3,isFiniteConfig$3,isInfConfig$3,isNaNConfig$3,leakyReluConfig$3,lessConfig$3,lessEqualConfig$3,linSpaceConfig$3,logConfig$3,log1pConfig$3,logicalAndConfig$3,logicalNotConfig$3,logicalOrConfig$3,lRNConfig$1,lRNGradConfig$1,maximumConfig$3,maxPoolConfig$3,maxPool3DConfig$3,maxPool3DGradConfig$2,maxPoolGradConfig$4,maxPoolWithArgmaxConfig$3,maxConfig$3,meanConfig$3,minConfig$3,minimumConfig$3,mirrorPadConfig$3,modConfig$3,multinomialConfig$3,multiplyConfig$3,negConfig$3,nonMaxSuppressionV3Config$3,nonMaxSuppressionV4Config$3,nonMaxSuppressionV5Config$3,notEqualConfig$3,oneHotConfig$3,onesLikeConfig$3,packConfig$3,padV2Config$3,powConfig$3,preluConfig$3,prodConfig$3,rangeConfig$3,realConfig$3,reciprocalConfig$3,reluConfig$3,relu6Config$3,reshapeConfig$3,resizeBilinearConfig$3,resizeBilinearGradConfig$4,resizeNearestNeighborConfig$3,resizeNearestNeighborGradConfig$4,reverseConfig$3,rotateWithOffsetConfig$3,roundConfig$3,rsqrtConfig$3,scatterNdConfig$3,selectConfig$3,seluConfig$3,sigmoidConfig$3,signConfig$3,sinConfig$3,sinhConfig$3,sliceConfig$3,softmaxConfig$3,softplusConfig$3,spaceToBatchNDConfig$3,sparseFillEmptyRowsConfig$3,sparseReshapeConfig$3,sparseSegmentMeanConfig$3,sparseSegmentSumConfig$3,sparseToDenseConfig$3,splitVConfig$3,sqrtConfig$3,squareConfig$3,squaredDifferenceConfig$3,stepConfig$3,stridedSliceConfig$3,stringNGramsConfig$3,stringSplitConfig$3,stringToHashBucketFastConfig$3,subConfig$3,sumConfig$3,tanConfig$3,tanhConfig$3,tileConfig$3,topKConfig$3,transposeConfig$3,transformConfig$3,uniqueConfig$3,unpackConfig$3,unsortedSegmentSumConfig$3,zerosLikeConfig$3];for(const e of kernelConfigs$3)registerKernel$1(e);const contexts$1={},WEBGL_ATTRIBUTES$1={alpha:!1,antialias:!1,premultipliedAlpha:!1,preserveDrawingBuffer:!1,depth:!1,stencil:!1,failIfMajorPerformanceCaveat:!0};function setWebGLContext$1(e,t){contexts$1[e]=t}function getWebGLContext$1(e){if(!(e in contexts$1)){const t=getWebGLRenderingContext$1(e);if(null===t)return console.log("Could not get context for WebGL version",e),null;contexts$1[e]=t}const t=contexts$1[e];return t.isContextLost()?(delete contexts$1[e],getWebGLContext$1(e)):(t.disable(t.DEPTH_TEST),t.disable(t.STENCIL_TEST),t.disable(t.BLEND),t.disable(t.DITHER),t.disable(t.POLYGON_OFFSET_FILL),t.disable(t.SAMPLE_COVERAGE),t.enable(t.SCISSOR_TEST),t.enable(t.CULL_FACE),t.cullFace(t.BACK),contexts$1[e])}function createCanvas$1(e){if("undefined"!=typeof OffscreenCanvas&&2===e)return new OffscreenCanvas(300,150);if("undefined"!=typeof document)return document.createElement("canvas");throw new Error("Cannot create a canvas in this context")}function getWebGLRenderingContext$1(e){if(1!==e&&2!==e)throw new Error("Cannot get WebGL rendering context, WebGL is disabled.");const t=createCanvas$1(e);return t.addEventListener("webglcontextlost",t=>{t.preventDefault(),delete contexts$1[e]},!1),1===e?t.getContext("webgl",WEBGL_ATTRIBUTES$1)||t.getContext("experimental-webgl",WEBGL_ATTRIBUTES$1):t.getContext("webgl2",WEBGL_ATTRIBUTES$1)}var PackingScheme$1,TextureUsage$1,PhysicalTextureType$1;function getUnpackedMatrixTextureShapeWidthHeight$1(e,t){return[t,e]}function getUnpackedArraySizeFromMatrixSize$1(e,t){return e*t}function getDenseTexShape$1(e){const t=sizeFromShape$1(e);return sizeToSquarishShape$1(Math.ceil(t/4))}function getPackedMatrixTextureShapeWidthHeight$1(e,t){return[Math.max(1,Math.ceil(t/2)),Math.max(1,Math.ceil(e/2))]}function getPackedRGBAArraySizeFromMatrixShape$1(e,t){const[n,r]=getPackedMatrixTextureShapeWidthHeight$1(e,t);return n*r*4}function getTextureConfig$1(e,t){const n=e;let r,a,s,o,i,l,u,c,p,d;return 2===env$1().getNumber("WEBGL_VERSION")?(r=n.R32F,a=n.R16F,s=n.RGBA16F,o=n.RGBA32F,i=n.RED,u=4,c=1,p=n.HALF_FLOAT,d=n.FLOAT):(r=e.RGBA,a=e.RGBA,s=e.RGBA,o=n.RGBA,i=e.RGBA,u=4,c=4,p=null!=t?t.HALF_FLOAT_OES:null,d=e.FLOAT),l=e.RGBA,{internalFormatFloat:r,internalFormatHalfFloat:a,internalFormatPackedHalfFloat:s,internalFormatPackedFloat:o,textureFormatFloat:i,downloadTextureFormat:l,downloadUnpackNumChannels:u,defaultNumChannels:c,textureTypeHalfFloat:p,textureTypeFloat:d}}function callAndCheck$1(e,t){const n=t();return env$1().getBool("DEBUG")&&checkWebGLError$1(e),n}function checkWebGLError$1(e){const t=e.getError();if(t!==e.NO_ERROR)throw new Error("WebGL Error: "+getWebGLErrorMessage$1(e,t))}!function(e){e[e.DENSE=0]="DENSE",e[e.SHARED_BATCH=1]="SHARED_BATCH"}(PackingScheme$1||(PackingScheme$1={})),function(e){e[e.RENDER=0]="RENDER",e[e.UPLOAD=1]="UPLOAD",e[e.PIXELS=2]="PIXELS",e[e.DOWNLOAD=3]="DOWNLOAD"}(TextureUsage$1||(TextureUsage$1={})),function(e){e[e.UNPACKED_FLOAT16=0]="UNPACKED_FLOAT16",e[e.UNPACKED_FLOAT32=1]="UNPACKED_FLOAT32",e[e.PACKED_4X1_UNSIGNED_BYTE=2]="PACKED_4X1_UNSIGNED_BYTE",e[e.PACKED_2X2_FLOAT32=3]="PACKED_2X2_FLOAT32",e[e.PACKED_2X2_FLOAT16=4]="PACKED_2X2_FLOAT16"}(PhysicalTextureType$1||(PhysicalTextureType$1={}));const MIN_FLOAT16$1=5.96e-8,MAX_FLOAT16$1=65504;function canBeRepresented$1(e){return!!(env$1().getBool("WEBGL_RENDER_FLOAT32_ENABLED")||0===e||MIN_FLOAT16$1<Math.abs(e)&&Math.abs(e)<MAX_FLOAT16$1)}function getWebGLErrorMessage$1(e,t){switch(t){case e.NO_ERROR:return"NO_ERROR";case e.INVALID_ENUM:return"INVALID_ENUM";case e.INVALID_VALUE:return"INVALID_VALUE";case e.INVALID_OPERATION:return"INVALID_OPERATION";case e.INVALID_FRAMEBUFFER_OPERATION:return"INVALID_FRAMEBUFFER_OPERATION";case e.OUT_OF_MEMORY:return"OUT_OF_MEMORY";case e.CONTEXT_LOST_WEBGL:return"CONTEXT_LOST_WEBGL";default:return`Unknown error code ${t}`}}function getExtensionOrThrow$1(e,t){return throwIfNull$1(e,()=>e.getExtension(t),'Extension "'+t+'" not supported on this browser.')}function createVertexShader$3(e,t){const n=throwIfNull$1(e,()=>e.createShader(e.VERTEX_SHADER),"Unable to create vertex WebGLShader.");if(callAndCheck$1(e,()=>e.shaderSource(n,t)),callAndCheck$1(e,()=>e.compileShader(n)),!1===e.getShaderParameter(n,e.COMPILE_STATUS))throw console.log(e.getShaderInfoLog(n)),new Error("Failed to compile vertex shader.");return n}function createFragmentShader$1(e,t){const n=throwIfNull$1(e,()=>e.createShader(e.FRAGMENT_SHADER),"Unable to create fragment WebGLShader.");if(callAndCheck$1(e,()=>e.shaderSource(n,t)),callAndCheck$1(e,()=>e.compileShader(n)),!1===e.getShaderParameter(n,e.COMPILE_STATUS))throw logShaderSourceAndInfoLog$1(t,e.getShaderInfoLog(n)),new Error("Failed to compile fragment shader.");return n}const lineNumberRegex$1=/ERROR: [0-9]+:([0-9]+):/g;function logShaderSourceAndInfoLog$1(e,t){const n=lineNumberRegex$1.exec(t);if(null==n)return console.log(`Couldn't parse line number in error: ${t}`),void console.log(e);const r=+n[1],a=e.split("\n"),s=a.length.toString().length+2,o=a.map((e,t)=>rightPad$1((t+1).toString(),s)+e);let i=0;for(let e=0;e<o.length;e++)i=Math.max(o[e].length,i);const l=o.slice(0,r-1),u=o.slice(r-1,r),c=o.slice(r);console.log(l.join("\n")),console.log(t.split("\n")[0]),console.log(`%c ${rightPad$1(u[0],i)}`,"border:1px solid red; background-color:#e3d2d2; color:#a61717"),console.log(c.join("\n"))}function createProgram$1(e){return throwIfNull$1(e,()=>e.createProgram(),"Unable to create WebGLProgram.")}function linkProgram$1(e,t){if(callAndCheck$1(e,()=>e.linkProgram(t)),!1===e.getProgramParameter(t,e.LINK_STATUS))throw console.log(e.getProgramInfoLog(t)),new Error("Failed to link vertex and fragment shaders.")}function validateProgram$1(e,t){if(callAndCheck$1(e,()=>e.validateProgram(t)),!1===e.getProgramParameter(t,e.VALIDATE_STATUS))throw console.log(e.getProgramInfoLog(t)),new Error("Shader program validation failed.")}function createStaticVertexBuffer$1(e,t){const n=throwIfNull$1(e,()=>e.createBuffer(),"Unable to create WebGLBuffer");return callAndCheck$1(e,()=>e.bindBuffer(e.ARRAY_BUFFER,n)),callAndCheck$1(e,()=>e.bufferData(e.ARRAY_BUFFER,t,e.STATIC_DRAW)),n}function createStaticIndexBuffer$1(e,t){const n=throwIfNull$1(e,()=>e.createBuffer(),"Unable to create WebGLBuffer");return callAndCheck$1(e,()=>e.bindBuffer(e.ELEMENT_ARRAY_BUFFER,n)),callAndCheck$1(e,()=>e.bufferData(e.ELEMENT_ARRAY_BUFFER,t,e.STATIC_DRAW)),n}function createTexture$1(e){return throwIfNull$1(e,()=>e.createTexture(),"Unable to create WebGLTexture.")}function validateTextureSize$1(e,t){const n=env$1().getNumber("WEBGL_MAX_TEXTURE_SIZE");if(e<=0||t<=0)throw new Error(`Requested texture size [${e}x${t}] is invalid.`);if(e>n||t>n)throw new Error(`Requested texture size [${e}x${t}] greater than WebGL maximum on this browser / GPU [${n}x${n}].`)}function createFramebuffer$1(e){return throwIfNull$1(e,()=>e.createFramebuffer(),"Unable to create WebGLFramebuffer.")}function bindVertexBufferToProgramAttribute$1(e,t,n,r,a,s,o){const i=e.getAttribLocation(t,n);return-1!==i&&(callAndCheck$1(e,()=>e.bindBuffer(e.ARRAY_BUFFER,r)),callAndCheck$1(e,()=>e.vertexAttribPointer(i,a,e.FLOAT,!1,s,o)),callAndCheck$1(e,()=>e.enableVertexAttribArray(i)),!0)}function bindTextureUnit$1(e,t,n){validateTextureUnit$1(e,n),callAndCheck$1(e,()=>e.activeTexture(e.TEXTURE0+n)),callAndCheck$1(e,()=>e.bindTexture(e.TEXTURE_2D,t))}function getProgramUniformLocationOrThrow$1(e,t,n){return throwIfNull$1(e,()=>e.getUniformLocation(t,n),'uniform "'+n+'" not present in program.')}function getProgramUniformLocation$1(e,t,n){return e.getUniformLocation(t,n)}function bindTextureToProgramUniformSampler$1(e,t,n,r){callAndCheck$1(e,()=>bindTextureUnit$1(e,t,r)),callAndCheck$1(e,()=>e.uniform1i(n,r))}function bindColorTextureToFramebuffer$1(e,t,n){callAndCheck$1(e,()=>e.bindFramebuffer(e.FRAMEBUFFER,n)),callAndCheck$1(e,()=>e.framebufferTexture2D(e.FRAMEBUFFER,e.COLOR_ATTACHMENT0,e.TEXTURE_2D,t,0))}function unbindColorTextureFromFramebuffer$1(e,t){callAndCheck$1(e,()=>e.bindFramebuffer(e.FRAMEBUFFER,t)),callAndCheck$1(e,()=>e.framebufferTexture2D(e.FRAMEBUFFER,e.COLOR_ATTACHMENT0,e.TEXTURE_2D,null,0))}function validateFramebuffer$1(e){const t=e.checkFramebufferStatus(e.FRAMEBUFFER);if(t!==e.FRAMEBUFFER_COMPLETE)throw new Error("Error binding framebuffer: "+getFramebufferErrorMessage$1(e,t))}function getFramebufferErrorMessage$1(e,t){switch(t){case e.FRAMEBUFFER_INCOMPLETE_ATTACHMENT:return"FRAMEBUFFER_INCOMPLETE_ATTACHMENT";case e.FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT:return"FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT";case e.FRAMEBUFFER_INCOMPLETE_DIMENSIONS:return"FRAMEBUFFER_INCOMPLETE_DIMENSIONS";case e.FRAMEBUFFER_UNSUPPORTED:return"FRAMEBUFFER_UNSUPPORTED";default:return`unknown error ${t}`}}function throwIfNull$1(e,t,n){const r=callAndCheck$1(e,()=>t());if(null==r)throw new Error(n);return r}function validateTextureUnit$1(e,t){const n=e.MAX_COMBINED_TEXTURE_IMAGE_UNITS-1,r=t+e.TEXTURE0;if(r<e.TEXTURE0||r>n)throw new Error(`textureUnit must be in [gl.TEXTURE0, gl.TEXTURE${n}].`)}function getBatchDim$1(e,t=2){return sizeFromShape$1(e.slice(0,e.length-t))}function getRowsCols$1(e){if(0===e.length)throw Error("Cannot get rows and columns of an empty shape array.");return[e.length>1?e[e.length-2]:1,e[e.length-1]]}function getShapeAs3D$1(e){let t=[1,1,1];return 0===e.length||1===e.length&&1===e[0]||(t=[getBatchDim$1(e),...getRowsCols$1(e)]),t}function getTextureShapeFromLogicalShape$1(e,t=!1){let n=env$1().getNumber("WEBGL_MAX_TEXTURE_SIZE");if(t&&(n*=2,1===(e=e.map((t,n)=>n>=e.length-2?nearestLargerEven$1(e[n]):e[n])).length&&(e=[2,e[0]])),2!==e.length){const t=squeezeShape$1(e);e=t.newShape}let r=sizeFromShape$1(e);if(e.length<=1&&r<=n)return[1,r];if(2===e.length&&e[0]<=n&&e[1]<=n)return e;if(3===e.length&&e[0]*e[1]<=n&&e[2]<=n)return[e[0]*e[1],e[2]];if(3===e.length&&e[0]<=n&&e[1]*e[2]<=n)return[e[0],e[1]*e[2]];if(4===e.length&&e[0]*e[1]*e[2]<=n&&e[3]<=n)return[e[0]*e[1]*e[2],e[3]];if(4===e.length&&e[0]<=n&&e[1]*e[2]*e[3]<=n)return[e[0],e[1]*e[2]*e[3]];if(t){const t=getBatchDim$1(e);let n=2,a=2;return e.length&&([n,a]=getRowsCols$1(e)),r=t*(n/2)*(a/2),sizeToSquarishShape$1(r).map(e=>2*e)}return sizeToSquarishShape$1(r)}function isEven$1(e){return e%2==0}function isReshapeFree$1(e,t){if(arraysEqual$1(e=e.slice(-2),t=t.slice(-2)))return!0;if(!e.length||!t.length)return!0;if(0===e[0]||0===e[1]||0===t[0]||0===t[1])return!0;if(e.length!==t.length){const n=e.slice(-1)[0],r=t.slice(-1)[0];if(n===r)return!0;if(isEven$1(n)&&isEven$1(r)&&(1===e[0]||1===t[0]))return!0}return e[1]===t[1]&&isEven$1(e[0])&&isEven$1(t[0])}let MAX_TEXTURE_SIZE$1,MAX_TEXTURES_IN_SHADER$1;function getWebGLMaxTextureSize$1(e){if(null==MAX_TEXTURE_SIZE$1){const t=getWebGLContext$1(e);MAX_TEXTURE_SIZE$1=t.getParameter(t.MAX_TEXTURE_SIZE)}return MAX_TEXTURE_SIZE$1}function getMaxTexturesInShader$1(e){if(null==MAX_TEXTURES_IN_SHADER$1){const t=getWebGLContext$1(e);MAX_TEXTURES_IN_SHADER$1=t.getParameter(t.MAX_TEXTURE_IMAGE_UNITS)}return Math.min(16,MAX_TEXTURES_IN_SHADER$1)}function getWebGLDisjointQueryTimerVersion$1(e){if(0===e)return 0;let t;const n=getWebGLContext$1(e);return t=hasExtension$1(n,"EXT_disjoint_timer_query_webgl2")&&2===e?2:hasExtension$1(n,"EXT_disjoint_timer_query")?1:0,t}function hasExtension$1(e,t){return null!=e.getExtension(t)}function isWebGLVersionEnabled$1(e){try{if(null!=getWebGLContext$1(e))return!0}catch(e){return console.log("Error when getting WebGL context: ",e),!1}return!1}function isCapableOfRenderingToFloatTexture$1(e){if(0===e)return!1;const t=getWebGLContext$1(e);if(1===e){if(!hasExtension$1(t,"OES_texture_float"))return!1}else if(!hasExtension$1(t,"EXT_color_buffer_float"))return!1;return createFloatTextureAndBindToFramebuffer$1(t)}function isDownloadFloatTextureEnabled$1(e){if(0===e)return!1;const t=getWebGLContext$1(e);if(1!==e){if(hasExtension$1(t,"EXT_color_buffer_float"))return createFloatTextureAndBindToFramebuffer$1(t);const e="EXT_color_buffer_half_float";if(hasExtension$1(t,e)){const n=t.getExtension(e);return createHalfFloatTextureAndBindToFramebuffer$1(t,n)}return!1}return!!hasExtension$1(t,"OES_texture_float")&&!!hasExtension$1(t,"WEBGL_color_buffer_float")&&createFloatTextureAndBindToFramebuffer$1(t)}function createFloatTextureAndBindToFramebuffer$1(e){const t=getTextureConfig$1(e),n=e.createTexture();e.bindTexture(e.TEXTURE_2D,n),e.texImage2D(e.TEXTURE_2D,0,t.internalFormatFloat,1,1,0,t.textureFormatFloat,t.textureTypeFloat,null);const r=e.createFramebuffer();e.bindFramebuffer(e.FRAMEBUFFER,r),e.framebufferTexture2D(e.FRAMEBUFFER,e.COLOR_ATTACHMENT0,e.TEXTURE_2D,n,0);const a=e.checkFramebufferStatus(e.FRAMEBUFFER)===e.FRAMEBUFFER_COMPLETE;return e.bindTexture(e.TEXTURE_2D,null),e.bindFramebuffer(e.FRAMEBUFFER,null),e.deleteTexture(n),e.deleteFramebuffer(r),a}function createHalfFloatTextureAndBindToFramebuffer$1(e,t){const n=getTextureConfig$1(e,t),r=e.createTexture();e.bindTexture(e.TEXTURE_2D,r),e.texImage2D(e.TEXTURE_2D,0,n.internalFormatHalfFloat,1,1,0,n.textureFormatFloat,n.textureTypeHalfFloat,null);const a=e.createFramebuffer();e.bindFramebuffer(e.FRAMEBUFFER,a),e.framebufferTexture2D(e.FRAMEBUFFER,e.COLOR_ATTACHMENT0,e.TEXTURE_2D,r,0);const s=e.checkFramebufferStatus(e.FRAMEBUFFER)===e.FRAMEBUFFER_COMPLETE;return e.bindTexture(e.TEXTURE_2D,null),e.bindFramebuffer(e.FRAMEBUFFER,null),e.deleteTexture(r),e.deleteFramebuffer(a),s}function isWebGLFenceEnabled$1(e){return 2===e&&null!=getWebGLContext$1(e).fenceSync}function assertNotComplex$2(e,t){Array.isArray(e)||(e=[e]),e.forEach(e=>{null!=e&&assert$6("complex64"!==e.dtype,()=>`${t} does not support complex64 tensors in the WebGL backend.`)})}const ENV$3=env$1();function getGlslDifferences$1(){let e,t,n,r,a,s,o,i,l,u;return 2===env$1().getNumber("WEBGL_VERSION")?(e="#version 300 es",t="in",n="out",r="in",a="texture",s="outputColor",o="out vec4 outputColor;",i="\n      bool isnan_custom(float val) {\n        return (val > 0.0 || val < 0.0) ? false : val != 0.0;\n      }\n\n      bvec4 isnan_custom(vec4 val) {\n        return bvec4(isnan_custom(val.x),\n          isnan_custom(val.y), isnan_custom(val.z), isnan_custom(val.w));\n      }\n\n      #define isnan(value) isnan_custom(value)\n    ",l="",u="\n      #define round(value) newRound(value)\n      int newRound(float value) {\n        return int(floor(value + 0.5));\n      }\n\n      ivec4 newRound(vec4 value) {\n        return ivec4(floor(value + vec4(0.5)));\n      }\n    "):(e="",t="attribute",n="varying",r="varying",a="texture2D",s="gl_FragColor",o="",i="\n      #define isnan(value) isnan_custom(value)\n      bool isnan_custom(float val) {\n        return (val > 0. || val < 1. || val == 0.) ? false : true;\n      }\n      bvec4 isnan_custom(vec4 val) {\n        return bvec4(isnan(val.x), isnan(val.y), isnan(val.z), isnan(val.w));\n      }\n    ",l="\n      uniform float INFINITY;\n\n      bool isinf(float val) {\n        return abs(val) == INFINITY;\n      }\n      bvec4 isinf(vec4 val) {\n        return equal(abs(val), vec4(INFINITY));\n      }\n    ",u="\n      int round(float value) {\n        return int(floor(value + 0.5));\n      }\n\n      ivec4 round(vec4 value) {\n        return ivec4(floor(value + vec4(0.5)));\n      }\n    "),{version:e,attribute:t,varyingVs:n,varyingFs:r,texture2D:a,output:s,defineOutput:o,defineSpecialNaN:i,defineSpecialInf:l,defineRound:u}}function getLogicalCoordinatesFromFlatIndex$1(e,t,n="index"){const r=computeStrides$1(t);return r.map((t,a)=>`int ${e[a]} = ${n} / ${t}; ${a===r.length-1?`int ${e[a+1]} = ${n} - ${e[a]} * ${t}`:`index -= ${e[a]} * ${t}`};`).join("")}function getLogicalCoordinatesFromFlatIndexByUniform$1(e,t,n="index"){const r=computeStrides$1(t);return r.map((t,a)=>`int ${e[a]} = ${n} / outShapeStrides[${a}]; ${a===r.length-1?`int ${e[a+1]} = ${n} - ${e[a]} * outShapeStrides[${a}]`:`index -= ${e[a]} * outShapeStrides[${a}]`};`).join("")}function getFlatIndexFrom3D$1(e){const t=computeStrides$1(e).map(e=>e.toString());return`\n  int getFlatIndex(ivec3 coords) {\n    return coords.x * ${t[0]} + coords.y * ${t[1]} + coords.z;\n  }\n`}ENV$3.registerFlag("HAS_WEBGL",()=>ENV$3.getNumber("WEBGL_VERSION")>0),ENV$3.registerFlag("WEBGL_VERSION",()=>isWebGLVersionEnabled$1(2)?2:isWebGLVersionEnabled$1(1)?1:0),ENV$3.registerFlag("WEBGL_CHECK_NUMERICAL_PROBLEMS",()=>!1),ENV$3.registerFlag("WEBGL_BUFFER_SUPPORTED",()=>2===ENV$3.get("WEBGL_VERSION")),ENV$3.registerFlag("WEBGL_CPU_FORWARD",()=>!0),ENV$3.registerFlag("WEBGL_FORCE_F16_TEXTURES",()=>!1),ENV$3.registerFlag("WEBGL_PACK",()=>ENV$3.getBool("HAS_WEBGL")),ENV$3.registerFlag("WEBGL_PACK_NORMALIZATION",()=>ENV$3.getBool("WEBGL_PACK")),ENV$3.registerFlag("WEBGL_PACK_CLIP",()=>ENV$3.getBool("WEBGL_PACK")),ENV$3.registerFlag("WEBGL_PACK_DEPTHWISECONV",()=>ENV$3.getBool("WEBGL_PACK")),ENV$3.registerFlag("WEBGL_PACK_BINARY_OPERATIONS",()=>ENV$3.getBool("WEBGL_PACK")),ENV$3.registerFlag("WEBGL_PACK_UNARY_OPERATIONS",()=>ENV$3.getBool("WEBGL_PACK")),ENV$3.registerFlag("WEBGL_PACK_ARRAY_OPERATIONS",()=>ENV$3.getBool("WEBGL_PACK")),ENV$3.registerFlag("WEBGL_PACK_IMAGE_OPERATIONS",()=>ENV$3.getBool("WEBGL_PACK")),ENV$3.registerFlag("WEBGL_PACK_REDUCE",()=>ENV$3.getBool("WEBGL_PACK")),ENV$3.registerFlag("WEBGL_LAZILY_UNPACK",()=>ENV$3.getBool("WEBGL_PACK")),ENV$3.registerFlag("WEBGL_CONV_IM2COL",()=>ENV$3.getBool("WEBGL_PACK")),ENV$3.registerFlag("WEBGL_MAX_TEXTURE_SIZE",()=>getWebGLMaxTextureSize$1(ENV$3.getNumber("WEBGL_VERSION"))),ENV$3.registerFlag("WEBGL_MAX_TEXTURES_IN_SHADER",()=>getMaxTexturesInShader$1(ENV$3.getNumber("WEBGL_VERSION"))),ENV$3.registerFlag("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION",()=>{const e=ENV$3.getNumber("WEBGL_VERSION");return 0===e?0:getWebGLDisjointQueryTimerVersion$1(e)}),ENV$3.registerFlag("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE",()=>ENV$3.getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")>0&&!isMobile$1()),ENV$3.registerFlag("WEBGL_RENDER_FLOAT32_CAPABLE",()=>isCapableOfRenderingToFloatTexture$1(ENV$3.getNumber("WEBGL_VERSION"))),ENV$3.registerFlag("WEBGL_RENDER_FLOAT32_ENABLED",()=>!ENV$3.getBool("WEBGL_FORCE_F16_TEXTURES")&&ENV$3.getBool("WEBGL_RENDER_FLOAT32_CAPABLE")),ENV$3.registerFlag("WEBGL_DOWNLOAD_FLOAT_ENABLED",()=>isDownloadFloatTextureEnabled$1(ENV$3.getNumber("WEBGL_VERSION"))),ENV$3.registerFlag("WEBGL_FENCE_API_ENABLED",()=>isWebGLFenceEnabled$1(ENV$3.getNumber("WEBGL_VERSION"))),ENV$3.registerFlag("WEBGL_SIZE_UPLOAD_UNIFORM",()=>ENV$3.getBool("WEBGL_RENDER_FLOAT32_ENABLED")?4:0),ENV$3.registerFlag("WEBGL_DELETE_TEXTURE_THRESHOLD",()=>-1,e=>{if(e<0&&-1!==e)throw new Error(`WEBGL_DELETE_TEXTURE_THRESHOLD must be -1 (indicating never delete) or at least 0, but got ${e}.`)}),ENV$3.registerFlag("WEBGL_FLUSH_THRESHOLD",()=>isMobile$1()&&ENV$3.getBool("IS_CHROME")?1:-1,e=>{if(e<0&&-1!==e)throw new Error(`WEBGL_FLUSH_THRESHOLD must be -1 (indicating never manual flush) or at least 0, but got ${e}.`)}),ENV$3.registerFlag("CPU_HANDOFF_SIZE_THRESHOLD",()=>128),ENV$3.registerFlag("WEBGL_USE_SHAPES_UNIFORMS",()=>!1),ENV$3.registerFlag("TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD",()=>1e5),ENV$3.registerFlag("TOPK_K_CPU_HANDOFF_THRESHOLD",()=>128);const ENCODE_FLOAT_SNIPPET$1="\n  const float FLOAT_MAX = 1.70141184e38;\n  const float FLOAT_MIN = 1.17549435e-38;\n\n  lowp vec4 encode_float(highp float v) {\n    if (isnan(v)) {\n      return vec4(255, 255, 255, 255);\n    }\n\n    highp float av = abs(v);\n\n    if(av < FLOAT_MIN) {\n      return vec4(0.0, 0.0, 0.0, 0.0);\n    } else if(v > FLOAT_MAX) {\n      return vec4(0.0, 0.0, 128.0, 127.0) / 255.0;\n    } else if(v < -FLOAT_MAX) {\n      return vec4(0.0, 0.0,  128.0, 255.0) / 255.0;\n    }\n\n    highp vec4 c = vec4(0,0,0,0);\n\n    highp float e = floor(log2(av));\n    highp float m = exp2(fract(log2(av))) - 1.0;\n\n    c[2] = floor(128.0 * m);\n    m -= c[2] / 128.0;\n    c[1] = floor(32768.0 * m);\n    m -= c[1] / 32768.0;\n    c[0] = floor(8388608.0 * m);\n\n    highp float ebias = e + 127.0;\n    c[3] = floor(ebias / 2.0);\n    ebias -= c[3] * 2.0;\n    c[2] += floor(ebias) * 128.0;\n\n    c[3] += 128.0 * step(0.0, -v);\n\n    return c / 255.0;\n  }\n";class DecodeMatrixProgram$1{constructor(e){this.variableNames=["A"],this.packedInputs=!1,this.packedOutput=!0,this.outPackingScheme=PackingScheme$1.DENSE;const t=getDenseTexShape$1(e),n=getGlslDifferences$1();this.outputShape=e,this.userCode=`\n      ivec3 outCoordsFromFlatIndex(int index) {\n        ${getLogicalCoordinatesFromFlatIndex$1(["r","c","d"],e)}\n        return ivec3(r, c, d);\n      }\n\n      void main() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n          vec2(${t[0]}, ${t[1]}));\n        int index = 4 * (resTexRC.x * ${t[1]} + resTexRC.y);\n\n        vec4 result = vec4(0.);\n\n        for (int i=0; i<4; i++) {\n          int flatIndex = index + i;\n          ivec3 rc = outCoordsFromFlatIndex(flatIndex);\n          result[i] = getA(rc.x, rc.y, rc.z);\n        }\n\n        ${n.output} = result;\n      }\n    `}}class DecodeMatrixPackedProgram$1{constructor(e){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,this.outPackingScheme=PackingScheme$1.DENSE;const t=getDenseTexShape$1(e),n=getGlslDifferences$1();this.outputShape=e,this.userCode=`\n      ivec3 outCoordsFromFlatIndex(int index) {\n        ${getLogicalCoordinatesFromFlatIndex$1(["r","c","d"],e)}\n        return ivec3(r, c, d);\n      }\n\n      void main() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n          vec2(${t[0]}, ${t[1]}));\n        int index = 4 * (resTexRC.x * ${t[1]} + resTexRC.y);\n\n        vec4 result = vec4(0.);\n\n        for (int i=0; i<4; i++) {\n          int flatIndex = index + i;\n          ivec3 rc = outCoordsFromFlatIndex(flatIndex);\n          result[i] = getChannel(getA(rc.x, rc.y, rc.z), vec2(rc.y, rc.z));\n        }\n\n        ${n.output} = result;\n      }\n    `}}class EncodeFloatProgram$1{constructor(e){this.variableNames=["A"],this.outTexUsage=TextureUsage$1.DOWNLOAD;const t=getGlslDifferences$1();this.outputShape=e,this.userCode=`\n      ${ENCODE_FLOAT_SNIPPET$1}\n\n      void main() {\n        float x = getAAtOutCoords();\n        ${t.output} = encode_float(x);\n      }\n    `}}class EncodeFloatPackedProgram$1{constructor(e){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!1,this.outTexUsage=TextureUsage$1.DOWNLOAD;const t=getGlslDifferences$1();this.outputShape=e,this.userCode=`\n      ${ENCODE_FLOAT_SNIPPET$1}\n\n      void main() {\n        ivec3 coords = getOutputCoords();\n        float x = getChannel(getAAtOutCoords(), vec2(coords.y, coords.z));\n        ${t.output} = encode_float(x);\n      }\n    `}}class EncodeMatrixProgram$1{constructor(e,t,n=!1){this.variableNames=["A"];const r=getGlslDifferences$1(),[a,s]=t;this.outputShape=e;let o="result";n&&(o="floor(result * 255. + 0.5)"),this.userCode=`\n      ${getFlatIndexFrom3D$1(e)}\n\n      void main() {\n        ivec3 coords = getOutputCoords();\n\n        int flatIndex = getFlatIndex(coords);\n        int offset = imod(flatIndex, 4);\n\n        flatIndex = idiv(flatIndex, 4, 1.);\n\n        int r = flatIndex / ${s};\n        int c = imod(flatIndex, ${s});\n        vec2 uv = (vec2(c, r) + halfCR) / vec2(${s}.0, ${a}.0);\n        vec4 values = ${r.texture2D}(A, uv);\n\n        float result;\n\n        if(offset == 0) {\n          result = values[0];\n        } else if(offset == 1) {\n          result = values[1];\n        } else if(offset == 2) {\n          result = values[2];\n        } else {\n          result = values[3];\n        }\n\n        ${r.output} = vec4(${o}, 0., 0., 0.);\n      }\n    `}}class EncodeMatrixPackedProgram$1{constructor(e,t,n=!1){this.variableNames=["A"],this.packedInputs=!1,this.packedOutput=!0;const r=getGlslDifferences$1(),[a,s]=t;this.outputShape=e;let o="",i="result";n&&(i="floor(result * 255. + 0.5)");for(let t=0;t<=1;t++)for(let n=0;n<=1;n++){const i=2*t+n;o+=`\n          localCoords = coords;\n          if(localCoords[2] + ${n} < ${e[2]}) {\n            localCoords[2] += ${n};\n            if(localCoords[1] + ${t} < ${e[1]}) {\n              localCoords[1] += ${t};\n\n              flatIndex = getFlatIndex(localCoords);\n              offset = imod(flatIndex, 4);\n\n              flatIndex = idiv(flatIndex, 4, 1.);\n\n              r = flatIndex / ${s};\n              c = imod(flatIndex, ${s});\n              uv = (vec2(c, r) + halfCR) / vec2(${s}.0, ${a}.0);\n              values = ${r.texture2D}(A, uv);\n\n              if(offset == 0) {\n                result[${i}] = values[0];\n              } else if(offset == 1) {\n                result[${i}] = values[1];\n              } else if(offset == 2) {\n                result[${i}] = values[2];\n              } else {\n                result[${i}] = values[3];\n              }\n            }\n          }\n        `}this.userCode=`\n      ${getFlatIndexFrom3D$1(e)}\n\n      void main() {\n        ivec3 coords = getOutputCoords();\n\n        vec4 result = vec4(0.);\n        int flatIndex, r, c, offset;\n        ivec3 localCoords;\n        vec2 uv;\n        vec4 values;\n\n        ${o}\n\n        ${r.output} = ${i};\n      }\n    `}}function createVertexShader$2(e){const t=getGlslDifferences$1();return createVertexShader$3(e,`${t.version}\n    precision highp float;\n    ${t.attribute} vec3 clipSpacePos;\n    ${t.attribute} vec2 uv;\n    ${t.varyingVs} vec2 resultUV;\n\n    void main() {\n      gl_Position = vec4(clipSpacePos, 1);\n      resultUV = uv;\n    }`)}function createVertexBuffer$1(e){return createStaticVertexBuffer$1(e,new Float32Array([-1,1,0,0,1,-1,-1,0,0,0,1,1,0,1,1,1,-1,0,1,0]))}function createIndexBuffer$1(e){return createStaticIndexBuffer$1(e,new Uint16Array([0,1,2,2,1,3]))}function createAndConfigureTexture$1(e,t,n,r,a,s){validateTextureSize$1(t,n);const o=createTexture$1(e),i=e.TEXTURE_2D;return callAndCheck$1(e,()=>e.bindTexture(i,o)),callAndCheck$1(e,()=>e.texParameteri(i,e.TEXTURE_WRAP_S,e.CLAMP_TO_EDGE)),callAndCheck$1(e,()=>e.texParameteri(i,e.TEXTURE_WRAP_T,e.CLAMP_TO_EDGE)),callAndCheck$1(e,()=>e.texParameteri(i,e.TEXTURE_MIN_FILTER,e.NEAREST)),callAndCheck$1(e,()=>e.texParameteri(i,e.TEXTURE_MAG_FILTER,e.NEAREST)),callAndCheck$1(e,()=>e.texImage2D(i,0,r,t,n,0,a,s,null)),callAndCheck$1(e,()=>e.bindTexture(e.TEXTURE_2D,null)),o}function getInternalFormatForFloat32MatrixTexture$1(e){return e.internalFormatFloat}function createFloat32MatrixTexture$1(e,t,n,r){const[a,s]=getUnpackedMatrixTextureShapeWidthHeight$1(t,n);return createAndConfigureTexture$1(e,a,s,getInternalFormatForFloat32MatrixTexture$1(r),r.textureFormatFloat,e.FLOAT)}function getInternalFormatForFloat16MatrixTexture$1(e){return e.internalFormatHalfFloat}function createFloat16MatrixTexture$1(e,t,n,r){const[a,s]=getUnpackedMatrixTextureShapeWidthHeight$1(t,n);return createAndConfigureTexture$1(e,a,s,getInternalFormatForFloat16MatrixTexture$1(r),r.textureFormatFloat,r.textureTypeHalfFloat)}function getInternalFormatForUnsignedBytesMatrixTexture$1(e){return e.downloadTextureFormat}function createUnsignedBytesMatrixTexture$1(e,t,n,r){const[a,s]=getUnpackedMatrixTextureShapeWidthHeight$1(t,n);return createAndConfigureTexture$1(e,a,s,getInternalFormatForUnsignedBytesMatrixTexture$1(r),e.RGBA,e.UNSIGNED_BYTE)}function getInternalFormatForPackedMatrixTexture$1(e){return e.internalFormatPackedFloat}function createPackedMatrixTexture$1(e,t,n,r){const[a,s]=getPackedMatrixTextureShapeWidthHeight$1(t,n);return createAndConfigureTexture$1(e,a,s,getInternalFormatForPackedMatrixTexture$1(r),e.RGBA,e.FLOAT)}function getInternalFormatForFloat16PackedMatrixTexture$1(e){return e.internalFormatPackedHalfFloat}function createFloat16PackedMatrixTexture$1(e,t,n,r){const[a,s]=getPackedMatrixTextureShapeWidthHeight$1(t,n);return createAndConfigureTexture$1(e,a,s,getInternalFormatForFloat16PackedMatrixTexture$1(r),e.RGBA,r.textureTypeHalfFloat)}function bindVertexProgramAttributeStreams$1(e,t,n){return callAndCheck$1(e,()=>e.bindBuffer(e.ARRAY_BUFFER,n)),bindVertexBufferToProgramAttribute$1(e,t,"clipSpacePos",n,3,20,0)&&bindVertexBufferToProgramAttribute$1(e,t,"uv",n,2,20,12)}function uploadDenseMatrixToTexture$1(e,t,n,r,a,s){let o,i,l;callAndCheck$1(e,()=>e.bindTexture(e.TEXTURE_2D,t)),a instanceof Uint8Array?(o=new Uint8Array(n*r*4),i=e.UNSIGNED_BYTE,l=e.RGBA):(o=new Float32Array(n*r*4),i=e.FLOAT,l=s.internalFormatPackedFloat),o.set(a),callAndCheck$1(e,()=>e.texImage2D(e.TEXTURE_2D,0,l,n,r,0,e.RGBA,i,o)),callAndCheck$1(e,()=>e.bindTexture(e.TEXTURE_2D,null))}function uploadPixelDataToTexture$1(e,t,n){callAndCheck$1(e,()=>e.bindTexture(e.TEXTURE_2D,t)),n.data instanceof Uint8Array?callAndCheck$1(e,()=>e.texImage2D(e.TEXTURE_2D,0,e.RGBA,n.width,n.height,0,e.RGBA,e.UNSIGNED_BYTE,n.data)):callAndCheck$1(e,()=>e.texImage2D(e.TEXTURE_2D,0,e.RGBA,e.RGBA,e.UNSIGNED_BYTE,n)),callAndCheck$1(e,()=>e.bindTexture(e.TEXTURE_2D,null))}function createBufferFromOutputTexture$1(e,t,n,r){const a=e.createBuffer();callAndCheck$1(e,()=>e.bindBuffer(e.PIXEL_PACK_BUFFER,a));const s=16*t*n;return callAndCheck$1(e,()=>e.bufferData(e.PIXEL_PACK_BUFFER,s,e.STREAM_READ)),callAndCheck$1(e,()=>e.readPixels(0,0,n,t,e.RGBA,e.FLOAT,0)),callAndCheck$1(e,()=>e.bindBuffer(e.PIXEL_PACK_BUFFER,null)),a}function downloadFloat32MatrixFromBuffer$1(e,t,n){const r=e,a=new Float32Array(n);return r.bindBuffer(r.PIXEL_PACK_BUFFER,t),r.getBufferSubData(r.PIXEL_PACK_BUFFER,0,a),r.bindBuffer(r.PIXEL_PACK_BUFFER,null),a}function downloadByteEncodedFloatMatrixFromOutputTexture$1(e,t,n,r){const[a,s]=getUnpackedMatrixTextureShapeWidthHeight$1(t,n),o=new Uint8Array(getUnpackedArraySizeFromMatrixSize$1(t*n,4));return callAndCheck$1(e,()=>e.readPixels(0,0,a,s,r.downloadTextureFormat,e.UNSIGNED_BYTE,o)),new Float32Array(o.buffer)}function downloadPackedMatrixFromBuffer$1(e,t,n,r,a,s,o,i){const l=e,u=new Float32Array(getPackedRGBAArraySizeFromMatrixShape$1(s,o));return l.bindBuffer(l.PIXEL_PACK_BUFFER,t),l.getBufferSubData(l.PIXEL_PACK_BUFFER,0,u),l.bindBuffer(l.PIXEL_PACK_BUFFER,null),u}function downloadMatrixFromPackedOutputTexture$1(e,t,n){const r=new Float32Array(t*n*4);return callAndCheck$1(e,()=>e.readPixels(0,0,n,t,e.RGBA,e.FLOAT,r)),r}class GPGPUContext$1{constructor(e){this.outputTexture=null,this.program=null,this.disposed=!1,this.vertexAttrsAreBound=!1,this.itemsToPoll=[];const t=env$1().getNumber("WEBGL_VERSION");null!=e?(this.gl=e,setWebGLContext$1(t,e)):this.gl=getWebGLContext$1(t);let n="WEBGL_color_buffer_float";const r="EXT_color_buffer_half_float";if(1===env$1().getNumber("WEBGL_VERSION")){const e="OES_texture_half_float";if(this.textureFloatExtension=getExtensionOrThrow$1(this.gl,"OES_texture_float"),hasExtension$1(this.gl,e))this.textureHalfFloatExtension=getExtensionOrThrow$1(this.gl,e);else if(env$1().get("WEBGL_FORCE_F16_TEXTURES"))throw new Error("GL context does not support half float textures, yet the environment flag WEBGL_FORCE_F16_TEXTURES is set to true.");if(this.colorBufferFloatExtension=this.gl.getExtension(n),hasExtension$1(this.gl,r))this.colorBufferHalfFloatExtension=getExtensionOrThrow$1(this.gl,r);else if(env$1().get("WEBGL_FORCE_F16_TEXTURES"))throw new Error("GL context does not support color renderable half floats, yet the environment flag WEBGL_FORCE_F16_TEXTURES is set to true.")}else if(n="EXT_color_buffer_float",hasExtension$1(this.gl,n))this.colorBufferFloatExtension=this.gl.getExtension(n);else{if(!hasExtension$1(this.gl,r))throw new Error("GL context does not support color renderable floats");this.colorBufferHalfFloatExtension=this.gl.getExtension(r)}this.vertexBuffer=createVertexBuffer$1(this.gl),this.indexBuffer=createIndexBuffer$1(this.gl),this.framebuffer=createFramebuffer$1(this.gl),this.textureConfig=getTextureConfig$1(this.gl,this.textureHalfFloatExtension)}get debug(){return env$1().getBool("DEBUG")}dispose(){if(this.disposed)return;null!=this.program&&console.warn("Disposing a GPGPUContext that still has a bound WebGLProgram. This is probably a resource leak, delete the program with GPGPUContext.deleteProgram before disposing."),null!=this.outputTexture&&console.warn("Disposing a GPGPUContext that still has a bound output matrix texture.  This is probably a resource leak, delete the output matrix texture with GPGPUContext.deleteMatrixTexture before disposing.");const e=this.gl;callAndCheck$1(e,()=>e.finish()),callAndCheck$1(e,()=>e.bindFramebuffer(e.FRAMEBUFFER,null)),callAndCheck$1(e,()=>e.deleteFramebuffer(this.framebuffer)),callAndCheck$1(e,()=>e.bindBuffer(e.ARRAY_BUFFER,null)),callAndCheck$1(e,()=>e.bindBuffer(e.ELEMENT_ARRAY_BUFFER,null)),callAndCheck$1(e,()=>e.deleteBuffer(this.indexBuffer)),this.disposed=!0}createFloat32MatrixTexture(e,t){return this.throwIfDisposed(),createFloat32MatrixTexture$1(this.gl,e,t,this.textureConfig)}createFloat16MatrixTexture(e,t){return this.throwIfDisposed(),createFloat16MatrixTexture$1(this.gl,e,t,this.textureConfig)}createUnsignedBytesMatrixTexture(e,t){return this.throwIfDisposed(),createUnsignedBytesMatrixTexture$1(this.gl,e,t,this.textureConfig)}uploadPixelDataToTexture(e,t){this.throwIfDisposed(),uploadPixelDataToTexture$1(this.gl,e,t)}uploadDenseMatrixToTexture(e,t,n,r){this.throwIfDisposed(),uploadDenseMatrixToTexture$1(this.gl,e,t,n,r,this.textureConfig)}createFloat16PackedMatrixTexture(e,t){return this.throwIfDisposed(),createFloat16PackedMatrixTexture$1(this.gl,e,t,this.textureConfig)}createPackedMatrixTexture(e,t){return this.throwIfDisposed(),createPackedMatrixTexture$1(this.gl,e,t,this.textureConfig)}deleteMatrixTexture(e){this.throwIfDisposed(),this.outputTexture===e&&(unbindColorTextureFromFramebuffer$1(this.gl,this.framebuffer),this.outputTexture=null),callAndCheck$1(this.gl,()=>this.gl.deleteTexture(e))}downloadByteEncodedFloatMatrixFromOutputTexture(e,t,n){return this.downloadMatrixDriver(e,()=>downloadByteEncodedFloatMatrixFromOutputTexture$1(this.gl,t,n,this.textureConfig))}downloadPackedMatrixFromBuffer(e,t,n,r,a,s){return downloadPackedMatrixFromBuffer$1(this.gl,e,t,n,r,a,s)}downloadFloat32MatrixFromBuffer(e,t){return downloadFloat32MatrixFromBuffer$1(this.gl,e,t)}createBufferFromTexture(e,t,n){this.bindTextureToFrameBuffer(e);const r=createBufferFromOutputTexture$1(this.gl,t,n);return this.unbindTextureToFrameBuffer(),r}createAndWaitForFence(){const e=this.createFence(this.gl);return this.pollFence(e)}createFence(e){let t,n;if(env$1().getBool("WEBGL_FENCE_API_ENABLED")){const r=e,a=r.fenceSync(r.SYNC_GPU_COMMANDS_COMPLETE,0);e.flush(),n=()=>{const e=r.clientWaitSync(a,0,0);return e===r.ALREADY_SIGNALED||e===r.CONDITION_SATISFIED},t=a}else env$1().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")>0?(t=this.beginQuery(),this.endQuery(),n=()=>this.isQueryAvailable(t,env$1().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"))):n=()=>!0;return{query:t,isFencePassed:n}}downloadMatrixFromPackedTexture(e,t,n){return this.downloadMatrixDriver(e,()=>downloadMatrixFromPackedOutputTexture$1(this.gl,t,n))}createProgram(e){this.throwIfDisposed();const t=this.gl,n=createFragmentShader$1(t,e);null==this.vertexShader&&(this.vertexShader=createVertexShader$2(t));const r=createProgram$1(t);return callAndCheck$1(t,()=>t.attachShader(r,this.vertexShader)),callAndCheck$1(t,()=>t.attachShader(r,n)),linkProgram$1(t,r),this.debug&&validateProgram$1(t,r),this.vertexAttrsAreBound||(this.setProgram(r),this.vertexAttrsAreBound=bindVertexProgramAttributeStreams$1(t,this.program,this.vertexBuffer)),r}deleteProgram(e){this.throwIfDisposed(),e===this.program&&(this.program=null),null!=e&&callAndCheck$1(this.gl,()=>this.gl.deleteProgram(e))}setProgram(e){this.throwIfDisposed(),this.program=e,null!=this.program&&this.debug&&validateProgram$1(this.gl,this.program),callAndCheck$1(this.gl,()=>this.gl.useProgram(e))}getUniformLocation(e,t,n=!0){return this.throwIfDisposed(),n?getProgramUniformLocationOrThrow$1(this.gl,e,t):getProgramUniformLocation$1(this.gl,e,t)}getAttributeLocation(e,t){return this.throwIfDisposed(),callAndCheck$1(this.gl,()=>this.gl.getAttribLocation(e,t))}getUniformLocationNoThrow(e,t){return this.throwIfDisposed(),this.gl.getUniformLocation(e,t)}setInputMatrixTexture(e,t,n){this.throwIfDisposed(),this.throwIfNoProgram(),bindTextureToProgramUniformSampler$1(this.gl,e,t,n)}setOutputMatrixTexture(e,t,n){this.setOutputMatrixTextureDriver(e,n,t)}setOutputPackedMatrixTexture(e,t,n){this.throwIfDisposed();const[r,a]=getPackedMatrixTextureShapeWidthHeight$1(t,n);this.setOutputMatrixTextureDriver(e,r,a)}setOutputMatrixWriteRegion(e,t,n,r){this.setOutputMatrixWriteRegionDriver(n,e,r,t)}setOutputPackedMatrixWriteRegion(e,t,n,r){throw new Error("setOutputPackedMatrixWriteRegion not implemented.")}debugValidate(){null!=this.program&&validateProgram$1(this.gl,this.program),validateFramebuffer$1(this.gl)}executeProgram(){this.throwIfDisposed(),this.throwIfNoProgram();const e=this.gl;this.debug&&this.debugValidate(),callAndCheck$1(e,()=>e.drawElements(e.TRIANGLES,6,e.UNSIGNED_SHORT,0))}blockUntilAllProgramsCompleted(){this.throwIfDisposed(),callAndCheck$1(this.gl,()=>this.gl.finish())}getQueryTimerExtension(){return null==this.disjointQueryTimerExtension&&(this.disjointQueryTimerExtension=getExtensionOrThrow$1(this.gl,2===env$1().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")?"EXT_disjoint_timer_query_webgl2":"EXT_disjoint_timer_query")),this.disjointQueryTimerExtension}getQueryTimerExtensionWebGL2(){return this.getQueryTimerExtension()}getQueryTimerExtensionWebGL1(){return this.getQueryTimerExtension()}beginQuery(){if(2===env$1().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")){const e=this.gl,t=this.getQueryTimerExtensionWebGL2(),n=e.createQuery();return e.beginQuery(t.TIME_ELAPSED_EXT,n),n}const e=this.getQueryTimerExtensionWebGL1(),t=e.createQueryEXT();return e.beginQueryEXT(e.TIME_ELAPSED_EXT,t),t}endQuery(){if(2===env$1().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")){const e=this.gl,t=this.getQueryTimerExtensionWebGL2();return void e.endQuery(t.TIME_ELAPSED_EXT)}const e=this.getQueryTimerExtensionWebGL1();e.endQueryEXT(e.TIME_ELAPSED_EXT)}async waitForQueryAndGetTime(e){return await repeatedTry$1(()=>this.disposed||this.isQueryAvailable(e,env$1().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"))),this.getQueryTime(e,env$1().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"))}getQueryTime(e,t){if(0===t)return null;if(2===t){const t=this.gl;return t.getQueryParameter(e,t.QUERY_RESULT)/1e6}{const t=this.getQueryTimerExtensionWebGL1();return t.getQueryObjectEXT(e,t.QUERY_RESULT_EXT)/1e6}}isQueryAvailable(e,t){if(0===t)return!0;if(2===t){const t=this.gl,n=this.getQueryTimerExtensionWebGL2(),r=t.getQueryParameter(e,t.QUERY_RESULT_AVAILABLE);return null==this.disjoint&&(this.disjoint=this.gl.getParameter(n.GPU_DISJOINT_EXT)),r&&!this.disjoint}{const t=this.getQueryTimerExtensionWebGL1(),n=t.getQueryObjectEXT(e,t.QUERY_RESULT_AVAILABLE_EXT);return null==this.disjoint&&(this.disjoint=this.gl.getParameter(t.GPU_DISJOINT_EXT)),n&&!this.disjoint}}pollFence(e){return new Promise(t=>{this.addItemToPoll(()=>e.isFencePassed(),()=>t())})}pollItems(){const e=linearSearchLastTrue$1(this.itemsToPoll.map(e=>e.isDoneFn));for(let t=0;t<=e;++t){const{resolveFn:e}=this.itemsToPoll[t];e()}this.itemsToPoll=this.itemsToPoll.slice(e+1)}addItemToPoll(e,t){this.itemsToPoll.push({isDoneFn:e,resolveFn:t}),this.itemsToPoll.length>1||repeatedTry$1(()=>(this.pollItems(),0===this.itemsToPoll.length))}bindTextureToFrameBuffer(e){this.throwIfDisposed(),bindColorTextureToFramebuffer$1(this.gl,e,this.framebuffer),this.debug&&validateFramebuffer$1(this.gl)}unbindTextureToFrameBuffer(){null!=this.outputTexture?(bindColorTextureToFramebuffer$1(this.gl,this.outputTexture,this.framebuffer),this.debug&&validateFramebuffer$1(this.gl)):unbindColorTextureFromFramebuffer$1(this.gl,this.framebuffer)}downloadMatrixDriver(e,t){this.bindTextureToFrameBuffer(e);const n=t();return this.unbindTextureToFrameBuffer(),n}setOutputMatrixTextureDriver(e,t,n){this.throwIfDisposed();const r=this.gl;bindColorTextureToFramebuffer$1(r,e,this.framebuffer),this.debug&&validateFramebuffer$1(r),this.outputTexture=e,callAndCheck$1(r,()=>r.viewport(0,0,t,n)),callAndCheck$1(r,()=>r.scissor(0,0,t,n))}setOutputMatrixWriteRegionDriver(e,t,n,r){this.throwIfDisposed(),callAndCheck$1(this.gl,()=>this.gl.scissor(e,t,n,r))}throwIfDisposed(){if(this.disposed)throw new Error("Attempted to use disposed GPGPUContext.")}throwIfNoProgram(){if(null==this.program)throw new Error("No GPU program is currently set.")}}function linearSearchLastTrue$1(e){let t=0;for(;t<e.length&&e[t]();++t);return t-1}const{getBroadcastDims:getBroadcastDims$2}=backend_util$1;function makeShader$1(e,t,n){const r=[];if(e.forEach(e=>{const t=sizeFromShape$1(e.shapeInfo.logicalShape);if(e.shapeInfo.isUniform?r.push(`uniform float ${e.name}${t>1?`[${t}]`:""};`):(r.push(`uniform sampler2D ${e.name};`),r.push(`uniform int offset${e.name};`)),n.enableShapeUniforms){const{uniformShape:t}=getUniformInfoFromShape$1(n.packedInputs,e.shapeInfo.logicalShape,e.shapeInfo.texShape);switch(t.length){case 1:r.push(`uniform int ${e.name}Shape;`);break;case 2:r.push(`uniform ivec2 ${e.name}Shape;`);break;case 3:r.push(`uniform ivec3 ${e.name}Shape;`);break;case 4:r.push(`uniform ivec4 ${e.name}Shape;`)}r.push(`uniform ivec2 ${e.name}TexShape;`)}}),n.enableShapeUniforms){switch(t.logicalShape.length){case 1:r.push("uniform int outShape;");break;case 2:r.push("uniform ivec2 outShape;"),r.push("uniform int outShapeStrides;");break;case 3:r.push("uniform ivec3 outShape;"),r.push("uniform ivec2 outShapeStrides;");break;case 4:r.push("uniform ivec4 outShape;"),r.push("uniform ivec3 outShapeStrides;")}r.push("uniform ivec2 outTexShape;")}n.customUniforms&&n.customUniforms.forEach(e=>{r.push(`uniform ${e.type} ${e.name}${e.arrayIndex?`[${e.arrayIndex}]`:""};`)});const a=r.join("\n"),s=e.map(e=>getInputSamplingSnippet$1(e,t,n.packedInputs,n.enableShapeUniforms)).join("\n"),o=t.texShape,i=getGlslDifferences$1(),l=getFloatTextureSampleSnippet$1(i);let u,c,p=getShaderPrefix$1(i);return t.isPacked?(u=getPackedOutputSamplingSnippet$1(t.logicalShape,o,n.enableShapeUniforms),c=getFloatTextureSetRGBASnippet$1(i)):(u=getOutputSamplingSnippet$1(t.logicalShape,o,n.enableShapeUniforms),c=getFloatTextureSetRSnippet$1(i)),n.packedInputs&&(p+=SHADER_PACKED_PREFIX$1),[p,l,c,a,u,s,n.userCode].join("\n")}function getSamplerFromInInfo$1(e,t=!1){const n=e.shapeInfo.logicalShape;switch(n.length){case 0:return getSamplerScalar$1(e,t);case 1:return getSampler1D$1(e,t);case 2:return getSampler2D$1(e,t);case 3:return getSampler3D$1(e,t);case 4:return getSampler4D$1(e,t);case 5:return getSampler5D$1(e);case 6:return getSampler6D$1(e);default:throw new Error(`${n.length}-D input sampling is not yet supported`)}}function getPackedSamplerFromInInfo$1(e,t){switch(e.shapeInfo.logicalShape.length){case 0:return getPackedSamplerScalar$1(e);case 1:return getPackedSampler1D$1(e,t);case 2:return getPackedSampler2D$1(e,t);case 3:return getPackedSampler3D$1(e,t);default:return getPackedSamplerND$1(e,t)}}function getInputSamplingSnippet$1(e,t,n=!1,r){let a="";return a+=n?getPackedSamplerFromInInfo$1(e,r):getSamplerFromInInfo$1(e,r),e.shapeInfo.logicalShape.length<=t.logicalShape.length&&(a+=n?getPackedSamplerAtOutputCoords$1(e,t):getSamplerAtOutputCoords$1(e,t)),a}function getPackedOutputSamplingSnippet$1(e,t,n){switch(e.length){case 0:return getOutputScalarCoords$1();case 1:return getOutputPacked1DCoords$1(e,t,n);case 2:return getOutputPacked2DCoords$1(e,t,n);case 3:return getOutputPacked3DCoords$1(e,t,n);default:return getOutputPackedNDCoords$1(e,t,n)}}function getOutputSamplingSnippet$1(e,t,n){switch(e.length){case 0:return getOutputScalarCoords$1();case 1:return getOutput1DCoords$1(e,t,n);case 2:return getOutput2DCoords$1(e,t,n);case 3:return getOutput3DCoords$1(e,t,n);case 4:return getOutput4DCoords$1(e,t,n);case 5:return getOutput5DCoords$1(e,t);case 6:return getOutput6DCoords$1(e,t);default:throw new Error(`${e.length}-D output sampling is not yet supported`)}}function getFloatTextureSampleSnippet$1(e){return`\n    float sampleTexture(sampler2D textureSampler, vec2 uv) {\n      return ${e.texture2D}(textureSampler, uv).r;\n    }\n  `}function getFloatTextureSetRSnippet$1(e){return`\n    void setOutput(float val) {\n      ${e.output} = vec4(val, 0, 0, 0);\n    }\n  `}function getFloatTextureSetRGBASnippet$1(e){return`\n    void setOutput(vec4 val) {\n      ${e.output} = val;\n    }\n  `}function getShaderPrefix$1(e){return`${e.version}\n    precision highp float;\n    precision highp int;\n    precision highp sampler2D;\n    ${e.varyingFs} vec2 resultUV;\n    ${e.defineOutput}\n    const vec2 halfCR = vec2(0.5, 0.5);\n\n    struct ivec5\n    {\n      int x;\n      int y;\n      int z;\n      int w;\n      int u;\n    };\n\n    struct ivec6\n    {\n      int x;\n      int y;\n      int z;\n      int w;\n      int u;\n      int v;\n    };\n\n    uniform float NAN;\n    ${e.defineSpecialNaN}\n    ${e.defineSpecialInf}\n    ${e.defineRound}\n\n    int imod(int x, int y) {\n      return x - y * (x / y);\n    }\n\n    int idiv(int a, int b, float sign) {\n      int res = a / b;\n      int mod = imod(a, b);\n      if (sign < 0. && mod != 0) {\n        res -= 1;\n      }\n      return res;\n    }\n\n    //Based on the work of Dave Hoskins\n    //https://www.shadertoy.com/view/4djSRW\n    #define HASHSCALE1 443.8975\n    float random(float seed){\n      vec2 p = resultUV * seed;\n      vec3 p3  = fract(vec3(p.xyx) * HASHSCALE1);\n      p3 += dot(p3, p3.yzx + 19.19);\n      return fract((p3.x + p3.y) * p3.z);\n    }\n\n    ${SAMPLE_1D_SNIPPET$1}\n    ${SAMPLE_2D_SNIPPET$1}\n    ${SAMPLE_3D_SNIPPET$1}\n  `}const SAMPLE_1D_SNIPPET$1="\nvec2 uvFromFlat(int texNumR, int texNumC, int index) {\n  int texR = index / texNumC;\n  int texC = index - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\nvec2 packedUVfrom1D(int texNumR, int texNumC, int index) {\n  int texelIndex = index / 2;\n  int texR = texelIndex / texNumC;\n  int texC = texelIndex - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\n",SAMPLE_2D_SNIPPET$1="\nvec2 packedUVfrom2D(int texelsInLogicalRow, int texNumR,\n  int texNumC, int row, int col) {\n  int texelIndex = (row / 2) * texelsInLogicalRow + (col / 2);\n  int texR = texelIndex / texNumC;\n  int texC = texelIndex - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\n",SAMPLE_3D_SNIPPET$1="\nvec2 packedUVfrom3D(int texNumR, int texNumC,\n    int texelsInBatch, int texelsInLogicalRow, int b,\n    int row, int col) {\n  int index = b * texelsInBatch + (row / 2) * texelsInLogicalRow + (col / 2);\n  int texR = index / texNumC;\n  int texC = index - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\n",SHADER_PACKED_PREFIX$1="\n  float getChannel(vec4 frag, vec2 innerDims) {\n    vec2 modCoord = mod(innerDims, 2.);\n    return modCoord.x == 0. ?\n      (modCoord.y == 0. ? frag.r : frag.g) :\n      (modCoord.y == 0. ? frag.b : frag.a);\n  }\n  float getChannel(vec4 frag, int dim) {\n    float modCoord = mod(float(dim), 2.);\n    return modCoord == 0. ? frag.r : frag.g;\n  }\n";function getOutputScalarCoords$1(){return"\n    int getOutputCoords() {\n      return 0;\n    }\n  "}function getOutputPacked1DCoords$1(e,t,n){const r=[Math.ceil(t[0]/2),Math.ceil(t[1]/2)];return 1===r[0]?n?"\n      int getOutputCoords() {\n        return 2 * int(resultUV.x * ceil(float(outTexShape[1]) / 2.0));\n      }\n    ":`\n      int getOutputCoords() {\n        return 2 * int(resultUV.x * ${r[1]}.0);\n      }\n    `:1===r[1]?n?"\n      int getOutputCoords() {\n        return 2 * int(resultUV.y * ceil(float(outTexShape[0]) / 2.0));\n      }\n    ":`\n      int getOutputCoords() {\n        return 2 * int(resultUV.y * ${r[0]}.0);\n      }\n    `:n?"\n    int getOutputCoords() {\n      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(packedTexShape[0], packedTexShape[1]));\n      return 2 * (resTexRC.x * packedTexShape[1] + resTexRC.y);\n    }\n  ":`\n    int getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${r[0]}, ${r[1]}));\n      return 2 * (resTexRC.x * ${r[1]} + resTexRC.y);\n    }\n  `}function getOutput1DCoords$1(e,t,n){return 1===t[0]?n?"\n      int getOutputCoords() {\n        return int(resultUV.x * float(outTexShape[1]));\n      }\n    ":`\n      int getOutputCoords() {\n        return int(resultUV.x * ${t[1]}.0);\n      }\n    `:1===t[1]?n?"\n      int getOutputCoords() {\n        return int(resultUV.y * float(outTexShape[0]));\n      }\n    ":`\n      int getOutputCoords() {\n        return int(resultUV.y * ${t[0]}.0);\n      }\n    `:n?"\n    int getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(outTexShape[0], outTexShape[1]));\n      return resTexRC.x * outTexShape[1] + resTexRC.y;\n    }\n  ":`\n    int getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${t[0]}, ${t[1]}));\n      return resTexRC.x * ${t[1]} + resTexRC.y;\n    }\n  `}function getOutputPacked3DCoords$1(e,t,n){if(n)return"\n    ivec3 getOutputCoords() {\n      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\n      int texelsInLogicalRow = int(ceil(float(outShape[2]) / 2.0));\n      int texelsInBatch = texelsInLogicalRow * int(ceil(float(outShape[1]) / 2.0));\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(packedTexShape[0], packedTexShape[1]));\n      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;\n\n      int b = index / texelsInBatch;\n      index -= b * texelsInBatch;\n\n      int r = 2 * (index / texelsInLogicalRow);\n      int c = imod(index, texelsInLogicalRow) * 2;\n\n      return ivec3(b, r, c);\n    }\n  ";const r=[Math.ceil(t[0]/2),Math.ceil(t[1]/2)],a=Math.ceil(e[2]/2),s=a*Math.ceil(e[1]/2);return`\n    ivec3 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${r[0]}, ${r[1]}));\n      int index = resTexRC.x * ${r[1]} + resTexRC.y;\n\n      int b = index / ${s};\n      index -= b * ${s};\n\n      int r = 2 * (index / ${a});\n      int c = imod(index, ${a}) * 2;\n\n      return ivec3(b, r, c);\n    }\n  `}function getOutput3DCoords$1(e,t,n){if(n)return`\n  ivec3 getOutputCoords() {\n    ivec2 resTexRC = ivec2(resultUV.yx *\n                           vec2(outTexShape[0], outTexShape[1]));\n    int index = resTexRC.x * outTexShape[1] + resTexRC.y;\n    ${getLogicalCoordinatesFromFlatIndexByUniform$1(["r","c","d"],e)}\n    return ivec3(r, c, d);\n  }\n`;const r=getLogicalCoordinatesFromFlatIndex$1(["r","c","d"],e);return`\n    ivec3 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${t[0]}, ${t[1]}));\n      int index = resTexRC.x * ${t[1]} + resTexRC.y;\n      ${r}\n      return ivec3(r, c, d);\n    }\n  `}function getOutputPackedNDCoords$1(e,t,n){if(n)return"\n    ivec4 getOutputCoords() {\n      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(packedTexShape[0], packedTexShape[1]));\n      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;\n\n      int texelsInLogicalRow = int(ceil(float(outShape[3]) / 2.0));\n      int texelsInBatch = texelsInLogicalRow * int(ceil(float(outShape[2]) / 2.0));\n      int texelsInBatchN = texelsInBatch * outShape[1];\n\n      int b2 = index / texelsInBatchN;\n      index -= b2 * texelsInBatchN;\n\n      int b = index / texelsInBatch;\n      index -= b * texelsInBatch;\n\n      int r = 2 * (index / texelsInLogicalRow);\n      int c = imod(index, texelsInLogicalRow) * 2;\n\n      return ivec4(b2, b, r, c);\n    }\n  ";const r=[Math.ceil(t[0]/2),Math.ceil(t[1]/2)],a=Math.ceil(e[e.length-1]/2),s=a*Math.ceil(e[e.length-2]/2);let o=s,i="",l="b, r, c";for(let t=2;t<e.length-1;t++)o*=e[e.length-t-1],i=`\n      int b${t} = index / ${o};\n      index -= b${t} * ${o};\n    `+i,l=`b${t}, `+l;return`\n    ivec${e.length} getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${r[0]}, ${r[1]}));\n      int index = resTexRC.x * ${r[1]} + resTexRC.y;\n\n      ${i}\n\n      int b = index / ${s};\n      index -= b * ${s};\n\n      int r = 2 * (index / ${a});\n      int c = imod(index, ${a}) * 2;\n\n      return ivec${e.length}(${l});\n    }\n  `}function getOutput4DCoords$1(e,t,n){if(n)return`\n    ivec4 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n        vec2(outTexShape[0], outTexShape[1]));\n      int index = resTexRC.x * outTexShape[1] + resTexRC.y;\n      ${getLogicalCoordinatesFromFlatIndexByUniform$1(["r","c","d","d2"],e)}\n      return ivec4(r, c, d, d2);\n    }\n  `;const r=getLogicalCoordinatesFromFlatIndex$1(["r","c","d","d2"],e);return`\n    ivec4 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n        vec2(${t[0]}, ${t[1]}));\n      int index = resTexRC.x * ${t[1]} + resTexRC.y;\n      ${r}\n      return ivec4(r, c, d, d2);\n    }\n  `}function getOutput5DCoords$1(e,t){const n=getLogicalCoordinatesFromFlatIndex$1(["r","c","d","d2","d3"],e);return`\n    ivec5 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx * vec2(${t[0]},\n                             ${t[1]}));\n\n      int index = resTexRC.x * ${t[1]} + resTexRC.y;\n\n      ${n}\n\n      ivec5 outShape = ivec5(r, c, d, d2, d3);\n      return outShape;\n    }\n  `}function getOutput6DCoords$1(e,t){const n=getLogicalCoordinatesFromFlatIndex$1(["r","c","d","d2","d3","d4"],e);return`\n    ivec6 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n        vec2(${t[0]}, ${t[1]}));\n      int index = resTexRC.x * ${t[1]} + resTexRC.y;\n\n      ${n}\n\n      ivec6 result = ivec6(r, c, d, d2, d3, d4);\n      return result;\n    }\n  `}function getOutputPacked2DCoords$1(e,t,n){const r=[Math.ceil(t[0]/2),Math.ceil(t[1]/2)];if(arraysEqual$1(e,t))return n?"\n      ivec2 getOutputCoords() {\n        ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\n        return 2 * ivec2(resultUV.yx * vec2(packedTexShape[0], packedTexShape[1]));\n      }\n    ":`\n      ivec2 getOutputCoords() {\n        return 2 * ivec2(resultUV.yx * vec2(${r[0]}, ${r[1]}));\n      }\n    `;const a=Math.ceil(e[1]/2);return n?"\n    ivec2 getOutputCoords() {\n      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\n      int texelsInLogicalRow = int(ceil(float(outShape[1]) / 2.0));\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(packedTexShape[0], packedTexShape[1]));\n\n      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;\n      int r = 2 * (index / texelsInLogicalRow);\n      int c = imod(index, texelsInLogicalRow) * 2;\n\n      return ivec2(r, c);\n    }\n  ":`\n    ivec2 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${r[0]}, ${r[1]}));\n\n      int index = resTexRC.x * ${r[1]} + resTexRC.y;\n      int r = 2 * (index / ${a});\n      int c = imod(index, ${a}) * 2;\n\n      return ivec2(r, c);\n    }\n  `}function getOutput2DCoords$1(e,t,n){return arraysEqual$1(e,t)?n?"\n      ivec2 getOutputCoords() {\n        return ivec2(resultUV.yx * vec2(outTexShape[0], outTexShape[1]));\n      }\n    ":`\n      ivec2 getOutputCoords() {\n        return ivec2(resultUV.yx * vec2(${t[0]}, ${t[1]}));\n      }\n    `:1===e[1]?n?"\n      ivec2 getOutputCoords() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n                               vec2(outTexShape[0], outTexShape[1]));\n        int index = resTexRC.x * outTexShape[1] + resTexRC.y;\n        return ivec2(index, 0);\n      }\n    ":`\n      ivec2 getOutputCoords() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n                               vec2(${t[0]}, ${t[1]}));\n        int index = resTexRC.x * ${t[1]} + resTexRC.y;\n        return ivec2(index, 0);\n      }\n    `:1===e[0]?n?"\n      ivec2 getOutputCoords() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n                               vec2(outTexShape[0], outTexShape[1]));\n        int index = resTexRC.x * outTexShape[1] + resTexRC.y;\n        return ivec2(0, index);\n      }\n    ":`\n      ivec2 getOutputCoords() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n                               vec2(${t[0]}, ${t[1]}));\n        int index = resTexRC.x * ${t[1]} + resTexRC.y;\n        return ivec2(0, index);\n      }\n    `:n?"\n    ivec2 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(outTexShape[0], outTexShape[1]));\n      int index = resTexRC.x * outTexShape[1] + resTexRC.y;\n      int r = index / outShape[1];\n      int c = index - r * outShape[1];\n      return ivec2(r, c);\n    }\n  ":`\n    ivec2 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${t[0]}, ${t[1]}));\n      int index = resTexRC.x * ${t[1]} + resTexRC.y;\n      int r = index / ${e[1]};\n      int c = index - r * ${e[1]};\n      return ivec2(r, c);\n    }\n  `}function getFlatOffsetUniformName$1(e){return`offset${e}`}function getPackedSamplerScalar$1(e){const t=e.name;return`\n    vec4 ${"get"+t.charAt(0).toUpperCase()+t.slice(1)}() {\n      return ${getGlslDifferences$1().texture2D}(${t}, halfCR);\n    }\n  `}function getSamplerScalar$1(e,t){const n=e.name,r="get"+n.charAt(0).toUpperCase()+n.slice(1);if(e.shapeInfo.isUniform)return`float ${r}() {return ${n};}`;const[a,s]=e.shapeInfo.texShape;if(1===a&&1===s)return`\n      float ${r}() {\n        return sampleTexture(${n}, halfCR);\n      }\n    `;const o=getFlatOffsetUniformName$1(n);if(t)return`\n    float ${r}() {\n      vec2 uv = uvFromFlat(${n}TexShape[0], ${n}TexShape[1], ${o});\n      return sampleTexture(${n}, uv);\n    }\n  `;const[i,l]=e.shapeInfo.texShape;return`\n    float ${r}() {\n      vec2 uv = uvFromFlat(${i}, ${l}, ${o});\n      return sampleTexture(${n}, uv);\n    }\n  `}function getPackedSampler1D$1(e,t){const n=e.name,r="get"+n.charAt(0).toUpperCase()+n.slice(1),a=e.shapeInfo.texShape,s=getGlslDifferences$1();if(t)return`\n    vec4 ${r}(int index) {\n      ivec2 packedTexShape = ivec2(ceil(float(${n}TexShape[0]) / 2.0), ceil(float(${n}TexShape[1]) / 2.0));\n      vec2 uv = packedUVfrom1D(\n        packedTexShape[0], packedTexShape[1], index);\n      return ${s.texture2D}(${n}, uv);\n    }\n  `;const o=[Math.ceil(a[0]/2),Math.ceil(a[1]/2)];return`\n    vec4 ${r}(int index) {\n      vec2 uv = packedUVfrom1D(\n        ${o[0]}, ${o[1]}, index);\n      return ${s.texture2D}(${n}, uv);\n    }\n  `}function getSampler1D$1(e,t){const n=e.name,r="get"+n.charAt(0).toUpperCase()+n.slice(1);if(e.shapeInfo.isUniform)return`\n      float ${r}(int index) {\n        ${getUniformSampler$1(e)}\n      }\n    `;const a=e.shapeInfo.texShape,s=a[0],o=a[1];if(1===o&&1===s)return`\n      float ${r}(int index) {\n        return sampleTexture(${n}, halfCR);\n      }\n    `;const i=getFlatOffsetUniformName$1(n);return 1===o?t?`\n      float ${r}(int index) {\n        vec2 uv = vec2(0.5, (float(index + ${i}) + 0.5) / float(${n}TexShape[0]));\n        return sampleTexture(${n}, uv);\n      }\n    `:`\n      float ${r}(int index) {\n        vec2 uv = vec2(0.5, (float(index + ${i}) + 0.5) / ${s}.0);\n        return sampleTexture(${n}, uv);\n      }\n    `:1===s?t?`\n      float ${r}(int index) {\n        vec2 uv = vec2((float(index + ${i}) + 0.5) / float(${n}TexShape[1]), 0.5);\n        return sampleTexture(${n}, uv);\n      }\n    `:`\n      float ${r}(int index) {\n        vec2 uv = vec2((float(index + ${i}) + 0.5) / ${o}.0, 0.5);\n        return sampleTexture(${n}, uv);\n      }\n    `:t?`\n    float ${r}(int index) {\n      vec2 uv = uvFromFlat(${n}TexShape[0], ${n}TexShape[1], index + ${i});\n      return sampleTexture(${n}, uv);\n    }\n  `:`\n    float ${r}(int index) {\n      vec2 uv = uvFromFlat(${s}, ${o}, index + ${i});\n      return sampleTexture(${n}, uv);\n    }\n  `}function getPackedSampler2D$1(e,t){const n=e.shapeInfo.logicalShape,r=e.name,a="get"+r.charAt(0).toUpperCase()+r.slice(1),s=e.shapeInfo.texShape,o=s[0],i=s[1],l=getGlslDifferences$1();if(null!=s&&arraysEqual$1(n,s))return t?`\n      vec4 ${a}(int row, int col) {\n        vec2 uv = (vec2(col, row) + halfCR) / vec2(${r}TexShape[1], ${r}TexShape[0]);\n\n        return ${l.texture2D}(${r}, uv);\n      }\n    `:`\n      vec4 ${a}(int row, int col) {\n        vec2 uv = (vec2(col, row) + halfCR) / vec2(${i}.0, ${o}.0);\n\n        return ${l.texture2D}(${r}, uv);\n      }\n    `;if(t)return`\n    vec4 ${a}(int row, int col) {\n      ivec2 packedTexShape = ivec2(ceil(float(${r}TexShape[0]) / 2.0), ceil(float(${r}TexShape[1]) / 2.0));\n      int valuesPerRow = int(ceil(float(${r}Shape[1]) / 2.0));\n      vec2 uv = packedUVfrom2D(valuesPerRow, packedTexShape[0], packedTexShape[1], row, col);\n      return ${l.texture2D}(${r}, uv);\n    }\n  `;const u=[Math.ceil(s[0]/2),Math.ceil(s[1]/2)];return`\n    vec4 ${a}(int row, int col) {\n      vec2 uv = packedUVfrom2D(${Math.ceil(n[1]/2)}, ${u[0]}, ${u[1]}, row, col);\n      return ${l.texture2D}(${r}, uv);\n    }\n  `}function getSampler2D$1(e,t){const n=e.shapeInfo.logicalShape,r=e.name,a="get"+r.charAt(0).toUpperCase()+r.slice(1),s=e.shapeInfo.texShape;if(null!=s&&arraysEqual$1(n,s))return t?`\n      float ${a}(int row, int col) {\n        vec2 uv = (vec2(col, row) + halfCR) / vec2(${r}TexShape[1], ${r}TexShape[0]);\n        return sampleTexture(${r}, uv);\n      }\n    `:`\n    float ${a}(int row, int col) {\n      vec2 uv = (vec2(col, row) + halfCR) / vec2(${s[1]}.0, ${s[0]}.0);\n      return sampleTexture(${r}, uv);\n    }\n  `;const{newShape:o,keptDims:i}=squeezeShape$1(n);if(o.length<n.length){const n=["row","col"];return`\n      ${getSamplerFromInInfo$1(squeezeInputInfo$1(e,o),t)}\n      float ${a}(int row, int col) {\n        return ${a}(${getSqueezedParams$1(n,i)});\n      }\n    `}if(e.shapeInfo.isUniform)return`\n      float ${a}(int row, int col) {\n        int index = round(dot(vec2(row, col), vec2(${n[1]}, 1)));\n        ${getUniformSampler$1(e)}\n      }\n    `;const l=s[0],u=s[1],c=getFlatOffsetUniformName$1(r);return 1===u?t?`\n      float ${a}(int row, int col) {\n        float index = dot(vec3(row, col, ${c}), vec3(${r}Shape[1], 1, 1));\n        vec2 uv = vec2(0.5, (index + 0.5) / float(${r}TexShape[0]));\n        return sampleTexture(${r}, uv);\n      }\n    `:`\n    float ${a}(int row, int col) {\n      float index = dot(vec3(row, col, ${c}), vec3(${n[1]}, 1, 1));\n      vec2 uv = vec2(0.5, (index + 0.5) / ${l}.0);\n      return sampleTexture(${r}, uv);\n    }\n  `:1===l?t?`\n      float ${a}(int row, int col) {\n        float index = dot(vec3(row, col, ${c}), vec3(${r}Shape[1], 1, 1));\n        vec2 uv = vec2((index + 0.5) / float(${r}TexShape[1]), 0.5);\n        return sampleTexture(${r}, uv);\n      }\n    `:`\n    float ${a}(int row, int col) {\n      float index = dot(vec3(row, col, ${c}), vec3(${n[1]}, 1, 1));\n      vec2 uv = vec2((index + 0.5) / ${u}.0, 0.5);\n      return sampleTexture(${r}, uv);\n    }\n  `:t?`\n      float ${a}(int row, int col) {\n        // Explicitly use integer operations as dot() only works on floats.\n        int index = row * ${r}Shape[1] + col + ${c};\n        vec2 uv = uvFromFlat(${r}TexShape[0], ${r}TexShape[1], index);\n        return sampleTexture(${r}, uv);\n      }\n    `:`\n  float ${a}(int row, int col) {\n    // Explicitly use integer operations as dot() only works on floats.\n    int index = row * ${n[1]} + col + ${c};\n    vec2 uv = uvFromFlat(${l}, ${u}, index);\n    return sampleTexture(${r}, uv);\n  }\n`}function getPackedSampler3D$1(e,t){const n=e.shapeInfo.logicalShape,r=e.name,a="get"+r.charAt(0).toUpperCase()+r.slice(1),s=e.shapeInfo.texShape,o=[Math.ceil(s[0]/2),Math.ceil(s[1]/2)];if(1===n[0]){const r=[1,2],s=["b","row","col"];return`\n        ${getPackedSamplerFromInInfo$1(squeezeInputInfo$1(e,n.slice(1)),t)}\n        vec4 ${a}(int b, int row, int col) {\n          return ${a}(${getSqueezedParams$1(s,r)});\n        }\n      `}const i=getGlslDifferences$1();if(t)return`\n    vec4 ${a}(int b, int row, int col) {\n      ivec2 packedTexShape = ivec2(ceil(float(${r}TexShape[0]) / 2.0), ceil(float(${r}TexShape[1]) / 2.0));\n      int valuesPerRow = int(ceil(float(${r}Shape[2]) / 2.0));\n      int texelsInBatch = valuesPerRow * int(ceil(float(${r}Shape[1]) / 2.0));\n      vec2 uv = packedUVfrom3D(\n        packedTexShape[0], packedTexShape[1], texelsInBatch, valuesPerRow, b, row, col);\n      return ${i.texture2D}(${r}, uv);\n    }\n  `;const l=o[0],u=o[1],c=Math.ceil(n[2]/2);return`\n    vec4 ${a}(int b, int row, int col) {\n      vec2 uv = packedUVfrom3D(\n        ${l}, ${u}, ${c*Math.ceil(n[1]/2)}, ${c}, b, row, col);\n      return ${i.texture2D}(${r}, uv);\n    }\n  `}function getSampler3D$1(e,t){const n=e.shapeInfo.logicalShape,r=e.name,a="get"+r.charAt(0).toUpperCase()+r.slice(1),s=n[1]*n[2],o=n[2],{newShape:i,keptDims:l}=squeezeShape$1(n);if(i.length<n.length){const n=["row","col","depth"];return`\n        ${getSamplerFromInInfo$1(squeezeInputInfo$1(e,i),t)}\n        float ${a}(int row, int col, int depth) {\n          return ${a}(${getSqueezedParams$1(n,l)});\n        }\n      `}if(e.shapeInfo.isUniform)return`\n      float ${a}(int row, int col, int depth) {\n        int index = round(dot(vec3(row, col, depth),\n                          vec3(${s}, ${o}, 1)));\n        ${getUniformSampler$1(e)}\n      }\n    `;const u=e.shapeInfo.texShape,c=u[0],p=u[1],d=e.shapeInfo.flatOffset;if(p===s&&null==d)return t?`\n      float ${a}(int row, int col, int depth) {\n        int stride1 = ${r}Shape[2];\n        float texR = float(row);\n        float texC = dot(vec2(col, depth), vec2(stride1, 1));\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(${r}TexShape[1], ${r}TexShape[0]);\n        return sampleTexture(${r}, uv);\n      }\n    `:`\n        float ${a}(int row, int col, int depth) {\n          float texR = float(row);\n          float texC = dot(vec2(col, depth), vec2(${o}, 1));\n          vec2 uv = (vec2(texC, texR) + halfCR) /\n                     vec2(${p}.0, ${c}.0);\n          return sampleTexture(${r}, uv);\n        }\n      `;if(p===o&&null==d)return t?`\n      float ${a}(int row, int col, int depth) {\n        float texR = dot(vec2(row, col), vec2(${r}Shape[1], 1));\n        float texC = float(depth);\n        vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${r}TexShape[1], ${r}TexShape[0]);\n        return sampleTexture(${r}, uv);\n      }\n    `:`\n    float ${a}(int row, int col, int depth) {\n      float texR = dot(vec2(row, col), vec2(${n[1]}, 1));\n      float texC = float(depth);\n      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${p}.0, ${c}.0);\n      return sampleTexture(${r}, uv);\n    }\n  `;const h=getFlatOffsetUniformName$1(r);return t?`\n    float ${a}(int row, int col, int depth) {\n      // Explicitly use integer operations as dot() only works on floats.\n      int stride0 = ${r}Shape[1] * ${r}Shape[2];\n      int stride1 = ${r}Shape[2];\n      int index = row * ${s} + col * ${o} + depth + ${h};\n      vec2 uv = uvFromFlat(${r}TexShape[0], ${r}TexShape[1], index);\n      return sampleTexture(${r}, uv);\n    }\n    `:`\n      float ${a}(int row, int col, int depth) {\n        // Explicitly use integer operations as dot() only works on floats.\n        int index = row * ${s} + col * ${o} + depth + ${h};\n        vec2 uv = uvFromFlat(${c}, ${p}, index);\n        return sampleTexture(${r}, uv);\n      }\n  `}function getPackedSamplerND$1(e,t){const n=e.name,r="get"+n.charAt(0).toUpperCase()+n.slice(1),a=getGlslDifferences$1();if(t)return`\n    vec4 ${r}(int b2, int b, int row, int col) {\n      int valuesPerRow = int(ceil(float(${n}Shape[3]) / 2.0));\n      int texelsInBatch = valuesPerRow * int(ceil(float(${n}Shape[2]) / 2.0));\n      int index = b * texelsInBatch + (row / 2) * valuesPerRow + (col / 2);\n      texelsInBatch *= ${n}Shape[1];\n      index = b2 * texelsInBatch + index;\n      ivec2 packedTexShape = ivec2(ceil(float(${n}TexShape[0]) / 2.0), ceil(float(${n}TexShape[1]) / 2.0));\n      int texR = index / packedTexShape[1];\n      int texC = index - texR * packedTexShape[1];\n      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(packedTexShape[1], packedTexShape[0]); return ${a.texture2D}(${n}, uv);\n    }\n  `;const s=e.shapeInfo.logicalShape,o=s.length,i=e.shapeInfo.texShape,l=[Math.ceil(i[0]/2),Math.ceil(i[1]/2)],u=l[0],c=l[1],p=Math.ceil(s[o-1]/2);let d=p*Math.ceil(s[o-2]/2),h="int b, int row, int col",m=`b * ${d} + (row / 2) * ${p} + (col / 2)`;for(let e=2;e<o-1;e++)h=`int b${e}, `+h,d*=s[o-e-1],m=`b${e} * ${d} + `+m;return`\n    vec4 ${r}(${h}) {\n      int index = ${m};\n      int texR = index / ${c};\n      int texC = index - texR * ${c};\n      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${c}, ${u});\n      return ${a.texture2D}(${n}, uv);\n    }\n  `}function getSampler4D$1(e,t){const n=e.shapeInfo.logicalShape,r=e.name,a="get"+r.charAt(0).toUpperCase()+r.slice(1),s=n[3],o=n[2]*s,i=n[1]*o,{newShape:l,keptDims:u}=squeezeShape$1(n);if(l.length<n.length){const n=["row","col","depth","depth2"];return`\n      ${getSamplerFromInInfo$1(squeezeInputInfo$1(e,l),t)}\n      float ${a}(int row, int col, int depth, int depth2) {\n        return ${a}(${getSqueezedParams$1(n,u)});\n      }\n    `}if(e.shapeInfo.isUniform)return`\n      float ${a}(int row, int col, int depth, int depth2) {\n        int index = round(dot(vec4(row, col, depth, depth2),\n                          vec4(${i}, ${o}, ${s}, 1)));\n        ${getUniformSampler$1(e)}\n      }\n    `;const c=e.shapeInfo.flatOffset,p=e.shapeInfo.texShape,d=p[0],h=p[1],m=`int stride2 = ${r}Shape[3];`,f=`int stride1 = ${r}Shape[2] * stride2;`,g=`int stride0 = ${r}Shape[1] * stride1;`;if(h===i&&null==c)return t?`\n      float ${a}(int row, int col, int depth, int depth2) {\n        ${m}\n        ${f}\n        float texR = float(row);\n        float texC =\n            dot(vec3(col, depth, depth2),\n                vec3(stride1, stride2, 1));\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(${r}TexShape[1], ${r}TexShape[0]);\n        return sampleTexture(${r}, uv);\n      }\n    `:`\n      float ${a}(int row, int col, int depth, int depth2) {\n        float texR = float(row);\n        float texC =\n            dot(vec3(col, depth, depth2),\n                vec3(${o}, ${s}, 1));\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(${h}.0, ${d}.0);\n        return sampleTexture(${r}, uv);\n      }\n    `;if(h===s&&null==c)return t?`\n      float ${a}(int row, int col, int depth, int depth2) {\n        float texR = dot(vec3(row, col, depth),\n                         vec3(${r}Shape[1] * ${r}Shape[2], ${r}Shape[2], 1));\n        float texC = float(depth2);\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                  vec2(${r}TexShape[1], ${r}TexShape[0]);\n        return sampleTexture(${r}, uv);\n      }\n    `:`\n      float ${a}(int row, int col, int depth, int depth2) {\n        float texR = dot(vec3(row, col, depth),\n                         vec3(${n[1]*n[2]}, ${n[2]}, 1));\n        float texC = float(depth2);\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                  vec2(${h}.0, ${d}.0);\n        return sampleTexture(${r}, uv);\n      }\n    `;const $=getFlatOffsetUniformName$1(r);return t?`\n    float ${a}(int row, int col, int depth, int depth2) {\n      // Explicitly use integer operations as dot() only works on floats.\n      ${m}\n      ${f}\n      ${g}\n      int index = row * stride0 + col * stride1 +\n          depth * stride2 + depth2;\n      vec2 uv = uvFromFlat(${r}TexShape[0], ${r}TexShape[1], index + ${$});\n      return sampleTexture(${r}, uv);\n    }\n  `:`\n    float ${a}(int row, int col, int depth, int depth2) {\n      // Explicitly use integer operations as dot() only works on floats.\n      int index = row * ${i} + col * ${o} +\n          depth * ${s} + depth2;\n      vec2 uv = uvFromFlat(${d}, ${h}, index + ${$});\n      return sampleTexture(${r}, uv);\n    }\n  `}function getSampler5D$1(e){const t=e.shapeInfo.logicalShape,n=e.name,r="get"+n.charAt(0).toUpperCase()+n.slice(1),a=t[4],s=t[3]*a,o=t[2]*s,i=t[1]*o,{newShape:l,keptDims:u}=squeezeShape$1(t);if(l.length<t.length){const t=["row","col","depth","depth2","depth3"];return`\n      ${getSamplerFromInInfo$1(squeezeInputInfo$1(e,l))}\n      float ${r}(int row, int col, int depth, int depth2, int depth3) {\n        return ${r}(${getSqueezedParams$1(t,u)});\n      }\n    `}if(e.shapeInfo.isUniform)return`\n      float ${r}(int row, int col, int depth, int depth2, int depth3) {\n        float index = dot(\n          vec4(row, col, depth, depth2),\n          vec4(${i}, ${o}, ${s}, ${a})) +\n          depth3;\n        ${getUniformSampler$1(e)}\n      }\n    `;const c=e.shapeInfo.flatOffset,p=e.shapeInfo.texShape,d=p[0],h=p[1];return h===i&&null==c?`\n      float ${r}(int row, int col, int depth, int depth2, int depth3) {\n        int texR = row;\n        float texC = dot(vec4(col, depth, depth2, depth3),\n                         vec4(${o}, ${s}, ${a}, 1));\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(${h}.0, ${d}.0);\n        return sampleTexture(${n}, uv);\n      }\n    `:h===a&&null==c?`\n      float ${r}(int row, int col, int depth, int depth2, int depth3) {\n        float texR = dot(\n          vec4(row, col, depth, depth2),\n          vec4(${t[1]*t[2]*t[3]},\n               ${t[2]*t[3]}, ${t[3]}, 1));\n        int texC = depth3;\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                  vec2(${h}.0, ${d}.0);\n        return sampleTexture(${n}, uv);\n      }\n    `:`\n    float ${r}(int row, int col, int depth, int depth2, int depth3) {\n      // Explicitly use integer operations as dot() only works on floats.\n      int index = row * ${i} + col * ${o} + depth * ${s} +\n          depth2 * ${a} + depth3 + ${getFlatOffsetUniformName$1(n)};\n      vec2 uv = uvFromFlat(${d}, ${h}, index);\n      return sampleTexture(${n}, uv);\n    }\n  `}function getSampler6D$1(e){const t=e.shapeInfo.logicalShape,n=e.name,r="get"+n.charAt(0).toUpperCase()+n.slice(1),{newShape:a,keptDims:s}=squeezeShape$1(t);if(a.length<t.length){const t=["row","col","depth","depth2","depth3","depth4"];return`\n      ${getSamplerFromInInfo$1(squeezeInputInfo$1(e,a))}\n      float ${r}(int row, int col, int depth,\n                    int depth2, int depth3, int depth4) {\n        return ${r}(${getSqueezedParams$1(t,s)});\n      }\n    `}const o=t[5],i=t[4]*o,l=t[3]*i,u=t[2]*l,c=t[1]*u;if(e.shapeInfo.isUniform)return`\n      float ${r}(int row, int col, int depth,\n                  int depth2, int depth3, int depth4) {\n        int index = round(dot(\n          vec4(row, col, depth, depth2),\n          vec4(${c}, ${u}, ${l}, ${i})) +\n          dot(\n            vec2(depth3, depth4),\n            vec2(${o}, 1)));\n        ${getUniformSampler$1(e)}\n      }\n    `;const p=e.shapeInfo.flatOffset,d=e.shapeInfo.texShape,h=d[0],m=d[1];return m===c&&null==p?`\n      float ${r}(int row, int col, int depth,\n                    int depth2, int depth3, int depth4) {\n        int texR = row;\n        float texC = dot(vec4(col, depth, depth2, depth3),\n          vec4(${u}, ${l}, ${i}, ${o})) +\n               float(depth4);\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(${m}.0, ${h}.0);\n        return sampleTexture(${n}, uv);\n      }\n    `:m===o&&null==p?`\n      float ${r}(int row, int col, int depth,\n                    int depth2, int depth3, int depth4) {\n        float texR = dot(vec4(row, col, depth, depth2),\n          vec4(${t[1]*t[2]*t[3]*t[4]},\n               ${t[2]*t[3]*t[4]},\n               ${t[3]*t[4]},\n               ${t[4]})) + float(depth3);\n        int texC = depth4;\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                  vec2(${m}.0, ${h}.0);\n        return sampleTexture(${n}, uv);\n      }\n    `:`\n    float ${r}(int row, int col, int depth,\n                  int depth2, int depth3, int depth4) {\n      // Explicitly use integer operations as dot() only works on floats.\n      int index = row * ${c} + col * ${u} + depth * ${l} +\n          depth2 * ${i} + depth3 * ${o} + depth4 + ${getFlatOffsetUniformName$1(n)};\n      vec2 uv = uvFromFlat(${h}, ${m}, index);\n      return sampleTexture(${n}, uv);\n    }\n  `}function getUniformSampler$1(e){const t=e.name,n=sizeFromShape$1(e.shapeInfo.logicalShape);return n<2?`return ${t};`:`\n    for (int i = 0; i < ${n}; i++) {\n      if (i == index) {\n        return ${t}[i];\n      }\n    }\n  `}function getPackedSamplerAtOutputCoords$1(e,t){const n=e.name,r=n.charAt(0).toUpperCase()+n.slice(1),a="get"+r+"AtOutCoords",s=e.shapeInfo.logicalShape.length,o=t.logicalShape.length,i=getBroadcastDims$2(e.shapeInfo.logicalShape,t.logicalShape),l=getCoordsDataType$1(o),u=o-s;let c;const p=["x","y","z","w","u","v"];c=0===s?"":o<2&&i.length>=1?"coords = 0;":i.map(e=>`coords.${p[e+u]} = 0;`).join("\n");let d="";d=o<2&&s>0?"coords":e.shapeInfo.logicalShape.map((e,t)=>`coords.${p[t+u]}`).join(", ");let h="return outputValue;";const m=1===sizeFromShape$1(e.shapeInfo.logicalShape),f=1===sizeFromShape$1(t.logicalShape);if(1!==s||m||f){if(m&&!f)h=1===o?"\n        return vec4(outputValue.x, outputValue.x, 0., 0.);\n      ":"\n        return vec4(outputValue.x);\n      ";else if(i.length){const e=s-2,t=s-1;i.indexOf(e)>-1&&i.indexOf(t)>-1?h="return vec4(outputValue.x);":i.indexOf(e)>-1?h="return vec4(outputValue.x, outputValue.y, outputValue.x, outputValue.y);":i.indexOf(t)>-1&&(h="return vec4(outputValue.xx, outputValue.zz);")}}else h="\n      return vec4(outputValue.xy, outputValue.xy);\n    ";return`\n    vec4 ${a}() {\n      ${l} coords = getOutputCoords();\n      ${c}\n      vec4 outputValue = get${r}(${d});\n      ${h}\n    }\n  `}function getSamplerAtOutputCoords$1(e,t){const n=e.name,r=n.charAt(0).toUpperCase()+n.slice(1),a="get"+r+"AtOutCoords",s=e.shapeInfo.logicalShape.length,o=t.logicalShape.length;if(!e.shapeInfo.isUniform&&s===o&&null==e.shapeInfo.flatOffset&&arraysEqual$1(e.shapeInfo.texShape,t.texShape))return`\n      float ${a}() {\n        return sampleTexture(${n}, resultUV);\n      }\n    `;const i=getCoordsDataType$1(o),l=getBroadcastDims$2(e.shapeInfo.logicalShape,t.logicalShape),u=o-s;let c;const p=["x","y","z","w","u","v"];c=0===s?"":o<2&&l.length>=1?"coords = 0;":l.map(e=>`coords.${p[e+u]} = 0;`).join("\n");let d="";return d=o<2&&s>0?"coords":e.shapeInfo.logicalShape.map((e,t)=>`coords.${p[t+u]}`).join(", "),`\n    float ${a}() {\n      ${i} coords = getOutputCoords();\n      ${c}\n      return get${r}(${d});\n    }\n  `}function getCoordsDataType$1(e){if(e<=1)return"int";if(2===e)return"ivec2";if(3===e)return"ivec3";if(4===e)return"ivec4";if(5===e)return"ivec5";if(6===e)return"ivec6";throw Error(`GPU for rank ${e} is not yet supported`)}function getUniformInfoFromShape$1(e,t,n){const{newShape:r}=squeezeShape$1(t),a=t.length,s=e&&3===a&&1===t[0],o=s?t.slice(1):r,i=!e&&a>1&&!arraysEqual$1(t,n)&&r.length<a||s;return{useSqueezeShape:i,uniformShape:i?o:t}}function squeezeInputInfo$1(e,t){const n=JSON.parse(JSON.stringify(e));return n.shapeInfo.logicalShape=t,n}function getSqueezedParams$1(e,t){return t.map(t=>e[t]).join(", ")}function compileProgram$1(e,t,n,r){const a=n.map((e,n)=>{const r={logicalShape:e.shape,texShape:e.isUniform?null:e.texData.texShape,isUniform:e.isUniform,isPacked:!e.isUniform&&e.texData.isPacked,flatOffset:null};return null!=e.texData&&null!=e.texData.slice&&e.texData.slice.flatOffset>0&&(r.flatOffset=e.texData.slice.flatOffset),{name:t.variableNames[n],shapeInfo:r}}),s=a.map(e=>e.shapeInfo),o={logicalShape:r.shape,texShape:r.texData.texShape,isUniform:!1,isPacked:r.texData.isPacked,flatOffset:null},i=makeShader$1(a,o,t),l=e.createProgram(i);let u=null;const c=e.getUniformLocation(l,"NAN",!1);1===env$1().getNumber("WEBGL_VERSION")&&(u=e.getUniformLocation(l,"INFINITY",!1));const p=!1,d={},h={},m={};for(let n=0;n<t.variableNames.length;n++){const r=t.variableNames[n];d[r]=e.getUniformLocation(l,r,p),d[`offset${r}`]=e.getUniformLocation(l,`offset${r}`,p),t.enableShapeUniforms&&(h[`${r}Shape`]=e.getUniformLocation(l,`${r}Shape`,p),m[`${r}TexShape`]=e.getUniformLocation(l,`${r}TexShape`,p))}let f,g,$;t.enableShapeUniforms&&(f=e.getUniformLocation(l,"outShape",p),$=e.getUniformLocation(l,"outShapeStrides",p),g=e.getUniformLocation(l,"outTexShape",p));const y=[];return t.customUniforms&&t.customUniforms.forEach((t,n)=>{y[n]=e.getUniformLocation(l,t.name,p)}),{program:t,source:i,webGLProgram:l,uniformLocations:d,customUniformLocations:y,inShapeInfos:s,outShapeInfo:o,infLoc:u,nanLoc:c,inShapesLocations:h,inTexShapesLocations:m,outShapeLocation:f,outShapeStridesLocation:$,outTexShapeLocation:g}}function validateBinaryAndProgram$1(e,t){if(e.length!==t.length)throw Error(`Binary was compiled with ${e.length} inputs, but was executed with ${t.length} inputs`);e.forEach((e,n)=>{const r=e.logicalShape,a=t[n],s=a.shape;if(!arraysEqual$1(r,s))throw Error(`Binary was compiled with different shapes than the current args. Shapes ${r} and ${s} must match`);if(e.isUniform&&a.isUniform)return;const o=e.texShape,i=a.isUniform?null:a.texData.texShape;if(!arraysEqual$1(o,i))throw Error(`Binary was compiled with different texture shapes than the current args. Shape ${o} and ${i} must match`)})}function runProgram$1(e,t,n,r,a){t.program.enableShapeUniforms||(validateBinaryAndProgram$1(t.inShapeInfos,n),validateBinaryAndProgram$1([t.outShapeInfo],[r]));const s=r.texData.texture,o=r.texData.texShape;r.texData.isPacked?e.setOutputPackedMatrixTexture(s,o[0],o[1]):e.setOutputMatrixTexture(s,o[0],o[1]),e.setProgram(t.webGLProgram),1===env$1().getNumber("WEBGL_VERSION")&&null!==t.infLoc&&e.gl.uniform1f(t.infLoc,Infinity),null!==t.nanLoc&&e.gl.uniform1f(t.nanLoc,NaN),n.forEach((n,r)=>{const a=t.program.variableNames[r],s=t.uniformLocations[a],o=t.uniformLocations[`offset${a}`],i=t.inShapesLocations[`${a}Shape`],l=t.inTexShapesLocations[`${a}TexShape`];if(i){const{uniformShape:r}=getUniformInfoFromShape$1(t.program.packedInputs,n.shape,n.texData.texShape);switch(r.length){case 1:e.gl.uniform1iv(i,new Int32Array(r));break;case 2:e.gl.uniform2iv(i,new Int32Array(r));break;case 3:e.gl.uniform3iv(i,new Int32Array(r));break;case 4:e.gl.uniform4iv(i,new Int32Array(r))}}if(l&&e.gl.uniform2i(l,n.texData.texShape[0],n.texData.texShape[1]),null!=s)if(n.isUniform)if(sizeFromShape$1(n.shape)<2)e.gl.uniform1f(s,n.uniformValues[0]);else{let t=n.uniformValues;t instanceof Float32Array||(t=new Float32Array(t)),e.gl.uniform1fv(s,t)}else null!=n.texData.slice&&null!=o&&e.gl.uniform1i(o,n.texData.slice.flatOffset),e.setInputMatrixTexture(n.texData.texture,s,r)});const i=t.outShapeLocation;if(i)switch(r.shape.length){case 1:e.gl.uniform1iv(i,new Int32Array(r.shape));break;case 2:e.gl.uniform2iv(i,new Int32Array(r.shape));break;case 3:e.gl.uniform3iv(i,new Int32Array(r.shape));break;case 4:e.gl.uniform4iv(i,new Int32Array(r.shape))}if(t.outShapeStridesLocation){const n=computeStrides$1(r.shape);switch(r.shape.length){case 2:e.gl.uniform1iv(t.outShapeStridesLocation,new Int32Array(n));break;case 3:e.gl.uniform2iv(t.outShapeStridesLocation,new Int32Array(n));break;case 4:e.gl.uniform3iv(t.outShapeStridesLocation,new Int32Array(n))}}t.outTexShapeLocation&&e.gl.uniform2i(t.outTexShapeLocation,r.texData.texShape[0],r.texData.texShape[1]),t.program.customUniforms&&a&&t.program.customUniforms.forEach((n,r)=>{const s=t.customUniformLocations[r],o=a[r];if("float"===n.type)e.gl.uniform1fv(s,o);else if("vec2"===n.type)e.gl.uniform2fv(s,o);else if("vec3"===n.type)e.gl.uniform3fv(s,o);else if("vec4"===n.type)e.gl.uniform4fv(s,o);else if("int"===n.type)e.gl.uniform1iv(s,o);else if("ivec2"===n.type)e.gl.uniform2iv(s,o);else if("ivec3"===n.type)e.gl.uniform3iv(s,o);else{if("ivec4"!==n.type)throw Error(`uniform type ${n.type} is not supported yet.`);e.gl.uniform4iv(s,o)}}),e.executeProgram()}function makeShaderKey$1(e,t,n){let r="";t.concat(n).forEach(t=>{const a=null!=t.texData&&null!=t.texData.slice&&t.texData.slice.flatOffset>0;if(e.enableShapeUniforms&&!t.isUniform){const s=t.texData.texShape,{useSqueezeShape:o,uniformShape:i}=getUniformInfoFromShape$1(e.packedInputs,t.shape,s);let l="",u="",c="";if(1===i.length&&e.packedInputs){const e=[Math.ceil(s[0]/2),Math.ceil(s[1]/2)];l=`${e[0]>1}_${e[1]>1}`}else if(2!==i.length||e.packedInputs){if(i.length>2&&!e.packedInputs){const e=computeStrides$1(i);c=`${e[0]===s[1]}_${e[e.length-1]===s[1]}`}}else u=`${i[0]>1}_${i[1]>1}`;const p=t.shape.length,d=2===p&&arraysEqual$1(t.shape,s),h=1===sizeFromShape$1(t.shape),m=getBroadcastDims$3(t.shape,n.shape),f=!e.packedInputs&&p===n.shape.length&&arraysEqual$1(s,n.texData.texShape);r+=`${p}_${f}_${o}_${i.length}_${h}_${m}_${d}_${l}_${u}_${c}_${e.packedInputs||p>2?"":`${s[0]>1}_${s[1]>1}`}_${a}`}else r+=`${t.shape}_${t.isUniform?"uniform":t.texData.texShape}_${a}`});let a=e.constructor.name;return a+="_"+r+"_"+e.userCode+`${env$1().getNumber("WEBGL_VERSION")}`,a}function useShapeUniforms$1(e){return env$1().getBool("WEBGL_USE_SHAPES_UNIFORMS")&&e<=4}const{addImpl:addImplCPU$1,bincountImpl:bincountImplCPU$1,bincountReduceImpl:bincountReduceImplCPU$1,ceilImpl:ceilImplCPU$1,concatImpl:concatImplCPU$1,equalImpl:equalImplCPU$1,expImpl:expImplCPU$1,expm1Impl:expm1ImplCPU$1,floorImpl:floorImplCPU$1,gatherNdImpl:gatherNdImplCPU$1,gatherV2Impl:gatherV2ImplCPU$1,greaterImpl:greaterImplCPU$1,greaterEqualImpl:greaterEqualImplCPU$1,lessImpl:lessImplCPU$1,lessEqualImpl:lessEqualImplCPU$1,linSpaceImpl:linSpaceImplCPU$1,logImpl:logImplCPU$1,maxImpl:maxImplCPU$1,maximumImpl:maximumImplCPU$1,minimumImpl:minimumImplCPU$1,multiplyImpl:multiplyImplCPU$1,negImpl:negImplCPU$1,notEqualImpl:notEqualImplCPU$1,prodImpl:prodImplCPU$1,rangeImpl:rangeImplCPU$1,rsqrtImpl:rsqrtImplCPU$1,simpleAbsImpl:simpleAbsImplCPU$1,sliceImpl:sliceImplCPU$1,sparseFillEmptyRowsImpl:sparseFillEmptyRowsImplCPU$1,sparseReshapeImpl:sparseReshapeImplCPU$1,sparseSegmentReductionImpl:sparseSegmentReductionImplCPU$1,stridedSliceImpl:stridedSliceImplCPU$1,stringNGramsImpl:stringNGramsImplCPU$1,stringSplitImpl:stringSplitImplCPU$1,stringToHashBucketFastImpl:stringToHashBucketFastImplCPU$1,subImpl:subImplCPU$1,tileImpl:tileImplCPU$1,topKImpl:topKImplCPU$1,transposeImpl:transposeImplCPU$1,uniqueImpl:uniqueImplCPU$1}=shared$1;function getVecChannels$1(e,t){return["x","y","z","w","u","v"].slice(0,t).map(t=>`${e}.${t}`)}function getChannels$1(e,t){return 1===t?[e]:getVecChannels$1(e,t)}function getSourceCoords$5(e,t){if(1===e)return"rc";let n="";for(let r=0;r<e;r++)n+=t[r],r<e-1&&(n+=",");return n}class PackProgram$1{constructor(e){this.variableNames=["A"],this.packedInputs=!1,this.packedOutput=!0,this.outputShape=e;const t=e.length;if(0===t)this.userCode="\n        void main() {\n          setOutput(vec4(getA(), 0., 0., 0.));\n        }\n      ";else{const n=getChannels$1("rc",t),r=getCoordsDataType$1(t),a=getOutOfBoundsCondition$1(t,e,n),s=getSetup$1(t,e[e.length-1],e[e.length-2],n),o=getOutput$1(e,n);this.userCode=`\n        void main() {\n          ${r} rc = getOutputCoords();\n\n          if(${a}) {\n            setOutput(vec4(0));\n          } else {\n            ${s}\n\n            setOutput(vec4(${o}));\n          }\n        }\n      `}}}function getSourceCoordsArr$1(e,t){const n=[];for(let r=0;r<=1;r++)for(let a=0;a<=1;a++){let s=`${0===r?"r":"rp1"}, ${0===a?"c":"cp1"}`;for(let n=2;n<e;n++)s=`${t[t.length-1-n]},`+s;n.push(s)}return n}function getOutOfBoundsCondition$1(e,t,n){if(1===e)return`rc > ${t[0]}`;let r="";for(let a=e-2;a<e;a++)r+=`${n[a]} >= ${t[a]}`,a<e-1&&(r+="||");return r}function getSetup$1(e,t,n,r){if(1===e)return"";const a=r.slice(-2);return`\n    int r = ${a[0]};\n    int c = ${a[1]};\n    int rp1 = r + 1;\n    int cp1 = c + 1;\n\n    bool cEdge = cp1 >= ${t};\n    bool rEdge = rp1 >= ${n};\n  `}function getOutput$1(e,t){const n=e.length,r=getSourceCoordsArr$1(n,t);return 1===n?`getA(rc),\n            rc + 1 >= ${e[0]} ? 0. : getA(rc + 1),\n            0, 0`:`getA(${r[0]}),\n          cEdge ? 0. : getA(${r[1]}),\n          rEdge ? 0. : getA(${r[2]}),\n          rEdge || cEdge ? 0. : getA(${r[3]})`}class ReshapePackedProgram$1{constructor(e,t){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=e;let n="";for(let e=0;e<4;e++){let t="thisRC = rc;";e%2==1&&(t+="thisRC.z += 1;"),e>1&&(t+="thisRC.y += 1;"),n+=`\n        ${t}\n        ${e>0?"if(thisRC.y < rows && thisRC.z < cols){":""}\n          int flatIndex = getFlatIndex(thisRC);\n\n          ivec3 inputRC = inputCoordsFromReshapedOutCoords(flatIndex);\n          vec2 inputRCInnerDims = vec2(float(inputRC.y),float(inputRC.z));\n\n          result[${e}] =\n            getChannel(getA(inputRC.x, inputRC.y, inputRC.z), inputRCInnerDims);\n        ${e>0?"}":""}\n      `}this.userCode=`\n      ${getReshapedInputCoords$1(t)}\n      ${getFlatIndexFrom3D$1(e)}\n\n      void main() {\n        ivec3 rc = getOutputCoords();\n\n        vec4 result = vec4(0.);\n\n        ivec3 thisRC;\n        int rows = ${e[1]};\n        int cols = ${e[2]};\n\n        ${n}\n\n        setOutput(result);\n      }\n    `}}function getReshapedInputCoords$1(e){return`\n    ivec3 inputCoordsFromReshapedOutCoords(int index) {\n      ${getLogicalCoordinatesFromFlatIndex$1(["r","c","d"],e)}\n      return ivec3(r, c, d);\n    }\n  `}class TextureManager$1{constructor(e){this.gpgpu=e,this.numUsedTextures=0,this.numFreeTextures=0,this._numBytesAllocated=0,this._numBytesFree=0,this.freeTextures={},this.logEnabled=!1,this.usedTextures={}}acquireTexture(e,t,n){const r=getPhysicalFromLogicalTextureType$1(t,n),a=getKeyFromTextureShape$1(e,r,n);a in this.freeTextures||(this.freeTextures[a]=[]),a in this.usedTextures||(this.usedTextures[a]=[]);const s=computeBytes$1(e,r,this.gpgpu.gl,this.gpgpu.textureConfig,n);if(this.freeTextures[a].length>0){this.numFreeTextures--,this.numUsedTextures++,this._numBytesFree-=s,this.log();const e=this.freeTextures[a].shift();return this.usedTextures[a].push(e),e}let o;return r===PhysicalTextureType$1.PACKED_2X2_FLOAT32?o=this.gpgpu.createPackedMatrixTexture(e[0],e[1]):r===PhysicalTextureType$1.PACKED_2X2_FLOAT16?o=this.gpgpu.createFloat16PackedMatrixTexture(e[0],e[1]):r===PhysicalTextureType$1.UNPACKED_FLOAT32?o=this.gpgpu.createFloat32MatrixTexture(e[0],e[1]):r===PhysicalTextureType$1.UNPACKED_FLOAT16?o=this.gpgpu.createFloat16MatrixTexture(e[0],e[1]):r===PhysicalTextureType$1.PACKED_4X1_UNSIGNED_BYTE&&(o=this.gpgpu.createUnsignedBytesMatrixTexture(e[0],e[1])),this.usedTextures[a].push(o),this.numUsedTextures++,this._numBytesAllocated+=s,this.log(),o}releaseTexture(e,t,n,r){if(null==this.freeTextures)return;const a=getPhysicalFromLogicalTextureType$1(n,r),s=getKeyFromTextureShape$1(t,a,r);s in this.freeTextures||(this.freeTextures[s]=[]);const o=computeBytes$1(t,a,this.gpgpu.gl,this.gpgpu.textureConfig,r),i=env$1().get("WEBGL_DELETE_TEXTURE_THRESHOLD");-1!==i&&this._numBytesAllocated>i?(this.gpgpu.deleteMatrixTexture(e),this._numBytesAllocated-=o):(this.freeTextures[s].push(e),this.numFreeTextures++,this._numBytesFree+=o),this.numUsedTextures--;const l=this.usedTextures[s],u=l.indexOf(e);if(u<0)throw new Error("Cannot release a texture that was never provided by this texture manager");l.splice(u,1),this.log()}log(){if(!this.logEnabled)return;console.log("Free/Used",`${this.numFreeTextures} / ${this.numUsedTextures}`,`(${this.numFreeTextures+this.numUsedTextures})`);const e=this._numBytesFree/this._numBytesAllocated;console.log(`Bytes allocated: ${this._numBytesAllocated}`),console.log(`Bytes unused: ${this._numBytesFree} (${Math.round(100*e)}%)`)}get numBytesAllocated(){return this._numBytesAllocated}get numBytesFree(){return this._numBytesFree}getNumUsedTextures(){return this.numUsedTextures}getNumFreeTextures(){return this.numFreeTextures}dispose(){if(null!=this.freeTextures){for(const e in this.freeTextures)this.freeTextures[e].forEach(e=>{this.gpgpu.deleteMatrixTexture(e)});for(const e in this.usedTextures)this.usedTextures[e].forEach(e=>{this.gpgpu.deleteMatrixTexture(e)});this.freeTextures=null,this.usedTextures=null,this.numUsedTextures=0,this.numFreeTextures=0,this._numBytesAllocated=0,this._numBytesFree=0}}}function numBytesForInternalFormat$1(e,t){if(t===e.R32F)return 4;if(t===e.R16F)return 2;if(t===e.RGBA32F)return 16;if(t===e.RGBA)return 16;if(t===e.RGBA16F)return 8;throw new Error(`Unknown internal format ${t}`)}function computeBytes$1(e,t,n,r,a){const s=internalFormatForPhysicalTexType$1(t,r);let o;if(a){const[t,n]=getPackedMatrixTextureShapeWidthHeight$1(e[0],e[1]);o=t*n}else{const[t,n]=getUnpackedMatrixTextureShapeWidthHeight$1(e[0],e[1]);o=t*n}return o*numBytesForInternalFormat$1(n,s)}function internalFormatForPhysicalTexType$1(e,t){switch(e){case PhysicalTextureType$1.PACKED_2X2_FLOAT32:return getInternalFormatForPackedMatrixTexture$1(t);case PhysicalTextureType$1.PACKED_2X2_FLOAT16:return getInternalFormatForFloat16PackedMatrixTexture$1(t);case PhysicalTextureType$1.UNPACKED_FLOAT32:return getInternalFormatForFloat32MatrixTexture$1(t);case PhysicalTextureType$1.UNPACKED_FLOAT16:return getInternalFormatForFloat16MatrixTexture$1(t);case PhysicalTextureType$1.PACKED_4X1_UNSIGNED_BYTE:return getInternalFormatForUnsignedBytesMatrixTexture$1(t);default:throw new Error(`Unknown physical texture type ${e}`)}}function getPhysicalTextureForRendering$1(e){return env$1().getBool("WEBGL_RENDER_FLOAT32_ENABLED")?e?PhysicalTextureType$1.PACKED_2X2_FLOAT32:PhysicalTextureType$1.UNPACKED_FLOAT32:e?PhysicalTextureType$1.PACKED_2X2_FLOAT16:PhysicalTextureType$1.UNPACKED_FLOAT16}function getPhysicalFromLogicalTextureType$1(e,t){if(e===TextureUsage$1.UPLOAD)return PhysicalTextureType$1.PACKED_2X2_FLOAT32;if(e===TextureUsage$1.RENDER||null==e)return getPhysicalTextureForRendering$1(t);if(e===TextureUsage$1.DOWNLOAD||e===TextureUsage$1.PIXELS)return PhysicalTextureType$1.PACKED_4X1_UNSIGNED_BYTE;throw new Error(`Unknown logical texture type ${e}`)}function getKeyFromTextureShape$1(e,t,n){return`${e[0]}_${e[1]}_${t}_${n}`}class UnaryOpProgram$1{constructor(e,t){this.variableNames=["A"],this.outputShape=e,this.enableShapeUniforms=useShapeUniforms$1(this.outputShape.length),this.userCode=`\n      float unaryOperation(float x) {\n        ${t}\n      }\n\n      void main() {\n        float x = getAAtOutCoords();\n        float y = unaryOperation(x);\n\n        setOutput(y);\n      }\n    `}}const CHECK_NAN_SNIPPET$5="if (isnan(x)) return x;",LINEAR$3="return x;",ABS$3="return abs(x);",ELU$6="return (x >= 0.0) ? x : (exp(x) - 1.0);",RELU$5=CHECK_NAN_SNIPPET$5+"\n  return (x < 0.0) ? 0.0 : x;\n",RELU6$5=CHECK_NAN_SNIPPET$5+"\n  return (x < 0.0) ? 0.0 : min(6.0, x);\n",CLONE$1="return x;",SIGMOID$5="return 1.0 / (1.0 + exp(-1.0 * x));",LINEAR$2="return x;",ELU$5="\n  vec4 result;\n\n  result.r = (x.r >= 0.0) ? x.r : (exp(x.r) - 1.0);\n  result.g = (x.g >= 0.0) ? x.g : (exp(x.g) - 1.0);\n  result.b = (x.b >= 0.0) ? x.b : (exp(x.b) - 1.0);\n  result.a = (x.a >= 0.0) ? x.a : (exp(x.a) - 1.0);\n\n  return result;\n",RELU$4="\n  vec4 result = x * vec4(greaterThanEqual(x, vec4(0.0)));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n",RELU6$4="\n  vec4 result = min(x, vec4(6.)) * vec4(greaterThanEqual(x, vec4(0.0)));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n",SIGMOID$4="return 1.0 / (1.0 + exp(-1.0 * x));";class UnaryOpPackedProgram$1{constructor(e,t){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=e,this.enableShapeUniforms=useShapeUniforms$1(this.outputShape.length),this.userCode=`\n      vec4 unaryOperation(vec4 x) {\n        ${t}\n      }\n\n      void main() {\n        vec4 x = getAAtOutCoords();\n        vec4 y = unaryOperation(x);\n\n        setOutput(y);\n      }\n    `}}class UnpackProgram$1{constructor(e){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!1,this.outputShape=e;const t=e.length,n=getChannels$1("rc",t),r=getCoordsDataType$1(t),a=getSourceCoords$5(t,n),s=n.slice(-2),o=t<=1?"rc":`vec2(${s.join(",")})`;this.userCode=`\n      void main() {\n        ${r} rc = getOutputCoords();\n        vec4 packedInput = getA(${a});\n\n        setOutput(getChannel(packedInput, ${o}));\n      }\n    `}}const whereImpl$3=whereImpl$5,EPSILON_FLOAT32$2=1e-7,EPSILON_FLOAT16$2=1e-4,binaryCaches$1={};function getBinaryCache$1(e){return e in binaryCaches$1||(binaryCaches$1[e]={}),binaryCaches$1[e]}const CPU_HANDOFF_SIZE_THRESHOLD$1=env$1().getNumber("CPU_HANDOFF_SIZE_THRESHOLD"),BEFORE_PAGING_CONSTANT$1=600;function numMBBeforeWarning$1(){return null==env$1().global.screen?1024:env$1().global.screen.height*env$1().global.screen.width*window.devicePixelRatio*BEFORE_PAGING_CONSTANT$1/1024/1024}class MathBackendWebGL$1 extends KernelBackend$1{constructor(e){if(super(),this.pendingRead=new WeakMap,this.pendingDisposal=new WeakSet,this.dataRefCount=new WeakMap,this.numBytesInGPU=0,this.uploadWaitMs=0,this.downloadWaitMs=0,this.lastGlFlushTime=0,this.warnedAboutMemory=!1,this.pendingDeletes=0,this.disposed=!1,!env$1().getBool("HAS_WEBGL"))throw new Error("WebGL is not supported on this device");if(null==e){const e=getWebGLContext$1(env$1().getNumber("WEBGL_VERSION"));this.binaryCache=getBinaryCache$1(env$1().getNumber("WEBGL_VERSION")),this.gpgpu=new GPGPUContext$1(e),this.canvas=e.canvas,this.gpgpuCreatedLocally=!0}else this.gpgpu=e,this.binaryCache={},this.gpgpuCreatedLocally=!1,this.canvas=e.gl.canvas;this.textureManager=new TextureManager$1(this.gpgpu),this.numMBBeforeWarning=numMBBeforeWarning$1(),this.texData=new DataStorage$1(this,engine$1())}nextDataId(){return MathBackendWebGL$1.nextDataId++}numDataIds(){return this.texData.numDataIds()-this.pendingDeletes}write(e,t,n){if((env$1().getBool("WEBGL_CHECK_NUMERICAL_PROBLEMS")||env$1().getBool("DEBUG"))&&this.checkNumericalProblems(e),"complex64"===n&&null!=e)throw new Error("Cannot write to a complex64 dtype. Please use tf.complex(real, imag).");const r={id:this.nextDataId()};return this.texData.set(r,{shape:t,dtype:n,values:e,usage:TextureUsage$1.UPLOAD,refCount:1}),r}refCount(e){return this.texData.has(e)?this.texData.get(e).refCount:0}incRef(e){this.texData.get(e).refCount++}decRef(e){this.texData.has(e)&&this.texData.get(e).refCount--}move(e,t,n,r,a){if(env$1().getBool("DEBUG")&&this.checkNumericalProblems(t),"complex64"===r)throw new Error("Cannot write to a complex64 dtype. Please use tf.complex(real, imag).");this.texData.set(e,{shape:n,dtype:r,values:t,usage:TextureUsage$1.UPLOAD,refCount:a})}disposeIntermediateTensorInfo(e){this.disposeData(e.dataId)}readSync(e){const t=this.texData.get(e),{values:n,dtype:r,complexTensorInfos:a,slice:s,shape:o,isPacked:i}=t;if(null!=s){let t;t=i?new UnaryOpPackedProgram$1(o,CLONE$1):new UnaryOpProgram$1(o,CLONE$1);const n=this.runWebGLProgram(t,[{dataId:e,shape:o,dtype:r}],r),a=this.readSync(n.dataId);return this.disposeIntermediateTensorInfo(n),a}if(null!=n)return this.convertAndCacheOnCPU(e);if("string"===r)return n;const l=null!=this.activeTimers;let u,c;return l&&(u=now$1()),c="complex64"===r?mergeRealAndImagArrays$1(this.readSync(a.real.dataId),this.readSync(a.imag.dataId)):this.getValuesFromTexture(e),l&&(this.downloadWaitMs+=now$1()-u),this.convertAndCacheOnCPU(e,c)}async read(e){if(this.pendingRead.has(e)){const t=this.pendingRead.get(e);return new Promise(e=>t.push(e))}const t=this.texData.get(e),{values:n,shape:r,slice:a,dtype:s,complexTensorInfos:o,isPacked:i}=t;if(null!=a){let t;t=i?new UnaryOpPackedProgram$1(r,CLONE$1):new UnaryOpProgram$1(r,CLONE$1);const n=this.runWebGLProgram(t,[{dataId:e,shape:r,dtype:s}],s),a=this.read(n.dataId);return this.disposeIntermediateTensorInfo(n),a}if(null!=n)return this.convertAndCacheOnCPU(e);if(!env$1().getBool("WEBGL_DOWNLOAD_FLOAT_ENABLED")&&2===env$1().getNumber("WEBGL_VERSION"))throw new Error("tensor.data() with WEBGL_DOWNLOAD_FLOAT_ENABLED=false and WEBGL_VERSION=2 not yet supported.");let l,u,c=null;if("complex64"!==s&&env$1().get("WEBGL_BUFFER_SUPPORTED")){l=this.decode(e);const t=this.texData.get(l.dataId);c=this.gpgpu.createBufferFromTexture(t.texture,...getDenseTexShape$1(r))}if(this.pendingRead.set(e,[]),"complex64"!==s&&await this.gpgpu.createAndWaitForFence(),"complex64"===s){const e=await Promise.all([this.read(o.real.dataId),this.read(o.imag.dataId)]);u=mergeRealAndImagArrays$1(e[0],e[1])}else if(null==c)u=this.getValuesFromTexture(e);else{const e=sizeFromShape$1(r);u=this.gpgpu.downloadFloat32MatrixFromBuffer(c,e)}if(null!=l&&this.disposeIntermediateTensorInfo(l),null!=c){const e=this.gpgpu.gl;callAndCheck$1(e,()=>e.deleteBuffer(c))}const p=this.convertAndCacheOnCPU(e,u),d=this.pendingRead.get(e);return this.pendingRead.delete(e),d.forEach(e=>e(p)),this.pendingDisposal.has(e)&&(this.pendingDisposal.delete(e),this.disposeData(e)&&engine$1().removeDataId(e,this),this.pendingDeletes--),p}bufferSync(e){const t=this.readSync(e.dataId);let n=t;if("string"===e.dtype)try{n=t.map(e=>decodeString$1(e))}catch(e){throw new Error("Failed to decode encoded string bytes into utf-8")}return buffer$1(e.shape,e.dtype,n)}checkNumericalProblems(e){if(null!=e)for(let t=0;t<e.length;t++){const n=e[t];if(!canBeRepresented$1(n)){if(env$1().getBool("WEBGL_RENDER_FLOAT32_CAPABLE"))throw Error(`The value ${n} cannot be represented with your current settings. Consider enabling float32 rendering: 'tf.env().set('WEBGL_RENDER_FLOAT32_ENABLED', true);'`);throw Error(`The value ${n} cannot be represented on this device.`)}}}getValuesFromTexture(e){const{shape:t,dtype:n,isPacked:r}=this.texData.get(e),a=sizeFromShape$1(t);if(env$1().getBool("WEBGL_DOWNLOAD_FLOAT_ENABLED")){const n=this.decode(e),r=this.texData.get(n.dataId),s=this.gpgpu.downloadMatrixFromPackedTexture(r.texture,...getDenseTexShape$1(t)).subarray(0,a);return this.disposeIntermediateTensorInfo(n),s}const s=env$1().getBool("WEBGL_PACK")&&!0===r,o=s?getShapeAs3D$1(t):t,i=s?new EncodeFloatPackedProgram$1(o):new EncodeFloatProgram$1(o),l=this.runWebGLProgram(i,[{shape:o,dtype:n,dataId:e}],"float32"),u=this.texData.get(l.dataId),c=this.gpgpu.downloadByteEncodedFloatMatrixFromOutputTexture(u.texture,u.texShape[0],u.texShape[1]).subarray(0,a);return this.disposeIntermediateTensorInfo(l),c}timerAvailable(){return env$1().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE")>0}async time(e){const t=this.activeTimers,n=[];let r=!1;null==this.programTimersStack?(this.programTimersStack=n,r=!0):this.activeTimers.push(n),this.activeTimers=n,e();const a=flatten$6(this.activeTimers.map(e=>e.query)).filter(e=>null!=e),s=flatten$6(this.activeTimers.map(e=>e.name)).filter(e=>null!=e);this.activeTimers=t,r&&(this.programTimersStack=null);const o={uploadWaitMs:this.uploadWaitMs,downloadWaitMs:this.downloadWaitMs,kernelMs:null,wallMs:null};if(env$1().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE")>0){const e=await Promise.all(a);o.kernelMs=sum$7(e),o.getExtraProfileInfo=()=>e.map((e,t)=>({name:s[t],ms:e})).map(e=>`${e.name}: ${e.ms}`).join(", ")}else o.kernelMs={error:"WebGL query timers are not supported in this environment."};return this.uploadWaitMs=0,this.downloadWaitMs=0,o}memory(){return{unreliable:!1,numBytesInGPU:this.numBytesInGPU,numBytesInGPUAllocated:this.textureManager.numBytesAllocated,numBytesInGPUFree:this.textureManager.numBytesFree}}startTimer(){return env$1().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE")>0?this.gpgpu.beginQuery():{startMs:now$1(),endMs:null}}endTimer(e){return env$1().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE")>0?(this.gpgpu.endQuery(),e):(e.endMs=now$1(),e)}async getQueryTime(e){return env$1().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE")>0?this.gpgpu.waitForQueryAndGetTime(e):e.endMs-e.startMs}disposeData(e,t=!1){if(this.pendingDisposal.has(e))return!1;if(!this.texData.has(e))return!0;if(t?this.texData.get(e).refCount=0:this.texData.get(e).refCount--,!t&&this.texData.get(e).refCount>0)return!1;if(this.pendingRead.has(e))return this.pendingDisposal.add(e),this.pendingDeletes++,!1;this.releaseGPUData(e);const{complexTensorInfos:n}=this.texData.get(e);return null!=n&&(this.disposeData(n.real.dataId,t),this.disposeData(n.imag.dataId,t)),this.texData.delete(e),!0}releaseGPUData(e){const{texture:t,dtype:n,texShape:r,usage:a,isPacked:s,slice:o}=this.texData.get(e),i=o&&o.origDataId||e,l=this.dataRefCount.get(i);l>1?this.dataRefCount.set(i,l-1):(this.dataRefCount.delete(i),null!=t&&(this.numBytesInGPU-=this.computeBytes(r,n),this.textureManager.releaseTexture(t,r,a,s)));const u=this.texData.get(e);u.texture=null,u.texShape=null,u.isPacked=!1,u.slice=null}getTexture(e){return this.uploadToGPU(e),this.texData.get(e).texture}getDataInfo(e){return this.texData.get(e)}shouldExecuteOnCPU(e,t=CPU_HANDOFF_SIZE_THRESHOLD$1){return env$1().getBool("WEBGL_CPU_FORWARD")&&e.every(e=>null==this.texData.get(e.dataId).texture&&sizeFromShape$1(e.shape)<t)}getGPGPUContext(){return this.gpgpu}where(e){warn$1("tf.where() in webgl locks the UI thread. Call tf.whereAsync() instead");const t=e.dataSync();return whereImpl$3(e.shape,t)}packedUnaryOp(e,t,n){const r=new UnaryOpPackedProgram$1(e.shape,t),a=this.compileAndRun(r,[e],n);return engine$1().makeTensorFromDataId(a.dataId,a.shape,a.dtype)}abs(e){if(this.shouldExecuteOnCPU([e])&&"complex64"!==e.dtype){const t=simpleAbsImplCPU$1(this.texData.get(e.dataId).values);return this.makeOutput(e.shape,e.dtype,t)}if(env$1().getBool("WEBGL_PACK_UNARY_OPERATIONS"))return this.packedUnaryOp(e,ABS$3,e.dtype);const t=new UnaryOpProgram$1(e.shape,ABS$3),n=this.compileAndRun(t,[e]);return engine$1().makeTensorFromDataId(n.dataId,n.shape,n.dtype)}makeTensorInfo(e,t,n){let r;if("string"===t&&null!=n&&n.length>0&&isString$1(n[0])){const a=n.map(e=>encodeString$1(e));r=this.write(a,e,t)}else r=this.write(n,e,t);return this.texData.get(r).usage=null,{dataId:r,shape:e,dtype:t}}makeOutput(e,t,n){const{dataId:r}=this.makeTensorInfo(e,t,n);return engine$1().makeTensorFromDataId(r,e,t,this)}unpackTensor(e){const t=new UnpackProgram$1(e.shape);return this.runWebGLProgram(t,[e],e.dtype)}packTensor(e){const t=new PackProgram$1(e.shape);return this.runWebGLProgram(t,[e],e.dtype,null,!0)}packedReshape(e,t){const n=[getBatchDim$1(e.shape),...getRowsCols$1(e.shape)],r={dtype:e.dtype,shape:n,dataId:e.dataId},a=[getBatchDim$1(t),...getRowsCols$1(t)],s=new ReshapePackedProgram$1(a,n),o=this.runWebGLProgram(s,[r],e.dtype,null,!0);return{dataId:o.dataId,shape:t,dtype:o.dtype}}decode(e){const t=this.texData.get(e),{isPacked:n,shape:r,dtype:a}=t,s=getShapeAs3D$1(r);let o;return o=n?new DecodeMatrixPackedProgram$1(s):new DecodeMatrixProgram$1(s),{dtype:a,shape:r,dataId:this.runWebGLProgram(o,[{shape:s,dtype:a,dataId:e}],a,null,!0).dataId}}runWebGLProgram(e,t,n,r,a=!1){const s=this.makeTensorInfo(e.outputShape,n),o=this.texData.get(s.dataId);if(e.packedOutput&&(o.isPacked=!0),e.outPackingScheme===PackingScheme$1.DENSE){const t=getDenseTexShape$1(e.outputShape);o.texShape=t.map(e=>2*e)}if(null!=e.outTexUsage&&(o.usage=e.outTexUsage),0===sizeFromShape$1(s.shape))return o.values=getTypedArrayFromDType$1(s.dtype,0),s;const i=[],l=t.map(t=>{if("complex64"===t.dtype)throw new Error("GPGPUProgram does not support complex64 input. For complex64 dtypes, please separate the program into real and imaginary parts.");let n=this.texData.get(t.dataId);if(null==n.texture){if(!e.packedInputs&&sizeFromShape$1(t.shape)<=env$1().getNumber("WEBGL_SIZE_UPLOAD_UNIFORM"))return{shape:t.shape,texData:null,isUniform:!0,uniformValues:n.values};e.packedInputs&&(n.isPacked=!0,n.shape=t.shape)}else if(!!n.isPacked!=!!e.packedInputs)t=n.isPacked?this.unpackTensor(t):this.packTensor(t),i.push(t),n=this.texData.get(t.dataId);else if(n.isPacked&&!isReshapeFree$1(n.shape,t.shape)){const e=t,r=t.shape;t.shape=n.shape,t=this.packedReshape(t,r),i.push(t),n=this.texData.get(t.dataId),e.shape=r}return this.uploadToGPU(t.dataId),{shape:t.shape,texData:n,isUniform:!1}});this.uploadToGPU(s.dataId);const u={shape:s.shape,texData:o,isUniform:!1},c=makeShaderKey$1(e,l,u),p=this.getAndSaveBinary(c,()=>compileProgram$1(this.gpgpu,e,l,u)),d=null!=this.activeTimers;let h;d&&(h=this.startTimer()),runProgram$1(this.gpgpu,p,l,u,r),i.forEach(e=>this.disposeIntermediateTensorInfo(e)),d&&(h=this.endTimer(h),this.activeTimers.push({name:e.constructor.name,query:this.getQueryTime(h)}));const m=env$1().get("WEBGL_FLUSH_THRESHOLD");if(m>0){const e=now$1();e-this.lastGlFlushTime>m&&(this.gpgpu.gl.flush(),this.lastGlFlushTime=e)}if(!env$1().getBool("WEBGL_LAZILY_UNPACK")&&o.isPacked&&!1===a){const e=this.unpackTensor(s);return this.disposeIntermediateTensorInfo(s),e}return s}compileAndRun(e,t,n,r,a=!1){return this.runWebGLProgram(e,t,n=n||t[0].dtype,r,a)}getAndSaveBinary(e,t){return e in this.binaryCache||(this.binaryCache[e]=t()),this.binaryCache[e]}getTextureManager(){return this.textureManager}dispose(){this.disposed||(env$1().getBool("IS_TEST")||Object.keys(this.binaryCache).forEach(e=>{this.gpgpu.deleteProgram(this.binaryCache[e].webGLProgram),delete this.binaryCache[e]}),this.textureManager.dispose(),null!=this.canvas&&"undefined"!=typeof HTMLCanvasElement&&this.canvas instanceof HTMLCanvasElement?this.canvas.remove():this.canvas=null,this.gpgpuCreatedLocally&&(this.gpgpu.program=null,this.gpgpu.dispose()),this.disposed=!0)}floatPrecision(){return null==this.floatPrecisionValue&&(this.floatPrecisionValue=tidy$1(()=>{if(!env$1().get("WEBGL_RENDER_FLOAT32_ENABLED")){const e=env$1().getBool("DEBUG");env$1().set("DEBUG",!1);const t=this.abs(scalar$1(1e-8)).dataSync()[0];if(env$1().set("DEBUG",e),t>0)return 32}return 16})),this.floatPrecisionValue}epsilon(){return 32===this.floatPrecision()?EPSILON_FLOAT32$2:EPSILON_FLOAT16$2}uploadToGPU(e){const t=this.texData.get(e),{shape:n,dtype:r,values:a,texture:s,usage:o,isPacked:i}=t;if(null!=s)return;const l=null!=this.activeTimers;let u;l&&(u=now$1());let c=t.texShape;if(null==c&&(c=getTextureShapeFromLogicalShape$1(n,i),t.texShape=c),null!=a){const e=getShapeAs3D$1(n);let s,o=c[1],p=c[0];const d=a instanceof Uint8Array;i?([o,p]=getPackedMatrixTextureShapeWidthHeight$1(c[0],c[1]),s=new EncodeMatrixPackedProgram$1(e,[p,o],d)):s=new EncodeMatrixProgram$1(e,[p,o],d);const h=this.makeTensorInfo([p,o],r);this.texData.get(h.dataId).usage=d?TextureUsage$1.PIXELS:TextureUsage$1.UPLOAD,this.gpgpu.uploadDenseMatrixToTexture(this.getTexture(h.dataId),o,p,a);const m=this.runWebGLProgram(s,[h],r,null,!0),f=this.texData.get(m.dataId);t.texture=f.texture,t.texShape=f.texShape,t.isPacked=f.isPacked,t.usage=f.usage,this.disposeIntermediateTensorInfo(h),this.texData.delete(m.dataId),t.values=null,l&&(this.uploadWaitMs+=now$1()-u)}else{const e=this.acquireTexture(c,o,r,i);t.texture=e}}convertAndCacheOnCPU(e,t){const n=this.texData.get(e),{dtype:r}=n;return this.releaseGPUData(e),null!=t&&(n.values=float32ToTypedArray$1(t,r)),n.values}acquireTexture(e,t,n,r){if(this.numBytesInGPU+=this.computeBytes(e,n),!this.warnedAboutMemory&&this.numBytesInGPU>1024*this.numMBBeforeWarning*1024){const e=(this.numBytesInGPU/1024/1024).toFixed(2);this.warnedAboutMemory=!0,console.warn(`High memory usage in GPU: ${e} MB, most likely due to a memory leak`)}return this.textureManager.acquireTexture(e,t,r)}computeBytes(e,t){return e[0]*e[1]*bytesPerElement$1(t)}}function float32ToTypedArray$1(e,t){if("float32"===t||"complex64"===t)return e;if("int32"===t||"bool"===t){const n="int32"===t?new Int32Array(e.length):new Uint8Array(e.length);for(let t=0;t<n.length;++t)n[t]=Math.round(e[t]);return n}throw new Error(`Unknown dtype ${t}`)}MathBackendWebGL$1.nextDataId=0;const version$9="3.8.0";isBrowser$1()&&registerBackend$1("webgl",()=>new MathBackendWebGL$1,2);const CHECK_NAN_SNIPPET$4="\n  if (isnan(a)) return a;\n  if (isnan(b)) return b;\n";class BinaryOpProgram$1{constructor(e,t,n){this.variableNames=["A","B"],this.outputShape=assertAndGetBroadcastShape$1(t,n),this.enableShapeUniforms=useShapeUniforms$1(this.outputShape.length),this.userCode=`\n      float binaryOperation(float a, float b) {\n        ${e}\n      }\n\n      void main() {\n        float a = getAAtOutCoords();\n        float b = getBAtOutCoords();\n        setOutput(binaryOperation(a, b));\n      }\n    `}}const CHECK_NAN_SNIPPET$3="\n  result.r = isNaN.r > 0. ? NAN : result.r;\n  result.g = isNaN.g > 0. ? NAN : result.g;\n  result.b = isNaN.b > 0. ? NAN : result.b;\n  result.a = isNaN.a > 0. ? NAN : result.a;\n";class BinaryOpPackedProgram$1{constructor(e,t,n,r=!1){this.variableNames=["A","B"],this.supportsBroadcasting=!0,this.packedInputs=!0,this.packedOutput=!0,this.outputShape=assertAndGetBroadcastShape$1(t,n);const a=this.outputShape.length;this.enableShapeUniforms=useShapeUniforms$1(a);let s="";if(r)if(0===a||1===sizeFromShape$1(this.outputShape))s="\n          result.y = 0.;\n          result.z = 0.;\n          result.w = 0.;\n        ";else if(s=`\n          ${getCoordsDataType$1(a)} coords = getOutputCoords();\n        `,1===a)s+=this.enableShapeUniforms?"\n            result.y = (coords + 1) >= outShape ? 0. : result.y;\n            result.z = 0.;\n            result.w = 0.;\n          ":`\n            result.y = (coords + 1) >= ${this.outputShape[0]} ? 0. : result.y;\n            result.z = 0.;\n            result.w = 0.;\n          `;else{const e=getChannels$1("coords",a);s+=this.enableShapeUniforms?`\n            bool nextRowOutOfBounds =\n              (${e[a-2]} + 1) >= outShape[${a} - 2];\n            bool nextColOutOfBounds =\n              (${e[a-1]} + 1) >= outShape[${a} - 1];\n            result.y = nextColOutOfBounds ? 0. : result.y;\n            result.z = nextRowOutOfBounds ? 0. : result.z;\n            result.w = nextColOutOfBounds || nextRowOutOfBounds ? 0. : result.w;\n          `:`\n            bool nextRowOutOfBounds =\n              (${e[a-2]} + 1) >= ${this.outputShape[a-2]};\n            bool nextColOutOfBounds =\n              (${e[a-1]} + 1) >= ${this.outputShape[a-1]};\n            result.y = nextColOutOfBounds ? 0. : result.y;\n            result.z = nextRowOutOfBounds ? 0. : result.z;\n            result.w = nextColOutOfBounds || nextRowOutOfBounds ? 0. : result.w;\n          `}this.userCode=`\n      vec4 binaryOperation(vec4 a, vec4 b) {\n        ${e}\n      }\n\n      void main() {\n        vec4 a = getAAtOutCoords();\n        vec4 b = getBAtOutCoords();\n\n        vec4 result = binaryOperation(a, b);\n        ${s}\n\n        setOutput(result);\n      }\n    `}}function identity$3(e){const{inputs:t,backend:n}=e,{x:r}=t;return n.incRef(r.dataId),{dataId:r.dataId,shape:r.shape,dtype:r.dtype}}const identityConfig$2={kernelName:Identity$3,backendName:"webgl",kernelFunc:identity$3};function complex$3(e){const{inputs:t,backend:n}=e,{real:r,imag:a}=t,s=n.makeTensorInfo(r.shape,"complex64"),o=n.texData.get(s.dataId),i=identity$3({inputs:{x:r},backend:n}),l=identity$3({inputs:{x:a},backend:n});return o.complexTensorInfos={real:i,imag:l},s}const complexConfig$2={kernelName:Complex$1,backendName:"webgl",kernelFunc:complex$3},LEAKYRELU$1="return (a < 0.) ? b * a : a;",LEAKYRELU_PACKED$1="\n  vec4 aLessThanZero = vec4(lessThan(a, vec4(0.)));\n  return (aLessThanZero * (b * a)) + ((vec4(1.0) - aLessThanZero) * a);\n";function leakyRelu$3(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{alpha:s}=r,o=n.makeTensorInfo([],"float32",createScalarValue$1(s,"float32")),i=env$1().getBool("WEBGL_PACK_BINARY_OPERATIONS")?new BinaryOpPackedProgram$1(LEAKYRELU_PACKED$1,a.shape,o.shape):new BinaryOpProgram$1(LEAKYRELU$1,a.shape,o.shape),l=n.runWebGLProgram(i,[a,o],a.dtype);return n.disposeIntermediateTensorInfo(o),l}const leakyReluConfig$2={kernelName:LeakyRelu$1,backendName:"webgl",kernelFunc:leakyRelu$3},PRELU$1="return (a < 0.) ? b * a : a;",PRELU_PACKED$1="\n  vec4 aLessThanZero = vec4(lessThan(a, vec4(0.)));\n  return (aLessThanZero * (b * a)) + ((vec4(1.0) - aLessThanZero) * a);\n";function prelu$4(e){const{inputs:t,backend:n}=e,{x:r,alpha:a}=t,s=env$1().getBool("WEBGL_PACK_BINARY_OPERATIONS")?new BinaryOpPackedProgram$1(PRELU_PACKED$1,r.shape,a.shape):new BinaryOpProgram$1(PRELU$1,r.shape,a.shape);return n.runWebGLProgram(s,[r,a],r.dtype)}const preluConfig$2={kernelName:Prelu$1,backendName:"webgl",kernelFunc:prelu$4},CHECK_NAN_SNIPPET_UNARY$1="if (isnan(x)) return x;",CHECK_NAN_SNIPPET_BINARY$1="\n  if (isnan(a)) return a;\n  if (isnan(b)) return b;\n",CHECK_NAN_SNIPPET_BINARY_PACKED$1="\n  result.r = isNaN.r > 0. ? NAN : result.r;\n  result.g = isNaN.g > 0. ? NAN : result.g;\n  result.b = isNaN.b > 0. ? NAN : result.b;\n  result.a = isNaN.a > 0. ? NAN : result.a;\n";function unaryKernelFunc$2({opSnippet:e,packedOpSnippet:t,cpuKernelImpl:n,dtype:r}){return({inputs:a,backend:s})=>{const{x:o}=a,i=s,l=r||o.dtype;if(i.shouldExecuteOnCPU([o])&&null!=n){const e=i.texData.get(o.dataId),t=n(e.values,l);return i.makeTensorInfo(o.shape,l,t)}let u;return u=env$1().getBool("WEBGL_PACK_UNARY_OPERATIONS")&&null!=t?new UnaryOpPackedProgram$1(o.shape,t):new UnaryOpProgram$1(o.shape,e),i.runWebGLProgram(u,[o],l)}}function binaryKernelFunc$2({opSnippet:e,packedOpSnippet:t,checkOutOfBounds:n=!1,supportsComplex:r=!1,cpuKernelImpl:a,dtype:s}){return({inputs:o,backend:i})=>{const{a:l,b:u}=o,c=i;if(r&&"complex64"===l.dtype){const t=c.texData.get(l.dataId),n=c.texData.get(u.dataId),[r,a]=[[t.complexTensorInfos.real,n.complexTensorInfos.real],[t.complexTensorInfos.imag,n.complexTensorInfos.imag]].map(t=>{const[n,r]=t,a={dataId:n.dataId,dtype:n.dtype,shape:l.shape},s={dataId:r.dataId,dtype:r.dtype,shape:u.shape},o=new BinaryOpProgram$1(e,l.shape,u.shape);return c.runWebGLProgram(o,[a,s],upcastType$1(n.dtype,r.dtype))}),s=complex$3({inputs:{real:r,imag:a},backend:c});return c.disposeIntermediateTensorInfo(r),c.disposeIntermediateTensorInfo(a),s}const p=s||upcastType$1(l.dtype,u.dtype);if(("string"===l.dtype||"string"===u.dtype||c.shouldExecuteOnCPU([l,u]))&&null!=a){const e=c.texData.get(l.dataId).values,t=c.texData.get(u.dataId).values,n="string"===l.dtype?fromUint8ToStringArray$1(e):e,r="string"===l.dtype?fromUint8ToStringArray$1(t):t,[s,o]=a(l.shape,u.shape,n,r,p),i=c.makeTensorInfo(o,p);return c.texData.get(i.dataId).values=s,i}let d;return d=env$1().getBool("WEBGL_PACK_BINARY_OPERATIONS")&&null!=t?new BinaryOpPackedProgram$1(t,l.shape,u.shape,n):new BinaryOpProgram$1(e,l.shape,u.shape),c.runWebGLProgram(d,[l,u],p)}}function mapActivationToShaderProgram$1(e,t=!1){if("linear"===e)return t?LINEAR$2:LINEAR$3;if("relu"===e)return t?RELU$4:RELU$5;if("elu"===e)return t?ELU$5:ELU$6;if("relu6"===e)return t?RELU6$4:RELU6$5;if("prelu"===e)return t?PRELU_PACKED$1:PRELU$1;if("leakyrelu"===e)return t?LEAKYRELU_PACKED$1:LEAKYRELU$1;if("sigmoid"===e)return t?SIGMOID$4:SIGMOID$5;throw new Error(`Activation ${e} has not been implemented for the WebGL backend.`)}class MatMulPackedProgram$1{constructor(e,t,n,r=!1,a=!1,s=!1,o=null,i=!1,l=!1){this.variableNames=["matrixA","matrixB"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=n;const u=Math.ceil((r?e[1]:e[2])/2),c=r?"i * 2, rc.y":"rc.y, i * 2",p=a?"rc.z, i * 2":"i * 2, rc.z",d=r?["a.xxyy","a.zzww"]:["a.xxzz","a.yyww"],h=a?["b.xzxz","b.ywyw"]:["b.xyxy","b.zwzw"];let m="",f="";o&&(m=i?`vec4 activation(vec4 a) {\n          vec4 b = getPreluActivationWeightsAtOutCoords();\n          ${o}\n        }`:l?`vec4 activation(vec4 a) {\n          vec4 b = getLeakyreluAlphaAtOutCoords();\n          ${o}\n        }`:`vec4 activation(vec4 x) {\n          ${o}\n        }`,f="result = activation(result);");const g=s?"result += getBiasAtOutCoords();":"";s&&this.variableNames.push("bias"),i&&this.variableNames.push("preluActivationWeights"),l&&this.variableNames.push("leakyreluAlpha");let $="rc.x",y="rc.x";e[0]<t[0]?$=`int(min(float(rc.x), ${e[0]-1}.))`:t[0]<e[0]&&(y=`int(min(float(rc.x), ${t[0]-1}.))`),this.userCode=`\n      ${m}\n\n      const float sharedDimension = ${u}.0;\n\n      vec4 dot2x2ARowBCol(ivec3 rc) {\n        vec4 result = vec4(0);\n        for (int i = 0; i < ${u}; i++) {\n          int batchA = ${$};\n          int batchB = ${y};\n          vec4 a = getMatrixA(batchA, ${c});\n          vec4 b = getMatrixB(batchB, ${p});\n\n          // These swizzled products need to be separately added.\n          // See: https://github.com/tensorflow/tfjs/issues/1735\n          result += (${d[0]} * ${h[0]});\n          result += (${d[1]} * ${h[1]});\n        }\n        return result;\n      }\n\n      void main() {\n        ivec3 rc = getOutputCoords();\n        vec4 result = dot2x2ARowBCol(rc);\n\n        ${g}\n\n        ${f}\n\n        setOutput(result);\n      }\n    `}}const COMPLEX_MULTIPLY$1={REAL:"return areal * breal - aimag * bimag;",IMAG:"return areal * bimag + aimag * breal;"};class BinaryOpComplexProgram$1{constructor(e,t,n){this.variableNames=["AReal","AImag","BReal","BImag"],this.outputShape=assertAndGetBroadcastShape$1(t,n),this.userCode=`\n      float binaryOpComplex(\n          float areal, float aimag, float breal, float bimag) {\n        ${e}\n      }\n\n      void main() {\n        float areal = getARealAtOutCoords();\n        float aimag = getAImagAtOutCoords();\n        float breal = getBRealAtOutCoords();\n        float bimag = getBImagAtOutCoords();\n        setOutput(binaryOpComplex(areal, aimag, breal, bimag));\n      }\n    `}}const MUL$1="return a * b;";function multiply$3(e){const{inputs:t,backend:n}=e,{a:r,b:a}=t,s=upcastType$1(r.dtype,a.dtype);if("complex64"===r.dtype){const e=n.texData.get(r.dataId),t=n.texData.get(a.dataId),s=new BinaryOpComplexProgram$1(COMPLEX_MULTIPLY$1.REAL,r.shape,a.shape),o=new BinaryOpComplexProgram$1(COMPLEX_MULTIPLY$1.IMAG,r.shape,a.shape),i=[{dataId:e.complexTensorInfos.real.dataId,dtype:e.complexTensorInfos.real.dtype,shape:r.shape},{dataId:e.complexTensorInfos.imag.dataId,dtype:e.complexTensorInfos.imag.dtype,shape:r.shape},{dataId:t.complexTensorInfos.real.dataId,dtype:t.complexTensorInfos.real.dtype,shape:a.shape},{dataId:t.complexTensorInfos.imag.dataId,dtype:t.complexTensorInfos.imag.dtype,shape:a.shape}],l=n.runWebGLProgram(s,i,"float32"),u=n.runWebGLProgram(o,i,"float32"),c=complex$3({inputs:{real:l,imag:u},backend:n});return n.disposeIntermediateTensorInfo(l),n.disposeIntermediateTensorInfo(u),c}if(n.shouldExecuteOnCPU([r,a])){const e=n.texData.get(r.dataId),t=n.texData.get(a.dataId),[o,i]=multiplyImplCPU$1(r.shape,a.shape,e.values,t.values,s),l=n.makeTensorInfo(i,s);return n.texData.get(l.dataId).values=o,l}let o;return o=env$1().getBool("WEBGL_PACK_BINARY_OPERATIONS")?new BinaryOpPackedProgram$1(MUL$1,r.shape,a.shape):new BinaryOpProgram$1(MUL$1,r.shape,a.shape),n.runWebGLProgram(o,[r,a],s)}const multiplyConfig$2={kernelName:Multiply$3,backendName:"webgl",kernelFunc:multiply$3};function packedReshape$1(e,t,n){const r=[getBatchDim$1(e.shape),...getRowsCols$1(e.shape)],a={dtype:e.dtype,shape:r,dataId:e.dataId},s=[getBatchDim$1(t),...getRowsCols$1(t)],o=new ReshapePackedProgram$1(s,r),i=n.runWebGLProgram(o,[a],e.dtype,null,!0);return{dataId:i.dataId,shape:t,dtype:i.dtype}}function reshape$4(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{shape:s}=r,o=n,i=sizeFromShape$1(a.shape),l=inferFromImplicitShape$1(s,i),u=sizeFromShape$1(l);assert$6(i===u,()=>`The new shape (${l}) has ${u} elements and the old shape (${a.shape}) has ${i} elements. The new shape and old shape must have the same number of elements.`);const c=o.texData.get(a.dataId);return!c.isPacked||isReshapeFree$1(a.shape,l)||null!==c.texture&&isReshapeFree$1(c.shape,l)?(o.incRef(a.dataId),{dataId:a.dataId,shape:l,dtype:a.dtype}):packedReshape$1(a,l,o)}const reshapeConfig$2={kernelName:Reshape$3,backendName:"webgl",kernelFunc:reshape$4};class MeanProgram$1{constructor(e,t){this.variableNames=["x"];const{windowSize:n,batchSize:r,inSize:a,outSize:s}=e;this.outputShape=[r,s];const o=4*Math.floor(n/4),i=n%4;let l="sumValue += dot(values, ones);";if(null!=t){const e=1/t;l=`sumValue += dot(values * ${isInt$1(e)?e.toPrecision(2):e}, ones);`}let u="";a%n>0&&(u=`\n        if (inIdx < 0 || inIdx >= ${a}) {\n          return 0.0;\n        }\n      `),this.userCode=`\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\n\n      float getValue(int batch, int inIdx) {\n        ${u}\n        return getX(batch, inIdx);\n      }\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n        int outIdx = coords[1];\n        int inOffset = outIdx * ${n};\n\n        float sumValue = 0.0;\n\n        for (int i = 0; i < ${o}; i += 4) {\n          int inIdx = inOffset + i;\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            getValue(batch, inIdx + 3)\n          );\n\n          ${l}\n        }\n\n        int inIdx = inOffset + ${o};\n        if (${1===i}) {\n          vec4 values = vec4(getValue(batch, inIdx), 0.0, 0.0, 0.0);\n\n          ${l}\n        } else if (${2===i}) {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1), 0.0, 0.0);\n\n          ${l}\n        } else if (${3===i}) {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2), 0.0);\n\n          ${l}\n        }\n        setOutput(sumValue);\n      }\n    `}}class ReduceProgram$1{constructor(e,t){this.variableNames=["x"];const{windowSize:n,batchSize:r,inSize:a,outSize:s}=e;this.outputShape=[r,s];let o="0.0",i="";"prod"===t?o="1.0":"min"===t?(o="1.0 / 1e-20",i="min"):"max"===t&&(o="-1.0 / 1e-20",i="max");let l=`${t}(${t}(${t}(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])`;"sum"===t?l="sumValue":"prod"===t?l="prodValue":"all"===t?l="allValue":"any"===t&&(l="anyValue");const u=4*Math.floor(n/4),c=n%4;let p=`\n      if (${"sum"===t}) {\n        sumValue += dot(values, ones);\n      } else if (${"prod"===t}) {\n        vec2 tmp = vec2(values[0], values[1]) * vec2(values[2], values[3]);\n        prodValue *= tmp[0] * tmp[1];\n      } else {\n        minMaxValue = ${i}(values, minMaxValue);\n        if (${"min"===t} || ${"max"===t}) {\n          minMaxValue = ${i}(values, minMaxValue);\n          bvec4 isNaN = isnan(values);\n          if (isNaN.r || isNaN.g || isNaN.b || isNaN.a) {\n            minMaxValue = vec4(NAN);\n          }\n        }\n      }\n    `,d="vec4";"all"===t?(o="1.0",p="\n        bool reducedAllValue = all(values);\n        float floatedReducedAllValue = float(reducedAllValue);\n        allValue = float(allValue >= 1.0 && floatedReducedAllValue >= 1.0);\n      ",d="bvec4"):"any"===t&&(o="0.0",p="\n        bool reducedAnyValue = any(values);\n        float floatedReducedAnyValue = float(reducedAnyValue);\n        anyValue = float(anyValue >= 1.0 || floatedReducedAnyValue >= 1.0);\n      ",d="bvec4");let h="";a%n>0&&(h=`\n        if (inIdx < 0 || inIdx >= ${a}) {\n          return initializationValue;\n        }\n      `),this.userCode=`\n      const float initializationValue = ${o};\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\n\n      float getValue(int batch, int inIdx) {\n        ${h}\n        return getX(batch, inIdx);\n      }\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n        int outIdx = coords[1];\n        int inOffset = outIdx * ${n};\n\n        vec4 minMaxValue = vec4(${o});\n        float prodValue = 1.0;\n        float sumValue = 0.0;\n        float allValue = 1.0;\n        float anyValue = 0.0;\n\n        for (int i = 0; i < ${u}; i += 4) {\n          int inIdx = inOffset + i;\n          ${d} values = ${d}(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            getValue(batch, inIdx + 3)\n          );\n\n          ${p}\n        }\n\n        int inIdx = inOffset + ${u};\n        if (${1===c}) {\n          ${d} values = ${d}(\n            getValue(batch, inIdx),\n            initializationValue,\n            initializationValue,\n            initializationValue\n          );\n\n          ${p}\n        } else if (${2===c}) {\n          ${d} values = ${d}(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            initializationValue,\n            initializationValue\n          );\n\n          ${p}\n        } else if (${3===c}) {\n          ${d} values = ${d}(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            initializationValue\n          );\n\n          ${p}\n        }\n        setOutput(${l});\n      }\n    `}}function getReductionStages$1(e){const t=[];for(;0===t.length||1!==t[t.length-1].outSize;){const n=t.length?t[t.length-1].outSize:e[1],r=computeOptimalWindowSize$1(n);t.push({inSize:n,windowSize:r,outSize:Math.ceil(n/r)})}return t}function reduce$1(e,t,n,r){const a=getReductionStages$1(e.shape);let s=e;for(let o=0;o<a.length;o++){const{inSize:i,windowSize:l,outSize:u}=a[o];let c,p;c="mean"===n?0===o?new MeanProgram$1({windowSize:l,inSize:i,batchSize:e.shape[0],outSize:u},i):new MeanProgram$1({windowSize:l,inSize:i,batchSize:e.shape[0],outSize:u}):new ReduceProgram$1({windowSize:l,inSize:i,batchSize:e.shape[0],outSize:u},n),p=s,s=r.runWebGLProgram(c,[s],t),p.dataId!==e.dataId&&r.disposeIntermediateTensorInfo(p)}return s}class TransposeProgram$1{constructor(e,t){this.variableNames=["A"];const n=new Array(e.length);for(let r=0;r<n.length;r++)n[r]=e[t[r]];this.outputShape=n,this.rank=n.length;const r=getCoordsDataType$1(this.rank),a=getSwitchedCoords$1(t);this.userCode=`\n    void main() {\n      ${r} resRC = getOutputCoords();\n      setOutput(getA(${a}));\n    }\n    `}}function getSwitchedCoords$1(e){const t=e.length;if(t>6)throw Error(`Transpose for rank ${t} is not yet supported`);const n=["resRC.x","resRC.y","resRC.z","resRC.w","resRC.u","resRC.v"],r=new Array(t);for(let t=0;t<e.length;t++)r[e[t]]=n[t];return r.join()}class TransposePackedProgram$1{constructor(e,t){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0;const n=new Array(e.length);for(let r=0;r<n.length;r++)n[r]=e[t[r]];if(this.outputShape=n,this.rank=n.length,this.rank>6)throw Error(`Packed transpose for rank ${this.rank} is not yet supported.`);const r=getCoordsDataType$1(this.rank),a=getVecChannels$1("rc",this.rank),s=new Array(this.rank);for(let e=0;e<t.length;e++)s[t[e]]=a[e];const o=`vec2(${s.slice(-2).join()})`,i=`++${a[this.rank-1]} < ${n[this.rank-1]}`,l=`getChannel(getA(${s.join()}), ${o})`;this.userCode=`\n    void main() {\n      ${r} rc = getOutputCoords();\n      vec4 result = vec4(0.);\n      result[0] = ${l};\n      if(${i}) {\n        result[1] = ${l};\n      }\n      --${a[this.rank-1]};\n      if(++${a[this.rank-2]} < ${n[this.rank-2]}) {\n        result[2] = ${l};\n        if(${i}) {\n          result[3] = ${l};\n        }\n      }\n      setOutput(result);\n    }\n    `}}function transposeImpl$2(e,t,n){const r=env$1().getBool("WEBGL_PACK_ARRAY_OPERATIONS")?new TransposePackedProgram$1(e.shape,t):new TransposeProgram$1(e.shape,t);return n.runWebGLProgram(r,[e],e.dtype)}function sumImpl$1(e,t,n,r){const a=e.shape.length,s=parseAxisParam$1(t,e.shape);let o=s;const i=getAxesPermutation$1(o,a),l=null!=i;let u=e;l&&(u=transposeImpl$2(e,i,r),o=getInnerMostAxes$1(o.length,a)),assertAxesAreInnerMostDims$1("sum",o,a);const[c,p]=computeOutAndReduceShapes$1(u.shape,o);let d=c;n&&(d=expandShapeToKeepDim$1(c,s));const h=sizeFromShape$1(p),m=reshape$4({inputs:{x:u},attrs:{shape:[sizeFromShape$1(e.shape)/h,h]},backend:r}),f=reduce$1(m,sumOutType$1(e.dtype),"sum",r),g=reshape$4({inputs:{x:f},attrs:{shape:d},backend:r});return r.disposeIntermediateTensorInfo(m),r.disposeIntermediateTensorInfo(f),l&&r.disposeIntermediateTensorInfo(u),g}function sum$4(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{axis:s,keepDims:o}=r;return sumImpl$1(a,s,o,n)}const sumConfig$2={kernelName:Sum$1,backendName:"webgl",kernelFunc:sum$4};function transpose$3(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{perm:s}=r,o=n,i=new Array(a.shape.length);for(let e=0;e<i.length;e++)i[e]=a.shape[s[e]];let l;if(o.shouldExecuteOnCPU([a])){const e=o.texData.get(a.dataId),t=transposeImplCPU$1(e.values,a.shape,a.dtype,s,i);l=o.makeTensorInfo(i,a.dtype),o.texData.get(l.dataId).values=t}else l=transposeImpl$2(a,s,o);return l}const transposeConfig$2={kernelName:Transpose$1,backendName:"webgl",kernelFunc:transpose$3},MATMUL_SHARED_DIM_THRESHOLD$1=1e3;function batchMatMulImpl$1({a:e,b:t,transposeA:n,transposeB:r,backend:a,bias:s=null,preluActivationWeights:o=null,leakyreluAlpha:i=0,activation:l=null}){const u=e.shape.length,c=t.shape.length,p=n?e.shape[u-2]:e.shape[u-1],d=r?t.shape[c-1]:t.shape[c-2],h=n?e.shape[u-1]:e.shape[u-2],m=r?t.shape[c-2]:t.shape[c-1],f=e.shape.slice(0,-2),g=t.shape.slice(0,-2),$=sizeFromShape$1(f),y=sizeFromShape$1(g);assert$6(u>=2&&c>=2&&($===y||1===$||1===y),()=>`Error in matMul: the input batch dimensions must either be the same or at least one input batch dimension must be 1. Got input batch dimensions of (${f}) and (${g}).`);const b=($>y?e.shape.slice(0,-2):t.shape.slice(0,-2)).concat([h,m]);assert$6(p===d,()=>`Error in matMul: inner shapes (${p}) and (${d}) of Tensors with shapes ${e.shape} and ${t.shape} and transposeA=${n} and transposeB=${r} must match.`);const x=n?[$,p,h]:[$,h,p],v=r?[y,m,d]:[y,d,m],I=reshape$4({inputs:{x:e},backend:a,attrs:{shape:x}}),C=reshape$4({inputs:{x:t},backend:a,attrs:{shape:v}}),S=[I,C],k=Math.max($,y),T=n?I.shape[1]:I.shape[2],N=null!=s,w=null!=o,E="leakyrelu"===l,A=null!=l?mapActivationToShaderProgram$1(l,!0):null;let D;if((1===h||1===m)&&T>MATMUL_SHARED_DIM_THRESHOLD$1&&!1===(N||w||E||null!=A)){let e=I,t=C;n&&(e=transpose$3({inputs:{x:I},backend:a,attrs:{perm:[0,2,1]}}),S.push(e)),r&&(t=transpose$3({inputs:{x:C},backend:a,attrs:{perm:[0,2,1]}}),S.push(t));const s=1===m;let o=e;1!==m&&(o=reshape$4({inputs:{x:e},backend:a,attrs:{shape:[k,T,1]}}),S.push(o));const i=1===m?2:1;let l=t;s&&(l=reshape$4({inputs:{x:t},backend:a,attrs:{shape:[k,1,T]}}),S.push(l));const u=multiply$3({inputs:{a:o,b:l},backend:a});D=sum$4({inputs:{x:u},backend:a,attrs:{axis:i,keepDims:!0}}),S.push(u)}else{const l=upcastType$1(e.dtype,t.dtype),u=new MatMulPackedProgram$1(x,v,[k,h,m],n,r,N,A,w,E),c=[I,C];if(null!=s&&c.push(s),w&&c.push(o),E){const e=a.makeTensorInfo([],"float32",createScalarValue$1(i,"float32"));c.push(e),S.push(e)}D=a.runWebGLProgram(u,c,l)}const R=reshape$4({inputs:{x:D},backend:a,attrs:{shape:b}});S.push(D);for(const e of S)a.disposeIntermediateTensorInfo(e);return R}function _fusedMatMul$2(e){const{inputs:t,backend:n,attrs:r}=e,{a,b:s,bias:o,preluActivationWeights:i}=t,{transposeA:l,transposeB:u,activation:c,leakyreluAlpha:p}=r;return batchMatMulImpl$1({a,b:s,transposeA:l,transposeB:u,backend:n,bias:o,preluActivationWeights:i,leakyreluAlpha:p,activation:c})}const _fusedMatMulConfig$2={kernelName:_FusedMatMul$1,backendName:"webgl",kernelFunc:_fusedMatMul$2},ABS$2="return abs(x);";function abs$3(e){const{inputs:t,backend:n}=e,{x:r}=t;if(n.shouldExecuteOnCPU([r])&&"complex64"!==r.dtype){const e=n.texData.get(r.dataId),t=simpleAbsImplCPU$1(e.values);return n.makeTensorInfo(r.shape,r.dtype,t)}let a;return a=env$1().getBool("WEBGL_PACK_UNARY_OPERATIONS")?new UnaryOpPackedProgram$1(r.shape,ABS$2):new UnaryOpProgram$1(r.shape,ABS$2),n.runWebGLProgram(a,[r],r.dtype)}const absConfig$2={kernelName:Abs$1,backendName:"webgl",kernelFunc:abs$3},ACOS$1=CHECK_NAN_SNIPPET$5+"\n  if (abs(x) > 1.) {\n    return NAN;\n  }\n  return acos(x);\n",acos$3=unaryKernelFunc$2({opSnippet:ACOS$1}),acosConfig$2={kernelName:Acos$1,backendName:"webgl",kernelFunc:acos$3},ACOSH$1=CHECK_NAN_SNIPPET$5+"\n  if (x < 1.0) return NAN;\nreturn log(x + sqrt(x * x - 1.0));",acosh$3=unaryKernelFunc$2({opSnippet:ACOSH$1}),acoshConfig$2={kernelName:Acosh$1,backendName:"webgl",kernelFunc:acosh$3},ADD$1="return a + b;",addKernelFunc$1=binaryKernelFunc$2({opSnippet:ADD$1,packedOpSnippet:ADD$1,supportsComplex:!0,cpuKernelImpl:addImplCPU$1}),addConfig$2={kernelName:Add$3,backendName:"webgl",kernelFunc:addKernelFunc$1};class AddNProgram$1{constructor(e,t){this.outputShape=[],this.outputShape=e,this.variableNames=t.map((e,t)=>`T${t}`);const n=[];this.variableNames.forEach(e=>{n.push(`float v${e} = get${e}AtOutCoords();`)});const r=this.variableNames.map(e=>`v${e}`).join(" + ");this.userCode=`\n      void main() {\n        ${n.join("\n        ")}\n\n        float result = ${r};\n        setOutput(result);\n      }\n    `}}class AddNPackedProgram$1{constructor(e,t){this.outputShape=[],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=e,this.variableNames=t.map((e,t)=>`T${t}`);const n=[];this.variableNames.forEach(e=>{n.push(`vec4 v${e} = get${e}AtOutCoords();`)});const r=this.variableNames.map(e=>`v${e}`).join(" + ");this.userCode=`\n      void main() {\n        ${n.join("\n        ")}\n\n        vec4 result = ${r};\n        setOutput(result);\n      }\n    `}}function addN$3(e){const{inputs:t,backend:n}=e,r=t;if(1===r.length)return identity$3({inputs:{x:r[0]},backend:n});if(r.length>env$1().get("WEBGL_MAX_TEXTURES_IN_SHADER")){const e=Math.floor(r.length/2),t=addN$3({inputs:r.slice(0,e),backend:n}),a=addN$3({inputs:r.slice(e),backend:n});return addN$3({inputs:[t,a],backend:n})}const a=r.map(e=>e.dtype).reduce((e,t)=>upcastType$1(e,t)),s=r.map(e=>e.shape),o=env$1().getBool("WEBGL_PACK")?new AddNPackedProgram$1(r[0].shape,s):new AddNProgram$1(r[0].shape,s);return n.runWebGLProgram(o,r,a)}const addNConfig$2={kernelName:AddN$1,backendName:"webgl",kernelFunc:addN$3};function all$3(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{axis:s,keepDims:o}=r,i=a.shape.length,l=parseAxisParam$1(s,a.shape);let u=l;const c=getAxesPermutation$1(u,i);let p=a;null!=c&&(p=transpose$3({inputs:{x:a},backend:n,attrs:{perm:c}}),u=getInnerMostAxes$1(u.length,i)),assertAxesAreInnerMostDims$1("all",u,i);const[d,h]=computeOutAndReduceShapes$1(p.shape,u),m=reshape$4({inputs:{x:p},backend:n,attrs:{shape:[-1,sizeFromShape$1(h)]}}),f=reduce$1(m,m.dtype,"all",n);let g;return g=reshape$4(o?{inputs:{x:f},backend:n,attrs:{shape:expandShapeToKeepDim$1(d,l)}}:{inputs:{x:f},backend:n,attrs:{shape:d}}),n.disposeIntermediateTensorInfo(m),n.disposeIntermediateTensorInfo(f),null!=c&&n.disposeIntermediateTensorInfo(p),g}const allConfig$2={kernelName:All$1,backendName:"webgl",kernelFunc:all$3};function any$3(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{axis:s,keepDims:o}=r,i=a.shape.length,l=parseAxisParam$1(s,a.shape);let u=l;const c=getAxesPermutation$1(u,i);let p=a;null!=c&&(p=transpose$3({inputs:{x:a},backend:n,attrs:{perm:c}}),u=getInnerMostAxes$1(u.length,i)),assertAxesAreInnerMostDims$1("any",u,i);const[d,h]=computeOutAndReduceShapes$1(p.shape,u),m=reshape$4({inputs:{x:p},backend:n,attrs:{shape:[-1,sizeFromShape$1(h)]}}),f=reduce$1(m,m.dtype,"any",n);let g;return g=reshape$4(o?{inputs:{x:f},backend:n,attrs:{shape:expandShapeToKeepDim$1(d,l)}}:{inputs:{x:f},backend:n,attrs:{shape:d}}),n.disposeIntermediateTensorInfo(m),n.disposeIntermediateTensorInfo(f),null!=c&&n.disposeIntermediateTensorInfo(p),g}const anyConfig$2={kernelName:Any$1,backendName:"webgl",kernelFunc:any$3};class ArgMinMaxProgram$1{constructor(e,t,n){this.variableNames=["A"];const{windowSize:r,batchSize:a,outSize:s}=e;n||this.variableNames.push("bestIndicesA"),this.outputShape=[a,s],this.userCode=`\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n        int outIdx = coords[1];\n        int inOffset = outIdx * ${r};\n\n        int bestIndex = inOffset;\n        float bestValue = getA(batch, bestIndex);\n\n        for (int i = 0; i < ${r}; i++) {\n          int inIdx = ${n?"inOffset + i;":"round(getBestIndicesA(batch, inOffset + i));"};\n          float candidate = getA(batch, inIdx);\n          if (candidate ${"max"===t?">":"<"} bestValue) {\n            bestValue = candidate;\n            bestIndex = inIdx;\n          }\n        }\n        setOutput(float(bestIndex));\n      }\n    `}}class ArgMinMaxPackedProgram$1{constructor(e,t,n,r){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,assert$6(e.length>2,()=>`Packed arg${n.charAt(0).toUpperCase()+n.slice(1)} supports only inputs with rank above 2.`);const a=Math.ceil(e[e.length-1]/t);this.outputShape=e.slice(0,-1),a>1&&this.outputShape.push(a),r||this.variableNames.push("bestIndicesA");const s=this.outputShape,o=s.length,i=getCoordsDataType$1(o),l=getChannels$1("coords",o);let u,c;if(1===a){c=o+1;const e=getCoordsDataType$1(c);u=`\n        ${e} sourceLocR = ${e}(${l.join()}, 0);\n        ++${l[o-1]};\n        ${e} sourceLocG = ${e}(${l.join()}, 0);\n        ++${l[o-2]};\n        ${e} sourceLocA = ${e}(${l.join()}, 0);\n        --${l[o-1]};\n        ${e} sourceLocB = ${e}(${l.join()}, 0);\n        --${l[o-2]};`}else c=o,u=`\n        ${i} sourceLocR = coords;\n        ++${l[o-1]};\n        ${i} sourceLocG = coords;\n        ++${l[o-2]};\n        ${i} sourceLocA = coords;\n        --${l[o-1]};\n        ${i} sourceLocB = coords;\n        --${l[o-2]};`;const p=["x","y","z","w","u","v"].slice(0,c),d="."+p[c-1],h=p.map(e=>"int "+e),m=getChannels$1("sourceLocR",c-1).concat("inIdx.r"),f=getChannels$1("sourceLocG",c-1).concat("inIdx.g"),g=getChannels$1("sourceLocB",c-1).concat("inIdx.b"),$=getChannels$1("sourceLocA",c-1).concat("inIdx.a"),y="max"===n?"greaterThan":"lessThan",b=r?"":`\n          inIdx = round(vec4(getBestIndicesAChannel(${m.join()}),\n                             getBestIndicesAChannel(${f.join()}),\n                             getBestIndicesAChannel(${g.join()}),\n                             getBestIndicesAChannel(${$.join()})));`,x=`vec4(\n            getAChannel(${m.join()}),\n            hasNextCol ? getAChannel(${f.join()}) : 0.,\n            hasNextRow ? getAChannel(${g.join()}) : 0.,\n            hasNextRow && hasNextCol ? getAChannel(${$.join()}) : 0.)`,v=r?"":`\n      float getBestIndicesAChannel(${h.join()}) {\n        return getChannel(getBestIndicesA(${p.join()}),\n                                          vec2(${p.slice(-2).join()}));\n      }`;this.userCode=`\n      float getAChannel(${h.join()}) {\n        return getChannel(getA(${p.join()}),\n                               vec2(${p.slice(-2).join()}));\n      }\n      ${v}\n      void main() {\n        ${i} coords = getOutputCoords();\n        bool hasNextCol = ${l[o-1]} < ${s[o-1]-1};\n        bool hasNextRow = ${l[o-2]} < ${s[o-2]-1};\n        ${u}\n        ivec4 srcIdx = ivec4(sourceLocR${d}, sourceLocG${d},\n          sourceLocB${d}, sourceLocA${d}) * ${t};\n        ivec4 inIdx = srcIdx;\n        vec4 bestIndex = vec4(inIdx);\n        vec4 bestValue = ${x};\n\n        for (int i = 0; i < ${t}; i++) {\n          inIdx = srcIdx;\n          ${b}\n          vec4 candidate = ${x};\n          bvec4 nan = isnan(candidate);\n          bvec4 replace = bvec4(\n            vec4(${y}(candidate, bestValue)) * (vec4(1.0) - vec4(nan)));\n\n          bestValue = vec4(replace.x  ? candidate.x : bestValue.x,\n                           replace.y  ? candidate.y : bestValue.y,\n                           replace.z  ? candidate.z : bestValue.z,\n                           replace.w  ? candidate.w : bestValue.w);\n          bestIndex = mix(bestIndex, vec4(inIdx), vec4(replace));\n          srcIdx++;\n        }\n        setOutput(bestIndex);\n      }\n    `}}function argReduce$1(e,t,n,r=null){let a=t.shape[0],s=t.shape[1];null!=r&&(a=r.shape[0],s=r.shape[1]);const o=computeOptimalWindowSize$1(s),i={windowSize:o,inSize:s,batchSize:a,outSize:Math.ceil(s/o)},l=new ArgMinMaxProgram$1(i,n,null==r),u=[t];null!=r&&u.push(r);const c=e.runWebGLProgram(l,u,"int32");if(1===c.shape[1])return c;const p=argReduce$1(e,t,n,c);return e.disposeIntermediateTensorInfo(c),p}function argReducePacked$1(e,t,n,r=null){const a=null!=r?r.shape:t.shape,s=computeOptimalWindowSize$1(a[a.length-1]),o=new ArgMinMaxPackedProgram$1(a,s,n,null==r),i=e.runWebGLProgram(o,null==r?[t]:[t,r],"int32");if(i.shape.length===t.shape.length){const r=argReducePacked$1(e,t,n,i);return e.disposeIntermediateTensorInfo(i),r}return i}function argMinMaxReduce$1(e,t,n,r){const a=[n];if(assertAxesAreInnerMostDims$1("arg"+r.charAt(0).toUpperCase()+r.slice(1),a,t.shape.length),!env$1().getBool("WEBGL_PACK_REDUCE")||t.shape.length<=2){const n=[],[s,o]=computeOutAndReduceShapes$1(t.shape,a),i=sizeFromShape$1(o),l=reshape$4({inputs:{x:t},backend:e,attrs:{shape:[-1,i]}});n.push(l);const u=argReduce$1(e,l,r);n.push(u);const c=reshape$4({inputs:{x:u},backend:e,attrs:{shape:s}});return n.forEach(t=>e.disposeIntermediateTensorInfo(t)),c}return argReducePacked$1(e,t,r)}function argMax$3(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{axis:s}=r;let o=parseAxisParam$1(s,a.shape);const i=getAxesPermutation$1(o,a.shape.length);let l=a;const u=[];null!=i&&(l=transpose$3({inputs:{x:a},backend:n,attrs:{perm:i}}),u.push(l),o=getInnerMostAxes$1(o.length,l.shape.length)),assertAxesAreInnerMostDims$1("argMax",[o[0]],l.shape.length);const c=argMinMaxReduce$1(n,l,o[0],"max");return u.forEach(e=>n.disposeIntermediateTensorInfo(e)),c}const argMaxConfig$2={kernelName:ArgMax$1,backendName:"webgl",kernelFunc:argMax$3};function argMin$3(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{axis:s}=r;let o=parseAxisParam$1(s,a.shape);const i=getAxesPermutation$1(o,a.shape.length);let l=a;const u=[];null!=i&&(l=transpose$3({inputs:{x:a},backend:n,attrs:{perm:i}}),u.push(l),o=getInnerMostAxes$1(o.length,l.shape.length)),assertAxesAreInnerMostDims$1("argMin",[o[0]],l.shape.length);const c=argMinMaxReduce$1(n,l,o[0],"min");return u.forEach(e=>n.disposeIntermediateTensorInfo(e)),c}const argMinConfig$2={kernelName:ArgMin$1,backendName:"webgl",kernelFunc:argMin$3},ASIN$1=CHECK_NAN_SNIPPET$5+"\n  if (abs(x) > 1.) {\n    return NAN;\n  }\n  return asin(x);\n",asin$3=unaryKernelFunc$2({opSnippet:ASIN$1}),asinConfig$2={kernelName:Asin$1,backendName:"webgl",kernelFunc:asin$3},ASINH$1=CHECK_NAN_SNIPPET$5+"return log(x + sqrt(x * x + 1.0));",asinh$3=unaryKernelFunc$2({opSnippet:ASINH$1}),asinhConfig$2={kernelName:Asinh$1,backendName:"webgl",kernelFunc:asinh$3},ATAN$1=CHECK_NAN_SNIPPET$5+"\n  return atan(x);\n",atan$3=unaryKernelFunc$2({opSnippet:ATAN$1}),atanConfig$2={kernelName:Atan$1,backendName:"webgl",kernelFunc:atan$3},ATAN2$1=CHECK_NAN_SNIPPET_BINARY$1+"\n  return atan(a, b);\n",ATAN2_PACKED$1="\n  vec4 result = atan(a, b);\n  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));\n  "+CHECK_NAN_SNIPPET_BINARY_PACKED$1+"\n  return result;\n",atan2$3=binaryKernelFunc$2({opSnippet:ATAN2$1,packedOpSnippet:ATAN2_PACKED$1}),atan2Config$2={kernelName:Atan2$1,backendName:"webgl",kernelFunc:atan2$3},ATANH$1=CHECK_NAN_SNIPPET$5+"\n  if ((x < -1.0) || (x > 1.0)) return NAN;\nreturn (log(1.0 + x) - log(1.0 - x)) / 2.0;",atanh$3=unaryKernelFunc$2({opSnippet:ATANH$1}),atanhConfig$2={kernelName:Atanh$1,backendName:"webgl",kernelFunc:atanh$3};class Pool2DProgram$1{constructor(e,t,n,r=!1,a=!1){if(this.variableNames=["x"],"avg"===t&&n)throw new Error("Cannot compute positions for average pool.");const s=e.filterWidth,o=e.strideHeight,i=e.strideWidth,l=e.dilationHeight,u=e.dilationWidth,c=e.effectiveFilterHeight,p=e.effectiveFilterWidth,d=e.padInfo.top,h=e.padInfo.left;this.outputShape=e.outShape;const m="avg"===t;let f="0.0";if(m||(f="-1.0 / 1e-20"),n)return void(this.userCode=`\n        const ivec2 strides = ivec2(${o}, ${i});\n        const ivec2 pads = ivec2(${d}, ${h});\n\n        void main() {\n          ivec4 coords = getOutputCoords();\n          int batch = coords[0];\n          int d = coords[3];\n\n          ivec2 xRCCorner = coords.yz * strides - pads;\n          int xRCorner = xRCCorner.x;\n          int xCCorner = xRCCorner.y;\n\n          // max/min x(?, ?, d) to get y(yR, yC, d).\n          // ? = to be determined\n          float minMaxValue = 0.0;\n          float minMaxValueFound = 0.0;\n          int minMaxPosition = 0;\n          float avgValue = 0.0;\n\n          for (int wR = 0; wR < ${c};\n              wR += ${l}) {\n            int xR = xRCorner + wR;\n\n            if (xR < 0 || xR >= ${e.inHeight}) {\n              continue;\n            }\n\n            for (int wC = 0; wC < ${p};\n                wC += ${u}) {\n              int xC = xCCorner + wC;\n\n              if (xC < 0 || xC >= ${e.inWidth}) {\n                continue;\n              }\n\n              float value = getX(batch, xR, xC, d);\n\n              // If a min / max value has already been found, use it. If not,\n              // use the current value.\n              float currMinMaxValue = mix(\n                  value, minMaxValue, minMaxValueFound);\n              if (value >= currMinMaxValue) {\n                minMaxValue = value;\n                minMaxValueFound = 1.0;\n                minMaxPosition = ${r?a?`((batch  * ${e.inHeight} + xR) * ${e.inWidth} + xC) * ${e.inChannels} + d`:`(xR * ${e.inWidth} + xC) * ${e.inChannels} + d`:`wR * ${p} + wC`};\n              }\n            }\n          }\n          setOutput(float(minMaxPosition));\n        }\n      `);let g=`${t}(${t}(${t}(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])`;"avg"===t&&(g="avgValue / count");const $=4*Math.floor(s/4),y=s%4,b=`\n      if (${m}) {\n        avgValue += dot(values, ones);\n      } else {\n        minMaxValue = max(values, minMaxValue);\n      }\n    `;this.userCode=`\n      const ivec2 strides = ivec2(${o}, ${i});\n      const ivec2 pads = ivec2(${d}, ${h});\n      const float initializationValue = ${f};\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\n\n      float count = 0.0;\n\n      float getValue(int batch, int xR, int xC, int d) {\n        if (xC < 0 || xC >= ${e.inWidth}) {\n          return initializationValue;\n        }\n        count += 1.0;\n        return getX(batch, xR, xC, d);\n      }\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d = coords[3];\n\n        ivec2 xRCCorner = coords.yz * strides - pads;\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        // max/min x(?, ?, d) to get y(yR, yC, d).\n        // ? = to be determined\n        vec4 minMaxValue = vec4(${f});\n        float avgValue = 0.0;\n        count = 0.0;\n\n        for (int wR = 0; wR < ${c};\n            wR += ${l}) {\n          int xR = xRCorner + wR;\n\n          if (xR < 0 || xR >= ${e.inHeight}) {\n            continue;\n          }\n\n          for (int wC = 0; wC < ${$}; wC += 4) {\n            int xC = xCCorner + wC * ${u};\n\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              getValue(batch, xR, xC + ${u}, d),\n              getValue(batch, xR, xC + 2 * ${u}, d),\n              getValue(batch, xR, xC + 3 * ${u}, d)\n            );\n\n            ${b}\n          }\n\n          int xC = xCCorner + ${$};\n          if (${1===y}) {\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              initializationValue,\n              initializationValue,\n              initializationValue\n            );\n\n            ${b}\n          } else if (${2===y}) {\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              getValue(batch, xR, xC + ${u}, d),\n              initializationValue,\n              initializationValue\n            );\n\n            ${b}\n          } else if (${3===y}) {\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              getValue(batch, xR, xC + ${u}, d),\n              getValue(batch, xR, xC + 2 * ${u}, d),\n              initializationValue\n            );\n\n            ${b}\n          }\n        }\n        setOutput(${g});\n      }\n    `}}class Pool3DProgram$1{constructor(e,t,n,r=!1,a=!1){if(this.variableNames=["x"],"avg"===t&&n)throw new Error("Cannot compute positions for average pool.");const s=e.filterWidth,o=e.strideDepth,i=e.strideHeight,l=e.strideWidth,u=e.dilationDepth,c=e.dilationHeight,p=e.dilationWidth,d=e.effectiveFilterDepth,h=e.effectiveFilterHeight,m=e.effectiveFilterWidth,f=e.padInfo.front,g=e.padInfo.top,$=e.padInfo.left;this.outputShape=e.outShape;const y="avg"===t;let b="0.0";if(y||(b="-1.0 / 1e-20"),n)return void(this.userCode=`\n        const ivec3 strides =\n            ivec3(${o}, ${i}, ${l});\n        const ivec3 pads = ivec3(${f}, ${g}, ${$});\n\n        void main() {\n          ivec5 coords = getOutputCoords();\n          int batch = coords.x;\n          int ch = coords.u;\n\n          ivec3 xCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\n          int xDCorner = xCorner.x;\n          int xRCorner = xCorner.y;\n          int xCCorner = xCorner.z;\n\n          // max/min x(?, ?, ?, ch) to get y(yD, yR, yC, ch).\n          // ? = to be determined\n          float minMaxValue = 0.0;\n          float minMaxValueFound = 0.0;\n          int minMaxPosition = 0;\n\n          for (int wD = 0; wD < ${d};\n              wD += ${u}) {\n            int xD = xDCorner + wD;\n\n            if (xD < 0 || xD >= ${e.inDepth}) {\n              continue;\n            }\n\n            for (int wR = 0; wR < ${h};\n                wR += ${c}) {\n              int xR = xRCorner + wR;\n\n              if (xR < 0 || xR >= ${e.inHeight}) {\n                continue;\n              }\n\n              for (int wC = 0; wC < ${m};\n                  wC += ${p}) {\n                int xC = xCCorner + wC;\n\n                if (xC < 0 || xC >= ${e.inWidth}) {\n                  continue;\n                }\n\n                float value = getX(batch, xD, xR, xC, ch);\n\n                // If a min / max value has already been found, use it. If not,\n                // use the current value.\n                float currMinMaxValue = mix(\n                    value, minMaxValue, minMaxValueFound);\n                if (value >= currMinMaxValue) {\n                  minMaxValue = value;\n                  minMaxValueFound = 1.0;\n                  minMaxPosition = ${r?a?`(((batch * ${e.inDepth} + xD) * ${e.inHeight} + xR) * ${e.inWidth} + xC) * ${e.inChannels} + ch`:`((xD * ${e.inHeight} + xR) * ${e.inWidth} + xC) * ${e.inChannels} + ch`:`wD * ${h} * ${m} +\n                      wR * ${m} + wC`};\n                }\n              }\n            }\n          }\n          setOutput(float(minMaxPosition));\n        }\n      `);let x=`${t}(${t}(${t}(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])`;"avg"===t&&(x="avgValue / count");const v=4*Math.floor(s/4),I=s%4,C=`\n      if (${y}) {\n        avgValue += dot(values, ones);\n      } else {\n        minMaxValue = max(values, minMaxValue);\n      }\n    `;this.userCode=`\n      const ivec3 strides =\n        ivec3(${o}, ${i}, ${l});\n      const ivec3 pads = ivec3(${f}, ${g}, ${$});\n      const float initializationValue = ${b};\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\n\n      float count = 0.0;\n\n      float getValue(int batch, int xD, int xR, int xC, int ch) {\n        if (xC < 0 || xC >= ${e.inWidth}) {\n          return initializationValue;\n        }\n        count += 1.0;\n        return getX(batch, xD, xR, xC, ch);\n      }\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int ch = coords.u;\n\n        ivec3 xCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\n        int xDCorner = xCorner.x;\n        int xRCorner = xCorner.y;\n        int xCCorner = xCorner.z;\n\n        // max/min x(?, ?, ?, d) to get y(yD, yR, yC, ch).\n        // ? = to be determined\n        vec4 minMaxValue = vec4(${b});\n        float avgValue = 0.0;\n        count = 0.0;\n\n        for (int wD = 0; wD < ${d};\n            wD += ${u}) {\n          int xD = xDCorner + wD;\n\n          if (xD < 0 || xD >= ${e.inDepth}) {\n            continue;\n          }\n\n          for (int wR = 0; wR < ${h};\n            wR += ${c}) {\n            int xR = xRCorner + wR;\n\n            if (xR < 0 || xR >= ${e.inHeight}) {\n              continue;\n            }\n\n            for (int wC = 0; wC < ${v}; wC += 4) {\n              int xC = xCCorner + wC * ${p};\n\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                getValue(batch, xD, xR, xC + ${p}, ch),\n                getValue(batch, xD, xR, xC + 2 * ${p}, ch),\n                getValue(batch, xD, xR, xC + 3 * ${p}, ch)\n              );\n\n              ${C}\n            }\n\n            int xC = xCCorner + ${v};\n            if (${1===I}) {\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                initializationValue,\n                initializationValue,\n                initializationValue\n              );\n\n              ${C}\n            } else if (${2===I}) {\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                getValue(batch, xD, xR, xC + ${p}, ch),\n                initializationValue,\n                initializationValue\n              );\n\n              ${C}\n            } else if (${3===I}) {\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                getValue(batch, xD, xR, xC + ${p}, ch),\n                getValue(batch, xD, xR, xC + 2 * ${p}, ch),\n                initializationValue\n              );\n\n              ${C}\n            }\n          }\n          setOutput(${x});\n        }\n      }\n    `}}function avgPool$3(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t;assertNotComplex$2(a,"avgPool");const{filterSize:s,strides:o,pad:i,dimRoundingMode:l}=r;assert$6(eitherStridesOrDilationsAreOne$1(o,1),()=>`Error in avgPool: Either strides or dilations must be 1. Got strides ${o} and dilations '1'`);const u=computePool2DInfo$1(a.shape,s,o,1,i,l);if(1===u.filterWidth&&1===u.filterHeight&&arraysEqual$1(u.inShape,u.outShape))return identity$3({inputs:{x:a},backend:n});const c=new Pool2DProgram$1(u,"avg",!1);return n.runWebGLProgram(c,[a],"float32")}const avgPoolConfig$2={kernelName:AvgPool$1,backendName:"webgl",kernelFunc:avgPool$3};function avgPool3D$2(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{filterSize:s,strides:o,pad:i,dimRoundingMode:l,dataFormat:u}=r,c=computePool3DInfo$1(a.shape,s,o,[1,1,1],i,l,u),p=new Pool3DProgram$1(c,"avg",!1);return n.runWebGLProgram(p,[a],"float32")}const avgPool3DConfig$2={kernelName:AvgPool3D$1,backendName:"webgl",kernelFunc:avgPool3D$2};class AvgPool2DBackpropProgram$1{constructor(e){this.variableNames=["dy"],this.outputShape=e.inShape;const t=e.effectiveFilterHeight,n=e.effectiveFilterWidth;this.userCode=`\n      const ivec2 pads = ivec2(${t-1-e.padInfo.top}, ${n-1-e.padInfo.left});\n      const float avgMultiplier = float(${1/(e.filterHeight*e.filterWidth)});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n\n        ivec2 dyRCCorner = coords.yz - pads;\n        int dyRCorner = dyRCCorner.x;\n        int dyCCorner = dyRCCorner.y;\n\n        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ${t};\n            wR += ${e.dilationHeight}) {\n          float dyR = float(dyRCorner + wR) / ${e.strideHeight}.0;\n\n          if (dyR < 0.0 || dyR >= ${e.outHeight}.0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          for (int wC = 0; wC < ${n};\n            wC+= ${e.dilationWidth}) {\n            float dyC = float(dyCCorner + wC) / ${e.strideWidth}.0;\n\n            if (dyC < 0.0 || dyC >= ${e.outWidth}.0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            float dyValue = getDy(b, idyR, idyC, d);\n\n            dotProd += dyValue * avgMultiplier;\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class AvgPool3DBackpropProgram$1{constructor(e){this.variableNames=["dy"],this.outputShape=e.inShape;const t=e.effectiveFilterDepth,n=e.effectiveFilterHeight,r=e.effectiveFilterWidth;this.userCode=`\n      const ivec3 pads = ivec3(${t-1-e.padInfo.front}, ${n-1-e.padInfo.top}, ${r-1-e.padInfo.left});\n      const float avgMultiplier = float(${1/(e.filterDepth*e.filterHeight*e.filterWidth)});\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int ch = coords.u;\n\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\n        int dyDCorner = dyCorner.x;\n        int dyRCorner = dyCorner.y;\n        int dyCCorner = dyCorner.z;\n\n        // Convolve dy(?, ?, ?, d) with pos mask(:, :, :, ch) to get\n        // dx(xD, xR, xC, ch).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n\n        for (int wD = 0; wD < ${t};\n            wD += ${e.dilationDepth}) {\n          float dyD = float(dyDCorner + wD) / ${e.strideDepth}.0;\n\n          if (dyD < 0.0 || dyD >= ${e.outDepth}.0 || fract(dyD) > 0.0) {\n            continue;\n          }\n          int idyD = int(dyD);\n\n          for (int wR = 0; wR < ${n};\n              wR += ${e.dilationHeight}) {\n            float dyR = float(dyRCorner + wR) / ${e.strideHeight}.0;\n\n            if (dyR < 0.0 || dyR >= ${e.outHeight}.0 ||\n                fract(dyR) > 0.0) {\n              continue;\n            }\n            int idyR = int(dyR);\n\n            for (int wC = 0; wC < ${r};\n                wC += ${e.dilationWidth}) {\n              float dyC = float(dyCCorner + wC) / ${e.strideWidth}.0;\n\n              if (dyC < 0.0 || dyC >= ${e.outWidth}.0 ||\n                  fract(dyC) > 0.0) {\n                continue;\n              }\n              int idyC = int(dyC);\n\n              float dyValue = getDy(batch, idyD, idyR, idyC, ch);\n\n              dotProd += dyValue * avgMultiplier;\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}function avgPool3DGrad$2(e){const{inputs:t,backend:n,attrs:r}=e,{dy:a,input:s}=t,o=s,{filterSize:i,strides:l,pad:u,dimRoundingMode:c}=r,p=computePool3DInfo$1(o.shape,i,l,[1,1,1],u,c),d=new AvgPool3DBackpropProgram$1(p);return n.runWebGLProgram(d,[a],o.dtype)}const avgPoolGrad3DConfig$1={kernelName:AvgPool3DGrad$1,backendName:"webgl",kernelFunc:avgPool3DGrad$2};function avgPoolGrad$3(e){const{inputs:t,backend:n,attrs:r}=e,{dy:a,input:s}=t,o=s;assertNotComplex$2([a,s],"avgPoolGrad");const{filterSize:i,strides:l,pad:u}=r,c=computePool2DInfo$1(o.shape,i,l,1,u),p=new AvgPool2DBackpropProgram$1(c);return n.runWebGLProgram(p,[a],o.dtype)}const avgPoolGradConfig$3={kernelName:AvgPoolGrad$1,backendName:"webgl",kernelFunc:avgPoolGrad$3};function batchMatMul$2(e){const{inputs:t,backend:n,attrs:r}=e,{a,b:s}=t,{transposeA:o,transposeB:i}=r;return batchMatMulImpl$1({a,b:s,transposeA:o,transposeB:i,backend:n})}const batchMatMulConfig$2={kernelName:BatchMatMul$1,backendName:"webgl",kernelFunc:batchMatMul$2};class BatchNormProgram$1{constructor(e,t,n,r,a,s){this.outputShape=[],this.variableNames=["x","mean","variance"],assertAndGetBroadcastShape$1(e,t),assertAndGetBroadcastShape$1(e,n);let o="0.0";null!=r&&(assertAndGetBroadcastShape$1(e,r),this.variableNames.push("offset"),o="getOffsetAtOutCoords()");let i="1.0";null!=a&&(assertAndGetBroadcastShape$1(e,a),this.variableNames.push("scale"),i="getScaleAtOutCoords()"),this.outputShape=e,this.userCode=`\n      void main() {\n        float x = getXAtOutCoords();\n        float mean = getMeanAtOutCoords();\n        float variance = getVarianceAtOutCoords();\n        float offset = ${o};\n        float scale = ${i};\n        float inv = scale * inversesqrt(variance + float(${s}));\n        setOutput(dot(vec3(x, -mean, offset), vec3(inv, inv, 1)));\n      }\n    `}}class BatchNormPackedProgram$1{constructor(e,t,n,r,a,s){this.packedInputs=!0,this.packedOutput=!0,this.variableNames=["x","mean","variance"],assertAndGetBroadcastShape$1(e,t),assertAndGetBroadcastShape$1(e,n);let o="vec4(0.0)";null!=r&&(assertAndGetBroadcastShape$1(e,r),this.variableNames.push("offset"),o="getOffsetAtOutCoords()");let i="vec4(1.0)";null!=a&&(assertAndGetBroadcastShape$1(e,a),this.variableNames.push("scale"),i="getScaleAtOutCoords()"),this.outputShape=e,this.userCode=`\n      void main() {\n        vec4 offset = ${o};\n        vec4 scale = ${i};\n\n        vec4 x = getXAtOutCoords();\n        vec4 mean = getMeanAtOutCoords();\n        vec4 variance = getVarianceAtOutCoords();\n\n        vec4 inv = scale * inversesqrt(variance + vec4(${s}));\n\n        setOutput((x - mean) * inv + offset);\n      }\n    `}}const batchNorm$3=({inputs:e,backend:t,attrs:n})=>{const{x:r,mean:a,variance:s,offset:o,scale:i}=e;assert$6(a.shape.length===s.shape.length,()=>"Batch normalization gradient requires mean and variance to have equal ranks."),assert$6(null==o||a.shape.length===o.shape.length,()=>"Batch normalization gradient requires mean and offset to have equal ranks."),assert$6(null==i||a.shape.length===i.shape.length,()=>"Batch normalization gradient requires mean and scale to have equal ranks.");let{varianceEpsilon:l}=n;null==l&&(l=.001);const u=[r,a,s];let c=null;null!=o&&(c=o.shape,u.push(o));let p=null;null!=i&&(p=i.shape,u.push(i));const d=env$1().getBool("WEBGL_PACK_NORMALIZATION")?new BatchNormPackedProgram$1(r.shape,a.shape,s.shape,c,p,l):new BatchNormProgram$1(r.shape,a.shape,s.shape,c,p,l);return t.runWebGLProgram(d,u,u[0].dtype)},batchNormConfig$2={kernelName:FusedBatchNorm$1,backendName:"webgl",kernelFunc:batchNorm$3};class SliceProgram$1{constructor(e){this.variableNames=["source"],this.outputShape=e,this.rank=e.length;const t=getCoordsDataType$1(this.rank);this.customUniforms=[{name:"start",arrayIndex:this.rank,type:"int"}];const n=getCoords$3(this.rank);let r;r=`\n        ${t} sourceLoc;\n        ${t} coords = getOutputCoords();\n        ${e.map((e,t)=>`sourceLoc.${coords$1[t]} = start[${t}] + coords.${coords$1[t]};`).join("\n")}\n      `,this.userCode=`\n      void main() {\n        ${r}\n        setOutput(getSource(${n}));\n      }\n    `}}const coords$1=["x","y","z","w","u","v"];function getCoords$3(e){if(1===e)return"sourceLoc";if(e<=6)return coords$1.slice(0,e).map(e=>"sourceLoc."+e).join(",");throw Error(`Slicing for rank ${e} is not yet supported`)}class SlicePackedProgram$1{constructor(e){this.variableNames=["source"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=e,this.rank=e.length,this.customUniforms=[{name:"start",arrayIndex:this.rank,type:"int"}];const t=getCoordsDataType$1(this.rank),n=getChannels$1("coords",this.rank),r=getChannels$1("sourceLoc",this.rank),a=1===this.rank?"sourceLoc":`vec2(${r.slice(-2).join()})`,s=`getChannel(getSource(${r.join()}), ${a})`,o=`\n      result.x = ${s};\n      if (++${n[this.rank-1]} < ${e[this.rank-1]}) {\n        ++${r[this.rank-1]};\n        result.y = ${s};\n        --${r[this.rank-1]};\n      }\n    `,i=1===this.rank?"":`\n      --${n[this.rank-1]};\n      if (++${n[this.rank-2]} < ${e[this.rank-2]}) {\n        ++${r[this.rank-2]};\n        result.z = ${s};\n        if (++${n[this.rank-1]} < ${e[this.rank-1]}) {\n          ++${r[this.rank-1]};\n          result.w = ${s};\n        }\n      }\n    `,l=this.rank<=4?`sourceLoc = coords +\n            ${t}(${e.map((e,t)=>`start[${t}]`).join()});`:e.map((e,t)=>`${r[t]} = ${n[t]} + start[${t}];`).join("\n");this.userCode=`\n      void main() {\n        ${t} coords = getOutputCoords();\n        ${t} sourceLoc;\n        ${l}\n        vec4 result = vec4(0.);\n        ${o}\n        ${i}\n        setOutput(result);\n      }\n    `}}function shallowSlice$1(e,t,n,r){const a=r.texData.get(e.dataId),s=r.makeTensorInfo(n,e.dtype),o=r.texData.get(s.dataId);Object.assign(o,a),o.refCount=1,o.shape=n,o.dtype=e.dtype;let i=computeFlatOffset$1(t,computeStrides$1(e.shape));a.slice&&(i+=a.slice.flatOffset),o.slice={flatOffset:i,origDataId:a.slice&&a.slice.origDataId||e.dataId};const l=r.dataRefCount.get(o.slice.origDataId)||1;return r.dataRefCount.set(o.slice.origDataId,l+1),s}function slice$3(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{begin:s,size:o}=r,[i,l]=parseSliceParams$1(a,s,o);if(assertParamsValid$1(a,i,l),0===sizeFromShape$1(l))return n.makeTensorInfo(l,a.dtype,[]);if(n.shouldExecuteOnCPU([a])||"string"===a.dtype){const e=n.texData.get(a.dataId),t=sliceImplCPU$1(e.values,i,l,a.shape,a.dtype);return n.makeTensorInfo(l,a.dtype,t)}const{isPacked:u}=n.texData.get(a.dataId),c=isSliceContinous$1(a.shape,i,l);if(u||!c){const e=env$1().getBool("WEBGL_PACK_ARRAY_OPERATIONS")?new SlicePackedProgram$1(l):new SliceProgram$1(l);return n.runWebGLProgram(e,[a],a.dtype,[i])}return n.uploadToGPU(a.dataId),shallowSlice$1(a,i,l,n)}const sliceConfig$2={kernelName:Slice$1,backendName:"webgl",kernelFunc:slice$3},batchToSpaceND$3=e=>{const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{blockShape:s,crops:o}=r;assert$6(a.shape.length<=4,()=>"batchToSpaceND for rank > 4 with a WebGL backend not implemented yet");const i=s.reduce((e,t)=>e*t),l=getReshaped$1(a.shape,s,i),u=getPermuted$1(l.length,s.length),c=getReshapedPermuted$1(a.shape,s,i),p=getSliceBeginCoords$1(o,s.length),d=getSliceSize$1(c,o,s.length),h=[],m=reshape$4({inputs:{x:a},backend:n,attrs:{shape:l}}),f=transpose$3({inputs:{x:m},backend:n,attrs:{perm:u}}),g=reshape$4({inputs:{x:f},backend:n,attrs:{shape:c}}),$=slice$3({inputs:{x:g},backend:n,attrs:{begin:p,size:d}});return h.push(m),h.push(f),h.push(g),h.forEach(e=>n.disposeIntermediateTensorInfo(e)),$},batchToSpaceNDConfig$2={kernelName:BatchToSpaceND$1,backendName:"webgl",kernelFunc:batchToSpaceND$3};function bincount$3(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,weights:s}=t,{size:o}=r,i=n.readSync(a.dataId),l=n.readSync(s.dataId),u=bincountImplCPU$1(i,l,s.dtype,s.shape,o);return n.makeTensorInfo([o],s.dtype,u)}const bincountConfig$2={kernelName:Bincount$1,backendName:"webgl",kernelFunc:bincount$3},NOT_EQUAL$1="return float(a != b);",notEqual$3=binaryKernelFunc$2({opSnippet:NOT_EQUAL$1,cpuKernelImpl:notEqualImplCPU$1,dtype:"bool"}),notEqualConfig$2={kernelName:NotEqual$1,backendName:"webgl",kernelFunc:notEqual$3};function real$3(e){const{inputs:t,backend:n}=e,{input:r}=t;return identity$3({inputs:{x:n.texData.get(r.dataId).complexTensorInfos.real},backend:n})}const realConfig$2={kernelName:Real$1,backendName:"webgl",kernelFunc:real$3},TO_INT$1="return float(int(x));";function int$1(e,t){const n=new UnaryOpProgram$1(e.shape,TO_INT$1),r=t.runWebGLProgram(n,[e],"int32");return{dataId:r.dataId,shape:r.shape,dtype:r.dtype}}function cast$4(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{dtype:s}=r;if("complex64"===s){if("complex64"===a.dtype)return identity$3({inputs:{x:a},backend:n});const e=zeros$4(a.shape),t=cast$4({inputs:{x:a},backend:n,attrs:{dtype:"float32"}}),r=complex$3({inputs:{real:t,imag:e},backend:n});return e.dispose(),n.disposeIntermediateTensorInfo(t),r}if("complex64"===a.dtype){const e=real$3({inputs:{input:a},backend:n}),t=cast$4({inputs:{x:e},backend:n,attrs:{dtype:s}});return n.disposeIntermediateTensorInfo(e),t}if(!hasEncodingLoss$1(a.dtype,s)){const e=identity$3({inputs:{x:a},backend:n});return{dataId:e.dataId,shape:e.shape,dtype:s}}if("int32"===s)return int$1(a,n);if("bool"===s){const e=n.makeTensorInfo([],"bool",getTypedArrayFromDType$1("bool",1)),t=notEqual$3({inputs:{a,b:e},backend:n});return n.disposeIntermediateTensorInfo(e),t}throw new Error(`Error in Cast: failed to cast ${a.dtype} to ${s}`)}const castConfig$2={kernelName:Cast$1,backendName:"webgl",kernelFunc:cast$4},CEIL$1="return ceil(x);",ceil$3=unaryKernelFunc$2({opSnippet:CEIL$1,packedOpSnippet:CEIL$1,cpuKernelImpl:ceilImplCPU$1}),ceilConfig$2={kernelName:Ceil$1,backendName:"webgl",kernelFunc:ceil$3};class ClipProgram$1{constructor(e){this.variableNames=["A"],this.customUniforms=[{name:"minVal",type:"float"},{name:"maxVal",type:"float"}],this.outputShape=e,this.userCode="\n\n      void main() {\n        float value = getAAtOutCoords();\n        if (isnan(value)) {\n          setOutput(value);\n          return;\n        }\n\n        setOutput(clamp(value, minVal, maxVal));\n      }\n    "}}class ClipPackedProgram$1{constructor(e){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,this.customUniforms=[{name:"minVal",type:"float"},{name:"maxVal",type:"float"}],this.outputShape=e,this.userCode="\n      void main() {\n        vec4 value = getAAtOutCoords();\n\n        if (any(isnan(value))) {\n          setOutput(value);\n          return;\n        }\n\n        setOutput(clamp(value, vec4(minVal), vec4(maxVal)));\n      }\n    "}}function clipByValue$2(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{clipValueMin:s,clipValueMax:o}=r;let i;return i=env$1().getBool("WEBGL_PACK_CLIP")?new ClipPackedProgram$1(a.shape):new ClipProgram$1(a.shape),n.runWebGLProgram(i,[a],a.dtype,[[s],[o]])}const clipByValueConfig$1={kernelName:ClipByValue$1,backendName:"webgl",kernelFunc:clipByValue$2};class ComplexAbsProgram$1{constructor(e){this.variableNames=["real","imag"],this.outputShape=e,this.userCode="\n      void main() {\n        float re = abs(getRealAtOutCoords());\n        float im = abs(getImagAtOutCoords());\n        float mx = max(re, im);\n\n        // sadly the length function in glsl is not underflow-safe\n        // (at least not on Intel GPUs). So the safe solution is\n        // to ensure underflow-safety in all cases.\n        setOutput(\n          mx == 0.0 ? 0.0 : mx * length(vec2(1, min(re, im)/mx))\n        );\n      }\n    "}}function makeComplexComponentTensorInfo$1(e,t){return{dataId:t.dataId,dtype:t.dtype,shape:e.shape}}function complexAbs$2(e){const{inputs:t,backend:n}=e,{x:r}=t,a=n.texData.get(r.dataId),s=new ComplexAbsProgram$1(r.shape),o=[makeComplexComponentTensorInfo$1(r,a.complexTensorInfos.real),makeComplexComponentTensorInfo$1(r,a.complexTensorInfos.imag)];return n.runWebGLProgram(s,o,o[0].dtype)}const complexAbsConfig$2={kernelName:ComplexAbs$1,backendName:"webgl",kernelFunc:complexAbs$2};class ConcatProgram$1{constructor(e){this.outputShape=[],this.outputShape=computeOutShape$4(e,1),this.variableNames=e.map((e,t)=>`T${t}`);const t=new Array(e.length-1);t[0]=e[0][1];for(let n=1;n<t.length;n++)t[n]=t[n-1]+e[n][1];const n=[`if (yC < ${t[0]}) setOutput(getT0(yR, yC));`];for(let e=1;e<t.length;e++)n.push(`else if (yC < ${t[e]}) setOutput(getT${e}(yR, yC-${t[e-1]}));`);n.push(`else setOutput(getT${t.length}(yR, yC-${t[t.length-1]}));`),this.userCode=`\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int yR = coords.x;\n        int yC = coords.y;\n\n        ${n.join("\n        ")}\n      }\n    `}}class ConcatPackedProgram$1{constructor(e,t){this.packedInputs=!0,this.packedOutput=!0,this.outputShape=[],this.outputShape=computeOutShape$4(e,t);const n=this.outputShape,r=n.length,a=getCoordsDataType$1(r),s=getChannels$1("coords",r),o=["x","y","z","w","u","v"].slice(0,r);this.variableNames=e.map((e,t)=>`T${t}`);const i=new Array(e.length-1);i[0]=e[0][t];for(let n=1;n<i.length;n++)i[n]=i[n-1]+e[n][t];const l=o[t],u=o.slice(-2),c=o.join();let p=`if (${l} < ${i[0]}) {\n        return getChannel(\n            getT0(${c}), vec2(${u.join()}));\n        }`;for(let e=1;e<i.length;e++){const t=i[e-1];p+=`\n        if (${l} < ${i[e]}  && ${l} >= ${i[e-1]}) {\n          return getChannel(\n            getT${e}(${shiftedChannels$1(o,l,t)}),\n            vec2(${shiftedChannels$1(u,l,t)}));\n        }`}const d=i[i.length-1];p+=`\n        return getChannel(\n          getT${i.length}(${shiftedChannels$1(o,l,d)}),\n          vec2(${shiftedChannels$1(u,l,d)}));`,this.userCode=`\n      float getValue(${o.map(e=>"int "+e)}) {\n        ${p}\n      }\n\n      void main() {\n        ${a} coords = getOutputCoords();\n        vec4 result = vec4(getValue(${s}), 0., 0., 0.);\n\n        ${s[r-1]} = ${s[r-1]} + 1;\n        if (${s[r-1]} < ${n[r-1]}) {\n          result.g = getValue(${s});\n        }\n\n        ${s[r-2]} = ${s[r-2]} + 1;\n        if (${s[r-2]} < ${n[r-2]}) {\n          result.a = getValue(${s});\n        }\n\n        ${s[r-1]} = ${s[r-1]} - 1;\n        if (${s[r-2]} < ${n[r-2]} &&\n            ${s[r-1]} < ${n[r-1]}) {\n          result.b = getValue(${s});\n        }\n        setOutput(result);\n      }\n    `}}function shiftedChannels$1(e,t,n){const r=e.indexOf(t);return e.map((e,t)=>t===r?`${e} - ${n}`:e).join()}function imag$3(e){const{inputs:t,backend:n}=e,{input:r}=t;return identity$3({inputs:{x:n.texData.get(r.dataId).complexTensorInfos.imag},backend:n})}const imagConfig$2={kernelName:Imag$1,backendName:"webgl",kernelFunc:imag$3};function concatImpl$2(e,t,n){const r=e[0].dtype;if("complex64"===r){const r=e.map(e=>real$3({inputs:{input:e},backend:n})),a=e.map(e=>imag$3({inputs:{input:e},backend:n})),s=concatImpl$2(r,t,n),o=concatImpl$2(a,t,n),i=complex$3({inputs:{real:s,imag:o},backend:n});return r.forEach(e=>n.disposeIntermediateTensorInfo(e)),a.forEach(e=>n.disposeIntermediateTensorInfo(e)),n.disposeIntermediateTensorInfo(s),n.disposeIntermediateTensorInfo(o),i}let a=n.shouldExecuteOnCPU(e);if("string"===r&&(a=!0),a){const a=e.map(e=>{const r=sizeFromShape$1(e.shape.slice(t));return reshape$4({inputs:{x:e},backend:n,attrs:{shape:[-1,r]}})}),s=a.map(e=>({vals:n.readSync(e.dataId),shape:e.shape})),o=computeOutShape$4(a.map(e=>e.shape),1),i=concatImplCPU$1(s,o,r,1===a[0].shape[0]),l=computeOutShape$4(e.map(e=>e.shape),t),u=n.makeTensorInfo(l,r,i);return a.forEach(e=>n.disposeIntermediateTensorInfo(e)),u}if(e.length>env$1().getNumber("WEBGL_MAX_TEXTURES_IN_SHADER")){const r=Math.floor(e.length/2),a=concatImpl$2(e.slice(0,r),t,n),s=concatImpl$2(e.slice(r),t,n),o=concatImpl$2([a,s],t,n);return n.disposeIntermediateTensorInfo(a),n.disposeIntermediateTensorInfo(s),o}if(env$1().getBool("WEBGL_PACK_ARRAY_OPERATIONS")&&e[0].shape.length>1){const a=new ConcatPackedProgram$1(e.map(e=>e.shape),t);return n.runWebGLProgram(a,e,r)}const{tensors2D:s,outShape:o}=computeTensors2D$1(e,t,n),i=new ConcatProgram$1(s.map(e=>e.shape)),l=n.runWebGLProgram(i,s,r);s.forEach(e=>n.disposeIntermediateTensorInfo(e));const u=reshape$4({inputs:{x:l},attrs:{shape:o},backend:n});return n.disposeIntermediateTensorInfo(l),u}function computeTensors2D$1(e,t,n){const r=computeOutShape$4(e.map(e=>e.shape),t);return{tensors2D:e.map(e=>reshape$4({inputs:{x:e},attrs:{shape:[-1,sizeFromShape$1(e.shape.slice(t))]},backend:n})),outShape:r}}function concat$3(e){const{inputs:t,backend:n,attrs:r}=e,{axis:a}=r,s=parseAxisParam$1(a,t[0].shape)[0],o=computeOutShape$4(t.map(e=>e.shape),s);if(0===sizeFromShape$1(o))return n.makeTensorInfo(o,t[0].dtype,[]);const i=t.filter(e=>sizeFromShape$1(e.shape)>0);return 1===i.length?identity$3({inputs:{x:i[0]},backend:n}):(assertParamsConsistent$1(i.map(e=>e.shape),s),concatImpl$2(i,s,n))}const concatConfig$2={kernelName:Concat$1,backendName:"webgl",kernelFunc:concat$3};class Conv2DProgram$1{constructor(e,t=!1,n=null,r=!1,a=!1){this.variableNames=["x","W"],this.outputShape=e.outShape;const s=e.padInfo.top,o=e.padInfo.left,i=e.strideHeight,l=e.strideWidth,u=e.dilationHeight,c=e.dilationWidth,p=e.filterHeight,d=e.filterWidth,h=4*Math.floor(e.inChannels/4),m=e.inChannels%4,f="channelsLast"===e.dataFormat,g=f?1:2,$=f?2:3,y=f?3:1;let b="",x="";n&&(b=r?`float activation(float a) {\n          float b = getPreluActivationWeightsAtOutCoords();\n          ${n}\n        }`:a?`float activation(float a) {\n          float b = getLeakyreluAlphaAtOutCoords();\n          ${n}\n        }`:`\n          float activation(float x) {\n            ${n}\n          }\n        `,x="result = activation(result);");const v=t?"result += getBiasAtOutCoords();":"";t&&this.variableNames.push("bias"),r&&this.variableNames.push("preluActivationWeights"),a&&this.variableNames.push("leakyreluAlpha"),this.userCode=`\n      ${b}\n\n      const ivec2 strides = ivec2(${i}, ${l});\n      const ivec2 pads = ivec2(${s}, ${o});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d2 = coords[${y}];\n\n        ivec2 xRCCorner =\n            ivec2(coords[${g}], coords[${$}]) * strides - pads;\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        // Convolve x(?, ?, d1) with w(:, :, d1, d2) to get y(yR, yC, d2).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ${p}; wR++) {\n          int xR = xRCorner + wR * ${u};\n\n          if (xR < 0 || xR >= ${e.inHeight}) {\n            continue;\n          }\n\n          for (int wC = 0; wC < ${d}; wC++) {\n            int xC = xCCorner + wC * ${c};\n\n            if (xC < 0 || xC >= ${e.inWidth}) {\n              continue;\n            }\n\n            for (int d1 = 0; d1 < ${h}; d1 += 4) {\n              vec4 wValues = vec4(\n                getW(wR, wC, d1, d2),\n                getW(wR, wC, d1 + 1, d2),\n                getW(wR, wC, d1 + 2, d2),\n                getW(wR, wC, d1 + 3, d2)\n              );\n\n              if (${f}) {\n                vec4 xValues = vec4(\n                  getX(batch, xR, xC, d1),\n                  getX(batch, xR, xC, d1 + 1),\n                  getX(batch, xR, xC, d1 + 2),\n                  getX(batch, xR, xC, d1 + 3)\n                );\n                dotProd += dot(xValues, wValues);\n              } else {\n                vec4 xValues = vec4(\n                  getX(batch, d1, xR, xC),\n                  getX(batch, d1 + 1, xR, xC),\n                  getX(batch, d1 + 2, xR, xC),\n                  getX(batch, d1 + 3, xR, xC)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n            }\n\n            if (${1===m}) {\n\n              if (${f}) {\n                dotProd +=\n                    getX(batch, xR, xC, ${h}) *\n                    getW(wR, wC, ${h}, d2);\n              } else {\n                dotProd +=\n                    getX(batch, ${h}, xR, xC) *\n                    getW(wR, wC, ${h}, d2);\n              }\n\n            } else if (${2===m}) {\n              vec2 wValues = vec2(\n                getW(wR, wC, ${h}, d2),\n                getW(wR, wC, ${h} + 1, d2)\n              );\n\n              if (${f}) {\n                vec2 xValues = vec2(\n                  getX(batch, xR, xC, ${h}),\n                  getX(batch, xR, xC, ${h} + 1)\n                );\n                dotProd += dot(xValues, wValues);\n              } else {\n                vec2 xValues = vec2(\n                  getX(batch, ${h}, xR, xC),\n                  getX(batch, ${h} + 1, xR, xC)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n\n            } else if (${3===m}) {\n              vec3 wValues = vec3(\n                getW(wR, wC, ${h}, d2),\n                getW(wR, wC, ${h} + 1, d2),\n                getW(wR, wC, ${h} + 2, d2)\n              );\n\n              if (${f}) {\n                vec3 xValues = vec3(\n                  getX(batch, xR, xC, ${h}),\n                  getX(batch, xR, xC, ${h} + 1),\n                  getX(batch, xR, xC, ${h} + 2)\n                );\n                dotProd += dot(xValues, wValues);\n              } else {\n                vec3 xValues = vec3(\n                  getX(batch, ${h}, xR, xC),\n                  getX(batch, ${h} + 1, xR, xC),\n                  getX(batch, ${h} + 2, xR, xC)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n\n            }\n          }\n        }\n\n        float result = dotProd;\n        ${v}\n        ${x}\n        setOutput(result);\n      }\n    `}}class Conv3DProgram$1{constructor(e){this.variableNames=["x","W"],this.outputShape=e.outShape;const t=e.padInfo.front,n=e.padInfo.top,r=e.padInfo.left,a=e.strideDepth,s=e.strideHeight,o=e.strideWidth,i=e.dilationDepth,l=e.dilationHeight,u=e.dilationWidth,c=e.filterDepth,p=e.filterHeight,d=e.filterWidth,h=4*Math.floor(e.inChannels/4),m=e.inChannels%4;this.userCode=`\n      const ivec3 strides = ivec3(${a}, ${s}, ${o});\n      const ivec3 pads = ivec3(${t}, ${n}, ${r});\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int d2 = coords.u;\n\n        ivec3 xFRCCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\n        int xFCorner = xFRCCorner.x;\n        int xRCorner = xFRCCorner.y;\n        int xCCorner = xFRCCorner.z;\n\n        // Convolve x(?, ?, ?, d1) with w(:, :, :, d1, d2) to get\n        // y(yF, yR, yC, d2). ? = to be determined. : = across all\n        // values in that axis.\n        float dotProd = 0.0;\n        for (int wF = 0; wF < ${c}; wF++) {\n          int xF = xFCorner + wF * ${i};\n\n          if (xF < 0 || xF >= ${e.inDepth}) {\n            continue;\n          }\n\n          for (int wR = 0; wR < ${p}; wR++) {\n            int xR = xRCorner + wR * ${l};\n\n            if (xR < 0 || xR >= ${e.inHeight}) {\n              continue;\n            }\n\n            for (int wC = 0; wC < ${d}; wC++) {\n              int xC = xCCorner + wC * ${u};\n\n              if (xC < 0 || xC >= ${e.inWidth}) {\n                continue;\n              }\n\n              for (int d1 = 0; d1 < ${h}; d1 += 4) {\n                vec4 xValues = vec4(\n                  getX(batch, xF, xR, xC, d1),\n                  getX(batch, xF, xR, xC, d1 + 1),\n                  getX(batch, xF, xR, xC, d1 + 2),\n                  getX(batch, xF, xR, xC, d1 + 3)\n                );\n                vec4 wValues = vec4(\n                  getW(wF, wR, wC, d1, d2),\n                  getW(wF, wR, wC, d1 + 1, d2),\n                  getW(wF, wR, wC, d1 + 2, d2),\n                  getW(wF, wR, wC, d1 + 3, d2)\n                );\n\n                dotProd += dot(xValues, wValues);\n              }\n\n              if (${1===m}) {\n                dotProd +=\n                  getX(batch, xF, xR, xC, ${h}) *\n                  getW(wF, wR, wC, ${h}, d2);\n              } else if (${2===m}) {\n                vec2 xValues = vec2(\n                  getX(batch, xF, xR, xC, ${h}),\n                  getX(batch, xF, xR, xC, ${h} + 1)\n                );\n                vec2 wValues = vec2(\n                  getW(wF, wR, wC, ${h}, d2),\n                  getW(wF, wR, wC, ${h} + 1, d2)\n                );\n                dotProd += dot(xValues, wValues);\n              } else if (${3===m}) {\n                vec3 xValues = vec3(\n                  getX(batch, xF, xR, xC, ${h}),\n                  getX(batch, xF, xR, xC, ${h} + 1),\n                  getX(batch, xF, xR, xC, ${h} + 2)\n                );\n                vec3 wValues = vec3(\n                  getW(wF, wR, wC, ${h}, d2),\n                  getW(wF, wR, wC, ${h} + 1, d2),\n                  getW(wF, wR, wC, ${h} + 2, d2)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class Im2ColPackedProgram$1{constructor(e,t,n){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=e;const{filterWidth:r,inChannels:a,strideWidth:s,strideHeight:o,padInfo:i,outWidth:l,dilationWidth:u,dilationHeight:c,dataFormat:p}=n,{left:d,top:h}=i,m=a*r,f=getGlslDifferences$1(),g="channelsLast"===p,$=g?0:1,y=g?1:2;let b="";for(let n=0;n<=1;n++)for(let r=0;r<=1;r++)b+=`\n          blockIndex = rc.y + ${r};\n          pos = rc.x + ${n};\n\n          if(blockIndex < ${e[1]} && pos < ${e[0]}) {\n            offsetY = int(blockIndex / (${l})) * ${o} - ${h};\n            d0 = offsetY + ${c} * (pos / ${m});\n\n            if(d0 < ${t[$]} && d0 >= 0) {\n\n              offsetX = int(mod(float(blockIndex), ${l}.) * ${s}. - ${d}.);\n              d1 = offsetX + ${u} * (int(mod(float(pos), ${m}.) / ${a}.));\n\n              if(d1 < ${t[y]} && d1 >= 0) {\n\n                ch = int(mod(float(pos), ${a}.));\n\n                if (${g}) {\n                  innerDims = vec2(d1, ch);\n                  result[${2*n+r}] = getChannel(\n                    getA(d0, int(innerDims.x),\n                    int(innerDims.y)), innerDims);\n                } else {\n                  innerDims = vec2(d0, d1);\n                  result[${2*n+r}] = getChannel(\n                    getA(ch, int(innerDims.x),\n                    int(innerDims.y)), innerDims);\n                }\n              }\n            }\n          }\n        `;this.userCode=`\n      void main() {\n        ivec2 rc = getOutputCoords();\n\n        vec4 result = vec4(0);\n\n        int blockIndex, pos, offsetY, d0, offsetX, d1, ch;\n        vec2 innerDims;\n\n        ${b}\n\n        ${f.output} = result;\n      }\n    `}}function conv2dByMatMul$1({x:e,filter:t,convInfo:n,backend:r,bias:a=null,preluActivationWeights:s=null,leakyreluAlpha:o=0,activation:i=null}){const l=e.shape,u=r.texData.get(e.dataId),c="channelsLast"===n.dataFormat;let p;const d=[],h=l[2]%2!=0&&!!u.isPacked;if((1!=l[0]*l[1]*l[2]&&1!==n.outChannels||!(n.inChannels>MATMUL_SHARED_DIM_THRESHOLD$1))&&env$1().getBool("WEBGL_LAZILY_UNPACK")&&env$1().getBool("WEBGL_PACK_BINARY_OPERATIONS")&&h){const h={dataId:e.dataId,shape:[1,c?l[0]*l[1]*(l[2]+1):l[0]*l[2]*(l[3]+1),n.inChannels],dtype:e.dtype},m=u.shape;u.shape=u.shape.slice(),u.shape[u.shape.length-2]++,assert$6(isReshapeFree$1(u.shape,h.shape),()=>`packed reshape ${u.shape} to ${h.shape} isn't free`);const f=reshape$4({inputs:{x:t},backend:r,attrs:{shape:[1,n.inChannels,n.outChannels]}});d.push(f);const g=batchMatMulImpl$1({a:h,b:f,backend:r,transposeA:!1,transposeB:!1,bias:a,activation:i,preluActivationWeights:s,leakyreluAlpha:o}),$=r.texData.get(g.dataId);assert$6($.isPacked,()=>"batchMatMul result is expected to be packed"),u.shape=m,$.shape=n.outShape,p=identity$3({inputs:{x:g},backend:r}),p.shape=n.outShape,d.push(g)}else{const u=reshape$4({inputs:{x:e},backend:r,attrs:{shape:[1,c?l[0]*l[1]*l[2]:l[0]*l[2]*l[3],n.inChannels]}}),h=reshape$4({inputs:{x:t},backend:r,attrs:{shape:[1,n.inChannels,n.outChannels]}}),m=batchMatMulImpl$1({a:u,b:h,transposeA:!1,transposeB:!1,backend:r,bias:a,activation:i,preluActivationWeights:s,leakyreluAlpha:o});p=reshape$4({inputs:{x:m},backend:r,attrs:{shape:n.outShape}}),d.push(u),d.push(h),d.push(m)}for(const e of d)r.disposeIntermediateTensorInfo(e);return p}function conv2dWithIm2Row$1({x:e,filter:t,convInfo:n,backend:r,bias:a=null,preluActivationWeights:s=null,leakyreluAlpha:o=0,activation:i=null}){const{filterWidth:l,filterHeight:u,inChannels:c,outWidth:p,outHeight:d,dataFormat:h}=n,m="channelsLast"===h,f=l*u*c,g=d*p,$=[f,g],y=[],b=reshape$4({inputs:{x:e},backend:r,attrs:{shape:e.shape.slice(1)}}),x=reshape$4({inputs:{x:t},backend:r,attrs:{shape:[1,f,sizeFromShape$1(t.shape)/f]}});y.push(b),y.push(x);const v=new Im2ColPackedProgram$1($,b.shape,n),I=r.runWebGLProgram(v,[b],"float32"),C=reshape$4({inputs:{x:I},backend:r,attrs:{shape:[1,$[0],$[1]]}});y.push(I),y.push(C);const S=null!=a,k=null!=s,T="leakyrelu"===i,N=i?mapActivationToShaderProgram$1(i,!0):null,w=new MatMulPackedProgram$1(C.shape,x.shape,[1,g,n.outChannels],!0,!1,S,N,k,T),E=[C,x];if(a&&E.push(a),k&&E.push(s),T){const e=r.makeTensorInfo([],"float32",createScalarValue$1(o,"float32"));E.push(e),y.push(e)}const A=r.runWebGLProgram(w,E,"float32"),D=reshape$4({inputs:{x:A},backend:r,attrs:{shape:m?[1,d,p,n.outChannels]:[1,n.outChannels,d,p]}});y.push(A);for(const e of y)r.disposeIntermediateTensorInfo(e);return D}function conv2d$4(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,filter:s}=t,{strides:o,pad:i,dataFormat:l,dilations:u,dimRoundingMode:c}=r,p=convertConv2DDataFormat$1(l),d=computeConv2DInfo$1(a.shape,s.shape,o,u,i,c,!1,p);let h;if(1!==d.filterHeight||1!==d.filterWidth||1!==d.dilationHeight||1!==d.dilationWidth||1!==d.strideHeight||1!==d.strideWidth||"SAME"!==d.padInfo.type&&"VALID"!==d.padInfo.type)if(env$1().getBool("WEBGL_CONV_IM2COL")&&1===a.shape[0])h=conv2dWithIm2Row$1({x:a,filter:s,convInfo:d,backend:n});else{const e=new Conv2DProgram$1(d);h=n.runWebGLProgram(e,[a,s],"float32")}else h=conv2dByMatMul$1({x:a,filter:s,convInfo:d,backend:n});const m=reshape$4({inputs:{x:h},backend:n,attrs:{shape:d.outShape}});return n.disposeIntermediateTensorInfo(h),m}const conv2DConfig$2={kernelName:Conv2D$3,backendName:"webgl",kernelFunc:conv2d$4};class Conv2DDerFilterProgram$1{constructor(e){this.variableNames=["x","dy"],this.outputShape=e.filterShape,this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int wR = coords.x;\n        int wC = coords.y;\n        int d1 = coords.z;\n        int d2 = coords.w;\n\n        // Convolve x(?, ?, d1) with dy(:, :, d2) to get dw(wR, wC, d1, d2).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n\n        for (int b = 0; b < ${e.batchSize}; b++) {\n          for (int yR = 0; yR < ${e.outHeight}; yR++) {\n            int xR = wR + yR * ${e.strideHeight} - ${e.padInfo.top};\n\n            if (xR < 0 || xR >= ${e.inHeight}) {\n              continue;\n            }\n\n            for (int yC = 0; yC < ${e.outWidth}; yC++) {\n              int xC = wC + yC * ${e.strideWidth} - ${e.padInfo.left};\n\n              if (xC < 0 || xC >= ${e.inWidth}) {\n                continue;\n              }\n\n              if (${"channelsLast"===e.dataFormat}) {\n                float dyValue = getDy(b, yR, yC, d2);\n                float xValue = getX(b, xR, xC, d1);\n                dotProd += (xValue * dyValue);\n              } else {\n                float dyValue = getDy(b, d2, yR, yC);\n                float xValue = getX(b, d1, xR, xC);\n                dotProd += (xValue * dyValue);\n              }\n\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class Conv2DDerInputProgram$1{constructor(e){this.variableNames=["dy","W"],this.outputShape=e.inShape;const t=e.filterHeight,n=e.filterWidth,r="channelsLast"===e.dataFormat;this.userCode=`\n      const ivec2 pads = ivec2(${t-1-e.padInfo.top}, ${n-1-e.padInfo.left});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d1 = coords[${r?3:1}];\n\n        ivec2 dyCorner = ivec2(coords[${r?1:2}], coords[${r?2:3}]) - pads;\n        int dyRCorner = dyCorner.x;\n        int dyCCorner = dyCorner.y;\n\n        // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ${t}; wR++) {\n          float dyR = float(dyRCorner + wR) / ${e.strideHeight}.0;\n\n          if (dyR < 0.0 || dyR >= ${e.outHeight}.0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          int wRPerm = ${t} - 1 - wR;\n\n          for (int wC = 0; wC < ${n}; wC++) {\n            float dyC = float(dyCCorner + wC) / ${e.strideWidth}.0;\n\n            if (dyC < 0.0 || dyC >= ${e.outWidth}.0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            int wCPerm = ${n} - 1 - wC;\n\n            for (int d2 = 0; d2 < ${e.outChannels}; d2++) {\n\n              if (${r}) {\n                float xValue = getDy(batch, idyR, idyC, d2);\n                float wValue = getW(wRPerm, wCPerm, d1, d2);\n                dotProd += xValue * wValue;\n              } else {\n                float xValue = getDy(batch, d2, idyR, idyC);\n                float wValue = getW(wRPerm, wCPerm, d1, d2);\n                dotProd += xValue * wValue;\n              }\n\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class Conv3DDerFilterProgram$1{constructor(e){this.variableNames=["x","dy"],this.outputShape=e.filterShape,this.userCode=`\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int wF = coords.x;\n        int wR = coords.y;\n        int wC = coords.z;\n        int d1 = coords.w;\n        int d2 = coords.u;\n\n        float dotProd = 0.0;\n\n        for (int b = 0; b < ${e.batchSize}; b++) {\n          for (int yF = 0; yF < ${e.outDepth}; yF++) {\n            int xF = wF + yF * ${e.strideDepth} - ${e.padInfo.front};\n\n            if (xF < 0 || xF >= ${e.inDepth}) {\n              continue;\n            }\n\n            for (int yR = 0; yR < ${e.outHeight}; yR++) {\n              int xR = wR + yR * ${e.strideHeight} - ${e.padInfo.top};\n\n              if (xR < 0 || xR >= ${e.inHeight}) {\n                continue;\n              }\n\n              for (int yC = 0; yC < ${e.outWidth}; yC++) {\n                int xC = wC + yC * ${e.strideWidth} - ${e.padInfo.left};\n\n                if (xC < 0 || xC >= ${e.inWidth}) {\n                  continue;\n                }\n\n                float dyValue = getDy(b, yF, yR, yC, d2);\n                float xValue = getX(b, xF, xR, xC, d1);\n                dotProd += (xValue * dyValue);\n              }\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class Conv3DDerInputProgram$1{constructor(e){this.variableNames=["dy","W"],this.outputShape=e.inShape;const t=e.filterDepth,n=e.filterHeight,r=e.filterWidth;this.userCode=`\n      const ivec3 pads = ivec3(${t-1-e.padInfo.front}, ${n-1-e.padInfo.top}, ${r-1-e.padInfo.left});\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int d1 = coords.u;\n\n\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\n        int dyFCorner = dyCorner.x;\n        int dyRCorner = dyCorner.y;\n        int dyCCorner = dyCorner.z;\n\n        float dotProd = 0.0;\n        for (int wF = 0; wF < ${t}; wF++) {\n          float dyF = float(dyFCorner + wF) / ${e.strideDepth}.0;\n\n          if (dyF < 0.0 || dyF >= ${e.outDepth}.0 || fract(dyF) > 0.0) {\n            continue;\n          }\n          int idyF = int(dyF);\n\n          int wFPerm = ${t} - 1 - wF;\n\n          for (int wR = 0; wR < ${n}; wR++) {\n            float dyR = float(dyRCorner + wR) / ${e.strideHeight}.0;\n\n            if (dyR < 0.0 || dyR >= ${e.outHeight}.0 ||\n              fract(dyR) > 0.0) {\n              continue;\n            }\n            int idyR = int(dyR);\n\n            int wRPerm = ${n} - 1 - wR;\n\n            for (int wC = 0; wC < ${r}; wC++) {\n              float dyC = float(dyCCorner + wC) / ${e.strideWidth}.0;\n\n              if (dyC < 0.0 || dyC >= ${e.outWidth}.0 ||\n                  fract(dyC) > 0.0) {\n                continue;\n              }\n              int idyC = int(dyC);\n\n              int wCPerm = ${r} - 1 - wC;\n\n              for (int d2 = 0; d2 < ${e.outChannels}; d2++) {\n                float xValue = getDy(batch, idyF, idyR, idyC, d2);\n                float wValue = getW(wFPerm, wRPerm, wCPerm, d1, d2);\n                dotProd += xValue * wValue;\n              }\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}function conv2DBackpropFilter$3(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,dy:s}=t,{strides:o,pad:i,dataFormat:l,dimRoundingMode:u,filterShape:c}=r,p=convertConv2DDataFormat$1(l),d=computeConv2DInfo$1(a.shape,c,o,1,i,u,!1,p),h=new Conv2DDerFilterProgram$1(d);return n.runWebGLProgram(h,[a,s],"float32")}const conv2DBackpropFilterConfig$2={kernelName:Conv2DBackpropFilter$1,backendName:"webgl",kernelFunc:conv2DBackpropFilter$3};function conv2DBackpropInput$3(e){const{inputs:t,backend:n,attrs:r}=e,{dy:a,filter:s}=t,{inputShape:o,strides:i,pad:l,dataFormat:u,dimRoundingMode:c}=r,p=convertConv2DDataFormat$1(u),d=computeConv2DInfo$1(o,s.shape,i,1,l,c,!1,p),h=new Conv2DDerInputProgram$1(d);return n.runWebGLProgram(h,[a,s],"float32")}const conv2DBackpropInputConfig$2={kernelName:Conv2DBackpropInput$1,backendName:"webgl",kernelFunc:conv2DBackpropInput$3};function conv3D$2(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,filter:s}=t,{strides:o,pad:i,dilations:l}=r,u=computeConv3DInfo$1(a.shape,s.shape,o,l,i),c=new Conv3DProgram$1(u);return n.runWebGLProgram(c,[a,s],"float32")}const conv3DConfig$2={kernelName:Conv3D$3,backendName:"webgl",kernelFunc:conv3D$2};function conv3DBackpropFilterV2$2(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,dy:s}=t,{strides:o,pad:i,filterShape:l}=r,u=computeConv3DInfo$1(a.shape,l,o,1,i),c=new Conv3DDerFilterProgram$1(u);return n.runWebGLProgram(c,[a,s],"float32")}const conv3DBackpropFilterV2Config$2={kernelName:Conv3DBackpropFilterV2$1,backendName:"webgl",kernelFunc:conv3DBackpropFilterV2$2};function conv3DBackpropInput$2(e){const{inputs:t,backend:n,attrs:r}=e,{dy:a,filter:s}=t,{pad:o,strides:i,inputShape:l}=r,u=computeConv3DInfo$1(l,s.shape,i,1,o),c=new Conv3DDerInputProgram$1(u);return n.runWebGLProgram(c,[a,s],"float32")}const conv3DBackpropInputConfig$1={kernelName:Conv3DBackpropInputV2$1,backendName:"webgl",kernelFunc:conv3DBackpropInput$2},COS$1=CHECK_NAN_SNIPPET_UNARY$1+"\n  return cos(x);\n",cos$3=unaryKernelFunc$2({opSnippet:COS$1}),cosConfig$2={kernelName:Cos$1,backendName:"webgl",kernelFunc:cos$3},COSH$1="\n  float e2x = exp(-x);\n  return (e2x + 1.0 / e2x) / 2.0;\n",cosh$3=unaryKernelFunc$2({opSnippet:COSH$1}),coshConfig$2={kernelName:Cosh$1,backendName:"webgl",kernelFunc:cosh$3};class CropAndResizeProgram$1{constructor(e,t,n,r,a){this.variableNames=["Image","Boxes","BoxInd"],this.outputShape=[];const[s,o,i,l]=e,[u]=t,[c,p]=n;this.outputShape=[u,c,p,l];const d="bilinear"===r?1:0,[h,m]=[o-1+".0",i-1+".0"],[f,g,$]=c>1?[""+(o-1)/(c-1),"(y2-y1) * height_ratio",`y1*${h} + float(y)*(height_scale)`]:["0.0","0.0",`0.5 * (y1+y2) * ${h}`],[y,b,x]=p>1?[""+(i-1)/(p-1),"(x2-x1) * width_ratio",`x1*${m} + float(x)*(width_scale)`]:["0.0","0.0",`0.5 * (x1+x2) * ${m}`];this.userCode=`\n      const float height_ratio = float(${f});\n      const float width_ratio = float(${y});\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int y = coords[1];\n        int x = coords[2];\n        int d = coords[3];\n\n        // get box vals\n        float y1 = getBoxes(b,0);\n        float x1 = getBoxes(b,1);\n        float y2 = getBoxes(b,2);\n        float x2 = getBoxes(b,3);\n\n        // get image in batch index\n        int bInd = round(getBoxInd(b));\n        if(bInd < 0 || bInd >= ${s}) {\n          return;\n        }\n\n        float height_scale = ${g};\n        float width_scale = ${b};\n\n        float in_y = ${$};\n        if( in_y < 0.0 || in_y > ${h} ) {\n          setOutput(float(${a}));\n          return;\n        }\n        float in_x = ${x};\n        if( in_x < 0.0 || in_x > ${m} ) {\n          setOutput(float(${a}));\n          return;\n        }\n\n        vec2 sourceFracIndexCR = vec2(in_x,in_y);\n        if(${d} == 1) {\n          // Compute the four integer indices.\n          ivec2 sourceFloorCR = ivec2(sourceFracIndexCR);\n          ivec2 sourceCeilCR = ivec2(ceil(sourceFracIndexCR));\n\n          float topLeft = getImage(b, sourceFloorCR.y, sourceFloorCR.x, d);\n          float bottomLeft = getImage(b, sourceCeilCR.y, sourceFloorCR.x, d);\n          float topRight = getImage(b, sourceFloorCR.y, sourceCeilCR.x, d);\n          float bottomRight = getImage(b, sourceCeilCR.y, sourceCeilCR.x, d);\n\n          vec2 fracCR = sourceFracIndexCR - vec2(sourceFloorCR);\n\n          float top = topLeft + (topRight - topLeft) * fracCR.x;\n          float bottom = bottomLeft + (bottomRight - bottomLeft) * fracCR.x;\n          float newValue = top + (bottom - top) * fracCR.y;\n          setOutput(newValue);\n        } else {\n          // Compute the coordinators of nearest neighbor point.\n          ivec2 sourceNearestCR = ivec2(floor(\n            sourceFracIndexCR + vec2(0.5,0.5)));\n          float newValue = getImage(b, sourceNearestCR.y, sourceNearestCR.x, d);\n          setOutput(newValue);\n        }\n      }\n    `}}const cropAndResize$3=e=>{const{inputs:t,backend:n,attrs:r}=e,{image:a,boxes:s,boxInd:o}=t,{cropSize:i,method:l,extrapolationValue:u}=r,c=new CropAndResizeProgram$1(a.shape,s.shape,i,l,u);return n.runWebGLProgram(c,[a,s,o],"float32")},cropAndResizeConfig$2={kernelName:CropAndResize$1,backendName:"webgl",kernelFunc:cropAndResize$3};class CumSumProgram$1{constructor(e,t,n){this.variableNames=["x"],this.customUniforms=[{name:"index",type:"float"}],this.outputShape=e;const r=e.length,a=t?"0.0":`getX(${getCoords$2(r,"coords")})`,s=e[e.length-1];let o="",i="";t?(o=n?"end != "+(s-1):"end != 0",i=n?"end + 1":"end - 1"):(o=n?`end + pow2 < ${s}`:"end >= pow2",i=n?"end + pow2":"end - pow2"),this.userCode=`\n      void main() {\n        ${getCoordsDataType$1(r)} coords = getOutputCoords();\n        int end = ${getFinalCoord$1(r,"coords")};\n        float val = ${a};\n        int pow2 = int(pow(2.0, index));\n        if (${o}) {\n          int idx = ${i};\n          ${getFinalCoord$1(r,"coords")} = idx;\n          val += getX(${getCoords$2(r,"coords")});\n        }\n        setOutput(val);\n      }\n    `}}function getCoords$2(e,t){if(1===e)return`${t}`;if(2===e)return`${t}.x, ${t}.y`;if(3===e)return`${t}.x, ${t}.y, ${t}.z`;if(4===e)return`${t}.x, ${t}.y, ${t}.z, ${t}.w`;throw Error(`Cumulative sum for rank ${e} is not yet supported`)}function getFinalCoord$1(e,t){if(1===e)return`${t}`;if(2===e)return`${t}.y`;if(3===e)return`${t}.z`;if(4===e)return`${t}.w`;throw Error(`Cumulative sum for rank ${e} is not yet supported`)}function cumsum$3(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{axis:s,exclusive:o,reverse:i}=r,l=a.shape.length,u=getAxesPermutation$1([s],l);let c=a;null!=u&&(c=transpose$3({inputs:{x:a},backend:n,attrs:{perm:u}}));const p=getInnerMostAxes$1(1,l)[0];if(p!==l-1)throw new Error(`WebGL cumsum shader expects an inner-most axis=${a.shape.length-1} but got axis=${s}`);const d=c.shape[p];let h=identity$3({inputs:{x:c},backend:n});for(let e=0;e<=Math.ceil(Math.log2(d))-1;e++){const t=new CumSumProgram$1(c.shape,!1,i),r=h;h=n.runWebGLProgram(t,[h],h.dtype,[[e]]),n.disposeIntermediateTensorInfo(r)}if(o){const e=new CumSumProgram$1(c.shape,o,i),t=h;h=n.runWebGLProgram(e,[h],h.dtype),n.disposeIntermediateTensorInfo(t)}if(null!=u){const e=transpose$3({inputs:{x:h},backend:n,attrs:{perm:getUndoAxesPermutation$1(u)}});return n.disposeIntermediateTensorInfo(h),n.disposeIntermediateTensorInfo(c),e}return h}const cumsumConfig$2={kernelName:Cumsum$1,backendName:"webgl",kernelFunc:cumsum$3};function denseBincount$3(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,weights:s}=t,{size:o,binaryOutput:i}=r;if(1===a.shape.length){const e=n.readSync(a.dataId),t=n.readSync(s.dataId),r=bincountImplCPU$1(e,t,s.dtype,s.shape,o);return n.makeTensorInfo([o],s.dtype,r)}if(2===a.shape.length){const e=n.bufferSync(a),t=n.bufferSync(s),r=bincountReduceImplCPU$1(e,t,o,i);return n.makeTensorInfo(r.shape,s.dtype,r.values)}throw new Error(`Error in denseBincount: input must be at most rank 2, but got rank${a.shape.length}.`)}const denseBincountConfig$2={kernelName:DenseBincount$1,backendName:"webgl",kernelFunc:denseBincount$3};class DepthToSpaceProgram$1{constructor(e,t,n){this.variableNames=["x"],this.outputShape=[],this.outputShape=e,this.blockSize=t,this.dataFormat=n,this.userCode=`\n    void main() {\n      ivec4 coords = getOutputCoords();\n      int b = coords[0];\n      int h = ${this.getHeightCoordString()};\n      int w = ${this.getWidthCoordString()};\n      int d = ${this.getDepthCoordString()};\n\n      int in_h = h / ${t};\n      int offset_h = imod(h, ${t});\n      int in_w = w / ${t};\n      int offset_w = imod(w, ${t});\n      int offset_d = (offset_h * ${t} + offset_w) *\n        ${this.getOutputDepthSize()};\n      int in_d = d + offset_d;\n\n      float result = ${this.getInputSamplingString()};\n      setOutput(result);\n    }\n  `}getHeightCoordString(){return"NHWC"===this.dataFormat?"coords[1]":"coords[2]"}getWidthCoordString(){return"NHWC"===this.dataFormat?"coords[2]":"coords[3]"}getDepthCoordString(){return"NHWC"===this.dataFormat?"coords[3]":"coords[1]"}getOutputDepthSize(){return"NHWC"===this.dataFormat?this.outputShape[3]:this.outputShape[1]}getInputSamplingString(){return"NHWC"===this.dataFormat?"getX(b, in_h, in_w, in_d)":"getX(b, in_d, in_h, in_w)"}}function depthToSpace$3(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{blockSize:s,dataFormat:o}=r;assert$6(s>1,()=>`blockSize should be > 1 for depthToSpace, but was: ${s}`);const i=a.shape[0],l=("NHWC"===o?a.shape[1]:a.shape[2])*s,u=("NHWC"===o?a.shape[2]:a.shape[3])*s,c=("NHWC"===o?a.shape[3]:a.shape[1])/(s*s),p=new DepthToSpaceProgram$1("NHWC"===o?[i,l,u,c]:[i,c,l,u],s,o);return n.runWebGLProgram(p,[a],a.dtype)}const depthToSpaceConfig$2={kernelName:DepthToSpace$1,backendName:"webgl",kernelFunc:depthToSpace$3};class DepthwiseConv2DProgram$1{constructor(e,t=!1,n=null,r=!1,a=!1){this.variableNames=["x","W"],this.outputShape=e.outShape;const s=e.inHeight,o=e.inWidth,i=e.padInfo.top,l=e.padInfo.left,u=e.strideHeight,c=e.strideWidth,p=e.dilationHeight,d=e.dilationWidth,h=e.filterHeight,m=e.filterWidth,f=e.outChannels/e.inChannels;let g="",$="";n&&(g=r?`float activation(float a) {\n          float b = getPreluActivationWeightsAtOutCoords();\n          ${n}\n        }`:a?`float activation(float a) {\n          float b = getLeakyreluAlphaAtOutCoords();\n          ${n}\n        }`:`\n          float activation(float x) {\n            ${n}\n          }\n        `,$="result = activation(result);");const y=t?"result += getBiasAtOutCoords();":"";t&&this.variableNames.push("bias"),r&&this.variableNames.push("preluActivationWeights"),a&&this.variableNames.push("leakyreluAlpha"),this.userCode=`\n      ${g}\n\n      const ivec2 strides = ivec2(${u}, ${c});\n      const ivec2 pads = ivec2(${i}, ${l});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords.x;\n        ivec2 xRCCorner = coords.yz * strides - pads;\n        int d2 = coords.w;\n        int d1 = d2 / ${f};\n        int q = d2 - d1 * ${f};\n\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        // Convolve x(?, ?, d1) with w(:, :, d1, q) to get y(yR, yC, d2).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        // TO DO(dsmilkov): Flatten the two for loops and vec4 the operations.\n        for (int wR = 0; wR < ${h}; wR++) {\n          int xR = xRCorner + wR * ${p};\n\n          if (xR < 0 || xR >= ${s}) {\n            continue;\n          }\n\n          for (int wC = 0; wC < ${m}; wC++) {\n            int xC = xCCorner + wC * ${d};\n\n            if (xC < 0 || xC >= ${o}) {\n              continue;\n            }\n\n            float xVal = getX(batch, xR, xC, d1);\n            float wVal = getW(wR, wC, d1, q);\n            dotProd += xVal * wVal;\n          }\n        }\n\n        float result = dotProd;\n        ${y}\n        ${$}\n        setOutput(result);\n      }\n    `}}class DepthwiseConvPacked2DProgram$1{constructor(e,t=!1,n=null,r=!1,a=!1){this.variableNames=["x","W"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=e.outShape;const s=e.outChannels/e.inChannels,o=e.inHeight,i=e.inWidth,l=e.padInfo.top,u=e.padInfo.left,c=e.strideHeight,p=e.strideWidth,d=e.dilationHeight,h=e.dilationWidth,m=e.filterHeight,f=e.filterWidth,g=f;let $="\n      int xR; int xC; int xCOffset;\n      vec4 wTexel; vec4 previous; vec4 final;";for(let e=0;e<f;e++)$+=`\n          vec4 xTexelC${2*e};\n          int xTexelC${2*e}Ready;\n          vec4 xTexelC${2*e+1};\n          int xTexelC${2*e+1}Ready;\n          vec4 xC${e};`;for(let e=0;e<m;e++){for(let e=0;e<f;e++)$+=`\n          xTexelC${2*e} = vec4(0.0);\n          xTexelC${2*e}Ready = 0;\n          xTexelC${2*e+1} = vec4(0.0);\n          xTexelC${2*e+1}Ready = 0;\n          xC${e} = vec4(0.0);`;$+=`\n        xR = xRCorner + ${e*d};\n        if (xR >=0 && xR < ${o}) {\n      `;for(let t=0;t<(g+1)/2;t++){const n=2*t,r=n*h;if($+=`\n          xC = xCCorner + ${r};\n          `,1===p){if(n<f&&(u%2==1?($+=`\n                xCOffset = xC + 1;\n                if (xCOffset >= 0 && xCOffset < ${i} && xTexelC${n}Ready == 0) {\n                  xTexelC${n} = getX(batch, xR, xCOffset, d1);\n\n                  // Need to manually clear unused channels in case\n                  // we're reading from recycled texture.\n                  if (xCOffset + 1 >= ${i}) {\n                    xTexelC${n}.zw = vec2(0.0);\n                  }\n                  xTexelC${n}Ready = 1;\n                }\n              `,$+=1===h&&r>0?`\n                xC${n} = vec4(xTexelC${n-2}.zw, xTexelC${n}.xy);\n                `:`\n                  xCOffset = xC + 1 - 2;\n\n                  if (xCOffset >= 0 && xCOffset < ${i}) {\n                    previous = getX(batch, xR, xCOffset, d1);\n\n                    // Need to manually clear unused channels in case\n                    // we're reading from recycled texture.\n                    if (xCOffset + 1 >= ${i}) {\n                      previous.zw = vec2(0.0);\n                    }\n\n                    xC${n} = vec4(previous.zw, xTexelC${n}.xy);\n                  } else {\n                    xC${n} = vec4(0.0, 0.0, xTexelC${n}.xy);\n                  }\n                  `):$+=`\n                if (xC >= 0 && xC < ${i} && xTexelC${n}Ready == 0) {\n                  xTexelC${n} = getX(batch, xR, xC, d1);\n                  if (xC + 1 >= ${i}) {\n                    xTexelC${n}.zw = vec2(0.0);\n                  }\n                  xTexelC${n}Ready = 1;\n                }\n\n                xC${n} = xTexelC${n};\n                `,r+1<f)){const e=u%2==0?nearestLargerEven$1(h):h;h%2==0&&u%2==1||h%2!=0&&u%2!=1?($+=`\n                  xCOffset = xC + ${u%2} + ${e};\n\n                  if (xCOffset >= 0 && xCOffset < ${i} && xTexelC${n+1}Ready == 0) {\n                    xTexelC${n+1} = getX(batch, xR, xCOffset, d1);\n\n                    // Need to manually clear unused channels in case\n                    // we're reading from recycled texture.\n                    if (xCOffset + 1 >= ${i}) {\n                      xTexelC${n+1}.zw = vec2(0.0);\n                    }\n                    xTexelC${n+1}Ready = 1;\n                  }\n                  `,h>1&&($+=`\n                    xCOffset -= 2;\n                    if (xCOffset >= 0 && xCOffset < ${i} && xTexelC${n}Ready == 0) {\n                      xTexelC${n} = getX(batch, xR, xCOffset, d1);\n                      xTexelC${n}Ready = 1;\n                    }\n                    `),$+=`\n                  xC${n+1} = vec4(xTexelC${n}.zw, xTexelC${n+1}.xy);\n                  `):$+=1===e?`\n                    xC${n+1} = xTexelC${n};\n                    `:`\n                    xCOffset = xC + ${e};\n\n                    if (xCOffset >= 0 && xCOffset < ${i} && xTexelC${n+1}Ready == 0) {\n                      xTexelC${n+1} = getX(batch, xR, xCOffset, d1);\n                      if (xCOffset + 1 >= ${i}) {\n                        xTexelC${n+1}.zw = vec2(0.0);\n                      }\n                      xTexelC${n+1}Ready = 1;\n                    }\n\n                    xC${n+1} = xTexelC${n+1};\n                    `}}else r<f&&(u%2==1?($+=`\n                xCOffset = xC + 1 - ${p};\n                if(xCOffset >= 0 && xCOffset < ${i} && xTexelC${n}Ready == 0) {\n                  xTexelC${n} = getX(batch, xR, xCOffset, d1);\n                  // Need to manually clear unused channels in case\n                  // we're reading from recycled texture.\n                  if (xCOffset + 1 >= ${i}) {\n                    xTexelC${n}.zw = vec2(0.0);\n                  }\n                  xTexelC${n}Ready = 1;\n                }\n\n                if(xC + 1 >= 0 && xC + 1 < ${i} && xTexelC${n+1}Ready == 0) {\n                  xTexelC${n+1} = getX(batch, xR, xC + 1, d1);\n                  // Need to manually clear unused channels in case\n                  // we're reading from recycled texture.\n                  if (xC + 2 >= ${i}) {\n                    xTexelC${n+1}.zw = vec2(0.0);\n                  }\n                  xTexelC${n+1}Ready = 1;\n                }\n\n                xC${n} = vec4(xTexelC${n}.zw, xTexelC${n+1}.zw);\n              `,r+1<f&&($+=`\n                  final = vec4(0.0);\n                  xCOffset = xC + 1 + ${p};\n                  if(xCOffset >= 0 && xCOffset < ${i}) {\n                    final = getX(batch, xR, xCOffset, d1);\n                  }\n                  xC${n+1} = vec4(xTexelC${n+1}.xy, final.xy);\n                `)):($+=`\n                if(xC >= 0 && xC < ${i} && xTexelC${n}Ready == 0) {\n                  xTexelC${n} = getX(batch, xR, xC, d1);\n                  if (xC + 1 >= ${i}) {\n                    xTexelC${n}.zw = vec2(0.0);\n                  }\n                  xTexelC${n}Ready = 1;\n                }\n\n                xCOffset = xC + ${p};\n                if(xCOffset >= 0 && xCOffset < ${i} && xTexelC${n+1}Ready == 0) {\n                  xTexelC${n+1} = getX(batch, xR, xCOffset, d1);\n                  if (xCOffset + 1 >= ${i}) {\n                    xTexelC${n+1}.zw = vec2(0.);\n                  }\n                  xTexelC${n+1}Ready = 1;\n                }\n\n                xC${n} = vec4(\n                  xTexelC${n}.xy, xTexelC${n+1}.xy);\n              `,r+1<f&&($+=`\n                  xC${n+1} = vec4(xTexelC${n}.zw, xTexelC${n+1}.zw);\n                `)));n<f&&($+=`\n            wTexel = getW(${e}, ${r}, d1, q);\n            dotProd += xC${n} * vec4(wTexel.xz, wTexel.xz);\n          `,r+1<f&&($+=`\n              wTexel = getW(${e}, ${r+1}, d1, q);\n              dotProd += xC${n+1} * vec4(wTexel.xz, wTexel.xz);\n            `))}$+="\n        }\n      "}let y="",b="";n&&(y=r?`vec4 activation(vec4 a) {\n          vec4 b = getPreluActivationWeightsAtOutCoords();\n          ${n}\n        }`:a?`vec4 activation(vec4 a) {\n          vec4 b = getLeakyreluAlphaAtOutCoords();\n          ${n}\n        }`:`vec4 activation(vec4 x) {\n          ${n}\n        }`,b="result = activation(result);");const x=t?"result += getBiasAtOutCoords();":"";t&&this.variableNames.push("bias"),r&&this.variableNames.push("preluActivationWeights"),a&&this.variableNames.push("leakyreluAlpha"),this.userCode=`\n      ${y}\n\n      const ivec2 strides = ivec2(${c}, ${p});\n      const ivec2 pads = ivec2(${l}, ${u});\n\n      void main() {\n\n        ivec4 coords = getOutputCoords();\n        int batch = coords.x;\n        ivec2 xRCCorner = coords.yz * strides - pads;\n        int d2 = coords.w;\n        int d1 = d2 / ${s};\n        int q = d2 - d1 * ${s};\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        //intialize dotProd with a small epsilon seems to reduce GPU accuracy loss.\n        vec4 dotProd = vec4(0.000000000000001);\n\n        ${$}\n\n        vec4 result = dotProd - vec4(0.000000000000001);\n        ${x}\n        ${b}\n        setOutput(result);\n      }\n    `}}function depthwiseConv2dNative$2(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,filter:s}=t,{strides:o,pad:i,dilations:l,dimRoundingMode:u}=r;let c=l;null==c&&(c=[1,1]),assert$6(eitherStridesOrDilationsAreOne$1(o,c),()=>`Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ${o} and dilations '${c}'`);const p=computeConv2DInfo$1(a.shape,s.shape,o,c,i,u,!0);let d;return d=env$1().getBool("WEBGL_PACK_DEPTHWISECONV")&&p.strideWidth<=2&&p.outChannels/p.inChannels==1?new DepthwiseConvPacked2DProgram$1(p):new DepthwiseConv2DProgram$1(p),n.runWebGLProgram(d,[a,s],"float32")}const depthwiseConv2dNativeConfig$2={kernelName:DepthwiseConv2dNative$1,backendName:"webgl",kernelFunc:depthwiseConv2dNative$2};class DepthwiseConv2DDerFilterProgram$1{constructor(e){this.variableNames=["x","dy"],this.outputShape=e.filterShape,this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int wR = coords.x;\n        int wC = coords.y;\n        int d1 = coords.z;\n        int dm = coords.w;\n        int d2 = d1 * ${e.outChannels/e.inChannels} + dm;\n\n        float dotProd = 0.0;\n\n        // TO DO: Vec4 over the batch size\n        for (int b = 0; b < ${e.batchSize}; b++) {\n          for (int yR = 0; yR < ${e.outHeight}; yR++) {\n            int xR = wR + yR * ${e.strideHeight} - ${e.padInfo.top};\n\n            if (xR < 0 || xR >= ${e.inHeight}) {\n              continue;\n            }\n\n            for (int yC = 0; yC < ${e.outWidth}; yC++) {\n              int xC = wC + yC * ${e.strideWidth} - ${e.padInfo.left};\n\n              if (xC < 0 || xC >= ${e.inWidth}) {\n                continue;\n              }\n\n              float dyValue = getDy(b, yR, yC, d2);\n              float xValue = getX(b, xR, xC, d1);\n              dotProd += (xValue * dyValue);\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class DepthwiseConv2DDerInputProgram$1{constructor(e){this.variableNames=["dy","W"],this.outputShape=e.inShape;const t=e.filterHeight,n=e.filterWidth,r=e.outChannels/e.inChannels;this.userCode=`\n      const ivec2 pads = ivec2(${t-1-e.padInfo.top}, ${n-1-e.padInfo.left});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d1 = coords[3];\n        ivec2 dyCorner = coords.yz - pads;\n        int dyRCorner = dyCorner.x;\n        int dyCCorner = dyCorner.y;\n\n        float dotProd = 0.0;\n\n        for (int wR = 0; wR < ${t}; wR++) {\n          float dyR = float(dyRCorner + wR) / ${e.strideHeight}.0;\n\n          if (dyR < 0.0 || dyR >= ${e.outHeight}.0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          int wRPerm = ${t} - 1 - wR;\n\n          for (int wC = 0; wC < ${n}; wC++) {\n            float dyC = float(dyCCorner + wC) / ${e.strideWidth}.0;\n\n            if (dyC < 0.0 || dyC >= ${e.outWidth}.0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            int wCPerm = ${n} - 1 - wC;\n\n            // TO DO: Vec4 over the channelMul\n            for (int dm = 0; dm < ${r}; dm++) {\n              int d2 = d1 * ${r} + dm;\n              float xValue = getDy(batch, idyR, idyC, d2);\n              float wValue = getW(wRPerm, wCPerm, d1, dm);\n              dotProd += xValue * wValue;\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}function depthwiseConv2dNativeBackpropFilter$3(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,dy:s}=t,{strides:o,dilations:i,pad:l,dimRoundingMode:u,filterShape:c}=r,p=computeConv2DInfo$1(a.shape,c,o,i,l,u,!0),d=new DepthwiseConv2DDerFilterProgram$1(p);return n.runWebGLProgram(d,[a,s],"float32")}const depthwiseConv2dNativeBackpropFilterConfig$2={kernelName:DepthwiseConv2dNativeBackpropFilter$1,backendName:"webgl",kernelFunc:depthwiseConv2dNativeBackpropFilter$3};function depthwiseConv2dNativeBackpropInput$3(e){const{inputs:t,backend:n,attrs:r}=e,{dy:a,filter:s}=t,{strides:o,dilations:i,pad:l,dimRoundingMode:u,inputShape:c}=r,p=computeConv2DInfo$1(c,s.shape,o,i,l,u,!0),d=new DepthwiseConv2DDerInputProgram$1(p);return n.runWebGLProgram(d,[a,s],"float32")}const depthwiseConv2dNativeBackpropInputConfig$2={kernelName:DepthwiseConv2dNativeBackpropInput$1,backendName:"webgl",kernelFunc:depthwiseConv2dNativeBackpropInput$3};class DiagProgram$1{constructor(e){this.variableNames=["X"],this.outputShape=[e,e],this.userCode="\n      void main() {\n          ivec2 coords = getOutputCoords();\n          float val = coords[0] == coords[1] ? getX(coords[0]) : 0.0;\n          setOutput(val);\n      }\n    "}}function diag$3(e){const{inputs:t,backend:n}=e,{x:r}=t,a=[...r.shape,...r.shape],s=sizeFromShape$1(r.shape),o=reshape$4({inputs:{x:r},backend:n,attrs:{shape:[s]}}),i=new DiagProgram$1(s),l=n.runWebGLProgram(i,[o],o.dtype),u=reshape$4({inputs:{x:l},backend:n,attrs:{shape:a}});return n.disposeIntermediateTensorInfo(o),n.disposeIntermediateTensorInfo(l),u}const diagConfig$2={kernelName:Diag$1,backendName:"webgl",kernelFunc:diag$3};class Dilation2DProgram$1{constructor(e){this.variableNames=["x","W"],this.outputShape=e.outShape;const{inHeight:t,inWidth:n,padInfo:r,strideHeight:a,strideWidth:s,filterHeight:o,filterWidth:i,dilationHeight:l,dilationWidth:u}=e,{top:c,left:p}=r;this.userCode=`\n      const ivec2 strides = ivec2(${a}, ${s});\n      const ivec2 pads = ivec2(${c}, ${p});\n      const float neg_infinity = -3.4e38;\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords.x;\n        int d1 = coords.w;\n        ivec2 outTopLeftCorner =\n            coords.yz * strides - pads;\n        int hBeg = outTopLeftCorner.x;\n        int wBeg = outTopLeftCorner.y;\n\n        float curVal = neg_infinity;\n        for (int h = 0; h < ${o}; h++) {\n          int hIn = hBeg + h * ${l};\n\n          if (hIn >= 0 && hIn < ${t}) {\n            for (int w = 0; w < ${i}; w++) {\n              int wIn = wBeg + w * ${u};\n\n              if (wIn >= 0 && wIn < ${n}) {\n                float xVal = getX(batch, hIn, wIn, d1);\n                float wVal = getW(h, w, d1);\n\n                float val = xVal + wVal;\n                if (val > curVal) {\n                  curVal = val;\n                }\n              }\n            }\n          }\n        }\n\n        float result = curVal;\n        setOutput(result);\n      }\n    `}}function dilation2D$1(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,filter:s}=t,{strides:o,pad:i,dilations:l}=r,u=computeDilation2DInfo$1(a.shape,s.shape,o,i,"NHWC",l);let c;const p=new Dilation2DProgram$1(u);c=n.runWebGLProgram(p,[a,s],"float32");const d=reshape$4({inputs:{x:c},backend:n,attrs:{shape:u.outShape}});return n.disposeIntermediateTensorInfo(c),d}const dilation2DConfig$1={kernelName:Dilation2D$1,backendName:"webgl",kernelFunc:dilation2D$1};function einsum$3(e){const{inputs:t,backend:n,attrs:r}=e,{equation:a}=r,s=t,{allDims:o,summedDims:i,idDims:l}=decodeEinsumEquation$1(a,s.length);checkEinsumDimSizes$1(o.length,l,s);const{path:u,steps:c}=getEinsumComputePath$1(i,l),p=c.length;let d=null,h=o.length;const m=[];for(let e=0;e<p;++e){for(const t of c[e]){const{permutationIndices:e,expandDims:r}=getEinsumPermutation$1(h,l[t]);let a;isIdentityPermutation$1(e)?a=s[t]:(a=transpose$3({inputs:{x:s[t]},backend:n,attrs:{perm:e}}),m.push(a));const o=a.shape.slice();for(let e=0;e<r.length;++e)o.splice(r[e],0,1);arraysEqual$1(a.shape,o)||(a=reshape$4({inputs:{x:a},backend:n,attrs:{shape:o}}),m.push(a)),null===d?d=a:(d=multiply$3({inputs:{a,b:d},backend:n}),m.push(d))}e<p-1&&(u[e]>=0&&(d=sum$4({inputs:{x:d},backend:n,attrs:{axis:u[e]-(o.length-h),keepDims:!1}}),m.push(d)),h--)}for(const e of m)e!==d&&n.disposeIntermediateTensorInfo(e);return d}const einsumConfig$2={kernelName:Einsum$1,backendName:"webgl",kernelFunc:einsum$3},ELU$4="return (x >= 0.0) ? x : (exp(x) - 1.0);",ELU_PACKED$1="\n  vec4 result;\n\n  result.r = (x.r >= 0.0) ? x.r : (exp(x.r) - 1.0);\n  result.g = (x.g >= 0.0) ? x.g : (exp(x.g) - 1.0);\n  result.b = (x.b >= 0.0) ? x.b : (exp(x.b) - 1.0);\n  result.a = (x.a >= 0.0) ? x.a : (exp(x.a) - 1.0);\n\n  return result;\n",elu$5=unaryKernelFunc$2({opSnippet:ELU$4,packedOpSnippet:ELU_PACKED$1}),eluConfig$2={kernelName:Elu$3,backendName:"webgl",kernelFunc:elu$5},ELU_DER$1="return (b >= 1.0) ? a : a * (b + 1.0);",ELU_DER_PACKED$1="\n  vec4 bGTEZero = vec4(greaterThanEqual(b, vec4(0.)));\n  return (bGTEZero * a) + ((vec4(1.0) - bGTEZero) * (a * (b + vec4(1.0))));\n",eluGrad$2=e=>{const{inputs:t,backend:n}=e,{dy:r,y:a}=t,s=env$1().getBool("WEBGL_PACK_BINARY_OPERATIONS")?new BinaryOpPackedProgram$1(ELU_DER_PACKED$1,r.shape,a.shape):new BinaryOpProgram$1(ELU_DER$1,r.shape,a.shape);return n.runWebGLProgram(s,[r,a],r.dtype)},eluGradConfig$3={kernelName:EluGrad$1,backendName:"webgl",kernelFunc:eluGrad$2},PACKED_EQUAL$1="\n  return vec4(equal(a, b));\n",EQUAL$1="return float(a == b);",equal$3=binaryKernelFunc$2({opSnippet:EQUAL$1,packedOpSnippet:PACKED_EQUAL$1,dtype:"bool",cpuKernelImpl:equalImplCPU$1}),equalConfig$2={kernelName:Equal$1,backendName:"webgl",kernelFunc:equal$3},ERF$1=`\n  // Error function is calculated approximately with elementary function.\n  // See "Handbook of Mathematical Functions with Formulas,\n  // Graphs, and Mathematical Tables", Abramowitz and Stegun.\n  float p = ${ERF_P$1};\n  float a1 = ${ERF_A1$1};\n  float a2 = ${ERF_A2$1};\n  float a3 = ${ERF_A3$1};\n  float a4 = ${ERF_A4$1};\n  float a5 = ${ERF_A5$1};\n\n  float sign = sign(x);\n  x = abs(x);\n  float t = 1.0 / (1.0 + p * x);\n  return sign * (1.0 - (((((a5*t + a4)*t) + a3)*t + a2)*t + a1)*t*exp(-x*x));\n`,erf$3=unaryKernelFunc$2({opSnippet:ERF$1}),erfConfig$2={kernelName:Erf$1,backendName:"webgl",kernelFunc:erf$3},EXP$1="return exp(x);",exp$3=unaryKernelFunc$2({opSnippet:EXP$1,packedOpSnippet:EXP$1,cpuKernelImpl:expImplCPU$1}),expConfig$2={kernelName:Exp$1,backendName:"webgl",kernelFunc:exp$3};function expandDims$4(e){const{inputs:t,attrs:n,backend:r}=e,{dim:a}=n,{input:s}=t,o=s.shape.length,i=s.shape.slice();let l=a;return a<0&&(assert$6(-(o+1)<=a,()=>`Axis must be in the interval [${-(o+1)}, ${o}]`),l=o+a+1),i.splice(l,0,1),reshape$4({inputs:{x:s},backend:r,attrs:{shape:i}})}const expandDimsConfig$2={kernelName:ExpandDims$1,backendName:"webgl",kernelFunc:expandDims$4},EXPM1$1="return exp(x) - 1.0;",expm1$3=unaryKernelFunc$2({opSnippet:EXPM1$1,packedOpSnippet:EXPM1$1,cpuKernelImpl:expm1ImplCPU$1}),expm1Config$2={kernelName:Expm1$1,backendName:"webgl",kernelFunc:expm1$3};class FFTProgram$1{constructor(e,t,n){this.variableNames=["real","imag"];const r=t[1];this.outputShape=t;const a=n?`2.0 * ${Math.PI}`:`-2.0 * ${Math.PI}`,s=n?`${r}.0`:"1.0";let o;if("real"===e)o="return real * expR - imag * expI;";else{if("imag"!==e)throw new Error(`FFT component must be either "real" or "imag", got ${e}.`);o="return real * expI + imag * expR;"}this.userCode=`\n      const float exponentMultiplier = ${a};\n\n      float unaryOpComplex(float real, float expR, float imag, float expI) {\n        ${o}\n      }\n\n      float mulMatDFT(int batch, int index) {\n        float indexRatio = float(index) / float(${r});\n        float exponentMultiplierTimesIndexRatio =\n            exponentMultiplier * indexRatio;\n\n        float result = 0.0;\n\n        for (int i = 0; i < ${r}; i++) {\n          // x = (-2|2 * PI / N) * index * i;\n          float x = exponentMultiplierTimesIndexRatio * float(i);\n          float expR = cos(x);\n          float expI = sin(x);\n          float real = getReal(batch, i);\n          float imag = getImag(batch, i);\n\n          result +=\n              unaryOpComplex(real, expR, imag, expI) / ${s};\n        }\n\n        return result;\n      }\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        setOutput(mulMatDFT(coords[0], coords[1]));\n      }\n    `}}function fftImpl$2(e,t,n){const r=n.texData.get(e.dataId),a=sizeFromShape$1(e.shape),s=e.shape[e.shape.length-1],o=reshape$4({inputs:{x:e},backend:n,attrs:{shape:[a/s,s]}}),i=o.shape,l=new FFTProgram$1("real",i,t),u=new FFTProgram$1("imag",i,t),c=[{dataId:r.complexTensorInfos.real.dataId,dtype:r.complexTensorInfos.real.dtype,shape:i},{dataId:r.complexTensorInfos.imag.dataId,dtype:r.complexTensorInfos.imag.dtype,shape:i}],p=n.runWebGLProgram(l,c,"float32"),d=n.runWebGLProgram(u,c,"float32"),h=complex$3({inputs:{real:p,imag:d},backend:n});n.disposeIntermediateTensorInfo(p),n.disposeIntermediateTensorInfo(d);const m=reshape$4({inputs:{x:h},backend:n,attrs:{shape:e.shape}});return n.disposeIntermediateTensorInfo(o),n.disposeIntermediateTensorInfo(h),m}function fft$3(e){const{inputs:t,backend:n}=e,{input:r}=t;return fftImpl$2(r,!1,n)}const fftConfig$2={kernelName:FFT$1,backendName:"webgl",kernelFunc:fft$3};class FillProgram$1{constructor(e,t){this.outputShape=[],this.customUniforms=[{name:"value",type:"float"}],this.variableNames=["x"],this.outputShape=e,this.userCode="\n      void main() {\n        // Input can be obtained from uniform value.\n        setOutput(value);\n      }\n    "}}function fill$3(e){const{backend:t,attrs:n}=e,{shape:r,value:a}=n;let{dtype:s}=n;if(s=s||inferDtype$1(a),"string"===s){const e=getArrayFromDType$1(s,sizeFromShape$1(r));return e.fill(a),t.makeTensorInfo(r,s,e)}{const e=new FillProgram$1(r,a);return t.runWebGLProgram(e,[],s,[[a]])}}const fillConfig$2={kernelName:Fill$1,backendName:"webgl",kernelFunc:fill$3};class FlipLeftRightProgram$1{constructor(e){this.variableNames=["Image"],this.outputShape=[];const t=e[2];this.outputShape=e,this.userCode=`\n        void main() {\n          ivec4 coords = getOutputCoords();\n          int x = coords[2];\n\n          int coordX = ${t} - x - 1;\n          float outputValue;\n          if(coordX >= 0 && coordX < ${t}) {\n            outputValue = getImage(coords[0], coords[1], coordX, coords[3]);\n          } else {\n            outputValue = getImage(coords[0], coords[1], coords[2], coords[3]);\n          }\n          setOutput(outputValue);\n        }\n    `}}const flipLeftRightConfig$2={kernelName:FlipLeftRight$1,backendName:"webgl",kernelFunc:({inputs:e,backend:t})=>{const{image:n}=e,r=t,a=new FlipLeftRightProgram$1(n.shape);return r.runWebGLProgram(a,[n],n.dtype)}},FLOOR$1="return floor(x);",floor$3=unaryKernelFunc$2({opSnippet:FLOOR$1,packedOpSnippet:FLOOR$1,cpuKernelImpl:floorImplCPU$1}),floorConfig$2={kernelName:Floor$1,backendName:"webgl",kernelFunc:floor$3},INT_DIV$1="\n  float s = sign(a) * sign(b);\n  int ia = round(a);\n  int ib = round(b);\n  if (ib != 0) {\n    // Windows (D3D) wants guaranteed non-zero int division at compile-time.\n    return float(idiv(ia, ib, s));\n  } else {\n    return NAN;\n  }\n",INT_DIV_PACKED$1="\n  ivec4 ia = round(a);\n  ivec4 ib = round(b);\n  bvec4 cond = notEqual(ib, ivec4(0));\n  ivec4 result = ivec4(0);\n  vec4 s = sign(a) * sign(b);\n\n  // Windows (D3D) wants guaranteed non-zero int division at compile-time.\n  if (cond[0]) {\n    result[0] = idiv(ia[0], ib[0], s[0]);\n  }\n  if (cond[1]) {\n    result[1] = idiv(ia[1], ib[1], s[1]);\n  }\n  if (cond[2]) {\n    result[2] = idiv(ia[2], ib[2], s[2]);\n  }\n  if (cond[3]) {\n    result[3] = idiv(ia[3], ib[3], s[3]);\n  }\n  return vec4(result);\n",floorDiv$3=binaryKernelFunc$2({opSnippet:INT_DIV$1,packedOpSnippet:INT_DIV_PACKED$1,dtype:"int32"}),floorDivConfig$2={kernelName:FloorDiv$1,backendName:"webgl",kernelFunc:floorDiv$3};class FromPixelsProgram$1{constructor(e){this.variableNames=["A"];const t=getGlslDifferences$1(),[n,r]=e;this.outputShape=e,this.userCode=`\n      void main() {\n        ivec3 coords = getOutputCoords();\n        int texR = coords[0];\n        int texC = coords[1];\n        int depth = coords[2];\n        vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${r}.0, ${n}.0);\n\n        vec4 values = ${t.texture2D}(A, uv);\n        float value;\n        if (depth == 0) {\n          value = values.r;\n        } else if (depth == 1) {\n          value = values.g;\n        } else if (depth == 2) {\n          value = values.b;\n        } else if (depth == 3) {\n          value = values.a;\n        }\n\n        setOutput(floor(value * 255.0 + 0.5));\n      }\n    `}}class FromPixelsPackedProgram$1{constructor(e){this.variableNames=["A"],this.packedInputs=!1,this.packedOutput=!0;const t=getGlslDifferences$1(),[n,r]=e;this.outputShape=e,this.userCode=`\n      void main() {\n        ivec3 coords = getOutputCoords();\n        int texR = coords[0];\n        int texC = coords[1];\n        int depth = coords[2];\n\n        vec4 result = vec4(0.);\n\n        for(int row=0; row<=1; row++) {\n          for(int col=0; col<=1; col++) {\n            texC = coords[1] + row;\n            depth = coords[2] + col;\n\n            vec2 uv = (vec2(texC, texR) + halfCR) /\n                       vec2(${r}.0, ${n}.0);\n            vec4 values = ${t.texture2D}(A, uv);\n            float value;\n            if (depth == 0) {\n              value = values.r;\n            } else if (depth == 1) {\n              value = values.g;\n            } else if (depth == 2) {\n              value = values.b;\n            } else if (depth == 3) {\n              value = values.a;\n            }\n\n            result[row * 2 + col] = floor(value * 255.0 + 0.5);\n          }\n        }\n\n        ${t.output} = result;\n      }\n    `}}const fromPixelsConfig$1={kernelName:FromPixels$1,backendName:"webgl",kernelFunc:fromPixels$2};let fromPixels2DContext$2;function fromPixels$2(e){const{inputs:t,backend:n,attrs:r}=e;let{pixels:a}=t;const{numChannels:s}=r,o="undefined"!=typeof HTMLVideoElement&&a instanceof HTMLVideoElement,i="undefined"!=typeof HTMLImageElement&&a instanceof HTMLImageElement,[l,u]=o?[a.videoWidth,a.videoHeight]:[a.width,a.height],c=[u,l],p=[u,l,s];(i||o)&&(null==fromPixels2DContext$2&&(fromPixels2DContext$2=document.createElement("canvas").getContext("2d")),fromPixels2DContext$2.canvas.width=l,fromPixels2DContext$2.canvas.height=u,fromPixels2DContext$2.drawImage(a,0,0,l,u),a=fromPixels2DContext$2.canvas);const d=n.makeTensorInfo(c,"int32");n.texData.get(d.dataId).usage=TextureUsage$1.PIXELS,n.gpgpu.uploadPixelDataToTexture(n.getTexture(d.dataId),a);const h=env$1().getBool("WEBGL_PACK")?new FromPixelsPackedProgram$1(p):new FromPixelsProgram$1(p),m=n.runWebGLProgram(h,[d],"int32");return n.disposeData(d.dataId),m}function fusedConv2d$1(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,filter:s,bias:o,preluActivationWeights:i}=t,{strides:l,pad:u,dataFormat:c,dilations:p,dimRoundingMode:d,activation:h,leakyreluAlpha:m}=r,f=convertConv2DDataFormat$1(c),g=computeConv2DInfo$1(a.shape,s.shape,l,p,u,d,!1,f);let $;const y=[];if(1!==g.filterHeight||1!==g.filterWidth||1!==g.dilationHeight||1!==g.dilationWidth||1!==g.strideHeight||1!==g.strideWidth||"SAME"!==g.padInfo.type&&"VALID"!==g.padInfo.type)if(env$1().getBool("WEBGL_CONV_IM2COL")&&1===a.shape[0])$=conv2dWithIm2Row$1({x:a,filter:s,convInfo:g,backend:n,bias:o,activation:h,preluActivationWeights:i,leakyreluAlpha:m});else{const e=null!=o,t=null!=i,r="leakyrelu"===h,l=h?mapActivationToShaderProgram$1(h,!1):null,u=new Conv2DProgram$1(g,e,l,t,r),c=[a,s];if(o&&c.push(o),i&&c.push(i),r){const e=n.makeTensorInfo([],"float32",createScalarValue$1(m,"float32"));c.push(e),y.push(e)}$=n.runWebGLProgram(u,c,"float32")}else $=conv2dByMatMul$1({x:a,filter:s,convInfo:g,backend:n,bias:o,activation:h,preluActivationWeights:i,leakyreluAlpha:m});const b=reshape$4({inputs:{x:$},backend:n,attrs:{shape:g.outShape}});return y.push($),y.forEach(e=>n.disposeIntermediateTensorInfo(e)),b}const fusedConv2DConfig$2={kernelName:FusedConv2D$1,backendName:"webgl",kernelFunc:fusedConv2d$1};function fusedDepthwiseConv2D$2(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,filter:s,bias:o,preluActivationWeights:i}=t,{strides:l,pad:u,dilations:c,dimRoundingMode:p,activation:d,leakyreluAlpha:h}=r,m=[];let f=c;null==f&&(f=[1,1]),assert$6(eitherStridesOrDilationsAreOne$1(l,f),()=>`Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ${l} and dilations '${f}'`);const g=computeConv2DInfo$1(a.shape,s.shape,l,f,u,p,!0),$=env$1().getBool("WEBGL_PACK_DEPTHWISECONV")&&g.strideWidth<=2&&g.outChannels/g.inChannels==1,y=d?mapActivationToShaderProgram$1(d,$):null,b=[a,s],x=null!=o,v=null!=i,I="leakyrelu"===d;if(x&&b.push(o),v&&b.push(i),I){const e=n.makeTensorInfo([],"float32",createScalarValue$1(h,"float32"));b.push(e),m.push(e)}let C;C=$?new DepthwiseConvPacked2DProgram$1(g,x,y,v,I):new DepthwiseConv2DProgram$1(g,x,y,v,I);const S=n.runWebGLProgram(C,b,"float32");return m.forEach(e=>n.disposeIntermediateTensorInfo(e)),S}const fusedDepthwiseConv2DConfig$2={kernelName:FusedDepthwiseConv2D$1,backendName:"webgl",kernelFunc:fusedDepthwiseConv2D$2};class GatherNDProgram$1{constructor(e,t,n){this.sliceDim=e,this.strides=t,this.variableNames=["x","indices"],this.outputShape=n;const r=getCoordsDataType$1(t.length),a=getCoordsDataType$1(n.length);this.userCode=`\n        ${r} strides = ${r}(${this.strides});\n         void main() {\n          ${a} coords = getOutputCoords();\n          int flattenIndex = 0;\n          for (int j = 0; j < ${this.sliceDim}; j++) {\n            int index = round(getIndices(coords[0], j));\n            flattenIndex += index * ${this.sliceDim>1?"strides[j]":"strides"};\n          }\n          setOutput(getX(flattenIndex, coords[1]));\n        }\n      `}}function gatherNd$2(e){const{inputs:t,backend:n}=e,{params:r,indices:a}=t,s=a.shape,o=s[s.length-1],i=sizeFromShape$1(r.shape),[l,u,c,p]=prepareAndValidate$1(r,a),d=reshape$4({inputs:{x:a},backend:n,attrs:{shape:[u,o]}}),h=reshape$4({inputs:{x:r},backend:n,attrs:{shape:[sizeFromShape$1(r.shape)/c,c]}});if(n.shouldExecuteOnCPU([r,a])||"string"===r.dtype){const e=n.readSync(a.dataId),t=n.bufferSync(r),s=gatherNdImplCPU$1(e,t,r.dtype,u,o,c,p,r.shape,i);return n.makeTensorInfo(l,r.dtype,s.values)}const m=new GatherNDProgram$1(o,p,[u,c]),f=n.runWebGLProgram(m,[h,d],h.dtype),g=reshape$4({inputs:{x:f},backend:n,attrs:{shape:l}});return n.disposeIntermediateTensorInfo(d),n.disposeIntermediateTensorInfo(h),n.disposeIntermediateTensorInfo(f),g}const gatherNdConfig$2={kernelName:GatherNd$1,backendName:"webgl",kernelFunc:gatherNd$2};class GatherProgram$1{constructor(e,t){this.variableNames=["A","indices"],this.outputShape=t,this.rank=t.length;const n=getCoordsDataType$1(this.rank),r=getSourceCoords$4(e);this.userCode=`\n      void main() {\n        ${n} resRC = getOutputCoords();\n        setOutput(getA(${r}));\n      }\n    `}}function getSourceCoords$4(e,t){const n=["resRC.x","resRC.y","resRC.z","resRC.w"],r=[];for(let t=0;t<e.length;t++)r.push(2===t?"int(getIndices(resRC.x, resRC.z))":`${n[t]}`);return r.join()}function gatherV2$2(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,indices:s}=t,{axis:o,batchDims:i}=r,l=collectGatherOpShapeInfo$1(a,s,parseAxisParam$1(o,a.shape)[0],i),u=sizeFromShape$1(s.shape),c=[],p=reshape$4({inputs:{x:a},backend:n,attrs:{shape:[l.batchSize,l.outerSize,l.dimSize,l.sliceSize]}}),d=reshape$4({inputs:{x:s},backend:n,attrs:{shape:[l.batchSize,u/l.batchSize]}});c.push(p),c.push(d);const h=[l.batchSize,l.outerSize,u/l.batchSize,l.sliceSize];if(n.shouldExecuteOnCPU([a,s])||"string"===a.dtype){const e=n.bufferSync(d),t=n.bufferSync(p),r=gatherV2ImplCPU$1(t,e,h);return c.forEach(e=>n.disposeIntermediateTensorInfo(e)),n.makeTensorInfo(l.outputShape,r.dtype,r.values)}const m=new GatherProgram$1(p.shape,h),f=n.runWebGLProgram(m,[p,d],p.dtype);c.push(f);const g=reshape$4({inputs:{x:f},backend:n,attrs:{shape:l.outputShape}});return c.forEach(e=>n.disposeIntermediateTensorInfo(e)),g}const gatherV2Config$2={kernelName:GatherV2$1,backendName:"webgl",kernelFunc:gatherV2$2},GREATER$1="return float(a > b);",GREATER_PACKED$1="\n  return vec4(greaterThan(a, b));\n",greater$4=binaryKernelFunc$2({opSnippet:GREATER$1,packedOpSnippet:GREATER_PACKED$1,cpuKernelImpl:greaterImplCPU$1,dtype:"bool"}),greaterConfig$2={kernelName:Greater$1,backendName:"webgl",kernelFunc:greater$4},GREATER_EQUAL$1="return float(a >= b);",GREATER_EQUAL_PACKED$1="\n  return vec4(greaterThanEqual(a, b));\n",greaterEqual$3=binaryKernelFunc$2({opSnippet:GREATER_EQUAL$1,packedOpSnippet:GREATER_EQUAL_PACKED$1,dtype:"bool",cpuKernelImpl:greaterEqualImplCPU$1}),greaterEqualConfig$2={kernelName:GreaterEqual$1,backendName:"webgl",kernelFunc:greaterEqual$3};function ifft$3(e){const{inputs:t,backend:n}=e,{input:r}=t;return fftImpl$2(r,!0,n)}const ifftConfig$2={kernelName:IFFT$1,backendName:"webgl",kernelFunc:ifft$3},IS_FINITE$1="return float(!isnan(x) && !isinf(x));",isFinite$4=unaryKernelFunc$2({opSnippet:IS_FINITE$1,dtype:"bool"}),isFiniteConfig$2={kernelName:IsFinite$1,backendName:"webgl",kernelFunc:isFinite$4},IS_INF$1="return float(isinf(x));",isInf$3=unaryKernelFunc$2({opSnippet:IS_INF$1,dtype:"bool"}),isInfConfig$2={kernelName:IsInf$1,backendName:"webgl",kernelFunc:isInf$3},IS_NAN$1="return float(isnan(x));",isNaN$4=unaryKernelFunc$2({opSnippet:IS_NAN$1,dtype:"bool"}),isNaNConfig$2={kernelName:IsNan$1,backendName:"webgl",kernelFunc:isNaN$4},LESS$1="return float(a < b);",LESS_PACKED$1="\n  return vec4(lessThan(a, b));\n",less$4=binaryKernelFunc$2({opSnippet:LESS$1,packedOpSnippet:LESS_PACKED$1,cpuKernelImpl:lessImplCPU$1,dtype:"bool"}),lessConfig$2={kernelName:Less$1,backendName:"webgl",kernelFunc:less$4},LESS_EQUAL$1="return float(a <= b);",LESS_EQUAL_PACKED$1="\n  return vec4(lessThanEqual(a, b));\n",lessEqual$3=binaryKernelFunc$2({opSnippet:LESS_EQUAL$1,packedOpSnippet:LESS_EQUAL_PACKED$1,cpuKernelImpl:lessEqualImplCPU$1,dtype:"bool"}),lessEqualConfig$2={kernelName:LessEqual$1,backendName:"webgl",kernelFunc:lessEqual$3};function linSpace$2(e){const{backend:t,attrs:n}=e,{start:r,stop:a,num:s}=n,o=linSpaceImplCPU$1(r,a,s);return t.makeTensorInfo([o.length],"float32",o)}const linSpaceConfig$2={kernelName:LinSpace$1,backendName:"webgl",kernelFunc:linSpace$2},LOG$1="if (x < 0.0) return NAN;\n  return log(x);",LOG_PACKED$1="\n  vec4 result = log(x);\n  vec4 isNaN = vec4(lessThan(x, vec4(0.0)));\n  result.r = isNaN.r == 1.0 ? NAN : result.r;\n  result.g = isNaN.g == 1.0 ? NAN : result.g;\n  result.b = isNaN.b == 1.0 ? NAN : result.b;\n  result.a = isNaN.a == 1.0 ? NAN : result.a;\n\n  return result;\n",log$4=unaryKernelFunc$2({opSnippet:LOG$1,packedOpSnippet:LOG_PACKED$1,cpuKernelImpl:logImplCPU$1}),logConfig$2={kernelName:Log$1,backendName:"webgl",kernelFunc:log$4},LOG1P$1="return log(1.0 + x);",log1p$3=unaryKernelFunc$2({opSnippet:LOG1P$1}),log1pConfig$2={kernelName:Log1p$1,backendName:"webgl",kernelFunc:log1p$3},LOGICAL_AND$1="return float(a >= 1.0 && b >= 1.0);",LOGICAL_AND_PACKED$1="\n  return vec4(\n    vec4(greaterThanEqual(a, vec4(1.0))) *\n    vec4(greaterThanEqual(b, vec4(1.0))));\n",logicalAnd$3=binaryKernelFunc$2({opSnippet:LOGICAL_AND$1,packedOpSnippet:LOGICAL_AND_PACKED$1,dtype:"bool"}),logicalAndConfig$2={kernelName:LogicalAnd$1,backendName:"webgl",kernelFunc:logicalAnd$3},LOGICAL_NOT$1="return float(!(x >= 1.0));",logicalNot$3=unaryKernelFunc$2({opSnippet:LOGICAL_NOT$1}),logicalNotConfig$2={kernelName:LogicalNot$1,backendName:"webgl",kernelFunc:logicalNot$3},LOGICAL_OR$1="return float(a >= 1.0 || b >= 1.0);",LOGICAL_OR_PACKED$1="\n  return min(\n    vec4(greaterThanEqual(a, vec4(1.0))) +\n    vec4(greaterThanEqual(b, vec4(1.0))),\n    vec4(1.0));\n",logicalOr$3=binaryKernelFunc$2({opSnippet:LOGICAL_OR$1,packedOpSnippet:LOGICAL_OR_PACKED$1,dtype:"bool"}),logicalOrConfig$2={kernelName:LogicalOr$1,backendName:"webgl",kernelFunc:logicalOr$3};class LRNProgram$1{constructor(e,t,n,r,a){this.variableNames=["x"],this.outputShape=[];const s=t,o=e[3]-1;let i;this.outputShape=e;const l=`float(${n}) + float(${r}) * sum`;i=.5===a?`inversesqrt(${l})`:1===a?`1.0/(${l})`:`exp(log(${l}) * float(-${a}));`,this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int r = coords[1];\n        int c = coords[2];\n        int d = coords[3];\n        float x = getX(b, r, c, d);\n        float sum = 0.0;\n        for (int j = -${s}; j <= ${s}; j++) {\n          int idx = d + j;\n          if (idx >= 0 && idx <=  ${o}) {\n            float z = getX(b, r, c, idx);\n            sum += z * z;\n          }\n        }\n        float val = x * ${i};\n        setOutput(val);\n      }\n    `}}class LRNPackedProgram$1{constructor(e,t,n,r,a){this.variableNames=["x"],this.outputShape=[],this.packedInputs=!0,this.packedOutput=!0;const s=t,o=e[3]-1;let i;this.outputShape=e;const l=`float(${n}) + float(${r}) * sum`;i=.5===a?`inversesqrt(${l})`:1===a?`1.0/(${l})`:`exp(log(${l}) * float(-${a}));`,this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords.x;\n        int r = coords.y;\n        int c = coords.z;\n        int d = coords.w;\n\n        bool hasNextCol = d < ${this.outputShape[3]};\n        bool hasNextRow = c < ${this.outputShape[2]};\n\n        vec4 sum = vec4(0.);\n        vec4 xFragAtOutputCoords = getX(b, r, c, d);\n\n        vec4 xAtOutputCoords = vec4(\n          getChannel(xFragAtOutputCoords, vec2(c, d)),\n          hasNextCol ?\n            getChannel(xFragAtOutputCoords, vec2(c, d + 1)) : 0.0,\n          hasNextRow ?\n            getChannel(xFragAtOutputCoords , vec2(c + 1, d)) : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getChannel(xFragAtOutputCoords, vec2(c + 1, d + 1)) : 0.0\n        );\n\n        int firstChannel = d - ${s};\n        vec2 cache = vec2(0.);\n        if(firstChannel >= 0){\n          vec4 firstChannelFrag = getX(b, r, c, firstChannel);\n          cache.x = getChannel(firstChannelFrag, vec2(c, firstChannel));\n            if(hasNextRow){\n              cache.y = getChannel(firstChannelFrag, vec2(c + 1, firstChannel));\n            }\n        }\n\n        ivec2 depth = ivec2(d, d + 1);\n        for (int j = - ${s}; j <= ${s}; j++) {\n          ivec2 idx = depth + j;\n          bvec2 aboveLowerBound = greaterThanEqual(idx, ivec2(0));\n          bvec2 belowUpperBound = lessThanEqual(idx, ivec2(${o}));\n\n          bool depthInRange = aboveLowerBound.x && belowUpperBound.x;\n          bool depthPlusOneInRange = aboveLowerBound.y && belowUpperBound.y;\n\n          if(depthInRange || depthPlusOneInRange){\n            vec4 z = vec4(0.);\n            vec4 xFragAtCurrentDepth;\n            z.xz = cache.xy;\n            if(depthPlusOneInRange && hasNextCol){\n              xFragAtCurrentDepth = idx.y != d ?\n                getX(b, r, c, idx.y) : xFragAtOutputCoords;\n              z.y = getChannel(xFragAtCurrentDepth, vec2(c, idx.y));\n              if(hasNextRow){\n                z.w = getChannel(xFragAtCurrentDepth, vec2(c + 1, idx.y));\n              }\n            }\n            cache.xy = z.yw;\n            sum += z * z;\n          }\n        }\n        vec4 result = xAtOutputCoords * ${i};\n        setOutput(result);\n      }\n    `}}const lrn$1=e=>{const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{depthRadius:s,bias:o,alpha:i,beta:l}=r,u=env$1().getBool("WEBGL_PACK_NORMALIZATION")?new LRNPackedProgram$1(a.shape,s,o,i,l):new LRNProgram$1(a.shape,s,o,i,l);return n.runWebGLProgram(u,[a],a.dtype)},LRNConfig$1={kernelName:LRN$1,backendName:"webgl",kernelFunc:lrn$1};class LRNGradProgram$1{constructor(e,t,n,r,a){this.variableNames=["inputImage","outputImage","dy"],this.outputShape=[],this.outputShape=e,this.depth=e[3],this.depthRadius=t,this.bias=n,this.alpha=r,this.beta=a,this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int r = coords[1];\n        int c = coords[2];\n\n        float result = 0.0;\n        for (int d = 0; d < ${this.depth}; ++d) {\n          int depthBegin = int(max(0.0, float(d - ${t})));\n          int depthEnd = int(min(float(${this.depth}),\n              float(d + ${t} + 1)));\n\n          const int MIN_DEPTH_BEGIN = 0;\n          const int MAX_DEPTH_END = ${this.depth};\n\n          float norm = 0.0;\n          for (int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k) {\n            if (k < depthBegin){\n              continue;\n            }\n            else if (k >= depthBegin && k < depthEnd) {\n              norm += getInputImage(b, r, c, k) * getInputImage(b, r, c, k);\n            }\n            else {\n              break;\n            }\n          }\n\n          norm = float(${r}) * norm + float(${n});\n\n          for(int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k){\n            if (k < depthBegin){\n              continue;\n            }\n            else if (k >= depthBegin && k < depthEnd){\n              float dyi = -2.0 * float(${r})\n                * float(${a})\n                * getInputImage(b ,r ,c, k) * getOutputImage(b, r, c, d)\n                / norm;\n              if (k == d) {\n                dyi += pow(norm, -1.0 * ${a});\n              }\n              if (k == coords[3]) {\n                dyi *= getDy(b, r, c, d);\n                result += dyi;\n              }\n            }\n            else {\n              break;\n            }\n          }\n      }\n      setOutput(result);\n      }\n    `}}const lrnGrad$1=e=>{const{inputs:t,backend:n,attrs:r}=e,{x:a,y:s,dy:o}=t,{depthRadius:i,bias:l,alpha:u,beta:c}=r,p=new LRNGradProgram$1(a.shape,i,l,u,c);return n.runWebGLProgram(p,[a,s,o],a.dtype)},LRNGradConfig$1={kernelName:LRNGrad$1,backendName:"webgl",kernelFunc:lrnGrad$1};function maxImpl$2(e,t,n,r){const a=sizeFromShape$1(t),s=reshape$4({inputs:{x:e},attrs:{shape:[sizeFromShape$1(e.shape)/a,a]},backend:r}),o=reduce$1(s,e.dtype,"max",r),i=reshape$4({inputs:{x:o},attrs:{shape:n},backend:r});return r.disposeIntermediateTensorInfo(s),r.disposeIntermediateTensorInfo(o),i}function max$4(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{reductionIndices:s,keepDims:o}=r,i=a.shape.length,l=parseAxisParam$1(s,a.shape);let u=l;const c=getAxesPermutation$1(u,i),p=null!=c,d=n.shouldExecuteOnCPU([a]);let h=a;if(p){if(d){const e=n.texData.get(h.dataId).values,t=new Array(i);for(let e=0;e<t.length;e++)t[e]=a.shape[c[e]];const r=transposeImplCPU$1(e,a.shape,a.dtype,c,t);h=n.makeTensorInfo(t,a.dtype),n.texData.get(h.dataId).values=r}else h=transposeImpl$2(a,c,n);u=getInnerMostAxes$1(u.length,i)}assertAxesAreInnerMostDims$1("max",u,i);const[m,f]=computeOutAndReduceShapes$1(h.shape,u);let g,$=m;if(o&&($=expandShapeToKeepDim$1(m,l)),d){const e=n.texData.get(h.dataId),t=maxImplCPU$1(e.values,sizeFromShape$1(f),$,a.dtype);g=n.makeTensorInfo($,a.dtype),n.texData.get(g.dataId).values=t}else g=maxImpl$2(h,f,$,n);return p&&n.disposeIntermediateTensorInfo(h),g}const maxConfig$2={kernelName:Max$1,backendName:"webgl",kernelFunc:max$4},MAXIMUM$1=CHECK_NAN_SNIPPET$4+"\n  return max(a, b);\n",MAXIMUM_PACKED$1="\n  vec4 result = vec4(max(a, b));\n  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));\n  "+CHECK_NAN_SNIPPET$3+"\n  return result;\n",maximum$4=binaryKernelFunc$2({opSnippet:MAXIMUM$1,packedOpSnippet:MAXIMUM_PACKED$1,cpuKernelImpl:maximumImplCPU$1}),maximumConfig$2={kernelName:Maximum$3,backendName:"webgl",kernelFunc:maximum$4};function maxPool$3(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t;assertNotComplex$2(a,"maxPool");const{filterSize:s,strides:o,pad:i,dimRoundingMode:l}=r;assert$6(eitherStridesOrDilationsAreOne$1(o,1),()=>`Error in maxPool: Either strides or dilations must be 1. Got strides ${o} and dilations '1'`);const u=computePool2DInfo$1(a.shape,s,o,1,i,l);if(1===u.filterWidth&&1===u.filterHeight&&arraysEqual$1(u.inShape,u.outShape))return identity$3({inputs:{x:a},backend:n});const c=new Pool2DProgram$1(u,"max",!1);return n.runWebGLProgram(c,[a],a.dtype)}const maxPoolConfig$2={kernelName:MaxPool$1,backendName:"webgl",kernelFunc:maxPool$3};function maxPool3d$2(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{filterSize:s,strides:o,pad:i,dataFormat:l,dimRoundingMode:u}=r,c=computePool3DInfo$1(a.shape,s,o,[1,1,1],i,u,l),p=new Pool3DProgram$1(c,"max",!1);return n.runWebGLProgram(p,[a],a.dtype)}const maxPool3DConfig$2={kernelName:MaxPool3D$1,backendName:"webgl",kernelFunc:maxPool3d$2};class MaxPool2DBackpropProgram$1{constructor(e){this.variableNames=["dy","maxPos"],this.outputShape=e.inShape;const t=e.effectiveFilterHeight,n=e.effectiveFilterWidth;this.userCode=`\n      const ivec2 pads = ivec2(${t-1-e.padInfo.top}, ${n-1-e.padInfo.left});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n\n        ivec2 dyRCCorner = coords.yz - pads;\n        int dyRCorner = dyRCCorner.x;\n        int dyCCorner = dyRCCorner.y;\n\n        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ${t};\n          wR += ${e.dilationHeight}) {\n          float dyR = float(dyRCorner + wR) / ${e.strideHeight}.0;\n\n          if (dyR < 0.0 || dyR >= ${e.outHeight}.0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          for (int wC = 0; wC < ${n}; wC++) {\n            float dyC = float(dyCCorner + wC) / ${e.strideWidth}.0;\n\n            if (dyC < 0.0 || dyC >= ${e.outWidth}.0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            float dyValue = getDy(b, idyR, idyC, d);\n            int maxPosValue = ${t*n-1} - int(getMaxPos(b, idyR, idyC, d));\n\n            // Get the current value, check it against the value from the\n            // position matrix.\n            int curPosValue = wR * ${n} + wC;\n            float mask = float(maxPosValue == curPosValue ? 1.0 : 0.0);\n\n            dotProd += dyValue * mask;\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class MaxPool3DBackpropProgram$1{constructor(e){this.variableNames=["dy","maxPos"],this.outputShape=e.inShape;const t=e.effectiveFilterDepth,n=e.effectiveFilterHeight,r=e.effectiveFilterWidth;this.userCode=`\n      const ivec3 pads = ivec3(${t-1-e.padInfo.front}, ${n-1-e.padInfo.top}, ${r-1-e.padInfo.left});\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int ch = coords.u;\n\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\n        int dyDCorner = dyCorner.x;\n        int dyRCorner = dyCorner.y;\n        int dyCCorner = dyCorner.z;\n\n        // Convolve dy(?, ?, ?, ch) with pos mask(:, :, :, d) to get\n        // dx(xD, xR, xC, ch).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n\n        for (int wD = 0; wD < ${t};\n           wD += ${e.dilationDepth}) {\n          float dyD = float(dyDCorner + wD) / ${e.strideDepth}.0;\n\n          if (dyD < 0.0 || dyD >= ${e.outDepth}.0 || fract(dyD) > 0.0) {\n            continue;\n          }\n          int idyD = int(dyD);\n\n          for (int wR = 0; wR < ${n};\n              wR += ${e.dilationHeight}) {\n            float dyR = float(dyRCorner + wR) / ${e.strideHeight}.0;\n\n            if (dyR < 0.0 || dyR >= ${e.outHeight}.0 ||\n                fract(dyR) > 0.0) {\n              continue;\n            }\n            int idyR = int(dyR);\n\n            for (int wC = 0; wC < ${r};\n                wC += ${e.dilationWidth}) {\n              float dyC = float(dyCCorner + wC) / ${e.strideWidth}.0;\n\n              if (dyC < 0.0 || dyC >= ${e.outWidth}.0 ||\n                  fract(dyC) > 0.0) {\n                continue;\n              }\n              int idyC = int(dyC);\n\n              float dyValue = getDy(batch, idyD, idyR, idyC, ch);\n              int maxPosValue = ${t*n*r-1} -\n                  int(getMaxPos(batch, idyD, idyR, idyC, ch));\n\n              // Get the current value, check it against the value from the\n              // position matrix.\n              int curPosValue =\n                  wD * ${n} * ${r} +\n                  wR * ${r} + wC;\n              float mask = float(maxPosValue == curPosValue ? 1.0 : 0.0);\n\n              dotProd += dyValue * mask;\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}function maxPool3DGrad$2(e){const{inputs:t,backend:n,attrs:r}=e,{dy:a,input:s}=t,o=s,{filterSize:i,strides:l,pad:u,dimRoundingMode:c}=r,p=computePool3DInfo$1(o.shape,i,l,[1,1,1],u,c),d=new Pool3DProgram$1(p,"max",!0),h=n.runWebGLProgram(d,[o],o.dtype),m=new MaxPool3DBackpropProgram$1(p),f=n.runWebGLProgram(m,[a,h],o.dtype);return n.disposeIntermediateTensorInfo(h),f}const maxPoolGrad3DConfig$1={kernelName:MaxPool3DGrad$1,backendName:"webgl",kernelFunc:maxPool3DGrad$2};function maxPoolGrad$3(e){const{inputs:t,backend:n,attrs:r}=e,{dy:a,input:s,output:o}=t,i=s;assertNotComplex$2([s,o],"maxPoolGrad");const{filterSize:l,strides:u,pad:c,dimRoundingMode:p}=r,d=computePool2DInfo$1(i.shape,l,u,1,c,p),h=new Pool2DProgram$1(d,"max",!0),m=n.runWebGLProgram(h,[i],i.dtype),f=new MaxPool2DBackpropProgram$1(d),g=n.runWebGLProgram(f,[a,m],i.dtype);return n.disposeIntermediateTensorInfo(m),g}const maxPoolGradConfig$3={kernelName:MaxPoolGrad$1,backendName:"webgl",kernelFunc:maxPoolGrad$3};function maxPoolWithArgmaxImpl$2(e,t,n,r){let a=new Pool2DProgram$1(n,"max",!1);const s=r.runWebGLProgram(a,[e],"float32");return a=new Pool2DProgram$1(n,"max",!0,!0,t),[s,r.runWebGLProgram(a,[e],"float32")]}const maxPoolWithArgmaxConfig$2={kernelName:MaxPoolWithArgmax$1,backendName:"webgl",kernelFunc:({inputs:e,attrs:t,backend:n})=>{const{x:r}=e,{filterSize:a,strides:s,pad:o,includeBatchInIndex:i}=t,l=n;assert$6(4===r.shape.length,()=>`Error in maxPool: input must be rank 4 but got rank ${r.shape.length}.`);const u=[1,1];assert$6(eitherStridesOrDilationsAreOne$1(s,u),()=>`Error in maxPool: Either strides or dilations must be 1. Got strides ${s} and dilations '${u}'`);const c=computePool2DInfo$1(r.shape,a,s,u,o),[p,d]=maxPoolWithArgmaxImpl$2(r,i,c,l);return[p,d]}};function meanImpl$1(e,t,n,r){const a=sizeFromShape$1(t),s=reshape$4({inputs:{x:e},attrs:{shape:[sizeFromShape$1(e.shape)/a,a]},backend:r}),o=reduce$1(s,"float32","mean",r),i=reshape$4({inputs:{x:o},attrs:{shape:n},backend:r});return r.disposeIntermediateTensorInfo(s),r.disposeIntermediateTensorInfo(o),i}const meanConfig$2={kernelName:Mean$1,backendName:"webgl",kernelFunc:({inputs:e,attrs:t,backend:n})=>{const{x:r}=e,{keepDims:a,axis:s}=t,o=n,i=r.shape.length,l=parseAxisParam$1(s,r.shape);let u=l;const c=getAxesPermutation$1(u,i),p=null!=c,d=o.shouldExecuteOnCPU([r]),h=[];let m=r;if(p){if(d){const e=o.texData.get(m.dataId).values,t=new Array(i);for(let e=0;e<t.length;e++)t[e]=r.shape[c[e]];const n=transposeImplCPU$1(e,r.shape,r.dtype,c,t);m=o.makeTensorInfo(t,r.dtype),o.texData.get(m.dataId).values=n}else m=transposeImpl$2(r,c,o);h.push(m),u=getInnerMostAxes$1(u.length,i)}assertAxesAreInnerMostDims$1("sum",u,i);const[f,g]=computeOutAndReduceShapes$1(m.shape,u);let $=f;a&&($=expandShapeToKeepDim$1(f,l));const y=meanImpl$1(m,g,$,o);for(const e of h)o.disposeIntermediateTensorInfo(e);return y}};function min$4(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{axis:s,keepDims:o}=r,i=a.shape.length,l=parseAxisParam$1(s,a.shape);let u=l;const c=getAxesPermutation$1(u,i);let p=a;null!=c&&(p=transpose$3({inputs:{x:a},backend:n,attrs:{perm:c}}),u=getInnerMostAxes$1(u.length,a.shape.length)),assertAxesAreInnerMostDims$1("min",u,i);const[d,h]=computeOutAndReduceShapes$1(p.shape,u),m=reshape$4({inputs:{x:p},backend:n,attrs:{shape:[-1,sizeFromShape$1(h)]}}),f=reduce$1(m,m.dtype,"min",n);let g;return g=reshape$4(o?{inputs:{x:f},backend:n,attrs:{shape:expandShapeToKeepDim$1(d,l)}}:{inputs:{x:f},backend:n,attrs:{shape:d}}),n.disposeIntermediateTensorInfo(m),n.disposeIntermediateTensorInfo(f),null!=c&&n.disposeIntermediateTensorInfo(p),g}const minConfig$2={kernelName:Min$1,backendName:"webgl",kernelFunc:min$4},MINIMUM$1=CHECK_NAN_SNIPPET$4+"\n  return min(a, b);\n",MINIMUM_PACKED$1="\n  vec4 result = vec4(min(a, b));\n  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));\n  "+CHECK_NAN_SNIPPET$3+"\n  return result;\n",minimum$4=binaryKernelFunc$2({opSnippet:MINIMUM$1,packedOpSnippet:MINIMUM_PACKED$1,cpuKernelImpl:minimumImplCPU$1}),minimumConfig$2={kernelName:Minimum$3,backendName:"webgl",kernelFunc:minimum$4};class MirrorPadProgram$1{constructor(e,t,n){this.variableNames=["x"],this.outputShape=t.map((t,n)=>t[0]+e[n]+t[1]);const r=e.length,a=getCoordsDataType$1(r),s=t.map(e=>e[0]).join(","),o=t.map((t,n)=>t[0]+e[n]).join(","),i=["coords[0]","coords[1]","coords[2]","coords[3]"].slice(0,r),l="reflect"===n?0:1;this.userCode=1!==r?`\n      ${a} start = ${a}(${s});\n      ${a} end = ${a}(${o});\n\n      void main() {\n        ${a} outC = getOutputCoords();\n        for (int i = 0; i < ${r}; i++) {\n          if (outC[i] < start[i]) {\n            outC[i] = start[i] * 2 - outC[i] - ${l};\n          } else if(outC[i] >= end[i]) {\n            outC[i] = (end[i] - 1) * 2 - outC[i] + ${l};\n          }\n        }\n        ${a} coords = outC - start;\n        setOutput(getX(${i}));\n      }\n    `:`\n        int start = ${s};\n        int end = ${o};\n\n        void main() {\n          int outC = getOutputCoords();\n          if (outC < start) {\n            outC = start * 2 - outC - ${l};\n          } else if(outC >= end) {\n            outC = (end - 1) * 2 - outC + ${l};\n          }\n          setOutput(getX(outC - start));\n        }\n      `}}class MirrorPadPackedProgram$1{constructor(e,t,n){this.variableNames=["x"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=t.map((t,n)=>t[0]+e[n]+t[1]);const r=e.length,a=getCoordsDataType$1(r),s=t.map(e=>e[0]).join(","),o=t.map((t,n)=>t[0]+e[n]).join(","),i=getChannels$1("rc",r),l=getChannels$1("source",r),u=`${i[r-1]} < ${this.outputShape[r-1]}`,c=1===r?"source":`vec2(${l.slice(-2).join()})`,p="reflect"===n?0:1;let d="";if(1===r){const e=`\n        ${a} source = rc;\n        if (source < start) {\n          source = start * 2 - source - ${p};\n        } else if (source >= end) {\n          source = (end - 1) * 2 - source + ${p};\n        }\n        source -= start;\n      `;d=`\n        ${a} rc = outputLoc;\n        ${e}\n        result[0] = getChannel(getX(${l.join()}), ${c});\n        ${i[r-1]} += 1;\n        if(${u}) {\n          ${e}\n          result[1] = getChannel(getX(${l.join()}), ${c});\n        }\n      `}else{const e=`\n        ${a} source = rc;\n        ${a} lt = ${a}(lessThan(source, start));\n        ${a} gte = ${a}(greaterThanEqual(source, end));\n        ${a} orig = 1 - (lt + gte);\n        source = orig * source +\n                lt * (start * 2 - source - ${p}) +\n                gte * ((end - 1) * 2 - source + ${p});\n        source -= start;\n      `;d=`\n        ${a} rc = outputLoc;\n        ${e}\n        result[0] = getChannel(getX(${l.join()}), ${c});\n        ${i[r-1]} += 1;\n        if(${u}) {\n          ${e}\n          result[1] = getChannel(getX(${l.join()}), ${c});\n        }\n        rc = outputLoc;\n        ${i[r-2]} += 1;\n        if(${i[r-2]} < ${this.outputShape[r-2]}) {\n          ${e}\n          result[2] = getChannel(getX(${l.join()}), ${c});\n          ${i[r-1]} += 1;\n          if(${u}) {\n            ${e}\n            result[3] = getChannel(getX(${l.join()}), ${c});\n          }\n        }\n      `}this.userCode=`\n      const ${a} start = ${a}(${s});\n      const ${a} end = ${a}(${o});\n\n      void main() {\n        ${a} outputLoc = getOutputCoords();\n        vec4 result = vec4(0.);\n        ${d}\n        setOutput(result);\n      }\n    `}}const mirrorPadKernelFunc$1=({inputs:e,backend:t,attrs:n})=>{const{x:r}=e,{paddings:a,mode:s}=n,o=env$1().getBool("WEBGL_PACK_ARRAY_OPERATIONS")?new MirrorPadPackedProgram$1(r.shape,a,s):new MirrorPadProgram$1(r.shape,a,s);return t.runWebGLProgram(o,[r],r.dtype)},mirrorPadConfig$2={kernelName:MirrorPad$1,backendName:"webgl",kernelFunc:mirrorPadKernelFunc$1},MOD$1="if (b == 0.0) return NAN;\n  return mod(a, b);",MOD_PACKED$1="\n  vec4 result = mod(a, b);\n  vec4 isNaN = vec4(equal(b, vec4(0.0)));\n  "+CHECK_NAN_SNIPPET$3+"\n  return result;\n",mod$3=binaryKernelFunc$2({opSnippet:MOD$1,packedOpSnippet:MOD_PACKED$1}),modConfig$2={kernelName:Mod$1,backendName:"webgl",kernelFunc:mod$3};class MultinomialProgram$1{constructor(e,t,n){this.variableNames=["probs"],this.customUniforms=[{name:"seed",type:"float"}],this.outputShape=[e,n],this.userCode=`\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n\n        float r = random(seed);\n        float cdf = 0.0;\n\n        for (int i = 0; i < ${t-1}; i++) {\n          cdf += getProbs(batch, i);\n\n          if (r < cdf) {\n            setOutput(float(i));\n            return;\n          }\n        }\n\n        // If no other event happened, last event happened.\n        setOutput(float(${t-1}));\n      }\n    `}}const DIV$1="\nif (a == b) {\n  return 1.0;\n};\nreturn a / b;",DIV_PACKED$1="\n  // vec4 one = vec4(equal(a, b));\n  // return one + (vec4(1.0) - one) * a / b;\n  vec4 result = a / b;\n  if(a.x == b.x) {\n    result.x = 1.;\n  }\n  if(a.y == b.y) {\n    result.y = 1.;\n  }\n  if(a.z == b.z) {\n    result.z = 1.;\n  }\n  if(a.w == b.w) {\n    result.w = 1.;\n  }\n\n  return result;\n",realDiv$1=binaryKernelFunc$2({opSnippet:DIV$1,packedOpSnippet:DIV_PACKED$1,checkOutOfBounds:!0}),realDivConfig$2={kernelName:RealDiv$1,backendName:"webgl",kernelFunc:realDiv$1},SUB$1="return a - b;",sub$3=binaryKernelFunc$2({opSnippet:SUB$1,packedOpSnippet:SUB$1,supportsComplex:!0,cpuKernelImpl:subImplCPU$1}),subConfig$2={kernelName:Sub$1,backendName:"webgl",kernelFunc:sub$3};function softmax$4(e){const{inputs:t,backend:n,attrs:r}=e,{logits:a}=t,{dim:s}=r,o=parseAxisParam$1([s],a.shape),i=max$4({inputs:{x:a},backend:n,attrs:{reductionIndices:o,keepDims:!1}}),l=expandShapeToKeepDim$1(i.shape,o),u=reshape$4({inputs:{x:i},backend:n,attrs:{shape:l}}),c=sub$3({inputs:{a,b:u},backend:n}),p=exp$3({inputs:{x:c},backend:n}),d=sum$4({inputs:{x:p},backend:n,attrs:{axis:o,keepDims:!1}}),h=reshape$4({inputs:{x:d},backend:n,attrs:{shape:l}}),m=realDiv$1({inputs:{a:p,b:h},backend:n});return n.disposeIntermediateTensorInfo(i),n.disposeIntermediateTensorInfo(u),n.disposeIntermediateTensorInfo(c),n.disposeIntermediateTensorInfo(p),n.disposeIntermediateTensorInfo(d),n.disposeIntermediateTensorInfo(h),m}const softmaxConfig$2={kernelName:Softmax$5,backendName:"webgl",kernelFunc:softmax$4};function multinomial$3(e){const{inputs:t,backend:n,attrs:r}=e,{logits:a}=t,{numSamples:s,seed:o,normalized:i}=r,l=i?a:softmax$4({inputs:{logits:a},backend:n,attrs:{dim:a.shape.length-1}}),u=new MultinomialProgram$1(l.shape[0],l.shape[1],s),c=n.runWebGLProgram(u,[l],"int32",[[o]]);return i||n.disposeIntermediateTensorInfo(l),c}const multinomialConfig$2={kernelName:Multinomial$1,backendName:"webgl",kernelFunc:multinomial$3},NEG$1="return -x;";function neg$3(e){const{inputs:t,backend:n}=e,{x:r}=t;if(n.shouldExecuteOnCPU([r])){const e=n.texData.get(r.dataId),[t,a]=negImplCPU$1(e.values,r.shape,r.dtype);return n.makeTensorInfo(a,r.dtype,t)}let a;return a=env$1().getBool("WEBGL_PACK_UNARY_OPERATIONS")?new UnaryOpPackedProgram$1(r.shape,NEG$1):new UnaryOpProgram$1(r.shape,NEG$1),n.runWebGLProgram(a,[r],r.dtype)}const negConfig$2={kernelName:Neg$1,backendName:"webgl",kernelFunc:neg$3},nonMaxSuppressionV3Impl$3=nonMaxSuppressionV3Impl$5;function nonMaxSuppressionV3$2(e){warn$1("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");const{inputs:t,backend:n,attrs:r}=e,{boxes:a,scores:s}=t,{maxOutputSize:o,iouThreshold:i,scoreThreshold:l}=r,u=n.readSync(a.dataId),c=n.readSync(s.dataId),{selectedIndices:p}=nonMaxSuppressionV3Impl$3(u,c,o,i,l);return n.makeTensorInfo([p.length],"int32",new Int32Array(p))}const nonMaxSuppressionV3Config$2={kernelName:NonMaxSuppressionV3$1,backendName:"webgl",kernelFunc:nonMaxSuppressionV3$2},nonMaxSuppressionV4Impl$3=nonMaxSuppressionV4Impl$5;function nonMaxSuppressionV4$2(e){warn$1("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");const{inputs:t,backend:n,attrs:r}=e,{boxes:a,scores:s}=t,{maxOutputSize:o,iouThreshold:i,scoreThreshold:l,padToMaxOutputSize:u}=r,c=n.readSync(a.dataId),p=n.readSync(s.dataId),{selectedIndices:d,validOutputs:h}=nonMaxSuppressionV4Impl$3(c,p,o,i,l,u);return[n.makeTensorInfo([d.length],"int32",new Int32Array(d)),n.makeTensorInfo([],"int32",new Int32Array([h]))]}const nonMaxSuppressionV4Config$2={kernelName:NonMaxSuppressionV4$1,backendName:"webgl",kernelFunc:nonMaxSuppressionV4$2},nonMaxSuppressionV5Impl$3=nonMaxSuppressionV5Impl$5;function nonMaxSuppressionV5$2(e){warn$1("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");const{inputs:t,backend:n,attrs:r}=e,{boxes:a,scores:s}=t,{maxOutputSize:o,iouThreshold:i,scoreThreshold:l,softNmsSigma:u}=r,c=n.readSync(a.dataId),p=n.readSync(s.dataId),d=o,h=i,m=l,f=u,{selectedIndices:g,selectedScores:$}=nonMaxSuppressionV5Impl$3(c,p,d,h,m,f);return[n.makeTensorInfo([g.length],"int32",new Int32Array(g)),n.makeTensorInfo([$.length],"float32",new Float32Array($))]}const nonMaxSuppressionV5Config$2={kernelName:NonMaxSuppressionV5$1,backendName:"webgl",kernelFunc:nonMaxSuppressionV5$2};class OneHotProgram$1{constructor(e,t,n,r){this.variableNames=["indices"],this.outputShape=[e,t],this.userCode=`\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int index = round(getIndices(coords.x));\n        setOutput(mix(float(${r}), float(${n}),\n                      float(index == coords.y)));\n      }\n    `}}const oneHot$3=e=>{const{inputs:t,backend:n,attrs:r}=e,{indices:a}=t,{depth:s,onValue:o,offValue:i}=r,l=sizeFromShape$1(a.shape),u=new OneHotProgram$1(l,s,o,i),c=reshape$4({inputs:{x:a},backend:n,attrs:{shape:[l]}}),p=n.runWebGLProgram(u,[c],a.dtype);n.disposeIntermediateTensorInfo(c);const d=reshape$4({inputs:{x:p},backend:n,attrs:{shape:[...a.shape,s]}});return n.disposeIntermediateTensorInfo(p),d},oneHotConfig$2={kernelName:OneHot$1,backendName:"webgl",kernelFunc:oneHot$3};function zerosLike$3(e){const{inputs:t,backend:n}=e,{x:r}=t;if("complex64"===r.dtype){const e=real$3({inputs:{input:r},backend:n}),t=zerosLike$3({inputs:{x:e},backend:n}),a=imag$3({inputs:{input:r},backend:n}),s=zerosLike$3({inputs:{x:a},backend:n}),o=complex$3({inputs:{real:t,imag:s},backend:n});return n.disposeIntermediateTensorInfo(e),n.disposeIntermediateTensorInfo(t),n.disposeIntermediateTensorInfo(a),n.disposeIntermediateTensorInfo(s),o}return fill$3({attrs:{shape:r.shape,dtype:r.dtype,value:"string"===r.dtype?"":0},backend:n})}const zerosLikeConfig$2={kernelName:ZerosLike$1,backendName:"webgl",kernelFunc:zerosLike$3};function onesLike$3(e){const{inputs:t,backend:n}=e,{x:r}=t;if("string"===r.dtype)throw new Error("onesLike is not supported under string dtype");if("complex64"===r.dtype){const e=real$3({inputs:{input:r},backend:n}),t=onesLike$3({inputs:{x:e},backend:n}),a=imag$3({inputs:{input:r},backend:n}),s=zerosLike$3({inputs:{x:a},backend:n}),o=complex$3({inputs:{real:t,imag:s},backend:n});return n.disposeIntermediateTensorInfo(e),n.disposeIntermediateTensorInfo(t),n.disposeIntermediateTensorInfo(a),n.disposeIntermediateTensorInfo(s),o}return fill$3({attrs:{shape:r.shape,dtype:r.dtype,value:1},backend:n})}const onesLikeConfig$2={kernelName:OnesLike$1,backendName:"webgl",kernelFunc:onesLike$3};function pack$2(e){const{inputs:t,backend:n,attrs:r}=e,{axis:a}=r;if(1===t.length)return expandDims$4({inputs:{input:t[0]},backend:n,attrs:{dim:a}});const s=t[0].shape,o=t[0].dtype;t.forEach(e=>{assertShapesMatch$1(s,e.shape,"All tensors passed to stack must have matching shapes"),assert$6(o===e.dtype,()=>"All tensors passed to stack must have matching dtypes")});const i=[],l=concat$3({inputs:t.map(e=>{const t=expandDims$4({inputs:{input:e},backend:n,attrs:{dim:a}});return i.push(t),t}),backend:n,attrs:{axis:a}});return i.forEach(e=>n.disposeIntermediateTensorInfo(e)),l}const packConfig$2={kernelName:Pack$1,backendName:"webgl",kernelFunc:pack$2};class PadProgram$1{constructor(e,t,n){this.variableNames=["x"],this.customUniforms=[{name:"value",type:"float"}],this.outputShape=t.map((t,n)=>t[0]+e[n]+t[1]);const r=e.length,a=getCoordsDataType$1(r),s=t.map(e=>e[0]).join(","),o=t.map((t,n)=>t[0]+e[n]).join(","),i=["coords[0]","coords[1]","coords[2]","coords[3]"].slice(0,r);this.userCode=1!==r?`\n      ${a} start = ${a}(${s});\n      ${a} end = ${a}(${o});\n\n      void main() {\n        ${a} outC = getOutputCoords();\n        if (any(lessThan(outC, start)) || any(greaterThanEqual(outC, end))) {\n          setOutput(value);\n        } else {\n          ${a} coords = outC - start;\n          setOutput(getX(${i}));\n        }\n      }\n    `:`\n        int start = ${s};\n        int end = ${o};\n\n        void main() {\n          int outC = getOutputCoords();\n          if (outC < start || outC >= end) {\n            setOutput(value);\n          } else {\n            setOutput(getX(outC - start));\n          }\n        }\n      `}}class PadPackedProgram$1{constructor(e,t,n){this.variableNames=["x"],this.packedInputs=!0,this.packedOutput=!0,this.customUniforms=[{name:"value",type:"float"}],this.outputShape=t.map((t,n)=>t[0]+e[n]+t[1]);const r=e.length,a=getCoordsDataType$1(r),s=t.map(e=>e[0]).join(","),o=t.map((t,n)=>t[0]+e[n]).join(","),i=getChannels$1("rc",r),l=getChannels$1("source",r),u=`${i[r-1]} < ${this.outputShape[r-1]}`,c=1===r?"source":`vec2(${l.slice(-2).join()})`,p=[`${a} rc = outputLoc;`,`${i[r-1]} += 1;\n       if(${u}) {\n      `,1===r?"":`}\n       rc = outputLoc;\n       ${i[r-2]} += 1;\n       if(${i[r-2]} < ${this.outputShape[r-2]}) {`,1===r?"":`  ${i[r-1]} += 1;\n         if(${u}) {`],d=1===r?"rc < start || rc >= end":"any(lessThan(rc, start)) || any(greaterThanEqual(rc, end))";let h="";for(let e=0,t=1===r?2:4;e<t;e++)h+=`\n        ${p[e]}\n        if (${d}) {\n          result[${e}] = float(value);\n        } else {\n          ${a} source = rc - start;\n          result[${e}] = getChannel(getX(${l.join()}), ${c});\n        }\n      `;h+=1===r?"} ":"}}",this.userCode=`\n      const ${a} start = ${a}(${s});\n      const ${a} end = ${a}(${o});\n\n      void main() {\n        ${a} outputLoc = getOutputCoords();\n        vec4 result = vec4(0.);\n        ${h}\n        setOutput(result);\n      }\n    `}}const padV2$2=e=>{const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{paddings:s,constantValue:o}=r,i=env$1().getBool("WEBGL_PACK_ARRAY_OPERATIONS")?new PadPackedProgram$1(a.shape,s,o):new PadProgram$1(a.shape,s,o);return n.runWebGLProgram(i,[a],a.dtype,[[o]])},padV2Config$2={kernelName:PadV2$1,backendName:"webgl",kernelFunc:padV2$2},POW$1="\n  if(a < 0.0 && floor(b) < b){\n    return NAN;\n  }\n  if (b == 0.0) {\n    return 1.0;\n  }\n  return (round(mod(b, 2.0)) != 1) ?\n      pow(abs(a), b) : sign(a) * pow(abs(a), b);\n",POW_PACKED$1="\n  // isModRound1 has 1 for components with round(mod(b, 2.0)) == 1, 0 otherwise.\n  vec4 isModRound1 = vec4(equal(round(mod(b, 2.0)), ivec4(1)));\n  vec4 multiplier = sign(a) * isModRound1 + (vec4(1.0) - isModRound1);\n  vec4 result = multiplier * pow(abs(a), b);\n\n  // Ensure that a^0 = 1, including 0^0 = 1 as this correspond to TF and JS\n  bvec4 isExpZero = equal(b, vec4(0.0));\n  result.r = isExpZero.r ? 1.0 : result.r;\n  result.g = isExpZero.g ? 1.0 : result.g;\n  result.b = isExpZero.b ? 1.0 : result.b;\n  result.a = isExpZero.a ? 1.0 : result.a;\n\n  vec4 isNaN = vec4(lessThan(a, vec4(0.0))) * vec4(lessThan(floor(b), b));\n  "+CHECK_NAN_SNIPPET$3+"\n  return result;\n",pow$3=binaryKernelFunc$2({opSnippet:POW$1,packedOpSnippet:POW_PACKED$1}),powConfig$2={kernelName:Pow$1,backendName:"webgl",kernelFunc:pow$3};function prod$3(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{axis:s,keepDims:o}=r,i=a.shape.length,l=[],u=parseAxisParam$1(s,a.shape);let c=u;const p=getAxesPermutation$1(c,i);let d,h=a;if(null!=p&&(h=transpose$3({inputs:{x:a},backend:n,attrs:{perm:p}}),c=getInnerMostAxes$1(c.length,i),l.push(h)),assertAxesAreInnerMostDims$1("prod",c,i),n.shouldExecuteOnCPU([h])){const e=n.texData.get(h.dataId).values,{outVals:t,outShape:r,outDtype:a}=prodImplCPU$1(h.shape,h.dtype,e,c);d=n.makeTensorInfo(r,a,t)}else{const[e,t]=computeOutAndReduceShapes$1(h.shape,c),r=sizeFromShape$1(t),s=reshape$4({inputs:{x:h},backend:n,attrs:{shape:[-1,r]}}),o=reduce$1(s,sumOutType$1(a.dtype),"prod",n);d=reshape$4({inputs:{x:o},backend:n,attrs:{shape:e}}),l.push(s),l.push(o)}if(o){l.push(d);const e=expandShapeToKeepDim$1(d.shape,u);d=reshape$4({inputs:{x:d},backend:n,attrs:{shape:e}})}return l.forEach(e=>n.disposeIntermediateTensorInfo(e)),d}const prodConfig$2={kernelName:Prod$1,backendName:"webgl",kernelFunc:prod$3},range$5=e=>{const{backend:t,attrs:n}=e,{start:r,stop:a,step:s,dtype:o}=n,i=rangeImplCPU$1(r,a,s,o);return t.makeTensorInfo([i.length],o,i)},rangeConfig$2={kernelName:Range$1,backendName:"webgl",kernelFunc:range$5},RECIPROCAL$1="return 1.0 / x;",reciprocal$3=unaryKernelFunc$2({opSnippet:RECIPROCAL$1}),reciprocalConfig$2={kernelName:Reciprocal$1,backendName:"webgl",kernelFunc:reciprocal$3},RELU$3=CHECK_NAN_SNIPPET$5+"\n  return (x < 0.0) ? 0.0 : x;\n",RELU_PACKED$1="\n  vec4 result = x * vec4(greaterThanEqual(x, vec4(0.0)));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n",relu$4=unaryKernelFunc$2({opSnippet:RELU$3,packedOpSnippet:RELU_PACKED$1}),reluConfig$2={kernelName:Relu$3,backendName:"webgl",kernelFunc:relu$4},RELU6$3=CHECK_NAN_SNIPPET$5+"\n  return (x < 0.0) ? 0.0 : min(6.0, x);\n",RELU6_PACKED$1="\n  vec4 result = min(x, vec4(6.)) * vec4(greaterThanEqual(x, vec4(0.0)));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n",relu6$3=unaryKernelFunc$2({opSnippet:RELU6$3,packedOpSnippet:RELU6_PACKED$1}),relu6Config$2={kernelName:Relu6$3,backendName:"webgl",kernelFunc:relu6$3};class ResizeBilinearProgram$1{constructor(e,t,n,r,a){this.variableNames=["A"],this.outputShape=[];const[s,o,i,l]=e;this.outputShape=[s,t,n,l];const u=[r&&t>1?o-1:o,r&&n>1?i-1:i],c=[r&&t>1?t-1:t,r&&n>1?n-1:n];let p;p=a?"(vec2(yRC) + vec2(0.5)) * effectiveInputOverOutputRatioRC - vec2(0.5)":"vec2(yRC) * effectiveInputOverOutputRatioRC",this.userCode=`\n      const vec2 effectiveInputOverOutputRatioRC = vec2(\n          ${u[0]/c[0]},\n          ${u[1]/c[1]});\n      const vec2 inputShapeRC = vec2(${o}.0, ${i}.0);\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        ivec2 yRC = coords.yz;\n\n        // Fractional source index.\n        vec2 sourceFracIndexRC = ${p};\n\n        // Compute the four integer indices.\n        ivec2 sourceFloorRC = ivec2(max(sourceFracIndexRC, vec2(0.0)));\n        ivec2 sourceCeilRC = ivec2(\n          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));\n\n        float topLeft = getA(b, sourceFloorRC.x, sourceFloorRC.y, d);\n        float bottomLeft = getA(b, sourceCeilRC.x, sourceFloorRC.y, d);\n        float topRight = getA(b, sourceFloorRC.x, sourceCeilRC.y, d);\n        float bottomRight = getA(b, sourceCeilRC.x, sourceCeilRC.y, d);\n\n        vec2 fracRC = sourceFracIndexRC - vec2(sourceFloorRC);\n\n        float top = topLeft + (topRight - topLeft) * fracRC.y;\n        float bottom = bottomLeft + (bottomRight - bottomLeft) * fracRC.y;\n        float newValue = top + (bottom - top) * fracRC.x;\n\n        setOutput(newValue);\n      }\n    `}}class ResizeBilinearPackedProgram$1{constructor(e,t,n,r,a){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=[];const[s,o,i,l]=e;this.outputShape=[s,t,n,l];const u=[r&&t>1?o-1:o,r&&n>1?i-1:i],c=[r&&t>1?t-1:t,r&&n>1?n-1:n];let p;p=a?"(vec3(yRC) + vec3(0.5)) * effectiveInputOverOutputRatioRC - vec3(0.5)":"vec3(yRC) * effectiveInputOverOutputRatioRC",this.userCode=`\n      const vec3 effectiveInputOverOutputRatioRC = vec3(\n          ${u[0]/c[0]},\n          ${u[1]/c[1]},\n          ${u[1]/c[1]});\n      const vec3 inputShapeRC = vec3(${o}.0, ${i}.0,\n                                     ${i}.0);\n\n      float getAValue(int b, int r, int c, int d) {\n        return getChannel(getA(b, r, c, d), vec2(c, d));\n      }\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        // Calculate values for next column in yRC.z.\n        ivec3 yRC = coords.yzz + ivec3(0, 0, 1);\n\n        // Fractional source index.\n        vec3 sourceFracIndexRC = ${p};\n\n        // Compute the four integer indices.\n        ivec3 sourceFloorRC = ivec3(max(sourceFracIndexRC, vec3(0.0)));\n        ivec3 sourceCeilRC = ivec3(\n          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));\n\n        // Should we calculate next column and row elements in 2x2 packed cell.\n        bool hasNextCol = d < ${l-1};\n        bool hasNextRow = coords.z < ${n-1};\n\n        // In parallel, construct four corners for all four components in\n        // packed 2x2 cell.\n        vec4 topLeft = vec4(\n          getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d),\n          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d + 1) : 0.0);\n\n        vec4 bottomLeft = vec4(\n          getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d),\n          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d + 1) : 0.0);\n\n        vec4 topRight = vec4(\n          getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d),\n          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d + 1) : 0.0);\n\n        vec4 bottomRight = vec4(\n          getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d),\n          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d + 1) : 0.0);\n\n        vec3 fracRC = sourceFracIndexRC - vec3(sourceFloorRC);\n\n        vec4 top = mix(topLeft, topRight, fracRC.yyzz);\n        vec4 bottom = mix(bottomLeft, bottomRight, fracRC.yyzz);\n        vec4 newValue = mix(top, bottom, fracRC.x);\n\n        setOutput(newValue);\n      }\n    `}}function resizeBilinear$3(e){const{inputs:t,backend:n,attrs:r}=e,{images:a}=t,{alignCorners:s,halfPixelCenters:o,size:i}=r,[l,u]=i,c=env$1().getBool("WEBGL_PACK_IMAGE_OPERATIONS")?new ResizeBilinearPackedProgram$1(a.shape,l,u,s,o):new ResizeBilinearProgram$1(a.shape,l,u,s,o);return n.runWebGLProgram(c,[a],"float32")}const resizeBilinearConfig$2={kernelName:ResizeBilinear$1,backendName:"webgl",kernelFunc:resizeBilinear$3};class ResizeBilinearBackpropProgram$1{constructor(e,t,n){this.variableNames=["dy"],this.outputShape=[],this.outputShape=t;const[,r,a]=t,[,s,o]=e,i=[n&&s>1?r-1:r,n&&o>1?a-1:a],l=[n&&s>1?s-1:s,n&&o>1?o-1:o],u=i[0]/l[0],c=i[1]/l[1],p=1/u,d=1/c,h=2*Math.ceil(p)+2,m=2*Math.ceil(d)+2;this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        int r = coords[1];\n        int c = coords[2];\n\n        float accumulator = 0.0;\n\n        const float heightScale = float(${u});\n        const float widthScale = float(${c});\n\n        const float invHeightScale = float(${p});\n        const float invWidthScale = float(${d});\n\n        const int winHeight = int(${h});\n        const int winWidth = int(${m});\n\n        // Compute bounds for where in dy we will look\n        float startRLerp = floor(float(r) * invHeightScale);\n        int startDyR = int(startRLerp - float(winHeight / 2));\n\n        float startCLerp = floor(float(c) * invWidthScale);\n        int startDyC = int(startCLerp - float(winWidth / 2));\n\n        // Loop over dy\n        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {\n          int dyR = dyROffset + startDyR;\n\n          // Guard against the window exceeding the bounds of dy\n          if (dyR < 0 || dyR >= ${s}) {\n            continue;\n          }\n\n          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {\n            int dyC = dyCOffset + startDyC;\n\n            // Guard against the window exceeding the bounds of dy\n            if (dyC < 0 || dyC >= ${o}) {\n              continue;\n            }\n\n            float dxR = float(dyR) * heightScale;\n            int topDxRIndex = int(floor(dxR));\n            int bottomDxRIndex = int(min(ceil(dxR), ${r-1}.0));\n            float dxRLerp = dxR - float(topDxRIndex);\n            float inverseDxRLerp = 1.0 - dxRLerp;\n\n            float dxC = float(dyC) * widthScale;\n            int leftDxCIndex = int(floor(dxC));\n            int rightDxCIndex = int(min(ceil(dxC), ${a-1}.0));\n            float dxCLerp = dxC - float(leftDxCIndex);\n            float inverseDxCLerp = 1.0 - dxCLerp;\n\n            if (r == topDxRIndex && c == leftDxCIndex) {\n              // topLeft\n              accumulator +=\n                getDy(b, dyR, dyC, d) * inverseDxRLerp * inverseDxCLerp;\n            }\n\n            if (r == topDxRIndex && c == rightDxCIndex) {\n              // topRight\n              accumulator += getDy(b, dyR, dyC, d) * inverseDxRLerp * dxCLerp;\n            }\n\n            if (r == bottomDxRIndex && c == leftDxCIndex) {\n              // bottomLeft\n              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * inverseDxCLerp;\n            }\n\n            if (r == bottomDxRIndex && c == rightDxCIndex) {\n              // bottomRight\n              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * dxCLerp;\n            }\n          }\n        }\n        // End loop over dy\n\n        setOutput(accumulator);\n      }\n    `}}function resizeBilinearGrad$2(e){const{inputs:t,backend:n,attrs:r}=e,{images:a,dy:s}=t,{alignCorners:o}=r,i=new ResizeBilinearBackpropProgram$1(s.shape,a.shape,o);return n.runWebGLProgram(i,[s],s.dtype)}const resizeBilinearGradConfig$3={kernelName:ResizeBilinearGrad$1,backendName:"webgl",kernelFunc:resizeBilinearGrad$2};class ResizeNearestNeighborProgram$1{constructor(e,t,n,r,a){this.variableNames=["A"],this.outputShape=[];const[s,o,i,l]=e;this.outputShape=[s,t,n,l];const u=[r&&t>1?o-1:o,r&&n>1?i-1:i],c=[r&&t>1?t-1:t,r&&n>1?n-1:n];let p;p=a?"max((vec2(yRC) + vec2(0.5)) * effectiveInputOverOutputRatioRC, vec2(0.0))":"vec2(yRC) * effectiveInputOverOutputRatioRC",this.userCode=`\n      const vec2 effectiveInputOverOutputRatioRC = vec2(\n          ${u[0]/c[0]},\n          ${u[1]/c[1]});\n      const vec2 inputShapeRC = vec2(${o}.0, ${i}.0);\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        ivec2 yRC = coords.yz;\n\n        // Fractional source index.\n        vec2 sourceFracIndexRC = ${p};\n\n        // Compute the coordinators of nearest neighbor point.\n        ivec2 sourceNearestRC = ivec2(\n          min(inputShapeRC - 1.0, floor(sourceFracIndexRC + ${r?"0.5":"0.0"})));\n        float newValue = getA(b, sourceNearestRC.x, sourceNearestRC.y, d);\n\n        setOutput(newValue);\n      }\n    `}}class ResizeNearestNeighborPackedProgram$1{constructor(e,t,n,r,a){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=[];const[s,o,i,l]=e;this.outputShape=[s,t,n,l];const u=[r&&t>1?o-1:o,r&&n>1?i-1:i],c=[r&&t>1?t-1:t,r&&n>1?n-1:n];let p;p=a?"max((vec3(yRC) + vec3(0.5)) * effectiveInputOverOutputRatioRC, vec3(0.0))":"vec3(yRC) * effectiveInputOverOutputRatioRC",this.userCode=`\n      const vec3 effectiveInputOverOutputRatioRC = vec3(\n          ${u[0]/c[0]},\n          ${u[1]/c[1]},\n          ${u[1]/c[1]});\n      const vec3 inputShapeRC = vec3(${o}.0, ${i}.0,\n                                     ${i}.0);\n\n      float getAValue(int b, int r, int c, int d) {\n        return getChannel(getA(b, r, c, d), vec2(c, d));\n      }\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        // Calculate values for next column in yRC.z.\n        ivec3 yRC = coords.yzz + ivec3(0, 0, 1);\n\n        // Fractional source index.\n        vec3 sourceFracIndexRC = ${p};\n\n        // Compute the coordinators of nearest neighbor point.\n        ivec3 sourceNearestRC = ivec3(\n          min(inputShapeRC - 1.0, floor(sourceFracIndexRC + ${r?"0.5":"0.0"})));\n\n        // Should we calculate next column and row elements in 2x2 packed cell.\n        bool hasNextCol = d < ${l-1};\n        bool hasNextRow = coords.z < ${n-1};\n\n        vec4 newValue = vec4(\n          getAValue(b, sourceNearestRC.x, sourceNearestRC.y, d),\n          hasNextCol ? getAValue(b, sourceNearestRC.x, sourceNearestRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceNearestRC.x, sourceNearestRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceNearestRC.x, sourceNearestRC.z, d + 1) : 0.0);\n\n        setOutput(newValue);\n      }\n    `}}function resizeNearestNeighbor$3(e){const{inputs:t,backend:n,attrs:r}=e,{images:a}=t,{alignCorners:s,halfPixelCenters:o,size:i}=r,[l,u]=i,c=env$1().getBool("WEBGL_PACK_IMAGE_OPERATIONS")?new ResizeNearestNeighborPackedProgram$1(a.shape,l,u,s,o):new ResizeNearestNeighborProgram$1(a.shape,l,u,s,o);return n.runWebGLProgram(c,[a],a.dtype)}const resizeNearestNeighborConfig$2={kernelName:ResizeNearestNeighbor$1,backendName:"webgl",kernelFunc:resizeNearestNeighbor$3};class ResizeNearestNeigborBackpropProgram$1{constructor(e,t,n){this.variableNames=["dy"],this.outputShape=[],this.outputShape=t;const[,r,a]=t,[,s,o]=e,i=[n&&s>1?r-1:r,n&&o>1?a-1:a],l=[n&&s>1?s-1:s,n&&o>1?o-1:o],u=i[0]/l[0],c=i[1]/l[1],p=1/u,d=1/c,h=2*Math.ceil(p)+2,m=2*Math.ceil(d)+2;this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        int r = coords[1];\n        int c = coords[2];\n\n        float accumulator = 0.0;\n\n        const float heightScale = float(${u});\n        const float widthScale = float(${c});\n\n        const float invHeightScale = float(${p});\n        const float invWidthScale = float(${d});\n\n        const int winHeight = int(${h});\n        const int winWidth = int(${m});\n\n        // Compute bounds for where in dy we will look\n        float startRLerp = floor(float(r) * invHeightScale);\n        int startDyR = int(floor(startRLerp - float(winHeight / 2)));\n\n        float startCLerp = floor(float(c) * invWidthScale);\n        int startDyC = int(floor(startCLerp - float(winWidth / 2)));\n\n        // Loop over dy\n        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {\n          int dyR = dyROffset + startDyR;\n\n          // Guard against the window exceeding the bounds of dy\n          if (dyR < 0 || dyR >= ${s}) {\n            continue;\n          }\n\n          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {\n            int dyC = dyCOffset + startDyC;\n\n            // Guard against the window exceeding the bounds of dy\n            if (dyC < 0 || dyC >= ${o}) {\n              continue;\n            }\n\n            float sourceFracRow =\n              float(${i[0]}) *\n                (float(dyR) / float(${l[0]}));\n\n            float sourceFracCol =\n                float(${i[1]}) *\n                  (float(dyC) / float(${l[1]}));\n\n            int sourceNearestRow = int(min(\n                float(int(${r}) - 1),\n                ${n} ? float(round(sourceFracRow)) :\n                                  float(floor(sourceFracRow))));\n\n            int sourceNearestCol = int(min(\n                float(int(${a}) - 1),\n                ${n} ? float(round(sourceFracCol)) :\n                                  float(floor(sourceFracCol))));\n\n            if (r == sourceNearestRow && c == sourceNearestCol) {\n              accumulator += getDy(b, dyR, dyC, d);\n            }\n          }\n        }\n        // End loop over dy\n\n        setOutput(accumulator);\n      }\n    `}}function resizeNearestNeighborGrad$2(e){const{inputs:t,backend:n,attrs:r}=e,{images:a,dy:s}=t,{alignCorners:o}=r,i=new ResizeNearestNeigborBackpropProgram$1(s.shape,a.shape,o);return n.runWebGLProgram(i,[s],s.dtype)}const resizeNearestNeighborGradConfig$3={kernelName:ResizeNearestNeighborGrad$1,backendName:"webgl",kernelFunc:resizeNearestNeighborGrad$2};class ReverseProgram$1{constructor(e,t){this.variableNames=["x"];const n=e.length;if(n>4)throw new Error(`WebGL backend: Reverse of rank-${n} tensor is not yet supported`);if(this.outputShape=e,1===n)return void(this.userCode=`\n        void main() {\n          int coord = getOutputCoords();\n          setOutput(getX(${e[0]} - coord - 1));\n        }\n      `);const r=e.map((n,r)=>(n=>-1!==t.indexOf(n)&&1!==e[n]?`${e[n]} - coords[${n}] - 1`:`coords[${n}]`)(r)).join(","),a=getCoordsDataType$1(n);this.userCode=`\n      void main() {\n        ${a} coords = getOutputCoords();\n        setOutput(getX(${r}));\n      }\n    `}}class ReversePackedProgram$1{constructor(e,t){this.variableNames=["x"],this.packedInputs=!0,this.packedOutput=!0;const n=e.length;if(n>4)throw new Error(`WebGL backend: Reverse of rank-${n} tensor is not yet supported`);this.outputShape=e;const r=getChannels$1("rc",n),a=`${r[n-1]} + 1 < ${this.outputShape[n-1]}`,s=`${r[n-2]} + 1 < ${this.outputShape[n-2]}`,o=getCoordsDataType$1(n);function i(n){const r=e.map((r,a)=>function(n,r){return-1!==t.indexOf(n)&&1!==e[n]?`${e[n]} - ${r[n]} - 1`:`${r[n]}`}(a,n));return`getChannel(getX(${r.join(",")}), vec2(${r.slice(-2).join(",")}))`}this.userCode=1===n?`\n        void main(){\n          int rc = getOutputCoords();\n          vec4 result = vec4(0.);\n          result.r = getChannel(getX(${e[0]} - rc - 1),\n            ${e[0]} - rc - 1);\n          if(${a}){\n              result.g = getChannel(getX(${e[0]} - (rc  + 1) - 1),\n                ${e[0]} - (rc  + 1) - 1);\n          }\n          setOutput(result);\n        }\n      `:`\n        void main() {\n          ${o} rc = getOutputCoords();\n          vec4 result = vec4(0.);\n          result.r = ${function(e){return i(e)}(r.slice())};\n          if(${a}){\n            result.g = ${function(e){return e[n-1]="("+e[n-1]+" + 1)",i(e)}(r.slice())};\n          }\n          if(${s}) {\n            result.b = ${function(e){return e[n-2]="("+e[n-2]+" + 1)",i(e)}(r.slice())};\n            if(${a}) {\n              result.a = ${function(e){return e[n-1]="("+e[n-1]+" + 1)",e[n-2]="("+e[n-2]+" + 1)",i(e)}(r.slice())};\n            }\n          }\n          setOutput(result);\n        }\n    `}}function reverse$3(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{dims:s}=r,o=a.shape.length,i=parseAxisParam$1(s,a.shape);if(0===o)return identity$3({inputs:{x:a},backend:n});const l=env$1().getBool("WEBGL_PACK_ARRAY_OPERATIONS")?new ReversePackedProgram$1(a.shape,i):new ReverseProgram$1(a.shape,i);return n.runWebGLProgram(l,[a],a.dtype)}const reverseConfig$2={kernelName:Reverse$1,backendName:"webgl",kernelFunc:reverse$3};class RotateProgram$1{constructor(e,t){this.variableNames=["Image"],this.outputShape=[],this.customUniforms=[{name:"params",type:"vec4"}];const n=e[1],r=e[2];this.outputShape=e;let a="";a="number"==typeof t?`float outputValue = ${t.toFixed(2)};`:`\n        vec3 fill = vec3(${t.join(",")});\n        float outputValue = fill[coords[3]];`,this.userCode=`\n        void main() {\n          ivec4 coords = getOutputCoords();\n          int x = coords[2];\n          int y = coords[1];\n          float coordXFloat = (float(x) - params[0]) * params[3] -\n            (float(y) - params[1]) * params[2];\n          float coordYFloat = (float(x) - params[0]) * params[2] +\n            (float(y) - params[1]) * params[3];\n          int coordX = int(round(coordXFloat + params[0]));\n          int coordY = int(round(coordYFloat + params[1]));\n          ${a}\n          if(coordX >= 0 && coordX < ${r} && coordY >= 0 && coordY < ${n}) {\n            outputValue = getImage(coords[0], coordY, coordX, coords[3]);\n          }\n          setOutput(outputValue);\n        }\n    `}}const rotateWithOffsetConfig$2={kernelName:RotateWithOffset$1,backendName:"webgl",kernelFunc:({inputs:e,attrs:t,backend:n})=>{const{image:r}=e,{radians:a,fillValue:s,center:o}=t,i=n,l=new RotateProgram$1(r.shape,s),[u,c]=getImageCenter$1(o,r.shape[1],r.shape[2]),p=[[u,c,Math.sin(a),Math.cos(a)]];return i.runWebGLProgram(l,[r],r.dtype,p)}},ROUND$1="\n  // OpenGL ES does not support round function.\n  // The algorithm is based on banker's rounding.\n  float base = floor(x);\n  if ((x - base) < 0.5) {\n    return floor(x);\n  } else if ((x - base) > 0.5) {\n    return ceil(x);\n  } else {\n    if (mod(base, 2.0) == 0.0) {\n      return base;\n    } else {\n      return base + 1.0;\n    }\n  }\n",round$4=unaryKernelFunc$2({opSnippet:ROUND$1}),roundConfig$2={kernelName:Round$1,backendName:"webgl",kernelFunc:round$4},RSQRT$1="return inversesqrt(x);",rsqrt$3=unaryKernelFunc$2({opSnippet:RSQRT$1,cpuKernelImpl:rsqrtImplCPU$1}),rsqrtConfig$2={kernelName:Rsqrt$1,backendName:"webgl",kernelFunc:rsqrt$3};class ScatterProgram$1{constructor(e,t,n,r,a,s,o=!0){this.variableNames=["updates","indices","defaultValue"],this.outputShape=s;const i=getCoordsDataType$1(a.length),l=getCoordsDataType$1(s.length);let u="";1===n?u="i":2===n&&(u="i, j");let c="";1===r?c="i":2===r&&(c="i, coords[1]"),this.userCode=`\n        ${i} strides = ${i}(${a});\n\n        void main() {\n          ${l} coords = getOutputCoords();\n          float sum = 0.0;\n          bool found = false;\n          for (int i = 0; i < ${e}; i++) {\n            int flattenedIndex = 0;\n            for (int j = 0; j < ${t}; j++) {\n              int index = round(getIndices(${u}));\n              flattenedIndex += index * ${t>1?"strides[j]":"strides"};\n            }\n            if (flattenedIndex == coords[0]) {\n              sum += getUpdates(${c});\n              found = true;\n            }\n          }\n          setOutput(mix(getDefaultValue(), sum, float(found)));\n        }\n      `}}function scatterNd$2(e){const{inputs:t,backend:n,attrs:r}=e,{indices:a,updates:s}=t,{shape:o}=r,{sliceRank:i,numUpdates:l,sliceSize:u,strides:c,outputSize:p}=calculateShapes$1(s,a,o),d=[p/u,u];if(0===p)return n.makeTensorInfo(o,a.dtype);const h=reshape$4({inputs:{x:a},backend:n,attrs:{shape:[l,i]}}),m=reshape$4({inputs:{x:s},backend:n,attrs:{shape:[l,u]}}),f=n.makeTensorInfo([],"float32",new Float32Array([0])),g=new ScatterProgram$1(l,i,h.shape.length,m.shape.length,c,d),$=n.runWebGLProgram(g,[m,h,f],m.dtype),y=reshape$4({inputs:{x:$},backend:n,attrs:{shape:o}});return n.disposeIntermediateTensorInfo(h),n.disposeIntermediateTensorInfo(m),n.disposeIntermediateTensorInfo($),n.disposeIntermediateTensorInfo(f),y}const scatterNdConfig$2={kernelName:ScatterNd$1,backendName:"webgl",kernelFunc:scatterNd$2};class SelectProgram$1{constructor(e,t,n){let r,a;if(this.variableNames=["c","a","b"],this.outputShape=t,n>4)throw Error(`Where for rank ${n} is not yet supported`);if(1===n)a="resRC",r="resRC";else{const n=["resRC.x","resRC.y","resRC.z","resRC.w"],s=[],o=[];for(let r=0;r<t.length;r++)o.push(`${n[r]}`),r<e&&s.push(`${n[r]}`);r=s.join(),a=o.join()}const s=getCoordsDataType$1(n);this.userCode=`\n      void main() {\n        ${s} resRC = getOutputCoords();\n        float cVal = getC(${r});\n        if (cVal >= 1.0) {\n          setOutput(getA(${a}));\n        } else {\n          setOutput(getB(${a}));\n        }\n      }\n    `}}function select$3(e){const{inputs:t,backend:n}=e,{condition:r,t:a,e:s}=t,o=new SelectProgram$1(r.shape.length,a.shape,a.shape.length);return n.runWebGLProgram(o,[r,a,s],upcastType$1(a.dtype,s.dtype))}const selectConfig$2={kernelName:Select$1,backendName:"webgl",kernelFunc:select$3},SELU$1=`\n  // Stable and Attracting Fixed Point (0, 1) for Normalized Weights.\n  // see: https://arxiv.org/abs/1706.02515\n  float scaleAlpha = ${SELU_SCALEALPHA$1};\n  float scale = ${SELU_SCALE$1};\n  return (x >= 0.0) ? scale * x : scaleAlpha * (exp(x) - 1.0);\n`,selu$3=unaryKernelFunc$2({opSnippet:SELU$1}),seluConfig$2={kernelName:Selu$3,backendName:"webgl",kernelFunc:selu$3},SIGMOID$3="return 1.0 / (1.0 + exp(-1.0 * x));",sigmoid$3=unaryKernelFunc$2({opSnippet:SIGMOID$3}),sigmoidConfig$2={kernelName:Sigmoid$3,backendName:"webgl",kernelFunc:sigmoid$3},SIGN$1="\n  if (isnan(x)) { return 0.0; }\n  return sign(x);\n",sign$3=unaryKernelFunc$2({opSnippet:SIGN$1}),signConfig$2={kernelName:Sign$1,backendName:"webgl",kernelFunc:sign$3},SIN$1=CHECK_NAN_SNIPPET_UNARY$1+"\n  return sin(x);\n",sin$3=unaryKernelFunc$2({opSnippet:SIN$1}),sinConfig$2={kernelName:Sin$1,backendName:"webgl",kernelFunc:sin$3},SINH$1="\n  float e2x = exp(x);\n  return (e2x - 1.0 / e2x) / 2.0;\n",sinh$3=unaryKernelFunc$2({opSnippet:SINH$1}),sinhConfig$2={kernelName:Sinh$1,backendName:"webgl",kernelFunc:sinh$3},SOFTPLUS$1="\n  float epsilon = 1.1920928955078125e-7;\n  float threshold = log(epsilon) + 2.0;\n\n  bool too_large = x > -threshold;\n  bool too_small = x < threshold;\n\n  float result;\n  float exp_x = exp(x);\n\n  if (too_large){\n    result = x;\n  }\n  else if (too_small){\n    result = exp_x;\n  }\n  else{\n    result = log(exp_x + 1.0);\n  }\n  return result;\n",softplus$3=unaryKernelFunc$2({opSnippet:SOFTPLUS$1}),softplusConfig$2={kernelName:Softplus$3,backendName:"webgl",kernelFunc:softplus$3},spaceToBatchND$3=e=>{const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{blockShape:s,paddings:o}=r;assert$6(a.shape.length<=4,()=>"spaceToBatchND for rank > 4 with a WebGL backend not implemented yet");const i=s.reduce((e,t)=>e*t),l=[[0,0]];l.push(...o);for(let e=1+s.length;e<a.shape.length;++e)l.push([0,0]);const u=[],c=padV2$2({inputs:{x:a},backend:n,attrs:{paddings:l,constantValue:0}}),p=getReshaped$1(c.shape,s,i,!1),d=getPermuted$1(p.length,s.length,!1),h=getReshapedPermuted$1(c.shape,s,i,!1),m=reshape$4({inputs:{x:c},backend:n,attrs:{shape:p}}),f=transpose$3({inputs:{x:m},backend:n,attrs:{perm:d}}),g=reshape$4({inputs:{x:f},backend:n,attrs:{shape:h}});return u.push(c),u.push(m),u.push(f),u.forEach(e=>n.disposeIntermediateTensorInfo(e)),g},spaceToBatchNDConfig$2={kernelName:SpaceToBatchND$1,backendName:"webgl",kernelFunc:spaceToBatchND$3};function sparseFillEmptyRows$3(e){const{inputs:t,backend:n}=e,{indices:r,values:a,denseShape:s,defaultValue:o}=t;if(1!==s.shape.length)throw new Error(`Dense shape must be a vector, saw:\n         ${s.shape}`);if(2!==r.shape.length)throw new Error(`Indices must be a matrix, saw:\n         ${r.shape}`);if(1!==a.shape.length)throw new Error(`Values must be a vector, saw:\n         ${a.shape}`);if(0!==o.shape.length)throw new Error(`Default value must be a scalar, saw:\n        ${o.shape}`);const i=n.readSync(r.dataId),l=n.readSync(a.dataId),u=n.readSync(s.dataId),c=n.readSync(o.dataId)[0],[p,d,h,m,f]=sparseFillEmptyRowsImplCPU$1(i,r.shape,r.dtype,l,a.dtype,u,c);return[n.makeTensorInfo(d,r.dtype,p),n.makeTensorInfo([d[0]],a.dtype,h),n.makeTensorInfo([m.length],"bool",new Uint8Array(m.map(e=>Number(e)))),n.makeTensorInfo([f.length],r.dtype,new Int32Array(f))]}const sparseFillEmptyRowsConfig$2={kernelName:SparseFillEmptyRows$1,backendName:"webgl",kernelFunc:sparseFillEmptyRows$3};function sparseReshape$3(e){const{inputs:t,backend:n}=e,{inputIndices:r,inputShape:a,newShape:s}=t;if(2!==r.shape.length)throw new Error(`Input indices should be a matrix but received shape ${r.shape}`);if(1!==a.shape.length)throw new Error(`Input shape should be a vector but received shape ${a.shape}`);if(1!==s.shape.length)throw new Error(`Target shape should be a vector but received shape ${s.shape}`);const o=Array.from(n.readSync(a.dataId)),i=n.readSync(r.dataId),l=Array.from(n.readSync(s.dataId)),[u,c,p]=sparseReshapeImplCPU$1(i,r.shape,r.dtype,o,l);return[n.makeTensorInfo(c,r.dtype,u),n.makeTensorInfo([p.length],s.dtype,new Int32Array(p))]}const sparseReshapeConfig$2={kernelName:SparseReshape$1,backendName:"webgl",kernelFunc:sparseReshape$3};function sparseSegmentMean$3(e){const{inputs:t,backend:n}=e,{data:r,indices:a,segmentIds:s}=t;if(r.shape.length<1)throw new Error("Data should be at least 1 dimensional but received scalar");if(1!==a.shape.length)throw new Error(`Indices should be a vector but received shape\n              ${a.shape}`);if(1!==s.shape.length)throw new Error(`Segment ids should be a vector but received shape\n              ${s.shape}`);const o=n.readSync(r.dataId),i=n.readSync(a.dataId),l=n.readSync(s.dataId),[u,c]=sparseSegmentReductionImplCPU$1(o,r.shape,r.dtype,i,l,!0);return n.makeTensorInfo(c,r.dtype,u)}const sparseSegmentMeanConfig$2={kernelName:SparseSegmentMean$1,backendName:"webgl",kernelFunc:sparseSegmentMean$3};function sparseSegmentSum$3(e){const{inputs:t,backend:n}=e,{data:r,indices:a,segmentIds:s}=t;if(r.shape.length<1)throw new Error("Data should be at least 1 dimensional but received scalar");if(1!==a.shape.length)throw new Error(`Indices should be a vector but received shape\n             ${a.shape}`);if(1!==s.shape.length)throw new Error(`Segment ids should be a vector but received shape\n             ${s.shape}`);const o=n.readSync(r.dataId),i=n.readSync(a.dataId),l=n.readSync(s.dataId),[u,c]=sparseSegmentReductionImplCPU$1(o,r.shape,r.dtype,i,l);return n.makeTensorInfo(c,r.dtype,u)}const sparseSegmentSumConfig$2={kernelName:SparseSegmentSum$1,backendName:"webgl",kernelFunc:sparseSegmentSum$3};function sparseToDense$3(e){const{inputs:t,backend:n,attrs:r}=e,{sparseIndices:a,sparseValues:s,defaultValue:o}=t,{outputShape:i}=r,{sliceRank:l,numUpdates:u,strides:c,outputSize:p}=calculateShapes$1(s,a,i),d=new ScatterProgram$1(u,l,a.shape.length,s.shape.length,c,[p,1],!1),h=n.runWebGLProgram(d,[s,a,o],s.dtype),m=reshape$4({inputs:{x:h},backend:n,attrs:{shape:i}});return n.disposeIntermediateTensorInfo(h),m}const sparseToDenseConfig$2={kernelName:SparseToDense$1,backendName:"webgl",kernelFunc:sparseToDense$3};function splitV$2(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{numOrSizeSplits:s,axis:o}=r,i=parseAxisParam$1(o,a.shape)[0],l=prepareSplitSize$1(a,s,i),u=new Array(a.shape.length).fill(0),c=a.shape.slice();return l.map(e=>{const t=[...c];t[i]=e;const r=slice$3({inputs:{x:a},backend:n,attrs:{begin:u,size:t}});return u[i]+=e,r})}const splitVConfig$2={kernelName:SplitV$1,backendName:"webgl",kernelFunc:splitV$2},SQRT$1="return sqrt(x);",sqrt$3=unaryKernelFunc$2({opSnippet:SQRT$1}),sqrtConfig$2={kernelName:Sqrt$1,backendName:"webgl",kernelFunc:sqrt$3},SQUARE$1="return x * x;",square$3=unaryKernelFunc$2({opSnippet:SQUARE$1}),squareConfig$2={kernelName:Square$1,backendName:"webgl",kernelFunc:square$3},SQUARED_DIFFERENCE$1="return (a - b) * (a - b);",squaredDifference$3=binaryKernelFunc$2({opSnippet:SQUARED_DIFFERENCE$1,packedOpSnippet:SQUARED_DIFFERENCE$1}),squaredDifferenceConfig$2={kernelName:SquaredDifference$1,backendName:"webgl",kernelFunc:squaredDifference$3};function step$3({inputs:e,attrs:t,backend:n}){const{x:r}=e,a=new UnaryOpProgram$1(r.shape,CHECK_NAN_SNIPPET$5+`\n    return x > 0.0 ? 1.0 : float(${t.alpha});\n  `);return n.runWebGLProgram(a,[r],r.dtype)}const stepConfig$2={kernelName:Step$1,backendName:"webgl",kernelFunc:step$3};class StridedSliceProgram$1{constructor(e,t,n){this.variableNames=["x"],this.outputShape=n;const r=n.length,a=getCoordsDataType$1(n.length),s=getCoordsDataType$1(n.length);let o="";if(1===r)o="coords * strides + begin";else{let e=0;o=n.map((t,r)=>(e++,1===n.length?`coords * strides[${r}] + begin[${r}]`:`coords[${e-1}] * strides[${r}] + begin[${r}]`)).join(",")}this.userCode=`\n      ${a} begin = ${a}(${e});\n      ${a} strides = ${a}(${t});\n\n      void main() {\n        ${s} coords = getOutputCoords();\n        setOutput(getX(${o}));\n      }\n    `}}function stridedSlice$3(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{begin:s,end:o,strides:i,beginMask:l,endMask:u,ellipsisMask:c,newAxisMask:p,shrinkAxisMask:d}=r,{nonStrided:h,$begin:m,$strides:f,size:g,newShape:$,outShape:y}=sliceInfo$1(a.shape,s,o,i,l,u,c,p,d),b=reshape$4({inputs:{x:a},backend:n,attrs:{shape:$}});let x;if(h){const e=slice$3({inputs:{x:b},backend:n,attrs:{begin:m,size:g}});x=reshape$4({inputs:{x:e},backend:n,attrs:{shape:y}}),n.disposeIntermediateTensorInfo(e)}else if(y.some(e=>0===e))x=n.makeTensorInfo(y,a.dtype,[]);else if(n.shouldExecuteOnCPU([b])){const e=n.texData.get(b.dataId),t=buffer$1(b.shape,b.dtype,e.values),r=stridedSliceImplCPU$1(y,t,f,m);x=n.makeTensorInfo(y,b.dtype,r.values)}else{const e=new StridedSliceProgram$1(m,f,y);x=n.runWebGLProgram(e,[b],b.dtype)}const v=reshape$4({inputs:{x},backend:n,attrs:{shape:y}});return n.disposeIntermediateTensorInfo(b),n.disposeIntermediateTensorInfo(x),v}const stridedSliceConfig$2={kernelName:StridedSlice$1,backendName:"webgl",kernelFunc:stridedSlice$3};function stringNGrams$3(e){const{inputs:t,backend:n,attrs:r}=e,{separator:a,nGramWidths:s,leftPad:o,rightPad:i,padWidth:l,preserveShortSequences:u}=r,{data:c,dataSplits:p}=t,d=n.readSync(c.dataId),h=n.readSync(p.dataId),[m,f]=stringNGramsImplCPU$1(d,h,a,s,o,i,l,u);return[n.makeTensorInfo([m.length],"string",m),n.makeTensorInfo(p.shape,"int32",f)]}const stringNGramsConfig$2={kernelName:StringNGrams$1,backendName:"webgl",kernelFunc:stringNGrams$3};function stringSplit$3(e){const{inputs:t,backend:n,attrs:r}=e,{skipEmpty:a}=r,{input:s,delimiter:o}=t;if("string"!==s.dtype)throw new Error("Input must be of datatype string");if(1!==s.shape.length)throw new Error(`Input must be a vector, got shape: ${s.shape}`);if(0!==o.shape.length)throw new Error(`Delimiter must be a scalar, got shape: ${o.shape}`);const i=n.readSync(s.dataId),l=n.readSync(o.dataId)[0],[u,c,p]=stringSplitImplCPU$1(i,l,a),d=c.length;return[n.makeTensorInfo([d,2],"int32",u),n.makeTensorInfo([d],"string",c),n.makeTensorInfo([2],"int32",new Int32Array(p))]}const stringSplitConfig$2={kernelName:StringSplit$1,backendName:"webgl",kernelFunc:stringSplit$3};function stringToHashBucketFast$3(e){const{inputs:t,backend:n,attrs:r}=e,{numBuckets:a}=r,{input:s}=t;if("string"!==s.dtype)throw new Error("Input must be of datatype string");if(a<=0)throw new Error("Number of buckets must be at least 1");const o=n.readSync(s.dataId),i=stringToHashBucketFastImplCPU$1(o,a);return n.makeTensorInfo(s.shape,"int32",i)}const stringToHashBucketFastConfig$2={kernelName:StringToHashBucketFast$1,backendName:"webgl",kernelFunc:stringToHashBucketFast$3},TAN$1="return tan(x);",tan$3=unaryKernelFunc$2({opSnippet:TAN$1}),tanConfig$2={kernelName:Tan$1,backendName:"webgl",kernelFunc:tan$3},TANH$1="\n  float e2x = exp(-2.0 * abs(x));\n  return sign(x) * (1.0 - e2x) / (1.0 + e2x);\n",tanh$4=unaryKernelFunc$2({opSnippet:TANH$1}),tanhConfig$2={kernelName:Tanh$3,backendName:"webgl",kernelFunc:tanh$4};class TileProgram$1{constructor(e,t){this.variableNames=["A"];const n=new Array(e.length);for(let r=0;r<n.length;r++)n[r]=e[r]*t[r];this.outputShape=n,this.rank=n.length;const r=getCoordsDataType$1(this.rank),a=getSourceCoords$3(e);this.userCode=`\n      void main() {\n        ${r} resRC = getOutputCoords();\n        setOutput(getA(${a}));\n      }\n    `}}function getSourceCoords$3(e){const t=e.length;if(t>5)throw Error(`Tile for rank ${t} is not yet supported`);if(1===t)return`imod(resRC, ${e[0]})`;const n=["resRC.x","resRC.y","resRC.z","resRC.w","resRC.u"],r=[];for(let t=0;t<e.length;t++)r.push(`imod(${n[t]}, ${e[t]})`);return r.join()}function tile$4(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{reps:s}=r;if("string"===a.dtype||a.shape.length>5){const e=n.readSync(a.dataId),t="string"===a.dtype?e.map(e=>decodeString$1(e)):e,r=buffer$1(a.shape,a.dtype,t),o=tileImplCPU$1(r,s);return n.makeTensorInfo(o.shape,o.dtype,o.values)}const o=new TileProgram$1(a.shape,s);return n.runWebGLProgram(o,[a],a.dtype)}const tileConfig$2={kernelName:Tile$1,backendName:"webgl",kernelFunc:tile$4};class SwapProgram$1{constructor(e){this.variableNames=["x","indices"],this.customUniforms=[{name:"n",type:"int"},{name:"firstPass",type:"int"},{name:"negativeInf",type:"float"},{name:"dir",type:"int"},{name:"inc",type:"int"}],this.outputShape=e,this.userCode="\n       void main() {\n         ivec2 coords = getOutputCoords();\n         int batch = coords[0];\n         int elemIdx = coords[1];\n\n         // We compare elements pair-wise within a group of size 2 * inc.\n         // The comparing rule for each group alternates between ascending\n         // and descending. Within each group, we compare each pair at\n         // positions i and i+inc. To decide whether an element at position i\n         // is x0 or x1, we mod it by 2 * inc, if the result is smaller than\n         // inc, it is in the first half of the group, we denote it as x0,\n         // otherwise we denote it as x1.\n         // For example, as shown in the Bitonic top K paper referenced above,\n         // Figure5(a) shows that element[1] is in the\n         // second half of the group when group size is 2, but it is in the\n         // first half of the group when group size is 4.\n\n         bool isFirstInPair = imod(elemIdx, 2 * inc) < inc;\n         int i = isFirstInPair ? elemIdx : elemIdx - inc;\n\n         int i0 = firstPass == 1 ? i : int(getIndices(batch, i));\n         int i1 = firstPass == 1 ? i + inc : int(getIndices(batch, i + inc));\n         float x0 = i0 < n ? getX(batch, i0) : negativeInf;\n         float x1 = i1 < n ? getX(batch, i1) : negativeInf;\n\n         // Denotes which direction indices are in (ascending or descending).\n         bool reverse = imod(elemIdx, 2 * dir) >= dir;\n         bool isGreater = x0 > x1 || (x0 == x1 && i1 > i0);\n         if (reverse == isGreater) { // Elements in opposite order of direction\n           int iTemp = i0;\n           i0 = i1;\n           i1 = iTemp;\n         }\n         if (isFirstInPair) {\n            setOutput(float(i0));\n         } else {\n            setOutput(float(i1));\n         }\n       }\n     "}}class MergeProgram$1{constructor(e){this.variableNames=["x","indices"],this.customUniforms=[{name:"n",type:"int"},{name:"firstPass",type:"int"},{name:"k",type:"int"}],this.outputShape=e,this.userCode="\n    void main() {\n         // Takes max of indices (0, k), (1, k + 1), (2, k + 2) ...\n         ivec2 coords = getOutputCoords();\n         int batch = coords[0];\n         int elemIdx = coords[1];\n\n         // The output size is half of the previous size.\n         // If the previous sequence is | | | | _ _ _ _  | | | |  _ _ _ _ (k=4),\n         // we only need to output the indices at positions |, the indices at\n         // positions _ can be thrown away, see Figure5(b) After Phase 2\n         // (Merge phase) in the Bitonic Top K paper referenced above.\n         // For example, the paper shows we only need to output the orange bars.\n         // The output sequence should look like this | | | | | | | |.\n         // Because the sequence is halved, to map the output index back\n         // to the previous sequence to find the corresponding value,\n         // we need to double the index. When we double the index,\n         // we basically interpolate a position, so 2i looks like\n         // | _ | _ | _ | _ | _ | _ | _. We move the | to the first k position\n         // of each 2k positions by - elemIdx % k. E.g. for output at\n         // index 4,5,6,7, we want to get the corresponding element at\n         // original index 8,9,10,11, for output at index 8,9,10,11,\n         // we want to get the corresponding element at original index\n         // 16,17,18,19, so on and so forth.\n\n         int i = elemIdx < k ? elemIdx : (elemIdx * 2 - imod(elemIdx, k));\n         int i0 = firstPass == 1 ? i : int(getIndices(batch, i));\n         int i1 = firstPass == 1 ? i + k : int(getIndices(batch, i + k));\n\n         float x0 = getX(batch, i0);\n         float x1 = i1 < n ? getX(batch, i1) : x0;\n\n         setOutput(x0 >= x1 ? float(i0) : float(i1));\n       }\n     "}}function disposeIntermediateTensorInfoOrNull$1(e,t){null!==t&&e.disposeIntermediateTensorInfo(t)}function roundUpToPow2$1(e){let t=1;for(;t<e;)t*=2;return t}function topK$2(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{k:s,sorted:o}=r,i=env$1().getNumber("TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD"),l=env$1().getNumber("TOPK_K_CPU_HANDOFF_THRESHOLD"),u=a.shape,c=u[u.length-1];if(n.shouldExecuteOnCPU([a])||c<i||s>l){const e=n.readSync(a.dataId),[t,r]=topKImplCPU$1(e,u,a.dtype,s,o);return[n.makeTensorInfo(t.shape,t.dtype,t.values),n.makeTensorInfo(r.shape,r.dtype,r.values)]}if(0===s)return u[u.length-1]=0,[n.makeTensorInfo(u,a.dtype,[]),n.makeTensorInfo(u,"int32",[])];if(1===c)return[a,fill$3({attrs:{shape:u,dtype:"int32",value:0},backend:n})];const p=n.texData.get(a.dataId),d=null!==p&&p.isPacked,h=d?n.unpackTensor(a):a,m=sizeFromShape$1(u)/c,f=reshape$4({inputs:{x:h},attrs:{shape:[m,c]},backend:n});d&&disposeIntermediateTensorInfoOrNull$1(n,h);const g=roundUpToPow2$1(s),$=roundUpToPow2$1(c);let y=null;const b=()=>null===y?[f,f]:[f,y],x=(e,t,r)=>{const a=b(),s=new SwapProgram$1(r),o=y;y=n.runWebGLProgram(s,a,"int32",[[c],[null===y?1:0],[Number.NEGATIVE_INFINITY],[e],[t]]),disposeIntermediateTensorInfoOrNull$1(n,o)};for(let e=1;e<g;e*=2){const t=2*e;for(let n=e;n>=1;n/=2)x(t,n,[m,$])}for(let e=$;e>g;e/=2){const t=b(),r=new MergeProgram$1([m,e/2]),a=y;y=n.runWebGLProgram(r,t,"int32",[[c],[null===y?1:0],[g]]),disposeIntermediateTensorInfoOrNull$1(n,a);const s=g/2,o=2*s;for(let e=s;e>=1;e/=2)x(o,e,y.shape)}let v=y;y=slice$3({inputs:{x:y},backend:n,attrs:{begin:0,size:[m,s]}}),disposeIntermediateTensorInfoOrNull$1(n,v);let I=gatherV2$2({inputs:{x:f,indices:y},backend:n,attrs:{axis:1,batchDims:1}});disposeIntermediateTensorInfoOrNull$1(n,f);const C=u.slice(0,-1);C.push(s),v=y,y=reshape$4({inputs:{x:y},attrs:{shape:C},backend:n}),disposeIntermediateTensorInfoOrNull$1(n,v);const S=I;return I=reshape$4({inputs:{x:I},attrs:{shape:C},backend:n}),disposeIntermediateTensorInfoOrNull$1(n,S),[I,y]}const topKConfig$2={kernelName:TopK$1,backendName:"webgl",kernelFunc:topK$2};class TransformProgram$1{constructor(e,t,n,r,a,s){this.variableNames=["Image","Transforms"],this.outputShape=s;const o="nearest"===n?1:2;let i;switch(r){case"constant":i=1;break;case"reflect":i=2;break;case"wrap":i=3;break;case"nearest":i=4;break;default:i=1}this.userCode=`\n            float mapCoord(float outCoord, float len) {\n              float inCoord = outCoord;\n              if(${i} == 2) {\n                if (inCoord < 0.0) {\n                  if (len <= 1.0) {\n                    inCoord = 0.0;\n                  } else {\n                    float sz2 = 2.0 * len;\n                    if (inCoord < sz2) {\n                      inCoord = sz2 * float(int(float(-inCoord / sz2))) +\n                      inCoord;\n                    }\n                    inCoord = inCoord < -len ? inCoord + sz2 : -inCoord - 1.0;\n                  }\n                } else if (inCoord > len - 1.0) {\n                  if (len <= 1.0) {\n                    inCoord = 0.0;\n                  } else {\n                    float sz2 = 2.0 * len;\n                    inCoord -= sz2 * float(int(float(inCoord / sz2)));\n                    if (inCoord >= len) {\n                      inCoord = sz2 - inCoord - 1.0;\n                    }\n                  }\n                }\n                return clamp(inCoord, 0.0, len - 1.0);\n              } else if (${i} == 3) {\n                if (inCoord < 0.0) {\n                  if (len <= 1.0) {\n                    inCoord = 0.0;\n                  } else {\n                    float sz = len - 1.0;\n                    inCoord += len * (float(int(float(-inCoord / sz))) + 1.0);\n                  }\n                } else if (inCoord > len - 1.0) {\n                  if (len <= 1.0) {\n                    inCoord = 0.0;\n                  } else {\n                    float sz = len - 1.0;\n                    inCoord -= len * float(int(float(inCoord / sz)));\n                  }\n                }\n                return clamp(inCoord, 0.0, len - 1.0);\n              } else if (${i} == 4) {\n                return clamp(outCoord, 0.0, len - 1.0);\n              } else {\n                return outCoord;\n              }\n            }\n\n            float readWithFillValue(int batch, int coordY, int coordX,\n              int channel) {\n              float outputValue;\n              if (0 <= coordY && coordY < ${e} && 0 <= coordX && coordX < ${t}) {\n                  outputValue = getImage(batch, coordY, coordX, channel);\n              } else {\n                outputValue = float(${a});\n              }\n              return outputValue;\n            }\n\n            void main() {\n              ivec4 coords = getOutputCoords();\n              float outputValue;\n              int batch = coords[0];\n              int x = coords[2];\n              int y = coords[1];\n              int channel = coords[3];\n              float xf = float(x);\n              float yf = float(y);\n              float a1 = getTransforms(batch, 0);\n              float a2 = getTransforms(batch, 1);\n              float a3 = getTransforms(batch, 2);\n              float b1 = getTransforms(batch, 3);\n              float b2 = getTransforms(batch, 4);\n              float b3 = getTransforms(batch, 5);\n              float c1 = getTransforms(batch, 6);\n              float c2 = getTransforms(batch, 7);\n              float projection = c1 * xf + c2 * yf + 1.0;\n              if (projection == 0.0) {\n                outputValue = float(${a});\n              } else {\n                float inX = (a1 * xf + a2 * yf + a3) / projection;\n                float inY = (b1 * xf + b2 * yf + b3) / projection;\n                float mapX = mapCoord(inX, float(${t}));\n                float mapY = mapCoord(inY, float(${e}));\n\n                if (${o} == 1) {\n                  int coordY = int(round(mapY));\n                  int coordX = int(round(mapX));\n                  outputValue = readWithFillValue(batch, coordY, coordX,\n                    channel);\n                } else {\n                  float yFloor = floor(mapY);\n                  float xFloor = floor(mapX);\n                  float yCeil = yFloor + 1.0;\n                  float xCeil = xFloor + 1.0;\n                  float valueYFloor = (xCeil - mapX) *\n                  readWithFillValue(batch, int(yFloor), int(xFloor), channel) +\n                  (mapX - xFloor) *\n                  readWithFillValue(batch, int(yFloor), int(xCeil), channel);\n                  float valueYCeil = (xCeil - mapX) *\n                  readWithFillValue(batch, int(yCeil), int(xFloor), channel) +\n                  (mapX - xFloor) *\n                  readWithFillValue(batch, int(yCeil), int(xCeil), channel);\n                  outputValue = (yCeil - mapY) * valueYFloor +\n                  (mapY - yFloor) * valueYCeil;\n                }\n              }\n              setOutput(outputValue);\n            }\n        `}}function transform$3(e){const{inputs:t,backend:n,attrs:r}=e,{image:a,transforms:s}=t,{interpolation:o,fillMode:i,fillValue:l,outputShape:u}=r,[c,p,d,h]=a.shape,[m,f]=null!=u?u:[p,d],g=new TransformProgram$1(p,d,o,i,l,[c,m,f,h]);return n.runWebGLProgram(g,[a,s],"float32")}const transformConfig$2={kernelName:Transform$1,backendName:"webgl",kernelFunc:transform$3};function unique$4(e){const{inputs:t,attrs:n,backend:r}=e,{axis:a}=n,{x:s}=t;assertNotComplex$2(s,"unique"),console.warn("WARNING: ","UI might be locked temporarily as data is being downloaded");const o=r.readSync(s.dataId),{outputValues:i,outputShape:l,indices:u}=uniqueImplCPU$1(o,a,s.shape,s.dtype);return[r.makeTensorInfo(l,s.dtype,i),r.makeTensorInfo([u.length],"int32",u)]}const uniqueConfig$2={kernelName:Unique$1,backendName:"webgl",kernelFunc:unique$4};function unpack$2(e){const{inputs:t,backend:n,attrs:r}=e,{value:a}=t;let{axis:s}=r;s<0&&(s+=a.shape.length);const o=a,i=o.shape.length,l=a.shape[s],u=new Array(i-1);let c=0;for(let e=0;e<i;e++)e!==s&&(u[c++]=o.shape[e]);const p=[],d=new Array(i).fill(0),h=o.shape.slice();h[s]=1;const m=new Array(l);for(let e=0;e<m.length;e++){d[s]=e;const t=slice$3({inputs:{x:o},backend:n,attrs:{begin:d,size:h}}),r=reshape$4({inputs:{x:t},backend:n,attrs:{shape:u}});m[e]=r,p.push(t)}return p.forEach(e=>n.disposeIntermediateTensorInfo(e)),m}const unpackConfig$2={kernelName:Unpack$1,backendName:"webgl",kernelFunc:unpack$2};class SegmentOpProgram$1{constructor(e,t){this.variableNames=["x","segmentIds"];const n=e.windowSize,r=e.batchSize,a=e.inSize,s=e.numSegments,o=s*Math.ceil(a/n);this.outputShape=[r,o];const i=4*Math.floor(n/4),l=n%4,u="\n        sumValue += dot(values, segFilter);\n    ";let c="";a%n>0&&(c=`\n        if (inIdx < 0 || inIdx >= ${a}) {\n          return initializationValue;\n        }\n      `);let p="";a%n>0&&(p=`\n        if (inIdx < 0 || inIdx >= ${a}) {\n          return -1.0;\n        }\n      `),this.userCode=`\n      const float initializationValue = 0.0;\n\n      float getValue(int batch, int inIdx) {\n        ${c}\n        return getX(batch, inIdx);\n      }\n\n      float getSegmentIdAtIndex(int inIdx) {\n        ${p}\n        return getSegmentIds(inIdx);\n      }\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n        int outIdx = coords[1];\n        int inOffset = int(floor(float(outIdx) / float(\n          ${s})) * float(${n}));\n        int currentSeg = int(mod(float(outIdx), float(${s})));\n\n        float sumValue = 0.0;\n\n        for (int i = 0; i < ${i}; i += 4) {\n          int inIdx = inOffset + i;\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            getValue(batch, inIdx + 3)\n          );\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 3)) == currentSeg ? 1 : 0\n          );\n\n          ${u}\n        }\n\n        int inIdx = inOffset + ${i};\n        if (${1===l}) {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            initializationValue,\n            initializationValue,\n            initializationValue\n          );\n\n          int inIdxSeg = int(getSegmentIdAtIndex(inIdx));\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            0,\n            0,\n            0\n          );\n\n          ${u}\n        } else if (${2===l}) {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            initializationValue,\n            initializationValue\n          );\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\n              0,\n              0\n          );\n\n          ${u}\n        } else if (${3===l}) {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            initializationValue\n          );\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,\n            0\n          );\n\n          ${u}\n        }\n        setOutput(sumValue);\n      }\n    `}}function unsortedSegmentSum$3(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,segmentIds:s}=t,{numSegments:o}=r,i=a.shape.length,l=[];let u=0;const c=getAxesPermutation$1([u],i);let p=a;null!=c&&(p=transpose$3({inputs:{x:a},backend:n,attrs:{perm:c}}),l.push(p),u=getInnerMostAxes$1(1,i)[0]);const d=computeOutShape$3(p.shape,u,o),h=sizeFromShape$1([p.shape[u]]),m=reshape$4({inputs:{x:p},backend:n,attrs:{shape:[-1,h]}});l.push(m);const f=sumOutType$1(a.dtype),g=(e,t,r,a,s)=>{const o=e.shape[0],i=e.shape[1],u=segOpComputeOptimalWindowSize$1(i,s),c=new SegmentOpProgram$1({windowSize:u,inSize:i,batchSize:o,numSegments:s},t),p=n.compileAndRun(c,[e,r],a);if(l.push(p),p.shape[1]===s)return p;const d=range$5({backend:n,attrs:{start:0,stop:s,step:1,dtype:"float32"}}),h=tile$4({inputs:{x:d},backend:n,attrs:{reps:[i/u]}});return l.push(d),l.push(h),g(p,t,h,a,s)},$=reshape$4({inputs:{x:g(m,"unsortedSegmentSum",s,f,o)},backend:n,attrs:{shape:d}});let y=$;if(null!=c){l.push($);const e=getUndoAxesPermutation$1(c);y=transpose$3({inputs:{x:y},backend:n,attrs:{perm:e}})}return l.forEach(e=>n.disposeIntermediateTensorInfo(e)),y}const unsortedSegmentSumConfig$2={kernelName:UnsortedSegmentSum$1,backendName:"webgl",kernelFunc:unsortedSegmentSum$3},kernelConfigs$2=[LRNConfig$1,LRNGradConfig$1,_fusedMatMulConfig$2,absConfig$2,acosConfig$2,acoshConfig$2,addConfig$2,addNConfig$2,allConfig$2,anyConfig$2,argMaxConfig$2,argMinConfig$2,asinConfig$2,asinhConfig$2,atan2Config$2,atanConfig$2,atanhConfig$2,avgPool3DConfig$2,avgPoolConfig$2,avgPoolGrad3DConfig$1,avgPoolGradConfig$3,batchMatMulConfig$2,batchNormConfig$2,batchToSpaceNDConfig$2,bincountConfig$2,castConfig$2,ceilConfig$2,clipByValueConfig$1,complexAbsConfig$2,complexConfig$2,concatConfig$2,conv2DBackpropFilterConfig$2,conv2DBackpropInputConfig$2,conv2DConfig$2,conv3DBackpropFilterV2Config$2,conv3DBackpropInputConfig$1,conv3DConfig$2,cosConfig$2,coshConfig$2,cropAndResizeConfig$2,cumsumConfig$2,denseBincountConfig$2,depthToSpaceConfig$2,depthwiseConv2dNativeBackpropFilterConfig$2,depthwiseConv2dNativeBackpropInputConfig$2,depthwiseConv2dNativeConfig$2,diagConfig$2,dilation2DConfig$1,einsumConfig$2,eluConfig$2,eluGradConfig$3,equalConfig$2,erfConfig$2,expConfig$2,expandDimsConfig$2,expm1Config$2,fftConfig$2,fillConfig$2,flipLeftRightConfig$2,floorConfig$2,floorDivConfig$2,fromPixelsConfig$1,fusedConv2DConfig$2,fusedDepthwiseConv2DConfig$2,gatherNdConfig$2,gatherV2Config$2,greaterConfig$2,greaterEqualConfig$2,identityConfig$2,ifftConfig$2,imagConfig$2,isFiniteConfig$2,isInfConfig$2,isNaNConfig$2,leakyReluConfig$2,lessConfig$2,lessEqualConfig$2,linSpaceConfig$2,log1pConfig$2,logConfig$2,logicalAndConfig$2,logicalNotConfig$2,logicalOrConfig$2,maxConfig$2,maxPool3DConfig$2,maxPoolConfig$2,maxPoolGrad3DConfig$1,maxPoolGradConfig$3,maxPoolWithArgmaxConfig$2,maximumConfig$2,meanConfig$2,minConfig$2,minimumConfig$2,mirrorPadConfig$2,modConfig$2,multinomialConfig$2,multiplyConfig$2,negConfig$2,nonMaxSuppressionV3Config$2,nonMaxSuppressionV4Config$2,nonMaxSuppressionV5Config$2,notEqualConfig$2,oneHotConfig$2,onesLikeConfig$2,packConfig$2,padV2Config$2,powConfig$2,preluConfig$2,prodConfig$2,rangeConfig$2,realConfig$2,realDivConfig$2,reciprocalConfig$2,relu6Config$2,reluConfig$2,reshapeConfig$2,resizeBilinearConfig$2,resizeBilinearGradConfig$3,resizeNearestNeighborConfig$2,resizeNearestNeighborGradConfig$3,reverseConfig$2,rotateWithOffsetConfig$2,roundConfig$2,rsqrtConfig$2,scatterNdConfig$2,selectConfig$2,seluConfig$2,sigmoidConfig$2,signConfig$2,sinConfig$2,sinhConfig$2,sliceConfig$2,softmaxConfig$2,softplusConfig$2,spaceToBatchNDConfig$2,sparseFillEmptyRowsConfig$2,sparseReshapeConfig$2,sparseSegmentMeanConfig$2,sparseSegmentSumConfig$2,sparseToDenseConfig$2,splitVConfig$2,sqrtConfig$2,squareConfig$2,squaredDifferenceConfig$2,stepConfig$2,stridedSliceConfig$2,stringNGramsConfig$2,stringSplitConfig$2,stringToHashBucketFastConfig$2,subConfig$2,sumConfig$2,tanConfig$2,tanhConfig$2,tileConfig$2,topKConfig$2,transformConfig$2,transposeConfig$2,uniqueConfig$2,unpackConfig$2,unsortedSegmentSumConfig$2,zerosLikeConfig$2];for(const e of kernelConfigs$2)registerKernel$1(e);const version$8="3.8.0",EPSILON_FLOAT32$1=1e-7,EPSILON_FLOAT16$1=1e-4;class DataStorage{constructor(e,t){this.backend=e,this.dataMover=t,this.data=new WeakMap,this.dataIdsCount=0}get(e){return this.data.has(e)||this.dataMover.moveData(this.backend,e),this.data.get(e)}set(e,t){this.dataIdsCount++,this.data.set(e,t)}has(e){return this.data.has(e)}delete(e){return this.dataIdsCount--,this.data.delete(e)}numDataIds(){return this.dataIdsCount}}class KernelBackend{refCount(e){return notYetImplemented("refCount")}incRef(e){return notYetImplemented("incRef")}timerAvailable(){return!0}time(e){return notYetImplemented("time")}read(e){return notYetImplemented("read")}readSync(e){return notYetImplemented("readSync")}numDataIds(){return notYetImplemented("numDataIds")}disposeData(e,t){return notYetImplemented("disposeData")}write(e,t,n){return notYetImplemented("write")}move(e,t,n,r,a){return notYetImplemented("move")}memory(){return notYetImplemented("memory")}floatPrecision(){return notYetImplemented("floatPrecision")}epsilon(){return 32===this.floatPrecision()?EPSILON_FLOAT32$1:EPSILON_FLOAT16$1}dispose(){return notYetImplemented("dispose")}}function notYetImplemented(e){throw new Error(`'${e}' not yet implemented or not found in the registry. This kernel may not be supported by the tfjs backend you have chosen`)}function shuffle(e){let t=e.length,n=0;for(;t>0;)n=Math.random()*t|0,t--,swap(e,t,n)}function shuffleCombo(e,t){if(e.length!==t.length)throw new Error(`Array sizes must match to be shuffled together First array length was ${e.length}Second array length was ${t.length}`);let n=e.length,r=0;for(;n>0;)r=Math.random()*n|0,n--,swap(e,n,r),swap(t,n,r)}function clamp(e,t,n){return Math.max(e,Math.min(t,n))}function nearestLargerEven(e){return e%2==0?e:e+1}function swap(e,t,n){const r=e[t];e[t]=e[n],e[n]=r}function sum$3(e){let t=0;for(let n=0;n<e.length;n++)t+=e[n];return t}function randUniform(e,t){const n=Math.random();return t*n+(1-n)*e}function distSquared(e,t){let n=0;for(let r=0;r<e.length;r++){const a=Number(e[r])-Number(t[r]);n+=a*a}return n}function assert$4(e,t){if(!e)throw new Error("string"==typeof t?t:t())}function assertShapesMatch(e,t,n=""){assert$4(arraysEqual(e,t),()=>n+` Shapes ${e} and ${t} must match`)}function assertNonNull(e){assert$4(null!=e,()=>"The input to the tensor constructor must be a non-null value.")}function flatten$3(e,t=[],n=!1){if(null==t&&(t=[]),Array.isArray(e)||isTypedArray(e)&&!n)for(let r=0;r<e.length;++r)flatten$3(e[r],t,n);else t.push(e);return t}function sizeFromShape(e){if(0===e.length)return 1;let t=e[0];for(let n=1;n<e.length;n++)t*=e[n];return t}function isScalarShape(e){return 0===e.length}function arraysEqual(e,t){if(e===t)return!0;if(null==e||null==t)return!1;if(e.length!==t.length)return!1;for(let n=0;n<e.length;n++)if(e[n]!==t[n])return!1;return!0}function isInt(e){return e%1==0}function tanh$3(e){if(null!=Math.tanh)return Math.tanh(e);if(Infinity===e)return 1;if(-Infinity===e)return-1;{const t=Math.exp(2*e);return(t-1)/(t+1)}}function sizeToSquarishShape(e){const t=Math.ceil(Math.sqrt(e));return[t,Math.ceil(e/t)]}function createShuffledIndices(e){const t=new Uint32Array(e);for(let n=0;n<e;++n)t[n]=n;return shuffle(t),t}function rightPad(e,t){return t<=e.length?e:e+" ".repeat(t-e.length)}function repeatedTry(e,t=(e=>0),n){return new Promise((r,a)=>{let s=0;const o=()=>{if(e())return void r();s++;const i=t(s);null!=n&&s>=n?a():setTimeout(o,i)};o()})}function inferFromImplicitShape(e,t){let n=1,r=-1;for(let t=0;t<e.length;++t)if(e[t]>=0)n*=e[t];else if(-1===e[t]){if(-1!==r)throw Error(`Shapes can only have 1 implicit size. Found -1 at dim ${r} and dim ${t}`);r=t}else if(e[t]<0)throw Error(`Shapes can not be < 0. Found ${e[t]} at dim ${t}`);if(-1===r){if(t>0&&t!==n)throw Error(`Size(${t}) must match the product of shape ${e}`);return e}if(0===n)throw Error(`Cannot infer the missing size in [${e}] when there are 0 elements`);if(t%n!=0)throw Error(`The implicit shape can't be a fractional number. Got ${t} / ${n}`);const a=e.slice();return a[r]=t/n,a}function parseAxisParam(e,t){const n=t.length;return assert$4((e=null==e?t.map((e,t)=>t):[].concat(e)).every(e=>e>=-n&&e<n),()=>`All values in axis param must be in range [-${n}, ${n}) but got axis ${e}`),assert$4(e.every(e=>isInt(e)),()=>`All values in axis param must be integers but got axis ${e}`),e.map(e=>e<0?n+e:e)}function squeezeShape(e,t){const n=[],r=[],a=null!=t&&Array.isArray(t)&&0===t.length,s=null==t||a?null:parseAxisParam(t,e).sort();let o=0;for(let t=0;t<e.length;++t){if(null!=s){if(s[o]===t&&1!==e[t])throw new Error(`Can't squeeze axis ${t} since its dim '${e[t]}' is not 1`);(null==s[o]||s[o]>t)&&1===e[t]&&(n.push(e[t]),r.push(t)),s[o]<=t&&o++}1!==e[t]&&(n.push(e[t]),r.push(t))}return{newShape:n,keptDims:r}}function getTypedArrayFromDType(e,t){let n=null;if(null==e||"float32"===e)n=new Float32Array(t);else if("int32"===e)n=new Int32Array(t);else{if("bool"!==e)throw new Error(`Unknown data type ${e}`);n=new Uint8Array(t)}return n}function getArrayFromDType(e,t){let n=null;if(null==e||"float32"===e)n=new Float32Array(t);else if("int32"===e)n=new Int32Array(t);else if("bool"===e)n=new Uint8Array(t);else{if("string"!==e)throw new Error(`Unknown data type ${e}`);n=new Array(t)}return n}function checkConversionForErrors(e,t){for(let n=0;n<e.length;n++){const r=e[n];if(isNaN(r)||!isFinite(r))throw Error(`A tensor of type ${t} being uploaded contains ${r}.`)}}function isValidDtype(e){return"bool"===e||"complex64"===e||"float32"===e||"int32"===e||"string"===e}function hasEncodingLoss(e,t){return!("complex64"===t||"float32"===t&&"complex64"!==e||"int32"===t&&"float32"!==e&&"complex64"!==e||"bool"===t&&"bool"===e)}function isTypedArray(e){return e instanceof Float32Array||e instanceof Int32Array||e instanceof Uint8Array}function bytesPerElement(e){if("float32"===e||"int32"===e)return 4;if("complex64"===e)return 8;if("bool"===e)return 1;throw new Error(`Unknown dtype ${e}`)}function bytesFromStringArray(e){if(null==e)return 0;let t=0;return e.forEach(e=>t+=e.length),t}function isString(e){return"string"==typeof e||e instanceof String}function isBoolean(e){return"boolean"==typeof e}function isNumber(e){return"number"==typeof e}function inferDtype(e){return Array.isArray(e)?inferDtype(e[0]):e instanceof Float32Array?"float32":e instanceof Int32Array||e instanceof Uint8Array?"int32":isNumber(e)?"float32":isString(e)?"string":isBoolean(e)?"bool":"float32"}function isFunction(e){return!!(e&&e.constructor&&e.call&&e.apply)}function nearestDivisor(e,t){for(let n=t;n<e;++n)if(e%n==0)return n;return e}function computeStrides(e){const t=e.length;if(t<2)return[];const n=new Array(t-1);n[t-2]=e[t-1];for(let r=t-3;r>=0;--r)n[r]=n[r+1]*e[r+1];return n}function createNestedArray(e,t,n,r=!1){const a=new Array;if(1===t.length){const s=t[0]*(r?2:1);for(let t=0;t<s;t++)a[t]=n[e+t]}else{const s=t[0],o=t.slice(1),i=o.reduce((e,t)=>e*t)*(r?2:1);for(let t=0;t<s;t++)a[t]=createNestedArray(e+t*i,o,n,r)}return a}function toNestedArray(e,t,n=!1){if(0===e.length)return t[0];const r=e.reduce((e,t)=>e*t)*(n?2:1);if(0===r)return[];if(r!==t.length)throw new Error(`[${e}] does not match the input size ${t.length}${n?" for a complex tensor":""}.`);return createNestedArray(0,e,t,n)}function makeOnesTypedArray(e,t){const n=makeZerosTypedArray(e,t);for(let e=0;e<n.length;e++)n[e]=1;return n}function makeZerosTypedArray(e,t){if(null==t||"float32"===t||"complex64"===t)return new Float32Array(e);if("int32"===t)return new Int32Array(e);if("bool"===t)return new Uint8Array(e);throw new Error(`Unknown data type ${t}`)}function makeZerosNestedTypedArray(e,t){const n=e.reduce((e,t)=>e*t,1);if(null==t||"float32"===t)return toNestedArray(e,new Float32Array(n));if("int32"===t)return toNestedArray(e,new Int32Array(n));if("bool"===t)return toNestedArray(e,new Uint8Array(n));throw new Error(`Unknown data type ${t}`)}function assertNonNegativeIntegerDimensions(e){e.forEach(t=>{assert$4(Number.isInteger(t)&&t>=0,()=>`Tensor must have a shape comprised of positive integers but got shape [${e}].`)})}function locToIndex(e,t,n){if(0===t)return 0;if(1===t)return e[0];let r=e[e.length-1];for(let t=0;t<e.length-1;++t)r+=n[t]*e[t];return r}function indexToLoc(e,t,n){if(0===t)return[];if(1===t)return[e];const r=new Array(t);for(let t=0;t<r.length-1;++t)r[t]=Math.floor(e/n[t]),e-=r[t]*n[t];return r[r.length-1]=e,r}function isPromise(e){return e&&e.then&&"function"==typeof e.then}const TENSORFLOWJS_FLAGS_PREFIX="tfjsflags";class Environment{constructor(e){this.global=e,this.flags={},this.flagRegistry={},this.urlFlags={},this.getQueryParams=getQueryParams,this.populateURLFlags()}setPlatform(e,t){null!=this.platform&&console.warn(`Platform ${this.platformName} has already been set. Overwriting the platform with ${t}.`),this.platformName=e,this.platform=t}registerFlag(e,t,n){if(this.flagRegistry[e]={evaluationFn:t,setHook:n},null!=this.urlFlags[e]){const t=this.urlFlags[e];console.warn(`Setting feature override from URL ${e}: ${t}.`),this.set(e,t)}}async getAsync(e){return e in this.flags||(this.flags[e]=await this.evaluateFlag(e)),this.flags[e]}get(e){if(e in this.flags)return this.flags[e];const t=this.evaluateFlag(e);if(isPromise(t))throw new Error(`Flag ${e} cannot be synchronously evaluated. Please use getAsync() instead.`);return this.flags[e]=t,this.flags[e]}getNumber(e){return this.get(e)}getBool(e){return this.get(e)}getFlags(){return this.flags}get features(){return this.flags}set(e,t){if(null==this.flagRegistry[e])throw new Error(`Cannot set flag ${e} as it has not been registered.`);this.flags[e]=t,null!=this.flagRegistry[e].setHook&&this.flagRegistry[e].setHook(t)}evaluateFlag(e){if(null==this.flagRegistry[e])throw new Error(`Cannot evaluate flag '${e}': no evaluation function found.`);return this.flagRegistry[e].evaluationFn()}setFlags(e){this.flags=Object.assign({},e)}reset(){this.flags={},this.urlFlags={},this.populateURLFlags()}populateURLFlags(){if(void 0===this.global||void 0===this.global.location||void 0===this.global.location.search)return;const e=this.getQueryParams(this.global.location.search);TENSORFLOWJS_FLAGS_PREFIX in e&&e[TENSORFLOWJS_FLAGS_PREFIX].split(",").forEach(e=>{const[t,n]=e.split(":");this.urlFlags[t]=parseValue(t,n)})}}function getQueryParams(e){const t={};return e.replace(/[?&]([^=?&]+)(?:=([^&]*))?/g,(e,...n)=>(decodeParam(t,n[0],n[1]),n.join("="))),t}function decodeParam(e,t,n){e[decodeURIComponent(t)]=decodeURIComponent(n||"")}function parseValue(e,t){if("true"===(t=t.toLowerCase())||"false"===t)return"true"===t;if(""+ +t===t)return+t;throw new Error(`Could not parse value flag value ${t} for flag ${e}.`)}function env(){return ENV$2}let ENV$2=null,globalNameSpace;function setEnvironmentGlobal(e){ENV$2=e}function getGlobalNamespace(){if(null==globalNameSpace){let e;if("undefined"!=typeof window)e=window;else if("undefined"!=typeof global)e=global;else if("undefined"!=typeof process)e=process;else{if("undefined"==typeof self)throw new Error("Could not find a global object");e=self}globalNameSpace=e}return globalNameSpace}function getGlobalMap(){const e=getGlobalNamespace();return null==e._tfGlobals&&(e._tfGlobals=new Map),e._tfGlobals}function getGlobal(e,t){const n=getGlobalMap();if(n.has(e))return n.get(e);{const r=t();return n.set(e,r),n.get(e)}}const Abs="Abs",Acos="Acos",Acosh="Acosh",Add$1="Add",AddN="AddN",All="All",Any="Any",ArgMax="ArgMax",ArgMin="ArgMin",Asin="Asin",Asinh="Asinh",Atan="Atan",Atanh="Atanh",Atan2="Atan2",AvgPool="AvgPool",AvgPoolGrad="AvgPoolGrad",AvgPool3D="AvgPool3D",AvgPool3DGrad="AvgPool3DGrad",BatchMatMul="BatchMatMul",BatchToSpaceND="BatchToSpaceND",Bincount="Bincount",BroadcastTo="BroadcastTo",Cast="Cast",Ceil="Ceil",ClipByValue="ClipByValue",Complex="Complex",ComplexAbs="ComplexAbs",Concat="Concat",Conv2D$1="Conv2D",Conv2DBackpropFilter="Conv2DBackpropFilter",Conv2DBackpropInput="Conv2DBackpropInput",Conv3D$1="Conv3D",Conv3DBackpropFilterV2="Conv3DBackpropFilterV2",Conv3DBackpropInputV2="Conv3DBackpropInputV2",Cos="Cos",Cosh="Cosh",Cumsum="Cumsum",CropAndResize="CropAndResize",DenseBincount="DenseBincount",DepthToSpace="DepthToSpace",DepthwiseConv2dNative="DepthwiseConv2dNative",DepthwiseConv2dNativeBackpropFilter="DepthwiseConv2dNativeBackpropFilter",DepthwiseConv2dNativeBackpropInput="DepthwiseConv2dNativeBackpropInput",Diag="Diag",Dilation2D="Dilation2D",Dilation2DBackpropInput="Dilation2DBackpropInput",Dilation2DBackpropFilter="Dilation2DBackpropFilter",RealDiv="RealDiv",Einsum="Einsum",Elu$1="Elu",EluGrad="EluGrad",Erf="Erf",Equal="Equal",Exp="Exp",ExpandDims="ExpandDims",Expm1="Expm1",FFT="FFT",Fill="Fill",FlipLeftRight="FlipLeftRight",Floor="Floor",FloorDiv="FloorDiv",FusedBatchNorm="FusedBatchNorm",GatherV2="GatherV2",GatherNd="GatherNd",Greater="Greater",GreaterEqual="GreaterEqual",Identity$1="Identity",IFFT="IFFT",Imag="Imag",IsFinite="IsFinite",IsInf="IsInf",IsNan="IsNan",LeakyRelu="LeakyRelu",Less="Less",LessEqual="LessEqual",LinSpace="LinSpace",Log="Log",Log1p="Log1p",LogicalAnd="LogicalAnd",LogicalNot="LogicalNot",LogicalOr="LogicalOr",LogSoftmax$1="LogSoftmax",LRN="LRN",LRNGrad="LRNGrad",Max="Max",Maximum$1="Maximum",MaxPool="MaxPool",MaxPoolGrad="MaxPoolGrad",MaxPool3D="MaxPool3D",MaxPool3DGrad="MaxPool3DGrad",MaxPoolWithArgmax="MaxPoolWithArgmax",Mean="Mean",Min="Min",Minimum$1="Minimum",MirrorPad="MirrorPad",Mod="Mod",Multinomial="Multinomial",Multiply$1="Multiply",Neg="Neg",NotEqual="NotEqual",NonMaxSuppressionV3="NonMaxSuppressionV3",NonMaxSuppressionV4="NonMaxSuppressionV4",NonMaxSuppressionV5="NonMaxSuppressionV5",OnesLike="OnesLike",OneHot="OneHot",Pack="Pack",PadV2="PadV2",Pool="Pool",Pow="Pow",Prelu="Prelu",Prod="Prod",Range="Range",Real="Real",Reciprocal="Reciprocal",Relu$1="Relu",Reshape$1="Reshape",ResizeNearestNeighbor="ResizeNearestNeighbor",ResizeNearestNeighborGrad="ResizeNearestNeighborGrad",ResizeBilinear="ResizeBilinear",ResizeBilinearGrad="ResizeBilinearGrad",Relu6$1="Relu6",Reverse="Reverse",Round="Round",Rsqrt="Rsqrt",ScatterNd="ScatterNd",Select="Select",Selu$1="Selu",Slice="Slice",Sin="Sin",Sinh="Sinh",Sign="Sign",Sigmoid$1="Sigmoid",Softplus$1="Softplus",Sqrt="Sqrt",Sum="Sum",SpaceToBatchND="SpaceToBatchND",SplitV="SplitV",Softmax$2="Softmax",SparseFillEmptyRows="SparseFillEmptyRows",SparseReshape="SparseReshape",SparseSegmentMean="SparseSegmentMean",SparseSegmentSum="SparseSegmentSum",SparseToDense="SparseToDense",SquaredDifference="SquaredDifference",Square="Square",StridedSlice="StridedSlice",StringNGrams="StringNGrams",StringSplit="StringSplit",StringToHashBucketFast="StringToHashBucketFast",Sub="Sub",Tan="Tan",Tanh$1="Tanh",Tile="Tile",TopK="TopK",Transform="Transform",Transpose="Transpose",Unique="Unique",Unpack="Unpack",UnsortedSegmentSum="UnsortedSegmentSum",ZerosLike="ZerosLike",Step="Step",FromPixels="FromPixels",RotateWithOffset="RotateWithOffset",_FusedMatMul="_FusedMatMul",FusedConv2D="FusedConv2D",FusedDepthwiseConv2D="FusedDepthwiseConv2D",kernelRegistry=getGlobal("kernelRegistry",()=>new Map),gradRegistry=getGlobal("gradRegistry",()=>new Map);function getKernel(e,t){const n=makeKey(e,t);return kernelRegistry.get(n)}function getGradient(e){return gradRegistry.get(e)}function getKernelsForBackend(e){const t=kernelRegistry.entries(),n=[];for(;;){const{done:r,value:a}=t.next();if(r)break;const[s,o]=a,[i]=s.split("_");i===e&&n.push(o)}return n}function registerKernel(e){const{kernelName:t,backendName:n}=e,r=makeKey(t,n);kernelRegistry.has(r)&&console.warn(`The kernel '${t}' for backend '${n}' is already registered`),kernelRegistry.set(r,e)}function registerGradient(e){const{kernelName:t}=e;gradRegistry.has(t)&&env().getBool("DEBUG")&&console.warn(`Overriding the gradient for '${t}'`),gradRegistry.set(t,e)}function unregisterKernel(e,t){const n=makeKey(e,t);if(!kernelRegistry.has(n))throw new Error(`The kernel '${e}' for backend '${t}' is not registered`);kernelRegistry.delete(n)}function unregisterGradient(e){if(!gradRegistry.has(e))throw new Error(`The gradient '${e}' for backend is not registered`);gradRegistry.delete(e)}function copyRegisteredKernels(e,t){getKernelsForBackend(e).forEach(e=>{registerKernel(Object.assign({},e,{backendName:t}))})}function makeKey(e,t){return`${t}_${e}`}var long=Long$1,wasm=null;try{wasm=new WebAssembly.Instance(new WebAssembly.Module(new Uint8Array([0,97,115,109,1,0,0,0,1,13,2,96,0,1,127,96,4,127,127,127,127,1,127,3,7,6,0,1,1,1,1,1,6,6,1,127,1,65,0,11,7,50,6,3,109,117,108,0,1,5,100,105,118,95,115,0,2,5,100,105,118,95,117,0,3,5,114,101,109,95,115,0,4,5,114,101,109,95,117,0,5,8,103,101,116,95,104,105,103,104,0,0,10,191,1,6,4,0,35,0,11,36,1,1,126,32,0,173,32,1,173,66,32,134,132,32,2,173,32,3,173,66,32,134,132,126,34,4,66,32,135,167,36,0,32,4,167,11,36,1,1,126,32,0,173,32,1,173,66,32,134,132,32,2,173,32,3,173,66,32,134,132,127,34,4,66,32,135,167,36,0,32,4,167,11,36,1,1,126,32,0,173,32,1,173,66,32,134,132,32,2,173,32,3,173,66,32,134,132,128,34,4,66,32,135,167,36,0,32,4,167,11,36,1,1,126,32,0,173,32,1,173,66,32,134,132,32,2,173,32,3,173,66,32,134,132,129,34,4,66,32,135,167,36,0,32,4,167,11,36,1,1,126,32,0,173,32,1,173,66,32,134,132,32,2,173,32,3,173,66,32,134,132,130,34,4,66,32,135,167,36,0,32,4,167,11])),{}).exports}catch(e){}function Long$1(e,t,n){this.low=0|e,this.high=0|t,this.unsigned=!!n}function isLong(e){return!0===(e&&e.__isLong__)}Object.defineProperty(Long$1.prototype,"__isLong__",{value:!0}),Long$1.isLong=isLong;var INT_CACHE={},UINT_CACHE={};function fromInt(e,t){var n,r,a;return t?(a=0<=(e>>>=0)&&e<256)&&(r=UINT_CACHE[e])?r:(n=fromBits(e,(0|e)<0?-1:0,!0),a&&(UINT_CACHE[e]=n),n):(a=-128<=(e|=0)&&e<128)&&(r=INT_CACHE[e])?r:(n=fromBits(e,e<0?-1:0,!1),a&&(INT_CACHE[e]=n),n)}function fromNumber(e,t){if(isNaN(e))return t?UZERO:ZERO;if(t){if(e<0)return UZERO;if(e>=TWO_PWR_64_DBL)return MAX_UNSIGNED_VALUE}else{if(e<=-TWO_PWR_63_DBL)return MIN_VALUE;if(e+1>=TWO_PWR_63_DBL)return MAX_VALUE}return e<0?fromNumber(-e,t).neg():fromBits(e%TWO_PWR_32_DBL|0,e/TWO_PWR_32_DBL|0,t)}function fromBits(e,t,n){return new Long$1(e,t,n)}Long$1.fromInt=fromInt,Long$1.fromNumber=fromNumber,Long$1.fromBits=fromBits;var pow_dbl=Math.pow;function fromString(e,t,n){if(0===e.length)throw Error("empty string");if("NaN"===e||"Infinity"===e||"+Infinity"===e||"-Infinity"===e)return ZERO;if("number"==typeof t?(n=t,t=!1):t=!!t,(n=n||10)<2||36<n)throw RangeError("radix");var r;if((r=e.indexOf("-"))>0)throw Error("interior hyphen");if(0===r)return fromString(e.substring(1),t,n).neg();for(var a=fromNumber(pow_dbl(n,8)),s=ZERO,o=0;o<e.length;o+=8){var i=Math.min(8,e.length-o),l=parseInt(e.substring(o,o+i),n);if(i<8){var u=fromNumber(pow_dbl(n,i));s=s.mul(u).add(fromNumber(l))}else s=(s=s.mul(a)).add(fromNumber(l))}return s.unsigned=t,s}function fromValue(e,t){return"number"==typeof e?fromNumber(e,t):"string"==typeof e?fromString(e,t):fromBits(e.low,e.high,"boolean"==typeof t?t:e.unsigned)}Long$1.fromString=fromString,Long$1.fromValue=fromValue;var TWO_PWR_16_DBL=65536,TWO_PWR_24_DBL=1<<24,TWO_PWR_32_DBL=TWO_PWR_16_DBL*TWO_PWR_16_DBL,TWO_PWR_64_DBL=TWO_PWR_32_DBL*TWO_PWR_32_DBL,TWO_PWR_63_DBL=TWO_PWR_64_DBL/2,TWO_PWR_24=fromInt(TWO_PWR_24_DBL),ZERO=fromInt(0);Long$1.ZERO=ZERO;var UZERO=fromInt(0,!0);Long$1.UZERO=UZERO;var ONE=fromInt(1);Long$1.ONE=ONE;var UONE=fromInt(1,!0);Long$1.UONE=UONE;var NEG_ONE=fromInt(-1);Long$1.NEG_ONE=NEG_ONE;var MAX_VALUE=fromBits(-1,2147483647,!1);Long$1.MAX_VALUE=MAX_VALUE;var MAX_UNSIGNED_VALUE=fromBits(-1,-1,!0);Long$1.MAX_UNSIGNED_VALUE=MAX_UNSIGNED_VALUE;var MIN_VALUE=fromBits(0,-2147483648,!1);Long$1.MIN_VALUE=MIN_VALUE;var LongPrototype=Long$1.prototype;LongPrototype.toInt=function(){return this.unsigned?this.low>>>0:this.low},LongPrototype.toNumber=function(){return this.unsigned?(this.high>>>0)*TWO_PWR_32_DBL+(this.low>>>0):this.high*TWO_PWR_32_DBL+(this.low>>>0)},LongPrototype.toString=function(e){if((e=e||10)<2||36<e)throw RangeError("radix");if(this.isZero())return"0";if(this.isNegative()){if(this.eq(MIN_VALUE)){var t=fromNumber(e),n=this.div(t),r=n.mul(t).sub(this);return n.toString(e)+r.toInt().toString(e)}return"-"+this.neg().toString(e)}for(var a=fromNumber(pow_dbl(e,6),this.unsigned),s=this,o="";;){var i=s.div(a),l=(s.sub(i.mul(a)).toInt()>>>0).toString(e);if((s=i).isZero())return l+o;for(;l.length<6;)l="0"+l;o=""+l+o}},LongPrototype.getHighBits=function(){return this.high},LongPrototype.getHighBitsUnsigned=function(){return this.high>>>0},LongPrototype.getLowBits=function(){return this.low},LongPrototype.getLowBitsUnsigned=function(){return this.low>>>0},LongPrototype.getNumBitsAbs=function(){if(this.isNegative())return this.eq(MIN_VALUE)?64:this.neg().getNumBitsAbs();for(var e=0!=this.high?this.high:this.low,t=31;t>0&&0==(e&1<<t);t--);return 0!=this.high?t+33:t+1},LongPrototype.isZero=function(){return 0===this.high&&0===this.low},LongPrototype.eqz=LongPrototype.isZero,LongPrototype.isNegative=function(){return!this.unsigned&&this.high<0},LongPrototype.isPositive=function(){return this.unsigned||this.high>=0},LongPrototype.isOdd=function(){return 1==(1&this.low)},LongPrototype.isEven=function(){return 0==(1&this.low)},LongPrototype.equals=function(e){return isLong(e)||(e=fromValue(e)),(this.unsigned===e.unsigned||this.high>>>31!=1||e.high>>>31!=1)&&this.high===e.high&&this.low===e.low},LongPrototype.eq=LongPrototype.equals,LongPrototype.notEquals=function(e){return!this.eq(e)},LongPrototype.neq=LongPrototype.notEquals,LongPrototype.ne=LongPrototype.notEquals,LongPrototype.lessThan=function(e){return this.comp(e)<0},LongPrototype.lt=LongPrototype.lessThan,LongPrototype.lessThanOrEqual=function(e){return this.comp(e)<=0},LongPrototype.lte=LongPrototype.lessThanOrEqual,LongPrototype.le=LongPrototype.lessThanOrEqual,LongPrototype.greaterThan=function(e){return this.comp(e)>0},LongPrototype.gt=LongPrototype.greaterThan,LongPrototype.greaterThanOrEqual=function(e){return this.comp(e)>=0},LongPrototype.gte=LongPrototype.greaterThanOrEqual,LongPrototype.ge=LongPrototype.greaterThanOrEqual,LongPrototype.compare=function(e){if(isLong(e)||(e=fromValue(e)),this.eq(e))return 0;var t=this.isNegative(),n=e.isNegative();return t&&!n?-1:!t&&n?1:this.unsigned?e.high>>>0>this.high>>>0||e.high===this.high&&e.low>>>0>this.low>>>0?-1:1:this.sub(e).isNegative()?-1:1},LongPrototype.comp=LongPrototype.compare,LongPrototype.negate=function(){return!this.unsigned&&this.eq(MIN_VALUE)?MIN_VALUE:this.not().add(ONE)},LongPrototype.neg=LongPrototype.negate,LongPrototype.add=function(e){isLong(e)||(e=fromValue(e));var t=0,n=0,r=0,a=0;return r+=(a+=(65535&this.low)+(65535&e.low))>>>16,n+=(r+=(this.low>>>16)+(e.low>>>16))>>>16,t+=(n+=(65535&this.high)+(65535&e.high))>>>16,t+=(this.high>>>16)+(e.high>>>16),fromBits((r&=65535)<<16|(a&=65535),(t&=65535)<<16|(n&=65535),this.unsigned)},LongPrototype.subtract=function(e){return isLong(e)||(e=fromValue(e)),this.add(e.neg())},LongPrototype.sub=LongPrototype.subtract,LongPrototype.multiply=function(e){if(this.isZero())return ZERO;if(isLong(e)||(e=fromValue(e)),wasm)return fromBits(wasm.mul(this.low,this.high,e.low,e.high),wasm.get_high(),this.unsigned);if(e.isZero())return ZERO;if(this.eq(MIN_VALUE))return e.isOdd()?MIN_VALUE:ZERO;if(e.eq(MIN_VALUE))return this.isOdd()?MIN_VALUE:ZERO;if(this.isNegative())return e.isNegative()?this.neg().mul(e.neg()):this.neg().mul(e).neg();if(e.isNegative())return this.mul(e.neg()).neg();if(this.lt(TWO_PWR_24)&&e.lt(TWO_PWR_24))return fromNumber(this.toNumber()*e.toNumber(),this.unsigned);var t=65535&this.high,n=this.low>>>16,r=65535&this.low,a=65535&e.high,s=e.low>>>16,o=65535&e.low,i=0,l=0,u=0,c=0;return u+=(c+=r*o)>>>16,l+=(u+=n*o)>>>16,u&=65535,l+=(u+=r*s)>>>16,i+=(l+=t*o)>>>16,l&=65535,i+=(l+=n*s)>>>16,l&=65535,i+=(l+=r*a)>>>16,i+=(this.high>>>16)*o+t*s+n*a+r*(e.high>>>16),fromBits((u&=65535)<<16|(c&=65535),(i&=65535)<<16|(l&=65535),this.unsigned)},LongPrototype.mul=LongPrototype.multiply,LongPrototype.divide=function(e){if(isLong(e)||(e=fromValue(e)),e.isZero())throw Error("division by zero");var t,n,r;if(wasm)return this.unsigned||-2147483648!==this.high||-1!==e.low||-1!==e.high?fromBits((this.unsigned?wasm.div_u:wasm.div_s)(this.low,this.high,e.low,e.high),wasm.get_high(),this.unsigned):this;if(this.isZero())return this.unsigned?UZERO:ZERO;if(this.unsigned){if(e.unsigned||(e=e.toUnsigned()),e.gt(this))return UZERO;if(e.gt(this.shru(1)))return UONE;r=UZERO}else{if(this.eq(MIN_VALUE))return e.eq(ONE)||e.eq(NEG_ONE)?MIN_VALUE:e.eq(MIN_VALUE)?ONE:(t=this.shr(1).div(e).shl(1)).eq(ZERO)?e.isNegative()?ONE:NEG_ONE:(n=this.sub(e.mul(t)),r=t.add(n.div(e)));if(e.eq(MIN_VALUE))return this.unsigned?UZERO:ZERO;if(this.isNegative())return e.isNegative()?this.neg().div(e.neg()):this.neg().div(e).neg();if(e.isNegative())return this.div(e.neg()).neg();r=ZERO}for(n=this;n.gte(e);){t=Math.max(1,Math.floor(n.toNumber()/e.toNumber()));for(var a=Math.ceil(Math.log(t)/Math.LN2),s=a<=48?1:pow_dbl(2,a-48),o=fromNumber(t),i=o.mul(e);i.isNegative()||i.gt(n);)i=(o=fromNumber(t-=s,this.unsigned)).mul(e);o.isZero()&&(o=ONE),r=r.add(o),n=n.sub(i)}return r},LongPrototype.div=LongPrototype.divide,LongPrototype.modulo=function(e){return isLong(e)||(e=fromValue(e)),wasm?fromBits((this.unsigned?wasm.rem_u:wasm.rem_s)(this.low,this.high,e.low,e.high),wasm.get_high(),this.unsigned):this.sub(this.div(e).mul(e))},LongPrototype.mod=LongPrototype.modulo,LongPrototype.rem=LongPrototype.modulo,LongPrototype.not=function(){return fromBits(~this.low,~this.high,this.unsigned)},LongPrototype.and=function(e){return isLong(e)||(e=fromValue(e)),fromBits(this.low&e.low,this.high&e.high,this.unsigned)},LongPrototype.or=function(e){return isLong(e)||(e=fromValue(e)),fromBits(this.low|e.low,this.high|e.high,this.unsigned)},LongPrototype.xor=function(e){return isLong(e)||(e=fromValue(e)),fromBits(this.low^e.low,this.high^e.high,this.unsigned)},LongPrototype.shiftLeft=function(e){return isLong(e)&&(e=e.toInt()),0==(e&=63)?this:e<32?fromBits(this.low<<e,this.high<<e|this.low>>>32-e,this.unsigned):fromBits(0,this.low<<e-32,this.unsigned)},LongPrototype.shl=LongPrototype.shiftLeft,LongPrototype.shiftRight=function(e){return isLong(e)&&(e=e.toInt()),0==(e&=63)?this:e<32?fromBits(this.low>>>e|this.high<<32-e,this.high>>e,this.unsigned):fromBits(this.high>>e-32,this.high>=0?0:-1,this.unsigned)},LongPrototype.shr=LongPrototype.shiftRight,LongPrototype.shiftRightUnsigned=function(e){if(isLong(e)&&(e=e.toInt()),0==(e&=63))return this;var t=this.high;return e<32?fromBits(this.low>>>e|t<<32-e,t>>>e,this.unsigned):fromBits(32===e?t:t>>>e-32,0,this.unsigned)},LongPrototype.shru=LongPrototype.shiftRightUnsigned,LongPrototype.shr_u=LongPrototype.shiftRightUnsigned,LongPrototype.toSigned=function(){return this.unsigned?fromBits(this.low,this.high,!1):this},LongPrototype.toUnsigned=function(){return this.unsigned?this:fromBits(this.low,this.high,!0)},LongPrototype.toBytes=function(e){return e?this.toBytesLE():this.toBytesBE()},LongPrototype.toBytesLE=function(){var e=this.high,t=this.low;return[255&t,t>>>8&255,t>>>16&255,t>>>24,255&e,e>>>8&255,e>>>16&255,e>>>24]},LongPrototype.toBytesBE=function(){var e=this.high,t=this.low;return[e>>>24,e>>>16&255,e>>>8&255,255&e,t>>>24,t>>>16&255,t>>>8&255,255&t]},Long$1.fromBytes=function(e,t,n){return n?Long$1.fromBytesLE(e,t):Long$1.fromBytesBE(e,t)},Long$1.fromBytesLE=function(e,t){return new Long$1(e[0]|e[1]<<8|e[2]<<16|e[3]<<24,e[4]|e[5]<<8|e[6]<<16|e[7]<<24,t)},Long$1.fromBytesBE=function(e,t){return new Long$1(e[4]<<24|e[5]<<16|e[6]<<8|e[7],e[0]<<24|e[1]<<16|e[2]<<8|e[3],t)};var long$1=long,LongExports=/*#__PURE__*/Object.assign(/*#__PURE__*/Object.create(null),long,{default:long$1});const Long=long$1||LongExports;function hexToLong(e){return Long.fromString(e,!0,16)}const k0=hexToLong("c3a5c85c97cb3127"),k1=hexToLong("b492b66fbe98f273"),k2=hexToLong("9ae16a3b2f90404f");function shiftMix(e){return e.xor(e.shru(47))}function fetch$2(e,t,n){const r=e.slice(t,t+n);return Long.fromBytes(Array.from(r),!0,!0)}function fetch64(e,t){return fetch$2(e,t,8)}function fetch32(e,t){return fetch$2(e,t,4)}function rotate64(e,t){return 0===t?e:e.shru(t).or(e.shl(64-t))}function hashLen16(e,t,n=hexToLong("9ddfea08eb382d69")){let r=e.xor(t).mul(n);r=r.xor(r.shru(47));let a=t.xor(r).mul(n);return a=a.xor(a.shru(47)),a=a.mul(n),a}function weakHashLen32WithSeeds(e,t,n,r,a,s){a=a.add(e),s=rotate64(s.add(a).add(r),21);const o=a;return a=(a=a.add(t)).add(n),s=s.add(rotate64(a,44)),[a.add(r),s.add(o)]}function weakHashLen32WithSeedsStr(e,t,n,r){return weakHashLen32WithSeeds(fetch64(e,t),fetch64(e,t+8),fetch64(e,t+16),fetch64(e,t+24),n,r)}function hashLen0to16(e,t=e.length){if(t>=8){const n=k2.add(2*t),r=fetch64(e,0).add(k2),a=fetch64(e,t-8);return hashLen16(rotate64(a,37).mul(n).add(r),rotate64(r,25).add(a).mul(n),n)}if(t>=4){const n=k2.add(2*t);return hashLen16(fetch32(e,0).shl(3).add(t),fetch32(e,t-4),n)}if(t>0){const n=t+(e[t-1]<<2);return shiftMix(k2.mul(e[0]+(e[t>>1]<<8)).xor(k0.mul(n))).mul(k2)}return k2}function hashLen17to32(e,t=e.length){const n=k2.add(2*t),r=fetch64(e,0).mul(k1),a=fetch64(e,8),s=fetch64(e,t-8).mul(n),o=fetch64(e,t-16).mul(k2);return hashLen16(rotate64(r.add(a),43).add(rotate64(s,30)).add(o),r.add(rotate64(a.add(k2),18)).add(s),n)}function hashLen33to64(e,t=e.length){const n=k2.add(2*t),r=fetch64(e,0).mul(k2),a=fetch64(e,8),s=fetch64(e,t-8).mul(n),o=fetch64(e,t-16).mul(k2),i=rotate64(r.add(a),43).add(rotate64(s,30)).add(o),l=hashLen16(i,r.add(rotate64(a.add(k2),18)).add(s),n),u=fetch64(e,16).mul(n),c=fetch64(e,24),p=i.add(fetch64(e,t-32)).mul(n),d=l.add(fetch64(e,t-24)).mul(n);return hashLen16(rotate64(u.add(c),43).add(rotate64(p,30)).add(d),u.add(rotate64(c.add(r),18)).add(p),n)}function fingerPrint64(e,t=e.length){const n=Long.fromNumber(81,!0);if(t<=32)return t<=16?hashLen0to16(e,t):hashLen17to32(e,t);if(t<=64)return hashLen33to64(e,t);let r=n,a=n.mul(k1).add(113),s=shiftMix(a.mul(k2).add(113)).mul(k2),o=[Long.UZERO,Long.UZERO],i=[Long.UZERO,Long.UZERO];r=r.mul(k2).add(fetch64(e,0));let l=0;const u=64*(t-1>>6),c=u+(t-1&63)-63;do{r=rotate64(r.add(a).add(o[0]).add(fetch64(e,l+8)),37).mul(k1),a=rotate64(a.add(o[1]).add(fetch64(e,l+48)),42).mul(k1),r=r.xor(i[1]),a=a.add(o[0]).add(fetch64(e,l+40)),s=rotate64(s.add(i[0]),33).mul(k1),o=weakHashLen32WithSeedsStr(e,l,o[1].mul(k1),r.add(i[0])),i=weakHashLen32WithSeedsStr(e,l+32,s.add(i[1]),a.add(fetch64(e,l+16))),[s,r]=[r,s],l+=64}while(l!==u);const p=k1.add(s.and(255).shl(1));return l=c,i[0]=i[0].add(t-1&63),o[0]=o[0].add(i[0]),i[0]=i[0].add(o[0]),r=rotate64(r.add(a).add(o[0]).add(fetch64(e,l+8)),37).mul(p),a=rotate64(a.add(o[1]).add(fetch64(e,l+48)),42).mul(p),r=r.xor(i[1].mul(9)),a=a.add(o[0].mul(9).add(fetch64(e,l+40))),s=rotate64(s.add(i[0]),33).mul(p),o=weakHashLen32WithSeedsStr(e,l,o[1].mul(p),r.add(i[0])),i=weakHashLen32WithSeedsStr(e,l+32,s.add(i[1]),a.add(fetch64(e,l+16))),[s,r]=[r,s],hashLen16(hashLen16(o[0],i[0],p).add(shiftMix(a).mul(k0)).add(s),hashLen16(o[1],i[1],p).add(r),p)}function createScalarValue(e,t){return"string"===t?encodeString(e):toTypedArray([e],t)}function noConversionNeeded(e,t){return e instanceof Float32Array&&"float32"===t||e instanceof Int32Array&&"int32"===t||e instanceof Uint8Array&&"bool"===t}function toTypedArray(e,t){if("string"===t)throw new Error("Cannot convert a string[] to a TypedArray");if(Array.isArray(e)&&(e=flatten$3(e)),env().getBool("DEBUG")&&checkConversionForErrors(e,t),noConversionNeeded(e,t))return e;if(null==t||"float32"===t||"complex64"===t)return new Float32Array(e);if("int32"===t)return new Int32Array(e);if("bool"===t){const t=new Uint8Array(e.length);for(let n=0;n<t.length;++n)0!==Math.round(e[n])&&(t[n]=1);return t}throw new Error(`Unknown data type ${t}`)}function now(){return env().platform.now()}function fetch$1(e,t){return env().platform.fetch(e,t)}function encodeString(e,t="utf-8"){return t=t||"utf-8",env().platform.encode(e,t)}function decodeString(e,t="utf-8"){return t=t||"utf-8",env().platform.decode(e,t)}var util={__proto__:null,createScalarValue,toTypedArray,now,fetch:fetch$1,encodeString,decodeString,shuffle,shuffleCombo,clamp,nearestLargerEven,swap,sum:sum$3,randUniform,distSquared,assert:assert$4,assertShapesMatch,assertNonNull,flatten:flatten$3,sizeFromShape,isScalarShape,arraysEqual,isInt,tanh:tanh$3,sizeToSquarishShape,createShuffledIndices,rightPad,repeatedTry,inferFromImplicitShape,parseAxisParam,squeezeShape,getTypedArrayFromDType,getArrayFromDType,checkConversionForErrors,isValidDtype,hasEncodingLoss,isTypedArray,bytesPerElement,bytesFromStringArray,isString,isBoolean,isNumber,inferDtype,isFunction,nearestDivisor,computeStrides,toNestedArray,makeOnesTypedArray,makeZerosTypedArray,makeZerosNestedTypedArray,assertNonNegativeIntegerDimensions,locToIndex,indexToLoc,isPromise,hexToLong,fingerPrint64};class Profiler{constructor(e,t){this.backendTimer=e,this.logger=t,null==t&&(this.logger=new Logger)}profileKernel(e,t,n){let r;const a=()=>{r=n()};let s;const o=now();if(this.backendTimer.timerAvailable())s=this.backendTimer.time(a);else{a();for(const e of r)e.dataSync();s=Promise.resolve({kernelMs:now()-o})}if(env().getBool("CHECK_COMPUTATION_FOR_ERRORS"))for(let t=0;t<r.length;t++){const n=r[t];n.data().then(t=>{checkComputationForErrors(t,n.dtype,e)})}return{kernelName:e,outputs:r,inputs:t,timeMs:s.then(e=>e.kernelMs),extraInfo:s.then(e=>null!=e.getExtraProfileInfo?e.getExtraProfileInfo():"")}}logKernelProfile(e){const{kernelName:t,outputs:n,timeMs:r,inputs:a,extraInfo:s}=e;n.forEach(e=>{Promise.all([e.data(),r,s]).then(n=>{this.logger.logKernelProfile(t,e,n[0],n[1],a,n[2])})})}}function checkComputationForErrors(e,t,n){if("float32"!==t)return!1;for(let t=0;t<e.length;t++){const r=e[t];if(isNaN(r)||!isFinite(r))return console.warn(`Found ${r} in the result of '${n}'`),!0}return!1}class Logger{logKernelProfile(e,t,n,r,a,s){const o="number"==typeof r?rightPad(`${r}ms`,9):r.error,i=rightPad(e,25),l=t.rank,u=t.size,c=rightPad(t.shape.toString(),14);let p="";for(const e in a){const n=a[e];if(null!=n){const r=n.shape||t.shape,a=r.length;p+=`${e}: ${a}D ${a>0?r:""} `}}console.log(`%c${i}\t%c${o}\t%c${l}D ${c}\t%c${u}\t%c${p}\t%c${s}`,"font-weight:bold","color:red","color:blue","color: orange","color: green","color: steelblue")}}function getFilteredNodesXToY(e,t,n){const r={},a={};for(let e=0;e<t.length;e++)r[t[e].id]=!0;for(let n=0;n<e.length;n++){const s=e[n],o=s.inputs;for(const e in o){const n=o[e];let i=!1;for(let e=0;e<t.length;e++)if(r[n.id]){s.outputs.forEach(e=>r[e.id]=!0),i=!0,a[s.id]=!0;break}if(i)break}}const s={};s[n.id]=!0;const o={};for(let t=e.length-1;t>=0;t--){const n=e[t],r=n.inputs;for(let e=0;e<n.outputs.length;e++)if(s[n.outputs[e].id]){for(const e in r)s[r[e].id]=!0,o[n.id]=!0;break}}const i=[];for(let t=0;t<e.length;t++){const n=e[t];if(a[n.id]&&o[n.id]){const e={};for(const t in n.inputs){const a=n.inputs[t];r[a.id]&&(e[t]=a)}const t=Object.assign({},n);t.inputs=e,t.outputs=n.outputs,i.push(t)}}return i}function backpropagateGradients(e,t,n,r){for(let a=t.length-1;a>=0;a--){const s=t[a],o=[];if(s.outputs.forEach(t=>{const n=e[t.id];o.push(null!=n?n:null)}),null==s.gradient)throw new Error(`Cannot compute gradient: gradient function not found for ${s.kernelName}.`);const i=s.gradient(o);for(const t in s.inputs){if(!(t in i))throw new Error(`Cannot backprop through input ${t}. Available gradients found: ${Object.keys(i)}.`);const a=n(()=>i[t]());if("float32"!==a.dtype)throw new Error(`Error in gradient for op ${s.kernelName}. The gradient of input ${t} must have 'float32' dtype, but has '${a.dtype}'`);const o=s.inputs[t];if(!arraysEqual(a.shape,o.shape))throw new Error(`Error in gradient for op ${s.kernelName}. The gradient of input '${t}' has shape '${a.shape}', which does not match the shape of the input '${o.shape}'`);if(null==e[o.id])e[o.id]=a;else{const t=e[o.id];e[o.id]=r(t,a),t.dispose()}}}}const FORMAT_LIMIT_NUM_VALS=20,FORMAT_NUM_FIRST_LAST_VALS=3,FORMAT_NUM_SIG_DIGITS=7;function tensorToString(e,t,n,r){const a=computeStrides(t),s=computeMaxSizePerColumn(e,t,n,a),o=t.length,i=subTensorToString(e,t,n,a,s),l=["Tensor"];return r&&(l.push(`  dtype: ${n}`),l.push(`  rank: ${o}`),l.push(`  shape: [${t}]`),l.push("  values:")),l.push(i.map(e=>"    "+e).join("\n")),l.join("\n")}function computeMaxSizePerColumn(e,t,n,r){const a=sizeFromShape(t),s=r[r.length-1],o=new Array(s).fill(0),i=t.length,l="complex64"===n?createComplexTuples(e):e;if(i>1)for(let e=0;e<a/s;e++){const t=e*s;for(let e=0;e<s;e++)o[e]=Math.max(o[e],valToString(l[t+e],0,n).length)}return o}function valToString(e,t,n){let r;return r=Array.isArray(e)?`${parseFloat(e[0].toFixed(FORMAT_NUM_SIG_DIGITS))} + ${parseFloat(e[1].toFixed(FORMAT_NUM_SIG_DIGITS))}j`:isString(e)?`'${e}'`:"bool"===n?boolNumToString(e):parseFloat(e.toFixed(FORMAT_NUM_SIG_DIGITS)).toString(),rightPad(r,t)}function boolNumToString(e){return 0===e?"false":"true"}function subTensorToString(e,t,n,r,a,s=!0){const o="complex64"===n?2:1,i=t[0],l=t.length;if(0===l)return"complex64"===n?[valToString(createComplexTuples(e)[0],0,n)]:"bool"===n?[boolNumToString(e[0])]:[e[0].toString()];if(1===l){if(i>FORMAT_LIMIT_NUM_VALS){let t=Array.from(e.slice(0,FORMAT_NUM_FIRST_LAST_VALS*o)),r=Array.from(e.slice((i-FORMAT_NUM_FIRST_LAST_VALS)*o,i*o));return"complex64"===n&&(t=createComplexTuples(t),r=createComplexTuples(r)),["["+t.map((e,t)=>valToString(e,a[t],n)).join(", ")+", ..., "+r.map((e,t)=>valToString(e,a[i-FORMAT_NUM_FIRST_LAST_VALS+t],n)).join(", ")+"]"]}return["["+("complex64"===n?createComplexTuples(e):Array.from(e)).map((e,t)=>valToString(e,a[t],n)).join(", ")+"]"]}const u=t.slice(1),c=r.slice(1),p=r[0]*o,d=[];if(i>FORMAT_LIMIT_NUM_VALS){for(let t=0;t<FORMAT_NUM_FIRST_LAST_VALS;t++){const r=t*p;d.push(...subTensorToString(e.slice(r,r+p),u,n,c,a,!1))}d.push("...");for(let t=i-FORMAT_NUM_FIRST_LAST_VALS;t<i;t++){const r=t*p;d.push(...subTensorToString(e.slice(r,r+p),u,n,c,a,t===i-1))}}else for(let t=0;t<i;t++){const r=t*p;d.push(...subTensorToString(e.slice(r,r+p),u,n,c,a,t===i-1))}const h=2===l?",":"";d[0]="["+d[0]+h;for(let e=1;e<d.length-1;e++)d[e]=" "+d[e]+h;let m=",\n";for(let e=2;e<l;e++)m+="\n";return d[d.length-1]=" "+d[d.length-1]+"]"+(s?"":m),d}function createComplexTuples(e){const t=[];for(let n=0;n<e.length;n+=2)t.push([e[n],e[n+1]]);return t}class TensorBuffer{constructor(e,t,n){if(this.dtype=t,this.shape=e.slice(),this.size=sizeFromShape(e),null!=n){const e=n.length;assert$4(e===this.size,()=>`Length of values '${e}' does not match the size inferred by the shape '${this.size}'.`)}if("complex64"===t)throw new Error("complex64 dtype TensorBuffers are not supported. Please create a TensorBuffer for the real and imaginary parts separately and call tf.complex(real, imag).");this.values=n||getArrayFromDType(t,this.size),this.strides=computeStrides(e)}set(e,...t){0===t.length&&(t=[0]),assert$4(t.length===this.rank,()=>`The number of provided coordinates (${t.length}) must match the rank (${this.rank})`);const n=this.locToIndex(t);this.values[n]=e}get(...e){0===e.length&&(e=[0]);let t=0;for(const n of e){if(n<0||n>=this.shape[t])throw new Error(`Requested out of range element at ${e}.   Buffer shape=${this.shape}`);t++}let n=e[e.length-1];for(let t=0;t<e.length-1;++t)n+=this.strides[t]*e[t];return this.values[n]}locToIndex(e){if(0===this.rank)return 0;if(1===this.rank)return e[0];let t=e[e.length-1];for(let n=0;n<e.length-1;++n)t+=this.strides[n]*e[n];return t}indexToLoc(e){if(0===this.rank)return[];if(1===this.rank)return[e];const t=new Array(this.shape.length);for(let n=0;n<t.length-1;++n)t[n]=Math.floor(e/this.strides[n]),e-=t[n]*this.strides[n];return t[t.length-1]=e,t}get rank(){return this.shape.length}toTensor(){return trackerFn().makeTensor(this.values,this.shape,this.dtype)}}let trackerFn=null,opHandler$1=null;function setTensorTracker(e){trackerFn=e}function setOpHandler(e){opHandler$1=e}class Tensor{constructor(e,t,n,r){this.kept=!1,this.isDisposedInternal=!1,this.shape=e.slice(),this.dtype=t||"float32",this.size=sizeFromShape(e),this.strides=computeStrides(e),this.dataId=n,this.id=r,this.rankType=this.rank<5?this.rank.toString():"higher"}get rank(){return this.shape.length}async buffer(){const e=await this.data();return opHandler$1.buffer(this.shape,this.dtype,e)}bufferSync(){return opHandler$1.buffer(this.shape,this.dtype,this.dataSync())}async array(){const e=await this.data();return toNestedArray(this.shape,e,"complex64"===this.dtype)}arraySync(){return toNestedArray(this.shape,this.dataSync(),"complex64"===this.dtype)}async data(){this.throwIfDisposed();const e=trackerFn().read(this.dataId);if("string"===this.dtype){const t=await e;try{return t.map(e=>decodeString(e))}catch(e){throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().")}}return e}dataSync(){this.throwIfDisposed();const e=trackerFn().readSync(this.dataId);if("string"===this.dtype)try{return e.map(e=>decodeString(e))}catch(e){throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().")}return e}async bytes(){this.throwIfDisposed();const e=await trackerFn().read(this.dataId);return"string"===this.dtype?e:new Uint8Array(e.buffer)}dispose(){this.isDisposed||(trackerFn().disposeTensor(this),this.isDisposedInternal=!0)}get isDisposed(){return this.isDisposedInternal}throwIfDisposed(){if(this.isDisposed)throw new Error("Tensor is disposed.")}print(e=!1){return opHandler$1.print(this,e)}clone(){return this.throwIfDisposed(),opHandler$1.clone(this)}toString(e=!1){return tensorToString(this.dataSync(),this.shape,this.dtype,e)}cast(e){return this.throwIfDisposed(),opHandler$1.cast(this,e)}variable(e=!0,t,n){return this.throwIfDisposed(),trackerFn().makeVariable(this,e,t,n)}}function getGlobalTensorClass(){return getGlobal("Tensor",()=>Tensor)}Object.defineProperty(Tensor,Symbol.hasInstance,{value:e=>!!e&&null!=e.data&&null!=e.dataSync&&null!=e.throwIfDisposed}),getGlobalTensorClass();class Variable extends Tensor{constructor(e,t,n,r){super(e.shape,e.dtype,e.dataId,r),this.trainable=t,this.name=n}assign(e){if(e.dtype!==this.dtype)throw new Error(`dtype of the new value (${e.dtype}) and previous value (${this.dtype}) must match`);if(!arraysEqual(e.shape,this.shape))throw new Error(`shape of the new value (${e.shape}) and previous value (${this.shape}) must match`);trackerFn().disposeTensor(this),this.dataId=e.dataId,trackerFn().incRef(this,null)}dispose(){trackerFn().disposeVariable(this),this.isDisposedInternal=!0}}var Rank,UpcastInt32AndMap,UpcastBoolAndMap,UpcastFloat32AndMap,UpcastComplex64AndMap;Object.defineProperty(Variable,Symbol.hasInstance,{value:e=>e instanceof Tensor&&null!=e.assign&&e.assign instanceof Function}),function(e){e.R0="R0",e.R1="R1",e.R2="R2",e.R3="R3",e.R4="R4",e.R5="R5",e.R6="R6"}(Rank||(Rank={})),function(e){e.float32="float32",e.int32="int32",e.bool="int32",e.complex64="complex64"}(UpcastInt32AndMap||(UpcastInt32AndMap={})),function(e){e.float32="float32",e.int32="int32",e.bool="bool",e.complex64="complex64"}(UpcastBoolAndMap||(UpcastBoolAndMap={})),function(e){e.float32="float32",e.int32="float32",e.bool="float32",e.complex64="complex64"}(UpcastFloat32AndMap||(UpcastFloat32AndMap={})),function(e){e.float32="complex64",e.int32="complex64",e.bool="complex64",e.complex64="complex64"}(UpcastComplex64AndMap||(UpcastComplex64AndMap={}));const upcastTypeMap={float32:UpcastFloat32AndMap,int32:UpcastInt32AndMap,bool:UpcastBoolAndMap,complex64:UpcastComplex64AndMap};function upcastType(e,t){if("string"===e||"string"===t){if("string"===e&&"string"===t)return"string";throw new Error(`Can not upcast ${e} with ${t}`)}return upcastTypeMap[e][t]}function sumOutType(e){return upcastType(e,"int32")}function makeTypesMatch(e,t){if(e.dtype===t.dtype)return[e,t];const n=upcastType(e.dtype,t.dtype);return[e.cast(n),t.cast(n)]}function assertTypesMatch(e,t){assert$4(e.dtype===t.dtype,()=>`The dtypes of the first(${e.dtype}) and second(${t.dtype}) input must match`)}function isTensorInList(e,t){return t.some(t=>t.id===e.id)}function getTensorsInContainer(e){const t=[];return walkTensorContainer(e,t,new Set),t}function walkTensorContainer(e,t,n){if(null==e)return;if(e instanceof Tensor)return void t.push(e);if(!isIterable$1(e))return;const r=e;for(const e in r){const a=r[e];n.has(a)||(n.add(a),walkTensorContainer(a,t,n))}}function isIterable$1(e){return Array.isArray(e)||"object"==typeof e}var tensor_util={__proto__:null,makeTypesMatch,assertTypesMatch,isTensorInList,getTensorsInContainer};function isRegisteredKernelInvocation(e){return null!=e.kernelName}class EngineState{constructor(){this.registeredVariables={},this.nextTapeNodeId=0,this.numBytes=0,this.numTensors=0,this.numStringTensors=0,this.numDataBuffers=0,this.gradientDepth=0,this.kernelDepth=0,this.scopeStack=[],this.numDataMovesStack=[],this.nextScopeId=0,this.tensorInfo=new WeakMap,this.profiling=!1,this.activeProfile={newBytes:0,newTensors:0,peakBytes:0,kernels:[],result:null,get kernelNames(){return Array.from(new Set(this.kernels.map(e=>e.name)))}}}dispose(){for(const e in this.registeredVariables)this.registeredVariables[e].dispose()}}class Engine{constructor(e){this.ENV=e,this.registry={},this.registryFactory={},this.pendingBackendInitId=0,this.state=new EngineState}async ready(){if(null!=this.pendingBackendInit)return this.pendingBackendInit.then(()=>{});if(null!=this.backendInstance)return;const e=this.getSortedBackends();for(let t=0;t<e.length;t++){const n=e[t];if(await this.initializeBackend(n).success)return void await this.setBackend(n)}throw new Error("Could not initialize any backends, all backend initializations failed.")}get backend(){if(null!=this.pendingBackendInit)throw new Error(`Backend '${this.backendName}' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods`);if(null==this.backendInstance){const{name:e,asyncInit:t}=this.initializeBackendsAndReturnBest();if(t)throw new Error(`The highest priority backend '${e}' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods`);this.setBackend(e)}return this.backendInstance}backendNames(){return Object.keys(this.registryFactory)}findBackend(e){if(!(e in this.registry)){if(!(e in this.registryFactory))return null;{const{asyncInit:t}=this.initializeBackend(e);if(t)return null}}return this.registry[e]}findBackendFactory(e){return e in this.registryFactory?this.registryFactory[e].factory:null}registerBackend(e,t,n=1){return e in this.registryFactory?(console.warn(`${e} backend was already registered. Reusing existing backend factory.`),!1):(this.registryFactory[e]={factory:t,priority:n},!0)}async setBackend(e){if(null==this.registryFactory[e])throw new Error(`Backend name '${e}' not found in registry`);if(this.backendName=e,null==this.registry[e]){this.backendInstance=null;const{success:t,asyncInit:n}=this.initializeBackend(e);if(!(n?await t:t))return!1}return this.backendInstance=this.registry[e],this.setupRegisteredKernels(),this.profiler=new Profiler(this.backendInstance),!0}setupRegisteredKernels(){getKernelsForBackend(this.backendName).forEach(e=>{null!=e.setupFunc&&e.setupFunc(this.backendInstance)})}disposeRegisteredKernels(e){getKernelsForBackend(e).forEach(t=>{null!=t.disposeFunc&&t.disposeFunc(this.registry[e])})}initializeBackend(e){const t=this.registryFactory[e];if(null==t)throw new Error(`Cannot initialize backend ${e}, no registration found.`);try{const n=t.factory();if(!n||n instanceof KernelBackend||"function"!=typeof n.then)return this.registry[e]=n,{success:!0,asyncInit:!1};{const t=++this.pendingBackendInitId,r=n.then(n=>!(t<this.pendingBackendInitId||(this.registry[e]=n,this.pendingBackendInit=null,0))).catch(n=>(t<this.pendingBackendInitId||(this.pendingBackendInit=null,console.warn(`Initialization of backend ${e} failed`),console.warn(n.stack||n.message)),!1));return this.pendingBackendInit=r,{success:r,asyncInit:!0}}}catch(t){return console.warn(`Initialization of backend ${e} failed`),console.warn(t.stack||t.message),{success:!1,asyncInit:!1}}}removeBackend(e){if(!(e in this.registryFactory))throw new Error(`${e} backend not found in registry`);this.backendName===e&&null!=this.pendingBackendInit&&this.pendingBackendInitId++,e in this.registry&&(this.disposeRegisteredKernels(e),this.registry[e].dispose(),delete this.registry[e]),delete this.registryFactory[e],this.backendName===e&&(this.pendingBackendInit=null,this.backendName=null,this.backendInstance=null)}getSortedBackends(){if(0===Object.keys(this.registryFactory).length)throw new Error("No backend found in registry.");return Object.keys(this.registryFactory).sort((e,t)=>this.registryFactory[t].priority-this.registryFactory[e].priority)}initializeBackendsAndReturnBest(){const e=this.getSortedBackends();for(let t=0;t<e.length;t++){const n=e[t],{success:r,asyncInit:a}=this.initializeBackend(n);if(a||r)return{name:n,asyncInit:a}}throw new Error("Could not initialize any backends, all backend initializations failed.")}moveData(e,t){const n=this.state.tensorInfo.get(t),r=n.backend,a=this.readSync(t),s=r.refCount(t);r.disposeData(t,!0),n.backend=e,e.move(t,a,n.shape,n.dtype,s),this.shouldCheckForMemLeaks()&&this.state.numDataMovesStack[this.state.numDataMovesStack.length-1]++}tidy(e,t){let n,r=null;if(null==t){if("function"!=typeof e)throw new Error("Please provide a function to tidy()");t=e}else{if("string"!=typeof e&&!(e instanceof String))throw new Error("When calling with two arguments, the first argument to tidy() must be a string");if("function"!=typeof t)throw new Error("When calling with two arguments, the 2nd argument to tidy() must be a function");r=e}return this.scopedRun(()=>this.startScope(r),()=>this.endScope(n),()=>(n=t(),n instanceof Promise&&console.error("Cannot return a Promise inside of tidy."),n))}scopedRun(e,t,n){e();try{const e=n();return t(),e}catch(e){throw t(),e}}nextTensorId(){return Engine.nextTensorId++}nextVariableId(){return Engine.nextVariableId++}clone(e){const t=ENGINE.runKernel(Identity$1,{x:e});return this.addTapeNode(this.state.activeScope.name,{x:e},[t],e=>({x:()=>ENGINE.runKernel(Cast,{x:e},{dtype:"float32"})}),[],{}),t}runKernel(e,t,n){if(null==getKernel(e,this.backendName))throw new Error(`Kernel '${e}' not registered for backend '${this.backendName}'`);return this.runKernelFunc({kernelName:e,inputs:t,attrs:n})}shouldCheckForMemLeaks(){return this.ENV.getBool("IS_TEST")}checkKernelForMemLeak(e,t,n){const r=this.backend.numDataIds();let a=0;n.forEach(e=>{a+="complex64"===e.dtype?3:1});const s=r-t-a-this.state.numDataMovesStack[this.state.numDataMovesStack.length-1];if(s>0)throw new Error(`Backend '${this.backendName}' has an internal memory leak (${s} data ids) after running '${e}'`)}runKernelFunc(e){let t,n=[];const r=this.isTapeOn(),a=this.state.numBytes,s=this.state.numTensors;let o,i;this.shouldCheckForMemLeaks()&&this.state.numDataMovesStack.push(0);const l=isRegisteredKernelInvocation(e)?e.kernelName:null!=this.state.activeScope?this.state.activeScope.name:"";if(isRegisteredKernelInvocation(e)){const{kernelName:t,inputs:a,attrs:s}=e,l=getKernel(t,this.backendName);assert$4(null!=l,()=>`Cannot find registered kernel '${t}' for backend '${this.backendName}'`),o=()=>{const e=this.backend.numDataIds();i=l.kernelFunc({inputs:a,attrs:s,backend:this.backend});const o=Array.isArray(i)?i:[i];this.shouldCheckForMemLeaks()&&this.checkKernelForMemLeak(t,e,o);const u=o.map(e=>{if(null!=e.rank)return e;const{dataId:t,shape:n,dtype:r}=e;return this.makeTensorFromDataId(t,n,r)});if(r){const e=this.getTensorsForGradient(t,a,u);n=this.saveTensorsForBackwardMode(e)}return u}}else{const{forwardFunc:t}=e,a=e=>{r&&(n=e.map(e=>this.keep(this.clone(e))))};o=()=>{const e=this.backend.numDataIds();i=this.tidy(()=>t(this.backend,a));const n=Array.isArray(i)?i:[i];return this.shouldCheckForMemLeaks()&&this.checkKernelForMemLeak(l,e,n),n}}const{inputs:u,attrs:c}=e,p=isRegisteredKernelInvocation(e)?null:e.backwardsFunc;let d;return this.scopedRun(()=>this.state.kernelDepth++,()=>this.state.kernelDepth--,()=>{this.ENV.getBool("DEBUG")||this.state.profiling?(d=this.profiler.profileKernel(l,u,()=>o()),this.ENV.getBool("DEBUG")&&this.profiler.logKernelProfile(d),t=d.outputs):t=o()}),r&&this.addTapeNode(l,u,t,p,n,c),this.state.profiling&&this.state.activeProfile.kernels.push({name:l,bytesAdded:this.state.numBytes-a,totalBytesSnapshot:this.state.numBytes,tensorsAdded:this.state.numTensors-s,totalTensorsSnapshot:this.state.numTensors,inputShapes:Object.keys(u).map(e=>null!=u[e]?u[e].shape:null),outputShapes:t.map(e=>e.shape),kernelTimeMs:d.timeMs,extraInfo:d.extraInfo}),Array.isArray(i)?t:t[0]}saveTensorsForBackwardMode(e){return e.map(e=>this.keep(this.clone(e)))}getTensorsForGradient(e,t,n){const r=getGradient(e);if(null!=r){const e=r.inputsToSave||[],a=r.outputsToSave||[];let s;r.saveAllInputs?(assert$4(Array.isArray(t),()=>"saveAllInputs is true, expected inputs to be an array."),s=Object.keys(t).map(e=>t[e])):s=e.map(e=>t[e]);const o=n.filter((e,t)=>a[t]);return s.concat(o)}return[]}makeTensor(e,t,n,r){if(null==e)throw new Error("Values passed to engine.makeTensor() are null");r=r||this.backend;let a=e;"string"===(n=n||"float32")&&isString(e[0])&&(a=e.map(e=>encodeString(e)));const s=r.write(a,t,n),o=new Tensor(t,n,s,this.nextTensorId());if(this.trackTensor(o,r),"string"===n){const e=this.state.tensorInfo.get(s),t=bytesFromStringArray(a);this.state.numBytes+=t-e.bytes,e.bytes=t}return o}makeTensorFromDataId(e,t,n,r){const a=new Tensor(t,n=n||"float32",e,this.nextTensorId());return this.trackTensor(a,r),a}makeVariable(e,t=!0,n,r){n=n||this.nextVariableId().toString(),null!=r&&r!==e.dtype&&(e=e.cast(r));const a=new Variable(e,t,n,this.nextTensorId());if(null!=this.state.registeredVariables[a.name])throw new Error(`Variable with name ${a.name} was already registered`);return this.state.registeredVariables[a.name]=a,this.incRef(a,this.backend),a}trackTensor(e,t){this.state.numTensors++,"string"===e.dtype&&this.state.numStringTensors++;let n=0;"complex64"!==e.dtype&&"string"!==e.dtype&&(n=e.size*bytesPerElement(e.dtype)),this.state.numBytes+=n,this.state.tensorInfo.has(e.dataId)||(this.state.numDataBuffers++,this.state.tensorInfo.set(e.dataId,{backend:t||this.backend,dtype:e.dtype,shape:e.shape,bytes:n})),e instanceof Variable||this.track(e)}incRef(e,t){this.trackTensor(e,t),this.backend.incRef(e.dataId)}removeDataId(e,t){this.state.tensorInfo.has(e)&&this.state.tensorInfo.get(e).backend===t&&(this.state.tensorInfo.delete(e),this.state.numDataBuffers--)}disposeTensor(e){if(!this.state.tensorInfo.has(e.dataId))return;const t=this.state.tensorInfo.get(e.dataId);if(this.state.numTensors--,"string"===e.dtype&&(this.state.numStringTensors--,this.state.numBytes-=t.bytes),"complex64"!==e.dtype&&"string"!==e.dtype){const t=e.size*bytesPerElement(e.dtype);this.state.numBytes-=t}t.backend.disposeData(e.dataId)&&this.removeDataId(e.dataId,t.backend)}disposeVariables(){for(const e in this.state.registeredVariables)this.disposeVariable(this.state.registeredVariables[e])}disposeVariable(e){this.disposeTensor(e),null!=this.state.registeredVariables[e.name]&&delete this.state.registeredVariables[e.name]}memory(){const e=this.backend.memory();return e.numTensors=this.state.numTensors,e.numDataBuffers=this.state.numDataBuffers,e.numBytes=this.state.numBytes,this.state.numStringTensors>0&&(e.unreliable=!0,null==e.reasons&&(e.reasons=[]),e.reasons.push("Memory usage by string tensors is approximate (2 bytes per character)")),e}async profile(e){this.state.profiling=!0;const t=this.state.numBytes,n=this.state.numTensors;this.state.activeProfile.kernels=[],this.state.activeProfile.result=await e(),this.state.profiling=!1,this.state.activeProfile.peakBytes=Math.max(...this.state.activeProfile.kernels.map(e=>e.totalBytesSnapshot)),this.state.activeProfile.newBytes=this.state.numBytes-t,this.state.activeProfile.newTensors=this.state.numTensors-n;for(const e of this.state.activeProfile.kernels)e.kernelTimeMs=await e.kernelTimeMs,e.extraInfo=await e.extraInfo;return this.state.activeProfile}isTapeOn(){return this.state.gradientDepth>0&&0===this.state.kernelDepth}addTapeNode(e,t,n,r,a,s){const o={id:this.state.nextTapeNodeId++,kernelName:e,inputs:t,outputs:n,saved:a},i=getGradient(e);null!=i&&(r=i.gradFunc),null!=r&&(o.gradient=e=>(e=e.map((e,t)=>{if(null==e){const e=n[t],r=makeZerosTypedArray(e.size,e.dtype);return this.makeTensor(r,e.shape,e.dtype)}return e}),r(e.length>1?e:e[0],a,s))),this.state.activeTape.push(o)}keep(e){return e.kept=!0,e}startTape(){0===this.state.gradientDepth&&(this.state.activeTape=[]),this.state.gradientDepth++}endTape(){this.state.gradientDepth--}startScope(e){const t={track:[],name:"unnamed scope",id:this.state.nextScopeId++};e&&(t.name=e),this.state.scopeStack.push(t),this.state.activeScope=t}endScope(e){const t=getTensorsInContainer(e),n=new Set(t.map(e=>e.id));for(let e=0;e<this.state.activeScope.track.length;e++){const t=this.state.activeScope.track[e];t.kept||n.has(t.id)||t.dispose()}const r=this.state.scopeStack.pop();this.state.activeScope=0===this.state.scopeStack.length?null:this.state.scopeStack[this.state.scopeStack.length-1],t.forEach(e=>{e.kept||e.scopeId!==r.id||this.track(e)})}gradients(e,t,n,r=!1){if(assert$4(t.length>0,()=>"gradients() received an empty list of xs."),null!=n&&"float32"!==n.dtype)throw new Error(`dy must have 'float32' dtype, but has '${n.dtype}'`);const a=this.scopedRun(()=>this.startTape(),()=>this.endTape(),()=>this.tidy("forward",e));assert$4(a instanceof Tensor,()=>"The result y returned by f() must be a tensor.");const s=getFilteredNodesXToY(this.state.activeTape,t,a);if(!r&&0===s.length&&t.length>0)throw new Error("Cannot compute gradient of y=f(x) with respect to x. Make sure that the f you passed encloses all operations that lead from x to y.");return this.tidy("backward",()=>{const e={};e[a.id]=null==n?ones$2(a.shape):n,backpropagateGradients(e,s,e=>this.tidy(e),add$3);const r=t.map(t=>e[t.id]);return 0===this.state.gradientDepth&&(this.state.activeTape.forEach(e=>{for(const t of e.saved)t.dispose()}),this.state.activeTape=null),{value:a,grads:r}})}customGrad(e){return assert$4(isFunction(e),()=>"The f passed in customGrad(f) must be a function."),(...t)=>{let n;assert$4(t.every(e=>e instanceof Tensor),()=>"The args passed in customGrad(f)(x1, x2,...) must all be tensors");const r={};return t.forEach((e,t)=>{r[t]=e}),this.runKernelFunc({forwardFunc:(r,a)=>(n=e(...t,a),assert$4(n.value instanceof Tensor,()=>"The function f passed in customGrad(f) must return an object where `obj.value` is a tensor"),assert$4(isFunction(n.gradFunc),()=>"The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function."),n.value),backwardsFunc:(e,r)=>{const a=n.gradFunc(e,r),s=Array.isArray(a)?a:[a];assert$4(s.length===t.length,()=>"The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns the same number of tensors as inputs passed to f(...)."),assert$4(s.every(e=>e instanceof Tensor),()=>"The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns a list of only tensors.");const o={};return s.forEach((e,t)=>{o[t]=()=>e}),o},inputs:r})}}readSync(e){return this.state.tensorInfo.get(e).backend.readSync(e)}read(e){return this.state.tensorInfo.get(e).backend.read(e)}async time(e){const t=now(),n=await this.backend.time(e);return n.wallMs=now()-t,n}track(e){return null!=this.state.activeScope&&(e.scopeId=this.state.activeScope.id,this.state.activeScope.track.push(e)),e}get registeredVariables(){return this.state.registeredVariables}reset(){this.pendingBackendInitId++,this.state.dispose(),this.ENV.reset(),this.state=new EngineState;for(const e in this.registry)this.disposeRegisteredKernels(e),this.registry[e].dispose(),delete this.registry[e];this.backendName=null,this.backendInstance=null,this.pendingBackendInit=null}}function ones$2(e){const t=makeOnesTypedArray(sizeFromShape(e),"float32");return ENGINE.makeTensor(t,e,"float32")}function getOrMakeEngine(){const e=getGlobalNamespace();if(null==e._tfengine){const t=new Environment(e);e._tfengine=new Engine(t)}return setEnvironmentGlobal(e._tfengine.ENV),setTensorTracker(()=>e._tfengine),e._tfengine}Engine.nextTensorId=0,Engine.nextVariableId=0;const ENGINE=getOrMakeEngine();function add$3(e,t){return ENGINE.runKernel(Add$1,{a:e,b:t})}function _isNavigatorDefined(){return"undefined"!=typeof navigator&&null!=navigator}function isMobile(e){if(e||_isNavigatorDefined()){if(e||(e=navigator),"ReactNative"===e.product)return!0;const t=e.userAgent||e.vendor||window.opera;return/(android|bb\d+|meego).+mobile|avantgo|bada\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\.(browser|link)|vodafone|wap|windows ce|xda|xiino/i.test(t)||/1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\-(n|u)|c55\/|capi|ccwa|cdm\-|cell|chtm|cldc|cmd\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\-s|devi|dica|dmob|do(c|p)o|ds(12|\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\-|_)|g1 u|g560|gene|gf\-5|g\-mo|go(\.w|od)|gr(ad|un)|haie|hcit|hd\-(m|p|t)|hei\-|hi(pt|ta)|hp( i|ip)|hs\-c|ht(c(\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\-(20|go|ma)|i230|iac( |\-|\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\/)|klon|kpt |kwc\-|kyo(c|k)|le(no|xi)|lg( g|\/(k|l|u)|50|54|\-[a-w])|libw|lynx|m1\-w|m3ga|m50\/|ma(te|ui|xo)|mc(01|21|ca)|m\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\-2|po(ck|rt|se)|prox|psio|pt\-g|qa\-a|qc(07|12|21|32|60|\-[2-7]|i\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\-|oo|p\-)|sdk\/|se(c(\-|0|1)|47|mc|nd|ri)|sgh\-|shar|sie(\-|m)|sk\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\-|v\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\-|tdg\-|tel(i|m)|tim\-|t\-mo|to(pl|sh)|ts(70|m\-|m3|m5)|tx\-9|up(\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\-|your|zeto|zte\-/i.test(t.substr(0,4))}return!1}function isBrowser(){return"undefined"!=typeof window&&null!=window.document||"undefined"!=typeof WorkerGlobalScope}var device_util={__proto__:null,isMobile,isBrowser};const ENV$1=env();function inferShape(e,t){let n=e;if(isTypedArray(e))return"string"===t?[]:[e.length];if(!Array.isArray(e))return[];const r=[];for(;Array.isArray(n)||isTypedArray(n)&&"string"!==t;)r.push(n.length),n=n[0];return Array.isArray(e)&&env().getBool("TENSORLIKE_CHECK_SHAPE_CONSISTENCY")&&deepAssertShapeConsistency(e,r,[]),r}function deepAssertShapeConsistency(e,t,n){if(n=n||[],!Array.isArray(e)&&!isTypedArray(e))return void assert$4(0===t.length,()=>`Element arr[${n.join("][")}] is a primitive, but should be an array/TypedArray of ${t[0]} elements`);assert$4(t.length>0,()=>`Element arr[${n.join("][")}] should be a primitive, but is an array of ${e.length} elements`),assert$4(e.length===t[0],()=>`Element arr[${n.join("][")}] should have ${t[0]} elements, but has ${e.length} elements`);const r=t.slice(1);for(let t=0;t<e.length;++t)deepAssertShapeConsistency(e[t],r,n.concat(t))}function assertDtype(e,t,n,r){if("string_or_numeric"!==e){if(null==e)throw new Error("Expected dtype cannot be null.");if("numeric"!==e&&e!==t||"numeric"===e&&"string"===t)throw new Error(`Argument '${n}' passed to '${r}' must be ${e} tensor, but got ${t} tensor`)}}function convertToTensor(e,t,n,r="numeric"){if(e instanceof Tensor)return assertDtype(r,e.dtype,t,n),e;let a=inferDtype(e);if("string"!==a&&["bool","int32","float32"].indexOf(r)>=0&&(a=r),assertDtype(r,a,t,n),null==e||!isTypedArray(e)&&!Array.isArray(e)&&"number"!=typeof e&&"boolean"!=typeof e&&"string"!=typeof e)throw new Error(`Argument '${t}' passed to '${n}' must be a Tensor or TensorLike, but got '${null==e?"null":e.constructor.name}'`);const s=inferShape(e,a);isTypedArray(e)||Array.isArray(e)||(e=[e]);const o="string"!==a?toTypedArray(e,a):flatten$3(e,[],!0);return ENGINE.makeTensor(o,s,a)}function convertToTensorArray(e,t,n,r="numeric"){if(!Array.isArray(e))throw new Error(`Argument ${t} passed to ${n} must be a \`Tensor[]\` or \`TensorLike[]\``);return e.map((e,a)=>convertToTensor(e,`${t}[${a}]`,n,r))}ENV$1.registerFlag("DEBUG",()=>!1,e=>{e&&console.warn("Debugging mode is ON. The output of every math call will be downloaded to CPU and checked for NaNs. This significantly impacts performance.")}),ENV$1.registerFlag("IS_BROWSER",()=>isBrowser()),ENV$1.registerFlag("IS_NODE",()=>"undefined"!=typeof process&&void 0!==process.versions&&void 0!==process.versions.node),ENV$1.registerFlag("IS_CHROME",()=>"undefined"!=typeof navigator&&null!=navigator&&null!=navigator.userAgent&&/Chrome/.test(navigator.userAgent)&&/Google Inc/.test(navigator.vendor)),ENV$1.registerFlag("PROD",()=>!1),ENV$1.registerFlag("TENSORLIKE_CHECK_SHAPE_CONSISTENCY",()=>ENV$1.getBool("DEBUG")),ENV$1.registerFlag("DEPRECATION_WARNINGS_ENABLED",()=>!0),ENV$1.registerFlag("IS_TEST",()=>!1),ENV$1.registerFlag("CHECK_COMPUTATION_FOR_ERRORS",()=>!0),ENV$1.registerFlag("WRAP_TO_IMAGEBITMAP",()=>!1);const OP_SCOPE_SUFFIX="__op";function op(e){const t=Object.keys(e);if(1!==t.length)throw new Error(`Please provide an object with a single key (operation name) mapping to a function. Got an object with ${t.length} keys.`);let n=t[0];const r=e[n];n.endsWith("_")&&(n=n.substring(0,n.length-1)),n+=OP_SCOPE_SUFFIX;const a=(...e)=>{ENGINE.startScope(n);try{const t=r(...e);return isPromise(t)&&console.error("Cannot return a Promise inside of tidy."),ENGINE.endScope(t),t}catch(e){throw ENGINE.endScope(null),e}};return Object.defineProperty(a,"name",{value:n,configurable:!0}),a}function complex_(e,t){const n=convertToTensor(e,"real","complex"),r=convertToTensor(t,"imag","complex");return assertShapesMatch(n.shape,r.shape,`real and imag shapes, ${n.shape} and ${r.shape}, must match in call to tf.complex().`),ENGINE.runKernel(Complex,{real:n,imag:r})}const complex$2=op({complex_});function makeTensor(e,t,n,r){if(null==r&&(r=inferDtype(e)),"complex64"===r)throw new Error("Cannot construct a complex64 tensor directly. Please use tf.complex(real, imag).");if(!isTypedArray(e)&&!Array.isArray(e)&&"number"!=typeof e&&"boolean"!=typeof e&&"string"!=typeof e)throw new Error("values passed to tensor(values) must be a number/boolean/string or an array of numbers/booleans/strings, or a TypedArray");if(null!=t){assertNonNegativeIntegerDimensions(t);const e=sizeFromShape(t),r=sizeFromShape(n);assert$4(e===r,()=>`Based on the provided shape, [${t}], the tensor should have ${e} values but has ${r}`);for(let e=0;e<n.length;++e){const r=n[e],a=e!==n.length-1||r!==sizeFromShape(t.slice(e));assert$4(n[e]===t[e]||!a,()=>`Error creating a new Tensor. Inferred shape (${n}) does not match the provided shape (${t}). `)}}return isTypedArray(e)||Array.isArray(e)||(e=[e]),t=t||n,e="string"!==r?toTypedArray(e,r):flatten$3(e,[],!0),ENGINE.makeTensor(e,t,r)}function tensor(e,t,n){return makeTensor(e,t,inferShape(e,n),n)}const DTYPE_VALUE_SIZE_MAP={float32:4,float16:2,int32:4,uint16:2,uint8:1,bool:1,complex64:8},NUM_BYTES_STRING_LENGTH=4;async function encodeWeights(e,t){const n=[],r=[],a=Array.isArray(e)?e.map(e=>e.name):Object.keys(e);for(let s=0;s<a.length;++s){const o=a[s],i=Array.isArray(e)?e[s].tensor:e[o];if("float32"!==i.dtype&&"int32"!==i.dtype&&"bool"!==i.dtype&&"string"!==i.dtype&&"complex64"!==i.dtype)throw new Error(`Unsupported dtype in weight '${o}': ${i.dtype}`);const l={name:o,shape:i.shape,dtype:i.dtype};if("string"===i.dtype){const e=new Promise(async e=>{const t=await i.bytes(),n=t.reduce((e,t)=>e+t.length,0)+NUM_BYTES_STRING_LENGTH*t.length,r=new Uint8Array(n);let a=0;for(let e=0;e<t.length;e++){const n=t[e],s=new Uint8Array(new Uint32Array([n.length]).buffer);r.set(s,a),a+=NUM_BYTES_STRING_LENGTH,r.set(n,a),a+=n.length}e(r)});r.push(e)}else r.push(i.data());null!=t&&(l.group=t),n.push(l)}return{data:concatenateTypedArrays(await Promise.all(r)),specs:n}}function decodeWeights(e,t){const n={};let r,a=0;for(const s of t){const t=s.name,o=s.dtype,i=s.shape,l=sizeFromShape(i);let u;if("quantization"in s){const n=s.quantization;if("uint8"===n.dtype||"uint16"===n.dtype){if(!("min"in n)||!("scale"in n))throw new Error(`Weight ${s.name} with quantization ${n.dtype} doesn't have corresponding metadata min and scale.`)}else{if("float16"!==n.dtype)throw new Error(`Weight ${s.name} has unknown quantization dtype ${n.dtype}. Supported quantization dtypes are: 'uint8', 'uint16', and 'float16'.`);if("float32"!==o)throw new Error(`Weight ${s.name} is quantized with ${n.dtype} which only supports weights of type float32 not ${o}.`)}const i=DTYPE_VALUE_SIZE_MAP[n.dtype],c=e.slice(a,a+l*i),p="uint8"===n.dtype?new Uint8Array(c):new Uint16Array(c);if("float32"===o)if("uint8"===n.dtype||"uint16"===n.dtype){u=new Float32Array(p.length);for(let e=0;e<p.length;e++)u[e]=p[e]*n.scale+n.min}else{if("float16"!==n.dtype)throw new Error(`Unsupported quantization type ${n.dtype} for weight type float32.`);void 0===r&&(r=getFloat16Decoder()),u=r(p)}else{if("int32"!==o)throw new Error(`Unsupported dtype in weight '${t}': ${o}`);if("uint8"!==n.dtype&&"uint16"!==n.dtype)throw new Error(`Unsupported quantization type ${n.dtype} for weight type int32.`);u=new Int32Array(p.length);for(let e=0;e<p.length;e++)u[e]=Math.round(p[e]*n.scale+n.min)}a+=l*i}else if("string"===o){const t=sizeFromShape(s.shape);u=[];for(let n=0;n<t;n++){const t=new Uint32Array(e.slice(a,a+NUM_BYTES_STRING_LENGTH))[0];a+=NUM_BYTES_STRING_LENGTH;const n=new Uint8Array(e.slice(a,a+t));u.push(n),a+=t}}else{const r=DTYPE_VALUE_SIZE_MAP[o],s=e.slice(a,a+l*r);if("float32"===o)u=new Float32Array(s);else if("int32"===o)u=new Int32Array(s);else if("bool"===o)u=new Uint8Array(s);else{if("complex64"!==o)throw new Error(`Unsupported dtype in weight '${t}': ${o}`);{u=new Float32Array(s);const e=new Float32Array(u.length/2),r=new Float32Array(u.length/2);for(let t=0;t<e.length;t++)e[t]=u[2*t],r[t]=u[2*t+1];const a=tensor(e,i,"float32"),o=tensor(r,i,"float32");n[t]=complex$2(a,o),a.dispose(),o.dispose()}}a+=l*r}"complex64"!==o&&(n[t]=tensor(u,i,o))}return n}function concatenateTypedArrays(e){if(null===e)throw new Error(`Invalid input value: ${JSON.stringify(e)}`);let t=0;const n=[];e.forEach(e=>{if(t+=e.byteLength,n.push(e.byteLength===e.buffer.byteLength?e:new e.constructor(e)),!(e instanceof Float32Array||e instanceof Int32Array||e instanceof Uint8Array))throw new Error(`Unsupported TypedArray subtype: ${e.constructor.name}`)});const r=new Uint8Array(t);let a=0;return n.forEach(e=>{r.set(new Uint8Array(e.buffer),a),a+=e.byteLength}),r.buffer}const useNodeBuffer="undefined"!=typeof Buffer&&("undefined"==typeof Blob||"undefined"==typeof atob||"undefined"==typeof btoa);function stringByteLength(e){return useNodeBuffer?Buffer.byteLength(e):new Blob([e]).size}function arrayBufferToBase64String(e){if(useNodeBuffer)return Buffer.from(e).toString("base64");const t=new Uint8Array(e);let n="";for(let e=0,r=t.length;e<r;e++)n+=String.fromCharCode(t[e]);return btoa(n)}function base64StringToArrayBuffer(e){if(useNodeBuffer){const t=Buffer.from(e,"base64");return t.buffer.slice(t.byteOffset,t.byteOffset+t.byteLength)}const t=atob(e),n=new Uint8Array(t.length);for(let e=0;e<t.length;++e)n.set([t.charCodeAt(e)],e);return n.buffer}function concatenateArrayBuffers(e){if(1===e.length)return e[0];let t=0;e.forEach(e=>{t+=e.byteLength});const n=new Uint8Array(t);let r=0;return e.forEach(e=>{n.set(new Uint8Array(e),r),r+=e.byteLength}),n.buffer}function basename(e){for(e=e.trim();e.endsWith("/");)e=e.slice(0,e.length-1);const t=e.split("/");return t[t.length-1]}function getModelJSONForModelArtifacts(e,t){const n={modelTopology:e.modelTopology,format:e.format,generatedBy:e.generatedBy,convertedBy:e.convertedBy,weightsManifest:t};return null!=e.signature&&(n.signature=e.signature),null!=e.userDefinedMetadata&&(n.userDefinedMetadata=e.userDefinedMetadata),null!=e.modelInitializer&&(n.modelInitializer=e.modelInitializer),null!=e.trainingConfig&&(n.trainingConfig=e.trainingConfig),n}async function getModelArtifactsForJSON(e,t){const n={modelTopology:e.modelTopology,format:e.format,generatedBy:e.generatedBy,convertedBy:e.convertedBy};if(null!=e.trainingConfig&&(n.trainingConfig=e.trainingConfig),null!=e.weightsManifest){const[r,a]=await t(e.weightsManifest);n.weightSpecs=r,n.weightData=a}return null!=e.signature&&(n.signature=e.signature),null!=e.userDefinedMetadata&&(n.userDefinedMetadata=e.userDefinedMetadata),null!=e.modelInitializer&&(n.modelInitializer=e.modelInitializer),n}function getModelArtifactsInfoForJSON(e){if(e.modelTopology instanceof ArrayBuffer)throw new Error("Expected JSON model topology, received ArrayBuffer.");return{dateSaved:new Date,modelTopologyType:"JSON",modelTopologyBytes:null==e.modelTopology?0:stringByteLength(JSON.stringify(e.modelTopology)),weightSpecsBytes:null==e.weightSpecs?0:stringByteLength(JSON.stringify(e.weightSpecs)),weightDataBytes:null==e.weightData?0:e.weightData.byteLength}}function computeFloat16MantisaTable(){const e=e=>{let t=e<<13,n=0;for(;0==(8388608&t);)n-=8388608,t<<=1;return t&=-8388609,n+=947912704,t|n},t=new Uint32Array(2048);t[0]=0;for(let n=1;n<1024;n++)t[n]=e(n);for(let e=1024;e<2048;e++)t[e]=939524096+(e-1024<<13);return t}function computeFloat16ExponentTable(){const e=new Uint32Array(64);e[0]=0,e[31]=1199570944,e[32]=2147483648,e[63]=3347054592;for(let t=1;t<31;t++)e[t]=t<<23;for(let t=33;t<63;t++)e[t]=2147483648+(t-32<<23);return e}function computeFloat16OffsetTable(){const e=new Uint32Array(64);for(let t=0;t<64;t++)e[t]=1024;return e[0]=e[32]=0,e}function getFloat16Decoder(){const e=computeFloat16MantisaTable(),t=computeFloat16ExponentTable(),n=computeFloat16OffsetTable();return r=>{const a=new ArrayBuffer(4*r.length),s=new Uint32Array(a);for(let a=0;a<r.length;a++){const o=r[a];s[a]=e[n[o>>10]+(1023&o)]+t[o>>10]}return new Float32Array(a)}}class IORouterRegistry{constructor(){this.saveRouters=[],this.loadRouters=[]}static getInstance(){return null==IORouterRegistry.instance&&(IORouterRegistry.instance=new IORouterRegistry),IORouterRegistry.instance}static registerSaveRouter(e){IORouterRegistry.getInstance().saveRouters.push(e)}static registerLoadRouter(e){IORouterRegistry.getInstance().loadRouters.push(e)}static getSaveHandlers(e){return IORouterRegistry.getHandlers(e,"save")}static getLoadHandlers(e,t){return IORouterRegistry.getHandlers(e,"load",t)}static getHandlers(e,t,n){const r=[];return("load"===t?IORouterRegistry.getInstance().loadRouters:IORouterRegistry.getInstance().saveRouters).forEach(t=>{const a=t(e,n);null!==a&&r.push(a)}),r}}const registerSaveRouter=e=>IORouterRegistry.registerSaveRouter(e),registerLoadRouter=e=>IORouterRegistry.registerLoadRouter(e),getSaveHandlers=e=>IORouterRegistry.getSaveHandlers(e),getLoadHandlers=(e,t)=>IORouterRegistry.getLoadHandlers(e,t),DATABASE_NAME="tensorflowjs",DATABASE_VERSION=1,MODEL_STORE_NAME="models_store",INFO_STORE_NAME="model_info_store";function getIndexedDBFactory(){if(!env().getBool("IS_BROWSER"))throw new Error("Failed to obtain IndexedDB factory because the current environmentis not a web browser.");const e="undefined"==typeof window?self:window,t=e.indexedDB||e.mozIndexedDB||e.webkitIndexedDB||e.msIndexedDB||e.shimIndexedDB;if(null==t)throw new Error("The current browser does not appear to support IndexedDB.");return t}function setUpDatabase(e){const t=e.result;t.createObjectStore(MODEL_STORE_NAME,{keyPath:"modelPath"}),t.createObjectStore(INFO_STORE_NAME,{keyPath:"modelPath"})}class BrowserIndexedDB{constructor(e){if(this.indexedDB=getIndexedDBFactory(),null==e||!e)throw new Error("For IndexedDB, modelPath must not be null, undefined or empty.");this.modelPath=e}async save(e){if(e.modelTopology instanceof ArrayBuffer)throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");return this.databaseAction(this.modelPath,e)}async load(){return this.databaseAction(this.modelPath)}databaseAction(e,t){return new Promise((e,n)=>{const r=this.indexedDB.open(DATABASE_NAME,DATABASE_VERSION);r.onupgradeneeded=()=>setUpDatabase(r),r.onsuccess=()=>{const a=r.result;if(null==t){const t=a.transaction(MODEL_STORE_NAME,"readonly"),r=t.objectStore(MODEL_STORE_NAME).get(this.modelPath);r.onsuccess=()=>{if(null==r.result)return a.close(),n(new Error(`Cannot find model with path '${this.modelPath}' in IndexedDB.`));e(r.result.modelArtifacts)},r.onerror=e=>(a.close(),n(r.error)),t.oncomplete=()=>a.close()}else{const r=getModelArtifactsInfoForJSON(t),s=a.transaction(INFO_STORE_NAME,"readwrite");let o=s.objectStore(INFO_STORE_NAME);const i=o.put({modelPath:this.modelPath,modelArtifactsInfo:r});let l;i.onsuccess=()=>{l=a.transaction(MODEL_STORE_NAME,"readwrite");const i=l.objectStore(MODEL_STORE_NAME).put({modelPath:this.modelPath,modelArtifacts:t,modelArtifactsInfo:r});i.onsuccess=()=>e({modelArtifactsInfo:r}),i.onerror=e=>{o=s.objectStore(INFO_STORE_NAME);const t=o.delete(this.modelPath);t.onsuccess=()=>(a.close(),n(i.error)),t.onerror=e=>(a.close(),n(i.error))}},i.onerror=e=>(a.close(),n(i.error)),s.oncomplete=()=>{null==l?a.close():l.oncomplete=()=>a.close()}}},r.onerror=e=>n(r.error)})}}BrowserIndexedDB.URL_SCHEME="indexeddb://";const indexedDBRouter=e=>env().getBool("IS_BROWSER")&&!Array.isArray(e)&&e.startsWith(BrowserIndexedDB.URL_SCHEME)?browserIndexedDB(e.slice(BrowserIndexedDB.URL_SCHEME.length)):null;function browserIndexedDB(e){return new BrowserIndexedDB(e)}function maybeStripScheme$1(e){return e.startsWith(BrowserIndexedDB.URL_SCHEME)?e.slice(BrowserIndexedDB.URL_SCHEME.length):e}IORouterRegistry.registerSaveRouter(indexedDBRouter),IORouterRegistry.registerLoadRouter(indexedDBRouter);class BrowserIndexedDBManager{constructor(){this.indexedDB=getIndexedDBFactory()}async listModels(){return new Promise((e,t)=>{const n=this.indexedDB.open(DATABASE_NAME,DATABASE_VERSION);n.onupgradeneeded=()=>setUpDatabase(n),n.onsuccess=()=>{const r=n.result,a=r.transaction(INFO_STORE_NAME,"readonly"),s=a.objectStore(INFO_STORE_NAME).getAll();s.onsuccess=()=>{const t={};for(const e of s.result)t[e.modelPath]=e.modelArtifactsInfo;e(t)},s.onerror=e=>(r.close(),t(s.error)),a.oncomplete=()=>r.close()},n.onerror=e=>t(n.error)})}async removeModel(e){return e=maybeStripScheme$1(e),new Promise((t,n)=>{const r=this.indexedDB.open(DATABASE_NAME,DATABASE_VERSION);r.onupgradeneeded=()=>setUpDatabase(r),r.onsuccess=()=>{const a=r.result,s=a.transaction(INFO_STORE_NAME,"readwrite"),o=s.objectStore(INFO_STORE_NAME),i=o.get(e);let l;i.onsuccess=()=>{if(null==i.result)return a.close(),n(new Error(`Cannot find model with path '${e}' in IndexedDB.`));{const r=o.delete(e),s=()=>{l=a.transaction(MODEL_STORE_NAME,"readwrite");const r=l.objectStore(MODEL_STORE_NAME).delete(e);r.onsuccess=()=>t(i.result.modelArtifactsInfo),r.onerror=e=>n(i.error)};r.onsuccess=s,r.onerror=e=>(s(),a.close(),n(i.error))}},i.onerror=e=>(a.close(),n(i.error)),s.oncomplete=()=>{null==l?a.close():l.oncomplete=()=>a.close()}},r.onerror=e=>n(r.error)})}}const PATH_SEPARATOR="/",PATH_PREFIX="tensorflowjs_models",INFO_SUFFIX="info",MODEL_TOPOLOGY_SUFFIX="model_topology",WEIGHT_SPECS_SUFFIX="weight_specs",WEIGHT_DATA_SUFFIX="weight_data",MODEL_METADATA_SUFFIX="model_metadata";function getModelKeys(e){return{info:[PATH_PREFIX,e,INFO_SUFFIX].join(PATH_SEPARATOR),topology:[PATH_PREFIX,e,MODEL_TOPOLOGY_SUFFIX].join(PATH_SEPARATOR),weightSpecs:[PATH_PREFIX,e,WEIGHT_SPECS_SUFFIX].join(PATH_SEPARATOR),weightData:[PATH_PREFIX,e,WEIGHT_DATA_SUFFIX].join(PATH_SEPARATOR),modelMetadata:[PATH_PREFIX,e,MODEL_METADATA_SUFFIX].join(PATH_SEPARATOR)}}function removeItems(e){for(const t of Object.values(e))window.localStorage.removeItem(t)}function getModelPathFromKey(e){const t=e.split(PATH_SEPARATOR);if(t.length<3)throw new Error(`Invalid key format: ${e}`);return t.slice(1,t.length-1).join(PATH_SEPARATOR)}function maybeStripScheme(e){return e.startsWith(BrowserLocalStorage.URL_SCHEME)?e.slice(BrowserLocalStorage.URL_SCHEME.length):e}class BrowserLocalStorage{constructor(e){if(!env().getBool("IS_BROWSER")||"undefined"==typeof window||void 0===window.localStorage)throw new Error("The current environment does not support local storage.");if(this.LS=window.localStorage,null==e||!e)throw new Error("For local storage, modelPath must not be null, undefined or empty.");this.modelPath=e,this.keys=getModelKeys(this.modelPath)}async save(e){if(e.modelTopology instanceof ArrayBuffer)throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");{const t=JSON.stringify(e.modelTopology),n=JSON.stringify(e.weightSpecs),r=getModelArtifactsInfoForJSON(e);try{return this.LS.setItem(this.keys.info,JSON.stringify(r)),this.LS.setItem(this.keys.topology,t),this.LS.setItem(this.keys.weightSpecs,n),this.LS.setItem(this.keys.weightData,arrayBufferToBase64String(e.weightData)),this.LS.setItem(this.keys.modelMetadata,JSON.stringify({format:e.format,generatedBy:e.generatedBy,convertedBy:e.convertedBy,signature:null!=e.signature?e.signature:void 0,userDefinedMetadata:null!=e.userDefinedMetadata?e.userDefinedMetadata:void 0,modelInitializer:null!=e.modelInitializer?e.modelInitializer:void 0,trainingConfig:null!=e.trainingConfig?e.trainingConfig:void 0})),{modelArtifactsInfo:r}}catch(e){throw removeItems(this.keys),new Error(`Failed to save model '${this.modelPath}' to local storage: size quota being exceeded is a possible cause of this failure: modelTopologyBytes=${r.modelTopologyBytes}, weightSpecsBytes=${r.weightSpecsBytes}, weightDataBytes=${r.weightDataBytes}.`)}}}async load(){const e=JSON.parse(this.LS.getItem(this.keys.info));if(null==e)throw new Error(`In local storage, there is no model with name '${this.modelPath}'`);if("JSON"!==e.modelTopologyType)throw new Error("BrowserLocalStorage does not support loading non-JSON model topology yet.");const t={},n=JSON.parse(this.LS.getItem(this.keys.topology));if(null==n)throw new Error(`In local storage, the topology of model '${this.modelPath}' is missing.`);t.modelTopology=n;const r=JSON.parse(this.LS.getItem(this.keys.weightSpecs));if(null==r)throw new Error(`In local storage, the weight specs of model '${this.modelPath}' are missing.`);t.weightSpecs=r;const a=this.LS.getItem(this.keys.modelMetadata);if(null!=a){const e=JSON.parse(a);t.format=e.format,t.generatedBy=e.generatedBy,t.convertedBy=e.convertedBy,null!=e.signature&&(t.signature=e.signature),null!=e.userDefinedMetadata&&(t.userDefinedMetadata=e.userDefinedMetadata),null!=e.modelInitializer&&(t.modelInitializer=e.modelInitializer),null!=e.trainingConfig&&(t.trainingConfig=e.trainingConfig)}const s=this.LS.getItem(this.keys.weightData);if(null==s)throw new Error(`In local storage, the binary weight values of model '${this.modelPath}' are missing.`);return t.weightData=base64StringToArrayBuffer(s),t}}BrowserLocalStorage.URL_SCHEME="localstorage://";const localStorageRouter=e=>env().getBool("IS_BROWSER")&&!Array.isArray(e)&&e.startsWith(BrowserLocalStorage.URL_SCHEME)?browserLocalStorage(e.slice(BrowserLocalStorage.URL_SCHEME.length)):null;function browserLocalStorage(e){return new BrowserLocalStorage(e)}IORouterRegistry.registerSaveRouter(localStorageRouter),IORouterRegistry.registerLoadRouter(localStorageRouter);class BrowserLocalStorageManager{constructor(){assert$4(env().getBool("IS_BROWSER"),()=>"Current environment is not a web browser"),assert$4("undefined"==typeof window||void 0!==window.localStorage,()=>"Current browser does not appear to support localStorage"),this.LS=window.localStorage}async listModels(){const e={},t=PATH_PREFIX+PATH_SEPARATOR,n=PATH_SEPARATOR+INFO_SUFFIX;for(let r=0;r<this.LS.length;++r){const a=this.LS.key(r);a.startsWith(t)&&a.endsWith(n)&&(e[getModelPathFromKey(a)]=JSON.parse(this.LS.getItem(a)))}return e}async removeModel(e){const t=getModelKeys(e=maybeStripScheme(e));if(null==this.LS.getItem(t.info))throw new Error(`Cannot find model at path '${e}'`);const n=JSON.parse(this.LS.getItem(t.info));return removeItems(t),n}}const URL_SCHEME_SUFFIX="://";class ModelStoreManagerRegistry{constructor(){this.managers={}}static getInstance(){return null==ModelStoreManagerRegistry.instance&&(ModelStoreManagerRegistry.instance=new ModelStoreManagerRegistry),ModelStoreManagerRegistry.instance}static registerManager(e,t){assert$4(null!=e,()=>"scheme must not be undefined or null."),e.endsWith(URL_SCHEME_SUFFIX)&&(e=e.slice(0,e.indexOf(URL_SCHEME_SUFFIX))),assert$4(e.length>0,()=>"scheme must not be an empty string.");const n=ModelStoreManagerRegistry.getInstance();assert$4(null==n.managers[e],()=>`A model store manager is already registered for scheme '${e}'.`),n.managers[e]=t}static getManager(e){const t=this.getInstance().managers[e];if(null==t)throw new Error(`Cannot find model manager for scheme '${e}'`);return t}static getSchemes(){return Object.keys(this.getInstance().managers)}}function parseURL(e){if(-1===e.indexOf(URL_SCHEME_SUFFIX))throw new Error(`The url string provided does not contain a scheme. Supported schemes are: ${ModelStoreManagerRegistry.getSchemes().join(",")}`);return{scheme:e.split(URL_SCHEME_SUFFIX)[0],path:e.split(URL_SCHEME_SUFFIX)[1]}}async function cloneModelInternal(e,t,n=!1){assert$4(e!==t,()=>`Old path and new path are the same: '${e}'`);const r=IORouterRegistry.getLoadHandlers(e);assert$4(r.length>0,()=>`Copying failed because no load handler is found for source URL ${e}.`),assert$4(r.length<2,()=>`Copying failed because more than one (${r.length}) load handlers for source URL ${e}.`);const a=r[0],s=IORouterRegistry.getSaveHandlers(t);assert$4(s.length>0,()=>`Copying failed because no save handler is found for destination URL ${t}.`),assert$4(s.length<2,()=>`Copying failed because more than one (${r.length}) save handlers for destination URL ${t}.`);const o=s[0],i=parseURL(e).scheme,l=parseURL(e).path,u=i===parseURL(e).scheme,c=await a.load();n&&u&&await ModelStoreManagerRegistry.getManager(i).removeModel(l);const p=await o.save(c);return n&&!u&&await ModelStoreManagerRegistry.getManager(i).removeModel(l),p.modelArtifactsInfo}async function listModels(){const e=ModelStoreManagerRegistry.getSchemes(),t={};for(const n of e){const e=await ModelStoreManagerRegistry.getManager(n).listModels();for(const r in e)t[n+URL_SCHEME_SUFFIX+r]=e[r]}return t}async function removeModel(e){const t=parseURL(e);return ModelStoreManagerRegistry.getManager(t.scheme).removeModel(t.path)}async function copyModel(e,t){return cloneModelInternal(e,t,!1)}async function moveModel(e,t){return cloneModelInternal(e,t,!0)}class PlatformBrowser{fetch(e,t){return fetch(e,t)}now(){return performance.now()}encode(e,t){if("utf-8"!==t&&"utf8"!==t)throw new Error(`Browser's encoder only supports utf-8, but got ${t}`);return null==this.textEncoder&&(this.textEncoder=new TextEncoder),this.textEncoder.encode(e)}decode(e,t){return new TextDecoder(t).decode(e)}}if(env().get("IS_BROWSER")){env().setPlatform("browser",new PlatformBrowser);try{ModelStoreManagerRegistry.registerManager(BrowserLocalStorage.URL_SCHEME,new BrowserLocalStorageManager)}catch(e){}try{ModelStoreManagerRegistry.registerManager(BrowserIndexedDB.URL_SCHEME,new BrowserIndexedDBManager)}catch(e){}}const getNodeFetch={importFetch:()=>require("node-fetch")};let systemFetch;class PlatformNode{constructor(){this.util=require("util"),this.textEncoder=new this.util.TextEncoder}fetch(e,t){return null!=env().global.fetch?env().global.fetch(e,t):(null==systemFetch&&(systemFetch=getNodeFetch.importFetch()),systemFetch(e,t))}now(){const e=process.hrtime();return 1e3*e[0]+e[1]/1e6}encode(e,t){if("utf-8"!==t&&"utf8"!==t)throw new Error(`Node built-in encoder only supports utf-8, but got ${t}`);return this.textEncoder.encode(e)}decode(e,t){return 0===e.length?"":new this.util.TextDecoder(t).decode(e)}}function buffer(e,t="float32",n){return t=t||"float32",assertNonNegativeIntegerDimensions(e),new TensorBuffer(e,t,n)}function cast_(e,t){const n=convertToTensor(e,"x","cast");if(!isValidDtype(t))throw new Error(`Failed to cast to unknown dtype ${t}`);if("string"===t&&"string"!==n.dtype||"string"!==t&&"string"===n.dtype)throw new Error("Only strings can be casted to strings");return ENGINE.runKernel(Cast,{x:n},{dtype:t})}env().get("IS_NODE")&&env().setPlatform("node",new PlatformNode);const cast$3=op({cast_});function clone_(e){const t=convertToTensor(e,"x","clone","string_or_numeric");return ENGINE.runKernel(Identity$1,{x:t})}const clone=op({clone_});function print(e,t=!1){console.log(e.toString(t))}getOrMakeEngine();const opHandler={buffer,cast:cast$3,clone,print};setOpHandler(opHandler);const DEFAULT_FILE_NAME_PREFIX="model",DEFAULT_JSON_EXTENSION_NAME=".json",DEFAULT_WEIGHT_DATA_EXTENSION_NAME=".weights.bin";function defer(e){return new Promise(e=>setTimeout(e)).then(e)}class BrowserDownloads{constructor(e){if(!env().getBool("IS_BROWSER"))throw new Error("browserDownloads() cannot proceed because the current environment is not a browser.");e.startsWith(BrowserDownloads.URL_SCHEME)&&(e=e.slice(BrowserDownloads.URL_SCHEME.length)),null!=e&&0!==e.length||(e=DEFAULT_FILE_NAME_PREFIX),this.modelJsonFileName=e+DEFAULT_JSON_EXTENSION_NAME,this.weightDataFileName=e+DEFAULT_WEIGHT_DATA_EXTENSION_NAME}async save(e){if("undefined"==typeof document)throw new Error("Browser downloads are not supported in this environment since `document` is not present");const t=window.URL.createObjectURL(new Blob([e.weightData],{type:"application/octet-stream"}));if(e.modelTopology instanceof ArrayBuffer)throw new Error("BrowserDownloads.save() does not support saving model topology in binary formats yet.");{const n=getModelJSONForModelArtifacts(e,[{paths:["./"+this.weightDataFileName],weights:e.weightSpecs}]),r=window.URL.createObjectURL(new Blob([JSON.stringify(n)],{type:"application/json"})),a=null==this.modelJsonAnchor?document.createElement("a"):this.modelJsonAnchor;if(a.download=this.modelJsonFileName,a.href=r,await defer(()=>a.dispatchEvent(new MouseEvent("click"))),null!=e.weightData){const e=null==this.weightDataAnchor?document.createElement("a"):this.weightDataAnchor;e.download=this.weightDataFileName,e.href=t,await defer(()=>e.dispatchEvent(new MouseEvent("click")))}return{modelArtifactsInfo:getModelArtifactsInfoForJSON(e)}}}}BrowserDownloads.URL_SCHEME="downloads://";class BrowserFiles{constructor(e){if(null==e||e.length<1)throw new Error(`When calling browserFiles, at least 1 file is required, but received ${e}`);this.jsonFile=e[0],this.weightsFiles=e.slice(1)}async load(){return new Promise((e,t)=>{const n=new FileReader;n.onload=n=>{const r=JSON.parse(n.target.result),a=r.modelTopology;if(null==a)return void t(new Error(`modelTopology field is missing from file ${this.jsonFile.name}`));if(null==r.weightsManifest)return void t(new Error(`weightManifest field is missing from file ${this.jsonFile.name}`));if(0===this.weightsFiles.length)return void e({modelTopology:a});const s=getModelArtifactsForJSON(r,e=>this.loadWeights(e));e(s)},n.onerror=e=>t(`Failed to read model topology and weights manifest JSON from file '${this.jsonFile.name}'. BrowserFiles supports loading Keras-style tf.Model artifacts only.`),n.readAsText(this.jsonFile)})}loadWeights(e){const t=[],n=[];for(const r of e)t.push(...r.weights),n.push(...r.paths);const r=this.checkManifestAndWeightFiles(e),a=n.map(e=>this.loadWeightsFile(e,r[e]));return Promise.all(a).then(e=>[t,concatenateArrayBuffers(e)])}loadWeightsFile(e,t){return new Promise((n,r)=>{const a=new FileReader;a.onload=e=>{n(e.target.result)},a.onerror=t=>r(`Failed to weights data from file of path '${e}'.`),a.readAsArrayBuffer(t)})}checkManifestAndWeightFiles(e){const t=[],n=this.weightsFiles.map(e=>basename(e.name)),r={};for(const a of e)a.paths.forEach(e=>{const a=basename(e);if(-1!==t.indexOf(a))throw new Error(`Duplicate file basename found in weights manifest: '${a}'`);if(t.push(a),-1===n.indexOf(a))throw new Error(`Weight file with basename '${a}' is not provided.`);r[e]=this.weightsFiles[n.indexOf(a)]});if(t.length!==this.weightsFiles.length)throw new Error(`Mismatch in the number of files in weights manifest (${t.length}) and the number of weight files provided (${this.weightsFiles.length}).`);return r}}const browserDownloadsRouter=e=>env().getBool("IS_BROWSER")&&!Array.isArray(e)&&e.startsWith(BrowserDownloads.URL_SCHEME)?browserDownloads(e.slice(BrowserDownloads.URL_SCHEME.length)):null;function browserDownloads(e="model"){return new BrowserDownloads(e)}function browserFiles(e){return new BrowserFiles(e)}function monitorPromisesProgress(e,t,n,r){!function(e){assert$4(null!=e&&Array.isArray(e)&&e.length>0,()=>"promises must be a none empty array")}(e),function(e,t){assert$4(e>=0&&e<=1,()=>`Progress fraction must be in range [0, 1], but got startFraction ${e}`),assert$4(t>=0&&t<=1,()=>`Progress fraction must be in range [0, 1], but got endFraction ${t}`),assert$4(t>=e,()=>`startFraction must be no more than endFraction, but got startFraction ${e} and endFraction ${t}`)}(n=null==n?0:n,r=null==r?1:r);let a=0;return Promise.all(e.map(s=>(s.then(s=>{const o=n+ ++a/e.length*(r-n);return t(o),s}),s)))}async function loadWeightsAsArrayBuffer(e,t){null==t&&(t={});const n=null==t.fetchFunc?env().platform.fetch:t.fetchFunc,r=e.map(e=>n(e,t.requestInit,{isBinary:!0})),a=(null==t.onProgress?await Promise.all(r):await monitorPromisesProgress(r,t.onProgress,0,.5)).map(e=>e.arrayBuffer());return null==t.onProgress?await Promise.all(a):await monitorPromisesProgress(a,t.onProgress,.5,1)}async function loadWeights(e,t="",n,r){return weightsLoaderFactory(e=>loadWeightsAsArrayBuffer(e,{requestInit:r}))(e,t,n)}function weightsLoaderFactory(e){return async(t,n="",r)=>{const a=t.map(()=>!1),s={},o=null!=r?r.map(()=>!1):[],i=[];if(t.forEach((e,t)=>{let n=0;e.weights.forEach(e=>{const l=DTYPE_VALUE_SIZE_MAP["quantization"in e?e.quantization.dtype:e.dtype]*sizeFromShape(e.shape),u=()=>{a[t]=!0,null==s[t]&&(s[t]=[]),s[t].push({manifestEntry:e,groupOffset:n,sizeBytes:l})};null!=r?r.forEach((t,n)=>{t===e.name&&(u(),o[n]=!0)}):u(),i.push(e.name),n+=l})}),!o.every(e=>e)){const e=r.filter((e,t)=>!o[t]);throw new Error(`Could not find weights in manifest with names: ${e.join(", ")}. \nManifest JSON has weights with names: ${i.join(", ")}.`)}const l=a.reduce((e,t,n)=>(t&&e.push(n),e),[]),u=[];l.forEach(e=>{t[e].paths.forEach(e=>{const t=n+(n.endsWith("/")?"":"/")+e;u.push(t)})});const c=await e(u),p={};let d=0;return l.forEach(e=>{const n=t[e].paths.length;let r=0;for(let e=0;e<n;e++)r+=c[d+e].byteLength;const a=new ArrayBuffer(r),o=new Uint8Array(a);let i=0;for(let e=0;e<n;e++){const t=new Uint8Array(c[d+e]);o.set(t,i),i+=t.byteLength}s[e].forEach(e=>{const t=decodeWeights(a.slice(e.groupOffset,e.groupOffset+e.sizeBytes),[e.manifestEntry]);for(const e in t)p[e]=t[e]}),d+=n}),p}}IORouterRegistry.registerSaveRouter(browserDownloadsRouter);const OCTET_STREAM_MIME_TYPE="application/octet-stream",JSON_TYPE="application/json";class HTTPRequest{constructor(e,t){if(this.DEFAULT_METHOD="POST",null==t&&(t={}),this.weightPathPrefix=t.weightPathPrefix,this.onProgress=t.onProgress,this.weightUrlConverter=t.weightUrlConverter,null!=t.fetchFunc?(assert$4("function"==typeof t.fetchFunc,()=>"Must pass a function that matches the signature of `fetch` (see https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API)"),this.fetch=t.fetchFunc):this.fetch=env().platform.fetch,assert$4(null!=e&&e.length>0,()=>"URL path for http must not be null, undefined or empty."),Array.isArray(e)&&assert$4(2===e.length,()=>`URL paths for http must have a length of 2, (actual length is ${e.length}).`),this.path=e,null!=t.requestInit&&null!=t.requestInit.body)throw new Error("requestInit is expected to have no pre-existing body, but has one.");this.requestInit=t.requestInit||{}}async save(e){if(e.modelTopology instanceof ArrayBuffer)throw new Error("BrowserHTTPRequest.save() does not support saving model topology in binary formats yet.");const t=Object.assign({method:this.DEFAULT_METHOD},this.requestInit);t.body=new FormData;const n=getModelJSONForModelArtifacts(e,[{paths:["./model.weights.bin"],weights:e.weightSpecs}]);t.body.append("model.json",new Blob([JSON.stringify(n)],{type:JSON_TYPE}),"model.json"),null!=e.weightData&&t.body.append("model.weights.bin",new Blob([e.weightData],{type:OCTET_STREAM_MIME_TYPE}),"model.weights.bin");const r=await this.fetch(this.path,t);if(r.ok)return{modelArtifactsInfo:getModelArtifactsInfoForJSON(e),responses:[r]};throw new Error(`BrowserHTTPRequest.save() failed due to HTTP response status ${r.status}.`)}async load(){const e=await this.fetch(this.path,this.requestInit);if(!e.ok)throw new Error(`Request to ${this.path} failed with status code ${e.status}. Please verify this URL points to the model JSON of the model to load.`);let t;try{t=await e.json()}catch(e){let t=`Failed to parse model JSON of response from ${this.path}.`;throw this.path.endsWith(".pb")?t+=" Your path contains a .pb file extension. Support for .pb models have been removed in TensorFlow.js 1.0 in favor of .json models. You can re-convert your Python TensorFlow model using the TensorFlow.js 1.0 conversion scripts or you can convert your.pb models with the 'pb2json'NPM script in the tensorflow/tfjs-converter repository.":t+=" Please make sure the server is serving valid JSON for this request.",new Error(t)}if(null==t.modelTopology&&null==t.weightsManifest)throw new Error(`The JSON from HTTP path ${this.path} contains neither model topology or manifest for weights.`);return getModelArtifactsForJSON(t,e=>this.loadWeights(e))}async loadWeights(e){const t=Array.isArray(this.path)?this.path[1]:this.path,[n,r]=parseUrl(t),a=this.weightPathPrefix||n,s=[];for(const t of e)s.push(...t.weights);const o=[],i=[];for(const t of e)for(const e of t.paths)null!=this.weightUrlConverter?i.push(this.weightUrlConverter(e)):o.push(a+e+r);return this.weightUrlConverter&&o.push(...await Promise.all(i)),[s,concatenateArrayBuffers(await loadWeightsAsArrayBuffer(o,{requestInit:this.requestInit,fetchFunc:this.fetch,onProgress:this.onProgress}))]}}function parseUrl(e){const t=e.lastIndexOf("/"),n=e.lastIndexOf("?");return[e.substring(0,t)+"/",n>t?e.substring(n):""]}function isHTTPScheme(e){return null!=e.match(HTTPRequest.URL_SCHEME_REGEX)}HTTPRequest.URL_SCHEME_REGEX=/^https?:\/\//;const httpRouter=(e,t)=>{if("undefined"==typeof fetch&&(null==t||null==t.fetchFunc))return null;{let n=!0;if(n=Array.isArray(e)?e.every(e=>isHTTPScheme(e)):isHTTPScheme(e),n)return http(e,t)}return null};function http(e,t){return new HTTPRequest(e,t)}function browserHTTPRequest(e,t){return http(e,t)}IORouterRegistry.registerSaveRouter(httpRouter),IORouterRegistry.registerLoadRouter(httpRouter);class PassthroughLoader{constructor(e){this.modelArtifacts=e}async load(){return this.modelArtifacts}}class PassthroughSaver{constructor(e){this.saveHandler=e}async save(e){return this.saveHandler(e)}}function fromMemory(e,t,n,r){return 1===arguments.length?null!=e.modelTopology||null!=e.weightSpecs?new PassthroughLoader(e):(console.warn("Please call tf.io.fromMemory() with only one argument. The argument should be of type ModelArtifacts. The multi-argument signature of tf.io.fromMemory() has been deprecated and will be removed in a future release."),new PassthroughLoader({modelTopology:e})):(console.warn("Please call tf.io.fromMemory() with only one argument. The argument should be of type ModelArtifacts. The multi-argument signature of tf.io.fromMemory() has been deprecated and will be removed in a future release."),new PassthroughLoader({modelTopology:e,weightSpecs:t,weightData:n,trainingConfig:r}))}function withSaveHandler(e){return new PassthroughSaver(e)}var io={__proto__:null,browserFiles,browserHTTPRequest,concatenateArrayBuffers,decodeWeights,encodeWeights,fromMemory,getLoadHandlers,getModelArtifactsForJSON,getModelArtifactsInfoForJSON,getSaveHandlers,http,isHTTPScheme,loadWeights,registerLoadRouter,registerSaveRouter,weightsLoaderFactory,withSaveHandler,copyModel,listModels,moveModel,removeModel};function matMul_(e,t,n=!1,r=!1){let a=convertToTensor(e,"a","matMul"),s=convertToTensor(t,"b","matMul");return[a,s]=makeTypesMatch(a,s),ENGINE.runKernel(BatchMatMul,{a,b:s},{transposeA:n,transposeB:r})}const matMul$1=op({matMul_});function oneHot_(e,t,n=1,r=0){if(t<2)throw new Error(`Error in oneHot: depth must be >=2, but it is ${t}`);const a=convertToTensor(e,"indices","oneHot","int32");return ENGINE.runKernel(OneHot,{indices:a},{depth:t,onValue:n,offValue:r})}const oneHot$2=op({oneHot_});function transpose_(e,t){const n=convertToTensor(e,"x","transpose");return null==t&&(t=n.shape.map((e,t)=>t).reverse()),assert$4(n.rank===t.length,()=>`Error in transpose: rank of input ${n.rank} must match length of perm ${t}.`),t.forEach(e=>{assert$4(e>=0&&e<n.rank,()=>"All entries in 'perm' must be between 0 and "+(n.rank-1)+` but got ${t}`)}),n.rank<=1?n.clone():ENGINE.runKernel(Transpose,{x:n},{perm:t})}const transpose$2=op({transpose_});function confusionMatrix_(e,t,n){const r=convertToTensor(e,"labels","confusionMatrix"),a=convertToTensor(t,"predictions","confusionMatrix");assert$4(null==n||n>0&&Number.isInteger(n),()=>`If provided, numClasses must be a positive integer, but got ${n}`),assert$4(1===r.rank,()=>`Expected the rank of labels to be 1, but got ${r.rank}`),assert$4(1===a.rank,()=>`Expected the rank of predictions to be 1, but got ${a.rank}`),assert$4(r.shape[0]===a.shape[0],()=>`Mismatch in the number of examples: ${r.shape[0]} vs. ${a.shape[0]}. Labels and predictions should have the same number of elements.`),assert$4(n>0&&Number.isInteger(n),()=>`numClasses is required to be a positive integer, but got ${n}`);const s=oneHot$2(cast$3(r,"int32"),n),o=oneHot$2(cast$3(a,"int32"),n),i=transpose$2(s),l=matMul$1(i,o);return cast$3(l,"int32")}const confusionMatrix=op({confusionMatrix_});var math={__proto__:null,confusionMatrix};function tensor3d(e,t,n){if(assertNonNull(e),null!=t&&3!==t.length)throw new Error("tensor3d() requires shape to have three numbers");const r=inferShape(e,n);if(3!==r.length&&1!==r.length)throw new Error("tensor3d() requires values to be number[][][] or flat/TypedArray");if(1===r.length&&null==t)throw new Error("tensor3d() requires shape to be provided when `values` are a flat array");return makeTensor(e,t,r,n)}let fromPixels2DContext$1;function fromPixels_(e,t=3){if(t>4)throw new Error("Cannot construct Tensor with more than 4 channels from pixels.");if(null==e)throw new Error("pixels passed to tf.browser.fromPixels() can not be null");let n=!1,r=!1,a=!1,s=!1,o=!1,i=!1;if(e.data instanceof Uint8Array)n=!0;else if("undefined"!=typeof ImageData&&e instanceof ImageData)r=!0;else if("undefined"!=typeof HTMLVideoElement&&e instanceof HTMLVideoElement)a=!0;else if("undefined"!=typeof HTMLImageElement&&e instanceof HTMLImageElement)s=!0;else if(null!=e.getContext)o=!0;else{if(!("undefined"!=typeof ImageBitmap&&e instanceof ImageBitmap))throw new Error(`pixels passed to tf.browser.fromPixels() must be either an HTMLVideoElement, HTMLImageElement, HTMLCanvasElement, ImageData in browser, or OffscreenCanvas, ImageData in webworker or {data: Uint32Array, width: number, height: number}, but was ${e.constructor.name}`);i=!0}if(a){const t=2;if(a&&e.readyState<t)throw new Error("The video element has not loaded data yet. Please wait for `loadeddata` event on the <video> element.")}if(null!=getKernel(FromPixels,ENGINE.backendName))return ENGINE.runKernel(FromPixels,{pixels:e},{numChannels:t});const[l,u]=a?[e.videoWidth,e.videoHeight]:[e.width,e.height];let c,p;if(o?c=e.getContext("2d").getImageData(0,0,l,u).data:r||n?c=e.data:(s||a||i)&&(null==fromPixels2DContext$1&&(fromPixels2DContext$1=document.createElement("canvas").getContext("2d")),fromPixels2DContext$1.canvas.width=l,fromPixels2DContext$1.canvas.height=u,fromPixels2DContext$1.drawImage(e,0,0,l,u),c=fromPixels2DContext$1.getImageData(0,0,l,u).data),4===t)p=new Int32Array(c);else{const e=l*u;p=new Int32Array(e*t);for(let n=0;n<e;n++)for(let e=0;e<t;++e)p[n*t+e]=c[4*n+e]}return tensor3d(p,[u,l,t],"int32")}function isPixelData(e){return null!=e&&e.data instanceof Uint8Array}function isImageBitmapFullySupported(){return"undefined"!=typeof window&&"undefined"!=typeof ImageBitmap&&window.hasOwnProperty("createImageBitmap")}function isNonEmptyPixels(e){return null!=e&&0!==e.width&&0!==e.height}function canWrapPixelsToImageBitmap(e){return isImageBitmapFullySupported()&&!(e instanceof ImageBitmap)&&isNonEmptyPixels(e)&&!isPixelData(e)}async function fromPixelsAsync(e,t=3){let n=null;if(env().getBool("WRAP_TO_IMAGEBITMAP")&&canWrapPixelsToImageBitmap(e)){let t;try{t=await createImageBitmap(e,{premultiplyAlpha:"none"})}catch(e){t=null}n=null!=t&&t.width===e.width&&t.height===e.height?t:e}else n=e;return fromPixels_(n,t)}async function toPixels(e,t){let n=convertToTensor(e,"img","toPixels");if(!(e instanceof Tensor)){const e=n;n=cast$3(e,"int32"),e.dispose()}if(2!==n.rank&&3!==n.rank)throw new Error(`toPixels only supports rank 2 or 3 tensors, got rank ${n.rank}.`);const[r,a]=n.shape.slice(0,2),s=2===n.rank?1:n.shape[2];if(s>4||2===s)throw new Error(`toPixels only supports depth of size 1, 3 or 4 but got ${s}`);if("float32"!==n.dtype&&"int32"!==n.dtype)throw new Error(`Unsupported type for toPixels: ${n.dtype}. Please use float32 or int32 tensors.`);const o=await n.data(),i="float32"===n.dtype?255:1,l=new Uint8ClampedArray(a*r*4);for(let e=0;e<r*a;++e){const t=[0,0,0,255];for(let r=0;r<s;r++){const a=o[e*s+r];if("float32"===n.dtype){if(a<0||a>1)throw new Error(`Tensor values for a float32 Tensor must be in the range [0 - 1] but encountered ${a}.`)}else if("int32"===n.dtype&&(a<0||a>255))throw new Error(`Tensor values for a int32 Tensor must be in the range [0 - 255] but encountered ${a}.`);1===s?(t[0]=a*i,t[1]=a*i,t[2]=a*i):t[r]=a*i}const r=4*e;l[r+0]=Math.round(t[0]),l[r+1]=Math.round(t[1]),l[r+2]=Math.round(t[2]),l[r+3]=Math.round(t[3])}if(null!=t){t.width=a,t.height=r;const e=t.getContext("2d"),n=new ImageData(l,a,r);e.putImageData(n,0,0)}return n!==e&&n.dispose(),l}const fromPixels$1=op({fromPixels_});var browser={__proto__:null,fromPixelsAsync,toPixels,fromPixels:fromPixels$1};function prepareAndValidate(e,t){const n=e.shape.length,r=t.shape.length;if(n<1)throw new Error(`tf.gatherND() expects the input to be rank 1 or higher, but the rank was ${n}.`);if(r<1)throw new Error(`tf.gatherND() expects the indices to be rank 1 or higher, but the rank was ${r}.`);if("int32"!==t.dtype)throw new Error(`tf.gatherND() expects the indices to be int32 type, but the dtype was ${t.dtype}.`);if(t.shape[r-1]>n)throw new Error(`index innermost dimension length must be <= tensor rank; saw: ${t.shape[r-1]} vs. ${n}`);if(0===sizeFromShape(e.shape))throw new Error(`Requested more than 0 entries, but input is empty. Input shape: ${e.shape}.`);const a=t.shape,s=a[a.length-1];let o=1;for(let e=0;e<a.length-1;++e)o*=a[e];const i=e.shape,l=a.slice();l.pop();let u=1;for(let e=s;e<n;++e)u*=i[e],l.push(i[e]);const c=[...computeStrides(e.shape).map(e=>e/u),1].slice(0,s);return[l,o,u,c]}var gather_nd_util={__proto__:null,prepareAndValidate};function validateUpdateShape(e,t,n){const r=t.rank>1?t.shape[t.rank-1]:1,a=t.rank>1?t.rank-1:1,s=`Must have updates.shape = indices.shape[:batchDim] + shape[sliceDim:], got updates.shape: ${n.shape}, indices.shape: ${t.shape}, shape: ${e}, sliceDim: ${r}, and batchDim: ${a}.`;if(n.rank<a)throw new Error(s+` update.rank < ${a}. `);if(e.length<r+(n.rank-a))throw new Error(s+` Output shape length < ${r+(n.rank-a)}`);if(n.rank!==a+e.length-r)throw new Error(s+" update.rank != "+(a+e.length-r));for(let e=0;e<a;++e)if(n.shape[e]!==t.shape[e])throw new Error(s+` updates.shape[${e}] (${n.shape[e]}) != indices.shape[${e}] (${t.shape[e]}).`);for(let t=0;t<n.rank-a;++t)if(n.shape[t+a]!==e[t+r])throw new Error(s+` updates.shape[${t+a}] (${n.shape[t+a]}) != shape[${t+a}] (${e[t+a]})`)}function validateInput$1(e,t,n){if(t.rank<1)throw new Error(`tf.scatterND() expects the indices to be rank 1 or higher, but the rank was ${t.rank}.`);if(e.rank<1)throw new Error(`tf.scatterND() expects the updates to be rank 1 or higher, but the rank was ${e.rank}.`);if("int32"!==t.dtype)throw new Error(`The dtype of 'indices' should be int32, but got dtype: ${t.dtype}`);if(n.length<1)throw new Error(`Output rank must be greater or equal to 1, but got shape: ${n}`);if(0===n.length){if(0===t.size)throw new Error(`Indices specified for empty output. indices shape: ${t.shape}`);if(0===e.size)throw new Error(`Updates specified for empty output. updates shape: ${e.shape}`)}validateUpdateShape(n,t,e)}function calculateShapes(e,t,n){const r=t.shape.length,a=r>1?t.shape[r-1]:1,s=n.length;let o=1;for(let e=a;e<s;++e)o*=n[e];const i=a<1?1:a;return{sliceRank:a,numUpdates:sizeFromShape(t.shape)/i,sliceSize:o,strides:[...computeStrides(n.slice(0,a)),1],outputSize:sizeFromShape(n)}}var scatter_nd_util={__proto__:null,validateUpdateShape,validateInput:validateInput$1,calculateShapes};function assertParamsValid(e,t,n){const r=e.shape.length;assert$4(r===t.length,()=>`Error in slice${r}D: Length of begin ${t} must match the rank of the array (${r}).`),assert$4(r===n.length,()=>`Error in slice${r}D: Length of size ${n} must match the rank of the array (${r}).`);for(let a=0;a<r;++a)assert$4(t[a]+n[a]<=e.shape[a],()=>`Error in slice${r}D: begin[${a}] + size[${a}] (${t[a]+n[a]}) would overflow input.shape[${a}] (${e.shape[a]})`)}function maskToAxes(e){const t=[];let n=0;for(;e>0;)1&e&&t.push(n),e/=2,n++;return t}function computeOutShape$2(e,t,n){const r=[];for(let a=0;a<e.length;a++)r[a]=Math.ceil((t[a]-e[a])/n[a]);return r}function stridesWithElidedDims(e,t,n,r){const a=[...e];for(let e=a.length;e<r.length;e++)a.push(1);for(let e=0;e<n;e++)0===e?a[t]=1:(a.splice(t,0,1),a.pop());return a}function unnormalizeAxis(e,t,n){return n<=e?n:n-(t-1)}function getElidedAxes(e,t){const n=[];for(let r=0;r<e;r++)n.push(t+r);return n}function getNormalizedAxes(e,t,n,r,a,s,o,i,l){const u=e.length;let c=new Array(u),p=new Array(u),d=new Array(u);if(t.length&&n>0){const l=t[0],u=n+1;c=startIndicesWithElidedDims(o,l,u,r,e),p=stopIndicesWithElidedDims(i,l,u,a,e),d=stridesWithElidedDims(s,l,u,e)}else for(let t=0;t<u;t++)c[t]=startForAxis(o,r,s,e,t,l),p[t]=stopForAxis(i,a,s,e,t,l),d[t]=stridesForAxis(s,t,l);return{begin:c,end:p,strides:d}}function startIndicesWithElidedDims(e,t,n,r,a){const s=[...a],o=getElidedAxes(n,t);for(let a=0;a<s.length;a++)if(o.indexOf(a)>-1)s[a]=0;else{const o=unnormalizeAxis(t,n,a);let i=r[o];e&1<<o&&(i=0),s[a]=i}return s}function stopIndicesWithElidedDims(e,t,n,r,a){const s=[...a],o=getElidedAxes(n,t);for(let a=0;a<s.length;a++)if(o.indexOf(a)>-1)s[a]=Number.MAX_SAFE_INTEGER;else{const o=unnormalizeAxis(t,n,a);let i=r[o];e&1<<o&&(i=Number.MAX_SAFE_INTEGER),s[a]=i}for(let e=0;e<s.length;e++){const t=a[e];s[e]<0&&(s[e]+=t),s[e]=clamp(0,s[e],a[e])}return s}function stridesForAxis(e,t,n){let r=e[t];return(n&1<<t||null==r)&&(r=1),r}function startForAxis(e,t,n,r,a,s){let o=t[a];(e&1<<a||s&1<<a||null==o)&&(o=(n[a]||1)>0?Number.MIN_SAFE_INTEGER:Number.MAX_SAFE_INTEGER);const i=r[a];return o<0&&(o+=i),o=clamp(0,o,i-1),o}function stopForAxis(e,t,n,r,a,s){let o=t[a];const i=n[a]||1;(e&1<<a||s&1<<a||null==o)&&(o=i>0?Number.MAX_SAFE_INTEGER:Number.MIN_SAFE_INTEGER);const l=r[a];return o<0&&(o+=l),o=i>0?clamp(0,o,l):clamp(-1,o,l-1),o}function isSliceContinous(e,t,n){let r=n.length;for(let e=0;e<n.length;e++)if(n[e]>1){r=e;break}for(let a=r+1;a<n.length;a++)if(t[a]>0||n[a]!==e[a])return!1;return!0}function computeFlatOffset(e,t){let n=e.length>0?e[e.length-1]:1;for(let r=0;r<e.length-1;r++)n+=e[r]*t[r];return n}function parseSliceParams(e,t,n){let r;const a=e.shape.length;let s;return r="number"==typeof t?[t,...new Array(a-1).fill(0)]:t.length<a?t.concat(new Array(a-t.length).fill(0)):t.slice(),r.forEach(e=>{assert$4(-1!==e,()=>"slice() does not support negative begin indexing.")}),s=null==n?new Array(a).fill(-1):"number"==typeof n?[n,...new Array(a-1).fill(-1)]:n.length<a?n.concat(new Array(a-n.length).fill(-1)):n,s=s.map((t,n)=>t>=0?t:(assert$4(-1===t,()=>`Negative size values should be exactly -1 but got ${t} for the slice() size at index ${n}.`),e.shape[n]-r[n])),[r,s]}function sliceInfo(e,t,n,r,a,s,o,i,l){let u=t.slice(),c=n.slice(),p=r;null==r&&(p=new Array(u.length));const d=maskToAxes(o);if(d.length>1)throw new Error("Multiple ellipses in slice is not allowed.");if(0!==o&&0!==i)throw new Error("Using both ellipsisMask and newAxisMask is not yet supported.");if(0!==o&&0!==l)throw new Error("Using both ellipsisMask and shrinkAxisMask is not yet supported.");const h=e.length-u.length,m=maskToAxes(i),f=e.slice();m.forEach(e=>{u[e]=0,c[e]=1,f.splice(e,0,1)});const{begin:g,end:$,strides:y}=getNormalizedAxes(f,d,h,u,c,p,a,s,o);u=g,c=$,p=y;const b=maskToAxes(l);b.forEach(e=>{c[e]=u[e]+1,p[e]=1});const x=computeOutShape$2(u,c,p),v=x.filter((e,t)=>-1===b.indexOf(t));return{nonStrided:p.every(e=>1===e),$begin:u,$end:c,$strides:p,size:x,newShape:f,outShape:v}}var slice_util={__proto__:null,assertParamsValid,maskToAxes,computeOutShape:computeOutShape$2,stridesWithElidedDims,getNormalizedAxes,startIndicesWithElidedDims,stopIndicesWithElidedDims,stridesForAxis,startForAxis,stopForAxis,isSliceContinous,computeFlatOffset,parseSliceParams,sliceInfo};class Serializable{getClassName(){return this.constructor.className}static fromConfig(e,t){return new e(t)}}class SerializationMap{constructor(){this.classNameMap={}}static getMap(){return null==SerializationMap.instance&&(SerializationMap.instance=new SerializationMap),SerializationMap.instance}static register(e){SerializationMap.getMap().classNameMap[e.className]=[e,e.fromConfig]}}function registerClass(e){assert$4(null!=e.className,()=>"Class being registered does not have the static className property defined."),assert$4("string"==typeof e.className,()=>"className is required to be a string, but got type "+typeof e.className),assert$4(e.className.length>0,()=>"Class being registered has an empty-string as its className, which is disallowed."),SerializationMap.register(e)}var serialization={__proto__:null,Serializable,SerializationMap,registerClass};const TEST_EPSILON_FLOAT32=.001,TEST_EPSILON_FLOAT16=.1;function expectArraysClose(e,t,n){return null==n&&(n=testEpsilon()),expectArraysPredicate(e,t,(e,t)=>areClose(e,t,n))}function testEpsilon(){return 32===ENGINE.backend.floatPrecision()?TEST_EPSILON_FLOAT32:TEST_EPSILON_FLOAT16}function expectArraysPredicate(e,t,n){let r=!0;if((isTypedArray(e)||isTypedArray(t))&&(r=!1),isTypedArray(e)&&isTypedArray(t)&&(r=!0),r){const n=e.constructor.name,r=t.constructor.name;if(n!==r)throw new Error(`Arrays are of different type. Actual: ${n}. Expected: ${r}`)}if(Array.isArray(e)&&Array.isArray(t)){const n=inferShape(e),r=inferShape(t);if(!arraysEqual(n,r))throw new Error(`Arrays have different shapes. Actual: [${n}]. Expected: [${r}]`)}const a=isTypedArray(e)?e:flatten$3(e),s=isTypedArray(t)?t:flatten$3(t);if(a.length!==s.length)throw new Error(`Arrays have different lengths actual: ${a.length} vs expected: ${s.length}.\nActual:   ${a}.\nExpected: ${s}.`);for(let e=0;e<s.length;++e){const t=a[e],r=s[e];if(!n(t,r))throw new Error(`Arrays differ: actual[${e}] = ${t}, expected[${e}] = ${r}.\nActual:   ${a}.\nExpected: ${s}.`)}}function expectPromiseToFail(e,t){e().then(()=>t.fail(),()=>t())}function expectArraysEqual(e,t){const n="string"==typeof t||"number"==typeof t||"boolean"==typeof t?[t]:t;return isString(e)||isString(e[0])||isString(t)||isString(t[0])?expectArraysPredicate(e,n,(e,t)=>e==t):expectArraysPredicate(e,t,(e,t)=>areClose(e,t,0))}function expectNumbersClose(e,t,n){if(null==n&&(n=testEpsilon()),!areClose(e,t,n))throw new Error(`Numbers differ: actual === ${e}, expected === ${t}`)}function areClose(e,t,n){return!isFinite(e)&&!isFinite(t)||!(isNaN(e)||isNaN(t)||Math.abs(e-t)>n)}function expectValuesInRange(e,t,n){for(let r=0;r<e.length;r++)if(e[r]<t||e[r]>n)throw new Error(`Value out of range:${e[r]} low: ${t}, high: ${n}`)}function expectArrayBuffersEqual(e,t){expect(new Float32Array(e)).toEqual(new Float32Array(t))}function encodeStrings(e){for(let t=0;t<e.length;t++){const n=e[t];Array.isArray(n)?encodeStrings(n):e[t]=encodeString(n)}return e}var test_util={__proto__:null,TEST_EPSILON_FLOAT16,expectArraysClose,testEpsilon,expectPromiseToFail,expectArraysEqual,expectNumbersClose,expectValuesInRange,expectArrayBuffersEqual,encodeStrings};const version$7="3.8.0";function enableProdMode(){env().set("PROD",!0)}function enableDebugMode(){env().set("DEBUG",!0)}function disableDeprecationWarnings(){env().set("DEPRECATION_WARNINGS_ENABLED",!1),console.warn("TensorFlow.js deprecation warnings have been disabled.")}function deprecationWarn(e){env().getBool("DEPRECATION_WARNINGS_ENABLED")&&console.warn(e+" You can disable deprecation warnings with tf.disableDeprecationWarnings().")}function disposeVariables(){ENGINE.disposeVariables()}function engine(){return ENGINE}function memory(){return ENGINE.memory()}function profile(e){return ENGINE.profile(e)}function tidy(e,t){return ENGINE.tidy(e,t)}function dispose(e){getTensorsInContainer(e).forEach(e=>e.dispose())}function keep(e){return ENGINE.keep(e)}function time(e){return ENGINE.time(e)}function setBackend(e){return ENGINE.setBackend(e)}function ready(){return ENGINE.ready()}function getBackend(){return ENGINE.backendName}function removeBackend(e){ENGINE.removeBackend(e)}function findBackend(e){return ENGINE.findBackend(e)}function findBackendFactory(e){return ENGINE.findBackendFactory(e)}function registerBackend(e,t,n=1){return ENGINE.registerBackend(e,t,n)}function backend(){return ENGINE.backend}function setPlatform(e,t){env().setPlatform(e,t)}function add_(e,t){let n=convertToTensor(e,"a","add"),r=convertToTensor(t,"b","add");return[n,r]=makeTypesMatch(n,r),ENGINE.runKernel(Add$1,{a:n,b:r})}const add$2=op({add_});function floorDiv_(e,t){let n=convertToTensor(e,"a","floorDiv"),r=convertToTensor(t,"b","floorDiv");return[n,r]=makeTypesMatch(n,r),ENGINE.runKernel(FloorDiv,{a:n,b:r})}const floorDiv$2=op({floorDiv_});function div_(e,t){let n=convertToTensor(e,"a","div"),r=convertToTensor(t,"b","div");return[n,r]=makeTypesMatch(n,r),"int32"===n.dtype&&"int32"===r.dtype?floorDiv$2(n,r):ENGINE.runKernel(RealDiv,{a:n,b:r},{})}const div$1=op({div_});function mul_(e,t){let n=convertToTensor(e,"a","mul"),r=convertToTensor(t,"b","mul");return[n,r]=makeTypesMatch(n,r),ENGINE.runKernel(Multiply$1,{a:n,b:r})}const mul=op({mul_});function abs_(e){const t=convertToTensor(e,"x","abs");return ENGINE.runKernel("complex64"===t.dtype?ComplexAbs:Abs,{x:t})}const abs$2=op({abs_});function acos_(e){const t=convertToTensor(e,"x","acos");return ENGINE.runKernel(Acos,{x:t})}const acos$2=op({acos_});function acosh_(e){const t=convertToTensor(e,"x","acosh");return ENGINE.runKernel(Acosh,{x:t})}const acosh$2=op({acosh_});function addN_(e){assert$4(Array.isArray(e),()=>"The argument passed to tf.addN() must be a list of tensors"),assert$4(e.length>=1,()=>`Must pass at least one tensor to tf.addN(), but got ${e.length}`);const t=e.map((e,t)=>convertToTensor(e,`tensors${t}`,"addN")),n=t[0];return t.forEach(e=>{if(e.dtype!==n.dtype)throw new Error("All tensors passed to tf.addN() must have the same dtype")}),t.forEach(e=>{if(!arraysEqual(e.shape,n.shape))throw new Error("All tensors passed to tf.addN() must have the same shape")}),ENGINE.runKernel(AddN,t)}const addN$2=op({addN_});function all_(e,t=null,n=!1){const r=convertToTensor(e,"x","all","bool");return ENGINE.runKernel(All,{x:r},{axis:t,keepDims:n})}const all$2=op({all_});function any_(e,t=null,n=!1){const r=convertToTensor(e,"x","any","bool");return ENGINE.runKernel(Any,{x:r},{axis:t,keepDims:n})}const any$2=op({any_});function argMax_(e,t=0){const n=convertToTensor(e,"x","argMax");return ENGINE.runKernel(ArgMax,{x:n},{axis:t})}const argMax$2=op({argMax_});function argMin_(e,t=0){const n=convertToTensor(e,"x","argMin");return ENGINE.runKernel(ArgMin,{x:n},{axis:t})}const argMin$2=op({argMin_});function asin_(e){const t=convertToTensor(e,"x","asin");return ENGINE.runKernel(Asin,{x:t})}const asin$2=op({asin_});function asinh_(e){const t=convertToTensor(e,"x","asinh");return ENGINE.runKernel(Asinh,{x:t})}const asinh$2=op({asinh_});function atan_(e){const t=convertToTensor(e,"x","atan");return ENGINE.runKernel(Atan,{x:t})}const atan$2=op({atan_});function atan2_(e,t){let n=convertToTensor(e,"a","atan2"),r=convertToTensor(t,"b","atan2");return[n,r]=makeTypesMatch(n,r),ENGINE.runKernel(Atan2,{a:n,b:r})}const atan2$2=op({atan2_});function atanh_(e){const t=convertToTensor(e,"x","atanh");return ENGINE.runKernel(Atanh,{x:t})}const atanh$2=op({atanh_});function computeDilation2DInfo(e,t,n,r,a="NHWC",s){return computeConv2DInfo(e,[...t,e[3]],n,s,r,null,null,convertConv2DDataFormat(a))}function computePool2DInfo(e,t,n,r,a,s,o="channelsLast"){const[i,l]=parseTupleParam(t);let u;if("channelsLast"===o)u=[i,l,e[3],e[3]];else{if("channelsFirst"!==o)throw new Error(`Unknown dataFormat ${o}`);u=[i,l,e[1],e[1]]}return computeConv2DInfo(e,u,n,r,a,s,!1,o)}function computePool3DInfo(e,t,n,r,a,s,o="NDHWC"){const[i,l,u]=parse3TupleParam(t);let c,p;if("NDHWC"===o)p="channelsLast",c=[i,l,u,e[4],e[4]];else{if("NCDHW"!==o)throw new Error(`Unknown dataFormat ${o}`);p="channelsFirst",c=[i,l,u,e[1],e[1]]}return computeConv3DInfo(e,c,n,r,a,!1,p,s)}function computeConv2DInfo(e,t,n,r,a,s,o=!1,i="channelsLast"){let[l,u,c,p]=[-1,-1,-1,-1];if("channelsLast"===i)[l,u,c,p]=e;else{if("channelsFirst"!==i)throw new Error(`Unknown dataFormat ${i}`);[l,p,u,c]=e}const[d,h,,m]=t,[f,g]=parseTupleParam(n),[$,y]=parseTupleParam(r),b=getEffectiveFilterSize(d,$),x=getEffectiveFilterSize(h,y),{padInfo:v,outHeight:I,outWidth:C}=getPadAndOutInfo(a,u,c,f,g,b,x,s,i),S=o?m*p:m;let k;return"channelsFirst"===i?k=[l,S,I,C]:"channelsLast"===i&&(k=[l,I,C,S]),{batchSize:l,dataFormat:i,inHeight:u,inWidth:c,inChannels:p,outHeight:I,outWidth:C,outChannels:S,padInfo:v,strideHeight:f,strideWidth:g,filterHeight:d,filterWidth:h,effectiveFilterHeight:b,effectiveFilterWidth:x,dilationHeight:$,dilationWidth:y,inShape:e,outShape:k,filterShape:t}}function computeConv3DInfo(e,t,n,r,a,s=!1,o="channelsLast",i){let[l,u,c,p,d]=[-1,-1,-1,-1,-1];if("channelsLast"===o)[l,u,c,p,d]=e;else{if("channelsFirst"!==o)throw new Error(`Unknown dataFormat ${o}`);[l,d,u,c,p]=e}const[h,m,f,,g]=t,[$,y,b]=parse3TupleParam(n),[x,v,I]=parse3TupleParam(r),C=getEffectiveFilterSize(h,x),S=getEffectiveFilterSize(m,v),k=getEffectiveFilterSize(f,I),{padInfo:T,outDepth:N,outHeight:w,outWidth:E}=get3DPadAndOutInfo(a,u,c,p,$,y,b,C,S,k,i),A=s?g*d:g;let D;return"channelsFirst"===o?D=[l,A,N,w,E]:"channelsLast"===o&&(D=[l,N,w,E,A]),{batchSize:l,dataFormat:o,inDepth:u,inHeight:c,inWidth:p,inChannels:d,outDepth:N,outHeight:w,outWidth:E,outChannels:A,padInfo:T,strideDepth:$,strideHeight:y,strideWidth:b,filterDepth:h,filterHeight:m,filterWidth:f,effectiveFilterDepth:C,effectiveFilterHeight:S,effectiveFilterWidth:k,dilationDepth:x,dilationHeight:v,dilationWidth:I,inShape:e,outShape:D,filterShape:t}}function computeOutputShape2D(e,t,n,r,a){null==r&&(r=computeDefaultPad(e,t,n));const s=e[1];return[round$3((e[0]-t+2*r)/n+1,a),round$3((s-t+2*r)/n+1,a)]}function computeOutputShape4D(e,t,n,r,a,s){null==a&&(a=computeDefaultPad(e,t,r));const o=e[1],i=e[2];return[round$3((e[0]-t+2*a)/r+1,s),round$3((o-t+2*a)/r+1,s),round$3((i-t+2*a)/r+1,s),n]}function computeDefaultPad(e,t,n,r=1){const a=getEffectiveFilterSize(t,r);return Math.floor((e[0]*(n-1)-n+a)/2)}function parseTupleParam(e){return"number"==typeof e?[e,e,e]:2===e.length?[e[0],e[1],1]:e}function parse3TupleParam(e){return"number"==typeof e?[e,e,e]:e}function getEffectiveFilterSize(e,t){return t<=1?e:e+(e-1)*(t-1)}function getPadAndOutInfo(e,t,n,r,a,s,o,i,l){let u,c,p;if("number"==typeof e){u={top:e,bottom:e,left:e,right:e,type:0===e?"VALID":"NUMBER"};const a=computeOutputShape2D([t,n],s,r,e,i);c=a[0],p=a[1]}else if("same"===e){c=Math.ceil(t/r),p=Math.ceil(n/a);const e=Math.max(0,(c-1)*r+s-t),i=Math.max(0,(p-1)*a+o-n),l=Math.floor(e/2),d=e-l,h=Math.floor(i/2);u={top:l,bottom:d,left:h,right:i-h,type:"SAME"}}else if("valid"===e)u={top:0,bottom:0,left:0,right:0,type:"VALID"},c=Math.ceil((t-s+1)/r),p=Math.ceil((n-o+1)/a);else{if("object"!=typeof e)throw Error(`Unknown padding parameter: ${e}`);{const d="channelsLast"===l?e[1][0]:e[2][0],h="channelsLast"===l?e[1][1]:e[2][1],m="channelsLast"===l?e[2][0]:e[3][0],f="channelsLast"===l?e[2][1]:e[3][1];u={top:d,bottom:h,left:m,right:f,type:0===d&&0===h&&0===m&&0===f?"VALID":"EXPLICIT"},c=round$3((t-s+d+h)/r+1,i),p=round$3((n-o+m+f)/a+1,i)}}return{padInfo:u,outHeight:c,outWidth:p}}function get3DPadAndOutInfo(e,t,n,r,a,s,o,i,l,u,c){let p,d,h,m;if("number"==typeof e){p={top:e,bottom:e,left:e,right:e,front:e,back:e,type:0===e?"VALID":"NUMBER"};const s=computeOutputShape4D([t,n,r,1],i,1,a,e,c);d=s[0],h=s[1],m=s[2]}else if("same"===e){d=Math.ceil(t/a),h=Math.ceil(n/s),m=Math.ceil(r/o);const e=(d-1)*a+i-t,c=(h-1)*s+l-n,f=(m-1)*o+u-r,g=Math.floor(e/2),$=e-g,y=Math.floor(c/2),b=c-y,x=Math.floor(f/2);p={top:y,bottom:b,left:x,right:f-x,front:g,back:$,type:"SAME"}}else{if("valid"!==e)throw Error(`Unknown padding parameter: ${e}`);p={top:0,bottom:0,left:0,right:0,front:0,back:0,type:"VALID"},d=Math.ceil((t-i+1)/a),h=Math.ceil((n-l+1)/s),m=Math.ceil((r-u+1)/o)}return{padInfo:p,outDepth:d,outHeight:h,outWidth:m}}function round$3(e,t){if(!t)return Math.trunc(e);switch(t){case"round":return Math.round(e);case"ceil":return Math.ceil(e);case"floor":return Math.floor(e);default:throw new Error(`Unknown roundingMode ${t}`)}}function tupleValuesAreOne(e){const[t,n,r]=parseTupleParam(e);return 1===t&&1===n&&1===r}function eitherStridesOrDilationsAreOne(e,t){return tupleValuesAreOne(e)||tupleValuesAreOne(t)}function convertConv2DDataFormat(e){if("NHWC"===e)return"channelsLast";if("NCHW"===e)return"channelsFirst";throw new Error(`Unknown dataFormat ${e}`)}function reshape_(e,t){const n=convertToTensor(e,"x","reshape","string_or_numeric");return ENGINE.runKernel(Reshape$1,{x:n},{shape:t})}const reshape$3=op({reshape_});function avgPool_(e,t,n,r,a){const s=convertToTensor(e,"x","avgPool","float32");assert$4(eitherStridesOrDilationsAreOne(n,1),()=>`Error in avgPool: Either strides or dilations must be 1. Got strides ${n} and dilations '1'`);let o=s,i=!1;3===s.rank&&(i=!0,o=reshape$3(s,[1,s.shape[0],s.shape[1],s.shape[2]])),assert$4(4===o.rank,()=>`Error in avgPool: x must be rank 4 but got rank ${o.rank}.`),null!=a&&assert$4(isInt(r),()=>`Error in avgPool: pad must be an integer when using, dimRoundingMode ${a} but got pad ${r}.`);let l=ENGINE.runKernel(AvgPool,{x:o},{filterSize:t,strides:n,pad:r,dimRoundingMode:a});return l=cast$3(l,s.dtype),i?reshape$3(l,[l.shape[1],l.shape[2],l.shape[3]]):l}const avgPool$2=op({avgPool_});function avgPool3d_(e,t,n,r,a,s="NDHWC"){const o=convertToTensor(e,"x","avgPool3d","float32");let i=o,l=!1;4===o.rank&&(l=!0,i=reshape$3(o,[1,o.shape[0],o.shape[1],o.shape[2],o.shape[3]])),assert$4(5===i.rank,()=>`Error in avgPool3d: x must be rank 5 but got rank ${i.rank}.`),assert$4("NDHWC"===s,()=>`Error in avgPool3d: Only NDHWC is currently supported, but got dataFormat of ${s}`),null!=a&&assert$4(isInt(r),()=>`Error in avgPool3d: pad must be an integer when using, dimRoundingMode ${a} but got pad ${r}.`);let u=ENGINE.runKernel(AvgPool3D,{x:i},{filterSize:t,strides:n,pad:r,dimRoundingMode:a,dataFormat:s});return u=cast$3(u,i.dtype),l?reshape$3(u,[u.shape[1],u.shape[2],u.shape[3],u.shape[4]]):u}const avgPool3d$1=op({avgPool3d_});function concat_(e,t=0){assert$4(e.length>=1,()=>"Pass at least one tensor to concat");const n=convertToTensorArray(e,"tensors","concat","string_or_numeric");return"complex64"===n[0].dtype&&n.forEach(e=>{if("complex64"!==e.dtype)throw new Error(`Cannot concatenate complex64 tensors with a tensor\n          with dtype ${e.dtype}. `)}),1===n.length?clone(n[0]):ENGINE.runKernel(Concat,n,{axis:t})}const concat$2=op({concat_});function sigmoid_(e){const t=convertToTensor(e,"x","sigmoid");return ENGINE.runKernel(Sigmoid$1,{x:t})}const sigmoid$2=op({sigmoid_});function slice_(e,t,n){const r=convertToTensor(e,"x","slice","string_or_numeric");if(0===r.rank)throw new Error("Slicing scalar is not possible");return ENGINE.runKernel(Slice,{x:r},{begin:t,size:n})}const slice$2=op({slice_});function tanh_(e){const t=convertToTensor(e,"x","tanh");return ENGINE.runKernel(Tanh$1,{x:t})}const tanh$2=op({tanh_});function basicLSTMCell_(e,t,n,r,a,s){const o=convertToTensor(e,"forgetBias","basicLSTMCell"),i=convertToTensor(t,"lstmKernel","basicLSTMCell"),l=convertToTensor(n,"lstmBias","basicLSTMCell"),u=convertToTensor(r,"data","basicLSTMCell"),c=convertToTensor(a,"c","basicLSTMCell"),p=convertToTensor(s,"h","basicLSTMCell"),d=concat$2([u,p],1),h=matMul$1(d,i),m=add$2(h,l),f=m.shape[1]/4,g=[m.shape[0],f],$=slice$2(m,[0,0],g),y=slice$2(m,[0,f],g),b=slice$2(m,[0,2*f],g),x=slice$2(m,[0,3*f],g),v=add$2(mul(sigmoid$2($),tanh$2(y)),mul(c,sigmoid$2(add$2(o,b))));return[v,mul(tanh$2(v),sigmoid$2(x))]}const basicLSTMCell=op({basicLSTMCell_});function batchToSpaceND_(e,t,n){const r=convertToTensor(e,"x","batchToSpaceND"),a=t.reduce((e,t)=>e*t);return assert$4(r.rank>=1+t.length,()=>`input rank is ${r.rank} but should be > than blockShape.length ${t.length}`),assert$4(n.length===t.length,()=>`crops.length is ${n.length} but should be equal to blockShape.length  ${t.length}`),assert$4(r.shape[0]%a==0,()=>`input tensor batch is ${r.shape[0]} but is not divisible by the product of the elements of blockShape ${t.join(" * ")} === ${a}`),ENGINE.runKernel(BatchToSpaceND,{x:r},{blockShape:t,crops:n})}const batchToSpaceND$2=op({batchToSpaceND_});function xAs4D(e){let t;return t=0===e.rank||1===e.rank?reshape$3(e,[1,1,1,e.size]):2===e.rank?reshape$3(e,[1,1,e.shape[0],e.shape[1]]):3===e.rank?reshape$3(e,[1,e.shape[0],e.shape[1],e.shape[2]]):e,t}function batchNorm_(e,t,n,r,a,s){null==s&&(s=.001);const o=convertToTensor(e,"x","batchNorm"),i=convertToTensor(t,"mean","batchNorm"),l=convertToTensor(n,"variance","batchNorm");let u,c;null!=a&&(u=convertToTensor(a,"scale","batchNorm")),null!=r&&(c=convertToTensor(r,"offset","batchNorm")),assert$4(i.rank===l.rank,()=>"Batch normalization gradient requires mean and variance to have equal ranks."),assert$4(null==c||i.rank===c.rank,()=>"Batch normalization gradient requires mean and offset to have equal ranks."),assert$4(null==u||i.rank===u.rank,()=>"Batch normalization gradient requires mean and scale to have equal ranks.");const p=xAs4D(o),d=ENGINE.runKernel(FusedBatchNorm,{x:p,scale:u,offset:c,mean:i,variance:l},{varianceEpsilon:s});return reshape$3(d,o.shape)}const batchNorm$2=op({batchNorm_});function batchNorm2d_(e,t,n,r,a,s){const o=convertToTensor(e,"x","batchNorm"),i=convertToTensor(t,"mean","batchNorm"),l=convertToTensor(n,"variance","batchNorm");let u,c;return null!=a&&(u=convertToTensor(a,"scale","batchNorm")),null!=r&&(c=convertToTensor(r,"offset","batchNorm")),assert$4(2===o.rank,()=>`Error in batchNorm2D: x must be rank 2 but got rank ${o.rank}.`),assert$4(2===i.rank||1===i.rank,()=>`Error in batchNorm2D: mean must be rank 2 or rank 1 but got rank ${i.rank}.`),assert$4(2===l.rank||1===l.rank,()=>`Error in batchNorm2D: variance must be rank 2 or rank 1 but got rank ${l.rank}.`),null!=u&&assert$4(2===u.rank||1===u.rank,()=>`Error in batchNorm2D: scale must be rank 2 or rank 1 but got rank ${u.rank}.`),null!=c&&assert$4(2===c.rank||1===c.rank,()=>`Error in batchNorm2D: offset must be rank 2 or rank 1 but got rank ${c.rank}.`),batchNorm$2(o,i,l,c,u,s)}const batchNorm2d=op({batchNorm2d_});function batchNorm3d_(e,t,n,r,a,s){const o=convertToTensor(e,"x","batchNorm"),i=convertToTensor(t,"mean","batchNorm"),l=convertToTensor(n,"variance","batchNorm");let u,c;return null!=a&&(u=convertToTensor(a,"scale","batchNorm")),null!=r&&(c=convertToTensor(r,"offset","batchNorm")),assert$4(3===o.rank,()=>`Error in batchNorm3D: x must be rank 3 but got rank ${o.rank}.`),assert$4(3===i.rank||1===i.rank,()=>`Error in batchNorm3D: mean must be rank 3 or rank 1 but got rank ${i.rank}.`),assert$4(3===l.rank||1===l.rank,()=>`Error in batchNorm3D: variance must be rank 3 or rank 1 but got rank ${l.rank}.`),null!=u&&assert$4(3===u.rank||1===u.rank,()=>`Error in batchNorm3D: scale must be rank 3 or rank 1 but got rank ${u.rank}.`),null!=c&&assert$4(3===c.rank||1===c.rank,()=>`Error in batchNorm3D: offset must be rank 3 or rank 1 but got rank ${c.rank}.`),batchNorm$2(o,i,l,c,u,s)}const batchNorm3d=op({batchNorm3d_});function batchNorm4d_(e,t,n,r,a,s){const o=convertToTensor(e,"x","batchNorm"),i=convertToTensor(t,"mean","batchNorm"),l=convertToTensor(n,"variance","batchNorm");let u,c;return null!=a&&(u=convertToTensor(a,"scale","batchNorm")),null!=r&&(c=convertToTensor(r,"offset","batchNorm")),assert$4(4===o.rank,()=>`Error in batchNorm4D: x must be rank 4 but got rank ${o.rank}.`),assert$4(4===i.rank||1===i.rank,()=>`Error in batchNorm4D: mean must be rank 4 or rank 1 but got rank ${i.rank}.`),assert$4(4===l.rank||1===l.rank,()=>`Error in batchNorm4D: variance must be rank 4 or rank 1 but got rank ${l.rank}.`),null!=u&&assert$4(4===u.rank||1===u.rank,()=>`Error in batchNorm4D: scale must be rank 4 or rank 1 but got rank ${u.rank}.`),null!=c&&assert$4(4===c.rank||1===c.rank,()=>`Error in batchNorm4D: offset must be rank 4 or rank 1 but got rank ${c.rank}.`),batchNorm$2(o,i,l,c,u,s)}const batchNorm4d=op({batchNorm4d_});function bincount_(e,t,n){const r=convertToTensor(e,"x","bincount"),a=convertToTensor(t,"weights","bincount");return assert$4("int32"===r.dtype,()=>`Error in bincount: input dtype must be int32, but got ${r.dtype}`),assert$4(n>=0,()=>`size must be non-negative, but got ${n}.`),assert$4(a.size===r.size||0===a.size,()=>`Error in bincount: weights must have the same size as input or0-length, but got input shape: ${r.shape}, weights shape: ${a.shape}.`),ENGINE.runKernel(Bincount,{x:r,weights:a},{size:n})}const bincount$2=op({bincount_});function broadcastTo_(e,t){let n=convertToTensor(e,"broadcastTo","x");const r=n.shape;if(t.some(e=>!(e>0)||e%1!=0))throw new Error(`broadcastTo(): Invalid broadcast shape [${t}].`);if(t.length<n.rank)throw new Error(`broadcastTo(): shape.length=${t.length} < input.rank=${n.rank}.`);if(t.length>n.rank){const e=n.shape.slice();for(;e.length<t.length;)e.unshift(1);n=reshape$3(n,e)}const a=n.shape,s=Array.from(t);for(let e=t.length-1;e>=0;e--)if(a[e]===t[e])s[e]=1;else if(1!==n.shape[e])throw new Error(`broadcastTo(): [${r}] cannot be broadcast to [${t}].`);return 0===s.map((e,t)=>e>1?t:-1).filter(e=>e>=0).length?clone(n):ENGINE.runKernel(Tile,{x:n},{reps:s})}const broadcastTo=op({broadcastTo_});function ceil_(e){const t=convertToTensor(e,"x","ceil");return ENGINE.runKernel(Ceil,{x:t})}const ceil$2=op({ceil_});function clipByValue_(e,t,n){const r=convertToTensor(e,"x","clipByValue");return assert$4(t<=n,()=>`Error in clip: min (${t}) must be less than or equal to max (${n}).`),ENGINE.runKernel(ClipByValue,{x:r},{clipValueMin:t,clipValueMax:n})}const clipByValue$1=op({clipByValue_});function concat1d_(e){return concat$2(e,0)}const concat1d=op({concat1d_});function concat2d_(e,t){return concat$2(e,t)}const concat2d=op({concat2d_});function concat3d_(e,t){return concat$2(e,t)}const concat3d=op({concat3d_});function concat4d_(e,t){return concat$2(e,t)}const concat4d=op({concat4d_});function conv2d_(e,t,n,r,a="NHWC",s=[1,1],o){const i=convertToTensor(e,"x","conv2d"),l=convertToTensor(t,"filter","conv2d");let u=i,c=!1;3===i.rank&&(c=!0,u=reshape$3(i,[1,i.shape[0],i.shape[1],i.shape[2]])),assert$4(4===u.rank,()=>`Error in conv2d: input must be rank 4, but got rank ${u.rank}.`),assert$4(4===l.rank,()=>`Error in conv2d: filter must be rank 4, but got rank ${l.rank}.`),null!=o&&assert$4(isInt(r),()=>`Error in conv2d: pad must be an integer when using, dimRoundingMode ${o} but got pad ${r}.`);const p="NHWC"===a?u.shape[3]:u.shape[1];assert$4(p===l.shape[2],()=>`Error in conv2d: depth of input (${p}) must match input depth for filter ${l.shape[2]}.`),assert$4(eitherStridesOrDilationsAreOne(n,s),()=>`Error in conv2D: Either strides or dilations must be 1. Got strides ${n} and dilations '${s}'`);const d=ENGINE.runKernel(Conv2D$1,{x:u,filter:l},{strides:n,pad:r,dataFormat:a,dilations:s,dimRoundingMode:o});return c?reshape$3(d,[d.shape[1],d.shape[2],d.shape[3]]):d}const conv2d$3=op({conv2d_});function conv1d_(e,t,n,r,a="NWC",s=1,o){const i=convertToTensor(e,"x","conv1d"),l=convertToTensor(t,"filter","conv1d");let u=i,c=!1;2===i.rank&&(c=!0,u=reshape$3(i,[1,i.shape[0],i.shape[1]])),assert$4(3===u.rank,()=>`Error in conv1d: input must be rank 3, but got rank ${u.rank}.`),assert$4(3===l.rank,()=>`Error in conv1d: filter must be rank 3, but got rank ${l.rank}.`),null!=o&&assert$4(isInt(r),()=>`Error in conv1d: pad must be an integer when using, dimRoundingMode ${o} but got pad ${r}.`),assert$4(u.shape[2]===l.shape[1],()=>`Error in conv1d: depth of input (${u.shape[2]}) must match input depth for filter ${l.shape[1]}.`),assert$4(eitherStridesOrDilationsAreOne(n,s),()=>`Error in conv1D: Either stride or dilation must be 1. Got stride ${n} and dilation '${s}'`),assert$4("NWC"===a,()=>`Error in conv1d: got dataFormat of ${a} but only NWC is currently supported.`);const p=reshape$3(l,[1,l.shape[0],l.shape[1],l.shape[2]]),d=reshape$3(u,[u.shape[0],1,u.shape[1],u.shape[2]]),h=conv2d$3(d,p,[1,n],r,"NHWC",[1,s],o);return reshape$3(h,c?[h.shape[2],h.shape[3]]:[h.shape[0],h.shape[2],h.shape[3]])}const conv1d$1=op({conv1d_});function conv2DBackpropInput_(e,t,n,r,a,s="NHWC",o){assert$4(e.length===t.rank,()=>`Length of inShape (${e.length}) and rank of dy (${t.rank}) must match`);let i=e,l=t,u=!1;3===t.rank&&(u=!0,l=reshape$3(t,[1,t.shape[0],t.shape[1],t.shape[2]]),i=[1,e[0],e[1],e[2]]),assert$4(4===i.length,()=>`Error in conv2dDerInput: inShape must be length 4, but got length ${i.length}.`),assert$4(4===l.rank,()=>`Error in conv2dDerInput: dy must be rank 4, but got rank ${l.rank}`),assert$4(4===n.rank,()=>`Error in conv2dDerInput: filter must be rank 4, but got rank ${n.rank}`);const c="NHWC"===s?i[3]:i[1],p="NHWC"===s?l.shape[3]:l.shape[1];assert$4(c===n.shape[2],()=>`Error in conv2dDerInput: depth of input (${c}) must match input depth for filter ${n.shape[2]}.`),assert$4(p===n.shape[3],()=>`Error in conv2dDerInput: depth of output (${p}) must match output depth for filter ${n.shape[3]}.`),null!=o&&assert$4(isInt(a),()=>`Error in conv2dDerInput: pad must be an integer when using, dimRoundingMode ${o} but got pad ${a}.`);const d=ENGINE.runKernel(Conv2DBackpropInput,{dy:l,filter:n},{strides:r,pad:a,dataFormat:s,dimRoundingMode:o,inputShape:i});return u?reshape$3(d,[d.shape[1],d.shape[2],d.shape[3]]):d}const conv2DBackpropInput$2=op({conv2DBackpropInput_});function conv2dTranspose_(e,t,n,r,a,s){const o=convertToTensor(e,"x","conv2dTranspose"),i=convertToTensor(t,"filter","conv2dTranspose");return conv2DBackpropInput$2(n,o,i,r,a,"NHWC",s)}const conv2dTranspose$1=op({conv2dTranspose_});function conv3d_(e,t,n,r,a="NDHWC",s=[1,1,1]){const o=convertToTensor(e,"x","conv3d"),i=convertToTensor(t,"filter","conv3d");let l=o,u=!1;4===o.rank&&(u=!0,l=reshape$3(o,[1,o.shape[0],o.shape[1],o.shape[2],o.shape[3]])),assert$4(5===l.rank,()=>`Error in conv3d: input must be rank 5, but got rank ${l.rank}.`),assert$4(5===i.rank,()=>`Error in conv3d: filter must be rank 5, but got rank ${i.rank}.`),assert$4(l.shape[4]===i.shape[3],()=>`Error in conv3d: depth of input (${l.shape[4]}) must match input depth for filter ${i.shape[3]}.`),assert$4(eitherStridesOrDilationsAreOne(n,s),()=>`Error in conv3D: Either strides or dilations must be 1. Got strides ${n} and dilations '${s}'`),assert$4("NDHWC"===a,()=>`Error in conv3d: got dataFormat of ${a} but only NDHWC is currently supported.`);const c=ENGINE.runKernel(Conv3D$1,{x:l,filter:i},{strides:n,pad:r,dataFormat:a,dilations:s});return u?reshape$3(c,[c.shape[1],c.shape[2],c.shape[3],c.shape[4]]):c}const conv3d$1=op({conv3d_});function conv3DBackpropInput_(e,t,n,r,a){assert$4(e.length===t.rank,()=>`Length of inShape (${e.length}) and rank of dy (${t.rank}) must match`);let s=e,o=t,i=!1;4===t.rank&&(i=!0,o=reshape$3(t,[1,t.shape[0],t.shape[1],t.shape[2],t.shape[3]]),s=[1,e[0],e[1],e[2],e[3]]);const l=s[4],u=o.shape[4];assert$4(5===s.length,()=>`Error in conv3dDerInput: inShape must be length 5, but got length ${s.length}.`),assert$4(5===o.rank,()=>`Error in conv3dDerInput: dy must be rank 5, but got rank ${o.rank}`),assert$4(5===n.rank,()=>`Error in conv3dDerInput: filter must be rank 5, but got rank ${n.rank}`),assert$4(l===n.shape[3],()=>`Error in conv3dDerInput: depth of input (${l}) must match input depth for filter ${n.shape[3]}.`),assert$4(u===n.shape[4],()=>`Error in conv3dDerInput: depth of output (${u}) must match output depth for filter ${n.shape[4]}.`);const c=ENGINE.runKernel(Conv3DBackpropInputV2,{dy:o,filter:n},{pad:a,strides:r,inputShape:s});return i?reshape$3(c,[c.shape[1],c.shape[2],c.shape[3],c.shape[4]]):c}const conv3DBackpropInput$1=op({conv3DBackpropInput_});function conv3dTranspose_(e,t,n,r,a){const s=convertToTensor(e,"x","conv3dTranspose"),o=convertToTensor(t,"filter","conv3dTranspose");return conv3DBackpropInput$1(n,s,o,r,a)}const conv3dTranspose$1=op({conv3dTranspose_});function cos_(e){const t=convertToTensor(e,"x","cos");return ENGINE.runKernel(Cos,{x:t})}const cos$2=op({cos_});function cosh_(e){const t=convertToTensor(e,"x","cosh");return ENGINE.runKernel(Cosh,{x:t})}const cosh$2=op({cosh_});function cumsum_(e,t=0,n=!1,r=!1){const a=convertToTensor(e,"x","cumsum");return ENGINE.runKernel(Cumsum,{x:a},{axis:t,exclusive:n,reverse:r})}const cumsum$2=op({cumsum_});function denseBincount_(e,t,n,r=!1){const a=convertToTensor(e,"x","denseBincount"),s=convertToTensor(t,"weights","denseBincount");return assert$4("int32"===a.dtype,()=>`Error in denseBincount: input dtype must be int32, but got ${a.dtype}`),assert$4(a.rank<=2,()=>`Error in denseBincount: input must be at most rank 2, but got rank ${a.rank}.`),assert$4(n>=0,()=>`size must be non-negative, but got ${n}.`),assert$4(s.size===a.size||0===s.size,()=>`Error in denseBincount: weights must have the same shape as x or 0-length, but got x shape: ${a.shape}, weights shape: ${s.shape}.`),ENGINE.runKernel(DenseBincount,{x:a,weights:s},{size:n,binaryOutput:r})}const denseBincount$2=op({denseBincount_});function depthToSpace_(e,t,n="NHWC"){const r=convertToTensor(e,"x","depthToSpace"),a="NHWC"===n?r.shape[1]:r.shape[2],s="NHWC"===n?r.shape[2]:r.shape[3],o="NHWC"===n?r.shape[3]:r.shape[1];return assert$4(a*t>=0,()=>`Negative dimension size caused by overflow when multiplying\n    ${a} and ${t}  for depthToSpace with input shape\n    ${r.shape}`),assert$4(s*t>=0,()=>`Negative dimension size caused by overflow when multiplying\n    ${s} and ${t} for depthToSpace with input shape\n        ${r.shape}`),assert$4(o%(t*t)==0,()=>`Dimension size must be evenly divisible by ${t*t} but is ${o} for depthToSpace with input shape ${r.shape}`),ENGINE.runKernel(DepthToSpace,{x:r},{blockSize:t,dataFormat:n})}const depthToSpace$2=op({depthToSpace_});function depthwiseConv2d_(e,t,n,r,a="NHWC",s=[1,1],o){const i=convertToTensor(e,"x","depthwiseConv2d"),l=convertToTensor(t,"filter","depthwiseConv2d");let u=i,c=!1;3===i.rank&&(c=!0,u=reshape$3(i,[1,i.shape[0],i.shape[1],i.shape[2]])),assert$4(4===u.rank,()=>`Error in depthwiseConv2d: input must be rank 4, but got rank ${u.rank}.`),assert$4(4===l.rank,()=>`Error in depthwiseConv2d: filter must be rank 4, but got rank ${l.rank}.`),assert$4(u.shape[3]===l.shape[2],()=>`Error in depthwiseConv2d: number of input channels (${u.shape[3]}) must match the inChannels dimension in filter ${l.shape[2]}.`),null!=o&&assert$4(isInt(r),()=>`Error in depthwiseConv2d: pad must be an integer when using, dimRoundingMode ${o} but got pad ${r}.`);const p=ENGINE.runKernel(DepthwiseConv2dNative,{x:u,filter:l},{strides:n,pad:r,dataFormat:a,dilations:s,dimRoundingMode:o});return c?reshape$3(p,[p.shape[1],p.shape[2],p.shape[3]]):p}const depthwiseConv2d$3=op({depthwiseConv2d_});function diag_(e){const t=convertToTensor(e,"x","diag");return ENGINE.runKernel(Diag,{x:t})}const diag$2=op({diag_});function dilation2d_(e,t,n,r,a=[1,1],s="NHWC"){const o=convertToTensor(e,"x","dilation2d"),i=convertToTensor(t,"filter","dilation2d");assert$4(3===o.rank||4===o.rank,()=>`Error in dilation2d: input must be rank 3 or 4, but got rank ${o.rank}.`),assert$4(3===i.rank,()=>`Error in dilation2d: filter must be rank 3, but got rank ${i.rank}.`),assert$4("NHWC"===s,()=>`Error in dilation2d: Only NHWC is currently supported, but got dataFormat of ${s}`);let l=o,u=!1;3===o.rank&&(l=reshape$3(o,[1,o.shape[0],o.shape[1],o.shape[2]]),u=!0);const c=ENGINE.runKernel(Dilation2D,{x:l,filter:i},{strides:n,pad:r,dilations:a});return u?reshape$3(c,[c.shape[1],c.shape[2],c.shape[3]]):c}const dilation2d=op({dilation2d_});function getBroadcastDims$1(e,t){const n=e.length,r=[];for(let a=0;a<n;a++){const s=n-1-a,o=e[s]||1;(t[t.length-1-a]||1)>1&&1===o&&r.unshift(s)}return r}function getReductionAxes(e,t){const n=[];for(let r=0;r<t.length;r++){const a=e[e.length-r-1],s=t.length-r-1,o=t[s];(null==a||1===a&&o>1)&&n.unshift(s)}return n}function assertAndGetBroadcastShape(e,t){const n=[],r=Math.max(e.length,t.length);for(let a=0;a<r;a++){let r=e[e.length-a-1];null==r&&(r=1);let s=t[t.length-a-1];if(null==s&&(s=1),1===r)n.unshift(s);else if(1===s)n.unshift(r);else{if(r!==s)throw Error(`Operands could not be broadcast together with shapes ${e} and ${t}.`);n.unshift(r)}}return n}function equal_(e,t){let n=convertToTensor(e,"a","equal","string_or_numeric"),r=convertToTensor(t,"b","equal","string_or_numeric");return[n,r]=makeTypesMatch(n,r),assertAndGetBroadcastShape(n.shape,r.shape),ENGINE.runKernel(Equal,{a:n,b:r})}const equal$2=op({equal_});function where_(e,t,n){const r=convertToTensor(t,"a","where"),a=convertToTensor(n,"b","where"),s=convertToTensor(e,"condition","where","bool"),o=assertAndGetBroadcastShape(assertAndGetBroadcastShape(s.shape,r.shape),a.shape),i=broadcastTo(s,o),l=broadcastTo(r,o),u=broadcastTo(a,o);return ENGINE.runKernel(Select,{condition:i,t:l,e:u})}const where=op({where_});function zerosLike_(e){const t=convertToTensor(e,"x","zerosLike");return ENGINE.runKernel(ZerosLike,{x:t})}const zerosLike$2=op({zerosLike_});function divNoNan_(e,t){let n=convertToTensor(e,"a","div"),r=convertToTensor(t,"b","div");[n,r]=makeTypesMatch(n,r);const a=div$1(n,r),s=zerosLike$2(a),o=equal$2(r,s);return where(o,s,a)}const divNoNan=op({divNoNan_});function dot_(e,t){const n=convertToTensor(e,"t1","dot"),r=convertToTensor(t,"t2","dot");assert$4(!(1!==n.rank&&2!==n.rank||1!==r.rank&&2!==r.rank),()=>`Error in dot: inputs must all be rank 1 or 2, but got ranks ${n.rank} and ${r.rank}.`);const a=1===n.rank?n.size:n.shape[1],s=1===r.rank?r.size:r.shape[0];if(assert$4(a===s,()=>`Error in dot: inner dimensions of inputs must match, but got ${a} and ${s}.`),1===n.rank&&1===r.rank){const e=reshape$3(n,[1,-1]),t=reshape$3(r,[-1,1]),a=matMul$1(e,t);return reshape$3(a,[])}if(1===n.rank&&2===r.rank){const e=reshape$3(n,[1,-1]),t=reshape$3(r,[r.shape[0],r.shape[1]]),a=matMul$1(e,t);return reshape$3(a,[a.size])}if(2===n.rank&&1===r.rank){const e=reshape$3(r,[-1,1]),t=matMul$1(n,e);return reshape$3(t,[t.size])}{const e=reshape$3(r,[r.shape[0],r.shape[1]]);return matMul$1(n,e)}}const dot$2=op({dot_});function einsum_(e,...t){const n=t.map((e,t)=>convertToTensor(e,`tensors${t}`,"einsum"));return ENGINE.runKernel(Einsum,n,{equation:e})}const einsum$2=op({einsum_});function elu_(e){const t=convertToTensor(e,"x","elu");return ENGINE.runKernel(Elu$1,{x:t})}const elu$4=op({elu_});function erf_(e){let t=convertToTensor(e,"x","erf");return assert$4("int32"===t.dtype||"float32"===t.dtype,()=>"Input dtype must be `int32` or `float32`."),"int32"===t.dtype&&(t=cast$3(t,"float32")),ENGINE.runKernel(Erf,{x:t})}const erf$2=op({erf_});function exp_(e){const t=convertToTensor(e,"x","exp");return ENGINE.runKernel(Exp,{x:t})}const exp$2=op({exp_});function expandDims_(e,t=0){const n=convertToTensor(e,"x","expandDims","string_or_numeric");return assert$4(t<=n.rank,()=>"Axis must be <= rank of the tensor"),ENGINE.runKernel(ExpandDims,{input:n},{dim:t})}const expandDims$3=op({expandDims_});function expm1_(e){const t=convertToTensor(e,"x","expm1");return ENGINE.runKernel(Expm1,{x:t})}const expm1$2=op({expm1_});function tile_(e,t){const n=convertToTensor(e,"x","tile","string_or_numeric");return assert$4(n.rank===t.length,()=>`Error in transpose: rank of input ${n.rank} must match length of reps ${t}.`),ENGINE.runKernel(Tile,{x:n},{reps:t})}const tile$3=op({tile_});function eye_(e,t,n,r="float32"){null==t&&(t=e);const a=buffer([e,t],r),s=e<=t?e:t;for(let e=0;e<s;++e)a.set(1,e,e);const o=reshape$3(a.toTensor(),[e,t]);if(null==n)return o;if(1===n.length)return tile$3(expandDims$3(o,0),[n[0],1,1]);if(2===n.length)return tile$3(expandDims$3(expandDims$3(o,0),0),[n[0],n[1],1,1]);if(3===n.length)return tile$3(expandDims$3(expandDims$3(expandDims$3(o,0),0),0),[n[0],n[1],n[2],1,1]);throw new Error(`eye() currently supports only 1D and 2D batchShapes, but received ${n.length}D.`)}const eye=op({eye_});function fill$2(e,t,n){return ENGINE.runKernel(Fill,{},{shape:e,value:t,dtype:n})}function floor_(e){const t=convertToTensor(e,"x","floor");return ENGINE.runKernel(Floor,{x:t})}const floor$2=op({floor_});function gather_(e,t,n=0,r=0){const a=convertToTensor(e,"x","gather"),s=convertToTensor(t,"indices","gather","int32");return ENGINE.runKernel(GatherV2,{x:a,indices:s},{axis:n,batchDims:r})}const gather$1=op({gather_});function greater_(e,t){let n=convertToTensor(e,"a","greater","string_or_numeric"),r=convertToTensor(t,"b","greater","string_or_numeric");return[n,r]=makeTypesMatch(n,r),assertAndGetBroadcastShape(n.shape,r.shape),ENGINE.runKernel(Greater,{a:n,b:r})}const greater$3=op({greater_});function greaterEqual_(e,t){let n=convertToTensor(e,"a","greaterEqual","string_or_numeric"),r=convertToTensor(t,"b","greaterEqual","string_or_numeric");return[n,r]=makeTypesMatch(n,r),assertAndGetBroadcastShape(n.shape,r.shape),ENGINE.runKernel(GreaterEqual,{a:n,b:r})}const greaterEqual$2=op({greaterEqual_});function imag_(e){const t=convertToTensor(e,"input","imag");return ENGINE.runKernel(Imag,{input:t})}const imag$2=op({imag_});function isFinite_(e){const t=convertToTensor(e,"x","isFinite");return ENGINE.runKernel(IsFinite,{x:t})}const isFinite$3=op({isFinite_});function isInf_(e){const t=convertToTensor(e,"x","isInf");return ENGINE.runKernel(IsInf,{x:t})}const isInf$2=op({isInf_});function isNaN_(e){const t=convertToTensor(e,"x","isNaN");return ENGINE.runKernel(IsNan,{x:t})}const isNaN$3=op({isNaN_});function leakyRelu_(e,t=.2){const n=convertToTensor(e,"x","leakyRelu");return ENGINE.runKernel(LeakyRelu,{x:n},{alpha:t})}const leakyRelu$2=op({leakyRelu_});function less_(e,t){let n=convertToTensor(e,"a","less","string_or_numeric"),r=convertToTensor(t,"b","less","string_or_numeric");return[n,r]=makeTypesMatch(n,r),assertAndGetBroadcastShape(n.shape,r.shape),ENGINE.runKernel(Less,{a:n,b:r})}const less$3=op({less_});function lessEqual_(e,t){let n=convertToTensor(e,"a","lessEqual","string_or_numeric"),r=convertToTensor(t,"b","lessEqual","string_or_numeric");return[n,r]=makeTypesMatch(n,r),assertAndGetBroadcastShape(n.shape,r.shape),ENGINE.runKernel(LessEqual,{a:n,b:r})}const lessEqual$2=op({lessEqual_});function linspace(e,t,n){if(n<=0)throw new Error("The number of values should be positive.");return ENGINE.runKernel(LinSpace,{},{start:e,stop:t,num:n})}function localResponseNormalization_(e,t=5,n=1,r=1,a=.5){const s=convertToTensor(e,"x","localResponseNormalization");assert$4(4===s.rank||3===s.rank,()=>`Error in localResponseNormalization: x must be rank 3 or 4 but got\n               rank ${s.rank}.`),assert$4(isInt(t),()=>`Error in localResponseNormalization: depthRadius must be an integer but got depthRadius ${t}.`);let o=s,i=!1;3===s.rank&&(i=!0,o=reshape$3(s,[1,s.shape[0],s.shape[1],s.shape[2]]));const l=ENGINE.runKernel(LRN,{x:o},{depthRadius:t,bias:n,alpha:r,beta:a});return i?reshape$3(l,[l.shape[1],l.shape[2],l.shape[3]]):l}const localResponseNormalization=op({localResponseNormalization_});function log_(e){const t=convertToTensor(e,"x","log");return ENGINE.runKernel(Log,{x:t})}const log$3=op({log_});function log1p_(e){const t=convertToTensor(e,"x","log1p");return ENGINE.runKernel(Log1p,{x:t})}const log1p$2=op({log1p_});function grad(e){return assert$4(isFunction(e),()=>"The f passed in grad(f) must be a function"),(t,n)=>{const r=convertToTensor(t,"x","tf.grad","string_or_numeric"),a=null!=n?convertToTensor(n,"dy","tf.grad"):null;return ENGINE.tidy(()=>{const{value:t,grads:n}=ENGINE.gradients(()=>e(r),[r],a);return null!=a&&assertShapesMatch(t.shape,a.shape,"The shape of dy passed in grad(f)(x, dy) must match the shape returned by f(x)"),checkGrads(n),n[0]})}}function grads(e){return assert$4(isFunction(e),()=>"The f passed in grads(f) must be a function"),(t,n)=>{assert$4(Array.isArray(t),()=>"The args passed in grads(f)(args) must be an array of `Tensor`s or `TensorLike`s");const r=convertToTensorArray(t,"args","tf.grads","string_or_numeric"),a=null!=n?convertToTensor(n,"dy","tf.grads"):null;return ENGINE.tidy(()=>{const{value:t,grads:n}=ENGINE.gradients(()=>e(...r),r,a);return null!=a&&assertShapesMatch(t.shape,a.shape,"The shape of dy passed in grads(f)([x1,...], dy) must match the shape returned by f([x1,...])"),checkGrads(n),n})}}function valueAndGrad(e){return assert$4(isFunction(e),()=>"The f passed in valueAndGrad(f) must be a function"),(t,n)=>{assert$4(t instanceof Tensor,()=>"The x passed in valueAndGrad(f)(x) must be a tensor"),assert$4(null==n||n instanceof Tensor,()=>"The dy passed in valueAndGrad(f)(x, dy) must be a tensor");const{grads:r,value:a}=ENGINE.gradients(()=>e(t),[t],n);return checkGrads(r),{grad:r[0],value:a}}}function valueAndGrads(e){return assert$4(isFunction(e),()=>"The f passed in valueAndGrads(f) must be a function"),(t,n)=>{assert$4(Array.isArray(t)&&t.every(e=>e instanceof Tensor),()=>"The args passed in valueAndGrads(f)(args) must be array of tensors"),assert$4(null==n||n instanceof Tensor,()=>"The dy passed in valueAndGrads(f)(args, dy) must be a tensor");const r=ENGINE.gradients(()=>e(...t),t,n);return null!=n&&assertShapesMatch(r.value.shape,n.shape,"The shape of dy passed in valueAndGrads(f)([x1,...], dy) must match the shape returned by f([x1,...])"),checkGrads(r.grads),r}}function variableGrads(e,t){assert$4(isFunction(e),()=>"The f passed in variableGrads(f) must be a function"),assert$4(null==t||Array.isArray(t)&&t.every(e=>e instanceof Variable),()=>"The varList passed in variableGrads(f, varList) must be an array of variables");const n=null!=t;if(!n){t=[];for(const e in ENGINE.registeredVariables)t.push(ENGINE.registeredVariables[e])}const r=n?t.filter(e=>!e.trainable):null,a=t.length;assert$4((t=t.filter(e=>e.trainable)).length>0,()=>`variableGrads() expects at least one of the input variables to be trainable, but none of the ${a} variables is trainable.`);const{value:s,grads:o}=ENGINE.gradients(e,t,null,!0);assert$4(o.some(e=>null!=e),()=>"Cannot find a connection between any variable and the result of the loss function y=f(x). Please make sure the operations that use variables are inside the function f passed to minimize()."),assert$4(0===s.rank,()=>`The f passed in variableGrads(f) must return a scalar, but it returned a rank-${s.rank} tensor`);const i={};return t.forEach((e,t)=>{null!=o[t]&&(i[e.name]=o[t])}),null!=r&&r.forEach(e=>i[e.name]=null),{value:s,grads:i}}function customGrad(e){return ENGINE.customGrad(e)}function checkGrads(e){if(e.filter(e=>null==e).length>0)throw new Error("Cannot compute gradient of y=f(x) with respect to x. Make sure that\n    the f you passed encloses all operations that lead from x to y.")}function neg_(e){const t=convertToTensor(e,"x","neg");return ENGINE.runKernel(Neg,{x:t})}const neg$2=op({neg_});function softplus_(e){const t=convertToTensor(e,"x","softplus");return ENGINE.runKernel(Softplus$1,{x:t})}const softplus$2=op({softplus_});function logSigmoid_(e){const t=convertToTensor(e,"x","logSigmoid");return customGrad(e=>({value:neg$2(softplus$2(neg$2(e))),gradFunc:t=>mul(t,sigmoid$2(neg$2(e)))}))(t)}const logSigmoid=op({logSigmoid_});function max_(e,t=null,n=!1){const r=convertToTensor(e,"x","max");return ENGINE.runKernel(Max,{x:r},{reductionIndices:t,keepDims:n})}const max$3=op({max_});function sub_(e,t){let n=convertToTensor(e,"a","sub"),r=convertToTensor(t,"b","sub");return[n,r]=makeTypesMatch(n,r),ENGINE.runKernel(Sub,{a:n,b:r})}const sub$2=op({sub_});function sum_(e,t=null,n=!1){let r=convertToTensor(e,"x","sum");return"bool"===r.dtype&&(r=cast$3(r,"int32")),ENGINE.runKernel(Sum,{x:r},{axis:t,keepDims:n})}const sum$2=op({sum_});function logSoftmax_(e,t=-1){const n=convertToTensor(e,"logits","logSoftmax");if(-1===t&&(t=n.rank-1),t!==n.rank-1)throw Error(`Log Softmax along a non-last dimension is not yet supported. Logits was rank ${n.rank} and axis was ${t}`);return customGrad((e,n)=>{const r=max$3(e,t,!0),a=sub$2(e,r),s=sub$2(cast$3(a,"float32"),log$3(sum$2(exp$2(a),t,!0)));return n([s]),{value:s,gradFunc:(e,n)=>{const[r]=n,a=exp$2(r);return sub$2(e,mul(sum$2(e,t,!0),a))}}})(n)}const logSoftmax=op({logSoftmax_});function axesAreInnerMostDims(e,t){for(let n=0;n<e.length;++n)if(e[e.length-n-1]!==t-1-n)return!1;return!0}function combineLocations(e,t,n){const r=e.length+t.length,a=[];let s=0,o=0;for(let i=0;i<r;i++)-1===n.indexOf(i)?a.push(e[s++]):a.push(t[o++]);return a}function computeOutAndReduceShapes(e,t){const n=[],r=e.length;for(let a=0;a<r;a++)-1===t.indexOf(a)&&n.push(e[a]);return[n,t.map(t=>e[t])]}function expandShapeToKeepDim(e,t){return combineLocations(e,t.map(e=>1),t)}function assertAxesAreInnerMostDims(e,t,n){assert$4(axesAreInnerMostDims(t,n),()=>`${e} supports only inner-most axes for now. Got axes ${t} and rank-${n} input.`)}function getAxesPermutation(e,t){if(axesAreInnerMostDims(e,t))return null;const n=[];for(let r=0;r<t;++r)-1===e.indexOf(r)&&n.push(r);return e.forEach(e=>n.push(e)),n}function getUndoAxesPermutation(e){return e.map((e,t)=>[t,e]).sort((e,t)=>e[1]-t[1]).map(e=>e[0])}function getInnerMostAxes(e,t){const n=[];for(let r=t-e;r<t;++r)n.push(r);return n}function logSumExp_(e,t=null,n=!1){const r=convertToTensor(e,"x","logSumExp"),a=parseAxisParam(t,r.shape),s=max$3(r,a,!0),o=sub$2(r,s),i=exp$2(o),l=sum$2(i,a),u=log$3(l),c=add$2(reshape$3(s,u.shape),u);if(n){const e=expandShapeToKeepDim(c.shape,a);return reshape$3(c,e)}return c}const logSumExp=op({logSumExp_});function logicalAnd_(e,t){const n=convertToTensor(e,"a","logicalAnd","bool"),r=convertToTensor(t,"b","logicalAnd","bool");return assertAndGetBroadcastShape(n.shape,r.shape),ENGINE.runKernel(LogicalAnd,{a:n,b:r})}const logicalAnd$2=op({logicalAnd_});function logicalNot_(e){const t=convertToTensor(e,"x","logicalNot","bool");return ENGINE.runKernel(LogicalNot,{x:t})}const logicalNot$2=op({logicalNot_});function logicalOr_(e,t){const n=convertToTensor(e,"a","logicalOr","bool"),r=convertToTensor(t,"b","logicalOr","bool");return assertAndGetBroadcastShape(n.shape,r.shape),ENGINE.runKernel(LogicalOr,{a:n,b:r})}const logicalOr$2=op({logicalOr_});function logicalXor_(e,t){const n=convertToTensor(e,"a","logicalXor","bool"),r=convertToTensor(t,"b","logicalXor","bool");return assertAndGetBroadcastShape(n.shape,r.shape),logicalAnd$2(logicalOr$2(e,t),logicalNot$2(logicalAnd$2(e,t)))}const logicalXor=op({logicalXor_});function maxPool_(e,t,n,r,a){const s=convertToTensor(e,"x","maxPool");let o=s,i=!1;3===s.rank&&(i=!0,o=reshape$3(s,[1,s.shape[0],s.shape[1],s.shape[2]])),assert$4(4===o.rank,()=>`Error in maxPool: input must be rank 4 but got rank ${o.rank}.`),assert$4(eitherStridesOrDilationsAreOne(n,1),()=>`Error in maxPool: Either strides or dilations must be 1. Got strides ${n} and dilations '1'`),null!=a&&assert$4(isInt(r),()=>`Error in maxPool: pad must be an integer when using, dimRoundingMode ${a} but got pad ${r}.`);const l=ENGINE.runKernel(MaxPool,{x:o},{filterSize:t,strides:n,pad:r,dimRoundingMode:a});return i?reshape$3(l,[l.shape[1],l.shape[2],l.shape[3]]):l}const maxPool$2=op({maxPool_});function maxPool3d_(e,t=[1,1,1],n,r,a,s="NDHWC"){const o=convertToTensor(e,"x","maxPool3d");let i=o,l=!1;4===o.rank&&(l=!0,i=reshape$3(o,[1,o.shape[0],o.shape[1],o.shape[2],o.shape[3]])),assert$4(5===i.rank,()=>`Error in maxPool3d: x must be rank 5 but got rank ${i.rank}.`),assert$4("NDHWC"===s,()=>`Error in maxPool3d: Only NDHWC is currently supported, but got dataFormat of ${s}`),null!=a&&assert$4(isInt(r),()=>`Error in maxPool3d: pad must be an integer when using, dimRoundingMode ${a} but got pad ${r}.`);const u=ENGINE.runKernel(MaxPool3D,{x:i},{filterSize:t,strides:n,pad:r,dimRoundingMode:a,dataFormat:s});return l?reshape$3(u,[u.shape[1],u.shape[2],u.shape[3],u.shape[4]]):u}const maxPool3d$1=op({maxPool3d_});function maxPoolWithArgmax_(e,t,n,r,a=!1){const s=convertToTensor(e,"x","maxPoolWithArgmax"),o=ENGINE.runKernel(MaxPoolWithArgmax,{x:s},{filterSize:t,strides:n,pad:r,includeBatchInIndex:a});return{result:o[0],indexes:o[1]}}const maxPoolWithArgmax=op({maxPoolWithArgmax_});function maximum_(e,t){let n=convertToTensor(e,"a","maximum"),r=convertToTensor(t,"b","maximum");return[n,r]=makeTypesMatch(n,r),"bool"===n.dtype&&(n=cast$3(n,"int32"),r=cast$3(r,"int32")),assertAndGetBroadcastShape(n.shape,r.shape),ENGINE.runKernel(Maximum$1,{a:n,b:r})}const maximum$3=op({maximum_});function mean_(e,t=null,n=!1){const r=convertToTensor(e,"x","mean");return ENGINE.runKernel(Mean,{x:r},{axis:t,keepDims:n})}const mean$1=op({mean_});function zeros$2(e,t="float32"){if("complex64"===t){const t=zeros$2(e,"float32"),n=zeros$2(e,"float32");return complex$2(t,n)}const n=makeZerosTypedArray(sizeFromShape(e),t);return ENGINE.makeTensor(n,e,t)}function ones$1(e,t="float32"){if("complex64"===t){const t=ones$1(e,"float32"),n=zeros$2(e,"float32");return complex$2(t,n)}const n=makeOnesTypedArray(sizeFromShape(e),t);return ENGINE.makeTensor(n,e,t)}function meshgrid(e,t,{indexing:n="xy"}={}){if("xy"!==n&&"ij"!==n)throw new TypeError(`${n} is not a valid third argument to meshgrid`);if(void 0===e)return[];let r=convertToTensor(e,"x","meshgrid",e instanceof Tensor?e.dtype:"float32");if(void 0===t)return[r];let a=convertToTensor(t,"y","meshgrid",t instanceof Tensor?t.dtype:"float32");const s=sizeFromShape(r.shape),o=sizeFromShape(a.shape);return"xy"===n?(r=reshape$3(r,[1,-1]),a=reshape$3(a,[-1,1]),[matMul$1(ones$1([o,1],r.dtype),r),matMul$1(a,ones$1([1,s],a.dtype))]):(r=reshape$3(r,[-1,1]),a=reshape$3(a,[1,-1]),[matMul$1(r,ones$1([1,o],r.dtype)),matMul$1(ones$1([s,1],a.dtype),a)])}function min_(e,t=null,n=!1){const r=convertToTensor(e,"x","min");return ENGINE.runKernel(Min,{x:r},{axis:t,keepDims:n})}const min$3=op({min_});function minimum_(e,t){let n=convertToTensor(e,"a","minimum"),r=convertToTensor(t,"b","minimum");return[n,r]=makeTypesMatch(n,r),"bool"===n.dtype&&(n=cast$3(n,"int32"),r=cast$3(r,"int32")),assertAndGetBroadcastShape(n.shape,r.shape),ENGINE.runKernel(Minimum$1,{a:n,b:r})}const minimum$3=op({minimum_});function mirrorPad_(e,t,n){assert$4("reflect"===n||"symmetric"===n,()=>`Invalid mode. Mode must be either reflect or symmetric. Got ${n}.`);const r=convertToTensor(e,"x","mirrorPad");if(0===r.rank)throw new Error("mirrorPad(scalar) is not defined. Pass non-scalar to mirrorPad");assert$4(t.length===r.rank,()=>`Padding doesn't match input. Must be ${r.rank}. Got ${t.length}.`);const a="reflect"===n?1:0;for(let e=0;e<r.rank;e++)assert$4(2===t[e].length,()=>"Invalid number of paddings. Must be length of 2 each."),assert$4(t[e][0]>=0&&t[e][0]<=r.shape[e]-a&&t[e][1]>=0&&t[e][1]<=r.shape[e]-a,()=>`Padding in dimension ${e} cannot be greater than or equal to ${r.shape[e]-a} or less than 0 for input of shape ${r.shape}`);return ENGINE.runKernel(MirrorPad,{x:r},{paddings:t,mode:n})}const mirrorPad$1=op({mirrorPad_});function mod_(e,t){let n=convertToTensor(e,"a","mod"),r=convertToTensor(t,"b","mod");return[n,r]=makeTypesMatch(n,r),ENGINE.runKernel(Mod,{a:n,b:r})}const mod$2=op({mod_});function square_(e){const t=convertToTensor(e,"x","square");return ENGINE.runKernel("Square",{x:t},{})}const square$2=op({square_});function moments_(e,t=null,n=!1){const r=parseAxisParam(t,(e=convertToTensor(e,"x","moments")).shape),a=mean$1(e,r,n);let s=a.shape;n||(s=expandShapeToKeepDim(a.shape,r));const o=square$2(sub$2(cast$3(e,"float32"),reshape$3(a,s)));return{mean:a,variance:mean$1(o,r,n)}}const moments=op({moments_});function multiRNNCell_(e,t,n,r){const a=convertToTensor(t,"data","multiRNNCell"),s=convertToTensorArray(n,"c","multiRNNCell"),o=convertToTensorArray(r,"h","multiRNNCell");let i=a;const l=[];for(let t=0;t<e.length;t++){const n=e[t](i,s[t],o[t]);l.push(n[0]),l.push(n[1]),i=n[1]}const u=[],c=[];for(let e=0;e<l.length;e+=2)u.push(l[e]),c.push(l[e+1]);return[u,c]}const multiRNNCell=op({multiRNNCell_});function multinomial_(e,t,n,r=!1){const a=convertToTensor(e,"logits","multinomial"),s=a.size,o=a.rank;if(s<2)throw new Error(`Error in multinomial: you need at least 2 outcomes, but got ${s}.`);if(o>2)throw new Error(`Rank of probabilities must be 1 or 2, but is ${o}`);n=n||Math.random();const i=1===o?reshape$3(a,[1,-1]):a,l=ENGINE.runKernel(Multinomial,{logits:i},{numSamples:t,seed:n,normalized:r});return 1===o?reshape$3(l,[l.size]):l}const multinomial$2=op({multinomial_});function notEqual_(e,t){let n=convertToTensor(e,"a","notEqual","string_or_numeric"),r=convertToTensor(t,"b","notEqual","string_or_numeric");return[n,r]=makeTypesMatch(n,r),assertAndGetBroadcastShape(n.shape,r.shape),ENGINE.runKernel(NotEqual,{a:n,b:r})}const notEqual$2=op({notEqual_});function onesLike_(e){const t=convertToTensor(e,"x","onesLike");return ENGINE.runKernel(OnesLike,{x:t})}const onesLike$2=op({onesLike_});function outerProduct_(e,t){const n=convertToTensor(e,"v1","outerProduct"),r=convertToTensor(t,"v2","outerProduct");assert$4(1===n.rank&&1===r.rank,()=>`Error in outerProduct: inputs must be rank 1, but got ranks ${n.rank} and ${r.rank}.`);const a=reshape$3(n,[-1,1]),s=reshape$3(r,[1,-1]);return matMul$1(a,s)}const outerProduct=op({outerProduct_});function pad_(e,t,n=0){const r=convertToTensor(e,"x","pad");if(0===r.rank)throw new Error("pad(scalar) is not defined. Pass non-scalar to pad");return ENGINE.runKernel(PadV2,{x:r},{paddings:t,constantValue:n})}const pad=op({pad_});function pad1d_(e,t,n=0){return assert$4(2===t.length,()=>"Invalid number of paddings. Must be length of 2."),pad(e,[t],n)}const pad1d=op({pad1d_});function pad2d_(e,t,n=0){return assert$4(2===t.length&&2===t[0].length&&2===t[1].length,()=>"Invalid number of paddings. Must be length of 2 each."),pad(e,t,n)}const pad2d=op({pad2d_});function pad3d_(e,t,n=0){return assert$4(3===t.length&&2===t[0].length&&2===t[1].length&&2===t[2].length,()=>"Invalid number of paddings. Must be length of 2 each."),pad(e,t,n)}const pad3d=op({pad3d_});function pad4d_(e,t,n=0){return assert$4(4===t.length&&2===t[0].length&&2===t[1].length&&2===t[2].length&&2===t[3].length,()=>"Invalid number of paddings. Must be length of 2 each."),pad(e,t,n)}const pad4d=op({pad4d_});function spaceToBatchND_(e,t,n){const r=convertToTensor(e,"x","spaceToBatchND");return assert$4(r.rank>=1+t.length,()=>`input rank ${r.rank} should be > than [blockShape] ${t.length}`),assert$4(n.length===t.length,()=>`paddings.shape[0] ${n.length} must be equal to [blockShape] ${t.length}`),assert$4(r.shape.reduce((e,r,a)=>a>0&&a<=t.length?e&&(r+n[a-1][0]+n[a-1][1])%t[a-1]==0:e,!0),()=>`input spatial dimensions ${r.shape.slice(1)} with paddings ${n.toString()} must be divisible by blockShapes ${t.toString()}`),ENGINE.runKernel(SpaceToBatchND,{x:r},{blockShape:t,paddings:n})}const spaceToBatchND$2=op({spaceToBatchND_});function pool_(e,t,n,r,a,s){null==a&&(a=[1,1]),null==s&&(s=1),0===r&&(r="valid");const o=convertToTensor(e,"x","maxPool");let i=o,l=!1;3===o.rank&&(l=!0,i=reshape$3(o,[1,o.shape[0],o.shape[1],o.shape[2]])),assert$4(eitherStridesOrDilationsAreOne(s,a),()=>`Error in pool: Either strides or dilations must be 1. Got strides ${s} and dilations '${a}'`);const u=computePool2DInfo(i.shape,t,s,a,r),c=[u.dilationHeight,u.dilationWidth];let p;p="same"===r?withSpaceToBatchBasePaddings([u.filterHeight,u.filterWidth],c):[[0,0],[0,0]];const d=1===c[0]&&1===c[1],[h,m]=requiredSpaceToBatchPaddings([u.inHeight,u.inWidth],c,p),f=d?r:"valid",g=d?i:spaceToBatchND$2(i,c,h),$=("avg"===n?()=>avgPool$2(g,t,s,f):()=>maxPool$2(g,t,s,f))(),y=d?$:batchToSpaceND$2($,c,m);return l?reshape$3(y,[y.shape[1],y.shape[2],y.shape[3]]):y}function requiredSpaceToBatchPaddings(e,t,n){const r=n.map(e=>e[0]),a=n.map(e=>e[1]),s=e.concat(r,a),o=t.map((e,t)=>(e-s[t]%e)%e),i=a.map((e,t)=>e+o[t]);return[t.map((e,t)=>[r[t],i[t]]),t.map((e,t)=>[0,o[t]])]}function withSpaceToBatchBasePaddings(e,t){const n=e.map((e,n)=>e+(e-1)*(t[n]-1)).map(e=>e-1),r=n.map(e=>Math.floor(e/2)),a=n.map((e,t)=>e-r[t]);return n.map((e,t)=>[r[t],a[t]])}const pool$1=op({pool_});function pow_(e,t){let n=convertToTensor(e,"base","pow"),r=convertToTensor(t,"exp","pow");return[n,r]=makeTypesMatch(n,r),ENGINE.runKernel(Pow,{a:n,b:r})}const pow$2=op({pow_});function prelu_(e,t){const n=convertToTensor(e,"x","prelu"),r=convertToTensor(t,"alpha","prelu");return ENGINE.runKernel(Prelu,{x:n,alpha:r})}const prelu$3=op({prelu_});function prod_(e,t=null,n=!1){let r=convertToTensor(e,"x","prod");return"bool"===r.dtype&&(r=cast$3(r,"int32")),ENGINE.runKernel(Prod,{x:r},{axis:t,keepDims:n})}const prod$2=op({prod_});function rand_(e,t,n){const r=sizeFromShape(e);let a=null;if(null==n||"float32"===n)a=new Float32Array(r);else if("int32"===n)a=new Int32Array(r);else{if("bool"!==n)throw new Error(`Unknown data type ${n}`);a=new Uint8Array(r)}for(let e=0;e<r;e++)a[e]=t();return ENGINE.makeTensor(a,e,n)}const rand=op({rand_});var alea=createCommonjsModule(function(e){!function(e,t,n){function r(e){var t,n=this,r=(t=4022871197,function(e){e=e.toString();for(var n=0;n<e.length;n++){var r=.02519603282416938*(t+=e.charCodeAt(n));r-=t=r>>>0,t=(r*=t)>>>0,t+=4294967296*(r-=t)}return 2.3283064365386963e-10*(t>>>0)});n.next=function(){var e=2091639*n.s0+2.3283064365386963e-10*n.c;return n.s0=n.s1,n.s1=n.s2,n.s2=e-(n.c=0|e)},n.c=1,n.s0=r(" "),n.s1=r(" "),n.s2=r(" "),n.s0-=r(e),n.s0<0&&(n.s0+=1),n.s1-=r(e),n.s1<0&&(n.s1+=1),n.s2-=r(e),n.s2<0&&(n.s2+=1),r=null}function a(e,t){return t.c=e.c,t.s0=e.s0,t.s1=e.s1,t.s2=e.s2,t}function s(e,t){var n=new r(e),s=t&&t.state,o=n.next;return o.int32=function(){return 4294967296*n.next()|0},o.double=function(){return o()+11102230246251565e-32*(2097152*o()|0)},o.quick=o,s&&("object"==typeof s&&a(s,n),o.state=function(){return a(n,{})}),o}t&&t.exports?t.exports=s:this.alea=s}(0,e)}),xor128=createCommonjsModule(function(e){!function(e,t,n){function r(e){var t=this,n="";t.x=0,t.y=0,t.z=0,t.w=0,t.next=function(){var e=t.x^t.x<<11;return t.x=t.y,t.y=t.z,t.z=t.w,t.w^=t.w>>>19^e^e>>>8},e===(0|e)?t.x=e:n+=e;for(var r=0;r<n.length+64;r++)t.x^=0|n.charCodeAt(r),t.next()}function a(e,t){return t.x=e.x,t.y=e.y,t.z=e.z,t.w=e.w,t}function s(e,t){var n=new r(e),s=t&&t.state,o=function(){return(n.next()>>>0)/4294967296};return o.double=function(){do{var e=((n.next()>>>11)+(n.next()>>>0)/4294967296)/(1<<21)}while(0===e);return e},o.int32=n.next,o.quick=o,s&&("object"==typeof s&&a(s,n),o.state=function(){return a(n,{})}),o}t&&t.exports?t.exports=s:this.xor128=s}(0,e)}),xorwow=createCommonjsModule(function(e){!function(e,t,n){function r(e){var t=this,n="";t.next=function(){var e=t.x^t.x>>>2;return t.x=t.y,t.y=t.z,t.z=t.w,t.w=t.v,(t.d=t.d+362437|0)+(t.v=t.v^t.v<<4^e^e<<1)|0},t.x=0,t.y=0,t.z=0,t.w=0,t.v=0,e===(0|e)?t.x=e:n+=e;for(var r=0;r<n.length+64;r++)t.x^=0|n.charCodeAt(r),r==n.length&&(t.d=t.x<<10^t.x>>>4),t.next()}function a(e,t){return t.x=e.x,t.y=e.y,t.z=e.z,t.w=e.w,t.v=e.v,t.d=e.d,t}function s(e,t){var n=new r(e),s=t&&t.state,o=function(){return(n.next()>>>0)/4294967296};return o.double=function(){do{var e=((n.next()>>>11)+(n.next()>>>0)/4294967296)/(1<<21)}while(0===e);return e},o.int32=n.next,o.quick=o,s&&("object"==typeof s&&a(s,n),o.state=function(){return a(n,{})}),o}t&&t.exports?t.exports=s:this.xorwow=s}(0,e)}),xorshift7=createCommonjsModule(function(e){!function(e,t,n){function r(e){var t=this;t.next=function(){var e,n,r=t.x,a=t.i;return e=r[a],n=(e^=e>>>7)^e<<24,n^=(e=r[a+1&7])^e>>>10,n^=(e=r[a+3&7])^e>>>3,n^=(e=r[a+4&7])^e<<7,e=r[a+7&7],r[a]=n^=(e^=e<<13)^e<<9,t.i=a+1&7,n},function(e,t){var n,r=[];if(t===(0|t))r[0]=t;else for(t=""+t,n=0;n<t.length;++n)r[7&n]=r[7&n]<<15^t.charCodeAt(n)+r[n+1&7]<<13;for(;r.length<8;)r.push(0);for(n=0;n<8&&0===r[n];++n);for(8==n&&(r[7]=-1),e.x=r,e.i=0,n=256;n>0;--n)e.next()}(t,e)}function a(e,t){return t.x=e.x.slice(),t.i=e.i,t}function s(e,t){null==e&&(e=+new Date);var n=new r(e),s=t&&t.state,o=function(){return(n.next()>>>0)/4294967296};return o.double=function(){do{var e=((n.next()>>>11)+(n.next()>>>0)/4294967296)/(1<<21)}while(0===e);return e},o.int32=n.next,o.quick=o,s&&(s.x&&a(s,n),o.state=function(){return a(n,{})}),o}t&&t.exports?t.exports=s:this.xorshift7=s}(0,e)}),xor4096=createCommonjsModule(function(e){!function(e,t,n){function r(e){var t=this;t.next=function(){var e,n,r=t.w,a=t.X,s=t.i;return t.w=r=r+1640531527|0,n=a[s+34&127],e=a[s=s+1&127],n^=n<<13,e^=e<<17,n=a[s]=(n^=n>>>15)^(e^=e>>>12),t.i=s,n+(r^r>>>16)|0},function(e,t){var n,r,a,s,o,i=[],l=128;for(t===(0|t)?(r=t,t=null):(t+="\0",r=0,l=Math.max(l,t.length)),a=0,s=-32;s<l;++s)t&&(r^=t.charCodeAt((s+32)%t.length)),0===s&&(o=r),r^=r<<10,r^=r>>>15,r^=r<<4,r^=r>>>13,s>=0&&(a=0==(n=i[127&s]^=r+(o=o+1640531527|0))?a+1:0);for(a>=128&&(i[127&(t&&t.length||0)]=-1),a=127,s=512;s>0;--s)r=i[a+34&127],n=i[a=a+1&127],r^=r<<13,n^=n<<17,i[a]=(r^=r>>>15)^(n^=n>>>12);e.w=o,e.X=i,e.i=a}(t,e)}function a(e,t){return t.i=e.i,t.w=e.w,t.X=e.X.slice(),t}function s(e,t){null==e&&(e=+new Date);var n=new r(e),s=t&&t.state,o=function(){return(n.next()>>>0)/4294967296};return o.double=function(){do{var e=((n.next()>>>11)+(n.next()>>>0)/4294967296)/(1<<21)}while(0===e);return e},o.int32=n.next,o.quick=o,s&&(s.X&&a(s,n),o.state=function(){return a(n,{})}),o}t&&t.exports?t.exports=s:this.xor4096=s}(0,e)}),tychei=createCommonjsModule(function(e){!function(e,t,n){function r(e){var t=this,n="";t.next=function(){var e=t.b,n=t.c,r=t.d,a=t.a;return e=e<<25^e>>>7^n,n=n-r|0,r=r<<24^r>>>8^a,a=a-e|0,t.b=e=e<<20^e>>>12^n,t.c=n=n-r|0,t.d=r<<16^n>>>16^a,t.a=a-e|0},t.a=0,t.b=0,t.c=-1640531527,t.d=1367130551,e===Math.floor(e)?(t.a=e/4294967296|0,t.b=0|e):n+=e;for(var r=0;r<n.length+20;r++)t.b^=0|n.charCodeAt(r),t.next()}function a(e,t){return t.a=e.a,t.b=e.b,t.c=e.c,t.d=e.d,t}function s(e,t){var n=new r(e),s=t&&t.state,o=function(){return(n.next()>>>0)/4294967296};return o.double=function(){do{var e=((n.next()>>>11)+(n.next()>>>0)/4294967296)/(1<<21)}while(0===e);return e},o.int32=n.next,o.quick=o,s&&("object"==typeof s&&a(s,n),o.state=function(){return a(n,{})}),o}t&&t.exports?t.exports=s:this.tychei=s}(0,e)}),seedrandom$1=createCommonjsModule(function(e){!function(t,n){var r,a=this,s=256,o=n.pow(s,6),i=n.pow(2,52),l=2*i,u=255;function c(e,u,c){var g=[],$=m(h((u=1==u?{entropy:!0}:u||{}).entropy?[e,f(t)]:null==e?function(){try{var e;return r&&(e=r.randomBytes)?e=e(s):(e=new Uint8Array(s),(a.crypto||a.msCrypto).getRandomValues(e)),f(e)}catch(e){var n=a.navigator,o=n&&n.plugins;return[+new Date,a,o,a.screen,f(t)]}}():e,3),g),y=new p(g),b=function(){for(var e=y.g(6),t=o,n=0;e<i;)e=(e+n)*s,t*=s,n=y.g(1);for(;e>=l;)e/=2,t/=2,n>>>=1;return(e+n)/t};return b.int32=function(){return 0|y.g(4)},b.quick=function(){return y.g(4)/4294967296},b.double=b,m(f(y.S),t),(u.pass||c||function(e,t,r,a){return a&&(a.S&&d(a,y),e.state=function(){return d(y,{})}),r?(n.random=e,t):e})(b,$,"global"in u?u.global:this==n,u.state)}function p(e){var t,n=e.length,r=this,a=0,o=r.i=r.j=0,i=r.S=[];for(n||(e=[n++]);a<s;)i[a]=a++;for(a=0;a<s;a++)i[a]=i[o=u&o+e[a%n]+(t=i[a])],i[o]=t;(r.g=function(e){for(var t,n=0,a=r.i,o=r.j,i=r.S;e--;)t=i[a=u&a+1],n=n*s+i[u&(i[a]=i[o=u&o+t])+(i[o]=t)];return r.i=a,r.j=o,n})(s)}function d(e,t){return t.i=e.i,t.j=e.j,t.S=e.S.slice(),t}function h(e,t){var n,r=[],a=typeof e;if(t&&"object"==a)for(n in e)try{r.push(h(e[n],t-1))}catch(e){}return r.length?r:"string"==a?e:e+"\0"}function m(e,t){for(var n,r=e+"",a=0;a<r.length;)t[u&a]=u&(n^=19*t[u&a])+r.charCodeAt(a++);return f(t)}function f(e){return String.fromCharCode.apply(0,e)}if(n.seedrandom=c,m(n.random(),t),e.exports){e.exports=c;try{r=_nodeResolve_empty$1}catch(e){}}}([],Math)});seedrandom$1.alea=alea,seedrandom$1.xor128=xor128,seedrandom$1.xorwow=xorwow,seedrandom$1.xorshift7=xorshift7,seedrandom$1.xor4096=xor4096,seedrandom$1.tychei=tychei;var seedrandom=seedrandom$1;class MPRandGauss{constructor(e,t,n,r,a){this.mean=e,this.stdDev=t,this.dtype=n,this.nextVal=NaN,this.truncated=r,this.truncated&&(this.upper=this.mean+2*this.stdDev,this.lower=this.mean-2*this.stdDev);const s=a||Math.random();this.random=seedrandom.alea(s.toString())}nextValue(){if(!isNaN(this.nextVal)){const e=this.nextVal;return this.nextVal=NaN,e}let e,t,n=!1;for(;!n;){let r,a,s;do{r=2*this.random()-1,a=2*this.random()-1,s=r*r+a*a}while(s>=1||0===s);const o=Math.sqrt(-2*Math.log(s)/s);e=this.mean+this.stdDev*r*o,t=this.mean+this.stdDev*a*o,this.truncated&&!this.isValidTruncated(e)||(n=!0)}return this.truncated&&!this.isValidTruncated(t)||(this.nextVal=this.convertValue(t)),this.convertValue(e)}convertValue(e){return null==this.dtype||"float32"===this.dtype?e:Math.round(e)}isValidTruncated(e){return e<=this.upper&&e>=this.lower}}class RandGamma{constructor(e,t,n,r){this.alpha=e,this.beta=1/t,this.dtype=n;const a=r||Math.random();this.randu=seedrandom.alea(a.toString()),this.randn=new MPRandGauss(0,1,n,!1,this.randu()),this.d=e<1?e+2/3:e-1/3,this.c=1/Math.sqrt(9*this.d)}nextValue(){let e,t,n,r,a,s;for(;;){do{r=this.randn.nextValue(),s=1+this.c*r}while(s<=0);if(s*=s*s,e=r*r,t=1-.331*e*e,n=.5*e+this.d*(1-s+Math.log(s)),a=this.randu(),a<t||Math.log(a)<n)break}return s*=1/this.beta*this.d,this.alpha<1&&(s*=Math.pow(this.randu(),1/this.alpha)),this.convertValue(s)}convertValue(e){return"float32"===this.dtype?e:Math.round(e)}}class UniformRandom{constructor(e=0,t=1,n,r){if(this.canReturnFloat=()=>null==this.dtype||"float32"===this.dtype,this.min=e,this.range=t-e,this.dtype=n,null==r&&(r=Math.random()),"number"==typeof r&&(r=r.toString()),!this.canReturnFloat()&&this.range<=1)throw new Error(`The difference between ${e} - ${t} <= 1 and dtype is not float`);this.random=seedrandom.alea(r)}convertValue(e){return this.canReturnFloat()?e:Math.round(e)}nextValue(){return this.convertValue(this.min+this.range*this.random())}}function randomGamma_(e,t,n=1,r="float32",a){if(null==n&&(n=1),null==r&&(r="float32"),"float32"!==r&&"int32"!==r)throw new Error(`Unsupported data type ${r}`);const s=new RandGamma(t,n,r,a),o=buffer(e,r);for(let e=0;e<o.values.length;e++)o.values[e]=s.nextValue();return o.toTensor()}const randomGamma=op({randomGamma_});function randomNormal_(e,t=0,n=1,r,a){if(null!=r&&"bool"===r)throw new Error(`Unsupported data type ${r}`);const s=new MPRandGauss(t,n,r,!1,a),o=buffer(e,r);for(let e=0;e<o.values.length;e++)o.values[e]=s.nextValue();return o.toTensor()}const randomNormal$2=op({randomNormal_});function randomUniform_(e,t=0,n=1,r="float32",a){const s=buffer(e,r),o=new UniformRandom(t,n,null,a);for(let e=0;e<s.values.length;e++)s.values[e]=o.nextValue();return s.toTensor()}const randomUniform$1=op({randomUniform_});function range$4(e,t,n=1,r="float32"){if(0===n)throw new Error("Cannot have a step of zero");return ENGINE.runKernel(Range,{},{start:e,stop:t,step:n,dtype:r})}function real_(e){const t=convertToTensor(e,"input","real");return ENGINE.runKernel(Real,{input:t})}const real$2=op({real_});function reciprocal_(e){const t=convertToTensor(e,"x","reciprocal");return ENGINE.runKernel(Reciprocal,{x:t})}const reciprocal$2=op({reciprocal_});function relu_(e){const t=convertToTensor(e,"x","relu");return ENGINE.runKernel(Relu$1,{x:t})}const relu$3=op({relu_});function relu6_(e){const t=convertToTensor(e,"x","relu6");return ENGINE.runKernel(Relu6$1,{x:t})}const relu6$2=op({relu6_});function reverse_(e,t){const n=convertToTensor(e,"x","reverse");return ENGINE.runKernel(Reverse,{x:n},{dims:t})}const reverse$2=op({reverse_});function reverse1d_(e){const t=convertToTensor(e,"x","reverse");return assert$4(1===t.rank,()=>`Error in reverse1D: x must be rank 1 but got rank ${t.rank}.`),reverse$2(t,0)}const reverse1d=op({reverse1d_});function reverse2d_(e,t){const n=convertToTensor(e,"x","reverse");return assert$4(2===n.rank,()=>`Error in reverse2D: x must be rank 2 but got rank ${n.rank}.`),reverse$2(n,t)}const reverse2d=op({reverse2d_});function reverse3d_(e,t){const n=convertToTensor(e,"x","reverse");return assert$4(3===n.rank,()=>`Error in reverse3D: x must be rank 3 but got rank ${n.rank}.`),reverse$2(n,t)}const reverse3d=op({reverse3d_});function reverse4d_(e,t){const n=convertToTensor(e,"x","reverse");return assert$4(4===n.rank,()=>`Error in reverse4D: x must be rank 4 but got rank ${n.rank}.`),reverse$2(n,t)}const reverse4d=op({reverse4d_});function round_(e){const t=convertToTensor(e,"x","round");return ENGINE.runKernel(Round,{x:t})}const round$2=op({round_});function rsqrt_(e){const t=convertToTensor(e,"x","rsqrt");return ENGINE.runKernel(Rsqrt,{x:t})}const rsqrt$2=op({rsqrt_});function scalar(e,t){if((isTypedArray(e)&&"string"!==t||Array.isArray(e))&&"complex64"!==t)throw new Error("Error creating a new Scalar: value must be a primitive (number|boolean|string)");if("string"===t&&isTypedArray(e)&&!(e instanceof Uint8Array))throw new Error("When making a scalar from encoded string, the value must be `Uint8Array`.");return makeTensor(e,[],[],t)}function selu_(e){const t=convertToTensor(e,"x","selu");return ENGINE.runKernel(Selu$1,{x:t})}const selu$2=op({selu_});function separableConv2d_(e,t,n,r,a,s=[1,1],o="NHWC"){const i=convertToTensor(e,"x","separableConv2d"),l=convertToTensor(t,"depthwiseFilter","separableConv2d"),u=convertToTensor(n,"pointwiseFilter","separableConv2d");let c=i,p=!1;if(3===i.rank&&(p=!0,c=reshape$3(i,[1,i.shape[0],i.shape[1],i.shape[2]])),"NCHW"===o)throw new Error("separableConv2d currently does not support dataFormat NCHW; only NHWC is supported");assert$4(4===c.rank,()=>`Error in separableConv2d: input must be rank 4, but got rank ${c.rank}.`),assert$4(4===l.rank,()=>`Error in separableConv2d: depthwise filter must be rank 4, but got rank ${l.rank}.`),assert$4(4===u.rank,()=>`Error in separableConv2d: pointwise filter must be rank 4, but got rank ${l.rank}.`),assert$4(1===u.shape[0],()=>`Error in separableConv2d: the first dimension of pointwise filter  must be 1, but got ${u.shape[0]}.`),assert$4(1===u.shape[1],()=>`Error in separableConv2d: the second dimension of pointwise filter must be 1, but got ${u.shape[1]}.`);const d=l.shape[2],h=l.shape[3];assert$4(u.shape[2]===d*h,()=>`Error in separableConv2d: the third dimension of pointwise filter must be ${d*h}, but got ${u.shape[2]}.`);const m=depthwiseConv2d$3(c,l,r,a,o,s),f=conv2d$3(m,u,1,"valid",o);return p?reshape$3(f,[f.shape[1],f.shape[2],f.shape[3]]):f}const separableConv2d$1=op({separableConv2d_});async function setdiff1dAsync_(e,t){const n=convertToTensor(e,"x","setdiff1d"),r=convertToTensor(t,"y","setdiff1d");assert$4(n.dtype===r.dtype,()=>`x and y should have the same dtype, but got x (${n.dtype}) and y (${r.dtype}).`),assert$4(1===n.rank,()=>`x should be 1D tensor, but got x (${n.shape}).`),assert$4(1===r.rank,()=>`y should be 1D tensor, but got y (${r.shape}).`);const a=await n.data(),s=await r.data(),o=new Set(s);let i=0;for(let e=0;e<a.length;e++)o.has(a[e])||i++;const l=new TensorBuffer([i],n.dtype),u=new TensorBuffer([i],"int32");for(let e=0,t=0;e<a.length;e++)o.has(a[e])||(l.values[t]=a[e],u.values[t]=e,t++);return[l.toTensor(),u.toTensor()]}const setdiff1dAsync=setdiff1dAsync_;function sign_(e){const t=convertToTensor(e,"x","sign");return ENGINE.runKernel(Sign,{x:t})}const sign$2=op({sign_});function sin_(e){const t=convertToTensor(e,"x","sin");return ENGINE.runKernel(Sin,{x:t})}const sin$2=op({sin_});function sinh_(e){const t=convertToTensor(e,"x","sinh");return ENGINE.runKernel(Sinh,{x:t})}const sinh$2=op({sinh_});function slice1d_(e,t,n){const r=convertToTensor(e,"x","slice1d");return assert$4(1===r.rank,()=>`slice1d expects a rank-1 tensor, but got a rank-${r.rank} tensor`),slice$2(r,[t],[n])}const slice1d=op({slice1d_});function slice2d_(e,t,n){const r=convertToTensor(e,"x","slice2d");return assert$4(2===r.rank,()=>`slice2d expects a rank-2 tensor, but got a rank-${r.rank} tensor`),slice$2(r,t,n)}const slice2d=op({slice2d_});function slice3d_(e,t,n){const r=convertToTensor(e,"x","slice3d");return assert$4(3===r.rank,()=>`slice3d expects a rank-3 tensor, but got a rank-${r.rank} tensor`),slice$2(r,t,n)}const slice3d=op({slice3d_});function slice4d_(e,t,n){const r=convertToTensor(e,"x","slice4d");return assert$4(4===r.rank,()=>`slice4d expects a rank-4 tensor, but got a rank-${r.rank} tensor`),slice$2(r,t,n)}const slice4d=op({slice4d_});function softmax_(e,t=-1){const n=convertToTensor(e,"logits","softmax","float32");if(-1===t&&(t=n.rank-1),t!==n.rank-1)throw Error(`Softmax along a non-last dimension is not yet supported. Logits was rank ${n.rank} and dim was ${t}`);return ENGINE.runKernel(Softmax$2,{logits:n},{dim:t})}const softmax$3=op({softmax_});function fft_(e){return assert$4("complex64"===e.dtype,()=>`The dtype for tf.spectral.fft() must be complex64 but got ${e.dtype}.`),ENGINE.runKernel(FFT,{input:e})}const fft$2=op({fft_});function ifft_(e){return assert$4("complex64"===e.dtype,()=>`The dtype for tf.spectral.ifft() must be complex64 but got ${e.dtype}.`),ENGINE.runKernel(IFFT,{input:e})}const ifft$2=op({ifft_});function irfft_(e){const t=e.shape[e.shape.length-1],n=e.size/t;let r;if(t<=2){const a=reshape$3(e,[n,t]);r=ifft$2(a)}else{const a=[n,2*(t-1)],s=reshape$3(real$2(e),[n,t]),o=reshape$3(imag$2(e),[n,t]),i=reverse$2(slice$2(s,[0,1],[n,t-2]),1),l=mul(reverse$2(slice$2(o,[0,1],[n,t-2]),1),scalar(-1)),u=concat$2([s,i],1),c=concat$2([o,l],1),p=reshape$3(complex$2(u,c),[a[0],a[1]]);r=ifft$2(p)}if(r=real$2(r),3===e.rank&&0!==e.shape[0]){const t=r,n=e.shape[0];r=reshape$3(r,[n,r.shape[0]/n,r.shape[1]]),t.dispose()}return r}const irfft=op({irfft_});function split_(e,t,n=0){const r=convertToTensor(e,"x","split");return ENGINE.runKernel(SplitV,{x:r},{numOrSizeSplits:t,axis:n})}const split$2=op({split_});function rfft_(e,t){assert$4("float32"===e.dtype,()=>`The dtype for rfft() must be real value but got ${e.dtype}`);let n=e.shape[e.shape.length-1];const r=e.size/n;let a;if(null!=t&&t<n){const r=e.shape.map(e=>0),s=e.shape.map(e=>e);s[e.shape.length-1]=t,a=slice$2(e,r,s),n=t}else if(null!=t&&t>n){const r=e.shape.map(e=>e);r[e.shape.length-1]=t-n,a=concat$2([e,zeros$2(r)],e.shape.length-1),n=t}else a=e;const s=zerosLike$2(a),o=reshape$3(complex$2(a,s),[r,n]),i=fft$2(o),l=Math.floor(n/2)+1,u=real$2(i),c=imag$2(i),p=split$2(u,[l,n-l],u.shape.length-1),d=split$2(c,[l,n-l],c.shape.length-1),h=a.shape.slice();return h[a.shape.length-1]=l,reshape$3(complex$2(p[0],d[0]),h)}const rfft=op({rfft_});function sqrt_(e){const t=convertToTensor(e,"x","sqrt");return ENGINE.runKernel(Sqrt,{x:t})}const sqrt$2=op({sqrt_});function squaredDifference_(e,t){let n=convertToTensor(e,"a","squaredDifference"),r=convertToTensor(t,"b","squaredDifference");return[n,r]=makeTypesMatch(n,r),assertAndGetBroadcastShape(n.shape,r.shape),ENGINE.runKernel(SquaredDifference,{a:n,b:r},{})}const squaredDifference$2=op({squaredDifference_});function squeeze_(e,t){const n=convertToTensor(e,"x","squeeze");return reshape$3(n,squeezeShape(n.shape,t).newShape)}const squeeze=op({squeeze_});function stack_(e,t=0){const n=convertToTensorArray(e,"tensors","stack","string_or_numeric");return assert$4(n.length>=1,()=>"Pass at least one tensor to tf.stack"),n.length>0&&assert$4(t<=n[0].rank,()=>"Axis must be <= rank of the tensor"),ENGINE.runKernel(Pack,n,{axis:t})}const stack=op({stack_});function step_(e,t=0){const n=convertToTensor(e,"x","step");return ENGINE.runKernel(Step,{x:n},{alpha:t})}const step$2=op({step_});function stridedSlice_(e,t,n,r,a=0,s=0,o=0,i=0,l=0){const u=convertToTensor(e,"x","stridedSlice","string_or_numeric");return ENGINE.runKernel(StridedSlice,{x:u},{begin:t,end:n,strides:r,beginMask:a,endMask:s,ellipsisMask:o,newAxisMask:i,shrinkAxisMask:l})}const stridedSlice$2=op({stridedSlice_});function tan_(e){const t=convertToTensor(e,"x","tan");return ENGINE.runKernel(Tan,{x:t})}const tan$2=op({tan_});function tensor1d(e,t){assertNonNull(e);const n=inferShape(e,t);if(1!==n.length)throw new Error("tensor1d() requires values to be a flat/TypedArray");return makeTensor(e,null,n,t)}function tensor2d(e,t,n){if(assertNonNull(e),null!=t&&2!==t.length)throw new Error("tensor2d() requires shape to have two numbers");const r=inferShape(e,n);if(2!==r.length&&1!==r.length)throw new Error("tensor2d() requires values to be number[][] or flat/TypedArray");if(1===r.length&&null==t)throw new Error("tensor2d() requires shape to be provided when `values` are a flat/TypedArray");return makeTensor(e,t,r,n)}function tensor4d(e,t,n){if(assertNonNull(e),null!=t&&4!==t.length)throw new Error("tensor4d() requires shape to have four numbers");const r=inferShape(e,n);if(4!==r.length&&1!==r.length)throw new Error("tensor4d() requires values to be number[][][][] or flat/TypedArray");if(1===r.length&&null==t)throw new Error("tensor4d() requires shape to be provided when `values` are a flat array");return makeTensor(e,t,r,n)}function tensor5d(e,t,n){if(assertNonNull(e),null!=t&&5!==t.length)throw new Error("tensor5d() requires shape to have five numbers");const r=inferShape(e,n);if(5!==r.length&&1!==r.length)throw new Error("tensor5d() requires values to be number[][][][][] or flat/TypedArray");if(1===r.length&&null==t)throw new Error("tensor5d() requires shape to be provided when `values` are a flat array");return makeTensor(e,t,r,n)}function tensor6d(e,t,n){if(assertNonNull(e),null!=t&&6!==t.length)throw new Error("tensor6d() requires shape to have six numbers");const r=inferShape(e,n);if(6!==r.length&&1!==r.length)throw new Error("tensor6d() requires values to be number[][][][][][] or flat/TypedArray");if(1===r.length&&null==t)throw new Error("tensor6d() requires shape to be provided when `values` are a flat array");return makeTensor(e,t=t||r,r,n)}function topk_(e,t=1,n=!0){const r=convertToTensor(e,"x","topk");if(0===r.rank)throw new Error("topk() expects the input to be of rank 1 or higher");const a=r.shape[r.shape.length-1];if(t<0)throw new Error(`'k' passed to topk() must be >= 0 but got ${t}`);if(t>a)throw new Error(`'k' passed to topk() must be <= the last dimension (${a}) but got ${t}`);const s={x:r},o={k:t,sorted:n},[i,l]=ENGINE.runKernel(TopK,s,o);return{values:i,indices:l}}const topk=op({topk_});function truncatedNormal_(e,t=0,n=1,r,a){if(null!=r&&"bool"===r)throw new Error("Unsupported data type $ { dtype }");const s=new MPRandGauss(t,n,r,!0,a),o=buffer(e,r);for(let e=0;e<o.values.length;e++)o.values[e]=s.nextValue();return o.toTensor()}const truncatedNormal$1=op({truncatedNormal_});function unique_(e,t=0){const n=convertToTensor(e,"x","unique","string_or_numeric");assert$4(n.rank>0,()=>"The input tensor must be at least 1D");const r={x:n},a={axis:t},[s,o]=ENGINE.runKernel(Unique,r,a);return{values:s,indices:o}}const unique$3=op({unique_});function unsortedSegmentSum_(e,t,n){const r=convertToTensor(e,"x","unsortedSegmentSum"),a=convertToTensor(t,"segmentIds","unsortedSegmentSum","int32");return assert$4(isInt(n),()=>"numSegments must be of dtype int"),ENGINE.runKernel(UnsortedSegmentSum,{x:r,segmentIds:a},{numSegments:n})}const unsortedSegmentSum$2=op({unsortedSegmentSum_});function unstack_(e,t=0){const n=convertToTensor(e,"x","unstack","string_or_numeric");return assert$4(t>=-n.shape.length&&t<n.shape.length,()=>`Axis = ${t} is not in [-${n.shape.length}, ${n.shape.length})`),ENGINE.runKernel(Unpack,{value:n},{axis:t})}const unstack=op({unstack_});function variable(e,t=!0,n,r){return ENGINE.makeVariable(e,t,n,r)}function whereImpl$2(e,t){const n=[];for(let e=0;e<t.length;e++)t[e]&&n.push(e);const r=buffer(e,"int32"),a=buffer([n.length,e.length],"int32");for(let t=0;t<n.length;t++){const s=r.indexToLoc(n[t]);a.values.set(s,t*e.length)}return a.toTensor()}async function whereAsync_(e){const t=convertToTensor(e,"condition","whereAsync","bool"),n=await t.data(),r=whereImpl$2(t.shape,n);return e!==t&&t.dispose(),r}const whereAsync=whereAsync_;async function booleanMaskAsync_(e,t,n){const r=convertToTensor(e,"tensor","boolMask"),a=convertToTensor(t,"mask","boolMask","bool"),s=null==n?0:n,o=a.rank,i=r.shape;assert$4(o>0,()=>"mask cannot be scalar"),assertShapesMatch(i.slice(s,s+o),a.shape,"mask's shape must match the first K dimensions of tensor's shape,");let l=1;for(let e=s;e<s+o;e++)l*=i[e];const u=i.slice(0,s).concat([l],i.slice(s+o)),c=reshape$3(r,u),p=reshape$3(a,[-1]),d=await whereAsync(p),h=squeeze(d,[1]),m=gather$1(c,h,s);return e!==r&&r.dispose(),t!==a&&a.dispose(),h.dispose(),c.dispose(),p.dispose(),d.dispose(),m}const booleanMaskAsync=booleanMaskAsync_;function norm_(e,t="euclidean",n=null,r=!1){const a=normImpl(e=convertToTensor(e,"x","norm"),t,n);let s=a.shape;if(r){const t=parseAxisParam(n,e.shape);s=expandShapeToKeepDim(a.shape,t)}return reshape$3(a,s)}function normImpl(e,t,n=null){if(0===e.rank)return abs$2(e);if(1!==e.rank&&null===n)return normImpl(reshape$3(e,[-1]),t,n);if(1===e.rank||"number"==typeof n||Array.isArray(n)&&1===n.length){if(1===t)return sum$2(abs$2(e),n);if(Infinity===t)return max$3(abs$2(e),n);if(-Infinity===t)return min$3(abs$2(e),n);if("euclidean"===t||2===t)return sqrt$2(sum$2(pow$2(abs$2(e),scalar(2,"int32")),n));throw new Error(`Error in norm: invalid ord value: ${t}`)}if(Array.isArray(n)&&2===n.length){if(1===t)return max$3(sum$2(abs$2(e),n[0]),n[1]-1);if(Infinity===t)return max$3(sum$2(abs$2(e),n[1]),n[0]);if(-Infinity===t)return min$3(sum$2(abs$2(e),n[1]),n[0]);if("fro"===t||"euclidean"===t)return sqrt$2(sum$2(square$2(e),n));throw new Error(`Error in norm: invalid ord value: ${t}`)}throw new Error(`Error in norm: invalid axis: ${n}`)}const norm=op({norm_});function movingAverage_(e,t,n,r,a=!0){const s=convertToTensor(e,"v","movingAverage"),o=convertToTensor(t,"x","movingAverage"),i=convertToTensor(n,"decay","movingAverage");assertTypesMatch(s,o),assert$4(arraysEqual(s.shape,o.shape),()=>"Shape mismatch in v and x");const l=scalar(1),u=sub$2(l,i);let c=mul(sub$2(o,s),u);if(a){assert$4(null!=r,()=>"When using zeroDebias: true, step is required.");const e=convertToTensor(r,"step","movingAverage");c=div$1(c,sub$2(l,pow$2(i,e)))}return add$2(s,c)}const movingAverage=op({movingAverage_});function scatterND_(e,t,n){const r=convertToTensor(e,"indices","scatterND","int32"),a=convertToTensor(t,"updates","scatterND");return validateInput$1(a,r,n),ENGINE.runKernel(ScatterNd,{indices:r,updates:a},{shape:n})}const scatterND=op({scatterND_});function validateInput(e,t,n,r){if("int32"!==e.dtype)throw new Error(`tf.sparseToDense() expects the indices to be int32 type, but the dtype was ${e.dtype}.`);if(e.rank>2)throw new Error(`sparseIndices should be a scalar, vector, or matrix, but got shape ${e.shape}.`);const a=e.rank>0?e.shape[0]:1,s=e.rank>1?e.shape[1]:1;if(n.length!==s)throw new Error(`outputShape has incorrect number of elements:, ${n.length}, should be: ${s}.`);if(0!==t.rank&&(1!==t.rank||t.size!==a))throw new Error(`sparseValues has incorrect shape ${t.shape}, should be [] or [${a}]`);if(t.dtype!==r.dtype)throw new Error("sparseValues.dtype must match defaultValues.dtype")}function sparseToDense_(e,t,n,r=0){const a=convertToTensor(e,"sparseIndices","sparseToDense","int32"),s=convertToTensor(t,"sparseValues","sparseToDense"),o=convertToTensor(r,"defaultValue","sparseToDense",s.dtype);return validateInput(a,s,n,o),ENGINE.runKernel(SparseToDense,{sparseIndices:a,sparseValues:s,defaultValue:o},{outputShape:n})}const sparseToDense$2=op({sparseToDense_});function gatherND_(e,t){const n=convertToTensor(t,"indices","gatherND","int32"),r=convertToTensor(e,"x","gatherND","string_or_numeric");return ENGINE.runKernel(GatherNd,{params:r,indices:n})}const gatherND=op({gatherND_});function getNoiseShape(e,t){if(null==t)return e.shape.slice();if(arraysEqual(e.shape,t))return t;if(e.shape.length===t.length){const n=[];for(let r=0;r<e.shape.length;r++)n.push(null==t[r]&&null!=e.shape[r]?e.shape[r]:t[r]);return n}return t}function dropout_(e,t,n,r){const a=convertToTensor(e,"x","dropout");if(assert$4("float32"===a.dtype,()=>`x has to be a floating point tensor since it's going to be scaled, but got a ${a.dtype} tensor instead.`),assert$4(t>=0&&t<1,()=>`rate must be a float in the range [0, 1), but got ${t}.`),0===t)return e instanceof Tensor?a.clone():a;const s=getNoiseShape(a,n),o=1-t,i=div$1(floor$2(add$2(randomUniform$1(s,0,1,"float32",r),o)),o);return mul(a,i)}const dropout$2=op({dropout_});function enclosingPowerOfTwo(e){return Math.floor(Math.pow(2,Math.ceil(Math.log(e)/Math.log(2))))}function cosineWindow(e,t,n){const r=1-e%2,a=new Float32Array(e);for(let s=0;s<e;++s){const o=2*Math.PI*s/(e+r-1);a[s]=t-n*Math.cos(o)}return tensor1d(a,"float32")}async function inTopKAsync_(e,t,n=1){const r=convertToTensor(e,"predictions","inTopK"),a=convertToTensor(t,"targets","inTopK");assert$4(r.rank>1,()=>`inTopK() expects the predictions to be of rank 2 or higher, but got ${r.rank}`),assert$4(r.rank-1===a.rank,()=>`predictions rank should be 1 larger than targets rank, but got predictions rank ${r.rank} and targets rank ${a.rank}`),assertShapesMatch(r.shape.slice(0,r.shape.length-1),a.shape,"predictions's shape should be align with the targets' shape, except the last dimension.");const s=r.shape[r.shape.length-1];assert$4(n>0&&n<=s,()=>`'k' passed to inTopK() must be > 0 && <= the predictions last dimension (${s}), but got ${n}`);const o=await r.data(),i=await a.data(),[l,u]=[o.length/s,s],c=getTypedArrayFromDType("bool",l);for(let e=0;e<l;e++){const t=e*u,r=o.subarray(t,t+u),a=[];for(let e=0;e<r.length;e++)a.push({value:r[e],index:e});a.sort((e,t)=>t.value-e.value),c[e]=0;for(let t=0;t<n;t++)if(a[t].index===i[e]){c[e]=1;break}}return e!==r&&r.dispose(),t!==a&&a.dispose(),tensor(c,a.shape,"bool")}const inTopKAsync=inTopKAsync_;function conv2DBackpropFilter_(e,t,n,r,a,s="NHWC",o){let i=e;3===e.rank&&(i=reshape$3(e,[1,e.shape[0],e.shape[1],e.shape[2]]));let l=t;3===l.rank&&(l=reshape$3(t,[1,t.shape[0],t.shape[1],t.shape[2]])),assert$4(4===i.rank,()=>`Error in conv2dDerFilter: input must be rank 4, but got shape ${i.shape}.`),assert$4(4===l.rank,()=>`Error in conv2dDerFilter: dy must be rank 4, but got shape ${l.shape}.`),assert$4(4===n.length,()=>`Error in conv2dDerFilter: filterShape must be length 4, but got ${n}.`);const u="NHWC"===s?i.shape[3]:i.shape[1],c="NHWC"===s?l.shape[3]:l.shape[1];return assert$4(u===n[2],()=>`Error in conv2dDerFilter: depth of input ${u}) must match input depth in filter (${n[2]}.`),assert$4(c===n[3],()=>`Error in conv2dDerFilter: depth of dy (${c}) must match output depth for filter (${n[3]}).`),null!=o&&assert$4(isInt(a),()=>`Error in conv2dDerFilter: pad must be an integer when using, dimRoundingMode ${o} but got pad ${a}.`),ENGINE.runKernel(Conv2DBackpropFilter,{x:i,dy:l},{strides:r,pad:a,dataFormat:s,dimRoundingMode:o,filterShape:n})}const conv2DBackpropFilter$2=op({conv2DBackpropFilter_});function getFusedDyActivation(e,t,n){if(null==n||"linear"===n)return e;if("relu"===n)return mul(e,step$2(t));throw new Error(`Cannot compute gradient for fused activation ${n}.`)}function getFusedBiasGradient(e,t){let n=t;const r=getReductionAxes(e.shape,t.shape);return r.length>0&&(n=sum$2(n,r)),reshape$3(n,e.shape)}function applyActivation$1(e,t,n,r){if("linear"===t)return e;if("relu"===t)return relu$3(e);if("elu"===t)return elu$4(e);if("relu6"===t)return relu6$2(e);if("prelu"===t)return prelu$3(e,n);if("leakyrelu"===t)return leakyRelu$2(e,r);if("sigmoid"===t)return sigmoid$2(e);throw new Error(`Unknown fused activation ${t}.`)}const shouldFuse=(e,t)=>!(e>0)||"linear"===t;function fusedConv2d_({x:e,filter:t,strides:n,pad:r,dataFormat:a="NHWC",dilations:s=[1,1],dimRoundingMode:o,bias:i,activation:l="linear",preluActivationWeights:u,leakyreluAlpha:c}){if(!1===shouldFuse(ENGINE.state.gradientDepth,l=l||"linear")){let p=conv2d$3(e,t,n,r,a,s,o);return null!=i&&(p=add$2(p,i)),applyActivation$1(p,l,u,c)}const p=convertToTensor(e,"x","conv2d"),d=convertToTensor(t,"filter","conv2d");let h=p,m=!1;3===p.rank&&(m=!0,h=reshape$3(p,[1,p.shape[0],p.shape[1],p.shape[2]])),assert$4(4===h.rank,()=>`Error in fused conv2d: input must be rank 4, but got rank ${h.rank}.`),assert$4(4===d.rank,()=>`Error in fused conv2d: filter must be rank 4, but got rank ${d.rank}.`),null!=o&&assert$4(isInt(r),()=>`Error in fused conv2d: pad must be an integer when using, dimRoundingMode ${o} but got pad ${r}.`),assert$4(h.shape[3]===d.shape[2],()=>`Error in conv2d: depth of input (${h.shape[3]}) must match input depth for filter ${d.shape[2]}.`),assert$4(eitherStridesOrDilationsAreOne(n,s),()=>`Error in conv2D: Either strides or dilations must be 1. Got strides ${n} and dilations '${s}'`),assert$4("NHWC"===a,()=>`Error in conv2d: got dataFormat of ${a} but only NHWC is currently supported.`);const f=computeConv2DInfo(h.shape,d.shape,n,s,r,o);let g,$;null!=i&&(g=convertToTensor(i,"bias","fused conv2d"),[g]=makeTypesMatch(g,p),assertAndGetBroadcastShape(f.outShape,g.shape)),null!=u&&($=convertToTensor(u,"prelu weights","fused conv2d"));const y=(e,t)=>{const[a,o,i,u]=t,c=getFusedDyActivation(e,i,l);assert$4(tupleValuesAreOne(s),()=>`Error in gradient of fused conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${s}'`);const p=[conv2DBackpropInput$2(o.shape,c,a,n,r),conv2DBackpropFilter$2(o,c,a.shape,n,r)];if(null!=u){const e=getFusedBiasGradient(u,c);p.push(e)}return p},b={x:h,filter:d,bias:g,preluActivationWeights:$},x={strides:n,pad:r,dataFormat:a,dilations:s,dimRoundingMode:o,activation:l,leakyreluAlpha:c};return null==i?customGrad((e,t,n)=>{let r=ENGINE.runKernel(FusedConv2D,b,x);return n([t,e,r]),m&&(r=reshape$3(r,[r.shape[1],r.shape[2],r.shape[3]])),{value:r,gradFunc:y}})(h,d):customGrad((e,t,n,r)=>{let a=ENGINE.runKernel(FusedConv2D,b,x);return r([t,e,a,n]),m&&(a=reshape$3(a,[a.shape[1],a.shape[2],a.shape[3]])),{value:a,gradFunc:y}})(h,d,g)}const conv2d$2=op({fusedConv2d_});function depthwiseConv2dNativeBackpropFilter_(e,t,n,r,a,s=[1,1],o){let i=e;3===e.rank&&(i=reshape$3(e,[1,e.shape[0],e.shape[1],e.shape[2]]));let l=t;return 3===l.rank&&(l=reshape$3(t,[1,t.shape[0],t.shape[1],t.shape[2]])),ENGINE.runKernel(DepthwiseConv2dNativeBackpropFilter,{x:i,dy:l},{strides:r,pad:a,dimRoundingMode:o,dilations:s,filterShape:n})}const depthwiseConv2dNativeBackpropFilter$2=op({depthwiseConv2dNativeBackpropFilter_});function depthwiseConv2dNativeBackpropInput_(e,t,n,r,a,s=[1,1],o){let i=t,l=!1;3===t.rank&&(l=!0,i=reshape$3(t,[1,t.shape[0],t.shape[1],t.shape[2]]));const u=ENGINE.runKernel(DepthwiseConv2dNativeBackpropInput,{dy:i,filter:n},{strides:r,pad:a,dimRoundingMode:o,dilations:s,inputShape:e});return l?reshape$3(u,[u.shape[1],u.shape[2],u.shape[3]]):u}const depthwiseConv2dNativeBackpropInput$2=op({depthwiseConv2dNativeBackpropInput_});function fusedDepthwiseConv2d_({x:e,filter:t,strides:n,pad:r,dataFormat:a="NHWC",dilations:s=[1,1],dimRoundingMode:o,bias:i,activation:l="linear",preluActivationWeights:u,leakyreluAlpha:c}){if(!1===shouldFuse(ENGINE.state.gradientDepth,l)){let p=depthwiseConv2d$3(e,t,n,r,a,s,o);return null!=i&&(p=add$2(p,i)),applyActivation$1(p,l,u,c)}const p=convertToTensor(e,"x","depthwiseConv2d"),d=convertToTensor(t,"filter","depthwiseConv2d");let h=p,m=!1;3===p.rank&&(m=!0,h=reshape$3(p,[1,p.shape[0],p.shape[1],p.shape[2]])),assert$4(4===h.rank,()=>`Error in fused depthwiseConv2d: input must be rank 4, but got rank ${h.rank}.`),assert$4(4===d.rank,()=>`Error in fused depthwiseConv2d: filter must be rank 4, but got rank ${d.rank}.`),assert$4(h.shape[3]===d.shape[2],()=>`Error in fused depthwiseConv2d: number of input channels (${h.shape[3]}) must match the inChannels dimension in filter ${d.shape[2]}.`),null==s&&(s=[1,1]),assert$4(eitherStridesOrDilationsAreOne(n,s),()=>`Error in fused depthwiseConv2d: Either strides or dilations must be 1. Got strides ${n} and dilations '${s}'`),null!=o&&assert$4(isInt(r),()=>`Error in fused depthwiseConv2d: pad must be an integer when using dimRoundingMode ${o} but got pad ${r}.`);const f=computeConv2DInfo(h.shape,d.shape,n,s,r,o,!0);let g,$;null!=i&&(g=convertToTensor(i,"bias","fused conv2d"),[g]=makeTypesMatch(g,p),assertAndGetBroadcastShape(f.outShape,g.shape)),null!=u&&($=convertToTensor(u,"prelu weights","fused depthwiseConv2d"));const y=(e,t)=>{assert$4(tupleValuesAreOne(s),()=>`Error in gradient of fused depthwiseConv2d: dilation rates greater than 1 are not yet supported. Got dilations '${s}'`);const[a,i,u,c]=t,p=getFusedDyActivation(e,u,l),d=depthwiseConv2dNativeBackpropInput$2(i.shape,p,a,n,r,s,o),h=depthwiseConv2dNativeBackpropFilter$2(i,p,a.shape,n,r,s,o);return null!=c?[d,h,getFusedBiasGradient(g,p)]:[d,h]},b={x:h,filter:d,bias:g,preluActivationWeights:$},x={strides:n,pad:r,dataFormat:a,dilations:s,dimRoundingMode:o,activation:l,leakyreluAlpha:c};return null==i?customGrad((e,t,n)=>{let r=ENGINE.runKernel(FusedDepthwiseConv2D,b,x);return n([t,e,r]),m&&(r=reshape$3(r,[r.shape[1],r.shape[2],r.shape[3]])),{value:r,gradFunc:y}})(h,d):customGrad((e,t,n,r)=>{let a=ENGINE.runKernel(FusedDepthwiseConv2D,b,x);return r([t,e,a,n]),m&&(a=reshape$3(a,[a.shape[1],a.shape[2],a.shape[3]])),{value:a,gradFunc:y}})(h,d,g)}const depthwiseConv2d$2=op({fusedDepthwiseConv2d_});function fusedMatMul_({a:e,b:t,transposeA:n=!1,transposeB:r=!1,bias:a,activation:s="linear",preluActivationWeights:o,leakyreluAlpha:i}){if(!1===shouldFuse(ENGINE.state.gradientDepth,s)){let l=matMul$1(e,t,n,r);return null!=a&&(l=add$2(l,a)),applyActivation$1(l,s,o,i)}let l=convertToTensor(e,"a","fused matMul"),u=convertToTensor(t,"b","fused matMul");[l,u]=makeTypesMatch(l,u);const c=n?l.shape[l.rank-2]:l.shape[l.rank-1],p=r?u.shape[u.rank-1]:u.shape[u.rank-2],d=n?l.shape[l.rank-1]:l.shape[l.rank-2],h=r?u.shape[u.rank-2]:u.shape[u.rank-1],m=l.shape.slice(0,-2),f=u.shape.slice(0,-2),g=sizeFromShape(m),$=sizeFromShape(f);assert$4(l.rank>=2&&u.rank>=2&&l.rank===u.rank,()=>`Error in fused matMul: inputs must have the same rank of at least 2, got ranks ${l.rank} and ${u.rank}.`),assert$4(arraysEqual(m,f),()=>`Error in fused matMul: outer dimensions (${m}) and (${f}) of Tensors with shapes ${l.shape} and ${u.shape} must match.`),assert$4(c===p,()=>`Error in fused matMul: inner shapes (${c}) and (${p}) of Tensors with shapes ${l.shape} and ${u.shape} and transposeA=${n} and transposeB=${r} must match.`);const y=l.shape.slice(0,-2).concat([d,h]),b=reshape$3(l,n?[g,c,d]:[g,d,c]),x=reshape$3(u,r?[$,h,p]:[$,p,h]);let v,I;null!=a&&(v=convertToTensor(a,"bias","fused matMul"),[v]=makeTypesMatch(v,l),assertAndGetBroadcastShape(y,v.shape)),null!=o&&(I=convertToTensor(o,"prelu weights","fused matMul"));const C=(e,t)=>{const[o,i,l,u]=t,c=getFusedDyActivation(reshape$3(e,l.shape),l,s);let p,d;return n||r?!n&&r?(p=matMul$1(c,i,!1,!1),d=matMul$1(c,o,!0,!1)):n&&!r?(p=matMul$1(i,c,!1,!0),d=matMul$1(o,c,!1,!1)):(p=matMul$1(i,c,!0,!0),d=matMul$1(c,o,!0,!0)):(p=matMul$1(c,i,!1,!0),d=matMul$1(o,c,!0,!1)),null!=a?[p,d,getFusedBiasGradient(u,c)]:[p,d]},S={a:b,b:x,bias:v,preluActivationWeights:I},k={transposeA:n,transposeB:r,activation:s,leakyreluAlpha:i};return null==a?customGrad((e,t,n)=>{const r=ENGINE.runKernel(_FusedMatMul,S,k);return n([e,t,r]),{value:reshape$3(r,y),gradFunc:C}})(b,x):customGrad((e,t,n,r)=>{const a=ENGINE.runKernel(_FusedMatMul,S,k);return r([e,t,a,n]),{value:reshape$3(a,y),gradFunc:C}})(b,x,v)}const matMul=op({fusedMatMul_});var fused_ops={__proto__:null,conv2d:conv2d$2,depthwiseConv2d:depthwiseConv2d$2,matMul};function hammingWindow_(e){return cosineWindow(e,.54,.46)}const hammingWindow=op({hammingWindow_});function hannWindow_(e){return cosineWindow(e,.5,.5)}const hannWindow=op({hannWindow_});function frame_(e,t,n,r=!1,a=0){let s=0;const o=[];for(;s+t<=e.size;)o.push(slice$2(e,s,t)),s+=n;if(r)for(;s<e.size;){const r=s+t-e.size,i=concat$2([slice$2(e,s,t-r),fill$2([r],a)]);o.push(i),s+=n}return 0===o.length?tensor2d([],[0,t]):reshape$3(concat$2(o),[o.length,t])}const frame=op({frame_});function stft_(e,t,n,r,a=hannWindow){null==r&&(r=enclosingPowerOfTwo(t));const s=frame(e,t,n),o=mul(s,a(t));return rfft(o,r)}const stft=op({stft_});function cropAndResize_(e,t,n,r,a="bilinear",s=0){const o=convertToTensor(e,"image","cropAndResize"),i=convertToTensor(t,"boxes","cropAndResize","float32"),l=convertToTensor(n,"boxInd","cropAndResize","int32"),u=i.shape[0];return assert$4(4===o.rank,()=>`Error in cropAndResize: image must be rank 4,but got rank ${o.rank}.`),assert$4(2===i.rank&&4===i.shape[1],()=>`Error in cropAndResize: boxes must be have size [${u},4] but had shape ${i.shape}.`),assert$4(1===l.rank&&l.shape[0]===u,()=>`Error in cropAndResize: boxInd must be have size [${u}] but had shape ${i.shape}.`),assert$4(2===r.length,()=>`Error in cropAndResize: cropSize must be of length 2, but got length ${r.length}.`),assert$4(r[0]>=1&&r[1]>=1,()=>`cropSize must be atleast [1,1], but was ${r}`),assert$4("bilinear"===a||"nearest"===a,()=>`method must be bilinear or nearest, but was ${a}`),ENGINE.runKernel(CropAndResize,{image:o,boxes:i,boxInd:l},{method:a,extrapolationValue:s,cropSize:r})}const cropAndResize$2=op({cropAndResize_});function flipLeftRight_(e){const t=convertToTensor(e,"image","flipLeftRight","float32");return assert$4(4===t.rank,()=>`Error in flipLeftRight: image must be rank 4,but got rank ${t.rank}.`),ENGINE.runKernel(FlipLeftRight,{image:t},{})}const flipLeftRight=op({flipLeftRight_});function rotateWithOffset_(e,t,n=0,r=.5){const a=convertToTensor(e,"image","rotateWithOffset","float32");return assert$4(4===a.rank,()=>`Error in rotateWithOffset: image must be rank 4,but got rank ${a.rank}.`),ENGINE.runKernel(RotateWithOffset,{image:a},{radians:t,fillValue:n,center:r})}const rotateWithOffset=op({rotateWithOffset_});function nonMaxSuppSanityCheck(e,t,n,r,a,s){null==r&&(r=.5),null==a&&(a=Number.NEGATIVE_INFINITY),null==s&&(s=0);const o=e.shape[0];return n=Math.min(n,o),assert$4(0<=r&&r<=1,()=>`iouThreshold must be in [0, 1], but was '${r}'`),assert$4(2===e.rank,()=>`boxes must be a 2D tensor, but was of rank '${e.rank}'`),assert$4(4===e.shape[1],()=>`boxes must have 4 columns, but 2nd dimension was ${e.shape[1]}`),assert$4(1===t.rank,()=>"scores must be a 1D tensor"),assert$4(t.shape[0]===o,()=>`scores has incompatible shape with boxes. Expected ${o}, but was ${t.shape[0]}`),assert$4(0<=s&&s<=1,()=>`softNmsSigma must be in [0, 1], but was '${s}'`),{maxOutputSize:n,iouThreshold:r,scoreThreshold:a,softNmsSigma:s}}function nonMaxSuppression_(e,t,n,r=.5,a=Number.NEGATIVE_INFINITY){const s=convertToTensor(e,"boxes","nonMaxSuppression"),o=convertToTensor(t,"scores","nonMaxSuppression"),i=nonMaxSuppSanityCheck(s,o,n,r,a);return ENGINE.runKernel(NonMaxSuppressionV3,{boxes:s,scores:o},{maxOutputSize:n=i.maxOutputSize,iouThreshold:r=i.iouThreshold,scoreThreshold:a=i.scoreThreshold})}const nonMaxSuppression=op({nonMaxSuppression_});function binaryInsert(e,t,n){const r=binarySearch(e,t,n);e.splice(r<0?-(r+1):r,0,t)}function binarySearch(e,t,n){return binarySearch_(e,t,n||defaultComparator)}function defaultComparator(e,t){return e>t?1:e<t?-1:0}function binarySearch_(e,t,n){let r=0,a=e.length,s=0,o=!1;for(;r<a;){s=r+(a-r>>>1);const i=n(t,e[s]);i>0?r=s+1:(a=s,o=!i)}return o?r:-r-1}function nonMaxSuppressionV3Impl$2(e,t,n,r,a){return nonMaxSuppressionImpl_(e,t,n,r,a,0)}function nonMaxSuppressionV4Impl$2(e,t,n,r,a,s){return nonMaxSuppressionImpl_(e,t,n,r,a,0,!1,s,!0)}function nonMaxSuppressionV5Impl$2(e,t,n,r,a,s){return nonMaxSuppressionImpl_(e,t,n,r,a,s,!0)}function nonMaxSuppressionImpl_(e,t,n,r,a,s,o=!1,i=!1,l=!1){const u=[];for(let e=0;e<t.length;e++)t[e]>a&&u.push({score:t[e],boxIndex:e,suppressBeginIndex:0});u.sort(ascendingComparator);const c=s>0?-.5/s:0,p=[],d=[];for(;p.length<n&&u.length>0;){const t=u.pop(),{score:n,boxIndex:s,suppressBeginIndex:o}=t;if(n<a)break;let i=!1;for(let n=p.length-1;n>=o;--n){const o=intersectionOverUnion(e,s,p[n]);if(o>=r){i=!0;break}if(t.score=t.score*suppressWeight(r,c,o),t.score<=a)break}t.suppressBeginIndex=p.length,i||(t.score===n?(p.push(s),d.push(t.score)):t.score>a&&binaryInsert(u,t,ascendingComparator))}const h=p.length,m=n-h;i&&m>0&&(p.push(...new Array(m).fill(0)),d.push(...new Array(m).fill(0)));const f={selectedIndices:p};return o&&(f.selectedScores=d),l&&(f.validOutputs=h),f}function intersectionOverUnion(e,t,n){const r=e.subarray(4*t,4*t+4),a=e.subarray(4*n,4*n+4),s=Math.min(r[0],r[2]),o=Math.min(r[1],r[3]),i=Math.max(r[0],r[2]),l=Math.max(r[1],r[3]),u=Math.min(a[0],a[2]),c=Math.min(a[1],a[3]),p=Math.max(a[0],a[2]),d=Math.max(a[1],a[3]),h=(i-s)*(l-o),m=(p-u)*(d-c);if(h<=0||m<=0)return 0;const f=Math.max(s,u),g=Math.max(o,c),$=Math.min(i,p),y=Math.min(l,d),b=Math.max($-f,0)*Math.max(y-g,0);return b/(h+m-b)}function suppressWeight(e,t,n){const r=Math.exp(t*n*n);return n<=e?r:0}function ascendingComparator(e,t){return e.score-t.score||e.score===t.score&&t.boxIndex-e.boxIndex}async function nonMaxSuppressionAsync_(e,t,n,r=.5,a=Number.NEGATIVE_INFINITY){const s=convertToTensor(e,"boxes","nonMaxSuppressionAsync"),o=convertToTensor(t,"scores","nonMaxSuppressionAsync"),i=nonMaxSuppSanityCheck(s,o,n,r,a);n=i.maxOutputSize,r=i.iouThreshold,a=i.scoreThreshold;const l=await Promise.all([s.data(),o.data()]),u=l[0],c=l[1],{selectedIndices:p}=nonMaxSuppressionV3Impl$2(u,c,n,r,a);return s!==e&&s.dispose(),o!==t&&o.dispose(),tensor1d(p,"int32")}const nonMaxSuppressionAsync=nonMaxSuppressionAsync_;function nonMaxSuppressionWithScore_(e,t,n,r=.5,a=Number.NEGATIVE_INFINITY,s=0){const o=convertToTensor(e,"boxes","nonMaxSuppression"),i=convertToTensor(t,"scores","nonMaxSuppression"),l=nonMaxSuppSanityCheck(o,i,n,r,a,s),u=ENGINE.runKernel(NonMaxSuppressionV5,{boxes:o,scores:i},{maxOutputSize:n=l.maxOutputSize,iouThreshold:r=l.iouThreshold,scoreThreshold:a=l.scoreThreshold,softNmsSigma:s=l.softNmsSigma});return{selectedIndices:u[0],selectedScores:u[1]}}const nonMaxSuppressionWithScore=op({nonMaxSuppressionWithScore_});async function nonMaxSuppressionWithScoreAsync_(e,t,n,r=.5,a=Number.NEGATIVE_INFINITY,s=0){const o=convertToTensor(e,"boxes","nonMaxSuppressionAsync"),i=convertToTensor(t,"scores","nonMaxSuppressionAsync"),l=nonMaxSuppSanityCheck(o,i,n,r,a,s);n=l.maxOutputSize,r=l.iouThreshold,a=l.scoreThreshold,s=l.softNmsSigma;const u=await Promise.all([o.data(),i.data()]),c=u[0],p=u[1],{selectedIndices:d,selectedScores:h}=nonMaxSuppressionV5Impl$2(c,p,n,r,a,s);return o!==e&&o.dispose(),i!==t&&i.dispose(),{selectedIndices:tensor1d(d,"int32"),selectedScores:tensor1d(h)}}const nonMaxSuppressionWithScoreAsync=nonMaxSuppressionWithScoreAsync_;function nonMaxSuppressionPadded_(e,t,n,r=.5,a=Number.NEGATIVE_INFINITY,s=!1){const o=convertToTensor(e,"boxes","nonMaxSuppression"),i=convertToTensor(t,"scores","nonMaxSuppression"),l=nonMaxSuppSanityCheck(o,i,n,r,a,null),u=ENGINE.runKernel(NonMaxSuppressionV4,{boxes:o,scores:i},{maxOutputSize:l.maxOutputSize,iouThreshold:l.iouThreshold,scoreThreshold:l.scoreThreshold,padToMaxOutputSize:s});return{selectedIndices:u[0],validOutputs:u[1]}}const nonMaxSuppressionPadded=op({nonMaxSuppressionPadded_});async function nonMaxSuppressionPaddedAsync_(e,t,n,r=.5,a=Number.NEGATIVE_INFINITY,s=!1){const o=convertToTensor(e,"boxes","nonMaxSuppressionAsync"),i=convertToTensor(t,"scores","nonMaxSuppressionAsync"),l=nonMaxSuppSanityCheck(o,i,n,r,a,null),u=l.maxOutputSize,c=l.iouThreshold,p=l.scoreThreshold,[d,h]=await Promise.all([o.data(),i.data()]),{selectedIndices:m,validOutputs:f}=nonMaxSuppressionV4Impl$2(d,h,u,c,p,s);return o!==e&&o.dispose(),i!==t&&i.dispose(),{selectedIndices:tensor1d(m,"int32"),validOutputs:scalar(f,"int32")}}const nonMaxSuppressionPaddedAsync=nonMaxSuppressionPaddedAsync_;function resizeBilinear_(e,t,n=!1,r=!1){const a=convertToTensor(e,"images","resizeBilinear");assert$4(3===a.rank||4===a.rank,()=>`Error in resizeBilinear: x must be rank 3 or 4, but got rank ${a.rank}.`),assert$4(2===t.length,()=>`Error in resizeBilinear: new shape must 2D, but got shape ${t}.`),assert$4(!1===r||!1===n,()=>"Error in resizeBilinear: If halfPixelCenters is true, alignCorners must be false.");let s=a,o=!1;3===a.rank&&(o=!0,s=reshape$3(a,[1,a.shape[0],a.shape[1],a.shape[2]]));const i=ENGINE.runKernel(ResizeBilinear,{images:s},{alignCorners:n,halfPixelCenters:r,size:t});return o?reshape$3(i,[i.shape[1],i.shape[2],i.shape[3]]):i}const resizeBilinear$2=op({resizeBilinear_});function resizeNearestNeighbor_(e,t,n=!1,r=!1){const a=convertToTensor(e,"images","resizeNearestNeighbor");assert$4(3===a.rank||4===a.rank,()=>`Error in resizeNearestNeighbor: x must be rank 3 or 4, but got rank ${a.rank}.`),assert$4(2===t.length,()=>`Error in resizeNearestNeighbor: new shape must 2D, but got shape ${t}.`),assert$4("float32"===a.dtype||"int32"===a.dtype,()=>"`images` must have `int32` or `float32` as dtype"),assert$4(!1===r||!1===n,()=>"Error in resizeNearestNeighbor: If halfPixelCenters is true, alignCorners must be false.");let s=a,o=!1;3===a.rank&&(o=!0,s=reshape$3(a,[1,a.shape[0],a.shape[1],a.shape[2]]));const i=ENGINE.runKernel(ResizeNearestNeighbor,{images:s},{alignCorners:n,halfPixelCenters:r,size:t});return o?reshape$3(i,[i.shape[1],i.shape[2],i.shape[3]]):i}const resizeNearestNeighbor$2=op({resizeNearestNeighbor_});function threshold_(e,t="binary",n=!1,r=.5){const a=convertToTensor(e,"image","threshold"),s=a.shape[0]*a.shape[1];let o,i,l,u,c=mul(tensor1d([r]),255);if(assert$4(3===a.rank,()=>`Error in threshold: image must be rank 3,but got rank ${a.rank}.`),assert$4(3===a.shape[2]||1===a.shape[2],()=>`Error in threshold: image color channel must be equal to 3 or 1but got ${a.shape[2]}.`),assert$4("int32"===a.dtype||"float32"===a.dtype,()=>`Error in dtype: image dtype must be int32 or float32,but got dtype ${a.dtype}.`),assert$4("otsu"===t||"binary"===t,()=>`Method must be binary or otsu, but was ${t}`),3===a.shape[2]){[o,i,l]=split$2(a,[1,1,1],-1);const e=mul(o,.2989),t=mul(i,.587),n=mul(l,.114);u=add$2(add$2(e,t),n)}else u=e;"otsu"===t&&(c=otsu(bincount$2(cast$3(round$2(u),"int32"),tensor([]),256),s));const p=n?lessEqual$2(u,c):greater$3(u,c);return cast$3(mul(p,255),"int32")}function otsu(e,t){let n,r,a,s,o,i,l=tensor1d([-1]),u=tensor1d([0]),c=tensor1d([0]);for(let p=0;p<e.size-1;p++){n=slice$2(e,0,p+1),r=slice$2(e,p+1),o=div$1(sum$2(n),t),i=div$1(sum$2(r),t);const d=sum$2(mul(n,range$4(0,n.size)));a=div$1(d,sum$2(n));const h=fill$2(r.shape,n.size),m=add$2(range$4(0,r.size),h),f=mul(r,m);s=div$1(sum$2(f),sum$2(r));const g=sub$2(a,s),$=sub$2(a,s),y=mul(o,i);c=mul(mul(y,g),$);const b=greater$3(c,u);u=where(b,c,u),l=where(b,tensor1d([p]),l)}return l}const threshold$1=op({threshold_});function transform_(e,t,n="nearest",r="constant",a=0,s){const o=convertToTensor(e,"image","transform","float32"),i=convertToTensor(t,"transforms","transform","float32");return assert$4(4===o.rank,()=>`Error in transform: image must be rank 4,but got rank ${o.rank}.`),assert$4(2===i.rank&&(i.shape[0]===o.shape[0]||1===i.shape[0])&&8===i.shape[1],()=>"Error in transform: Input transform should be batch x 8 or 1 x 8"),assert$4(null==s||2===s.length,()=>`Error in transform: outputShape must be [height, width] or null, but got ${s}.`),ENGINE.runKernel(Transform,{image:o,transforms:i},{interpolation:n,fillMode:r,fillValue:a,outputShape:s})}const transform$2=op({transform_});function bandPart_(e,t,n){assert$4(t%1==0,()=>`bandPart(): numLower must be an integer, got ${t}.`),assert$4(n%1==0,()=>`bandPart(): numUpper must be an integer, got ${n}.`);const r=convertToTensor(e,"a","bandPart");assert$4(r.rank>=2,()=>`bandPart(): Rank must be at least 2, got ${r.rank}.`);const a=r.shape,[s,o]=r.shape.slice(-2);if(!(t<=s))throw new Error(`bandPart(): numLower (${t}) must not be greater than the number of rows (${s}).`);if(!(n<=o))throw new Error(`bandPart(): numUpper (${n}) must not be greater than the number of columns (${o}).`);t<0&&(t=s),n<0&&(n=o);const i=reshape$3(range$4(0,s,1,"int32"),[-1,1]),l=range$4(0,o,1,"int32"),u=sub$2(i,l),c=logicalAnd$2(lessEqual$2(u,scalar(+t,"int32")),greaterEqual$2(u,scalar(-n,"int32"))),p=zeros$2([s,o],r.dtype);return reshape$3(stack(unstack(reshape$3(r,[-1,s,o])).map(e=>where(c,e,p))),a)}const bandPart=op({bandPart_});function gramSchmidt_(e){let t;if(Array.isArray(e)){t=!1,assert$4(null!=e&&e.length>0,()=>"Gram-Schmidt process: input must not be null, undefined, or empty");const n=e[0].shape[0];for(let t=1;t<e.length;++t)assert$4(e[t].shape[0]===n,()=>`Gram-Schmidt: Non-unique lengths found in the input vectors: (${e[t].shape[0]} vs. ${n})`)}else t=!0,e=split$2(e,e.shape[0],0).map(e=>squeeze(e,[0]));assert$4(e.length<=e[0].shape[0],()=>`Gram-Schmidt: Number of vectors (${e.length}) exceeds number of dimensions (${e[0].shape[0]}).`);const n=[],r=e;for(let t=0;t<e.length;++t)n.push(ENGINE.tidy(()=>{let e=r[t];if(t>0)for(let r=0;r<t;++r){const t=mul(sum$2(mul(n[r],e)),n[r]);e=sub$2(e,t)}return div$1(e,norm(e,"euclidean"))}));return t?stack(n,0):n}const gramSchmidt=op({gramSchmidt_});function qr_(e,t=!1){if(assert$4(e.rank>=2,()=>`qr() requires input tensor to have a rank >= 2, but got rank ${e.rank}`),2===e.rank)return qr2d(e,t);{const n=e.shape.slice(0,e.shape.length-2).reduce((e,t)=>e*t),r=unstack(reshape$3(e,[n,e.shape[e.shape.length-2],e.shape[e.shape.length-1]]),0),a=[],s=[];return r.forEach(e=>{const[n,r]=qr2d(e,t);a.push(n),s.push(r)}),[reshape$3(stack(a,0),e.shape),reshape$3(stack(s,0),e.shape)]}}function qr2d(e,t=!1){return ENGINE.tidy(()=>{assert$4(2===e.shape.length,()=>`qr2d() requires a 2D Tensor, but got a ${e.shape.length}D Tensor.`);const n=e.shape[0],r=e.shape[1];let a=eye(n),s=clone(e);const o=tensor2d([[1]],[1,1]);let i=clone(o);const l=n>=r?r:n;for(let e=0;e<l;++e){const t=s,l=i,u=a;[i,s,a]=ENGINE.tidy(()=>{const t=slice$2(s,[e,e],[n-e,1]),l=norm(t),u=slice$2(s,[e,e],[1,1]),c=where(greater$3(u,0),tensor2d([[-1]]),tensor2d([[1]])),p=sub$2(u,mul(c,l)),d=div$1(t,p);i=1===d.shape[0]?clone(o):concat$2([o,slice$2(d,[1,0],[d.shape[0]-1,d.shape[1]])],0);const h=neg$2(div$1(matMul$1(c,p),l)),m=slice$2(s,[e,0],[n-e,r]),f=mul(h,i),g=transpose$2(i);if(0===e)s=sub$2(m,matMul$1(f,matMul$1(g,m)));else{const t=sub$2(m,matMul$1(f,matMul$1(g,m)));s=concat$2([slice$2(s,[0,0],[e,r]),t],0)}const $=transpose$2(f),y=slice$2(a,[0,e],[n,a.shape[1]-e]);if(0===e)a=sub$2(y,matMul$1(matMul$1(y,i),$));else{const t=sub$2(y,matMul$1(matMul$1(y,i),$));a=concat$2([slice$2(a,[0,0],[n,e]),t],1)}return[i,s,a]}),dispose([t,l,u])}return!t&&n>r&&(a=slice$2(a,[0,0],[n,r]),s=slice$2(s,[0,0],[r,r])),[a,s]})}const qr=op({qr_});var Reduction;function computeWeightedLoss_(e,t,n=Reduction.SUM_BY_NONZERO_WEIGHTS){const r=convertToTensor(e,"losses","computeWeightedLoss");let a=null;null!=t&&(a=convertToTensor(t,"weights","computeWeightedLoss"));const s=null==a?r:mul(r,a);if(n===Reduction.NONE)return s;if(n===Reduction.SUM)return sum$2(s);if(n===Reduction.MEAN){if(null==a)return mean$1(s);{const e=r.size/a.size,t=div$1(sum$2(s),sum$2(a));return e>1?div$1(t,scalar(e)):t}}if(n===Reduction.SUM_BY_NONZERO_WEIGHTS){if(null==a)return div$1(sum$2(s),scalar(r.size));{const e=mul(a,ones$1(r.shape)),t=cast$3(sum$2(notEqual$2(e,scalar(0))),"float32");return div$1(sum$2(s),t)}}throw Error(`Unknown reduction: ${n}`)}!function(e){e[e.NONE=0]="NONE",e[e.MEAN=1]="MEAN",e[e.SUM=2]="SUM",e[e.SUM_BY_NONZERO_WEIGHTS=3]="SUM_BY_NONZERO_WEIGHTS"}(Reduction||(Reduction={}));const computeWeightedLoss$1=op({computeWeightedLoss_});function absoluteDifference_(e,t,n,r=Reduction.SUM_BY_NONZERO_WEIGHTS){const a=convertToTensor(e,"labels","absoluteDifference"),s=convertToTensor(t,"predictions","absoluteDifference");let o=null;null!=n&&(o=convertToTensor(n,"weights","absoluteDifference")),assertShapesMatch(a.shape,s.shape,"Error in absoluteDifference: ");const i=abs$2(sub$2(a,s));return computeWeightedLoss$1(i,o,r)}const absoluteDifference=op({absoluteDifference_});function cosineDistance_(e,t,n,r,a=Reduction.SUM_BY_NONZERO_WEIGHTS){const s=convertToTensor(e,"labels","cosineDistance"),o=convertToTensor(t,"predictions","cosineDistance");let i=null;null!=r&&(i=convertToTensor(r,"weights","cosineDistance")),assertShapesMatch(s.shape,o.shape,"Error in cosineDistance: ");const l=scalar(1),u=sub$2(l,sum$2(mul(s,o),n,!0));return computeWeightedLoss$1(u,i,a)}const cosineDistance=op({cosineDistance_});function hingeLoss_(e,t,n,r=Reduction.SUM_BY_NONZERO_WEIGHTS){let a=convertToTensor(e,"labels","hingeLoss");const s=convertToTensor(t,"predictions","hingeLoss");let o=null;null!=n&&(o=convertToTensor(n,"weights","hingeLoss")),assertShapesMatch(a.shape,s.shape,"Error in hingeLoss: ");const i=scalar(1);a=sub$2(mul(scalar(2),a),i);const l=relu$3(sub$2(i,mul(a,s)));return computeWeightedLoss$1(l,o,r)}const hingeLoss=op({hingeLoss_});function huberLoss_(e,t,n,r=1,a=Reduction.SUM_BY_NONZERO_WEIGHTS){const s=convertToTensor(e,"labels","huberLoss"),o=convertToTensor(t,"predictions","huberLoss");let i=null;null!=n&&(i=convertToTensor(n,"weights","huberLoss")),assertShapesMatch(s.shape,o.shape,"Error in huberLoss: ");const l=scalar(r),u=abs$2(sub$2(o,s)),c=minimum$3(u,l),p=sub$2(u,c),d=add$2(mul(scalar(.5),square$2(c)),mul(l,p));return computeWeightedLoss$1(d,i,a)}const huberLoss=op({huberLoss_});function logLoss_(e,t,n,r=1e-7,a=Reduction.SUM_BY_NONZERO_WEIGHTS){const s=convertToTensor(e,"labels","logLoss"),o=convertToTensor(t,"predictions","logLoss");let i=null;null!=n&&(i=convertToTensor(n,"weights","logLoss")),assertShapesMatch(s.shape,o.shape,"Error in logLoss: ");const l=scalar(1),u=scalar(r),c=neg$2(mul(s,log$3(add$2(o,u)))),p=mul(sub$2(l,s),log$3(add$2(sub$2(l,o),u))),d=sub$2(c,p);return computeWeightedLoss$1(d,i,a)}const logLoss=op({logLoss_});function meanSquaredError_(e,t,n,r=Reduction.SUM_BY_NONZERO_WEIGHTS){const a=convertToTensor(e,"labels","meanSquaredError"),s=convertToTensor(t,"predictions","meanSquaredError");let o=null;null!=n&&(o=convertToTensor(n,"weights","meanSquaredError")),assertShapesMatch(a.shape,s.shape,"Error in meanSquaredError: ");const i=squaredDifference$2(a,s);return computeWeightedLoss$1(i,o,r)}const meanSquaredError$2=op({meanSquaredError_});function sigmoidCrossEntropyWithLogits_(e,t){const n=convertToTensor(e,"labels","sigmoidCrossEntropyWithLogits"),r=convertToTensor(t,"logits","sigmoidCrossEntropyWithLogits");assertShapesMatch(n.shape,r.shape,"Error in sigmoidCrossEntropyWithLogits: ");const a=relu$3(r),s=mul(r,n),o=log1p$2(exp$2(neg$2(abs$2(r))));return add$2(sub$2(a,s),o)}function sigmoidCrossEntropy_(e,t,n,r=0,a=Reduction.SUM_BY_NONZERO_WEIGHTS){let s=convertToTensor(e,"multiClassLabels","sigmoidCrossEntropy");const o=convertToTensor(t,"logits","sigmoidCrossEntropy");let i=null;if(null!=n&&(i=convertToTensor(n,"weights","sigmoidCrossEntropy")),assertShapesMatch(s.shape,o.shape,"Error in sigmoidCrossEntropy: "),r>0){const e=scalar(r),t=scalar(1),n=scalar(.5);s=add$2(mul(s,sub$2(t,e)),mul(n,e))}const l=sigmoidCrossEntropyWithLogits_(s,o);return computeWeightedLoss$1(l,i,a)}const sigmoidCrossEntropy=op({sigmoidCrossEntropy_});function softmaxCrossEntropyWithLogits_(e,t,n=-1){if(-1===n&&(n=t.rank-1),n!==t.rank-1)throw Error(`Softmax cross entropy along a non-last dimension is not yet supported. Labels / logits was rank ${t.rank} and dim was ${n}`);return customGrad((e,t,r)=>{const a=logSumExp(t,[n],!0),s=sub$2(cast$3(t,"float32"),a);r([e,s]);const o=neg$2(mul(s,e));return{value:sum$2(o,[n]),gradFunc:(e,t)=>{const[r,a]=t,s=expandShapeToKeepDim(e.shape,[n]);return[mul(reshape$3(e,s),sub$2(cast$3(r,"float32"),exp$2(a))),mul(reshape$3(e,s),sub$2(exp$2(a),cast$3(r,"float32")))]}}})(e,t)}function softmaxCrossEntropy_(e,t,n,r=0,a=Reduction.SUM_BY_NONZERO_WEIGHTS){let s=convertToTensor(e,"onehotLabels","softmaxCrossEntropy");const o=convertToTensor(t,"logits","softmaxCrossEntropy");let i=null;if(null!=n&&(i=convertToTensor(n,"weights","softmaxCrossEntropy")),assertShapesMatch(s.shape,o.shape,"Error in softmaxCrossEntropy: "),r>0){const e=scalar(r),t=scalar(1),n=scalar(s.shape[1]);s=add$2(mul(s,sub$2(t,e)),div$1(e,n))}const l=softmaxCrossEntropyWithLogits_(s,o);return computeWeightedLoss$1(l,i,a)}const softmaxCrossEntropy=op({softmaxCrossEntropy_});function sparseFillEmptyRows_(e,t,n,r){const a=convertToTensor(e,"indices","sparseFillEmptyRows"),s=convertToTensor(t,"values","sparseFillEmptyRows"),o=convertToTensor(n,"denseShape","sparseFillEmptyRows"),i=convertToTensor(r,"defaultValue","sparseFillEmptyRows",s.dtype);if(2!==a.rank)throw new Error(`Indices should be Tensor2D but received shape\n        ${a.shape}`);if(1!==s.rank)throw new Error(`Values should be Tensor1D but received shape ${s.shape}`);if(1!==o.rank)throw new Error(`Dense shape should be Tensor1D but received shape ${o.shape}`);if(0!==i.rank)throw new Error(`Default value should be a scalar but received shape ${i.shape}`);const l=ENGINE.runKernel(SparseFillEmptyRows,{indices:a,values:s,denseShape:o,defaultValue:i});return{outputIndices:l[0],outputValues:l[1],emptyRowIndicator:l[2],reverseIndexMap:l[3]}}const sparseFillEmptyRows$2=op({sparseFillEmptyRows_});function sparseReshape_(e,t,n){const r=convertToTensor(e,"inputIndices","sparseReshape"),a=convertToTensor(t,"inputShape","sparseReshape"),s=convertToTensor(n,"newShape","sparseReshape");if(2!==r.rank)throw new Error(`Input indices should be Tensor2D but received shape\n        ${r.shape}`);if(1!==a.rank)throw new Error(`Input shape should be Tensor1D but received shape ${a.shape}`);if(1!==s.rank)throw new Error(`New shape should be Tensor1D but received shape ${s.shape}`);const o=ENGINE.runKernel(SparseReshape,{inputIndices:r,inputShape:a,newShape:s});return{outputIndices:o[0],outputShape:o[1]}}const sparseReshape$2=op({sparseReshape_});function sparseSegmentMean_(e,t,n){const r=convertToTensor(e,"data","sparseSegmentMean"),a=convertToTensor(t,"indices","sparseSegmentMean"),s=convertToTensor(n,"segmentIds","sparseSegmentMean");if(r.rank<1)throw new Error("Data should be at least 1 dimensional but received scalar");if(1!==a.rank)throw new Error(`Indices should be Tensor1D but received shape\n          ${a.shape}`);if(1!==s.rank)throw new Error(`Segment ids should be Tensor1D but received shape\n          ${s.shape}`);return ENGINE.runKernel(SparseSegmentMean,{data:r,indices:a,segmentIds:s})}const sparseSegmentMean$2=op({sparseSegmentMean_});function sparseSegmentSum_(e,t,n){const r=convertToTensor(e,"data","sparseSegmentSum"),a=convertToTensor(t,"indices","sparseSegmentSum"),s=convertToTensor(n,"segmentIds","sparseSegmentSum");if(r.rank<1)throw new Error("Data should be at least 1 dimensional but received scalar");if(1!==a.rank)throw new Error(`Indices should be Tensor1D but received shape\n         ${a.shape}`);if(1!==s.rank)throw new Error(`Segment ids should be Tensor1D but received shape\n         ${s.shape}`);return ENGINE.runKernel(SparseSegmentSum,{data:r,indices:a,segmentIds:s})}const sparseSegmentSum$2=op({sparseSegmentSum_});function stringNGrams_(e,t,n,r,a,s,o,i){const l=convertToTensor(e,"data","stringNGrams","string");if("string"!==l.dtype)throw new Error("Data must be of datatype string");if(1!==l.shape.length)throw new Error(`Data must be a vector, saw: ${l.shape}`);const u=convertToTensor(t,"dataSplits","stringNGrams");if("int32"!==u.dtype)throw new Error("Data splits must be of datatype int32");const c=ENGINE.runKernel(StringNGrams,{data:l,dataSplits:u},{separator:n,nGramWidths:r,leftPad:a,rightPad:s,padWidth:o,preserveShortSequences:i});return{nGrams:c[0],nGramsSplits:c[1]}}const stringNGrams$2=op({stringNGrams_});function stringSplit_(e,t,n=!0){const r=convertToTensor(e,"input","stringSplit","string"),a=convertToTensor(t,"delimiter","stringSplit","string");if(1!==r.rank)throw new Error(`Input should be Tensor1D but received shape ${r.shape}`);if(0!==a.rank)throw new Error(`Delimiter should be a scalar but received shape ${a.shape}`);const s=ENGINE.runKernel(StringSplit,{input:r,delimiter:a},{skipEmpty:n});return{indices:s[0],values:s[1],shape:s[2]}}const stringSplit$2=op({stringSplit_});function stringToHashBucketFast_(e,t){const n=convertToTensor(e,"input","stringToHashBucketFast","string"),r={numBuckets:t};if(t<=0)throw new Error("Number of buckets must be at least 1");return ENGINE.runKernel(StringToHashBucketFast,{input:n},r)}const stringToHashBucketFast$2=op({stringToHashBucketFast_}),spectral$1={fft:fft$2,ifft:ifft$2,rfft,irfft},signal={hammingWindow,hannWindow,frame,stft},image$1={flipLeftRight,resizeNearestNeighbor:resizeNearestNeighbor$2,resizeBilinear:resizeBilinear$2,rotateWithOffset,cropAndResize:cropAndResize$2,nonMaxSuppression,nonMaxSuppressionAsync,nonMaxSuppressionWithScore,nonMaxSuppressionWithScoreAsync,nonMaxSuppressionPadded,nonMaxSuppressionPaddedAsync,threshold:threshold$1,transform:transform$2},linalg={bandPart,gramSchmidt,qr},losses={absoluteDifference,computeWeightedLoss:computeWeightedLoss$1,cosineDistance,hingeLoss,huberLoss,logLoss,meanSquaredError:meanSquaredError$2,sigmoidCrossEntropy,softmaxCrossEntropy},sparse$1={sparseFillEmptyRows:sparseFillEmptyRows$2,sparseReshape:sparseReshape$2,sparseSegmentMean:sparseSegmentMean$2,sparseSegmentSum:sparseSegmentSum$2},string$1={stringNGrams:stringNGrams$2,stringSplit:stringSplit$2,stringToHashBucketFast:stringToHashBucketFast$2};class Optimizer extends Serializable{minimize(e,t=!1,n){const{value:r,grads:a}=this.computeGradients(e,n);if(null!=n){const e=n.map(e=>({name:e.name,tensor:a[e.name]}));this.applyGradients(e)}else this.applyGradients(a);return dispose(a),t?r:(r.dispose(),null)}get iterations(){return null==this.iterations_&&(this.iterations_=0),this.iterations_}incrementIterations(){this.iterations_=this.iterations+1}computeGradients(e,t){return variableGrads(e,t)}dispose(){null!=this.iterations_&&dispose(this.iterations_)}async saveIterations(){return null==this.iterations_&&(this.iterations_=0),{name:"iter",tensor:scalar(this.iterations_,"int32")}}async getWeights(){throw new Error("getWeights() is not implemented for this optimizer yet.")}async setWeights(e){throw new Error(`setWeights() is not implemented for this optimizer class ${this.getClassName()}`)}async extractIterations(e){return this.iterations_=(await e[0].tensor.data())[0],e.slice(1)}}Object.defineProperty(Optimizer,Symbol.hasInstance,{value:e=>null!=e.minimize&&null!=e.computeGradients&&null!=e.applyGradients});class AdadeltaOptimizer extends Optimizer{constructor(e,t,n=null){super(),this.learningRate=e,this.rho=t,this.epsilon=n,this.accumulatedGrads=[],this.accumulatedUpdates=[],null==n&&(this.epsilon=ENGINE.backend.epsilon())}applyGradients(e){(Array.isArray(e)?e.map(e=>e.name):Object.keys(e)).forEach((t,n)=>{const r=ENGINE.registeredVariables[t];null==this.accumulatedGrads[n]&&(this.accumulatedGrads[n]={originalName:`${t}/accum_grad`,variable:tidy(()=>zerosLike$2(r).variable(!1))}),null==this.accumulatedUpdates[n]&&(this.accumulatedUpdates[n]={originalName:`${t}/accum_var`,variable:tidy(()=>zerosLike$2(r).variable(!1))});const a=Array.isArray(e)?e[n].tensor:e[t];if(null==a)return;const s=this.accumulatedGrads[n].variable,o=this.accumulatedUpdates[n].variable;tidy(()=>{const e=add$2(mul(s,this.rho),mul(square$2(a),1-this.rho)),t=mul(div$1(sqrt$2(add$2(o,this.epsilon)),sqrt$2(add$2(s,this.epsilon))),a),n=add$2(mul(o,this.rho),mul(square$2(t),1-this.rho));s.assign(e),o.assign(n);const i=add$2(mul(t,-this.learningRate),r);r.assign(i)})}),this.incrementIterations()}dispose(){null!=this.accumulatedUpdates&&(dispose(this.accumulatedGrads.map(e=>e.variable)),dispose(this.accumulatedUpdates.map(e=>e.variable)))}async getWeights(){const e=[...this.accumulatedGrads,...this.accumulatedUpdates];return[await this.saveIterations()].concat(e.map(e=>({name:e.originalName,tensor:e.variable})))}async setWeights(e){const t=(e=await this.extractIterations(e)).length/2;this.accumulatedGrads=e.slice(0,t).map(e=>({originalName:e.name,variable:e.tensor.variable(!1)})),this.accumulatedUpdates=e.slice(t,2*t).map(e=>({originalName:e.name,variable:e.tensor.variable(!1)}))}getConfig(){return{learningRate:this.learningRate,rho:this.rho,epsilon:this.epsilon}}static fromConfig(e,t){return new e(t.learningRate,t.rho,t.epsilon)}}AdadeltaOptimizer.className="Adadelta",registerClass(AdadeltaOptimizer);class AdagradOptimizer extends Optimizer{constructor(e,t=.1){super(),this.learningRate=e,this.initialAccumulatorValue=t,this.accumulatedGrads=[]}applyGradients(e){(Array.isArray(e)?e.map(e=>e.name):Object.keys(e)).forEach((t,n)=>{const r=ENGINE.registeredVariables[t];if(null==this.accumulatedGrads[n]){const e=!1;this.accumulatedGrads[n]={originalName:`${t}/accumulator`,variable:tidy(()=>fill$2(r.shape,this.initialAccumulatorValue).variable(e))}}const a=Array.isArray(e)?e[n].tensor:e[t];if(null==a)return;const s=this.accumulatedGrads[n].variable;tidy(()=>{const e=add$2(s,square$2(a));s.assign(e);const t=add$2(mul(div$1(a,sqrt$2(add$2(e,ENGINE.backend.epsilon()))),-this.learningRate),r);r.assign(t)})}),this.incrementIterations()}dispose(){null!=this.accumulatedGrads&&dispose(this.accumulatedGrads.map(e=>e.variable))}async getWeights(){return[await this.saveIterations()].concat(this.accumulatedGrads.map(e=>({name:e.originalName,tensor:e.variable})))}async setWeights(e){e=await this.extractIterations(e),this.accumulatedGrads=e.map(e=>({originalName:e.name,variable:e.tensor.variable(!1)}))}getConfig(){return{learningRate:this.learningRate,initialAccumulatorValue:this.initialAccumulatorValue}}static fromConfig(e,t){return new e(t.learningRate,t.initialAccumulatorValue)}}AdagradOptimizer.className="Adagrad",registerClass(AdagradOptimizer);class AdamOptimizer extends Optimizer{constructor(e,t,n,r=null){super(),this.learningRate=e,this.beta1=t,this.beta2=n,this.epsilon=r,this.accumulatedFirstMoment=[],this.accumulatedSecondMoment=[],tidy(()=>{this.accBeta1=scalar(t).variable(),this.accBeta2=scalar(n).variable()}),null==r&&(this.epsilon=ENGINE.backend.epsilon())}applyGradients(e){const t=Array.isArray(e)?e.map(e=>e.name):Object.keys(e);tidy(()=>{const n=sub$2(1,this.accBeta1),r=sub$2(1,this.accBeta2);t.forEach((t,a)=>{const s=ENGINE.registeredVariables[t];null==this.accumulatedFirstMoment[a]&&(this.accumulatedFirstMoment[a]={originalName:`${t}/m`,variable:tidy(()=>zerosLike$2(s).variable(!1))}),null==this.accumulatedSecondMoment[a]&&(this.accumulatedSecondMoment[a]={originalName:`${t}/v`,variable:tidy(()=>zerosLike$2(s).variable(!1))});const o=Array.isArray(e)?e[a].tensor:e[t];if(null==o)return;const i=this.accumulatedFirstMoment[a].variable,l=this.accumulatedSecondMoment[a].variable,u=add$2(mul(i,this.beta1),mul(o,1-this.beta1)),c=add$2(mul(l,this.beta2),mul(square$2(o),1-this.beta2)),p=div$1(u,n),d=div$1(c,r);i.assign(u),l.assign(c);const h=add$2(mul(div$1(p,add$2(sqrt$2(d),this.epsilon)),-this.learningRate),s);s.assign(h)}),this.accBeta1.assign(mul(this.accBeta1,this.beta1)),this.accBeta2.assign(mul(this.accBeta2,this.beta2))}),this.incrementIterations()}dispose(){this.accBeta1.dispose(),this.accBeta2.dispose(),null!=this.accumulatedFirstMoment&&dispose(this.accumulatedFirstMoment.map(e=>e.variable)),null!=this.accumulatedSecondMoment&&dispose(this.accumulatedSecondMoment.map(e=>e.variable))}async getWeights(){const e=[...this.accumulatedFirstMoment,...this.accumulatedSecondMoment];return[await this.saveIterations()].concat(e.map(e=>({name:e.originalName,tensor:e.variable})))}async setWeights(e){e=await this.extractIterations(e),tidy(()=>{this.accBeta1.assign(pow$2(this.beta1,this.iterations_+1)),this.accBeta2.assign(pow$2(this.beta2,this.iterations_+1))});const t=e.length/2;this.accumulatedFirstMoment=e.slice(0,t).map(e=>({originalName:e.name,variable:e.tensor.variable(!1)})),this.accumulatedSecondMoment=e.slice(t,2*t).map(e=>({originalName:e.name,variable:e.tensor.variable(!1)}))}getConfig(){return{learningRate:this.learningRate,beta1:this.beta1,beta2:this.beta2,epsilon:this.epsilon}}static fromConfig(e,t){return new e(t.learningRate,t.beta1,t.beta2,t.epsilon)}}AdamOptimizer.className="Adam",registerClass(AdamOptimizer);class AdamaxOptimizer extends Optimizer{constructor(e,t,n,r=null,a=0){super(),this.learningRate=e,this.beta1=t,this.beta2=n,this.epsilon=r,this.decay=a,this.accumulatedFirstMoment=[],this.accumulatedWeightedInfNorm=[],tidy(()=>{this.iteration=scalar(0).variable(),this.accBeta1=scalar(t).variable()}),null==r&&(this.epsilon=ENGINE.backend.epsilon())}applyGradients(e){const t=Array.isArray(e)?e.map(e=>e.name):Object.keys(e);tidy(()=>{const n=sub$2(1,this.accBeta1),r=div$1(-this.learningRate,add$2(mul(this.iteration,this.decay),1));t.forEach((t,a)=>{const s=ENGINE.registeredVariables[t];null==this.accumulatedFirstMoment[a]&&(this.accumulatedFirstMoment[a]={originalName:`${t}/m`,variable:zerosLike$2(s).variable(!1)}),null==this.accumulatedWeightedInfNorm[a]&&(this.accumulatedWeightedInfNorm[a]={originalName:`${t}/v`,variable:zerosLike$2(s).variable(!1)});const o=Array.isArray(e)?e[a].tensor:e[t];if(null==o)return;const i=this.accumulatedFirstMoment[a].variable,l=this.accumulatedWeightedInfNorm[a].variable,u=add$2(mul(i,this.beta1),mul(o,1-this.beta1)),c=mul(l,this.beta2),p=abs$2(o),d=maximum$3(c,p);i.assign(u),l.assign(d);const h=add$2(mul(div$1(r,n),div$1(u,add$2(d,this.epsilon))),s);s.assign(h)}),this.iteration.assign(add$2(this.iteration,1)),this.accBeta1.assign(mul(this.accBeta1,this.beta1))}),this.incrementIterations()}dispose(){this.accBeta1.dispose(),this.iteration.dispose(),null!=this.accumulatedFirstMoment&&dispose(this.accumulatedFirstMoment.map(e=>e.variable)),null!=this.accumulatedWeightedInfNorm&&dispose(this.accumulatedWeightedInfNorm.map(e=>e.variable))}async getWeights(){throw new Error("getWeights() is not implemented for Adamax yet.")}async setWeights(e){throw new Error("setWeights() is not implemented for Adamax yet.")}getConfig(){return{learningRate:this.learningRate,beta1:this.beta1,beta2:this.beta2,epsilon:this.epsilon,decay:this.decay}}static fromConfig(e,t){return new e(t.learningRate,t.beta1,t.beta2,t.epsilon,t.decay)}}AdamaxOptimizer.className="Adamax",registerClass(AdamaxOptimizer);class SGDOptimizer extends Optimizer{constructor(e){super(),this.learningRate=e,this.setLearningRate(e)}applyGradients(e){(Array.isArray(e)?e.map(e=>e.name):Object.keys(e)).forEach((t,n)=>{const r=Array.isArray(e)?e[n].tensor:e[t];if(null==r)return;const a=ENGINE.registeredVariables[t];tidy(()=>{const e=add$2(mul(this.c,r),a);a.assign(e)})}),this.incrementIterations()}setLearningRate(e){this.learningRate=e,null!=this.c&&this.c.dispose(),this.c=keep(scalar(-e))}dispose(){this.c.dispose()}async getWeights(){return[await this.saveIterations()]}async setWeights(e){if(0!==(e=await this.extractIterations(e)).length)throw new Error("SGD optimizer does not have settable weights.")}getConfig(){return{learningRate:this.learningRate}}static fromConfig(e,t){return new e(t.learningRate)}}SGDOptimizer.className="SGD",registerClass(SGDOptimizer);class MomentumOptimizer extends SGDOptimizer{constructor(e,t,n=!1){super(e),this.learningRate=e,this.momentum=t,this.useNesterov=n,this.accumulations=[],this.m=scalar(this.momentum)}applyGradients(e){(Array.isArray(e)?e.map(e=>e.name):Object.keys(e)).forEach((t,n)=>{const r=ENGINE.registeredVariables[t];if(null==this.accumulations[n]){const e=!1;this.accumulations[n]={originalName:`${t}/momentum`,variable:tidy(()=>zerosLike$2(r).variable(e))}}const a=this.accumulations[n].variable,s=Array.isArray(e)?e[n].tensor:e[t];null!=s&&tidy(()=>{let e;const t=add$2(mul(this.m,a),s);e=add$2(mul(this.c,this.useNesterov?add$2(s,mul(t,this.m)):t),r),a.assign(t),r.assign(e)})}),this.incrementIterations()}dispose(){this.m.dispose(),null!=this.accumulations&&dispose(this.accumulations.map(e=>e.variable))}setMomentum(e){this.momentum=e}async getWeights(){return[await this.saveIterations()].concat(this.accumulations.map(e=>({name:e.originalName,tensor:e.variable})))}async setWeights(e){e=await this.extractIterations(e),this.accumulations=e.map(e=>({originalName:e.name,variable:e.tensor.variable(!1)}))}getConfig(){return{learningRate:this.learningRate,momentum:this.momentum,useNesterov:this.useNesterov}}static fromConfig(e,t){return new e(t.learningRate,t.momentum,t.useNesterov)}}MomentumOptimizer.className="Momentum",registerClass(MomentumOptimizer);class RMSPropOptimizer extends Optimizer{constructor(e,t=.9,n=0,r=null,a=!1){if(super(),this.learningRate=e,this.decay=t,this.momentum=n,this.epsilon=r,this.accumulatedMeanSquares=[],this.accumulatedMoments=[],this.accumulatedMeanGrads=[],this.centered=a,null==r&&(this.epsilon=ENGINE.backend.epsilon()),null==e)throw new Error("learningRate for RMSPropOptimizer must be defined.")}applyGradients(e){(Array.isArray(e)?e.map(e=>e.name):Object.keys(e)).forEach((t,n)=>{const r=ENGINE.registeredVariables[t],a=!1;null==this.accumulatedMeanSquares[n]&&(this.accumulatedMeanSquares[n]={originalName:`${t}/rms`,variable:tidy(()=>zerosLike$2(r).variable(a))}),null==this.accumulatedMoments[n]&&(this.accumulatedMoments[n]={originalName:`${t}/momentum`,variable:tidy(()=>zerosLike$2(r).variable(a))}),null==this.accumulatedMeanGrads[n]&&this.centered&&(this.accumulatedMeanGrads[n]={originalName:`${t}/mg`,variable:tidy(()=>zerosLike$2(r).variable(a))});const s=Array.isArray(e)?e[n].tensor:e[t];if(null==s)return;const o=this.accumulatedMeanSquares[n].variable,i=this.accumulatedMoments[n].variable;tidy(()=>{const e=add$2(mul(o,this.decay),mul(square$2(s),1-this.decay));if(this.centered){const t=this.accumulatedMeanGrads[n].variable,a=add$2(mul(t,this.decay),mul(s,1-this.decay)),l=div$1(mul(s,this.learningRate),sqrt$2(sub$2(e,add$2(square$2(a),this.epsilon)))),u=add$2(mul(i,this.momentum),l);o.assign(e),t.assign(a),i.assign(u);const c=sub$2(r,u);r.assign(c)}else{const e=add$2(mul(o,this.decay),mul(square$2(s),1-this.decay)),t=add$2(mul(i,this.momentum),div$1(mul(s,this.learningRate),sqrt$2(add$2(e,this.epsilon))));o.assign(e),i.assign(t);const n=sub$2(r,t);r.assign(n)}})}),this.incrementIterations()}dispose(){null!=this.accumulatedMeanSquares&&dispose(this.accumulatedMeanSquares.map(e=>e.variable)),null!=this.accumulatedMeanGrads&&this.centered&&dispose(this.accumulatedMeanGrads.map(e=>e.variable)),null!=this.accumulatedMoments&&dispose(this.accumulatedMoments.map(e=>e.variable))}async getWeights(){const e=[...this.accumulatedMeanSquares,...this.accumulatedMoments];return this.centered&&e.push(...this.accumulatedMeanGrads),[await this.saveIterations()].concat(e.map(e=>({name:e.originalName,tensor:e.variable})))}async setWeights(e){e=await this.extractIterations(e);const t=this.centered?e.length/3:e.length/2,n=!1;this.accumulatedMeanSquares=e.slice(0,t).map(e=>({originalName:e.name,variable:e.tensor.variable(n)})),this.accumulatedMoments=e.slice(t,2*t).map(e=>({originalName:e.name,variable:e.tensor.variable(n)})),this.centered&&(this.accumulatedMeanGrads=e.slice(2*t,3*t).map(e=>({originalName:e.name,variable:e.tensor.variable(n)})))}getConfig(){return{learningRate:this.learningRate,decay:this.decay,momentum:this.momentum,epsilon:this.epsilon,centered:this.centered}}static fromConfig(e,t){return new e(t.learningRate,t.decay,t.momentum,t.epsilon,t.centered)}}RMSPropOptimizer.className="RMSProp",registerClass(RMSPropOptimizer);class OptimizerConstructors{static sgd(e){return new SGDOptimizer(e)}static momentum(e,t,n=!1){return new MomentumOptimizer(e,t,n)}static rmsprop(e,t=.9,n=0,r=null,a=!1){return new RMSPropOptimizer(e,t,n,r,a)}static adam(e=.001,t=.9,n=.999,r=null){return new AdamOptimizer(e,t,n,r)}static adadelta(e=.001,t=.95,n=null){return new AdadeltaOptimizer(e,t,n)}static adamax(e=.002,t=.9,n=.999,r=null,a=0){return new AdamaxOptimizer(e,t,n,r,a)}static adagrad(e,t=.1){return new AdagradOptimizer(e,t)}}const train={sgd:OptimizerConstructors.sgd,momentum:OptimizerConstructors.momentum,adadelta:OptimizerConstructors.adadelta,adagrad:OptimizerConstructors.adagrad,rmsprop:OptimizerConstructors.rmsprop,adamax:OptimizerConstructors.adamax,adam:OptimizerConstructors.adam},delayCallback="undefined"!=typeof requestAnimationFrame?requestAnimationFrame:"undefined"!=typeof setImmediate?setImmediate:e=>e();function nextFrame(){return new Promise(e=>delayCallback(()=>e()))}function assertParamsConsistent(e,t){const n=e[0].length;e.forEach((e,t)=>{assert$4(e.length===n,()=>`Error in concat${n}D: rank of tensors[${t}] must be the same as the rank of the rest (${n})`)}),assert$4(t>=0&&t<n,()=>`Error in concat${n}D: axis must be between 0 and ${n-1}.`);const r=e[0];e.forEach((e,a)=>{for(let s=0;s<n;s++)assert$4(s===t||e[s]===r[s],()=>`Error in concat${n}D: Shape of tensors[${a}] (${e}) does not match the shape of the rest (${r}) along the non-concatenated axis ${a}.`)})}function computeOutShape$1(e,t){const n=e[0].slice();for(let r=1;r<e.length;r++)n[t]+=e[r][t];return n}const PARALLELIZE_THRESHOLD=30;function computeOptimalWindowSize(e){return e<=PARALLELIZE_THRESHOLD?e:nearestDivisor(e,Math.floor(Math.sqrt(e)))}function getImageCenter(e,t,n){return[n*("number"==typeof e?e:e[0]),t*("number"==typeof e?e:e[1])]}function getReshaped(e,t,n,r=!0){let a=[];if(r)a=a.concat(t.slice(0)),a.push(e[0]/n),a=a.concat(e.slice(1));else{a=a.concat(e[0]);const n=t.length;for(let r=0;r<n;++r)a=a.concat([e[r+1]/t[r],t[r]]);a=a.concat(e.slice(n+1))}return a}function getPermuted(e,t,n=!0){const r=[];if(n){r.push(t);for(let n=t+1;n<e;++n)n<=2*t?(r.push(n),r.push(n-(t+1))):r.push(n)}else{const n=[],a=[];for(let r=1;r<e;++r)r>=2*t+1||r%2==1?a.push(r):n.push(r);r.push(...n),r.push(0),r.push(...a)}return r}function getReshapedPermuted(e,t,n,r=!0){const a=[];a.push(r?e[0]/n:e[0]*n);for(let n=1;n<e.length;++n)a.push(n<=t.length?r?t[n-1]*e[n]:e[n]/t[n-1]:e[n]);return a}function getSliceBeginCoords(e,t){const n=[0];for(let r=0;r<t;++r)n.push(e[r][0]);return n}function getSliceSize(e,t,n){const r=e.slice(0,1);for(let a=0;a<n;++a)r.push(e[a+1]-t[a][0]-t[a][1]);return r}const SELU_SCALEALPHA=1.7580993408473768,SELU_SCALE=1.0507009873554805,ERF_P=.3275911,ERF_A1=.254829592,ERF_A2=-.284496736,ERF_A3=1.421413741,ERF_A4=-1.453152027,ERF_A5=1.061405429;function warn(...e){env().getBool("IS_TEST")||console.warn(...e)}function log$2(...e){env().getBool("IS_TEST")||console.log(...e)}function mergeRealAndImagArrays(e,t){if(e.length!==t.length)throw new Error(`Cannot merge real and imag arrays of different lengths. real:${e.length}, imag: ${t.length}.`);const n=new Float32Array(2*e.length);for(let r=0;r<n.length;r+=2)n[r]=e[r/2],n[r+1]=t[r/2];return n}function splitRealAndImagArrays(e){const t=new Float32Array(e.length/2),n=new Float32Array(e.length/2);for(let r=0;r<e.length;r+=2)t[r/2]=e[r],n[r/2]=e[r+1];return{real:t,imag:n}}function complexWithEvenIndex(e){const t=Math.ceil(e.length/4),n=new Float32Array(t),r=new Float32Array(t);for(let t=0;t<e.length;t+=4)n[Math.floor(t/4)]=e[t],r[Math.floor(t/4)]=e[t+1];return{real:n,imag:r}}function complexWithOddIndex(e){const t=Math.floor(e.length/4),n=new Float32Array(t),r=new Float32Array(t);for(let t=2;t<e.length;t+=4)n[Math.floor(t/4)]=e[t],r[Math.floor(t/4)]=e[t+1];return{real:n,imag:r}}function getComplexWithIndex(e,t){return{real:e[2*t],imag:e[2*t+1]}}function assignToTypedArray(e,t,n,r){e[2*r]=t,e[2*r+1]=n}function exponents(e,t){const n=new Float32Array(e/2),r=new Float32Array(e/2);for(let a=0;a<Math.ceil(e/2);a++){const s=(t?2:-2)*Math.PI*(a/e);n[a]=Math.cos(s),r[a]=Math.sin(s)}return{real:n,imag:r}}function exponent(e,t,n){const r=(n?2:-2)*Math.PI*(e/t);return{real:Math.cos(r),imag:Math.sin(r)}}const ARROW="->",ARROW_REGEX=/->/g,COMMA=",",ELLIPSIS="...";function decodeEinsumEquation(e,t){const n=((e=e.replace(/\s/g,"")).length-e.replace(ARROW_REGEX,"").length)/ARROW.length;if(n<1)throw new Error("Equations without an arrow are not supported.");if(n>1)throw new Error(`Equation must contain exactly one arrow ("${ARROW}").`);const[r,a]=e.split(ARROW);assert$4(-1===r.indexOf(ELLIPSIS),()=>`The ellipsis notation ("${ELLIPSIS}") is not supported yet.`);const s=r.split(COMMA),o=s.length;if(t!==o)throw new Error(`Expected ${o} input tensors, received ${t}`);if(o>2)throw new Error("Support for more than 2 input tensors is not implemented yet.");const i=[];for(let e=0;e<a.length;++e){const t=a[e];if(!s.some(e=>-1!==e.indexOf(t)))throw new Error(`Output subscripts contain the label ${t} not present in the input subscripts.`);-1===i.indexOf(t)&&i.push(t)}for(let e=0;e<r.length;++e){const t=r[e];-1===i.indexOf(t)&&t!==COMMA&&i.push(t)}const l=new Array(s.length);for(let e=0;e<o;++e){if(new Set(s[e].split("")).size!==s[e].length)throw new Error(`Found duplicate axes in input component ${s[e]}. Support for duplicate axes in input is not implemented yet.`);l[e]=[];for(let t=0;t<s[e].length;++t)l[e].push(i.indexOf(s[e][t]))}const u=i.length,c=[];for(let e=a.length;e<u;++e)c.push(e);return{allDims:i,summedDims:c,idDims:l}}function getEinsumPermutation(e,t){let n=new Array(e);n.fill(-1);for(let e=0;e<t.length;++e)n[t[e]]=e;const r=[];for(let t=0;t<e;++t)-1===n[t]&&r.push(t);return n=n.filter(e=>-1!==e),{permutationIndices:n,expandDims:r}}function checkEinsumDimSizes(e,t,n){const r=new Array(e);for(let e=0;e<n.length;++e){const a=n[e].shape;for(let n=0;n<t[e].length;++n)void 0===r[t[e][n]]?r[t[e][n]]=a[n]:assert$4(r[t[e][n]]===a[n],()=>`Expected dimension ${r[t[e][n]]} at axis ${n} of input shaped ${JSON.stringify(a)}, but got dimension ${a[n]}`)}}function getEinsumComputePath(e,t){const n=e,r=[];let a=0;0===e.length&&n.push(-1),a=e.length+1;for(let e=0;e<a;++e)r.push([]);const s=[];for(let e=0;e<n.length;++e){const a=findTermsWithDim(t,n[e]);for(const t of a)-1===s.indexOf(t)&&(r[e].push(t),s.push(t))}return{path:n,steps:r}}function isIdentityPermutation(e){return e.every((e,t)=>e===t)}function findTermsWithDim(e,t){const n=[];for(let r=0;r<e.length;++r)0!==e[r].length&&-1===e[r].indexOf(t)&&-1!==t||n.push(r);return n}function prepareSplitSize(e,t,n=0){let r=[];if("number"==typeof t)assert$4(e.shape[n]%t==0,()=>"Number of splits must evenly divide the axis."),r=new Array(t).fill(e.shape[n]/t);else{assert$4(t.reduce((e,t)=>(-1===t&&(e+=1),e),0)<=1,()=>"There should be only one negative value in split array.");const a=t.indexOf(-1);if(-1!==a){const r=t.reduce((e,t)=>t>0?e+t:e);t[a]=e.shape[n]-r}assert$4(e.shape[n]===t.reduce((e,t)=>e+t),()=>"The sum of sizes must match the size of the axis dimension."),r=t}return r}function segOpComputeOptimalWindowSize(e,t){let n,r=!1;for(e<=PARALLELIZE_THRESHOLD?(n=e,r=!0):n=nearestDivisor(e,Math.floor(Math.sqrt(e)));!r;)n>t||n===e?r=!0:n=nearestDivisor(e,n+1);return n}function computeOutShape(e,t,n){const r=[],a=e.length;for(let s=0;s<a;s++)r.push(s!==t?e[s]:n);return r}function collectGatherOpShapeInfo(e,t,n,r){const a=t.shape.length,s=e.shape.length;if(0!==r&&(r<-a||r>a))throw new Error(`Expect batchDims in the range of [-${a}, ${a}], but got ${r}`);if(r<0&&(r+=a),r>s)throw new Error(`batchDims (${r}) must be less than rank(x) (\n    ${s}).`);if(n<r)throw new Error(`batchDims (${r}) must be less than or equal to axis (${n}).`);for(let n=0;n<r;++n)if(e.shape[n]!==t.shape[n])throw new Error(`x.shape[${n}]: ${e.shape[n]} should be equal to indices.shape[${n}]: ${t.shape[n]}.`);const o=e.shape[n],i=[];let l=1,u=1,c=1;for(let t=0;t<r;++t)i.push(e.shape[t]),l*=e.shape[t];for(let t=r;t<n;t++)i.push(e.shape[t]),u*=e.shape[t];for(let e=r;e<a;e++)i.push(t.shape[e]);for(let t=n+1;t<s;t++)i.push(e.shape[t]),c*=e.shape[t];return{batchSize:l,sliceSize:c,outerSize:u,dimSize:o,outputShape:i}}var segment_util={__proto__:null,segOpComputeOptimalWindowSize,computeOutShape,collectGatherOpShapeInfo};function fromUint8ToStringArray(e){try{return e.map(e=>decodeString(e))}catch(e){throw new Error(`Failed to decode encoded string bytes into utf-8, error: ${e}`)}}function fromStringArrayToUint8(e){return e.map(e=>encodeString(e))}var backend_util={__proto__:null,slice_util,segment_util,fromUint8ToStringArray,fromStringArrayToUint8,upcastType,axesAreInnerMostDims,combineLocations,computeOutAndReduceShapes,expandShapeToKeepDim,assertAxesAreInnerMostDims,getAxesPermutation,getUndoAxesPermutation,getInnerMostAxes,getBroadcastDims:getBroadcastDims$1,getReductionAxes,assertAndGetBroadcastShape,assertParamsConsistent,computeOutShape:computeOutShape$1,computeDilation2DInfo,computePool2DInfo,computePool3DInfo,computeConv2DInfo,computeConv3DInfo,computeDefaultPad,tupleValuesAreOne,eitherStridesOrDilationsAreOne,convertConv2DDataFormat,getFusedDyActivation,getFusedBiasGradient,applyActivation:applyActivation$1,shouldFuse,PARALLELIZE_THRESHOLD,computeOptimalWindowSize,getImageCenter,getReshaped,getPermuted,getReshapedPermuted,getSliceBeginCoords,getSliceSize,prepareAndValidate,validateUpdateShape,validateInput:validateInput$1,calculateShapes,SELU_SCALEALPHA,SELU_SCALE,ERF_P,ERF_A1,ERF_A2,ERF_A3,ERF_A4,ERF_A5,warn,log:log$2,mergeRealAndImagArrays,splitRealAndImagArrays,complexWithEvenIndex,complexWithOddIndex,getComplexWithIndex,assignToTypedArray,exponents,exponent,decodeEinsumEquation,getEinsumPermutation,checkEinsumDimSizes,getEinsumComputePath,isIdentityPermutation,prepareSplitSize},kernel_impls={__proto__:null,nonMaxSuppressionV3Impl:nonMaxSuppressionV3Impl$2,nonMaxSuppressionV4Impl:nonMaxSuppressionV4Impl$2,nonMaxSuppressionV5Impl:nonMaxSuppressionV5Impl$2,whereImpl:whereImpl$2};const absGradConfig={kernelName:Abs,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>mul(e,step$2(cast$3(n,"float32"),-1))}}},acosGradConfig={kernelName:Acos,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>{const t=square$2(cast$3(n,"float32")),r=sqrt$2(sub$2(scalar(1),t));return neg$2(div$1(e,r))}}}},acoshGradConfig={kernelName:Acosh,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>{const t=sqrt$2(sub$2(square$2(cast$3(n,"float32")),1));return div$1(e,t)}}}},addGradConfig={kernelName:Add$1,inputsToSave:["a","b"],gradFunc:(e,t)=>{const[n,r]=t,a=assertAndGetBroadcastShape(n.shape,r.shape);return{a:()=>{let t=e;const r=getReductionAxes(n.shape,a);return r.length>0&&(t=sum$2(t,r)),reshape$3(t,n.shape)},b:()=>{let t=e;const n=getReductionAxes(r.shape,a);return n.length>0&&(t=sum$2(t,n)),reshape$3(t,r.shape)}}}},addNGradConfig={kernelName:AddN,saveAllInputs:!0,gradFunc:(e,t)=>{const n={};return t.forEach((t,r)=>{n[r]=()=>e.clone()}),n}},argMaxGradConfig={kernelName:ArgMax,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>zerosLike$2(n)}}},argMinGradConfig={kernelName:ArgMin,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>zerosLike$2(n)}}},asinGradConfig={kernelName:Asin,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>div$1(e,sqrt$2(sub$2(scalar(1),square$2(cast$3(n,"float32")))))}}},asinhGradConfig={kernelName:Asinh,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>{const t=sqrt$2(add$2(scalar(1),square$2(cast$3(n,"float32"))));return div$1(e,t)}}}},atan2GradConfig={kernelName:Atan2,inputsToSave:["a","b"],gradFunc:(e,t)=>{const[n,r]=t,a=assertAndGetBroadcastShape(n.shape,r.shape);return{a:()=>{const t=add$2(square$2(n),square$2(r));let s=mul(e,div$1(r,t));const o=getReductionAxes(n.shape,a);return o.length>0&&(s=sum$2(s,o)),reshape$3(s,n.shape)},b:()=>{const t=add$2(square$2(n),square$2(r));let s=neg$2(mul(e,div$1(n,t)));const o=getReductionAxes(r.shape,a);return o.length>0&&(s=sum$2(s,o)),reshape$3(s,r.shape)}}}},atanGradConfig={kernelName:Atan,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>div$1(e,add$2(square$2(cast$3(n,"float32")),1))}}},atanhGradConfig={kernelName:Atanh,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>div$1(e,sub$2(scalar(1),square$2(cast$3(n,"float32"))))}}};function avgPool3dGrad_(e,t,n,r,a,s){const o=convertToTensor(e,"dy","avgPool3dGrad"),i=convertToTensor(t,"input","avgPool3dGrad");let l=o,u=i,c=!1;4===i.rank&&(c=!0,l=reshape$3(o,[1,o.shape[0],o.shape[1],o.shape[2],o.shape[3]]),u=reshape$3(i,[1,i.shape[0],i.shape[1],i.shape[2],i.shape[3]])),assert$4(5===l.rank,()=>`Error in avgPool3dGrad: dy must be rank 5 but got rank ${l.rank}.`),assert$4(5===u.rank,()=>`Error in avgPool3dGrad: input must be rank 5 but got rank ${u.rank}.`),null!=s&&assert$4(isInt(a),()=>`Error in avgPool3dGrad: pad must be an integer when using, dimRoundingMode ${s} but got pad ${a}.`);const p=ENGINE.runKernel(AvgPool3DGrad,{dy:l,input:u},{filterSize:n,strides:r,pad:a,dimRoundingMode:s});return c?reshape$3(p,[p.shape[1],p.shape[2],p.shape[3],p.shape[4]]):p}const avgPool3dGrad=op({avgPool3dGrad_}),avgPool3DGradConfig$1={kernelName:AvgPool3D,inputsToSave:["x"],gradFunc:(e,t,n)=>{const[r]=t,{filterSize:a,strides:s,pad:o,dimRoundingMode:i}=n;return{x:()=>avgPool3dGrad(e,r,a,s,o,i)}}};function avgPoolGrad_(e,t,n,r,a){const s=convertToTensor(e,"dy","avgPoolGrad"),o=convertToTensor(t,"input","avgPoolGrad");assert$4(o.rank===s.rank,()=>`Rank of input (${o.rank}) does not match rank of dy (${s.rank})`);let i=o,l=s,u=!1;3===o.rank&&(u=!0,i=reshape$3(o,[1,o.shape[0],o.shape[1],o.shape[2]]),l=reshape$3(s,[1,s.shape[0],s.shape[1],s.shape[2]])),assert$4(4===l.rank,()=>`Error in avgPoolGrad: dy must be rank 4 but got rank ${l.rank}.`),assert$4(4===i.rank,()=>`Error in avgPoolGrad: input must be rank 4 but got rank ${i.rank}.`);const c=ENGINE.runKernel(AvgPoolGrad,{dy:l,input:i},{filterSize:n,strides:r,pad:a});return u?reshape$3(c,[c.shape[1],c.shape[2],c.shape[3]]):c}const avgPoolGrad$2=op({avgPoolGrad_}),avgPoolGradConfig$2={kernelName:AvgPool,inputsToSave:["x"],gradFunc:(e,t,n)=>{const[r]=t,{filterSize:a,strides:s,pad:o}=n;return{x:()=>avgPoolGrad$2(e,r,a,s,o)}}},batchMatMulGradConfig={kernelName:BatchMatMul,inputsToSave:["a","b"],gradFunc:(e,t,n)=>{const[r,a]=t,{transposeA:s,transposeB:o}=n;return s||o?!s&&o?{a:()=>matMul$1(e,a,!1,!1),b:()=>matMul$1(e,r,!0,!1)}:s&&!o?{a:()=>matMul$1(a,e,!1,!0),b:()=>matMul$1(r,e,!1,!1)}:{a:()=>matMul$1(a,e,!0,!0),b:()=>matMul$1(e,r,!0,!0)}:{a:()=>matMul$1(e,a,!1,!0),b:()=>matMul$1(r,e,!0,!1)}}},batchToSpaceNDGradConfig={kernelName:BatchToSpaceND,gradFunc:(e,t,n)=>{const{blockShape:r,crops:a}=n;return{x:()=>spaceToBatchND$2(e,r,a)}}},broadcastToGradConfig={kernelName:BroadcastTo,gradFunc:(e,t,n)=>{const r=n.inputShape,a=n.shape,s=Array.from(a);for(let e=r.length-1;e>=0;e--)if(r[e]===a[e])s[e]=1;else if(1!==r[e])throw new Error(`broadcastTo(): [${r}] cannot be broadcast to [${a}].`);const o=[];for(let e=0;e<s.length;e++)s[e]>1&&o.push(e);return{x:()=>sum$2(e,o,!0)}}},castGradConfig={kernelName:Cast,gradFunc:e=>({x:()=>e.clone()})},ceilGradConfig={kernelName:Ceil,gradFunc:e=>({x:()=>zerosLike$2(e)})},clipByValueGradConfig={kernelName:ClipByValue,inputsToSave:["x"],gradFunc:(e,t,n)=>{const[r]=t,{clipValueMin:a,clipValueMax:s}=n;return{x:()=>where(logicalAnd$2(greaterEqual$2(r,a),lessEqual$2(r,s)),e,zerosLike$2(e))}}},complexAbsGradConfig={kernelName:ComplexAbs,inputsToSave:["x"],gradFunc:absGradConfig.gradFunc},concatGradConfig={kernelName:Concat,saveAllInputs:!0,gradFunc:(e,t,n)=>{const r=t.map(e=>e.shape),{axis:a}=n,s=parseAxisParam(a,t[0].shape)[0],o=r.map(e=>e[s]);return split$2(e,o,s).map(e=>()=>e)}},conv2DGradConfig={kernelName:Conv2D$1,inputsToSave:["x","filter"],gradFunc:(e,t,n)=>{const[r,a]=t,{dilations:s,strides:o,pad:i,dataFormat:l}=n;return assert$4(tupleValuesAreOne(s),()=>`Error in gradient of conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${s}'`),{x:()=>conv2DBackpropInput$2(r.shape,e,a,o,i,l),filter:()=>conv2DBackpropFilter$2(r,e,a.shape,o,i,l)}}},conv2DBackpropInputGradConfig={kernelName:Conv2DBackpropInput,inputsToSave:["dy","filter"],gradFunc:(e,t,n)=>{const[r,a]=t,{strides:s,pad:o,dataFormat:i,dimRoundingMode:l}=n;return{dy:()=>conv2d$3(e,a,s,o,i,1,l),filter:()=>conv2DBackpropFilter$2(e,r,a.shape,s,o,i,l)}}};function conv3DBackpropFilter_(e,t,n,r,a){let s=e;4===e.rank&&(s=reshape$3(e,[1,e.shape[0],e.shape[1],e.shape[2],e.shape[3]]));let o=t;return 4===o.rank&&(o=reshape$3(t,[1,t.shape[0],t.shape[1],t.shape[2],t.shape[3]])),assert$4(5===s.rank,()=>`Error in conv3dDerFilter: input must be rank 5, but got shape ${s.shape}.`),assert$4(5===o.rank,()=>`Error in conv3dDerFilter: dy must be rank 5, but got shape ${o.shape}.`),assert$4(5===n.length,()=>`Error in conv3dDerFilter: filterShape must be length 5, but got ${n}.`),assert$4(s.shape[4]===n[3],()=>`Error in conv3dDerFilter: depth of input ${s.shape[4]}) must match input depth in filter (${n[3]}.`),assert$4(o.shape[4]===n[4],()=>`Error in conv3dDerFilter: depth of dy (${o.shape[4]}) must match output depth for filter (${n[4]}).`),ENGINE.runKernel(Conv3DBackpropFilterV2,{x:s,dy:o},{strides:r,pad:a,filterShape:n})}const conv3DBackpropFilter=op({conv3DBackpropFilter_}),conv3DGradConfig={kernelName:Conv3D$1,inputsToSave:["x","filter"],gradFunc:(e,t,n)=>{const{dilations:r,strides:a,pad:s}=n;assert$4(tupleValuesAreOne(r),()=>`Error in gradient of conv3D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '${r}'`);const[o,i]=t;return{x:()=>conv3DBackpropInput$1(o.shape,e,i,a,s),filter:()=>conv3DBackpropFilter(o,e,i.shape,a,s)}}},cosGradConfig={kernelName:Cos,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>mul(neg$2(sin$2(cast$3(n,"float32"))),e)}}},coshGradConfig={kernelName:Cosh,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>mul(sinh$2(cast$3(n,"float32")),e)}}},cumsumGradConfig={kernelName:Cumsum,inputsToSave:["x"],gradFunc:(e,t,n)=>{const[r]=t,{axis:a,exclusive:s,reverse:o}=n;return{x:()=>{const t=getAxesPermutation([a],r.rank);let n=cumsum$2(e,a,s,!o);return null!=t&&(n=transpose$2(n,t)),n}}}},depthwiseConv2dNativeGradConfig={kernelName:DepthwiseConv2dNative,inputsToSave:["x","filter"],gradFunc:(e,t,n)=>{const{dilations:r,strides:a,pad:s,dimRoundingMode:o}=n,i=null==r?[1,1]:r;assert$4(tupleValuesAreOne(i),()=>`Error in gradient of depthwiseConv2dNative: dilation rates greater than 1 are not yet supported. Got dilations '${i}'`);const[l,u]=t;return assert$4(4===l.rank,()=>`Error in gradient of depthwiseConv2dNative: input must be rank 4, but got rank ${l.rank}.`),assert$4(4===u.rank,()=>`Error in gradient of depthwiseConv2dNative: filter must be rank 4, but got rank ${u.rank}.`),assert$4(l.shape[3]===u.shape[2],()=>`Error in gradient of depthwiseConv2d: number of input channels (${l.shape[3]}) must match the inChannels dimension in filter ${u.shape[2]}.`),assert$4(eitherStridesOrDilationsAreOne(a,i),()=>`Error in gradient of depthwiseConv2d: Either strides or dilations must be  1. Got strides ${a} and dilations '${i}'.`),null!=o&&assert$4(isInt(s),()=>`Error in depthwiseConv2d: pad must be an integer when using, dimRoundingMode ${o} but got pad ${s}.`),{x:()=>depthwiseConv2dNativeBackpropInput$2(l.shape,e,u,a,s,r,o),filter:()=>depthwiseConv2dNativeBackpropFilter$2(l,e,u.shape,a,s,r,o)}}},dilation2dGradConfig={kernelName:Dilation2D,inputsToSave:["x","filter"],gradFunc:(e,t,n)=>{const[r,a]=t,s={x:r,filter:a,dy:e},o={x:r,filter:a,dy:e};return{x:()=>ENGINE.runKernel(Dilation2DBackpropInput,s,n),filter:()=>ENGINE.runKernel(Dilation2DBackpropFilter,o,n)}}},eluGradConfig$2={kernelName:Elu$1,outputsToSave:[!0],gradFunc:(e,t)=>{const[n]=t,r={dy:e,y:n};return{x:()=>ENGINE.runKernel(EluGrad,r)}}},erfGradConfig={kernelName:Erf,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t,r=mul(exp$2(neg$2(square$2(n))),2/Math.sqrt(Math.PI));return{x:()=>mul(e,r)}}},expGradConfig={kernelName:Exp,outputsToSave:[!0],gradFunc:(e,t)=>{const[n]=t;return{x:()=>mul(e,n)}}},expandDimsGradConfig={kernelName:ExpandDims,inputsToSave:["input"],gradFunc:(e,t)=>{const[n]=t;return{input:()=>reshape$3(e,n.shape)}}},expm1GradConfig={kernelName:Expm1,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>mul(e,exp$2(n))}}},floorGradConfig={kernelName:Floor,gradFunc:e=>({x:()=>zerosLike$2(e)})},floorDivGradConfig={kernelName:FloorDiv,inputsToSave:["a","b"],gradFunc:(e,t)=>{const[n,r]=t,a=assertAndGetBroadcastShape(n.shape,r.shape);return{a:()=>{const t=div$1(e,cast$3(r,"float32")),s=getReductionAxes(n.shape,a);return s.length>0?reshape$3(sum$2(t,s),n.shape):t},b:()=>{let t=mul(e,cast$3(n,"float32"));const s=getReductionAxes(r.shape,a);s.length>0&&(t=reshape$3(sum$2(t,s),r.shape));const o=square$2(r);return neg$2(div$1(t,cast$3(o,"float32")))}}}},fusedBatchNormGradConfig={kernelName:FusedBatchNorm,inputsToSave:["x","mean","variance","scale"],gradFunc:(e,t,n)=>{const{varianceEpsilon:r}=n,[a,s,o,i]=t,l=null==i?scalar(1):i,u=getReductionAxes(s.shape,a.shape),c=[];if(1===s.rank){for(let e=0;e<a.shape.length-1;++e)c.push(a.shape[e]);c.push(1)}const p=sub$2(a,s),d=mul(e,l),h=rsqrt$2(add$2(o,scalar(r))),m=mul(mul(mul(h,h),h),scalar(-.5));return{x:()=>reshape$3(mul(mul(e,1===s.rank?tile$3(reshape$3(h,[1,1,1,s.shape[0]]),c):h),l),a.shape),mean:()=>{let e=mul(mul(h,scalar(-1)),d);return 1===s.rank&&(e=sum$2(e,u)),reshape$3(e,s.shape)},variance:()=>{let e=mul(mul(m,p),d);return 1===s.rank&&(e=sum$2(e,u)),reshape$3(e,s.shape)},scale:()=>{const t=mul(p,h);let n=mul(e,t);return 1===s.rank&&(n=sum$2(n,u)),reshape$3(n,s.shape)},offset:()=>{let t=e;return 1===s.rank&&(t=sum$2(t,u)),reshape$3(t,s.shape)}}}},gatherGradConfig={kernelName:GatherV2,inputsToSave:["x","indices"],gradFunc:(e,t,n)=>{const[r,a]=t,{axis:s}=n,o=parseAxisParam(s,r.shape)[0];return{x:()=>{const t=r.shape,n=a.size,i=t.slice(0,o),l=i.length,u=t.slice(s,t.length).slice(1),c=u.length,p=arrayRange(0,l),d=arrayRange(l+1,l+1+c),h=arrayConcat([i,[n],u]),m=reshape$3(e,h),f=reshape$3(a,[n]),g=arrayConcat([[l],p,d]),$=transpose$2(m,g);let y=unsortedSegmentSum$2($,f,r.shape[o]);const b=getUndoAxesPermutation(g);return y=transpose$2(y,b),y},indices:()=>a}}};function arrayRange(e,t){const n=[];for(let r=e;r<t;++r)n.push(r);return n}function arrayConcat(e){const t=[];for(let n=0;n<e.length;++n)for(let r=0;r<e[n].length;++r)t.push(e[n][r]);return t}const greaterEqualGradConfig={kernelName:GreaterEqual,inputsToSave:["a","b"],gradFunc:(e,t)=>{const[n,r]=t;return{a:()=>zerosLike$2(n),b:()=>zerosLike$2(r)}}},identityGradConfig={kernelName:Identity$1,gradFunc:e=>({x:()=>cast$3(e,"float32")})},isFiniteGradConfig={kernelName:IsFinite,gradFunc:e=>({x:()=>zerosLike$2(e)})},isInfGradConfig={kernelName:IsInf,gradFunc:e=>({x:()=>zerosLike$2(e)})},isNanGradConfig={kernelName:IsNan,gradFunc:e=>({x:()=>zerosLike$2(e)})},leakyReluGradConfig={kernelName:LeakyRelu,inputsToSave:["x"],gradFunc:(e,t,n)=>{const[r]=t,{alpha:a}=n,s=greater$3(r,0);return{x:()=>where(s,e,mul(e,a))}}},log1pGradConfig={kernelName:Log1p,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>div$1(e,add$2(n,1))}}},logGradConfig={kernelName:Log,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>div$1(e,cast$3(n,"float32"))}}},logSoftmaxGradConfig={kernelName:LogSoftmax$1,inputsToSave:[],outputsToSave:[!0],gradFunc:(e,t,n)=>{const[r]=t,{axis:a}=n;return{logits:()=>{const t=exp$2(r);return sub$2(e,mul(sum$2(e,a,!0),t))}}}};function localResponseNormalizationBackprop_(e,t,n,r=5,a=1,s=1,o=.5){return ENGINE.runKernel(LRNGrad,{x:e,y:t,dy:n},{depthRadius:r,bias:a,alpha:s,beta:o})}const localResponseNormalizationBackprop=op({localResponseNormalizationBackprop_}),lrnGradConfig={kernelName:LRN,inputsToSave:["x"],outputsToSave:[!0],gradFunc:(e,t,n)=>{const[r,a]=t,{depthRadius:s,bias:o,alpha:i,beta:l}=n;return{x:()=>localResponseNormalizationBackprop(r,a,e,s,o,i,l)}}};function gradForMinAndMax(e,t,n,r){return t.rank<n.rank&&(t=reshape$3(t,expandShapeToKeepDim(t.shape,r))),e.rank<n.rank&&(e=reshape$3(e,expandShapeToKeepDim(e.shape,r))),{x:()=>mul(e,cast$3(equal$2(n,t),e.dtype))}}const maxGradConfig={kernelName:Max,inputsToSave:["x"],outputsToSave:[!0],gradFunc:(e,t,n)=>{const r=n,{reductionIndices:a}=r,s=t[0],o=gradForMinAndMax(e,t[1],s,parseAxisParam(a,s.shape));return{x:()=>o.x()}}},maximumGradConfig={kernelName:Maximum$1,inputsToSave:["a","b"],gradFunc:(e,t)=>{const[n,r]=t;return{a:()=>mul(e,cast$3(greaterEqual$2(n,r),"float32")),b:()=>mul(e,cast$3(less$3(n,r),"float32"))}}};function maxPool3dGrad_(e,t,n,r,a,s,o){const i=convertToTensor(e,"dy","maxPool3dGrad"),l=convertToTensor(t,"input","maxPool3dGrad"),u=convertToTensor(n,"output","maxPool3dGrad");let c=i,p=l,d=u,h=!1;4===l.rank&&(h=!0,c=reshape$3(i,[1,i.shape[0],i.shape[1],i.shape[2],i.shape[3]]),p=reshape$3(l,[1,l.shape[0],l.shape[1],l.shape[2],l.shape[3]]),d=reshape$3(u,[1,u.shape[0],u.shape[1],u.shape[2],u.shape[3]])),assert$4(5===c.rank,()=>`Error in maxPool3dGrad: dy must be rank 5 but got rank ${c.rank}.`),assert$4(5===p.rank,()=>`Error in maxPool3dGrad: input must be rank 5 but got rank ${p.rank}.`),assert$4(5===d.rank,()=>`Error in maxPool3dGrad: output must be rank 5 but got rank ${d.rank}.`),null!=o&&assert$4(isInt(s),()=>`Error in maxPool3dGrad: pad must be an integer when using, dimRoundingMode ${o} but got pad ${s}.`);const m=ENGINE.runKernel(MaxPool3DGrad,{dy:c,input:p,output:d},{filterSize:r,strides:a,pad:s,dimRoundingMode:o});return h?reshape$3(m,[m.shape[1],m.shape[2],m.shape[3],m.shape[4]]):m}const maxPool3dGrad=op({maxPool3dGrad_}),maxPool3DGradConfig$1={kernelName:MaxPool3D,inputsToSave:["x"],outputsToSave:[!0],gradFunc:(e,t,n)=>{const[r,a]=t,{filterSize:s,strides:o,pad:i,dimRoundingMode:l}=n;return{x:()=>maxPool3dGrad(e,r,a,s,o,i,l)}}};function maxPoolGrad_(e,t,n,r,a,s,o){const i=convertToTensor(e,"dy","maxPoolGrad"),l=convertToTensor(t,"input","maxPoolGrad"),u=convertToTensor(n,"output","maxPoolGrad");return assert$4(l.rank===i.rank,()=>`Rank of input (${l.rank}) does not match rank of dy (${i.rank})`),assert$4(4===i.rank,()=>`Error in maxPoolGrad: dy must be rank 4 but got rank ${i.rank}.`),assert$4(4===l.rank,()=>`Error in maxPoolGrad: input must be rank 4 but got rank ${l.rank}.`),null!=o&&assert$4(isInt(s),()=>`Error in maxPoolGrad: pad must be an integer when using, dimRoundingMode ${o} but got pad ${s}.`),ENGINE.runKernel(MaxPoolGrad,{dy:i,input:l,output:u},{filterSize:r,strides:a,pad:s,dimRoundingMode:o})}const maxPoolGrad$2=op({maxPoolGrad_}),maxPoolGradConfig$2={kernelName:MaxPool,inputsToSave:["x"],outputsToSave:[!0],gradFunc:(e,t,n)=>{const[r,a]=t,{filterSize:s,strides:o,pad:i}=n;return{x:()=>maxPoolGrad$2(e,r,a,s,o,i)}}},meanGradConfig={kernelName:Mean,inputsToSave:["x"],gradFunc:(e,t,n)=>{const[r]=t,{axis:a}=n,s=parseAxisParam(a,r.shape),o=sizeFromShape(computeOutAndReduceShapes(r.shape,s)[1]);return{x:()=>{const t=r.shape.slice();s.forEach(e=>{t[e]=1});const n=reshape$3(e,t);return div$1(mul(n,ones$1(r.shape,"float32")),o)}}}},minGradConfig={kernelName:Min,inputsToSave:["x"],outputsToSave:[!0],gradFunc:(e,t,n)=>{const r=n,{axis:a}=r,[s,o]=t,i=gradForMinAndMax(e,o,s,parseAxisParam(a,s.shape));return{x:()=>i.x()}}},minimumGradConfig={kernelName:Minimum$1,inputsToSave:["a","b"],gradFunc:(e,t)=>{const[n,r]=t;return{a:()=>mul(e,cast$3(lessEqual$2(n,r),"float32")),b:()=>mul(e,cast$3(greater$3(n,r),"float32"))}}},mirrorPadGradConfig={kernelName:MirrorPad,inputsToSave:["x"],gradFunc:(e,t,n)=>{const r=t[0],{paddings:a}=n,s=a.map(e=>e[0]);return{x:()=>slice$2(e,s,r.shape)}}},modGradConfig={kernelName:Mod,inputsToSave:["a","b"],gradFunc:(e,t)=>{const[n,r]=t,a=assertAndGetBroadcastShape(n.shape,r.shape);return{a:()=>{const t=getReductionAxes(n.shape,a);return t.length>0?reshape$3(sum$2(e,t),n.shape):e},b:()=>{const t=mul(e,neg$2(floor$2(div$1(n,r)))),s=getReductionAxes(r.shape,a);return s.length>0?reshape$3(sum$2(t,s),r.shape):t}}}},multiplyGradConfig={kernelName:Multiply$1,inputsToSave:["a","b"],gradFunc:(e,t)=>{const[n,r]=t,a=assertAndGetBroadcastShape(n.shape,r.shape);return{a:()=>{const t=mul(e,cast$3(r,"float32")),s=getReductionAxes(n.shape,a);return s.length>0?reshape$3(sum$2(t,s),n.shape):t},b:()=>{const t=mul(e,cast$3(n,"float32")),s=getReductionAxes(r.shape,a);return s.length>0?reshape$3(sum$2(t,s),r.shape):t}}}},negGradConfig={kernelName:Neg,gradFunc:e=>({x:()=>neg$2(e)})},oneHotGradConfig={kernelName:OneHot,inputsToSave:["indices"],gradFunc:(e,t)=>{const n=t[0];return{indices:()=>zeros$2(n.shape,"float32")}}},onesLikeGradConfig={kernelName:OnesLike,gradFunc:e=>({x:()=>zerosLike$2(e)})},packGradConfig={kernelName:Pack,saveAllInputs:!0,gradFunc:(e,t,n)=>{const{axis:r}=n;return unstack(e,r).map(e=>()=>e)}},padV2GradConfig={kernelName:PadV2,inputsToSave:["x"],gradFunc:(e,t,n)=>{const r=t[0],{paddings:a}=n,s=a.map(e=>e[0]);return{x:()=>slice$2(e,s,r.shape)}}},powGradConfig={kernelName:Pow,inputsToSave:["a","b"],outputsToSave:[!0],gradFunc:(e,t)=>{const[n,r,a]=t,s=n,o=r,i=assertAndGetBroadcastShape(s.shape,o.shape);return{a:()=>{const t=cast$3(o,"float32");let n=mul(e,mul(t,pow$2(s,sub$2(t,scalar(1)))));const r=getReductionAxes(s.shape,i);return r.length>0&&(n=sum$2(n,r)),reshape$3(n,s.shape)},b:()=>{const t=greater$3(s,0),n=where(t,log$3(s),zerosLike$2(s));let r=mul(e,mul(a,n));const l=getReductionAxes(o.shape,i);return l.length>0&&(r=sum$2(r,l)),reshape$3(r,o.shape)}}}},preluGradConfig={kernelName:Prelu,inputsToSave:["x","alpha"],gradFunc:(e,t)=>{const[n,r]=t,a=greater$3(n,0);return{x:()=>where(a,e,mul(e,r)),alpha:()=>{let t=where(a,zerosLike$2(e),mul(e,n));const s=getReductionAxes(r.shape,e.shape);return s.length>0&&(t=sum$2(t,s)),reshape$3(t,r.shape)}}}},divGradConfig={kernelName:RealDiv,inputsToSave:["a","b"],gradFunc:(e,t)=>{const[n,r]=t,a=assertAndGetBroadcastShape(n.shape,r.shape);return{a:()=>{const t=div$1(e,cast$3(r,"float32")),s=getReductionAxes(n.shape,a);return s.length>0?reshape$3(sum$2(t,s),n.shape):t},b:()=>{let t=mul(e,cast$3(n,"float32"));const s=getReductionAxes(r.shape,a);s.length>0&&(t=reshape$3(sum$2(t,s),r.shape));const o=square$2(r);return neg$2(div$1(t,cast$3(o,"float32")))}}}},reciprocalGradConfig={kernelName:Reciprocal,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>div$1(e,neg$2(square$2(n)))}}},relu6GradConfig={kernelName:Relu6$1,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t,r=mul(lessEqual$2(n,6),step$2(n));return{x:()=>mul(e,cast$3(r,"float32"))}}},reluGradConfig={kernelName:Relu$1,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>mul(e,cast$3(step$2(n),"float32"))}}},reshapeGradConfig={kernelName:Reshape$1,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>reshape$3(e,n.shape)}}},resizeBilinearGradConfig$2={kernelName:ResizeBilinear,inputsToSave:["images"],gradFunc:(e,t,n)=>{const[r]=t,a={dy:e,images:r};return{images:()=>ENGINE.runKernel(ResizeBilinearGrad,a,n)}}},resizeNearestNeighborGradConfig$2={kernelName:ResizeNearestNeighbor,inputsToSave:["images"],gradFunc:(e,t,n)=>{const[r]=t,a={dy:e,images:r};return{images:()=>ENGINE.runKernel(ResizeNearestNeighborGrad,a,n)}}},reverseGradConfig={kernelName:Reverse,gradFunc:(e,t,n)=>{const{dims:r}=n,a=parseAxisParam(r,e.shape);return{x:()=>reverse$2(e,a)}}},roundGradConfig={kernelName:Round,gradFunc:e=>({x:()=>zerosLike$2(e)})},rsqrtGradConfig={kernelName:Rsqrt,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>neg$2(div$1(e,mul(pow$2(n,1.5),2)))}}},selectGradConfig={kernelName:Select,inputsToSave:["condition"],gradFunc:(e,t)=>{const[n]=t;return{condition:()=>cast$3(zerosLike$2(n),"float32"),t:()=>mul(e,cast$3(n,e.dtype)),e:()=>mul(e,cast$3(logicalNot$2(n),e.dtype))}}},seluGradConfig={kernelName:Selu$1,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>{const t=greater$3(n,scalar(0)),r=scalar(SELU_SCALEALPHA),a=scalar(SELU_SCALE),s=mul(e,a),o=mul(mul(e,r),exp$2(cast$3(n,"float32")));return where(t,s,o)}}}},sigmoidGradConfig={kernelName:Sigmoid$1,outputsToSave:[!0],gradFunc:(e,t)=>{const[n]=t;return{x:()=>mul(e,mul(n,sub$2(scalar(1),n)))}}},signGradConfig={kernelName:Sign,gradFunc:e=>({x:()=>zerosLike$2(e)})},sinGradConfig={kernelName:Sin,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>mul(cos$2(cast$3(n,"float32")),e)}}},sinhGradConfig={kernelName:Sinh,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>mul(cosh$2(cast$3(n,"float32")),e)}}},sliceGradConfig={kernelName:Slice,inputsToSave:["x"],gradFunc:(e,t,n)=>{const[r]=t,{begin:a,size:s}=n,o=r.shape,[i,l]=parseSliceParams(r,a,s),u=[];for(let t=0;t<e.rank;t++)u.push([i[t],o[t]-i[t]-l[t]]);return{x:()=>pad(e,u)}}},softmaxGradConfig={kernelName:Softmax$2,outputsToSave:[!0],gradFunc:(e,t,n)=>{const[r]=t,{dim:a}=n,s=mul(e,r);return{logits:()=>sub$2(s,mul(sum$2(s,[a],!0),r))}}},softplusGradConfig={kernelName:Softplus$1,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>mul(e,sigmoid$2(n))}}},spaceToBatchNDGradConfig={kernelName:SpaceToBatchND,gradFunc:(e,t,n)=>{const{blockShape:r,paddings:a}=n;return{x:()=>batchToSpaceND$2(e,r,a)}}},splitVGradConfig={kernelName:SplitV,gradFunc:(e,t,n)=>{const{axis:r}=n;return{x:()=>concat$2(e,r)}}},sqrtGradConfig={kernelName:Sqrt,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>div$1(e,mul(sqrt$2(cast$3(n,"float32")),2))}}},squareGradConfig={kernelName:Square,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>mul(e,mul(cast$3(n,"float32"),2))}}},squaredDifferenceGradConfig={kernelName:SquaredDifference,inputsToSave:["a","b"],gradFunc:(e,t)=>{const[n,r]=t,a=scalar(2);return{a:()=>mul(e,mul(a,sub$2(n,r))),b:()=>mul(e,mul(a,sub$2(r,n)))}}},stepGradConfig={kernelName:Step,gradFunc:e=>({x:()=>zerosLike$2(e)})},subGradConfig={kernelName:Sub,inputsToSave:["a","b"],gradFunc:(e,t)=>{const[n,r]=t,a=assertAndGetBroadcastShape(n.shape,r.shape);return{a:()=>{let t=e;const r=getReductionAxes(n.shape,a);return r.length>0&&(t=sum$2(t,r)),reshape$3(t,n.shape)},b:()=>{let t=e;const n=getReductionAxes(r.shape,a);return n.length>0&&(t=sum$2(t,n)),reshape$3(neg$2(t),r.shape)}}}},sumGradConfig={kernelName:Sum,inputsToSave:["x"],gradFunc:(e,t,n)=>{const[r]=t,a=r.shape.slice(),{axis:s}=n;parseAxisParam(s,r.shape).forEach(e=>{a[e]=1});const o=reshape$3(e,a),i=mul(o,ones$1(r.shape,"float32"));return{x:()=>i}}},tanGradConfig={kernelName:Tan,inputsToSave:["x"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>div$1(e,square$2(cos$2(n)))}}},tanhGradConfig={kernelName:Tanh$1,outputsToSave:[!0],gradFunc:(e,t)=>{const[n]=t;return{x:()=>mul(sub$2(scalar(1),square$2(n)),e)}}},tileGradConfig={kernelName:Tile,inputsToSave:["x"],gradFunc:(e,t,n)=>{const[r]=t,{reps:a}=n;return{x:()=>{let t=zerosLike$2(r);if(1===r.rank)for(let n=0;n<a[0];++n)t=add$2(t,slice$2(e,[n*r.shape[0]],[r.shape[0]]));else if(2===r.rank)for(let n=0;n<a[0];++n)for(let s=0;s<a[1];++s)t=add$2(t,slice$2(e,[n*r.shape[0],s*r.shape[1]],[r.shape[0],r.shape[1]]));else if(3===r.rank)for(let n=0;n<a[0];++n)for(let s=0;s<a[1];++s)for(let o=0;o<a[2];++o)t=add$2(t,slice$2(e,[n*r.shape[0],s*r.shape[1],o*r.shape[2]],[r.shape[0],r.shape[1],r.shape[2]]));else{if(4!==r.rank)throw new Error(`Gradient for tile operation is not implemented for rank-${r.rank} tensors yet.`);for(let n=0;n<a[0];++n)for(let s=0;s<a[1];++s)for(let o=0;o<a[2];++o)for(let i=0;i<a[3];++i)t=add$2(t,slice$2(e,[n*r.shape[0],s*r.shape[1],o*r.shape[2],i*r.shape[3]],[r.shape[0],r.shape[1],r.shape[2],r.shape[3]]))}return t}}}},transposeGradConfig={kernelName:Transpose,gradFunc:(e,t,n)=>{const r=n,{perm:a}=r,s=getUndoAxesPermutation(a);return{x:()=>transpose$2(e,s)}}},unpackGradConfig={kernelName:Unpack,gradFunc:(e,t,n)=>{const r=n,{axis:a}=r;return{value:()=>stack(e,a)}}},unsortedSegmentSumGradConfig={kernelName:UnsortedSegmentSum,inputsToSave:["segmentIds"],gradFunc:(e,t)=>{const[n]=t;return{x:()=>gatherDropNegatives(e,n)}}};function gatherDropNegatives(e,t){const n=maximum$3(t,zerosLike$2(t)),r=gather$1(e,n);let a=greaterEqual$2(t,scalar(0,"int32"));const s=r.rank-a.rank;for(let e=0;e<s;++e)a=expandDims$3(a,e+1);a=logicalAnd$2(a,ones$1(r.shape,"bool"));const o=zerosLike$2(r);return where(a,r,o)}const zerosLikeGradConfig={kernelName:ZerosLike,gradFunc:e=>({x:()=>zerosLike$2(e)})},gradConfigs=[absGradConfig,acosGradConfig,acoshGradConfig,addGradConfig,addNGradConfig,argMaxGradConfig,argMinGradConfig,asinGradConfig,asinhGradConfig,atan2GradConfig,atanGradConfig,atanhGradConfig,avgPool3DGradConfig$1,avgPoolGradConfig$2,batchMatMulGradConfig,batchToSpaceNDGradConfig,broadcastToGradConfig,castGradConfig,ceilGradConfig,clipByValueGradConfig,complexAbsGradConfig,concatGradConfig,conv2DBackpropInputGradConfig,conv2DGradConfig,conv3DGradConfig,cosGradConfig,coshGradConfig,cumsumGradConfig,depthwiseConv2dNativeGradConfig,dilation2dGradConfig,divGradConfig,eluGradConfig$2,erfGradConfig,expGradConfig,expandDimsGradConfig,expm1GradConfig,floorDivGradConfig,floorGradConfig,fusedBatchNormGradConfig,gatherGradConfig,greaterEqualGradConfig,identityGradConfig,isFiniteGradConfig,isInfGradConfig,isNanGradConfig,leakyReluGradConfig,log1pGradConfig,logGradConfig,logSoftmaxGradConfig,lrnGradConfig,maxGradConfig,maxGradConfig,maximumGradConfig,maxPool3DGradConfig$1,maxPoolGradConfig$2,meanGradConfig,minGradConfig,minimumGradConfig,mirrorPadGradConfig,modGradConfig,multiplyGradConfig,negGradConfig,oneHotGradConfig,onesLikeGradConfig,packGradConfig,padV2GradConfig,padV2GradConfig,powGradConfig,preluGradConfig,reciprocalGradConfig,relu6GradConfig,reluGradConfig,reshapeGradConfig,resizeBilinearGradConfig$2,resizeNearestNeighborGradConfig$2,reverseGradConfig,roundGradConfig,rsqrtGradConfig,selectGradConfig,seluGradConfig,sigmoidGradConfig,signGradConfig,sinGradConfig,sinhGradConfig,sliceGradConfig,softmaxGradConfig,softplusGradConfig,spaceToBatchNDGradConfig,spaceToBatchNDGradConfig,splitVGradConfig,splitVGradConfig,sqrtGradConfig,squaredDifferenceGradConfig,squareGradConfig,stepGradConfig,subGradConfig,sumGradConfig,tanGradConfig,tanhGradConfig,tileGradConfig,transposeGradConfig,unpackGradConfig,unsortedSegmentSumGradConfig,zerosLikeGradConfig];for(const e of gradConfigs)registerGradient(e);let _epsilon;function epsilon$1(){return null==_epsilon&&(_epsilon=backend().epsilon()),_epsilon}function imageDataFormat(){return"channelsLast"}getGlobalTensorClass().prototype.abs=function(){return this.throwIfDisposed(),abs$2(this)},getGlobalTensorClass().prototype.acos=function(){return this.throwIfDisposed(),acos$2(this)},getGlobalTensorClass().prototype.acosh=function(){return this.throwIfDisposed(),acosh$2(this)},getGlobalTensorClass().prototype.add=function(e){return this.throwIfDisposed(),add$2(this,e)},getGlobalTensorClass().prototype.all=function(e,t){return this.throwIfDisposed(),all$2(this,e,t)},getGlobalTensorClass().prototype.any=function(e,t){return this.throwIfDisposed(),any$2(this,e,t)},getGlobalTensorClass().prototype.argMax=function(e){return this.throwIfDisposed(),argMax$2(this,e)},getGlobalTensorClass().prototype.argMin=function(e){return this.throwIfDisposed(),argMin$2(this,e)},getGlobalTensorClass().prototype.asScalar=function(){return this.throwIfDisposed(),assert$4(1===this.size,()=>"The array must have only 1 element."),reshape$3(this,[])},getGlobalTensorClass().prototype.asType=function(e){return this.throwIfDisposed(),cast$3(this,e)},getGlobalTensorClass().prototype.as1D=function(){return this.throwIfDisposed(),reshape$3(this,[this.size])},getGlobalTensorClass().prototype.as2D=function(e,t){return this.throwIfDisposed(),reshape$3(this,[e,t])},getGlobalTensorClass().prototype.as3D=function(e,t,n){return this.throwIfDisposed(),reshape$3(this,[e,t,n])},getGlobalTensorClass().prototype.as4D=function(e,t,n,r){return this.throwIfDisposed(),reshape$3(this,[e,t,n,r])},getGlobalTensorClass().prototype.as5D=function(e,t,n,r,a){return this.throwIfDisposed(),reshape$3(this,[e,t,n,r,a])},getGlobalTensorClass().prototype.asin=function(){return this.throwIfDisposed(),asin$2(this)},getGlobalTensorClass().prototype.asinh=function(){return this.throwIfDisposed(),asinh$2(this)},getGlobalTensorClass().prototype.atan=function(){return this.throwIfDisposed(),atan$2(this)},getGlobalTensorClass().prototype.atan2=function(e){return this.throwIfDisposed(),atan2$2(this,e)},getGlobalTensorClass().prototype.atanh=function(){return this.throwIfDisposed(),atanh$2(this)},getGlobalTensorClass().prototype.avgPool=function(e,t,n,r){return this.throwIfDisposed(),avgPool$2(this,e,t,n,r)},getGlobalTensorClass().prototype.batchToSpaceND=function(e,t){return this.throwIfDisposed(),batchToSpaceND$2(this,e,t)},getGlobalTensorClass().prototype.batchNorm=function(e,t,n,r,a){return this.throwIfDisposed(),batchNorm$2(this,e,t,n,r,a)},getGlobalTensorClass().prototype.broadcastTo=function(e){return this.throwIfDisposed(),broadcastTo(this,e)},getGlobalTensorClass().prototype.cast=function(e){return this.throwIfDisposed(),cast$3(this,e)},getGlobalTensorClass().prototype.ceil=function(){return this.throwIfDisposed(),ceil$2(this)},getGlobalTensorClass().prototype.clipByValue=function(e,t){return this.throwIfDisposed(),clipByValue$1(this,e,t)},getGlobalTensorClass().prototype.concat=function(e,t){return this.throwIfDisposed(),e instanceof Tensor&&(e=[e]),concat$2([this,...e],t)},getGlobalTensorClass().prototype.conv1d=function(e,t,n,r,a,s){return this.throwIfDisposed(),conv1d$1(this,e,t,n,r,a,s)},getGlobalTensorClass().prototype.conv2dTranspose=function(e,t,n,r,a){return this.throwIfDisposed(),conv2dTranspose$1(this,e,t,n,r,a)},getGlobalTensorClass().prototype.conv2d=function(e,t,n,r,a,s){return this.throwIfDisposed(),conv2d$3(this,e,t,n,r,a,s)},getGlobalTensorClass().prototype.cos=function(){return this.throwIfDisposed(),cos$2(this)},getGlobalTensorClass().prototype.cosh=function(){return this.throwIfDisposed(),cosh$2(this)},getGlobalTensorClass().prototype.cumsum=function(e,t,n){return this.throwIfDisposed(),cumsum$2(this,e,t,n)},getGlobalTensorClass().prototype.depthToSpace=function(e,t){return this.throwIfDisposed(),depthToSpace$2(this,e,t)},getGlobalTensorClass().prototype.depthwiseConv2d=function(e,t,n,r,a,s){return this.throwIfDisposed(),depthwiseConv2d$3(this,e,t,n,r,a,s)},getGlobalTensorClass().prototype.dilation2d=function(e,t,n,r,a){return this.throwIfDisposed(),dilation2d(this,e,t,n,r,a)},getGlobalTensorClass().prototype.divNoNan=function(e){return this.throwIfDisposed(),divNoNan(this,e)},getGlobalTensorClass().prototype.div=function(e){return this.throwIfDisposed(),div$1(this,e)},getGlobalTensorClass().prototype.dot=function(e){return this.throwIfDisposed(),dot$2(this,e)},getGlobalTensorClass().prototype.elu=function(){return this.throwIfDisposed(),elu$4(this)},getGlobalTensorClass().prototype.equal=function(e){return this.throwIfDisposed(),equal$2(this,e)},getGlobalTensorClass().prototype.erf=function(){return this.throwIfDisposed(),erf$2(this)},getGlobalTensorClass().prototype.exp=function(){return this.throwIfDisposed(),exp$2(this)},getGlobalTensorClass().prototype.expandDims=function(e){return this.throwIfDisposed(),expandDims$3(this,e)},getGlobalTensorClass().prototype.expm1=function(){return this.throwIfDisposed(),expm1$2(this)},getGlobalTensorClass().prototype.fft=function(){return this.throwIfDisposed(),fft$2(this)},getGlobalTensorClass().prototype.flatten=function(){return this.throwIfDisposed(),reshape$3(this,[this.size])},getGlobalTensorClass().prototype.floor=function(){return this.throwIfDisposed(),floor$2(this)},getGlobalTensorClass().prototype.floorDiv=function(e){return this.throwIfDisposed(),floorDiv$2(this,e)},getGlobalTensorClass().prototype.gather=function(e,t){return this.throwIfDisposed(),gather$1(this,e,t)},getGlobalTensorClass().prototype.greaterEqual=function(e){return this.throwIfDisposed(),greaterEqual$2(this,e)},getGlobalTensorClass().prototype.greater=function(e){return this.throwIfDisposed(),greater$3(this,e)},getGlobalTensorClass().prototype.ifft=function(){return this.throwIfDisposed(),ifft$2(this)},getGlobalTensorClass().prototype.irfft=function(){return this.throwIfDisposed(),irfft(this)},getGlobalTensorClass().prototype.isFinite=function(){return this.throwIfDisposed(),isFinite$3(this)},getGlobalTensorClass().prototype.isInf=function(){return this.throwIfDisposed(),isInf$2(this)},getGlobalTensorClass().prototype.isNaN=function(){return this.throwIfDisposed(),isNaN$3(this)},getGlobalTensorClass().prototype.leakyRelu=function(e){return this.throwIfDisposed(),leakyRelu$2(this,e)},getGlobalTensorClass().prototype.lessEqual=function(e){return this.throwIfDisposed(),lessEqual$2(this,e)},getGlobalTensorClass().prototype.less=function(e){return this.throwIfDisposed(),less$3(this,e)},getGlobalTensorClass().prototype.localResponseNormalization=function(e,t,n,r){return this.throwIfDisposed(),localResponseNormalization(this,e,t,n,r)},getGlobalTensorClass().prototype.logSigmoid=function(){return this.throwIfDisposed(),logSigmoid(this)},getGlobalTensorClass().prototype.logSoftmax=function(e){return this.throwIfDisposed(),logSoftmax(this,e)},getGlobalTensorClass().prototype.logSumExp=function(e,t){return this.throwIfDisposed(),logSumExp(this,e,t)},getGlobalTensorClass().prototype.log=function(){return this.throwIfDisposed(),log$3(this)},getGlobalTensorClass().prototype.log1p=function(){return this.throwIfDisposed(),log1p$2(this)},getGlobalTensorClass().prototype.logicalAnd=function(e){return this.throwIfDisposed(),logicalAnd$2(this,e)},getGlobalTensorClass().prototype.logicalNot=function(){return this.throwIfDisposed(),logicalNot$2(this)},getGlobalTensorClass().prototype.logicalOr=function(e){return this.throwIfDisposed(),logicalOr$2(this,e)},getGlobalTensorClass().prototype.logicalXor=function(e){return this.throwIfDisposed(),logicalXor(this,e)},getGlobalTensorClass().prototype.matMul=function(e,t,n){return this.throwIfDisposed(),matMul$1(this,e,t,n)},getGlobalTensorClass().prototype.maxPool=function(e,t,n,r){return this.throwIfDisposed(),maxPool$2(this,e,t,n,r)},getGlobalTensorClass().prototype.max=function(e,t){return this.throwIfDisposed(),max$3(this,e,t)},getGlobalTensorClass().prototype.maximum=function(e){return this.throwIfDisposed(),maximum$3(this,e)},getGlobalTensorClass().prototype.mean=function(e,t){return this.throwIfDisposed(),mean$1(this,e,t)},getGlobalTensorClass().prototype.min=function(e,t){return this.throwIfDisposed(),min$3(this,e,t)},getGlobalTensorClass().prototype.minimum=function(e){return this.throwIfDisposed(),minimum$3(this,e)},getGlobalTensorClass().prototype.mirrorPad=function(e,t){return this.throwIfDisposed(),mirrorPad$1(this,e,t)},getGlobalTensorClass().prototype.mod=function(e){return this.throwIfDisposed(),mod$2(this,e)},getGlobalTensorClass().prototype.mul=function(e){return this.throwIfDisposed(),mul(this,e)},getGlobalTensorClass().prototype.neg=function(){return this.throwIfDisposed(),neg$2(this)},getGlobalTensorClass().prototype.norm=function(e,t,n){return this.throwIfDisposed(),norm(this,e,t,n)},getGlobalTensorClass().prototype.notEqual=function(e){return this.throwIfDisposed(),notEqual$2(this,e)},getGlobalTensorClass().prototype.oneHot=function(e,t=1,n=0){return this.throwIfDisposed(),oneHot$2(this,e,t,n)},getGlobalTensorClass().prototype.onesLike=function(){return this.throwIfDisposed(),onesLike$2(this)},getGlobalTensorClass().prototype.pad=function(e,t){return this.throwIfDisposed(),pad(this,e,t)},getGlobalTensorClass().prototype.pool=function(e,t,n,r,a){return this.throwIfDisposed(),pool$1(this,e,t,n,r,a)},getGlobalTensorClass().prototype.pow=function(e){return this.throwIfDisposed(),pow$2(this,e)},getGlobalTensorClass().prototype.prelu=function(e){return this.throwIfDisposed(),prelu$3(this,e)},getGlobalTensorClass().prototype.prod=function(e,t){return this.throwIfDisposed(),prod$2(this,e,t)},getGlobalTensorClass().prototype.reciprocal=function(){return this.throwIfDisposed(),reciprocal$2(this)},getGlobalTensorClass().prototype.relu=function(){return this.throwIfDisposed(),relu$3(this)},getGlobalTensorClass().prototype.relu6=function(){return this.throwIfDisposed(),relu6$2(this)},getGlobalTensorClass().prototype.reshapeAs=function(e){return this.throwIfDisposed(),reshape$3(this,e.shape)},getGlobalTensorClass().prototype.reshape=function(e){return this.throwIfDisposed(),reshape$3(this,e)},getGlobalTensorClass().prototype.resizeBilinear=function(e,t,n){return this.throwIfDisposed(),resizeBilinear$2(this,e,t,n)},getGlobalTensorClass().prototype.resizeNearestNeighbor=function(e,t,n){return this.throwIfDisposed(),resizeNearestNeighbor$2(this,e,t,n)},getGlobalTensorClass().prototype.reverse=function(e){return this.throwIfDisposed(),reverse$2(this,e)},getGlobalTensorClass().prototype.rfft=function(){return this.throwIfDisposed(),rfft(this)},getGlobalTensorClass().prototype.round=function(){return this.throwIfDisposed(),round$2(this)},getGlobalTensorClass().prototype.rsqrt=function(){return this.throwIfDisposed(),rsqrt$2(this)},getGlobalTensorClass().prototype.selu=function(){return this.throwIfDisposed(),selu$2(this)},getGlobalTensorClass().prototype.separableConv2d=function(e,t,n,r,a,s){return this.throwIfDisposed(),separableConv2d$1(this,e,t,n,r,a,s)},getGlobalTensorClass().prototype.sigmoid=function(){return this.throwIfDisposed(),sigmoid$2(this)},getGlobalTensorClass().prototype.sign=function(){return this.throwIfDisposed(),sign$2(this)},getGlobalTensorClass().prototype.sin=function(){return this.throwIfDisposed(),sin$2(this)},getGlobalTensorClass().prototype.sinh=function(){return this.throwIfDisposed(),sinh$2(this)},getGlobalTensorClass().prototype.slice=function(e,t){return this.throwIfDisposed(),slice$2(this,e,t)},getGlobalTensorClass().prototype.softmax=function(e){return this.throwIfDisposed(),softmax$3(this,e)},getGlobalTensorClass().prototype.softplus=function(){return this.throwIfDisposed(),softplus$2(this)},getGlobalTensorClass().prototype.spaceToBatchND=function(e,t){return this.throwIfDisposed(),spaceToBatchND$2(this,e,t)},getGlobalTensorClass().prototype.split=function(e,t){return this.throwIfDisposed(),split$2(this,e,t)},getGlobalTensorClass().prototype.sqrt=function(){return this.throwIfDisposed(),sqrt$2(this)},getGlobalTensorClass().prototype.square=function(){return this.throwIfDisposed(),square$2(this)},getGlobalTensorClass().prototype.squaredDifference=function(e){return this.throwIfDisposed(),squaredDifference$2(this,e)},getGlobalTensorClass().prototype.squeeze=function(e){return this.throwIfDisposed(),squeeze(this,e)},getGlobalTensorClass().prototype.stack=function(e,t){this.throwIfDisposed();const n=e instanceof Tensor?[this,e]:[this,...e];return stack(n,t)},getGlobalTensorClass().prototype.step=function(e){return this.throwIfDisposed(),step$2(this,e)},getGlobalTensorClass().prototype.stridedSlice=function(e,t,n,r,a,s,o,i){return this.throwIfDisposed(),stridedSlice$2(this,e,t,n,r,a,s,o,i)},getGlobalTensorClass().prototype.sub=function(e){return this.throwIfDisposed(),sub$2(this,e)},getGlobalTensorClass().prototype.sum=function(e,t){return this.throwIfDisposed(),sum$2(this,e,t)},getGlobalTensorClass().prototype.tan=function(){return this.throwIfDisposed(),tan$2(this)},getGlobalTensorClass().prototype.tanh=function(){return this.throwIfDisposed(),tanh$2(this)},getGlobalTensorClass().prototype.tile=function(e){return this.throwIfDisposed(),tile$3(this,e)},getGlobalTensorClass().prototype.toBool=function(){return this.throwIfDisposed(),cast$3(this,"bool")},getGlobalTensorClass().prototype.toFloat=function(){return this.throwIfDisposed(),cast$3(this,"float32")},getGlobalTensorClass().prototype.toInt=function(){return this.throwIfDisposed(),cast$3(this,"int32")},getGlobalTensorClass().prototype.topk=function(e,t){return this.throwIfDisposed(),topk(this,e,t)},getGlobalTensorClass().prototype.transpose=function(e){return this.throwIfDisposed(),transpose$2(this,e)},getGlobalTensorClass().prototype.unique=function(e){return this.throwIfDisposed(),unique$3(this,e)},getGlobalTensorClass().prototype.unsortedSegmentSum=function(e,t){return this.throwIfDisposed(),unsortedSegmentSum$2(this,e,t)},getGlobalTensorClass().prototype.unstack=function(e){return this.throwIfDisposed(),unstack(this,e)},getGlobalTensorClass().prototype.where=function(e,t){return this.throwIfDisposed(),where(e,this,t)},getGlobalTensorClass().prototype.zerosLike=function(){return this.throwIfDisposed(),zerosLike$2(this)};class AttributeError extends Error{constructor(e){super(e),Object.setPrototypeOf(this,AttributeError.prototype)}}class RuntimeError extends Error{constructor(e){super(e),Object.setPrototypeOf(this,RuntimeError.prototype)}}class ValueError extends Error{constructor(e){super(e),Object.setPrototypeOf(this,ValueError.prototype)}}class NotImplementedError extends Error{constructor(e){super(e),Object.setPrototypeOf(this,NotImplementedError.prototype)}}class AssertionError extends Error{constructor(e){super(e),Object.setPrototypeOf(this,AssertionError.prototype)}}function pyListRepeat(e,t){if(Array.isArray(e)){let n=[];for(let r=0;r<t;r++)n=n.concat(e);return n}{const n=new Array(t);return n.fill(e),n}}function assert$3(e,t){if(!e)throw new AssertionError(t)}function count(e,t){let n=0;for(const r of e)r===t&&n++;return n}function singletonOrArray(e){return 1===e.length?e[0]:e}function toList(e){return Array.isArray(e)?e:[e]}function toSnakeCase(e){const t=e.replace(/(.)([A-Z][a-z0-9]+)/g,"$1_$2").replace(/([a-z])([A-Z])/g,"$1_$2").toLowerCase();return"_"!==t[0]?t:"private"+t}function toCamelCase(e){return e.length<=1||-1===e.indexOf("_")?e:e.replace(/[_]+(\w|$)/g,(e,t)=>t.toUpperCase())}let _GLOBAL_CUSTOM_OBJECTS={};function serializeKerasObject(e){if(null==e)return null;const t={};return t.className=e.getClassName(),t.config=e.getConfig(),t}function convertNDArrayScalarsInConfig(e){if(null!=e&&"object"==typeof e)if(Array.isArray(e))e.forEach(e=>convertNDArrayScalarsInConfig(e));else{const t=Object.keys(e);for(const n of t){const t=e[n];null!=t&&"object"==typeof t&&(Array.isArray(t)||"ndarray"!==t.type||"number"!=typeof t.value?convertNDArrayScalarsInConfig(t):e[n]=t.value)}}}function deserializeKerasObject(e,t={},n={},r="object",a=!1){if("string"==typeof e){const a=e;let s;if(a in n)s=n[a];else if(a in _GLOBAL_CUSTOM_OBJECTS)s=_GLOBAL_CUSTOM_OBJECTS[a];else if(s=t[a],null==s)throw new ValueError(`Unknown ${r}: ${e}. This may be due to one of the following reasons:\n1. The ${r} is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.\n2. The custom ${r} is defined in JavaScript, but is not registered properly with tf.serialization.registerClass().`);return s}{const s=e;if(null==s.className||null==s.config)throw new ValueError(`${r}: Improper config format: ${JSON.stringify(s)}.\n'className' and 'config' must set.`);const o=s.className;let i,l;if(o in n?[i,l]=n[o]:o in _GLOBAL_CUSTOM_OBJECTS?[i,l]=_GLOBAL_CUSTOM_OBJECTS.className:o in t&&([i,l]=t[o]),null==i)throw new ValueError(`Unknown ${r}: ${o}. This may be due to one of the following reasons:\n1. The ${r} is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.\n2. The custom ${r} is defined in JavaScript, but is not registered properly with tf.serialization.registerClass().`);if(null!=l){const e={};for(const t of Object.keys(_GLOBAL_CUSTOM_OBJECTS))e[t]=_GLOBAL_CUSTOM_OBJECTS[t];for(const t of Object.keys(n))e[t]=n[t];s.config.customObjects=e;const t=Object.assign({},_GLOBAL_CUSTOM_OBJECTS);for(const e of Object.keys(n))_GLOBAL_CUSTOM_OBJECTS[e]=n[e];convertNDArrayScalarsInConfig(s.config);const r=l(i,s.config,n,a);return _GLOBAL_CUSTOM_OBJECTS=Object.assign({},t),r}{const e=Object.assign({},_GLOBAL_CUSTOM_OBJECTS);for(const e of Object.keys(n))_GLOBAL_CUSTOM_OBJECTS[e]=n[e];const t=new i(s.config);return _GLOBAL_CUSTOM_OBJECTS=Object.assign({},e),t}}}function numberCompare(e,t){return e<t?-1:e>t?1:0}function reverseNumberCompare(e,t){return-1*numberCompare(e,t)}function unique$2(e){if(null==e)return e;const t=[];for(const n of e)-1===t.indexOf(n)&&t.push(n);return t}function isObjectEmpty(e){if(null==e)throw new ValueError(`Invalid value in obj: ${JSON.stringify(e)}`);for(const t in e)if(e.hasOwnProperty(t))return!1;return!0}function checkStringTypeUnionValue(e,t,n){if(null!=n&&e.indexOf(n)<0)throw new ValueError(`${n} is not a valid ${t}.  Valid values are ${e} or null/undefined.`)}function checkArrayTypeAndLength(e,t,n=0,r=Infinity){return assert$3(n>=0),assert$3(r>=n),Array.isArray(e)&&e.length>=n&&e.length<=r&&e.every(e=>typeof e===t)}function assertPositiveInteger(e,t){Array.isArray(e)?(assert$4(e.length>0,()=>`${t} is unexpectedly an empty array.`),e.forEach((e,n)=>assertPositiveInteger(e,`element ${n+1} of ${t}`))):assert$4(Number.isInteger(e)&&e>0,()=>`Expected ${t} to be a positive integer, but got ${formatAsFriendlyString(e)}.`)}function formatAsFriendlyString(e){return null===e?"null":Array.isArray(e)?"["+e.map(e=>formatAsFriendlyString(e)).join(",")+"]":"string"==typeof e?`"${e}"`:`${e}`}function debounce(e,t){let n,r=now();return(...a)=>{const s=now();return s-r<t||(r=s,n=e(...a)),n}}function mapActivationToFusedKernel(e){return"relu"===e?"relu":"linear"===e?"linear":"elu"===e?"elu":null}function calcL2Norms(e,t){return tidy(()=>sqrt$2(sum$2(mul(e,e),t,!0)))}class Constraint extends Serializable{getConfig(){return{}}}class MaxNorm extends Constraint{constructor(e){super(),this.defaultMaxValue=2,this.defaultAxis=0,this.maxValue=null!=e.maxValue?e.maxValue:this.defaultMaxValue,this.axis=null!=e.axis?e.axis:this.defaultAxis}apply(e){return tidy(()=>{const t=calcL2Norms(e,this.axis),n=clipByValue$1(t,0,this.maxValue);return mul(e,div$1(n,add$2(epsilon$1(),t)))})}getConfig(){return{maxValue:this.maxValue,axis:this.axis}}}MaxNorm.className="MaxNorm",registerClass(MaxNorm);class UnitNorm extends Constraint{constructor(e){super(),this.defaultAxis=0,this.axis=null!=e.axis?e.axis:this.defaultAxis}apply(e){return tidy(()=>div$1(e,add$2(epsilon$1(),calcL2Norms(e,this.axis))))}getConfig(){return{axis:this.axis}}}UnitNorm.className="UnitNorm",registerClass(UnitNorm);class NonNeg extends Constraint{apply(e){return relu$3(e)}}NonNeg.className="NonNeg",registerClass(NonNeg);class MinMaxNorm extends Constraint{constructor(e){super(),this.defaultMinValue=0,this.defaultMaxValue=1,this.defaultRate=1,this.defaultAxis=0,this.minValue=null!=e.minValue?e.minValue:this.defaultMinValue,this.maxValue=null!=e.maxValue?e.maxValue:this.defaultMaxValue,this.rate=null!=e.rate?e.rate:this.defaultRate,this.axis=null!=e.axis?e.axis:this.defaultAxis}apply(e){return tidy(()=>{const t=calcL2Norms(e,this.axis),n=add$2(mul(this.rate,clipByValue$1(t,this.minValue,this.maxValue)),mul(1-this.rate,t));return mul(e,div$1(n,add$2(epsilon$1(),t)))})}getConfig(){return{minValue:this.minValue,maxValue:this.maxValue,rate:this.rate,axis:this.axis}}}MinMaxNorm.className="MinMaxNorm",registerClass(MinMaxNorm);const CONSTRAINT_IDENTIFIER_REGISTRY_SYMBOL_MAP={maxNorm:"MaxNorm",minMaxNorm:"MinMaxNorm",nonNeg:"NonNeg",unitNorm:"UnitNorm"};function serializeConstraint(e){return serializeKerasObject(e)}function deserializeConstraint(e,t={}){return deserializeKerasObject(e,SerializationMap.getMap().classNameMap,t,"constraint")}function getConstraint(e){return null==e?null:"string"==typeof e?deserializeConstraint({className:e in CONSTRAINT_IDENTIFIER_REGISTRY_SYMBOL_MAP?CONSTRAINT_IDENTIFIER_REGISTRY_SYMBOL_MAP[e]:e,config:{}}):e instanceof Constraint?e:deserializeConstraint(e)}function maxNorm(e){return new MaxNorm(e)}function unitNorm(e){return new UnitNorm(e)}function nonNeg(){return new NonNeg}function minMaxNorm(e){return new MinMaxNorm(e)}var exports_constraints={__proto__:null,maxNorm,unitNorm,nonNeg,minMaxNorm};const VALID_DATA_FORMAT_VALUES=["channelsFirst","channelsLast"],VALID_INTERPOLATION_FORMAT_VALUES=["nearest","bilinear"],VALID_PADDING_MODE_VALUES=["valid","same","causal"],VALID_POOL_MODE_VALUES=["max","avg"],VALID_BIDIRECTIONAL_MERGE_MODES=["sum","mul","concat","ave"],nameMap=new Map;function checkDataFormat(e){checkStringTypeUnionValue(VALID_DATA_FORMAT_VALUES,"DataFormat",e)}function checkInterpolationFormat(e){checkStringTypeUnionValue(VALID_INTERPOLATION_FORMAT_VALUES,"InterpolationFormat",e)}function checkPaddingMode(e){checkStringTypeUnionValue(VALID_PADDING_MODE_VALUES,"PaddingMode",e)}function checkPoolMode(e){checkStringTypeUnionValue(VALID_POOL_MODE_VALUES,"PoolMode",e)}const _nameScopeStack=[],_nameScopeDivider="/";function nameScope(e,t){_nameScopeStack.push(e);try{const e=t();return _nameScopeStack.pop(),e}catch(e){throw _nameScopeStack.pop(),e}}function currentNameScopePrefix(){return 0===_nameScopeStack.length?"":_nameScopeStack.join(_nameScopeDivider)+_nameScopeDivider}function getScopedTensorName(e){if(!isValidTensorName(e))throw new Error("Not a valid tensor name: '"+e+"'");return currentNameScopePrefix()+e}function getUniqueTensorName(e){if(!isValidTensorName(e))throw new Error("Not a valid tensor name: '"+e+"'");nameMap.has(e)||nameMap.set(e,0);const t=nameMap.get(e);if(nameMap.set(e,nameMap.get(e)+1),t>0){const n=`${e}_${t}`;return nameMap.set(n,1),n}return e}const tensorNameRegex=new RegExp(/^[A-Za-z0-9][-A-Za-z0-9\._\/]*$/);function isValidTensorName(e){return!!e.match(tensorNameRegex)}function isInteger(e){return e===parseInt(e.toString(),10)}function arrayProd(e,t,n){null==t&&(t=0),null==n&&(n=e.length);let r=1;for(let a=t;a<n;++a)r*=e[a];return r}function min$2(e){if(0===e.length)return Number.NaN;let t=Number.POSITIVE_INFINITY;for(let n=0;n<e.length;n++){const r=e[n];r<t&&(t=r)}return t}function max$2(e){if(0===e.length)return Number.NaN;let t=Number.NEGATIVE_INFINITY;for(let n=0;n<e.length;n++){const r=e[n];r>t&&(t=r)}return t}function range$3(e,t){if(t<e)throw new ValueError(`end (${t}) < begin (${e}) is forbidden.`);const n=[];for(let r=e;r<t;++r)n.push(r);return n}function cast$2(e,t){return cast$3(e,t)}function expandDims$2(e,t=-1){const n=e.shape.slice();return t<0&&(t=n.length+t+1),n.splice(t,0,1),reshape$3(e,n)}function repeat$1(e,t){return tidy(()=>{if(2!==e.shape.length)throw new ValueError(`repeat() expects a rank-2 tensor, but received a rank-${e.shape.length} tensor.`);return tile$2(expandDims$2(e,1),[1,t,1])})}function flatten$2(e){const t=[arrayProd(e.shape)];return reshape$3(e,t)}function batchFlatten(e){if(e.rank<=1)throw new ValueError(`batchFlatten requires a minimum rank of 2. Got rank: ${e.rank}.`);const t=[e.shape[0],arrayProd(e.shape,1)];return reshape$3(e,t)}function sliceAlongFirstAxis(e,t,n){return tidy(()=>{switch(e.rank){case 1:return slice1d(e,t,n);case 2:return slice2d(e,[t,0],[n,e.shape[1]]);case 3:return slice3d(e,[t,0,0],[n,e.shape[1],e.shape[2]]);case 4:return slice4d(e,[t,0,0,0],[n,e.shape[1],e.shape[2],e.shape[3]]);case 5:return slice$2(e,[t,0,0,0,0],[n,e.shape[1],e.shape[2],e.shape[3],e.shape[4]]);case 6:return slice$2(e,[t,0,0,0,0,0],[n,e.shape[1],e.shape[2],e.shape[3],e.shape[4],e.shape[5]]);default:throw new ValueError(`sliceAlongFirstAxis() received an unsupported tensor rank: ${e.rank}`)}})}function sliceAlongLastAxis(e,t,n){return tidy(()=>{switch(e.rank){case 1:return slice1d(e,t,n);case 2:return slice2d(e,[0,t],[e.shape[0],n]);case 3:return slice3d(e,[0,0,t],[e.shape[0],e.shape[1],n]);case 4:return slice4d(e,[0,0,0,t],[e.shape[0],e.shape[1],e.shape[2],n]);default:throw new ValueError(`sliceAlongLastAxis() received an unsupported tensor rank: ${e.rank}`)}})}function sliceAlongAxis(e,t,n,r){return tidy(()=>{switch(e.rank){case 1:return slice1d(e,t,n);case 2:switch(r){case 1:return sliceAlongFirstAxis(e,t,n);case 2:return sliceAlongLastAxis(e,t,n);default:throw new ValueError(`The axis is not within the rank of the tensor ${r}`)}case 3:switch(r){case 1:return sliceAlongFirstAxis(e,t,n);case 2:return slice3d(e,[0,t,0],[e.shape[0],n,e.shape[2]]);case 3:return sliceAlongLastAxis(e,t,n);default:throw new ValueError(`The axis is not within the rank of the tensor ${r}`)}case 4:switch(r){case 1:return sliceAlongFirstAxis(e,t,n);case 2:return slice4d(e,[0,t,0,0],[e.shape[0],n,e.shape[2],e.shape[3]]);case 3:return slice4d(e,[0,0,t,0],[e.shape[0],e.shape[1],n,e.shape[3]]);case 4:return sliceAlongLastAxis(e,t,n);default:throw new ValueError(`The axis is not within the rank of the tensor ${r}`)}default:throw new ValueError(`sliceAlongLastAxis() received an unsupported tensor rank: ${e.rank}`)}})}function concatenate$1(e,t=-1){let n;return t<0&&(n=e[0].rank,t=0!==n?n:0),t===e[0].rank&&(t=-1),concat$2(e,t)}function concatAlongFirstAxis(e,t){switch(e.rank){case 1:return concat1d([e,t]);case 2:return concat2d([e,t],0);case 3:return concat3d([e,t],0);case 4:return concat4d([e,t],0);default:throw new ValueError(`concatAlongFirstAxis() received an unsupported tensor rank: ${e.rank}`)}}function tile$2(e,t){if(Array.isArray(t)||(t=[t]),e.rank!==t.length)throw new ValueError(`The length of input n (${t.length}) does not match the number of dimensions in input x (${e.rank})`);return tile$3(e,t)}function randomNormal$1(e,t=0,n=1,r,a){return randomNormal$2(e,t,n,r,a)}function dot$1(e,t,n,r){if(e.rank<2||t.rank<2)throw new NotImplementedError(`dot requires both inputs to be rank >= 2 but got x shape = ${e.shape} and y shape = ${t.shape}`);if(t.rank>=3&&e.shape.slice(-1)[0]!==t.shape.slice(-2)[0])throw new NotImplementedError(`If rank y >= 3, then the second last dim of y must equal the last dim of x but got x shape = ${e.shape} and  y shape = ${t.shape}`);if(2===e.rank&&2===t.rank)return matMul({a:e,b:t,transposeA:!1,transposeB:!1,bias:r?reshapeBias(e.rank,r,imageDataFormat()):null,activation:n});{const a=e.shape.slice(),s=a.pop();e=reshape$3(e,[-1,s]);const o=t.shape.slice(),i=o.pop(),l=o.pop(),u=[...o,i],c=Array.from({length:t.rank},(e,n)=>0===n?t.rank-2:n<=t.rank-2?n-1:n);t=reshape$3(transpose$2(t,c),[l,-1]);const p=[...a,...u];return reshape$3(matMul({a:e,b:t,transposeA:!1,transposeB:!1,bias:r?reshapeBias(e.rank,r,imageDataFormat()):null,activation:n}),p)}}function gather(e,t,n){return tidy(()=>(t=Array.isArray(t)?tensor1d(t,"int32"):cast$3(t,"int32"),gather$1(e,t,n)))}function square$1(e){return mul(e,e)}function reshapeBias(e,t,n){const r=t.shape;if(1!==t.rank&&t.rank!==e)throw new ValueError(`Unexpected bias dimensions: ${t.rank}; expected it to be 1 or ${e}`);if(5===e){if("channelsFirst"===n)return reshape$3(t,1===r.length?[1,r[0],1,1,1]:[1,r[3],r[0],r[1],r[2]]);if("channelsLast"===n)return reshape$3(t,1===r.length?[1,1,1,1,r[0]]:[1].concat(r))}else if(4===e){if("channelsFirst"===n)return reshape$3(t,1===r.length?[1,r[0],1,1]:[1,r[2],r[0],r[1]]);if("channelsLast"===n)return reshape$3(t,1===r.length?[1,1,1,r[0]]:[1].concat(r))}else if(3===e){if("channelsFirst"===n)return reshape$3(t,1===r.length?[1,r[0],1]:[1,r[1],r[0]]);if("channelsLast"===n)return reshape$3(t,1===r.length?[1,1,r[0]]:[1].concat(r))}else if(e<3)return t;throw new ValueError(`Unsupported input rank by biasAdd: ${t.rank}`)}function biasAdd(e,t,n){return tidy(()=>(null==n&&(n=imageDataFormat()),checkDataFormat(n),add$2(e,reshapeBias(e.rank,t,n))))}function elu$3(e,t=1){if(1!==t)throw new NotImplementedError(`Support for alpha values other than 1 (${t}) is not implemented yet.`);return elu$4(e)}function softsign(e){return tidy(()=>div$1(e,add$2(abs$2(e),1)))}function dropout$1(e,t,n,r){return tidy(()=>dropout$2(e,t,n,r))}function hardSigmoid(e){return tidy(()=>{const t=add$2(.5,mul(.2,e));return clipByValue$1(t,0,1)})}function inTrainPhase(e,t,n=!1){return n?e():t()}const VALID_FAN_MODE_VALUES=["fanIn","fanOut","fanAvg"],VALID_DISTRIBUTION_VALUES=["normal","uniform","truncatedNormal"];function checkFanMode(e){checkStringTypeUnionValue(VALID_FAN_MODE_VALUES,"FanMode",e)}function checkDistribution(e){checkStringTypeUnionValue(VALID_DISTRIBUTION_VALUES,"Distribution",e)}class Initializer extends Serializable{fromConfigUsesCustomObjects(){return!1}getConfig(){return{}}}class Zeros extends Initializer{apply(e,t){return zeros$2(e,t)}}Zeros.className="Zeros",registerClass(Zeros);class Ones extends Initializer{apply(e,t){return ones$1(e,t)}}Ones.className="Ones",registerClass(Ones);class Constant extends Initializer{constructor(e){if(super(),"object"!=typeof e)throw new ValueError(`Expected argument of type ConstantConfig but got ${e}`);if(void 0===e.value)throw new ValueError(`config must have value set but got ${e}`);this.value=e.value}apply(e,t){return tidy(()=>mul(scalar(this.value),ones$1(e,t)))}getConfig(){return{value:this.value}}}Constant.className="Constant",registerClass(Constant);class RandomUniform extends Initializer{constructor(e){super(),this.DEFAULT_MINVAL=-.05,this.DEFAULT_MAXVAL=.05,this.minval=e.minval||this.DEFAULT_MINVAL,this.maxval=e.maxval||this.DEFAULT_MAXVAL,this.seed=e.seed}apply(e,t){return randomUniform$1(e,this.minval,this.maxval,t)}getConfig(){return{minval:this.minval,maxval:this.maxval,seed:this.seed}}}RandomUniform.className="RandomUniform",registerClass(RandomUniform);class RandomNormal extends Initializer{constructor(e){super(),this.DEFAULT_MEAN=0,this.DEFAULT_STDDEV=.05,this.mean=e.mean||this.DEFAULT_MEAN,this.stddev=e.stddev||this.DEFAULT_STDDEV,this.seed=e.seed}apply(e,t){if("float32"!==(t=t||"float32")&&"int32"!==t)throw new NotImplementedError(`randomNormal does not support dType ${t}.`);return randomNormal$1(e,this.mean,this.stddev,t,this.seed)}getConfig(){return{mean:this.mean,stddev:this.stddev,seed:this.seed}}}RandomNormal.className="RandomNormal",registerClass(RandomNormal);class TruncatedNormal extends Initializer{constructor(e){super(),this.DEFAULT_MEAN=0,this.DEFAULT_STDDEV=.05,this.mean=e.mean||this.DEFAULT_MEAN,this.stddev=e.stddev||this.DEFAULT_STDDEV,this.seed=e.seed}apply(e,t){if("float32"!==(t=t||"float32")&&"int32"!==t)throw new NotImplementedError(`truncatedNormal does not support dType ${t}.`);return truncatedNormal$1(e,this.mean,this.stddev,t,this.seed)}getConfig(){return{mean:this.mean,stddev:this.stddev,seed:this.seed}}}TruncatedNormal.className="TruncatedNormal",registerClass(TruncatedNormal);class Identity extends Initializer{constructor(e){super(),this.gain=null!=e.gain?e.gain:1}apply(e,t){return tidy(()=>{if(2!==e.length||e[0]!==e[1])throw new ValueError("Identity matrix initializer can only be used for 2D square matrices.");return mul(this.gain,eye(e[0]))})}getConfig(){return{gain:this.gain}}}function computeFans(e,t="channelsLast"){let n,r;if(checkDataFormat(t),2===e.length)n=e[0],r=e[1];else if(-1!==[3,4,5].indexOf(e.length)){if("channelsFirst"===t){const t=arrayProd(e,2);n=e[1]*t,r=e[0]*t}else if("channelsLast"===t){const t=arrayProd(e,0,e.length-2);n=e[e.length-2]*t,r=e[e.length-1]*t}}else{const t=arrayProd(e);n=Math.sqrt(t),r=Math.sqrt(t)}return[n,r]}Identity.className="Identity",registerClass(Identity);class VarianceScaling extends Initializer{constructor(e){if(super(),e.scale<0)throw new ValueError(`scale must be a positive float. Got: ${e.scale}`);this.scale=null==e.scale?1:e.scale,this.mode=null==e.mode?"fanIn":e.mode,checkFanMode(this.mode),this.distribution=null==e.distribution?"normal":e.distribution,checkDistribution(this.distribution),this.seed=e.seed}apply(e,t){const n=computeFans(e),r=n[0],a=n[1];let s=this.scale;if(s/="fanIn"===this.mode?Math.max(1,r):"fanOut"===this.mode?Math.max(1,a):Math.max(1,(r+a)/2),"normal"===this.distribution){const n=Math.sqrt(s);if("float32"!==(t=t||"float32")&&"int32"!==t)throw new NotImplementedError(`${this.getClassName()} does not support dType ${t}.`);return truncatedNormal$1(e,0,n,t,this.seed)}{const n=Math.sqrt(3*s);return randomUniform$1(e,-n,n,t)}}getConfig(){return{scale:this.scale,mode:this.mode,distribution:this.distribution,seed:this.seed}}}VarianceScaling.className="VarianceScaling",registerClass(VarianceScaling);class GlorotUniform extends VarianceScaling{constructor(e){super({scale:1,mode:"fanAvg",distribution:"uniform",seed:null==e?null:e.seed})}getClassName(){return VarianceScaling.className}}GlorotUniform.className="GlorotUniform",registerClass(GlorotUniform);class GlorotNormal extends VarianceScaling{constructor(e){super({scale:1,mode:"fanAvg",distribution:"normal",seed:null==e?null:e.seed})}getClassName(){return VarianceScaling.className}}GlorotNormal.className="GlorotNormal",registerClass(GlorotNormal);class HeNormal extends VarianceScaling{constructor(e){super({scale:2,mode:"fanIn",distribution:"normal",seed:null==e?null:e.seed})}getClassName(){return VarianceScaling.className}}HeNormal.className="HeNormal",registerClass(HeNormal);class HeUniform extends VarianceScaling{constructor(e){super({scale:2,mode:"fanIn",distribution:"uniform",seed:null==e?null:e.seed})}getClassName(){return VarianceScaling.className}}HeUniform.className="HeUniform",registerClass(HeUniform);class LeCunNormal extends VarianceScaling{constructor(e){super({scale:1,mode:"fanIn",distribution:"normal",seed:null==e?null:e.seed})}getClassName(){return VarianceScaling.className}}LeCunNormal.className="LeCunNormal",registerClass(LeCunNormal);class LeCunUniform extends VarianceScaling{constructor(e){super({scale:1,mode:"fanIn",distribution:"uniform",seed:null==e?null:e.seed})}getClassName(){return VarianceScaling.className}}LeCunUniform.className="LeCunNormal",registerClass(LeCunUniform);class Orthogonal extends Initializer{constructor(e){if(super(),this.DEFAULT_GAIN=1,this.gain=null==e.gain?this.DEFAULT_GAIN:e.gain,this.seed=e.seed,null!=this.seed)throw new NotImplementedError("Random seed is not implemented for Orthogonal Initializer yet.")}apply(e,t){return tidy(()=>{if(e.length<2)throw new NotImplementedError("Shape must be at least 2D.");e[0]*e[1]>2e3&&console.warn(`Orthogonal initializer is being called on a matrix with more than 2000 (${e[0]*e[1]}) elements: Slowness may result.`);const t=randomNormal$1(e[0]>e[1]?[e[1],e[0]]:e,0,1,"float32");let n=linalg.gramSchmidt(t);return e[0]>e[1]&&(n=transpose$2(n)),mul(this.gain,n)})}getConfig(){return{gain:this.gain,seed:this.seed}}}Orthogonal.className="Orthogonal",registerClass(Orthogonal);const INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP={constant:"Constant",glorotNormal:"GlorotNormal",glorotUniform:"GlorotUniform",heNormal:"HeNormal",heUniform:"HeUniform",identity:"Identity",leCunNormal:"LeCunNormal",leCunUniform:"LeCunUniform",ones:"Ones",orthogonal:"Orthogonal",randomNormal:"RandomNormal",randomUniform:"RandomUniform",truncatedNormal:"TruncatedNormal",varianceScaling:"VarianceScaling",zeros:"Zeros"};function deserializeInitializer(e,t={}){return deserializeKerasObject(e,SerializationMap.getMap().classNameMap,t,"initializer")}function serializeInitializer(e){return serializeKerasObject(e)}function getInitializer(e){if("string"==typeof e){const t=e in INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP?INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP[e]:e;if("GlorotNormal"===t)return new GlorotNormal;if("GlorotUniform"===t)return new GlorotUniform;if("HeNormal"===t)return new HeNormal;if("HeUniform"===t)return new HeUniform;if("LeCunNormal"===t)return new LeCunNormal;if("LeCunUniform"===t)return new LeCunUniform;{const e={};return e.className=t,e.config={},deserializeInitializer(e)}}return e instanceof Initializer?e:deserializeInitializer(e)}function zeros$1(){return new Zeros}function ones(){return new Ones}function constant(e){return new Constant(e)}function randomUniform(e){return new RandomUniform(e)}function randomNormal(e){return new RandomNormal(e)}function truncatedNormal(e){return new TruncatedNormal(e)}function identity$2(e){return new Identity(e)}function varianceScaling(e){return new VarianceScaling(e)}function glorotUniform(e){return new GlorotUniform(e)}function glorotNormal(e){return new GlorotNormal(e)}function heNormal(e){return new HeNormal(e)}function heUniform(e){return new HeUniform(e)}function leCunNormal(e){return new LeCunNormal(e)}function leCunUniform(e){return new LeCunUniform(e)}function orthogonal(e){return new Orthogonal(e)}var exports_initializers={__proto__:null,zeros:zeros$1,ones,constant,randomUniform,randomNormal,truncatedNormal,identity:identity$2,varianceScaling,glorotUniform,glorotNormal,heNormal,heUniform,leCunNormal,leCunUniform,orthogonal};let _nextUniqueTensorId=0;function getNextUniqueTensorId(){return _nextUniqueTensorId++}const _uidPrefixes={};function getUid(e=""){return e in _uidPrefixes||(_uidPrefixes[e]=0),_uidPrefixes[e]+=1,e+_uidPrefixes[e].toString()}function isArrayOfShapes(e){return Array.isArray(e)&&Array.isArray(e[0])}function normalizeShapeList(e){return 0===e.length?[]:Array.isArray(e[0])?e:[e]}function getExactlyOneTensor(e){let t;if(Array.isArray(e)){if(1!==e.length)throw new ValueError(`Expected Tensor length to be 1; got ${e.length}`);t=e[0]}else t=e;return t}function getExactlyOneShape(e){if(Array.isArray(e)&&Array.isArray(e[0])){if(1===e.length)return(e=e)[0];throw new ValueError(`Expected exactly 1 Shape; got ${e.length}`)}return e}function countParamsInWeights(e){let t=0;for(const n of e)t+=0===n.shape.length?1:n.shape.reduce((e,t)=>e*t);return t}const DEFAULT_VARIABLE_NAME_PREFIX="Variable";class LayerVariable{constructor(e,t="float32",n=DEFAULT_VARIABLE_NAME_PREFIX,r=!0,a=null){this.dtype=null==t?"float32":t,this.shape=e.shape,this.id=getNextUniqueTensorId(),this.originalName=getScopedTensorName(n=null==n?DEFAULT_VARIABLE_NAME_PREFIX:n),this.name=getUniqueTensorName(this.originalName),this.trainable_=r,this.constraint=a,this.val=variable(e,this.trainable_,this.name,this.dtype)}read(){return this.assertNotDisposed(),this.val}write(e){return this.assertNotDisposed(),checkShapesMatch(this.val,e),this.val.id!==e.id&&(this.val.assign(e),null!=this.constraint&&this.val.assign(this.constraint.apply(this.val))),this}dispose(){this.assertNotDisposed(),this.val.dispose()}assertNotDisposed(){if(this.val.isDisposed)throw new Error(`LayersVariable ${this.name} is already disposed.`)}get trainable(){return this.trainable_}set trainable(e){this.trainable_=e,this.val.trainable=e}}function checkShapesMatch(e,t){if(e.shape.toString()!==t.shape.toString())throw new Error("Shape mismatch: "+JSON.stringify(e.shape)+" vs. "+JSON.stringify(t.shape))}function batchGetValue(e){return e.map(e=>e.read())}function batchSetValue(e){e.forEach(e=>{e[0].write(e[1])})}class InputSpec{constructor(e){this.dtype=e.dtype,this.shape=e.shape,this.ndim=null!=e.shape?e.shape.length:e.ndim,this.maxNDim=e.maxNDim,this.minNDim=e.minNDim,this.axes=e.axes||{}}}class SymbolicTensor{constructor(e,t,n,r,a,s,o){this.dtype=e,this.shape=t,this.sourceLayer=n,this.inputs=r,this.callArgs=a,this.outputTensorIndex=o,this.id=getNextUniqueTensorId(),null!=s&&(this.originalName=getScopedTensorName(s),this.name=getUniqueTensorName(this.originalName)),this.rank=t.length}}let _nextNodeID=0;class Node{constructor(e,t){this.callArgs=t,this.id=_nextNodeID++,this.outboundLayer=e.outboundLayer,this.inboundLayers=e.inboundLayers,this.nodeIndices=e.nodeIndices,this.tensorIndices=e.tensorIndices,this.inputTensors=e.inputTensors,this.outputTensors=e.outputTensors,this.inputMasks=e.inputMasks,this.outputMasks=e.outputMasks,this.inputShapes=e.inputShapes,this.outputShapes=e.outputShapes;for(const t of e.inboundLayers)null!=t&&t.outboundNodes.push(this);e.outboundLayer.inboundNodes.push(this)}getConfig(){const e=[];for(const t of this.inboundLayers)e.push(null!=t?t.name:null);return{outboundLayer:this.outboundLayer?this.outboundLayer.name:null,inboundLayers:e,nodeIndices:this.nodeIndices,tensorIndices:this.tensorIndices}}}let _nextLayerID=0;class Layer extends Serializable{constructor(e={}){super(),this._callHook=null,this._addedWeightNames=[],this._stateful=!1,this.id=_nextLayerID++,this.activityRegularizer=null,this.inputSpec=null,this.supportsMasking=!1,this._trainableWeights=[],this._nonTrainableWeights=[],this._losses=[],this._updates=[],this._built=!1,this.inboundNodes=[],this.outboundNodes=[];let t=e.name;if(!t){const e=this.getClassName();t=toSnakeCase(e)+"_"+getUid(e)}if(this.name=t,this.trainable_=null==e.trainable||e.trainable,null!=e.inputShape||null!=e.batchInputShape){let t;if(null!=e.batchInputShape)t=e.batchInputShape;else if(null!=e.inputShape){let n=null;null!=e.batchSize&&(n=e.batchSize),t=[n].concat(e.inputShape)}this.batchInputShape=t;let n=e.dtype;null==n&&(n=e.inputDType),null==n&&(n="float32"),this.dtype=n}this.initialWeights=null!=e.weights?e.weights:null,this._refCount=null,this.fastWeightInitDuringBuild=!1}static nodeKey(e,t){return e.name+"_ib-"+t.toString()}getNodeAtIndex(e,t){if(0===this.inboundNodes.length)throw new RuntimeError(`The layer has never been called and thus has no defined ${t}.`);if(this.inboundNodes.length<=e)throw new ValueError(`Asked to get ${t} at node ${e}, but the layer has only ${this.inboundNodes.length} inbound nodes.`);return this.inboundNodes[e]}getInputAt(e){return singletonOrArray(this.getNodeAtIndex(e,"input").inputTensors)}getOutputAt(e){return singletonOrArray(this.getNodeAtIndex(e,"output").outputTensors)}get input(){if(this.inboundNodes.length>1)throw new AttributeError(`Layer ${this.name} has multiple inbound nodes, hence the notion of "layer input" is ill-defined. Use \`getInputAt(nodeIndex)\` instead.`);if(0===this.inboundNodes.length)throw new AttributeError(`Layer ${this.name} is not connected, no input to return.`);return singletonOrArray(this.getNodeAtIndex(0,"input").inputTensors)}get output(){if(0===this.inboundNodes.length)throw new AttributeError(`Layer ${this.name} has no inbound nodes.`);if(this.inboundNodes.length>1)throw new AttributeError(`Layer ${this.name} has multiple inbound nodes, hence the notion of "layer output" is ill-defined. Use \`getOutputAt(nodeIndex)\` instead.`);return singletonOrArray(this.getNodeAtIndex(0,"output").outputTensors)}get losses(){return this._losses}calculateLosses(){return this.losses.map(e=>e())}get updates(){return this._updates}get built(){return this._built}set built(e){this._built=e}get trainable(){return this.trainable_}set trainable(e){this._trainableWeights.forEach(t=>t.trainable=e),this.trainable_=e}get trainableWeights(){return this.trainable_?this._trainableWeights.filter(e=>e.trainable):[]}set trainableWeights(e){this._trainableWeights=e}get nonTrainableWeights(){return this.trainable?this._trainableWeights.filter(e=>!e.trainable).concat(this._nonTrainableWeights):this._trainableWeights.concat(this._nonTrainableWeights)}set nonTrainableWeights(e){this._nonTrainableWeights=e}get weights(){return this.trainableWeights.concat(this.nonTrainableWeights)}get stateful(){return this._stateful}resetStates(){if(!this.stateful)throw new Error("Cannot call the resetStates() method of a non-stateful Layer object.")}assertInputCompatibility(e){if(e=toList(e),null==this.inputSpec||0===this.inputSpec.length)return;const t=toList(this.inputSpec);if(e.length!==t.length)throw new ValueError(`Layer ${this.name} expects ${t.length} inputs, but it received ${e.length} input tensors. Input received: ${e}`);for(let n=0;n<e.length;n++){const r=e[n],a=t[n];if(null==a)continue;const s=r.rank;if(null!=a.ndim&&s!==a.ndim)throw new ValueError(`Input ${n} is incompatible with layer ${this.name}: expected ndim=${a.ndim}, found ndim=${s}`);if(null!=a.maxNDim&&s>a.maxNDim)throw new ValueError(`Input ${n} is incompatible with layer ${this.name}: expected max_ndim=${a.maxNDim}, found ndim=${s}`);if(null!=a.minNDim&&s<a.minNDim)throw new ValueError(`Input ${n} is incompatible with layer ${this.name}: expected min_ndim=${a.minNDim}, found ndim=${s}.`);if(null!=a.dtype&&r.dtype!==a.dtype)throw new ValueError(`Input ${n} is incompatible with layer ${this.name} : expected dtype=${a.dtype}, found dtype=${r.dtype}.`);if(a.axes){const e=r.shape;for(const t in a.axes){const r=Number(t),s=a.axes[t],o=r>=0?e[r]:e[e.length+r];if(null!=s&&-1===[s,null].indexOf(o))throw new ValueError(`Input ${n} is incompatible with layer ${this.name}: expected axis ${r} of input shape to have value ${s} but got shape ${e}.`)}}if(null!=a.shape)for(let e=0;e<a.shape.length;++e){const t=a.shape[e],s=r.shape[e];if(null!=t&&null!=s&&t!==s)throw new ValueError(`Input ${n} is incompatible with layer ${this.name}: expected shape=${a.shape}, found shape=${r.shape}.`)}}}call(e,t){return e}invokeCallHook(e,t){null!=this._callHook&&this._callHook(e,t)}setCallHook(e){this._callHook=e}clearCallHook(){this._callHook=null}apply(e,t){t=t||{},this.assertNotDisposed();const n=toList(e);let r=!0;for(const e of n)if(!(e instanceof SymbolicTensor)){r=!1;break}let a=!0;for(const e of n)if(e instanceof SymbolicTensor){a=!1;break}if(r===a)throw new ValueError("Arguments to apply() must be all SymbolicTensors or all Tensors");return nameScope(this.name,()=>{if(!this.built){this.assertInputCompatibility(e);const t=[];for(const n of toList(e))t.push(n.shape);this.build(singletonOrArray(t)),this.built=!0,this.initialWeights&&this.setWeights(this.initialWeights),null===this._refCount&&a&&(this._refCount=1)}if(this.assertInputCompatibility(e),a){let r=this.call(e,t);const a=toList(r),s=[];for(let e of a)-1!==n.indexOf(e)&&(e=e.clone()),s.push(e);if(r=singletonOrArray(s),null!=this.activityRegularizer)throw new NotImplementedError("Layer invocation in the presence of activity regularizer(s) is not supported yet.");return r}{const n=collectInputShape(e),r=this.computeOutputShape(n);let a;const s=guessOutputDType(e);if(this.warnOnIncompatibleInputShape(Array.isArray(e)?n[0]:n),a=null!=r&&r.length>0&&Array.isArray(r[0])?r.map((n,r)=>new SymbolicTensor(s,n,this,toList(e),t,this.name,r)):new SymbolicTensor(s,r,this,toList(e),t,this.name),this.addInboundNode(e,a,null,null,n,r,t),this._refCount++,null!=this.activityRegularizer)throw new NotImplementedError("Layer invocation in the presence of activity regularizer(s) is not supported yet.");return a}})}warnOnIncompatibleInputShape(e){if(null!=this.batchInputShape)if(e.length!==this.batchInputShape.length)console.warn(`The rank of the input tensor provided (shape: ${JSON.stringify(e)}) does not match that of the batchInputShape (${JSON.stringify(this.batchInputShape)}) of the layer ${this.name}`);else{let t=!1;this.batchInputShape.forEach((n,r)=>{null!=n&&null!=e[r]&&e[r]!==n&&(t=!0)}),t&&console.warn(`The shape of the input tensor (${JSON.stringify(e)}) does not match the expectation of layer ${this.name}: ${JSON.stringify(this.batchInputShape)}`)}}get outputShape(){if(null==this.inboundNodes||0===this.inboundNodes.length)throw new AttributeError(`The layer ${this.name} has never been called and thus has no defined output shape.`);const e=[];for(const t of this.inboundNodes){const n=JSON.stringify(t.outputShapes);-1===e.indexOf(n)&&e.push(n)}if(1===e.length){const e=this.inboundNodes[0].outputShapes;return Array.isArray(e)&&Array.isArray(e[0])&&1===e.length?e[0]:e}throw new AttributeError(`The layer ${this.name} has multiple inbound nodes with different output shapes. Hence the notion of "output shape" is ill-defined for the layer.`)}countParams(){if(!this.built)throw new RuntimeError(`You tried to call countParams() on ${this.name}, but the layer is not built yet. Build it first by calling build(batchInputShape).`);return countParamsInWeights(this.weights)}build(e){this.built=!0}getWeights(e=!1){return batchGetValue(e?this.trainableWeights:this.weights)}setWeights(e){tidy(()=>{const t=this.weights;if(t.length!==e.length)throw new ValueError(`You called setWeights(weights) on layer "${this.name}" with a weight list of length ${e.length}, but the layer was expecting ${t.length} weights. Provided weights: ${e}...`);if(0===t.length)return;const n=[],r=batchGetValue(t);for(let a=0;a<r.length;++a){const s=r[a],o=t[a],i=e[a];if(!arraysEqual(s.shape,i.shape))throw new ValueError(`Layer weight shape ${s.shape} not compatible with provided weight shape ${i.shape}`);n.push([o,i])}batchSetValue(n)})}addWeight(e,t,n,r,a,s,o){if(-1!==this._addedWeightNames.indexOf(e))throw new ValueError(`Duplicate weight name ${e} for layer ${this.name}`);this._addedWeightNames.push(e),null==n&&(n="float32"),this.fastWeightInitDuringBuild&&(r=getInitializer("zeros"));const i=r.apply(t,n),l=new LayerVariable(i,n,e,s,o);return i.dispose(),null!=a&&this.addLoss(()=>a.apply(l.read())),null==s&&(s=!0),s?this._trainableWeights.push(l):this._nonTrainableWeights.push(l),l}setFastWeightInitDuringBuild(e){this.fastWeightInitDuringBuild=e}addLoss(e){null==e||Array.isArray(e)&&0===e.length||(e=toList(e),null!=this._losses&&this.losses.push(...e))}computeOutputShape(e){return e}computeMask(e,t){if(!this.supportsMasking){if(null!=t){if(!Array.isArray(t))throw new TypeError(`Layer ${this.name} does not support masking, but was passed an inputMask.`);t.forEach(e=>{if(null!=e)throw new TypeError(`Layer ${this.name} does not support masking, but was passed an inputMask.`)})}return null}return t}addInboundNode(e,t,n,r,a,s,o=null){const i=toList(e);t=toList(t),n=toList(n),r=toList(r),a=normalizeShapeList(a),s=normalizeShapeList(s);const l=[],u=[],c=[];for(const e of i)l.push(e.sourceLayer),u.push(e.nodeIndex),c.push(e.tensorIndex);new Node({outboundLayer:this,inboundLayers:l,nodeIndices:u,tensorIndices:c,inputTensors:i,outputTensors:t,inputMasks:n,outputMasks:r,inputShapes:a,outputShapes:s},o);for(let e=0;e<t.length;e++)t[e].sourceLayer=this,t[e].nodeIndex=this.inboundNodes.length-1,t[e].tensorIndex=e}getConfig(){const e={name:this.name,trainable:this.trainable};return null!=this.batchInputShape&&(e.batchInputShape=this.batchInputShape),null!=this.dtype&&(e.dtype=this.dtype),e}disposeWeights(){return this.weights.forEach(e=>e.dispose()),this.weights.length}assertNotDisposed(){if(0===this._refCount)throw new Error(`Layer '${this.name}' is already disposed.`)}dispose(){if(!this.built)throw new Error(`Cannot dispose Layer ${this.name} because it has not been built yet.`);if(null===this._refCount)throw new Error(`Cannot dispose Layer ${this.name} because it has not been used yet.`);this.assertNotDisposed();let e=0;return 0==--this._refCount&&(e=this.disposeWeights()),{refCountAfterDispose:this._refCount,numDisposedVariables:e}}}function collectInputShape(e){e=toList(e);const t=[];for(const n of e)t.push(n.shape);return singletonOrArray(t)}function guessOutputDType(e){return"float32"}function getSourceInputs(e,t,n){if((null==t||null!=n&&n>0)&&(t=e.sourceLayer,n=e.nodeIndex),0===t.inboundNodes.length)return[e];{const e=t.inboundNodes[n];if(0===e.inboundLayers.length)return e.inputTensors;{const t=[];for(let n=0;n<e.inboundLayers.length;n++){const r=getSourceInputs(e.inputTensors[n],e.inboundLayers[n],e.nodeIndices[n]);for(const e of r)-1===t.indexOf(e)&&t.push(e)}return t}}}class InputLayer extends Layer{constructor(e){if(super({dtype:e.dtype,name:null!=e.name?e.name:getUid("input").toString()}),null==e.batchSize&&(e.batchSize=null),null==e.sparse&&(e.sparse=!1),this.trainable=!1,this.built=!0,this.sparse=e.sparse,null!=e.inputShape&&null!=e.batchInputShape)throw new ValueError("Only provide the inputShape OR batchInputShape argument to inputLayer, not both at the same time.");let t=e.batchInputShape;if(null==t){if(null==e.inputShape)throw new ValueError("An InputLayer should be passed either a `batchInputShape` or an `inputShape`.");t=[e.batchSize].concat(e.inputShape)}else if(null!=e.batchSize)throw new ValueError("Cannot specify batchSize if batchInputShape is specified when creating an InputLayer.");const n=e.dtype||"float32";this.batchInputShape=t,this.dtype=n,this.inputSpec=[{shape:t}];const r=new SymbolicTensor(this.dtype,this.batchInputShape,this,[],{},this.name);r.nodeIndex=0,r.tensorIndex=0,new Node({outboundLayer:this,inboundLayers:[],nodeIndices:[],tensorIndices:[],inputTensors:[r],outputTensors:[r],inputMasks:[null],outputMasks:[null],inputShapes:[t],outputShapes:[t]})}apply(e,t){throw new ValueError(`Cannot pass any input to an InputLayer's apply() method. InputLayer name: ${this.name}`)}dispose(){return{refCountAfterDispose:this._refCount,numDisposedVariables:0}}getConfig(){return{batchInputShape:this.batchInputShape,dtype:this.dtype,sparse:this.sparse,name:this.name}}}function Input(e){if(null==e.batchShape&&null==e.shape)throw new Error("Please provide to Input either a `shape` or a `batchShape` argument. Note that `shape` does not include the batch dimension.");if(null!=e.batchShape&&null!=e.shape)throw new ValueError("Please provide either a `shape` or `batchShape` argument to Input, but not both.");let t=e.batchShape;null!=e.shape&&null==t&&(t=[null].concat(e.shape));let n=e.dtype;return null==n&&(n="float32"),new InputLayer({batchInputShape:t,name:e.name,dtype:n,sparse:e.sparse}).inboundNodes[0].outputTensors[0]}async function resolveScalarsInLogs(e){if(null==e)return;const t=[],n=[],r=[];for(const a in e){const s=e[a];if("number"!=typeof s){const e=s;t.push(e.data()),n.push(a),r.push(e)}}if(t.length>0){const a=await Promise.all(t);for(let t=0;t<a.length;++t)e[n[t]]=a[t][0];dispose(r)}}function disposeTensorsInLogs(e){if(null!=e)for(const t in e){const n=e[t];"number"!=typeof n&&n.dispose()}}var ModelLoggingVerbosity;InputLayer.className="InputLayer",registerClass(InputLayer),function(e){e[e.SILENT=0]="SILENT",e[e.VERBOSE=1]="VERBOSE"}(ModelLoggingVerbosity||(ModelLoggingVerbosity={}));const DEFAULT_YIELD_EVERY_MS=125;class BaseCallback{constructor(){this.validationData=null}setParams(e){this.params=e}async onEpochBegin(e,t){}async onEpochEnd(e,t){}async onBatchBegin(e,t){}async onBatchEnd(e,t){}async onTrainBegin(e){}async onTrainEnd(e){}setModel(e){}}class CallbackList{constructor(e,t=10){null==e&&(e=[]),this.callbacks=e,this.queueLength=t}append(e){this.callbacks.push(e)}setParams(e){for(const t of this.callbacks)t.setParams(e)}setModel(e){for(const t of this.callbacks)t.setModel(e)}async onEpochBegin(e,t){null==t&&(t={});for(const n of this.callbacks)await n.onEpochBegin(e,t)}async onEpochEnd(e,t){null==t&&(t={});for(const n of this.callbacks)await n.onEpochEnd(e,t)}async onBatchBegin(e,t){null==t&&(t={});for(const n of this.callbacks)await n.onBatchBegin(e,t)}async onBatchEnd(e,t){null==t&&(t={});for(const n of this.callbacks)await n.onBatchEnd(e,t)}async onTrainBegin(e){null==e&&(e={});for(const t of this.callbacks)await t.onTrainBegin(e)}async onTrainEnd(e){null==e&&(e={});for(const t of this.callbacks)await t.onTrainEnd(e)}}class BaseLogger extends BaseCallback{constructor(){super()}async onEpochBegin(e){this.seen=0,this.totals={}}async onBatchEnd(e,t){null==t&&(t={});const n=null==t.size?0:t.size;this.seen+=n;for(const e in t){const r=t[e];if("number"==typeof r)this.totals.hasOwnProperty(e)||(this.totals[e]=0),this.totals[e]=this.totals[e]+r*n;else{let t;e in this.totals?t=this.totals[e]:this.totals[e]=0;const a=tidy(()=>add$2(this.totals[e],mul(r,n)));this.totals[e]=a,null!=t&&t.dispose()}}}async onEpochEnd(e,t){if(null!=t)for(const e of this.params.metrics)null!=this.totals[e]&&("number"==typeof this.totals[e]?t[e]=this.totals[e]/this.seen:tidy(()=>{const n=mul(div$1(1,this.seen),this.totals[e]);t[e]=n,this.totals[e].dispose(),keep(t[e])}))}}class History extends BaseCallback{async onTrainBegin(e){this.epoch=[],this.history={}}async onEpochEnd(e,t){null==t&&(t={}),this.epoch.push(e);for(const e in t)null==this.history[e]&&(this.history[e]=[]),this.history[e].push(t[e])}async syncData(){const e=[],t=[],n=[];for(const r in this.history){const a=this.history[r];for(let s=0;s<a.length;++s)"number"!=typeof a[s]&&(e.push(a[s].data()),t.push(r),n.push(s))}const r=await Promise.all(e);for(let e=0;e<r.length;++e)this.history[t[e]][n[e]].dispose(),this.history[t[e]][n[e]]=r[e][0]}}class CustomCallback extends BaseCallback{constructor(e,t){if(super(),this.currentEpoch=0,this.yieldEvery=t||"auto","auto"===this.yieldEvery&&(this.yieldEvery=DEFAULT_YIELD_EVERY_MS),"never"===this.yieldEvery&&null!=e.onYield)throw new Error("yieldEvery is `never` but you provided an `onYield` callback. Either change `yieldEvery` or remove the callback");isNumber(this.yieldEvery)&&(this.maybeWait=debounce(this.maybeWait.bind(this),this.yieldEvery)),this.trainBegin=e.onTrainBegin,this.trainEnd=e.onTrainEnd,this.epochBegin=e.onEpochBegin,this.epochEnd=e.onEpochEnd,this.batchBegin=e.onBatchBegin,this.batchEnd=e.onBatchEnd,this.yield=e.onYield}async maybeWait(e,t,n){const r=[];null!=this.yield&&(await resolveScalarsInLogs(n),r.push(this.yield(e,t,n))),r.push(nextFrame()),await Promise.all(r)}async onEpochBegin(e,t){this.currentEpoch=e,null!=this.epochBegin&&(await resolveScalarsInLogs(t),await this.epochBegin(e,t))}async onEpochEnd(e,t){const n=[];null!=this.epochEnd&&(await resolveScalarsInLogs(t),n.push(this.epochEnd(e,t))),"epoch"===this.yieldEvery&&n.push(nextFrame()),await Promise.all(n)}async onBatchBegin(e,t){null!=this.batchBegin&&(await resolveScalarsInLogs(t),await this.batchBegin(e,t))}async onBatchEnd(e,t){const n=[];null!=this.batchEnd&&(await resolveScalarsInLogs(t),n.push(this.batchEnd(e,t))),"batch"===this.yieldEvery?n.push(nextFrame()):isNumber(this.yieldEvery)&&n.push(this.maybeWait(this.currentEpoch,e,t)),await Promise.all(n)}async onTrainBegin(e){null!=this.trainBegin&&(await resolveScalarsInLogs(e),await this.trainBegin(e))}async onTrainEnd(e){null!=this.trainEnd&&(await resolveScalarsInLogs(e),await this.trainEnd(e))}}function standardizeCallbacks(e,t){return null==e&&(e={}),e instanceof BaseCallback?[e]:Array.isArray(e)&&e[0]instanceof BaseCallback?e:toList(e).map(e=>new CustomCallback(e,t))}class CallbackConstructorRegistry{constructor(){}static registerCallbackConstructor(e,t){assert$4(e>=0&&Number.isInteger(e),()=>`Verbosity level is expected to be an integer >= 0, but got ${e}`),CallbackConstructorRegistry.checkForDuplicate(t),null==CallbackConstructorRegistry.constructors[e]&&(CallbackConstructorRegistry.constructors[e]=[]),CallbackConstructorRegistry.constructors[e].push(t)}static checkForDuplicate(e){for(const t in CallbackConstructorRegistry.constructors)CallbackConstructorRegistry.constructors[+t].forEach(t=>{if(t===e)throw new ValueError("Duplicate callback constructor.")})}static clear(){CallbackConstructorRegistry.constructors={}}static createCallbacks(e){const t=[];for(const n in CallbackConstructorRegistry.constructors){const r=+n;e>=r&&t.push(...CallbackConstructorRegistry.constructors[r])}return t.map(e=>new e)}}function configureCallbacks(e,t,n,r,a,s,o,i,l){const u=new History,c=[new BaseLogger,...CallbackConstructorRegistry.createCallbacks(t)];null!=e&&c.push(...e),c.push(u);const p=new CallbackList(c);return p.setParams({epochs:n,initialEpoch:r,samples:a,steps:s,batchSize:o,verbose:t,doValidation:i,metrics:l}),{callbackList:p,history:u}}function deserialize(e,t={},n=!1){return deserializeKerasObject(e,SerializationMap.getMap().classNameMap,t,"layer",n)}function l2Normalize(e,t){return tidy(()=>{"float32"!==e.dtype&&(e=cast$3(e,"float32"));const n=sum$2(square$1(e),t,!0),r=fill$2(n.shape,epsilon$1()),a=sqrt$2(maximum$3(n,r));return div$1(e,a)})}function meanSquaredError$1(e,t){return tidy(()=>mean$1(square$1(sub$2(t,e)),-1))}function meanAbsoluteError$1(e,t){return tidy(()=>mean$1(abs$2(sub$2(t,e)),-1))}function meanAbsolutePercentageError$1(e,t){return tidy(()=>{const n=sub$2(e,t),r=clipByValue$1(abs$2(e),epsilon$1(),Number.MAX_VALUE),a=abs$2(div$1(n,r));return mul(100,mean$1(a,-1))})}function meanSquaredLogarithmicError(e,t){return tidy(()=>{const n=clipByValue$1(t,epsilon$1(),Number.MAX_VALUE),r=log$3(add$2(1,n)),a=clipByValue$1(e,epsilon$1(),Number.MAX_VALUE),s=log$3(add$2(1,a));return mean$1(square$1(sub$2(r,s)),-1)})}function squaredHinge(e,t){return tidy(()=>{const n=maximum$3(0,sub$2(1,mul(e,t)));return mean$1(square$1(n),-1)})}function hinge(e,t){return tidy(()=>{const n=maximum$3(0,sub$2(1,mul(e,t)));return mean$1(n,-1)})}function categoricalHinge(e,t){return tidy(()=>{const n=sum$2(mul(e,t),-1),r=max$3(mul(sub$2(1,e),t),-1);return maximum$3(0,add$2(1,sub$2(r,n)))})}function logcosh(e,t){return tidy(()=>{const n=Math.log(2),r=sub$2(t,e),a=sub$2(add$2(r,softplus$2(mul(-2,r))),n);return mean$1(a,-1)})}function categoricalCrossentropy$2(e,t,n=!1){return tidy(()=>{if(n)t=softmax$3(t);else{const e=sum$2(t,t.shape.length-1,!0);t=div$1(t,e)}return t=clipByValue$1(t,epsilon$1(),1-epsilon$1()),neg$2(sum$2(mul(cast$3(e,"float32"),log$3(t)),t.shape.length-1))})}function sparseCategoricalCrossentropy$1(e,t,n=!1){return tidy(()=>{const r=cast$3(floor$2(flatten$2(e)),"int32"),a=(t=clipByValue$1(t,epsilon$1(),1-epsilon$1())).shape;return categoricalCrossentropy$2(reshape$3(oneHot$2(r,a[a.length-1]),a),t,n)})}function sigmoidCrossEntropyWithLogits(e,t){if(!arraysEqual(e.shape,t.shape))throw new ValueError(`logits and labels must have the same shape, but got shapes ${JSON.stringify(e.shape)} and ${JSON.stringify(t.shape)}`);return tidy(()=>{const n=relu$3(t),r=neg$2(abs$2(t));return add$2(sub$2(n,mul(t,e)),log1p$2(exp$2(r)))})}function binaryCrossentropy$2(e,t){return tidy(()=>{let n;return n=clipByValue$1(t,epsilon$1(),1-epsilon$1()),n=log$3(div$1(n,sub$2(1,n))),mean$1(sigmoidCrossEntropyWithLogits(e,n),-1)})}function kullbackLeiblerDivergence(e,t){return tidy(()=>{const n=clipByValue$1(e,epsilon$1(),1),r=clipByValue$1(t,epsilon$1(),1);return sum$2(mul(e,log$3(div$1(n,r))),-1)})}function poisson(e,t){return tidy(()=>{const n=log$3(add$2(epsilon$1(),t));return mean$1(sub$2(t,mul(e,n)),-1)})}function cosineProximity$1(e,t){return tidy(()=>{const n=l2Normalize(e,-1),r=l2Normalize(t,-1),a=mul(n,r);return neg$2(sum$2(a,-1))})}CallbackConstructorRegistry.constructors={};const lossesMap={meanSquaredError:meanSquaredError$1,meanAbsoluteError:meanAbsoluteError$1,meanAbsolutePercentageError:meanAbsolutePercentageError$1,meanSquaredLogarithmicError,squaredHinge,hinge,categoricalHinge,logcosh,categoricalCrossentropy:categoricalCrossentropy$2,sparseCategoricalCrossentropy:sparseCategoricalCrossentropy$1,binaryCrossentropy:binaryCrossentropy$2,kullbackLeiblerDivergence,poisson,cosineProximity:cosineProximity$1};function get$1(e){if("string"==typeof e){if(e in lossesMap)return lossesMap[e];let t=`Unknown loss ${e}`;throw e.toLowerCase().includes("softmaxcrossentropy")&&(t=`Unknown loss ${e}. Use "categoricalCrossentropy" as the string name for tf.losses.softmaxCrossEntropy`),new ValueError(t)}return e}function binaryAccuracy$1(e,t){return tidy(()=>{const n=mul(.5,onesLike$2(t)),r=cast$2(greater$3(t,n),e.dtype);return mean$1(equal$2(e,r),-1)})}function categoricalAccuracy$1(e,t){return tidy(()=>cast$2(equal$2(argMax$2(e,-1),argMax$2(t,-1)),"float32"))}function truePositives(e,t){return tidy(()=>cast$3(sum$2(logicalAnd$2(equal$2(e,1),equal$2(t,1))),"float32"))}function falseNegatives(e,t){return tidy(()=>cast$3(sum$2(logicalAnd$2(equal$2(e,1),equal$2(t,0))),"float32"))}function falsePositives(e,t){return tidy(()=>cast$3(sum$2(logicalAnd$2(equal$2(e,0),equal$2(t,1))),"float32"))}function precision$1(e,t){return tidy(()=>{const n=truePositives(e,t),r=falsePositives(e,t),a=add$2(n,r);return cast$3(where(greater$3(a,0),div$1(n,a),0),"float32")})}function recall$1(e,t){return tidy(()=>{const n=truePositives(e,t),r=falseNegatives(e,t),a=add$2(n,r);return cast$3(where(greater$3(a,0),div$1(n,a),0),"float32")})}function binaryCrossentropy$1(e,t){return binaryCrossentropy$2(e,t)}function sparseCategoricalAccuracy$1(e,t){return e.rank===t.rank&&(e=squeeze(e,[e.rank-1])),(t=argMax$2(t,-1)).dtype!==e.dtype&&(t=cast$3(t,e.dtype)),cast$3(equal$2(e,t),"float32")}const mse$1=meanSquaredError$1,MSE$1=meanSquaredError$1,mae=meanAbsoluteError$1,MAE=meanAbsoluteError$1,mape$1=meanAbsolutePercentageError$1,MAPE$1=meanAbsolutePercentageError$1,categoricalCrossentropy$1=categoricalCrossentropy$2,cosine=cosineProximity$1,sparseCategoricalCrossentropy=sparseCategoricalCrossentropy$1,metricsMap={binaryAccuracy:binaryAccuracy$1,categoricalAccuracy:categoricalAccuracy$1,precision:precision$1,categoricalCrossentropy:categoricalCrossentropy$1,sparseCategoricalCrossentropy,mse:mse$1,MSE:MSE$1,mae,MAE,mape:mape$1,MAPE:MAPE$1,cosine};function get(e){if("string"==typeof e&&e in metricsMap)return metricsMap[e];if("string"!=typeof e&&null!=e)return e;throw new ValueError(`Unknown metric ${e}`)}function getLossOrMetricName(e){if(assert$3(null!==e,`Unknown LossOrMetricFn ${e}`),"string"==typeof e)return e;{let t;for(const n of Object.keys(lossesMap))if(lossesMap[n]===e){t=n;break}if(void 0!==t)return t;for(const n of Object.keys(metricsMap))if(metricsMap[n]===e){t=n;break}return void 0!==t?t:e.name}}function getOptimizer(e){const t={Adagrad:()=>train.adagrad(.01),Adadelta:()=>train.adadelta(1,.95,epsilon$1()),Adam:()=>train.adam(.001,.9,.999,epsilon$1()),Adamax:()=>train.adamax(.002,.9,.999,epsilon$1(),0),RMSProp:()=>train.rmsprop(.001,.9,0,epsilon$1()),SGD:()=>train.sgd(.01)};if(t.adagrad=t.Adagrad,t.adadelta=t.Adadelta,t.adam=t.Adam,t.adamax=t.Adamax,t.rmsprop=t.RMSProp,t.sgd=t.SGD,e in t)return t[e]();throw new ValueError(`Unknown Optimizer ${e}`)}const MAX_USER_DEFINED_METADATA_SERIALIZED_LENGTH=1048576;function checkUserDefinedMetadata(e,t,n=!1){if(null==e||"object"!=typeof e||Object.getPrototypeOf(e)!==Object.prototype||!plainObjectCheck(e))throw new Error("User-defined metadata is expected to be a JSON object, but is not.");if(n){const n=JSON.stringify(e);n.length>MAX_USER_DEFINED_METADATA_SERIALIZED_LENGTH&&console.warn(`User-defined metadata of model "${t}" is too large in size (length=${n.length} when serialized). It is not recommended to store such large objects in user-defined metadata. Please make sure its serialized length is <= ${MAX_USER_DEFINED_METADATA_SERIALIZED_LENGTH}.`)}}function plainObjectCheck(e){if(null===e)return!0;if("object"==typeof e){if(Object.getPrototypeOf(e)===Object.prototype){const t=Object.keys(e);for(const n of t){if("string"!=typeof n)return!1;if(!plainObjectCheck(e[n]))return!1}return!0}if(Array.isArray(e)){for(const t of e)if(!plainObjectCheck(t))return!1;return!0}return!1}{const t=typeof e;return"string"===t||"number"===t||"boolean"===t}}function printSummary(e,t,n,r=console.log){const a=isModelSequentialLike(e),s=["Layer (type)","Output shape","Param #"];let o;if(a?(t=t||65,n=n||[.45,.85,1]):(t=t||98,n=n||[.33,.55,.67,1]),n[n.length-1]<=1&&(n=n.map(e=>Math.floor(t*e))),!a){s.push("Receives inputs"),o=[];for(const t in e.nodesByDepth)o.push(...e.nodesByDepth[t])}r("_".repeat(t)),printRow(s,n,r),r("=".repeat(t));const i=e.layers;for(let e=0;e<i.length;++e)a?printLayerSummary(i[e],n,r):printLayerSummaryWithConnections(i[e],n,o,r),r((e===i.length-1?"=":"_").repeat(t));e.checkTrainableWeightsConsistency();const l=countTrainableParams(e),u=countParamsInWeights(e.nonTrainableWeights);r(`Total params: ${l+u}`),r(`Trainable params: ${l}`),r(`Non-trainable params: ${u}`),r("_".repeat(t))}function countTrainableParams(e){let t;return t=countParamsInWeights(null!=e.collectedTrainableWeights?e.collectedTrainableWeights:e.trainableWeights),t}function isModelSequentialLike(e){let t=!0;const n=[],r=[];for(const t in e.nodesByDepth)n.push(e.nodesByDepth[t]);for(const e of n){if(e.length>1||1===e.length&&e[0].inboundLayers.length>1){t=!1;break}r.push(...e)}if(t)for(const n of e.layers){let e=!1;for(const a of n.inboundNodes)if(-1!==r.indexOf(a)){if(e){t=!1;break}e=!0}if(!t)break}return t}function printRow(e,t,n=console.log){let r="";for(let n=0;n<e.length;++n)n>0&&(r=r.slice(0,r.length-1)+" "),r+=e[n],r=r.slice(0,t[n]),r+=" ".repeat(t[n]-r.length);n(r)}function printLayerSummary(e,t,n){let r;try{r=JSON.stringify(e.outputShape)}catch(e){r="multiple"}printRow([`${e.name} (${e.getClassName()})`,r,e.countParams().toString()],t,n)}function printLayerSummaryWithConnections(e,t,n,r){let a;try{a=JSON.stringify(e.outputShape)}catch(e){a="multiple"}const s=[];for(const t of e.inboundNodes)if(!(null!=n&&n.length>0&&-1===n.indexOf(t)))for(let e=0;e<t.inboundLayers.length;++e)s.push(`${t.inboundLayers[e].name}[${t.nodeIndices[e]}][${t.tensorIndices[e]}]`);const o=e.name,i=e.getClassName(),l=0===s.length?"":s[0];printRow([`${o} (${i})`,a,e.countParams().toString(),l],t,r);for(let e=1;e<s.length;++e)printRow(["","","",s[e]],t,r)}function isArrayItemInputOrOutputName(e,t,n){return("inboundNodes"===e||"outputLayers"===e||"inputLayers"===e)&&0===t&&"string"==typeof n}function convertPythonicToTs(e,t){if(null===e)return null;if("string"==typeof e)return toCamelCase(e);if("number"==typeof e||"boolean"==typeof e)return e;if(e instanceof Array){const n=[],r=e.length;for(let a=0;a<r;++a){const r=e[a];isArrayItemInputOrOutputName(t,a,r)?n.push(r):n.push(convertPythonicToTs(r,t))}return n}{const t={};for(const n of Object.keys(e)){const r=e[n];if("name"===n&&"string"==typeof r)t[n]=r;else{const e=toCamelCase(n);t[e]=convertPythonicToTs(r,e)}}return t}}function convertTsToPythonic(e,t){if(null==e)return null;if("string"==typeof e)return toSnakeCase(e);if("number"==typeof e||"boolean"==typeof e)return e;if(e instanceof Array){const n=[],r=e.length;for(let a=0;a<r;++a){const r=e[a];isArrayItemInputOrOutputName(t,a,r)?n.push(r):n.push(convertTsToPythonic(r,t))}return n}{const t={};for(const n of Object.keys(e)){const r=e[n];t[toSnakeCase(n)]="name"!==n&&"className"!==n||"string"!=typeof r?convertTsToPythonic(r,n):r}return t}}const version$6="3.8.0";function assertFeedCompatibility(e,t){if(null==e.dtype||e.dtype===t.dtype)return t;try{return cast$3(t,e.dtype)}catch(n){throw new ValueError(`The dtype of the feed (${t.dtype}) can not be cast to the dtype of the key '${e.name}' (${e.dtype}).`)}}class FeedDict{constructor(e){if(this.id2Value={},this.id2Mask={},this.name2Id={},e instanceof FeedDict)for(const t in e.id2Value)this.id2Value[t]=e.id2Value[t],t in e.id2Mask&&(this.id2Mask[t]=e.id2Mask[t]);else{if(null==e)return;for(const t of e)this.add(t.key,t.value)}}add(e,t,n){if(null!=this.id2Value[e.id])throw new ValueError(`Duplicate key: name=${e.name}, id=${e.id}`);return this.id2Value[e.id]=assertFeedCompatibility(e,t),this.name2Id[e.name]=e.id,null!=n&&(this.id2Mask[e.id]=n),this}addFeed(e){this.add(e.key,e.value)}hasKey(e){return null!=this.id2Value[e.id]}names(){return Object.keys(this.name2Id)}getValue(e){if(e instanceof SymbolicTensor){if(null==this.id2Value[e.id])throw new ValueError(`Nonexistent key: ${e.name}`);return this.id2Value[e.id]}{const t=this.name2Id[e];if(null==t)throw new ValueError(`Feed dict has no SymbolicTensor name: ${e}`);return this.id2Value[t]}}getMask(e){if(e instanceof SymbolicTensor){if(null==this.id2Value[e.id])throw new ValueError(`Nonexistent key: ${e.name}`);return this.id2Mask[e.id]}{const t=this.name2Id[e];if(null==t)throw new ValueError(`Feed dict has no SymbolicTensor name: ${e}`);return this.id2Mask[t]}}disposeMasks(){null!=this.id2Mask&&dispose(this.id2Mask)}}const cachedSorted={},cachedRecipientCounts={};function execute(e,t,n,r){const a=null!=n&&n.training,s=Array.isArray(e),o=s?e:[e],i=o.map(e=>e.name),l=[],u=t.names();for(const e of i)-1!==u.indexOf(e)?l.push(t.getValue(e)):l.push(null);null!=r&&(r.maxNumTensors=-Infinity,r.minNumTensors=Infinity);const c=i.join(",")+"|"+t.names().join(",");let p,d;if(null==cachedSorted[c]){const e=getTopologicalSortAndRecipientCounts(o,t);p=e.sorted,d=e.recipientCounts,cachedSorted[c]=p,cachedRecipientCounts[c]=d}p=cachedSorted[c],d={},a||Object.assign(d,cachedRecipientCounts[c]);const h=new FeedDict(t);for(let e=0;e<p.length;++e){if(null!=r){const e=memory().numTensors;e>r.maxNumTensors&&(r.maxNumTensors=e),e<r.minNumTensors&&(r.minNumTensors=e)}const s=p[e],o=s.sourceLayer;if(o instanceof InputLayer)continue;const u=[],c=[],m=[];let f=!1;for(const e of s.inputs){const n=h.getValue(e),r=h.getMask(e);u.push(n),c.push(r),null!=r&&(f=!0),a||(d[e.name]--,0!==d[e.name]||t.hasKey(e)||-1!==i.indexOf(e.name)||n.isDisposed||!0===e.sourceLayer.stateful||m.push(n))}f&&((n=n||{}).mask=c[0]);const g=toList(o.apply(u,n));let $=null;o.supportsMasking&&($=o.computeMask(u,c));const y=getNodeOutputs(s),b=Array.isArray(y)?y:[y];for(let e=0;e<b.length;++e){h.hasKey(b[e])||h.add(b[e],g[e],Array.isArray($)?$[0]:$);const t=i.indexOf(b[e].name);-1!==t&&(l[t]=g[e])}a||dispose(m)}return h.disposeMasks(),s?l:l[0]}function getTopologicalSortAndRecipientCounts(e,t){assert$4(null!=e&&e.length>0,()=>"Expected at least one fetch, got none");let n=[],r={};if(1===e.length){const a=getTopologicalSortAndRecipientCountsForOneFetch(e[0],t);n=a.sorted,r=a.recipientMap}else{const a=new Set;for(const s of e){const{sorted:e,recipientMap:o}=getTopologicalSortAndRecipientCountsForOneFetch(s,t);for(const t of e)a.has(t.name)||(n.push(t),a.add(t.name));for(const e in o)null==r[e]&&(r[e]=new Set),o[e].forEach(t=>r[e].add(t))}}return{sorted:n,recipientCounts:recipientMap2Counts(r)}}function recipientMap2Counts(e){const t={};for(const n in e)t[n]=e[n].size;return t}function getTopologicalSortAndRecipientCountsForOneFetch(e,t){const n=new Set,r=[],a={};for(const e of t.names())n.add(e);const s=[],o=[];for(s.push(e);s.length>0;){const e=s[s.length-1];if(n.has(e.name)){s.pop();continue}const t=o[o.length-1]===s.length-1;if(0===e.inputs.length||t)s.pop(),r.push(e),n.add(e.name),t&&o.pop();else{o.push(s.length-1);for(const t of e.inputs)null==a[t.name]&&(a[t.name]=new Set),a[t.name].add(e.name),n.has(t.name)||s.push(t)}}return{sorted:r,recipientMap:a}}function getNodeOutputs(e){let t;if(1===e.sourceLayer.inboundNodes.length)t=e.sourceLayer.output;else{let n=null;for(let t=0;t<e.sourceLayer.inboundNodes.length;++t)for(const r of e.sourceLayer.inboundNodes[t].outputTensors)if(r.id===e.id){n=t;break}t=e.sourceLayer.getOutputAt(n)}return t}class Container extends Layer{constructor(e){if(super({}),this.containerNodes=new Set,this.name=e.name,null==this.name){const e=this.getClassName().toLowerCase();this.name=getUid(e)}if(this.supportsMasking=!1,this.trainable_=!0,this.inputs=Array.isArray(e.inputs)?e.inputs.slice():[e.inputs],this.outputs=Array.isArray(e.outputs)?e.outputs.slice():[e.outputs],unique$2(this.inputs).length!==this.inputs.length)throw new ValueError(`The list of inputs passed to the model is redundant. All inputs should only appear once. Found: ${this.inputs.map(e=>e.name)}`);unique$2(this.outputs).length!==this.outputs.length&&console.warn(`The list of outputs passed to the model is redundant. All outputs should only appear once. Found: ${this.outputs.map(e=>e.name)}`),this.inputLayers=[],this.inputLayersNodeIndices=[],this.inputLayersTensorIndices=[],this.outputLayers=[],this.outputLayersNodeIndices=[],this.outputLayersTensorIndices=[],this.layers=[],this.internalContainerRefs=[];for(const e of this.outputs){const t=e.nodeIndex,n=e.tensorIndex;this.outputLayers.push(e.sourceLayer),this.outputLayersNodeIndices.push(t),this.outputLayersTensorIndices.push(n)}for(const e of this.inputs){const t=e.sourceLayer,n=e.nodeIndex,r=e.tensorIndex;assert$3(0===n,"input layer has >1 nodes"),assert$3(0===r,"input layer has >1 tensors"),this.inputLayers.push(t),this.inputLayersNodeIndices.push(n),this.inputLayersTensorIndices.push(r)}this.inputNames=[],this.outputNames=[],this.feedInputShapes=[],this.feedInputNames=[],this.feedOutputNames=[];for(let t=0;t<this.inputLayers.length;t++){const n=this.inputLayers[t];if(!(n instanceof InputLayer))throw new TypeError(`Input layers to a LayersModel must be InputLayer objects. Received inputs: ${e.inputs}. Input ${t} (0-based) originates from layer type ${n.getClassName()}.`);this.inputNames.push(n.name),this.feedInputShapes.push(n.batchInputShape),this.feedInputNames.push(n.name)}for(const e of this.outputLayers)this.outputNames.push(e.name);this.internalInputShapes=this.inputs.map(e=>e.shape),this.internalOutputShapes=this.outputs.map(e=>e.shape);const t={},n={},r={},a={},s={},o=[],i=(e,t,n,r,a,l)=>{null!=r&&null!=a&&null!=l||(r=e.sourceLayer,a=e.nodeIndex,l=e.tensorIndex);const u=r.inboundNodes[a];if(-1!==n.indexOf(u))throw new RuntimeError(`The tensor ${e.name} at layer "${r.name}" is part of a cycle.`);if(-1!==t.indexOf(u))return;this.containerNodes.add(Container.nodeKey(r,a)),r.id in s||(s[r.id]=Object.keys(s).length),-1===n.indexOf(u)&&n.push(u);const c=u.inboundLayers.length;for(let e=0;e<c;e++)i(u.inputTensors[e],t,n,u.inboundLayers[e],u.nodeIndices[e],u.tensorIndices[e]);for(t.push(u);n.indexOf(u)>=0;)n.splice(n.indexOf(u),1);o.push(u)},l=[],u=[];for(const e of this.outputs)i(e,l,u);const c=o.slice().reverse();for(const e of c){n[e.id]=e,e.id in t||(t[e.id]=0);let s=t[e.id];s=Math.max(s,null==r[e.outboundLayer.id]?0:r[e.outboundLayer.id]),r[e.outboundLayer.id]=s,a[e.outboundLayer.id]=e.outboundLayer,t[e.id]=s;for(let r=0;r<e.inboundLayers.length;r++){const a=e.inboundLayers[r].inboundNodes[e.nodeIndices[r]];t[a.id]=Math.max(s+1,null==t[a.id]?0:t[a.id]),n[a.id]=a}}const p={};for(const e in t){const r=t[e];r in p||(p[r]=[]),p[r].push(n[e])}const d={};for(const e in r){const t=r[e];t in d||(d[t]=[]),d[t].push(a[e])}let h=Object.keys(d).map(e=>parseInt(e,10)).sort(reverseNumberCompare);this.layers=[];for(const e of h){const t=d[e];t.sort((e,t)=>{const n=s[e.id],r=s[t.id];return n<r?-1:n>r?1:0});for(const e of t)e instanceof Container&&this.internalContainerRefs.push(e),this.layers.push(e)}this.layersByDepth=d,h=Object.keys(p).map(e=>parseInt(e,10)).sort(reverseNumberCompare);const m=this.inputs.slice(),f=[];for(const e of h)for(const t of p[e]){const e=t.outboundLayer;if(null!=e){for(const n of t.inputTensors)if(-1===m.indexOf(n))throw new RuntimeError(`Graph disconnected: cannot obtain value for tensor ${n} at layer "${e.name}". The following previous layers were accessed without issue: ${f}`);for(const e of t.outputTensors)m.push(e);f.push(e.name)}}this.nodesByDepth=p;const g=this.layers.map(e=>e.name);for(const e of g){const t=g.filter(t=>t===e).length;if(1!==t)throw new RuntimeError(`The name "${e}" is used ${t} times in the model. All layer names should be unique. Layer names: `+JSON.stringify(g))}this.outboundNodes=[],this.inboundNodes=[],new Node({outboundLayer:this,inboundLayers:[],nodeIndices:[],tensorIndices:[],inputTensors:this.inputs,outputTensors:this.outputs,inputMasks:this.inputs.map(e=>null),outputMasks:this.outputs.map(e=>null),inputShapes:this.inputs.map(e=>e.shape),outputShapes:this.outputs.map(e=>e.shape)}),this.built=!0,this._refCount=1}assertNotDisposed(){if(0===this._refCount)throw new Error(`Container '${this.name}' is already disposed.`)}dispose(){this.assertNotDisposed();const e={refCountAfterDispose:null,numDisposedVariables:0};if(0==--this._refCount){for(const t of this.layers)e.numDisposedVariables+=t.dispose().numDisposedVariables;for(const t of this.internalContainerRefs)e.numDisposedVariables+=t.dispose().numDisposedVariables}return e.refCountAfterDispose=this._refCount,e}get trainable(){return this.trainable_}set trainable(e){this.layers.forEach(t=>{t._trainableWeights.forEach(t=>t.trainable=e)}),this.trainable_=e}get trainableWeights(){if(this._trainableWeights.length>0)throw new ValueError("Container instance unexpectedly contains _trainableWeights.The trainable weights of a Container are a union of the trainable weights of its consituent Layers. Its own _trainableWeights must remain an empty Array.");if(!this.trainable)return[];let e=[];for(const t of this.layers)e=e.concat(t.trainableWeights);return e}get nonTrainableWeights(){const e=[];for(const t of this.layers)e.push(...t.nonTrainableWeights);if(!this.trainable){const t=[];for(const e of this.layers)t.push(...e.trainableWeights);return t.concat(e)}return e}get weights(){return this.trainableWeights.concat(this.nonTrainableWeights)}loadWeights(e,t=!0){const n={};let r=0;for(const e of this.layers)for(const t of e.weights){if(null!=n[t.originalName])throw new ValueError(`Duplicate weight name: ${t.originalName}`);n[t.originalName]=t,r++}const a=[];for(const r in e){let s=r;if(null==n[r]){const e=r.split("/");s=e.slice(0,-2).concat([e[e.length-1]]).join("/")}if(null!=n[s])a.push([n[s],e[r]]);else if(t)throw new ValueError(`Provided weight data has no target variable: ${r}`);delete n[s]}if(t){const e=[];for(const t in n)e.push(t);if(e.length>0)throw new ValueError(`${e.length} of ${r} weights are not set: ${e}`)}batchSetValue(a)}updatedConfig(){const e=this.getConfig(),t={};return t.className=this.getClassName(),t.config=e,t.kerasVersion=`tfjs-layers ${version$6}`,t.backend="TensorFlow.js",t}toJSON(e,t=!0){const n=convertTsToPythonic(this.updatedConfig());return t?JSON.stringify(n):n}call(e,t){return tidy(()=>{e=toList(e);const n=new FeedDict;for(let t=0;t<this.inputs.length;++t)n.add(this.inputs[t],e[t]);return execute(this.outputs,n,t)})}computeMask(e,t){return tidy(()=>{let n;return e=toList(e),n=null==t?pyListRepeat(null,e.length):toList(t),this.runInternalGraph(e,n)[1]})}computeOutputShape(e){const t=normalizeShapeList(e);if(t.length!==this.inputLayers.length)throw new ValueError(`Invalid inputShape argument ${e}: model has ${this.inputLayers.length} tensor inputs.`);const n={};for(let e=0;e<t.length;e++)n[this.inputLayers[e].name+"_0_0"]=t[e];const r=Object.keys(this.nodesByDepth).map(e=>parseInt(e,10)).sort(reverseNumberCompare);if(r.length>1)for(const e of r){const t=this.nodesByDepth[e];for(const e of t){const t=e.outboundLayer;if(-1!==this.inputLayers.map(e=>e.id).indexOf(t.id))continue;const r=[];for(let t=0;t<e.inboundLayers.length;t++)r.push(n[`${e.inboundLayers[t].name}_${e.nodeIndices[t]}_${e.tensorIndices[t]}`]);const a=normalizeShapeList(t.computeOutputShape(singletonOrArray(r))),s=t.inboundNodes.indexOf(e);for(let e=0;e<a.length;e++)n[`${t.name}_${s}_${e}`]=a[e]}}const a=[],s=[];for(let e=0;e<this.outputLayers.length;e++)s.push(`${this.outputLayers[e].name}_${this.outputLayersNodeIndices[e]}_${this.outputLayersTensorIndices[e]}`);for(let e=0;e<s.length;e++){const t=s[e];assert$3(t in n),a.push(n[t])}return singletonOrArray(a)}runInternalGraph(e,t){null==t&&(t=pyListRepeat(null,e.length));const n={};for(let r=0;r<this.inputs.length;++r)n[this.inputs[r].id]=[e[r],t[r]];const r=Object.keys(this.nodesByDepth).map(e=>parseInt(e,10)).sort(reverseNumberCompare);for(const e of r){const t=this.nodesByDepth[e];for(const e of t){const t=e.outboundLayer,r=e.inputTensors,a=e.outputTensors,s=new Array;for(const e of r)e.id in n&&s.push(n[e.id]);if(s.length===r.length){let r,o,i,l,u={};if(null!=e.callArgs&&(u=e.callArgs),1===s.length){const[e,n]=s[0];null==u.mask&&(u.mask=n),i=toList(t.call(e,u)),l=toList(t.computeMask(e,n)),r=[e],o=[n]}else r=s.map(e=>e[0]),o=s.map(e=>e[1]),null==u.mask&&(u.mask=o),i=toList(t.call(r,u)),l=toList(t.computeMask(r,o));if(t.activityRegularizer)throw new NotImplementedError("LayersModel invocation with concrete Tensor value(s) in the presence of activity regularizer(s) is not supported yet.");for(let e=0;e<a.length;++e)n[a[e].id]=[i[e],l[e]]}}}const a=[],s=[],o=[];for(const e of this.outputs){assert$3(e.id in n,`Could not compute output ${e.name} : ${e.id}`);const[t,r]=n[e.id];o.push(t.shape),a.push(t),s.push(r)}return[a,s,o]}buildNodeConversionMap(e){const t={};let n;for(const e of this.layers){n=e instanceof Container?1:0;for(let r=0;r<e.inboundNodes.length;r++){const a=Container.nodeKey(e,r);this.containerNodes.has(a)&&(t[a]=n,n+=1)}}return t}getLayer(e,t){if(null!=t){if(this.layers.length<=t)throw new ValueError(`Was asked to retrieve layer at index ${t}, but model only has ${this.layers.length} layer(s).`);return this.layers[t]}if(null==e)throw new ValueError("Provide either a layer name or layer index");for(const t of this.layers)if(t.name===e)return t;throw new ValueError(`No such layer: ${e}`)}calculateLosses(){return tidy(()=>{const e=[];for(const t of this.layers)for(let n=0;n<t.inboundNodes.length;++n){const r=Container.nodeKey(t,n);this.containerNodes.has(r)&&e.push(...t.calculateLosses())}return e})}getConfig(){const e={name:this.name},t=this.buildNodeConversionMap(this.layers),n=[];for(const e of this.layers){const r=e.getClassName(),a=e.getConfig(),s=[];for(let n=0;n<e.inboundNodes.length;n++){const r=e.inboundNodes[n],a=Container.nodeKey(e,n);let o={};if(this.containerNodes.has(a)){if(r.callArgs)try{JSON.stringify(r.callArgs),o=r.callArgs}catch(t){console.warn(`Layer ${e.name} was passed non-serializable keyword arguments: ${r.callArgs}. They will not be included in the serialized model (and thus will be missing at deserialization time).`),o={}}if(r.inboundLayers.length>0){const e=[];for(let n=0;n<r.inboundLayers.length;n++){const a=r.inboundLayers[n],s=r.tensorIndices[n];let i=t[Container.nodeKey(a,r.nodeIndices[n])];null==i&&(i=0),e.push([a.name,i,s,o])}s.push(e)}}}const o={};o.name=e.name,o.className=r,o.config=a,o.inboundNodes=s,n.push(o)}e.layers=n;const r=[];for(let e=0;e<this.inputLayers.length;e++){const n=this.inputLayers[e],a=Container.nodeKey(n,this.inputLayersNodeIndices[e]);if(!this.containerNodes.has(a))continue;let s=t[a];null==s&&(s=0),r.push([n.name,s,this.inputLayersTensorIndices[e]])}e.inputLayers=r;const a=[];for(let e=0;e<this.outputLayers.length;e++){const n=this.outputLayers[e],r=Container.nodeKey(n,this.outputLayersNodeIndices[e]);if(!this.containerNodes.has(r))continue;let s=t[r];null==s&&(s=0),a.push([n.name,s,this.outputLayersTensorIndices[e]])}return e.outputLayers=a,e}static fromConfig(e,t,n={},r=!1){const a={},s={};function o(e,t){e.name in s?s[e.name].push(t):s[e.name]=[t]}function i(e,t){const n=[];let r;for(const s of t){const i=s[0],l=s[1],u=s[2];if(r=null==s[3]?{}:s[3],!(i in a))return void o(e,t);const c=a[i];if(c.inboundNodes.length<=l)return void o(e,t);n.push(c.inboundNodes[l].outputTensors[u])}n.length>0&&e.apply(singletonOrArray(n),r)}function l(e){const n=e.name,s=deserialize(e,null!=t.customObjects?t.customObjects:{});s.setFastWeightInitDuringBuild(r),a[n]=s,e.inboundNodes.forEach(e=>{if(!(e instanceof Array))throw new ValueError(`Corrupted configuration, expected array for nodeData: ${e}`);o(s,e)})}const u=t.name,c=t.layers;for(const e of c)l(e);for(;!isObjectEmpty(s);)for(const e of c){const t=a[e.name];if(t.name in s){const e=s[t.name];delete s[t.name];for(const n of e)i(t,n)}}const p=[],d=[],h=t.inputLayers;for(const e of h){const t=e[0],n=e[1],r=e[2];assert$3(t in a),p.push(a[t].inboundNodes[n].outputTensors[r])}const m=t.outputLayers;for(const e of m){const t=e[0],n=e[1],r=e[2];assert$3(t in a),d.push(a[t].inboundNodes[n].outputTensors[r])}return new e({inputs:p,outputs:d,name:u})}get stateful(){if(this._stateful)throw new ValueError("Container instance unexpectedly has _stateful = true. The statefulness of a Container is determined by the Layers it contains. Its _stateful property must remain the default false.");for(const e of this.layers)if(e.stateful)return!0;return!1}resetStates(){tidy(()=>{this.layers.forEach(e=>{e.stateful&&e.resetStates()})})}}function standardizeSampleOrClassWeights(e,t,n){const r=t.length;if(null==e||Array.isArray(e)&&0===e.length)return t.map(e=>null);if(1===r)return Array.isArray(e)&&1===e.length?e:"object"==typeof e&&t[0]in e?[e[t[0]]]:[e];if(Array.isArray(e)){if(e.length!==r)throw new Error(`Provided ${n} is an array of ${e.length} element(s), but the model has ${r} outputs. Make sure a set of weights is provided for each model output.`);return e}if("object"==typeof e&&Object.keys(e).length>0&&"object"==typeof e[Object.keys(e)[0]]){const n=[];return t.forEach(t=>{n.push(t in e?e[t]:null)}),n}throw new Error(`The model has multiple (${r}) outputs, so ${n} must be either an array with ${r} elements or an object with ${t} keys. Provided ${n} not understood: ${JSON.stringify(e)}`)}function standardizeClassWeights(e,t){return standardizeSampleOrClassWeights(e,t,"classWeight")}async function standardizeWeights(e,t,n,r){if(null!=t||null!=r)throw new Error("Support sampleWeight is not implemented yet");if(null!=n){const t=tidy(()=>{if(1===e.shape.length)return clone(e);if(2===e.shape.length){if(e.shape[1]>1)return argMax$2(e,1);if(1===e.shape[1])return reshape$3(e,[e.shape[0]]);throw new Error(`Encountered unexpected last-dimension size (${e.shape[1]}) during handling of class weights. The size is expected to be >= 1.`)}throw new Error(`Unexpected rank of target (y) tensor (${e.rank}) during handling of class weights. The rank is expected to be 1 or 2.`)}),r=Array.from(await t.data());dispose(t);const a=[];return r.forEach(e=>{if(null==n[e])throw new Error(`classWeight must contain all classes in the training data. The class ${e} exists in the data but not in classWeight`);a.push(n[e])}),tensor1d(a,"float32")}return null}function computeWeightedLoss(e,t){return mul(e,t)}const DEFAULT_VALIDATION_BATCH_SIZE=32;function standardizeDataIteratorOutput(e,t){let n,r;n=t.xs,r=t.ys,assert$4(null!=n&&null!=r,()=>`A Dataset iterator for fitDataset() is expected to generate objects of the form \`{xs: xVal, ys: yVal}\`, where the two values may be \`tf.Tensor\`, an array of Tensors, or a map of string to Tensor.  The provided Dataset instead generates ${t}`);const a=flattenTensorOrArrayOrMap("input",e.inputNames,n),s=flattenTensorOrArrayOrMap("output",e.outputNames,r),o=a[0].shape[0];assert$4(a.length===e.inputs.length,()=>`LayersModel has ${e.inputs.length} inputs, but the dataset provides ${a.length} inputs.  (Expected input keys: ${JSON.stringify(e.inputNames)})`),assert$4(s.length===e.outputs.length,()=>`LayersModel has ${e.outputs.length} outputs, but the dataset provides ${s.length} outputs.  (Expected output keys: ${JSON.stringify(e.outputNames)})`);for(let t=0;t<a.length;t++)assert$4(a[t].shape[0]===o,()=>`Batch size mismatch: input ${e.inputNames[t]} has ${a[t].shape[0]}; expected  ${o} based on input ${e.inputNames[0]}.`);for(let t=0;t<s.length;t++)assert$4(s[t].shape[0]===o,()=>`Batch size mismatch: output ${e.outputNames[t]} has ${s[t].shape[0]}; expected  ${o} based on input ${e.inputNames[0]}.`);return{xs:a,ys:s}}function flattenTensorOrArrayOrMap(e,t,n){if(n instanceof Tensor)return[n];if(Array.isArray(n))return assert$4(n.length===t.length,()=>`Received an array of ${n.length} Tensors, but expected ${t.length} to match the ${e} keys ${t}.`),n;{const r=[];for(const a of t){if(null==n[a])throw new ValueError(`The feature data generated by the dataset lacks the required ${e} key '${a}'.`);r.push(n[a])}return r}}function standardizeTensorValidationData(e){if(3===e.length)throw new NotImplementedError("Validation with sample weights is not implemented yet.");return{xs:e[0],ys:e[1]}}async function fitDataset(e,t,n){const r=null!=n.batchesPerEpoch;if(assert$4(null!=e.optimizer,()=>"You must compile a model before training/testing. Use LayersModel.compile(modelCompileConfig)."),assert$4(null!=n,()=>"For fitDataset(), the 2nd argument (config) is required, but it is not provided in this call."),assert$4(null!=n.epochs&&n.epochs>0&&Number.isInteger(n.epochs),()=>`For fitDataset(), config.epochs is expected to be a positive integer, but got ${n.epochs}`),assert$4(!r||n.batchesPerEpoch>0&&Number.isInteger(n.batchesPerEpoch),()=>`For fitDataset(), config.batchesPerEpoch is expected to be a positive integer if specified, but got ${n.batchesPerEpoch}`),assert$4(null==n.validationSplit,()=>"`validationSplit` is not supported by `fitDataset()`. Use validationData instead."),e.isTraining)throw new Error("Cannot start training because another fit() call is ongoing.");e.isTraining=!0;try{const a=null!=n.validationData;let s,o;if(a)if(isDatasetObject(n.validationData))assert$4(null==n.validationBatches||n.validationBatches>0&&Number.isInteger(n.validationBatches),()=>`For fitDataset() with dataset-based validation, config.validationBatches is expected not to be provided, or to be a positive integer, but got ${n.validationBatches}`);else{const e=standardizeTensorValidationData(n.validationData);s=e.xs,o=e.ys}const i=e.makeTrainFunction(),l=e.getDedupedMetricsNames();let u;u=a?l.slice().concat(l.map(e=>"val_"+e)):l.slice();const c=standardizeCallbacks(n.callbacks,n.yieldEvery),p=null==n.verbose?1:n.verbose,{callbackList:d,history:h}=configureCallbacks(c,p,n.epochs,null,null,getStepsPerEpoch(t,n),null,a,u);d.setModel(e),e.history=h,await d.onTrainBegin(),e.stopTraining_=!1;let m=null==n.initialEpoch?0:n.initialEpoch,f=await t.iterator();for(;m<n.epochs;){const u={};await d.onEpochBegin(m);let c=0,p=0;for(r||(f=await t.iterator());!r||c<n.batchesPerEpoch;){const t=await f.next();if(r&&t.done){console.warn(`You provided \`batchesPerEpoch\` as ${n.batchesPerEpoch}, but your dataset iterator ran out of data after ${c} batches; interrupting training. Make sure that your dataset can generate at least \`batchesPerEpoch * epochs\` batches (in this case, `+n.batchesPerEpoch*n.epochs+" batches). You may need to use the repeat() function when building your dataset.");break}if(null!=t.value){const{xs:r,ys:a}=standardizeDataIteratorOutput(e,t.value),s={};s.batch=p,s.size=r[0].shape[0],await d.onBatchBegin(p,s);const o=[];if(null!=n.classWeight){const t=standardizeClassWeights(n.classWeight,e.outputNames);for(let e=0;e<t.length;++e)o.push(await standardizeWeights(a[e],null,t[e]))}const u=r.concat(a).concat(o),h=i(u);dispose(u);for(let e=0;e<l.length;++e){const t=h[e];s[l[e]]=t,keep(t)}await d.onBatchEnd(p,s),disposeTensorsInLogs(s),p++,c++}if(r?c>=n.batchesPerEpoch:t.done){if(a){let t;t=isDatasetObject(n.validationData)?toList(await e.evaluateDataset(n.validationData,{batches:n.validationBatches})):toList(e.evaluate(s,o,{batchSize:null==n.validationBatchSize?DEFAULT_VALIDATION_BATCH_SIZE:n.validationBatchSize,verbose:0}));for(let n=0;n<e.metricsNames.length;++n)u[`val_${e.metricsNames[n]}`]=t[n]}break}if(e.stopTraining_)break}if(await d.onEpochEnd(m,u),m++,e.stopTraining_)break}return await d.onTrainEnd(),await e.history.syncData(),e.history}finally{e.isTraining=!1}}function getStepsPerEpoch(e,t){let n=null;return null!=t.batchesPerEpoch?n=t.batchesPerEpoch:Number.isFinite(e.size)&&(n=e.size),n}function isDatasetObject(e){return"function"==typeof e.iterator}function isLazyIteratorObject(e){return"function"==typeof e.next}async function evaluateDataset(e,t,n){const r=null!=(n=n||{}).batches,a=e.testFunction;let s=[];if(n.verbose>0)throw new NotImplementedError("Verbose mode is not implemented yet.");assert$4(!r||n.batches>0&&Number.isInteger(n.batches),()=>`Test loop expects \`batches\` to be a positive integer, but received ${JSON.stringify(n.batches)}`);const o=isLazyIteratorObject(t)?t:await t.iterator();let i=0,l=0;for(;!r||l<n.batches;){const t=await o.next();if(s=tidy(()=>{if(t.value){const{xs:n,ys:r}=standardizeDataIteratorOutput(e,t.value),o=n.concat(r),u=tidy(()=>a(o));if(dispose(o),0===l)for(let e=0;e<u.length;++e)s.push(scalar(0));const c=o[0].shape[0];for(let e=0;e<u.length;++e){const t=u[e],n=s[e];s[e]=tidy(()=>add$2(s[e],mul(c,t))),l>0&&dispose(n)}dispose(u),i+=c,++l}return s}),t.done){r&&console.warn(`Your dataset iterator ran out of data during evaluateDataset(). Interrupting evalution. Make sure that your dataset can generate at least \`batches\` batches (in this case, ${n.batches} batches). You may need to use the repeat() function when building your dataset.`);break}}for(let e=0;e<s.length;++e){const t=s[e];s[e]=div$1(s[e],i),dispose(t)}return singletonOrArray(s)}function checkBatchSize(e){assert$4(e>0&&Number.isInteger(e),()=>`batchSize is required to be a positive integer, but got ${e}`)}function sliceArrays(e,t,n){return null==e?[null]:Array.isArray(e)?e.map(e=>sliceAlongFirstAxis(e,t,n-t)):sliceAlongFirstAxis(e,t,n-t)}function sliceArraysByIndices(e,t){return tidy(()=>null==e?null:Array.isArray(e)?e.map(e=>sliceArraysByIndices(e,t)):gather(e,"int32"===t.dtype?t:cast$3(t,"int32")))}function makeBatches(e,t){const n=[];let r=0,a=null;for(;r<e;)a=r+t,a>=e&&(a=e),n.push([r,a]),r=a;return n}async function fitLoop(e,t,n,r,a,s,o,i,l,u,c,p,d,h,m){null==a&&(a=32),null==s&&(s=1),null==c&&(c=!0),null==d&&(d=0);let f=!1;if(null!=l&&null!=u&&(f=!0),null!=m&&(f=!0,null==h))throw new ValueError("Can only use `validationSteps` when doing step-wise training, i.e., `stepsPerEpoch` must be set.");const g=e.checkNumSamples(n,a,h,"steps_per_epoch");let $;null!=g&&($=range$3(0,g)),null==o&&(o=1);const{callbackList:y,history:b}=configureCallbacks(i,o,s,d,g,h,a,f,p);y.setModel(e),e.history=b,await y.onTrainBegin(),e.stopTraining_=!1;for(let o=d;o<s;++o){await y.onEpochBegin(o);const s={};if(null!=h)throw new NotImplementedError("stepsPerEpoch mode is not implemented yet.");{if("batch"===c)throw new NotImplementedError("batch shuffling is not implemneted yet");c&&shuffle($);const o=tensor1d($),i=makeBatches(g,a);for(let c=0;c<i.length;++c){const p={};if(await y.onBatchBegin(c,p),tidy(()=>{const d=i[c][0],h=i[c][1],m=sliceAlongFirstAxis(o,d,h-d);p.batch=c,p.size=h-d;const g=sliceArraysByIndices(n,m),$=t(g);for(let e=0;e<r.length;++e){const t=$[e];p[r[e]]=t,keep(t)}if(c===i.length-1&&f){const t=e.testLoop(l,u,a);for(let e=0;e<r.length;++e){const n=r[e],a=t[e];keep(a),s["val_"+n]=a}}}),await y.onBatchEnd(c,p),disposeTensorsInLogs(p),e.stopTraining_)break}o.dispose()}if(await y.onEpochEnd(o,s),e.stopTraining_)break}return await y.onTrainEnd(),await e.history.syncData(),e.history}async function fitTensors(e,t,n,r={}){if(e.isTraining)throw new Error("Cannot start training because another fit() call is ongoing.");let a,s,o,i,l,u,c;e.isTraining=!0;try{const p=null==r.batchSize?32:r.batchSize;checkBatchSize(p);const d=!1,h=await e.standardizeUserData(t,n,r.sampleWeight,r.classWeight,d,p);a=h[0],s=h[1],c=h[2];let m,f=!1;if(null!=r.validationData&&r.validationData.length>0){if(f=!0,2!==r.validationData.length)throw 3===r.validationData.length?new NotImplementedError("validationData including sample weights is not supported yet."):new ValueError(`When passing validation data, it must contain 2 (valX, valY) or 3 (valX, valY, valSampleWeight) items; ${r.validationData} is invalid.`);o=r.validationData[0],i=r.validationData[1];const t=!0,n=await e.standardizeUserData(o,i,null,null,t,p);l=n[0],u=n[1],m=l.concat(u)}else if(null!=r.validationSplit&&r.validationSplit>0&&r.validationSplit<1){f=!0;const e=Math.floor(a[0].shape[0]*(1-r.validationSplit)),t=a[0].shape[0];l=sliceArrays(a,e,t),a=sliceArrays(a,0,e),u=sliceArrays(s,e,t),s=sliceArrays(s,0,e),m=l.concat(u)}else null!=r.validationSteps&&(f=!0);const g=a.concat(s).concat(c);e.checkTrainableWeightsConsistency();const $=e.makeTrainFunction(),y=e.getDedupedMetricsNames();let b,x;f?(e.makeTestFunction(),b=e.testFunction,x=y.slice().concat(y.map(e=>"val_"+e))):(b=null,m=[],x=y.slice());const v=standardizeCallbacks(r.callbacks,r.yieldEvery);return await fitLoop(e,$,g,y,p,r.epochs,r.verbose,v,b,m,r.shuffle,x,r.initialEpoch,null,null)}finally{e.isTraining=!1,disposeNewTensors(a,t),disposeNewTensors(s,n),disposeNewTensors(l,o),disposeNewTensors(u,i),null!=c&&dispose(c)}}function ensureTensorsRank2OrHigher(e){const t=[];e instanceof Tensor&&(e=[e]);for(let n=0;n<e.length;++n){const r=e[n];if(1===r.rank)t.push(expandDims$2(r,1));else{if(0===r.rank)throw new Error("Expected tensor to be at least 1D, but received a 0D tensor (scalar).");t.push(r)}}return t}function disposeNewTensors(e,t){if(null==e)return;const n=[];if(t instanceof Tensor)n.push(t.id);else if(Array.isArray(t))t.forEach(e=>n.push(e.id));else if(null!=t)for(const e in t)n.push(t[e].id);const r=[];if(e instanceof Tensor)-1===n.indexOf(e.id)&&r.push(e);else if(Array.isArray(e))e.forEach(e=>{-1===n.indexOf(e.id)&&r.push(e)});else if(null!=e)for(const t in e){const a=e[t];-1===n.indexOf(a.id)&&r.push(a)}r.forEach(e=>{e.isDisposed||e.dispose()})}function isDataTensor(e){return e instanceof Tensor}function isDataArray(e){return Array.isArray(e)}function isDataDict(e){return!isDataTensor(e)&&!isDataArray(e)}function standardizeInputData(e,t,n,r=!0,a=""){if(null==t||0===t.length){if(null!=e){let t=!1;if(isDataArray(e)&&e.length>0)t=!0;else if(isDataDict(e)){for(const n in e)if(e.hasOwnProperty(n)){t=!0;break}}else t=!0;if(t)throw new ValueError(`Error when checking model ${a} expected no data, but got ${e}`)}return[]}if(null==e)return t.map(e=>null);let s;if(isDataDict(e)){e=e,s=[];for(const n of t){if(null==e[n])throw new ValueError(`No data provided for "${n}". Need data for each key in: ${t}`);s.push(e[n])}}else if(isDataArray(e)){if((e=e).length!==t.length)throw new ValueError(`Error when checking model ${a}: the Array of Tensors that you are passing to your model is not the size the model expected. Expected to see ${t.length} Tensor(s), but instead got the following list of Tensor(s): ${e}`);s=e}else{if(e=e,t.length>1)throw new ValueError(`The model ${a} expects ${t.length} Tensor(s), but only received one Tensor. Found: Tensor with shape ${e.shape}`);s=[e]}if(s=ensureTensorsRank2OrHigher(s),null!=n)for(let e=0;e<t.length;++e){if(null==n[e])continue;const o=s[e];if(o.shape.length!==n[e].length)throw new ValueError(`Error when checking ${a}: expected ${t[e]} to have ${n[e].length} dimension(s). but got array with shape ${o.shape}`);for(let s=0;s<n[e].length;++s){if(0===s&&!r)continue;const i=o.shape[s],l=n[e][s];if(null!=l&&l>=0&&i!==l)throw new ValueError(`Error when checking ${a}: expected ${t[e]} to have shape [${n[e]}], but got array with shape [${o.shape}].`)}}return s}function checkArrayLengths(e,t,n){const r=unique$2(e.map(e=>e.shape[0]));r.sort();const a=unique$2(t.map(e=>e.shape[0]));if(a.sort(),r.length>1)throw new ValueError(`All input Tensors (x) should have the same number of samples. Got array shapes: ${JSON.stringify(e.map(e=>e.shape))}`);if(a.length>1)throw new ValueError(`All target Tensors (y) should have the same number of samples. Got array shapes: ${JSON.stringify(t.map(e=>e.shape))}`);if(r.length>0&&a.length>0&&!arraysEqual(r,a))throw new ValueError(`Input Tensors should have the same number of samples as target Tensors. Found ${r[0]} input sample(s) and ${a[0]} target sample(s).`)}function checkLossAndTargetCompatibility(e,t,n){const r=[meanSquaredError$1,binaryCrossentropy$2,categoricalCrossentropy$2];for(let a=0;a<e.length;++a){const s=e[a],o=t[a],i=n[a];if(null!=o){if(o===categoricalCrossentropy$2&&1===s.shape[s.shape.length-1])throw new ValueError(`You are passing a target array of shape ${s.shape} while using a loss 'categorical_crossentropy'. 'categorical_crossentropy'expects targets to be binary matrices (1s and 0s) of shape [samples, classes].`);if(-1!==r.indexOf(o)){const e=s.shape.slice(1),t=i.slice(1);for(let n=0;n<e.length;++n){const r=e[n],a=t[n];if(null!=a&&r!==a)throw new ValueError(`A target Tensor with shape ${s.shape} was passed for an output of shape ${i}, while using a loss function that expects targets to have the same shape as the output.`)}}}}}function checkInputData(e,t,n,r=!0,a=""){let s;if(Array.isArray(e)){if(e.length!==t.length)throw new ValueError(`Error when checking model ${a}: the Array of Tensors that you are passing to your model is not the size the the model expected. Expected to see ${t.length} Tensor(s), but instead got ${e.length} Tensors(s).`);s=e}else{if(t.length>1)throw new ValueError(`The model expects ${t.length} ${a} Tensors, but only received one Tensor. Found: array with shape ${JSON.stringify(e.shape)}.`);s=[e]}if(null!=n)for(let e=0;e<t.length;++e){if(null==n[e])continue;const o=s[e];if(o.shape.length!==n[e].length)throw new ValueError(`Error when checking ${a}: expected ${t[e]} to have ${n[e].length} dimension(s), but got array with shape ${JSON.stringify(o.shape)}`);for(let s=0;s<n[e].length;++s){if(0===s&&!r)continue;const i=o.shape[s],l=n[e][s];if(null!=l&&l!==i)throw new ValueError(`Error when checking ${a}: expected ${t[e]} to have shape ${JSON.stringify(n[e])} but got array with shape ${JSON.stringify(o.shape)}.`)}}}function collectMetrics(e,t){if(null==e||Array.isArray(e)&&0===e.length)return t.map(e=>[]);let n;if("string"==typeof e||"function"==typeof e)n=[e];else{if(!Array.isArray(e)&&"object"!=typeof e)throw new TypeError(`Type of metrics argument not understood. Expected an string,function, Array, or Object, found: ${e}`);n=e}if(Array.isArray(n))return t.map(e=>n);{const e=[];for(const r of t){let t=n.hasOwnProperty(r)?n[r]:[];Array.isArray(t)||(t=[t]),e.push(t)}return e}}const LAYERS_MODEL_FORMAT_NAME="layers-model";class LayersModel extends Container{constructor(e){super(e),this.isTraining=!1}summary(e,t,n=console.log){if(!this.built)throw new ValueError("This model has never been called, thus its weights have not been created yet. So no summary can be displayed. Build the model first (e.g., by calling it on some test data).");printSummary(this,e,t,n)}compile(e){if(null==e.loss&&(e.loss=[]),this.loss=e.loss,"string"==typeof e.optimizer)this.optimizer_=getOptimizer(e.optimizer),this.isOptimizerOwned=!0;else{if(!(e.optimizer instanceof Optimizer))throw new ValueError("User-defined optimizer must be an instance of tf.Optimizer.");this.optimizer_=e.optimizer,this.isOptimizerOwned=!1}let t=[];if(Array.isArray(e.loss)||"string"==typeof e.loss||"function"==typeof e.loss)if(Array.isArray(e.loss)){if(e.loss.length!==this.outputs.length)throw new ValueError(`When passing an Array as loss, it should have one entry per model output. The model has ${this.outputs.length} output(s), but you passed loss=${e.loss}.`);t=e.loss.map(e=>get$1(e))}else{const n=get$1(e.loss);this.outputs.forEach(e=>{t.push(n)})}else{e.loss=e.loss;for(const t in e.loss)if(-1===this.outputNames.indexOf(t))throw new ValueError(`Unknown entry in loss dictionary: "${t}". Only expected the following keys: ${this.outputNames}`);for(const n of this.outputNames)null==e.loss[n]&&console.warn(`Output "${n}" is missing from loss dictionary. We assume this was done on purpose, and we will not be expecting data to be passed to ${n} during training`),t.push(get$1(e.loss[n]))}this.lossFunctions=t,this.feedOutputNames=[],this.feedOutputShapes=[],this.feedLossFns=[];for(let e=0;e<this.outputs.length;++e){const t=this.internalOutputShapes[e];this.feedOutputNames.push(this.outputNames[e]),this.feedOutputShapes.push(t),this.feedLossFns.push(this.lossFunctions[e])}const n=[];this.metrics=e.metrics,this.metricsNames=["loss"],this.metricsTensors=[],nameScope("loss",()=>{for(let e=0;e<this.outputs.length;++e){if(-1!==n.indexOf(e))continue;const t=this.lossFunctions[e];this.outputs.length>1&&(this.metricsTensors.push([t,e]),this.metricsNames.push(this.outputNames[e]+"_loss"))}});const r=collectMetrics(e.metrics,this.outputNames),a=(e,t,n)=>{this.outputNames.length>1&&(t=this.outputNames[e]+"_"+t),this.metricsNames.push(t),this.metricsTensors.push([n,e])};nameScope("metric",()=>{for(let e=0;e<this.outputs.length;++e)-1===n.indexOf(e)&&(t=>{let n,r,s;for(const o of t){if("string"==typeof o&&-1!==["accuracy","acc","crossentropy","ce"].indexOf(o)){const t=this.internalOutputShapes[e];let a;1===t[t.length-1]||this.lossFunctions[e]===binaryCrossentropy$2?-1!==["accuracy","acc"].indexOf(o)?r=binaryAccuracy$1:-1!==["crossentropy","ce"].indexOf(o)&&(r=binaryCrossentropy$1):this.lossFunctions[e]===sparseCategoricalCrossentropy$1?-1!==["accuracy","acc"].indexOf(o)?r=sparseCategoricalAccuracy$1:-1!==["crossentropy","ce"].indexOf(o)&&(r=sparseCategoricalCrossentropy):-1!==["accuracy","acc"].indexOf(o)?r=categoricalAccuracy$1:-1!==["crossentropy","ce"].indexOf(o)&&(r=categoricalCrossentropy$1),-1!==["accuracy","acc"].indexOf(o)?a="acc":-1!==["crossentropy","ce"].indexOf(o)&&(a="ce"),s=r,n=""+a}else{const e=get(o);s=e,n=""+getLossOrMetricName(o)}let t;nameScope(n,()=>{t=s}),a(e,n,t)}})(r[e])}),this.collectedTrainableWeights=this.trainableWeights}checkTrainableWeightsConsistency(){null!=this.collectedTrainableWeights&&this.trainableWeights.length!==this.collectedTrainableWeights.length&&console.warn("Discrepancy between trainableweights and collected trainable weights. Did you set `model.trainable` without calling `model.compile()` afterwards?")}evaluate(e,t,n={}){const r=null==n.batchSize?32:n.batchSize;checkBatchSize(r);const a=this.standardizeUserDataXY(e,t,!0,r);try{const s=a[0].concat(a[1]);return this.makeTestFunction(),singletonOrArray(this.testLoop(this.testFunction,s,r,n.verbose,n.steps))}finally{disposeNewTensors(a[0],e),disposeNewTensors(a[1],t)}}async evaluateDataset(e,t){return this.makeTestFunction(),evaluateDataset(this,e,t)}checkNumSamples(e,t,n,r="steps"){let a;if(null!=n){if(a=null,null!=t)throw new ValueError(`If ${r} is set, batchSize must be null or undefined.Got batchSize = ${t}`)}else{if(null==e)throw new ValueError(`Either the input data should have a defined shape, or ${r} shoud be specified.`);a=Array.isArray(e)?e[0].shape[0]:e.shape[0]}return a}execute(e,t){if(Array.isArray(t)&&0===t.length)throw new ValueError("`outputs` is an empty Array, which is not allowed.");const n=Array.isArray(t),r=this.retrieveSymbolicTensors(n?t:[t]),a=new FeedDict;if(e instanceof Tensor&&(e=[e]),Array.isArray(e)){if(e.length!==this.inputs.length)throw new ValueError(`The number of inputs provided (${e.length}) does not match the number of inputs of this model (${this.inputs.length}).`);for(let t=0;t<this.inputs.length;++t)a.add(this.inputs[t],e[t])}else for(const t of this.inputs){const n=e[t.name];if(null==n)throw new ValueError(`No value is provided for the model's input ${t.name}`);a.add(t,n)}const s=execute(r,a);return n?s:s[0]}retrieveSymbolicTensors(e){const t=pyListRepeat(null,e.length);let n=e.length;for(const r of this.layers){const a=Array.isArray(r.output)?r.output:[r.output],s=a.map(e=>e.name);for(let r=0;r<e.length;++r){const o=s.indexOf(e[r]);if(-1!==o&&(t[r]=a[o],n--),0===n)break}if(0===n)break}if(n>0){const n=[];throw t.forEach((t,r)=>{null==t&&n.push(e[r])}),new ValueError(`Cannot find SymbolicTensors for output name(s): ${JSON.stringify(n)}`)}return t}predictLoop(e,t=32,n=!1){return tidy(()=>{const r=this.checkNumSamples(e);if(n)throw new NotImplementedError("Verbose predictLoop() is not implemented yet.");const a=makeBatches(r,t),s=this.outputs.map(e=>[]);for(let t=0;t<a.length;++t)tidy(()=>{const n=sliceArrays(e,a[t][0],a[t][1]),r=[];if(Array.isArray(n))for(let e=0;e<n.length;++e)r.push({key:this.inputs[e],value:n[e]});else r.push({key:this.inputs[0],value:n});const s=new FeedDict(r);return execute(this.outputs,s)}).forEach((e,t)=>s[t].push(e));return singletonOrArray(s.map(e=>concat$2(e,0)))})}predict(e,t={}){const n=ensureTensorsRank2OrHigher(e);checkInputData(n,this.inputNames,this.feedInputShapes,!1);try{const r=null==t.batchSize?32:t.batchSize;return checkBatchSize(r),this.predictLoop(n,r)}finally{disposeNewTensors(n,e)}}predictOnBatch(e){checkInputData(e,this.inputNames,this.feedInputShapes,!0);const t=(Array.isArray(e)?e[0]:e).shape[0];return this.predictLoop(e,t)}standardizeUserDataXY(e,t,n=!0,r){if(null==this.optimizer_)throw new RuntimeError("You must compile a model before training/testing. Use LayersModel.compile(modelCompileArgs).");const a=[];for(let e=0;e<this.feedOutputShapes.length;++e){const t=this.feedOutputShapes[e];a.push(this.feedLossFns[e]===sparseCategoricalCrossentropy$1?t.slice(0,t.length-1).concat([1]):t)}if(checkArrayLengths(e=standardizeInputData(e,this.feedInputNames,this.feedInputShapes,!1,"input"),t=standardizeInputData(t,this.feedOutputNames,a,!1,"target")),checkLossAndTargetCompatibility(t,this.feedLossFns,this.feedOutputShapes),this.stateful&&null!=r&&r>0&&e[0].shape[0]%r!=0)throw new ValueError(`In a stateful network, you should only pass inputs with a number of samples that is divisible by the batch size ${r}. Found: ${e[0].shape[0]} sample(s).`);return[e,t]}async standardizeUserData(e,t,n,r,a=!0,s){const[o,i]=this.standardizeUserDataXY(e,t,a,s);if(null!=n)throw new Error("sample weight is not supported yet.");let l=null;if(null!=r){const e=standardizeClassWeights(r,this.outputNames);l=[];for(let t=0;t<e.length;++t)l.push(await standardizeWeights(i[t],null,e[t]))}return[o,i,l]}testLoop(e,t,n,r=0,a){return tidy(()=>{const s=this.checkNumSamples(t,n,a,"steps"),o=[];if(r>0)throw new NotImplementedError("Verbose mode is not implemented yet.");if(null!=a)throw new NotImplementedError("steps mode in testLoop() is not implemented yet");{const r=makeBatches(s,n),a=tensor1d(range$3(0,s));for(let n=0;n<r.length;++n){const s=r[n][0],i=r[n][1],l=sliceAlongFirstAxis(a,s,i-s),u=sliceArraysByIndices(t,l),c=e(u);if(0===n)for(let e=0;e<c.length;++e)o.push(scalar(0));for(let e=0;e<c.length;++e)o[e]=add$2(o[e],mul(i-s,c[e]))}for(let e=0;e<o.length;++e)o[e]=div$1(o[e],s)}return o})}getDedupedMetricsNames(){const e=this.metricsNames,t=[];for(let n=0;n<e.length;++n){const r=e[n];let a=r;count(e,r)>1&&(a+=`_${count(e.slice(0,n),r)}`),t.push(a)}return t}makeTrainFunction(){return e=>{const t=[],n=e.slice(0,this.inputs.length),r=e.slice(this.inputs.length,this.inputs.length+this.outputs.length),a=e.slice(this.inputs.length+this.outputs.length,this.inputs.length+2*this.outputs.length),s=[],o=this.collectedTrainableWeights.map(e=>e.read());return[this.optimizer_.minimize(()=>{const e=[];for(let t=0;t<this.inputs.length;++t)e.push({key:this.inputs[t],value:n[t]});const o=new FeedDict(e),i=execute(this.outputs,o,{training:!0});let l;for(let e=0;e<this.lossFunctions.length;++e){let n=(0,this.lossFunctions[e])(r[e],i[e]);null!=a[e]&&(n=computeWeightedLoss(n,a[e]));const s=mean$1(n);t.push(s),l=0===e?n:add$2(l,n)}for(let e=0;e<this.metricsTensors.length;++e){let n;if(this.outputs.length>1&&e<this.outputs.length)n=t[e];else{const t=this.metricsTensors[e][1];n=mean$1((0,this.metricsTensors[e][0])(r[t],i[t]))}keep(n),s.push(n)}return l=mean$1(l),this.calculateLosses().forEach(e=>{l=add$2(l,e)}),l},!0,o)].concat(s)}}makeTestFunction(){this.testFunction=e=>tidy(()=>{const t=[];let n;const r=e.slice(0,this.inputs.length),a=e.slice(this.inputs.length,this.inputs.length+this.outputs.length),s=[];for(let e=0;e<this.inputs.length;++e)s.push({key:this.inputs[e],value:r[e]});const o=new FeedDict(s),i=execute(this.outputs,o);for(let e=0;e<this.lossFunctions.length;++e){const r=mean$1((0,this.lossFunctions[e])(a[e],i[e]));n=0===e?r:add$2(n,r),t.push(n)}for(let e=0;e<this.metricsTensors.length;++e){const n=this.metricsTensors[e][1],r=mean$1((0,this.metricsTensors[e][0])(a[n],i[n]));t.push(r)}return t})}async fit(e,t,n={}){return fitTensors(this,e,t,n)}async fitDataset(e,t){return fitDataset(this,e,t)}async trainOnBatch(e,t){const n=await this.standardizeUserData(e,t),r=n[0],a=n[1],s=this.makeTrainFunction()(r.concat(a)),o=[];for(const e of s){const t=await e.data();o.push(t[0])}return dispose(s),singletonOrArray(o)}getNamedWeights(e){const t=[],n=null!=e&&e.trainableOnly,r=n?this.trainableWeights:this.weights,a=this.getWeights(n);for(let e=0;e<r.length;++e)n&&!r[e].trainable||t.push({name:r[e].originalName,tensor:a[e]});return t}set stopTraining(e){this.stopTraining_=e}get stopTraining(){return this.stopTraining_}get optimizer(){return this.optimizer_}set optimizer(e){this.optimizer_!==e&&(this.optimizer_=e,this.isOptimizerOwned=!1)}dispose(){const e=super.dispose();if(0===e.refCountAfterDispose&&null!=this.optimizer&&this.isOptimizerOwned){const t=memory().numTensors;this.optimizer_.dispose(),e.numDisposedVariables+=t-memory().numTensors}return e}getLossIdentifiers(){let e;if("string"==typeof this.loss)e=toSnakeCase(this.loss);else if(Array.isArray(this.loss)){for(const e of this.loss)if("string"!=typeof e)throw new Error("Serialization of non-string loss is not supported.");e=this.loss.map(e=>toSnakeCase(e))}else{const t=Object.keys(this.loss);e={};const n=this.loss;for(const r of t){if("string"!=typeof n[r])throw new Error("Serialization of non-string loss is not supported.");e[r]=toSnakeCase(n[r])}}return e}getMetricIdentifiers(){if("string"==typeof this.metrics||"function"==typeof this.metrics)return[toSnakeCase(getLossOrMetricName(this.metrics))];if(Array.isArray(this.metrics))return this.metrics.map(e=>toSnakeCase(getLossOrMetricName(e)));{const e={};for(const t in this.metrics)e[t]=toSnakeCase(getLossOrMetricName(this.metrics[t]));return e}}getTrainingConfig(){return{loss:this.getLossIdentifiers(),metrics:this.getMetricIdentifiers(),optimizer_config:{class_name:this.optimizer.getClassName(),config:this.optimizer.getConfig()}}}loadTrainingConfig(e){if(null!=e.weighted_metrics)throw new Error("Loading weight_metrics is not supported yet.");if(null!=e.loss_weights)throw new Error("Loading loss_weights is not supported yet.");if(null!=e.sample_weight_mode)throw new Error("Loading sample_weight_mode is not supported yet.");const t=deserialize(convertPythonicToTs(e.optimizer_config));let n,r;if("string"==typeof e.loss)n=toCamelCase(e.loss);else if(Array.isArray(e.loss))n=e.loss.map(e=>toCamelCase(e));else if(null!=e.loss){n={};for(const t in e.loss)n[t]=toCamelCase(e.loss[t])}if(Array.isArray(e.metrics))r=e.metrics.map(e=>toCamelCase(e));else if(null!=e.metrics){r={};for(const t in e.metrics)r[t]=toCamelCase(e.metrics[t])}this.compile({loss:n,metrics:r,optimizer:t})}async save(e,t){if("string"==typeof e){const t=getSaveHandlers(e);if(0===t.length)throw new ValueError(`Cannot find any save handlers for URL '${e}'`);if(t.length>1)throw new ValueError(`Found more than one (${t.length}) save handlers for URL '${e}'`);e=t[0]}if(null==e.save)throw new ValueError("LayersModel.save() cannot proceed because the IOHandler provided does not have the `save` attribute defined.");const n=await encodeWeights(this.getNamedWeights(t)),r={modelTopology:this.toJSON(null,!1),format:LAYERS_MODEL_FORMAT_NAME,generatedBy:`TensorFlow.js tfjs-layers v${version$6}`,convertedBy:null};if(null!=t&&t.includeOptimizer&&null!=this.optimizer){r.trainingConfig=this.getTrainingConfig();const e="optimizer",{data:t,specs:a}=await encodeWeights(await this.optimizer.getWeights(),e);n.specs.push(...a),n.data=concatenateArrayBuffers([n.data,t])}return null!=this.userDefinedMetadata&&(checkUserDefinedMetadata(this.userDefinedMetadata,this.name,!0),r.userDefinedMetadata=this.userDefinedMetadata),r.weightData=n.data,r.weightSpecs=n.specs,e.save(r)}setUserDefinedMetadata(e){checkUserDefinedMetadata(e,this.name),this.userDefinedMetadata=e}getUserDefinedMetadata(){return this.userDefinedMetadata}}LayersModel.className="Model",registerClass(LayersModel);class Functional extends LayersModel{}async function modelFromJSON(e,t){"modelTopology"in e||(e={modelTopology:e});let n=(e=e).modelTopology;null!=n.model_config&&(n=n.model_config);const r=deserialize(convertPythonicToTs(n),t);if(null!=e.weightsManifest){const t=await loadWeights(e.weightsManifest,e.pathPrefix,r.weights.map(e=>e.originalName)),n={};for(const e of r.weights)n[e.originalName]=t[e.originalName];r.loadWeights(n),dispose(t)}return r}async function loadLayersModelInternal(e,t){if(null==t&&(t={}),"string"==typeof e){const n=getLoadHandlers(e,t);if(0===n.length)n.push(browserHTTPRequest(e,t));else if(n.length>1)throw new ValueError(`Found more than one (${n.length}) load handlers for URL '${e}'`);e=n[0]}return loadLayersModelFromIOHandler(e,void 0,t)}async function loadLayersModelFromIOHandler(e,t,n){if(null==n&&(n={}),null==e.load)throw new ValueError("Cannot proceed with model loading because the IOHandler provided does not have the `load` method implemented.");const r=await e.load();let a=r.modelTopology;null!=a.model_config&&(a=a.model_config);const s=null==n.strict||n.strict,o=null!=r.weightData&&null!=r.weightSpecs&&s,i=deserialize(convertPythonicToTs(a),t,o),l=r.trainingConfig;if(null!=l&&i.loadTrainingConfig(l),null!=r.userDefinedMetadata&&i.setUserDefinedMetadata(r.userDefinedMetadata),null!=r.weightData){if(null==r.weightSpecs)throw new ValueError("LayersModel artifacts contains weight data, but not weight specs. Therefore loading of weights cannot proceed.");const{modelWeights:e,optimizerWeights:t}=decodeModelAndOptimizerWeights(r.weightData,r.weightSpecs);i.loadWeights(e,s),null!=i.optimizer&&t.length>0&&await i.optimizer.setWeights(t),dispose(e),dispose(t.map(e=>e.tensor))}return i}function decodeModelAndOptimizerWeights(e,t){const n=decodeWeights(e,t),r={},a=[];return t.forEach(e=>{"optimizer"===e.group?a.push({name:e.name,tensor:n[e.name]}):r[e.name]=n[e.name]}),{modelWeights:r,optimizerWeights:a}}Functional.className="Functional",registerClass(Functional);class Sequential extends LayersModel{constructor(e){if(super({inputs:[],outputs:[]}),e=e||{},this.trainable=!0,this.built=!1,this.name=null!=e.name?e.name:getUid("sequential_"),null!=e.layers)for(const t of e.layers)this.add(t)}checkShape(e){if(e.inboundNodes[0].outputTensors[0].shape.some(e=>e<0))throw new ValueError(`Negative dimension size caused by adding layer ${e.name} with input shape [${e.inboundNodes[0].inputTensors[0].shape}]`)}add(e){const t=e instanceof Sequential||e instanceof LayersModel;let n;if(t){if(n=e,1!==n.outputs.length)throw new ValueError("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");if(1!==n.inputs.length)throw new ValueError("All layers in a Sequential model should have a single input tensor. For multi-input layers, use the functional API.")}if(0===this.outputs.length){if(0===e.inboundNodes.length){if(null==e.batchInputShape)throw new ValueError("The first layer in a Sequential model must get an `inputShape` or `batchInputShape` argument.");const t=Input({batchShape:e.batchInputShape,dtype:e.dtype,name:e.name+"_input"});e.apply(t)}if(t)this.outputs=n.outputs,this.inputs=n.inputs;else{if(1!==e.inboundNodes.length)throw new ValueError(`A layer added to a Sequential model must not already be connected somewhere else. LayersModel received layer ${e.name} which has ${e.inboundNodes.length} pre-existing inbound connections.`);if(1!==e.inboundNodes[0].outputTensors.length)throw new ValueError("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");this.checkShape(e),this.outputs=[e.inboundNodes[0].outputTensors[0]],this.inputs=getSourceInputs(this.outputs[0])}this.inboundNodes=[],new Node({outboundLayer:this,inboundLayers:[],nodeIndices:[],tensorIndices:[],inputTensors:this.inputs,outputTensors:this.outputs,inputMasks:pyListRepeat(null,this.inputs.length),outputMasks:[null],inputShapes:this.inputs.map(e=>e.shape),outputShapes:this.outputs[0].shape})}else{const t=e.apply(this.outputs[0]);if(Array.isArray(t))throw new TypeError("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");this.checkShape(e),this.outputs=[t],this.inboundNodes[0].outputTensors=this.outputs,this.inboundNodes[0].outputShapes=[this.outputs[0].shape]}this.layers.push(e),this.built=!1}pop(){if(0===this.layers.length)throw new TypeError("There are no layers in the model.");if(this.layers.pop(),0===this.layers.length)this.outputs=[],this.inboundNodes=[],this.outboundNodes=[];else{const e=this.layers.length-1;this.layers[e].outboundNodes=[],this.outputs=[this.layers[e].output],this.inboundNodes[0].outputTensors=this.outputs,this.inboundNodes[0].outputShapes=[this.outputs[0].shape]}}call(e,t){return null==this.model&&this.build(),this.model.call(e,t)}build(e){if(getExactlyOneShape(e),0===this.inputs.length||0===this.outputs.length)throw new TypeError("Sequential model cannot be built: model is empty. Add some layers first.");this.model=new LayersModel({inputs:this.inputs,outputs:this.outputs[0],name:this.name+"_model"}),this.model.trainable=this.trainable,this.supportsMasking=this.model.supportsMasking,this.inputLayers=this.model.inputLayers,this.inputLayersNodeIndices=this.model.inputLayersNodeIndices,this.inputLayersTensorIndices=this.model.inputLayersTensorIndices,this.outputLayers=this.model.outputLayers,this.outputLayersNodeIndices=this.model.outputLayersNodeIndices,this.outputLayersTensorIndices=this.model.outputLayersTensorIndices,this.nodesByDepth=this.model.nodesByDepth,this.containerNodes=this.model.containerNodes,this.outputNames=this.model.outputNames,this.inputNames=this.model.inputNames,this.built=!0}countParams(){return this.built||this.build(),super.countParams()}summary(e,t,n=console.log){this.built||this.build(),super.summary(e,t,n)}setWeights(e){null==this.model&&this.build(),this.model.setWeights(e)}evaluate(e,t,n={}){if(!this.built)throw new RuntimeError("The model needs to be compiled before being used.");return this.model.evaluate(e,t,n)}async evaluateDataset(e,t){if(!this.built)throw new RuntimeError("The model needs to be compiled before being used.");return this.model.evaluateDataset(e,t)}predict(e,t={}){return null==this.model&&this.build(),this.model.predict(e,t)}predictOnBatch(e){return null==this.model&&this.build(),this.model.predictOnBatch(e)}compile(e){this.build(),this.model.compile(e),this.optimizer_=this.model.optimizer,this.isOptimizerOwned=this.model.isOptimizerOwned,this.loss=this.model.loss,this.metrics=this.model.metrics,this.metricsTensors=this.model.metricsTensors,this.metricsNames=this.model.metricsNames}get optimizer(){return null==this.model?void 0:this.model.optimizer}set optimizer(e){this.model.optimizer=e}async fit(e,t,n={}){if(!this.built)throw new RuntimeError("The model needs to be compiled before being used.");return this.model.fit(e,t,n)}async fitDataset(e,t){if(!this.built)throw new RuntimeError("The model needs to be compiled before being used.");return this.model.fitDataset(e,t)}async trainOnBatch(e,t){return this.model.trainOnBatch(e,t)}static fromConfig(e,t,n={},r=!1){let a,s={};if(t instanceof Array){if(null==t[0].className||"Merge"===t[0].className)throw new ValueError("Legacy serialization format not supported yet.");a=t}else assert$4(null!=t.layers,()=>"When the config data for a Sequential model is not an Array, it must be an Object that contains the 'layers' field."),a=t.layers,delete t.layers,s=t;const o=new e(s);if(!(o instanceof Sequential))throw new NotImplementedError(`Sequential.fromConfig called on non-Sequential input: ${o}`);for(const e of a){const t=deserialize(e,void 0,r);r&&t.setFastWeightInitDuringBuild(!0),o.add(t)}return o}set stopTraining(e){if(null==this.model)throw new ValueError("Cannot set the stopTraining property of a sequential model before it is compiled.");this.model.stopTraining=e}get stopTraining(){if(null==this.model)throw new ValueError("Cannot get the stopTraining property of a sequential model before it is compiled.");return this.model.stopTraining}getConfig(){const e=[];for(const t of this.layers){const n={};n.className=t.getClassName(),n.config=t.getConfig(),e.push(n)}return{name:this.name,layers:e}}}function model(e){return new LayersModel(e)}function sequential(e){return new Sequential(e)}function loadLayersModel(e,t){return null==t&&(t={}),loadLayersModelInternal(e,t)}function input(e){return Input(e)}function registerCallbackConstructor(e,t){CallbackConstructorRegistry.registerCallbackConstructor(e,t)}Sequential.className="Sequential",registerClass(Sequential);class Activation$1 extends Serializable{getConfig(){return{}}}class Elu extends Activation$1{apply(e,t=1){return elu$3(e,t)}}Elu.className="elu",registerClass(Elu);class Selu extends Activation$1{apply(e){return selu$2(e)}}Selu.className="selu",registerClass(Selu);class Relu extends Activation$1{apply(e){return relu$3(e)}}Relu.className="relu",registerClass(Relu);class Relu6 extends Activation$1{apply(e){return tidy(()=>minimum$3(6,relu$3(e)))}}Relu6.className="relu6",registerClass(Relu6);class Linear extends Activation$1{apply(e){return e}}Linear.className="linear",registerClass(Linear);class Sigmoid extends Activation$1{apply(e){return sigmoid$2(e)}}Sigmoid.className="sigmoid",registerClass(Sigmoid);class HardSigmoid extends Activation$1{apply(e){return hardSigmoid(e)}}HardSigmoid.className="hardSigmoid",registerClass(HardSigmoid);class Softplus extends Activation$1{apply(e){return softplus$2(e)}}Softplus.className="softplus",registerClass(Softplus);class Softsign extends Activation$1{apply(e){return softsign(e)}}Softsign.className="softsign",registerClass(Softsign);class Tanh extends Activation$1{apply(e){return tanh$2(e)}}Tanh.className="tanh",registerClass(Tanh);class Softmax$1 extends Activation$1{apply(e,t=-1){return softmax$3(e,t)}}Softmax$1.className="softmax",registerClass(Softmax$1);class LogSoftmax extends Activation$1{apply(e,t=-1){return logSoftmax(e,t)}}LogSoftmax.className="logSoftmax",registerClass(LogSoftmax);class Swish extends Activation$1{apply(e,t=1){return tidy(()=>mul(sigmoid$2(mul(e,t)),e))}}Swish.className="swish",registerClass(Swish);class Mish extends Activation$1{apply(e){return tidy(()=>mul(e,tanh$2(softplus$2(e))))}}function serializeActivation(e){return e.getClassName()}function deserializeActivation(e,t={}){return deserializeKerasObject(e,SerializationMap.getMap().classNameMap,t,"activation")}function getActivation(e){if(null==e)return deserializeActivation({className:"linear",config:{}});if("string"==typeof e){const t={};return t.className=e,t.config={},deserializeActivation(t)}return e instanceof Activation$1?e:deserializeActivation(e)}function assertObjectArgs(e){if(null!=e&&"object"!=typeof e)throw new Error(`Argument to L1L2 regularizer's constructor is expected to be an object, but received: ${e}`)}Mish.className="mish",registerClass(Mish);class Regularizer extends Serializable{}class L1L2 extends Regularizer{constructor(e){super(),assertObjectArgs(e),this.l1=null==e||null==e.l1?.01:e.l1,this.l2=null==e||null==e.l2?.01:e.l2,this.hasL1=0!==this.l1,this.hasL2=0!==this.l2}apply(e){return tidy(()=>{let t=zeros$2([1]);return this.hasL1&&(t=add$2(t,sum$2(mul(this.l1,abs$2(e))))),this.hasL2&&(t=add$2(t,sum$2(mul(this.l2,square$1(e))))),reshape$3(t,[])})}getConfig(){return{l1:this.l1,l2:this.l2}}static fromConfig(e,t){return new e({l1:t.l1,l2:t.l2})}}function l1$1(e){return assertObjectArgs(e),new L1L2({l1:null!=e?e.l1:null,l2:0})}function l2$1(e){return assertObjectArgs(e),new L1L2({l2:null!=e?e.l2:null,l1:0})}L1L2.className="L1L2",registerClass(L1L2);const REGULARIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP={l1l2:"L1L2"};function serializeRegularizer(e){return serializeKerasObject(e)}function deserializeRegularizer(e,t={}){return deserializeKerasObject(e,SerializationMap.getMap().classNameMap,t,"regularizer")}function getRegularizer(e){return null==e?null:"string"==typeof e?deserializeRegularizer({className:e in REGULARIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP?REGULARIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP[e]:e,config:{}}):e instanceof Regularizer?e:deserializeRegularizer(e)}class ReLU extends Layer{constructor(e){super(null==e?{}:e),this.supportsMasking=!0,null!=e&&(this.maxValue=e.maxValue)}call(e,t){e=getExactlyOneTensor(e);let n=relu$3(e);return null!=this.maxValue&&(n=clipByValue$1(n,0,this.maxValue)),n}computeOutputShape(e){return e}getConfig(){const e={maxValue:this.maxValue},t=super.getConfig();return Object.assign(e,t),e}}ReLU.className="ReLU",registerClass(ReLU);class LeakyReLU extends Layer{constructor(e){super(null==e?{}:e),this.DEFAULT_ALPHA=.3,null==e&&(e={}),this.alpha=null==e.alpha?this.DEFAULT_ALPHA:e.alpha}call(e,t){const n=getExactlyOneTensor(e);return leakyRelu$2(n,this.alpha)}computeOutputShape(e){return e}getConfig(){const e={alpha:this.alpha},t=super.getConfig();return Object.assign(e,t),e}}LeakyReLU.className="LeakyReLU",registerClass(LeakyReLU);class PReLU extends Layer{constructor(e){if(super(null==e?{}:e),this.DEFAULT_ALPHA_INITIALIZER="zeros",null==e&&(e={}),this.supportsMasking=!0,this.alphaInitializer=getInitializer(e.alphaInitializer||this.DEFAULT_ALPHA_INITIALIZER),this.alphaRegularizer=getRegularizer(e.alphaRegularizer),this.alphaConstraint=getConstraint(e.alphaConstraint),null==e.sharedAxes)this.sharedAxes=null;else if(Array.isArray(e.sharedAxes))this.sharedAxes=e.sharedAxes;else{if("number"!=typeof e.sharedAxes)throw new ValueError(`Expected sharedAxes to be a number or an array of numbers, but got ${e.sharedAxes}`);this.sharedAxes=[e.sharedAxes]}}build(e){const t=(e=getExactlyOneShape(e)).slice(1);if(null!=this.sharedAxes)for(const e of this.sharedAxes)t[e-1]=1;this.alpha=this.addWeight("alpha",t,"float32",this.alphaInitializer,this.alphaRegularizer,!0,this.alphaConstraint);const n={};if(null!=this.sharedAxes)for(let t=1;t<e.length;++t)n[t]=e[t];this.inputSpec=[new InputSpec({ndim:e.length,axes:n})],this.built=!0}call(e,t){return e=getExactlyOneTensor(e),prelu$3(e,this.alpha.read())}getConfig(){const e={alphaInitializer:serializeInitializer(this.alphaInitializer),alphaRegularizer:serializeRegularizer(this.alphaRegularizer),alphaConstraint:serializeConstraint(this.alphaConstraint),sharedAxes:this.sharedAxes},t=super.getConfig();return Object.assign(e,t),e}}PReLU.className="PReLU",registerClass(PReLU);class ELU$3 extends Layer{constructor(e){if(super(null==e?{}:e),this.DEFAULT_ALPHA=1,null==e&&(e={}),null!=e.alpha&&e.alpha!==this.DEFAULT_ALPHA)throw new NotImplementedError(`Non-default alpha value (${e.alpha}) is not supported by the ELU layer yet.`);this.alpha=null==e.alpha?this.DEFAULT_ALPHA:e.alpha}call(e,t){const n=getExactlyOneTensor(e);return elu$4(n)}computeOutputShape(e){return e}getConfig(){const e={alpha:this.alpha},t=super.getConfig();return Object.assign(e,t),e}}ELU$3.className="ELU",registerClass(ELU$3);class ThresholdedReLU extends Layer{constructor(e){super(null==e?{}:e),this.DEFAULT_THETA=1,null==e&&(e={}),this.theta=null==e.theta?this.DEFAULT_THETA:e.theta}call(e,t){const n=getExactlyOneTensor(e);return mul(n,cast$3(greater$3(n,this.theta),"float32"))}computeOutputShape(e){return e}getConfig(){const e={theta:this.theta},t=super.getConfig();return Object.assign(e,t),e}}ThresholdedReLU.className="ThresholdedReLU",registerClass(ThresholdedReLU);class Softmax extends Layer{constructor(e){super(null==e?{}:e),this.DEFAULT_AXIS=1,null==e&&(e={}),this.softmax=(new Softmax$1).apply,this.axis=null==e.axis?this.DEFAULT_AXIS:e.axis}call(e,t){const n=getExactlyOneTensor(e);return this.softmax(n,this.axis)}computeOutputShape(e){return e}getConfig(){const e={axis:this.axis},t=super.getConfig();return Object.assign(e,t),e}}function normalizeArray(e,t,n){if("number"==typeof e)return pyListRepeat(e,t);if(e.length!==t)throw new ValueError(`The ${n} argument must be an integer or tuple of ${t} integers. Received: ${e.length} elements.`);for(let r=0;r<t;++r){const a=e[r];if(!isInteger(a))throw new ValueError(`The ${n} argument must be an integer or tuple of ${t} integers. Received: ${JSON.stringify(e)} including a non-integer number ${a}`)}return e}function convOutputLength(e,t,n,r,a=1){if(null==e)return e;let s;return s="same"===n?e:e-(t+(t-1)*(a-1))+1,Math.floor((s+r-1)/r)}function deconvLength(e,t,n,r){if(null==e)return null;if("valid"===r)e=e*t+max$2([n-t,0]);else{if("same"!==r)throw new ValueError(`Unsupport padding mode: ${r}.`);e*=t}return e}function preprocessConv2DInput(e,t){return tidy(()=>(checkDataFormat(t),"channelsFirst"===t?transpose$2(e,[0,2,3,1]):e))}function preprocessConv3DInput(e,t){return tidy(()=>(checkDataFormat(t),"channelsFirst"===t?transpose$2(e,[0,2,3,4,1]):e))}function conv1dWithBias(e,t,n,r=1,a="valid",s,o=1){return tidy(()=>{if(null==s&&(s=imageDataFormat()),checkDataFormat(s),3!==e.shape.length)throw new ValueError(`The input of a conv1dWithBias operation should be 3, but is ${e.shape.length} instead.`);if(3!==t.shape.length)throw new ValueError(`The kernel for a conv1dWithBias operation should be 3, but is ${t.shape.length} instead`);if(null!=n&&1!==n.shape.length)throw new ValueError(`The bias for a conv1dWithBias operation should be 1, but is ${t.shape.length} instead`);if("channelsFirst"===s&&(e=transpose$2(e,[0,2,1])),"causal"===a)throw new NotImplementedError("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");let i=conv1d$1(e,t,r,"same"===a?"same":"valid","NWC",o);return null!=n&&(i=biasAdd(i,n)),i})}function conv2dWithBiasActivation(e,t,n,r=[1,1],a="valid",s,o,i=null){return tidy(()=>{if(null==s&&(s=imageDataFormat()),checkDataFormat(s),3!==e.rank&&4!==e.rank)throw new ValueError(`conv2dWithBiasActivation expects input to be of rank 3 or 4, but received ${e.rank}.`);if(3!==t.rank&&4!==t.rank)throw new ValueError(`conv2dWithBiasActivation expects kernel to be of rank 3 or 4, but received ${e.rank}.`);let l=preprocessConv2DInput(e,s);if("causal"===a)throw new NotImplementedError("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");return l=conv2d$2({x:l,filter:t,strides:r,pad:"same"===a?"same":"valid",dilations:o,dataFormat:"NHWC",bias:n,activation:i}),"channelsFirst"===s&&(l=transpose$2(l,[0,3,1,2])),l})}function conv3dWithBias(e,t,n,r=[1,1,1],a="valid",s,o){return tidy(()=>{if(null==s&&(s=imageDataFormat()),checkDataFormat(s),4!==e.rank&&5!==e.rank)throw new ValueError(`conv3dWithBias expects input to be of rank 4 or 5, but received ${e.rank}.`);if(4!==t.rank&&5!==t.rank)throw new ValueError(`conv3dWithBias expects kernel to be of rank 4 or 5, but received ${e.rank}.`);let i=preprocessConv3DInput(e,s);if("causal"===a)throw new NotImplementedError("The support for CAUSAL padding mode in conv3dWithBias is not implemented yet.");return i=conv3d$1(i,t,r,"same"===a?"same":"valid","NDHWC",o),null!=n&&(i=biasAdd(i,n)),"channelsFirst"===s&&(i=transpose$2(i,[0,4,1,2,3])),i})}Softmax.className="Softmax",registerClass(Softmax);class BaseConv extends Layer{constructor(e,t){if(super(t),this.bias=null,this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_BIAS_INITIALIZER="zeros",BaseConv.verifyArgs(t),this.rank=e,assertPositiveInteger(this.rank,"rank"),1!==this.rank&&2!==this.rank&&3!==this.rank)throw new NotImplementedError(`Convolution layer for rank other than 1, 2, or 3 (${this.rank}) is not implemented yet.`);if(this.kernelSize=normalizeArray(t.kernelSize,e,"kernelSize"),this.strides=normalizeArray(null==t.strides?1:t.strides,e,"strides"),this.padding=null==t.padding?"valid":t.padding,checkPaddingMode(this.padding),this.dataFormat=null==t.dataFormat?"channelsLast":t.dataFormat,checkDataFormat(this.dataFormat),this.activation=getActivation(t.activation),this.useBias=null==t.useBias||t.useBias,this.biasInitializer=getInitializer(t.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.biasConstraint=getConstraint(t.biasConstraint),this.biasRegularizer=getRegularizer(t.biasRegularizer),this.activityRegularizer=getRegularizer(t.activityRegularizer),this.dilationRate=normalizeArray(null==t.dilationRate?1:t.dilationRate,e,"dilationRate"),1===this.rank&&Array.isArray(this.dilationRate)&&1!==this.dilationRate.length)throw new ValueError(`dilationRate must be a number or an array of a single number for 1D convolution, but received ${JSON.stringify(this.dilationRate)}`);if(2===this.rank){if("number"==typeof this.dilationRate)this.dilationRate=[this.dilationRate,this.dilationRate];else if(2!==this.dilationRate.length)throw new ValueError(`dilationRate must be a number or array of two numbers for 2D convolution, but received ${JSON.stringify(this.dilationRate)}`)}else if(3===this.rank)if("number"==typeof this.dilationRate)this.dilationRate=[this.dilationRate,this.dilationRate,this.dilationRate];else if(3!==this.dilationRate.length)throw new ValueError(`dilationRate must be a number or array of three numbers for 3D convolution, but received ${JSON.stringify(this.dilationRate)}`)}static verifyArgs(e){if(assert$3("kernelSize"in e,"required key 'kernelSize' not in config"),"number"!=typeof e.kernelSize&&!checkArrayTypeAndLength(e.kernelSize,"number",1,3))throw new ValueError(`BaseConv expects config.kernelSize to be number or number[] with length 1, 2, or 3, but received ${JSON.stringify(e.kernelSize)}.`)}getConfig(){const e={kernelSize:this.kernelSize,strides:this.strides,padding:this.padding,dataFormat:this.dataFormat,dilationRate:this.dilationRate,activation:serializeActivation(this.activation),useBias:this.useBias,biasInitializer:serializeInitializer(this.biasInitializer),biasRegularizer:serializeRegularizer(this.biasRegularizer),activityRegularizer:serializeRegularizer(this.activityRegularizer),biasConstraint:serializeConstraint(this.biasConstraint)},t=super.getConfig();return Object.assign(e,t),e}}class Conv extends BaseConv{constructor(e,t){super(e,t),this.kernel=null,Conv.verifyArgs(t),this.filters=t.filters,assertPositiveInteger(this.filters,"filters"),this.kernelInitializer=getInitializer(t.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.kernelConstraint=getConstraint(t.kernelConstraint),this.kernelRegularizer=getRegularizer(t.kernelRegularizer)}build(e){e=getExactlyOneShape(e);const t="channelsFirst"===this.dataFormat?1:e.length-1;if(null==e[t])throw new ValueError(`The channel dimension of the input should be defined. Found ${e[t]}`);const n=e[t],r=this.kernelSize.concat([n,this.filters]);this.kernel=this.addWeight("kernel",r,null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.filters],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[{ndim:this.rank+2,axes:{[t]:n}}],this.built=!0}call(e,t){return tidy(()=>{let t;e=getExactlyOneTensor(e);const n=null==this.bias?null:this.bias.read(),r=mapActivationToFusedKernel(this.activation.getClassName());if(null!=r&&2===this.rank)t=conv2dWithBiasActivation(e,this.kernel.read(),n,this.strides,this.padding,this.dataFormat,this.dilationRate,r);else{if(1===this.rank)t=conv1dWithBias(e,this.kernel.read(),n,this.strides[0],this.padding,this.dataFormat,this.dilationRate[0]);else if(2===this.rank)t=conv2dWithBiasActivation(e,this.kernel.read(),n,this.strides,this.padding,this.dataFormat,this.dilationRate);else{if(3!==this.rank)throw new NotImplementedError("convolutions greater than 3D are not implemented yet.");t=conv3dWithBias(e,this.kernel.read(),n,this.strides,this.padding,this.dataFormat,this.dilationRate)}null!=this.activation&&(t=this.activation.apply(t))}return t})}computeOutputShape(e){e=getExactlyOneShape(e);const t=[],n="channelsLast"===this.dataFormat?e.slice(1,e.length-1):e.slice(2);for(let e=0;e<n.length;++e){const r=convOutputLength(n[e],this.kernelSize[e],this.padding,this.strides[e],"number"==typeof this.dilationRate?this.dilationRate:this.dilationRate[e]);t.push(r)}let r=[e[0]];return"channelsLast"===this.dataFormat?(r=r.concat(t),r.push(this.filters)):(r.push(this.filters),r=r.concat(t)),r}getConfig(){const e={filters:this.filters,kernelInitializer:serializeInitializer(this.kernelInitializer),kernelRegularizer:serializeRegularizer(this.kernelRegularizer),kernelConstraint:serializeConstraint(this.kernelConstraint)},t=super.getConfig();return Object.assign(e,t),e}static verifyArgs(e){if(!("filters"in e)||"number"!=typeof e.filters||e.filters<1)throw new ValueError(`Convolution layer expected config.filters to be a 'number' > 0 but got ${JSON.stringify(e.filters)}`)}}class Conv2D extends Conv{constructor(e){super(2,e),Conv2D.verifyArgs(e)}getConfig(){const e=super.getConfig();return delete e.rank,e}static verifyArgs(e){if("number"!=typeof e.kernelSize&&!checkArrayTypeAndLength(e.kernelSize,"number",1,2))throw new ValueError(`Conv2D expects config.kernelSize to be number or number[] with length 1 or 2, but received ${JSON.stringify(e.kernelSize)}.`)}}Conv2D.className="Conv2D",registerClass(Conv2D);class Conv3D extends Conv{constructor(e){super(3,e),Conv3D.verifyArgs(e)}getConfig(){const e=super.getConfig();return delete e.rank,e}static verifyArgs(e){if("number"!=typeof e.kernelSize&&(!Array.isArray(e.kernelSize)||1!==e.kernelSize.length&&3!==e.kernelSize.length))throw new ValueError(`Conv3D expects config.kernelSize to be number or [number, number, number], but received ${JSON.stringify(e.kernelSize)}.`)}}Conv3D.className="Conv3D",registerClass(Conv3D);class Conv2DTranspose extends Conv2D{constructor(e){if(super(e),this.inputSpec=[new InputSpec({ndim:4})],"same"!==this.padding&&"valid"!==this.padding)throw new ValueError(`Conv2DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode ${this.padding}`)}build(e){if(4!==(e=getExactlyOneShape(e)).length)throw new ValueError("Input should have rank 4; Received input shape: "+JSON.stringify(e));const t="channelsFirst"===this.dataFormat?1:e.length-1;if(null==e[t])throw new ValueError("The channel dimension of the inputs should be defined. Found `None`.");const n=e[t],r=this.kernelSize.concat([this.filters,n]);this.kernel=this.addWeight("kernel",r,"float32",this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.filters],"float32",this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[new InputSpec({ndim:4,axes:{[t]:n}})],this.built=!0}call(e,t){return tidy(()=>{let t=getExactlyOneTensor(e);if(4!==t.shape.length)throw new ValueError(`Conv2DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-${t.shape.length}`);const n=t.shape;let r,a;"channelsFirst"===this.dataFormat?(r=2,a=3):(r=1,a=2);const s=n[a],o=this.kernelSize[1],i=this.strides[1],l=[n[0],deconvLength(n[r],this.strides[0],this.kernelSize[0],this.padding),deconvLength(s,i,o,this.padding),this.filters];"channelsLast"!==this.dataFormat&&(t=transpose$2(t,[0,2,3,1]));let u=conv2dTranspose$1(t,this.kernel.read(),l,this.strides,this.padding);return"channelsLast"!==this.dataFormat&&(u=transpose$2(u,[0,3,1,2])),null!=this.bias&&(u=biasAdd(u,this.bias.read(),this.dataFormat)),null!=this.activation&&(u=this.activation.apply(u)),u})}computeOutputShape(e){const t=(e=getExactlyOneShape(e)).slice();let n,r,a;"channelsFirst"===this.dataFormat?(n=1,r=2,a=3):(n=3,r=1,a=2);const s=this.kernelSize[0],o=this.kernelSize[1],i=this.strides[0],l=this.strides[1];return t[n]=this.filters,t[r]=deconvLength(t[r],i,s,this.padding),t[a]=deconvLength(t[a],l,o,this.padding),t}getConfig(){const e=super.getConfig();return delete e.dilationRate,e}}Conv2DTranspose.className="Conv2DTranspose",registerClass(Conv2DTranspose);class Conv3DTranspose extends Conv3D{constructor(e){if(super(e),this.inputSpec=[new InputSpec({ndim:5})],"same"!==this.padding&&"valid"!==this.padding)throw new ValueError(`Conv3DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode ${this.padding}`)}build(e){if(5!==(e=getExactlyOneShape(e)).length)throw new ValueError("Input should have rank 5; Received input shape: "+JSON.stringify(e));const t="channelsFirst"===this.dataFormat?1:e.length-1;if(null==e[t])throw new ValueError("The channel dimension of the inputs should be defined. Found `None`.");const n=e[t],r=this.kernelSize.concat([this.filters,n]);this.kernel=this.addWeight("kernel",r,"float32",this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.filters],"float32",this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[new InputSpec({ndim:5,axes:{[t]:n}})],this.built=!0}call(e,t){return tidy(()=>{let t=getExactlyOneTensor(e);if(5!==t.shape.length)throw new ValueError(`Conv3DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-${t.shape.length}`);const n=t.shape;let r,a,s;"channelsFirst"===this.dataFormat?(s=2,r=3,a=4):(s=1,r=2,a=3);const o=n[r],i=n[a],l=this.kernelSize[1],u=this.kernelSize[2],c=this.strides[1],p=this.strides[2],d=[n[0],deconvLength(n[s],this.strides[0],this.kernelSize[0],this.padding),deconvLength(o,c,l,this.padding),deconvLength(i,p,u,this.padding),this.filters];"channelsLast"!==this.dataFormat&&(t=transpose$2(t,[0,2,3,4,1]));let h=conv3dTranspose$1(t,this.kernel.read(),d,this.strides,this.padding);return"channelsLast"!==this.dataFormat&&(h=transpose$2(h,[0,4,1,2,3])),null!==this.bias&&(h=biasAdd(h,this.bias.read(),this.dataFormat)),null!==this.activation&&(h=this.activation.apply(h)),h})}computeOutputShape(e){const t=(e=getExactlyOneShape(e)).slice();let n,r,a,s;"channelsFirst"===this.dataFormat?(n=1,r=2,a=3,s=4):(n=4,r=1,a=2,s=3);const o=this.kernelSize[0],i=this.kernelSize[1],l=this.kernelSize[2],u=this.strides[0],c=this.strides[1],p=this.strides[2];return t[n]=this.filters,t[r]=deconvLength(t[r],u,o,this.padding),t[a]=deconvLength(t[a],c,i,this.padding),t[s]=deconvLength(t[s],p,l,this.padding),t}getConfig(){const e=super.getConfig();return delete e.dilationRate,e}}Conv3DTranspose.className="Conv3DTranspose",registerClass(Conv3DTranspose);class SeparableConv extends Conv{constructor(e,t){if(super(e,t),this.DEFAULT_DEPTHWISE_INITIALIZER="glorotUniform",this.DEFAULT_POINTWISE_INITIALIZER="glorotUniform",this.depthwiseKernel=null,this.pointwiseKernel=null,null==t.filters)throw new ValueError("The `filters` configuration field is required by SeparableConv, but is unspecified.");if(null!=t.kernelInitializer||null!=t.kernelRegularizer||null!=t.kernelConstraint)throw new ValueError("Fields kernelInitializer, kernelRegularizer and kernelConstraint are invalid for SeparableConv2D. Use depthwiseInitializer, depthwiseRegularizer, depthwiseConstraint, pointwiseInitializer, pointwiseRegularizer and pointwiseConstraint instead.");if(null!=t.padding&&"same"!==t.padding&&"valid"!==t.padding)throw new ValueError(`SeparableConv${this.rank}D supports only padding modes: 'same' and 'valid', but received ${JSON.stringify(t.padding)}`);this.depthMultiplier=null==t.depthMultiplier?1:t.depthMultiplier,this.depthwiseInitializer=getInitializer(t.depthwiseInitializer||this.DEFAULT_DEPTHWISE_INITIALIZER),this.depthwiseRegularizer=getRegularizer(t.depthwiseRegularizer),this.depthwiseConstraint=getConstraint(t.depthwiseConstraint),this.pointwiseInitializer=getInitializer(t.depthwiseInitializer||this.DEFAULT_POINTWISE_INITIALIZER),this.pointwiseRegularizer=getRegularizer(t.pointwiseRegularizer),this.pointwiseConstraint=getConstraint(t.pointwiseConstraint)}build(e){if((e=getExactlyOneShape(e)).length<this.rank+2)throw new ValueError(`Inputs to SeparableConv${this.rank}D should have rank ${this.rank+2}, but received input shape: ${JSON.stringify(e)}`);const t="channelsFirst"===this.dataFormat?1:e.length-1;if(null==e[t]||e[t]<0)throw new ValueError(`The channel dimension of the inputs should be defined, but found ${JSON.stringify(e[t])}`);const n=e[t],r=this.kernelSize.concat([n,this.depthMultiplier]),a=[];for(let e=0;e<this.rank;++e)a.push(1);a.push(n*this.depthMultiplier,this.filters);const s=!0;this.depthwiseKernel=this.addWeight("depthwise_kernel",r,"float32",this.depthwiseInitializer,this.depthwiseRegularizer,s,this.depthwiseConstraint),this.pointwiseKernel=this.addWeight("pointwise_kernel",a,"float32",this.pointwiseInitializer,this.pointwiseRegularizer,s,this.pointwiseConstraint),this.bias=this.useBias?this.addWeight("bias",[this.filters],"float32",this.biasInitializer,this.biasRegularizer,s,this.biasConstraint):null,this.inputSpec=[new InputSpec({ndim:this.rank+2,axes:{[t]:n}})],this.built=!0}call(e,t){return tidy(()=>{let t;if(e=getExactlyOneTensor(e),1===this.rank)throw new NotImplementedError("1D separable convolution is not implemented yet.");return 2===this.rank&&("channelsFirst"===this.dataFormat&&(e=transpose$2(e,[0,2,3,1])),t=separableConv2d$1(e,this.depthwiseKernel.read(),this.pointwiseKernel.read(),this.strides,this.padding,this.dilationRate,"NHWC")),this.useBias&&(t=biasAdd(t,this.bias.read(),this.dataFormat)),null!=this.activation&&(t=this.activation.apply(t)),"channelsFirst"===this.dataFormat&&(t=transpose$2(t,[0,3,1,2])),t})}getConfig(){const e=super.getConfig();return delete e.rank,delete e.kernelInitializer,delete e.kernelRegularizer,delete e.kernelConstraint,e.depthwiseInitializer=serializeInitializer(this.depthwiseInitializer),e.pointwiseInitializer=serializeInitializer(this.pointwiseInitializer),e.depthwiseRegularizer=serializeRegularizer(this.depthwiseRegularizer),e.pointwiseRegularizer=serializeRegularizer(this.pointwiseRegularizer),e.depthwiseConstraint=serializeConstraint(this.depthwiseConstraint),e.pointwiseConstraint=serializeConstraint(this.pointwiseConstraint),e}}SeparableConv.className="SeparableConv";class SeparableConv2D extends SeparableConv{constructor(e){super(2,e)}}SeparableConv2D.className="SeparableConv2D",registerClass(SeparableConv2D);class Conv1D extends Conv{constructor(e){super(1,e),Conv1D.verifyArgs(e),this.inputSpec=[{ndim:3}]}getConfig(){const e=super.getConfig();return delete e.rank,delete e.dataFormat,e}static verifyArgs(e){if("number"!=typeof e.kernelSize&&!checkArrayTypeAndLength(e.kernelSize,"number",1,1))throw new ValueError(`Conv1D expects config.kernelSize to be number or number[] with length 1, but received ${JSON.stringify(e.kernelSize)}.`)}}Conv1D.className="Conv1D",registerClass(Conv1D);class Cropping2D extends Layer{constructor(e){super(e),this.cropping="number"==typeof e.cropping?[[e.cropping,e.cropping],[e.cropping,e.cropping]]:"number"==typeof e.cropping[0]?[[e.cropping[0],e.cropping[0]],[e.cropping[1],e.cropping[1]]]:e.cropping,this.dataFormat=void 0===e.dataFormat?"channelsLast":e.dataFormat,this.inputSpec=[{ndim:4}]}computeOutputShape(e){return"channelsFirst"===this.dataFormat?[e[0],e[1],e[2]-this.cropping[0][0]-this.cropping[0][1],e[3]-this.cropping[1][0]-this.cropping[1][1]]:[e[0],e[1]-this.cropping[0][0]-this.cropping[0][1],e[2]-this.cropping[1][0]-this.cropping[1][1],e[3]]}call(e,t){return tidy(()=>{if(e=getExactlyOneTensor(e),"channelsLast"===this.dataFormat){const t=sliceAlongAxis(e,this.cropping[0][0],e.shape[1]-this.cropping[0][0]-this.cropping[0][1],2);return sliceAlongAxis(t,this.cropping[1][0],e.shape[2]-this.cropping[1][1]-this.cropping[1][0],3)}{const t=sliceAlongAxis(e,this.cropping[0][0],e.shape[2]-this.cropping[0][0]-this.cropping[0][1],3);return sliceAlongAxis(t,this.cropping[1][0],e.shape[3]-this.cropping[1][1]-this.cropping[1][0],4)}})}getConfig(){const e={cropping:this.cropping,dataFormat:this.dataFormat},t=super.getConfig();return Object.assign(e,t),e}}Cropping2D.className="Cropping2D",registerClass(Cropping2D);class UpSampling2D extends Layer{constructor(e){super(e),this.DEFAULT_SIZE=[2,2],this.inputSpec=[{ndim:4}],this.size=null==e.size?this.DEFAULT_SIZE:e.size,this.dataFormat=null==e.dataFormat?"channelsLast":e.dataFormat,checkDataFormat(this.dataFormat),this.interpolation=null==e.interpolation?"nearest":e.interpolation,checkInterpolationFormat(this.interpolation)}computeOutputShape(e){return"channelsFirst"===this.dataFormat?[e[0],e[1],null==e[2]?null:this.size[0]*e[2],null==e[3]?null:this.size[1]*e[3]]:[e[0],null==e[1]?null:this.size[0]*e[1],null==e[2]?null:this.size[1]*e[2],e[3]]}call(e,t){return tidy(()=>{let t=getExactlyOneTensor(e);const n=t.shape;if("channelsFirst"===this.dataFormat){t=transpose$2(t,[0,2,3,1]);const e=this.size[0]*n[2],r=this.size[1]*n[3],a="nearest"===this.interpolation?image$1.resizeNearestNeighbor(t,[e,r]):image$1.resizeBilinear(t,[e,r]);return transpose$2(a,[0,3,1,2])}{const e=this.size[0]*n[1],r=this.size[1]*n[2];return"nearest"===this.interpolation?image$1.resizeNearestNeighbor(t,[e,r]):image$1.resizeBilinear(t,[e,r])}})}getConfig(){const e={size:this.size,dataFormat:this.dataFormat},t=super.getConfig();return Object.assign(e,t),e}}function depthwiseConv2d$1(e,t,n=[1,1],r="valid",a,s){return tidy(()=>{null==a&&(a=imageDataFormat()),checkDataFormat(a);let o=preprocessConv2DInput(e,a);if(4!==e.rank)throw new ValueError(`Input for depthwiseConv2d is required to be 4-D, but is instead ${e.rank}-D`);if(4!==t.rank)throw new ValueError(`depthwiseKernel is required to be 4-D, but is instead ${t.rank}-D`);return o=depthwiseConv2d$3(o,t,n,"same"===r?"same":"valid","NHWC",s),"channelsFirst"===a&&(o=transpose$2(o,[0,3,1,2])),o})}UpSampling2D.className="UpSampling2D",registerClass(UpSampling2D);class DepthwiseConv2D extends BaseConv{constructor(e){super(2,e),this.depthwiseKernel=null,this.depthMultiplier=null==e.depthMultiplier?1:e.depthMultiplier,this.depthwiseInitializer=getInitializer(e.depthwiseInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.depthwiseConstraint=getConstraint(e.depthwiseConstraint),this.depthwiseRegularizer=getRegularizer(e.depthwiseRegularizer)}build(e){if((e=getExactlyOneShape(e)).length<4)throw new ValueError(`Inputs to DepthwiseConv2D should have rank 4. Received input shape: ${JSON.stringify(e)}.`);const t="channelsFirst"===this.dataFormat?1:3;if(null==e[t]||e[t]<0)throw new ValueError(`The channel dimension of the inputs to DepthwiseConv2D should be defined, but is not (${e[t]}).`);const n=e[t];this.depthwiseKernel=this.addWeight("depthwise_kernel",[this.kernelSize[0],this.kernelSize[1],n,this.depthMultiplier],null,this.depthwiseInitializer,this.depthwiseRegularizer,!0,this.depthwiseConstraint),this.bias=this.useBias?this.addWeight("bias",[n*this.depthMultiplier],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint):null,this.built=!0}call(e,t){return tidy(()=>{let t=depthwiseConv2d$1(e=getExactlyOneTensor(e),this.depthwiseKernel.read(),this.strides,this.padding,this.dataFormat,null);return this.useBias&&(t=biasAdd(t,this.bias.read(),this.dataFormat)),null!=this.activation&&(t=this.activation.apply(t)),t})}computeOutputShape(e){e=getExactlyOneShape(e);const t="channelsFirst"===this.dataFormat?e[3]:e[2],n="channelsFirst"===this.dataFormat?e[1]*this.depthMultiplier:e[3]*this.depthMultiplier,r=convOutputLength("channelsFirst"===this.dataFormat?e[2]:e[1],this.kernelSize[0],this.padding,this.strides[0]),a=convOutputLength(t,this.kernelSize[1],this.padding,this.strides[1]);return"channelsFirst"===this.dataFormat?[e[0],n,r,a]:[e[0],r,a,n]}getConfig(){const e=super.getConfig();return e.depthMultiplier=this.depthMultiplier,e.depthwiseInitializer=serializeInitializer(this.depthwiseInitializer),e.depthwiseRegularizer=serializeRegularizer(this.depthwiseRegularizer),e.depthwiseConstraint=serializeConstraint(this.depthwiseRegularizer),e}}function standardizeArgs(e,t,n,r){if(Array.isArray(e)){if(null!=t||null!=n)throw new ValueError("When inputs is an array, neither initialState or constants should be provided");null!=r&&(n=e.slice(e.length-r,e.length),e=e.slice(0,e.length-r)),e.length>1&&(t=e.slice(1,e.length)),e=e[0]}function a(e){return null==e||Array.isArray(e)?e:[e]}return{inputs:e,initialState:t=a(t),constants:n=a(n)}}function rnn$1(e,t,n,r=!1,a,s,o=!1,i=!1){return tidy(()=>{const l=t.shape.length;if(l<3)throw new ValueError(`Input should be at least 3D, but is ${l}D.`);const u=[1,0].concat(range$3(2,l));if(t=transpose$2(t,u),null!=s)throw new NotImplementedError("The rnn() functoin of the deeplearn.js backend does not support constants yet.");o&&console.warn("Backend rnn(): the unroll = true option is not applicable to the imperative deeplearn.js backend."),null!=a&&((a=cast$3(cast$3(a,"bool"),"float32")).rank===l-1&&(a=expandDims$3(a,-1)),a=transpose$2(a,u)),r&&(t=reverse$2(t,0),null!=a&&(a=reverse$2(a,0)));const c=[];let p,d=n;const h=t.shape[0],m=unstack(t);let f,g;null!=a&&(f=unstack(a));for(let t=0;t<h;++t){const n=m[t],r=tidy(()=>e(n,d));if(null==a)p=r[0],d=r[1];else{const e=tidy(()=>{const e=f[t],n=sub$2(onesLike$2(e),e);return{output:add$2(mul(r[0],e),mul(d[0],n)),newStates:d.map((t,a)=>add$2(mul(r[1][a],e),mul(t,n)))}});p=e.output,d=e.newStates}i&&c.push(p)}return i&&(g=stack(c,1)),[p,g,d]})}DepthwiseConv2D.className="DepthwiseConv2D",registerClass(DepthwiseConv2D);class RNN extends Layer{constructor(e){let t;if(super(e),null==e.cell)throw new ValueError("cell property is missing for the constructor of RNN.");if(t=Array.isArray(e.cell)?new StackedRNNCells({cells:e.cell}):e.cell,null==t.stateSize)throw new ValueError("The RNN cell should have an attribute `stateSize` (tuple of integers, one integer per RNN state).");this.cell=t,this.returnSequences=null!=e.returnSequences&&e.returnSequences,this.returnState=null!=e.returnState&&e.returnState,this.goBackwards=null!=e.goBackwards&&e.goBackwards,this._stateful=null!=e.stateful&&e.stateful,this.unroll=null!=e.unroll&&e.unroll,this.supportsMasking=!0,this.inputSpec=[new InputSpec({ndim:3})],this.stateSpec=null,this.states_=null,this.numConstants=null,this.keptStates=[]}getStates(){return null==this.states_?range$3(0,Array.isArray(this.cell.stateSize)?this.cell.stateSize.length:1).map(e=>null):this.states_}setStates(e){this.states_=e}computeOutputShape(e){isArrayOfShapes(e)&&(e=e[0]),e=e;let t=this.cell.stateSize;Array.isArray(t)||(t=[t]);const n=t[0];let r;if(r=this.returnSequences?[e[0],e[1],n]:[e[0],n],this.returnState){const n=[];for(const r of t)n.push([e[0],r]);return[r].concat(n)}return r}computeMask(e,t){return tidy(()=>{Array.isArray(t)&&(t=t[0]);const e=this.returnSequences?t:null;if(this.returnState){const t=this.states.map(e=>null);return[e].concat(t)}return e})}get states(){if(null==this.states_){const e=Array.isArray(this.cell.stateSize)?this.cell.stateSize.length:1,t=[];for(let n=0;n<e;++n)t.push(null);return t}return this.states_}set states(e){this.states_=e}build(e){if(null!=this.numConstants)throw new NotImplementedError("Constants support is not implemented in RNN yet.");isArrayOfShapes(e)&&(e=e[0]),e=e;const t=this.stateful?e[0]:null,n=e.slice(2);this.inputSpec[0]=new InputSpec({shape:[t,null,...n]});const r=[e[0]].concat(e.slice(2));let a;if(this.cell.build(r),a=Array.isArray(this.cell.stateSize)?this.cell.stateSize:[this.cell.stateSize],null!=this.stateSpec){if(!arraysEqual(this.stateSpec.map(e=>e.shape[e.shape.length-1]),a))throw new ValueError(`An initialState was passed that is not compatible with cell.stateSize. Received stateSpec=${this.stateSpec}; However cell.stateSize is ${this.cell.stateSize}`)}else this.stateSpec=a.map(e=>new InputSpec({shape:[null,e]}));this.stateful&&this.resetStates()}resetStates(e,t=!1){tidy(()=>{if(!this.stateful)throw new AttributeError("Cannot call resetStates() on an RNN Layer that is not stateful.");const n=this.inputSpec[0].shape[0];if(null==n)throw new ValueError("If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.");if(null==this.states_)this.states_=Array.isArray(this.cell.stateSize)?this.cell.stateSize.map(e=>zeros$2([n,e])):[zeros$2([n,this.cell.stateSize])];else if(null==e)dispose(this.states_),null!=this.keptStates&&(dispose(this.keptStates),this.keptStates=[]),Array.isArray(this.cell.stateSize)?this.states_=this.cell.stateSize.map(e=>zeros$2([n,e])):this.states_[0]=zeros$2([n,this.cell.stateSize]);else{if(Array.isArray(e)||(e=[e]),e.length!==this.states_.length)throw new ValueError(`Layer ${this.name} expects ${this.states_.length} state(s), but it received ${e.length} state value(s). Input received: ${e}`);!0===t?this.keptStates.push(this.states_.slice()):dispose(this.states_);for(let t=0;t<this.states_.length;++t){const r=e[t],a=Array.isArray(this.cell.stateSize)?this.cell.stateSize[t]:this.cell.stateSize,s=[n,a];if(!arraysEqual(r.shape,s))throw new ValueError(`State ${t} is incompatible with layer ${this.name}: expected shape=${s}, received shape=${r.shape}`);this.states_[t]=r}}this.states_=this.states_.map(e=>keep(e.clone()))})}apply(e,t){let n=null==t?null:t.initialState,r=null==t?null:t.constants;null==t&&(t={});const a=standardizeArgs(e,n,r,this.numConstants);e=a.inputs,n=a.initialState,r=a.constants;let s=[],o=[];if(null!=n){t.initialState=n,s=s.concat(n),this.stateSpec=[];for(const e of n)this.stateSpec.push(new InputSpec({shape:e.shape}));o=o.concat(this.stateSpec)}if(null!=r&&(t.constants=r,s=s.concat(r),this.numConstants=r.length),s[0]instanceof SymbolicTensor){const n=[e].concat(s),r=this.inputSpec.concat(o),a=this.inputSpec;this.inputSpec=r;const i=super.apply(n,t);return this.inputSpec=a,i}return super.apply(e,t)}call(e,t){return tidy(()=>{const n=null==t?null:t.mask,r=null==t?null:t.training;let a=null==t?null:t.initialState;e=getExactlyOneTensor(e),null==a&&(a=this.stateful?this.states_:this.getInitialState(e));const s=Array.isArray(this.cell.stateSize)?this.cell.stateSize.length:1;if(a.length!==s)throw new ValueError(`RNN Layer has ${s} state(s) but was passed ${a.length} initial state(s).`);this.unroll&&console.warn("Ignoring unroll = true for RNN layer, due to imperative backend.");const o={training:r},i=rnn$1((e,t)=>{const n=this.cell.call([e].concat(t),o);return[n[0],n.slice(1)]},e,a,this.goBackwards,n,null,this.unroll,this.returnSequences),l=i[0],u=i[1],c=i[2];this.stateful&&this.resetStates(c,r);const p=this.returnSequences?u:l;return this.returnState?[p].concat(c):p})}getInitialState(e){return tidy(()=>{let t=zeros$2(e.shape);return t=sum$2(t,[1,2]),t=expandDims$2(t),Array.isArray(this.cell.stateSize)?this.cell.stateSize.map(e=>e>1?tile$2(t,[1,e]):t):this.cell.stateSize>1?[tile$2(t,[1,this.cell.stateSize])]:[t]})}get trainableWeights(){return this.trainable?this.cell.trainableWeights:[]}get nonTrainableWeights(){return this.trainable?this.cell.nonTrainableWeights:this.cell.weights}setFastWeightInitDuringBuild(e){super.setFastWeightInitDuringBuild(e),null!=this.cell&&this.cell.setFastWeightInitDuringBuild(e)}getConfig(){const e=super.getConfig(),t={returnSequences:this.returnSequences,returnState:this.returnState,goBackwards:this.goBackwards,stateful:this.stateful,unroll:this.unroll};null!=this.numConstants&&(t.numConstants=this.numConstants);const n=this.cell.getConfig();return this.getClassName()===RNN.className&&(t.cell={className:this.cell.getClassName(),config:n}),Object.assign({},n,e,t)}static fromConfig(e,t,n={}){const r=deserialize(t.cell,n);return new e(Object.assign(t,{cell:r}))}}RNN.className="RNN",registerClass(RNN);class RNNCell extends Layer{}class SimpleRNNCell extends RNNCell{constructor(e){super(e),this.DEFAULT_ACTIVATION="tanh",this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_RECURRENT_INITIALIZER="orthogonal",this.DEFAULT_BIAS_INITIALIZER="zeros",this.units=e.units,assertPositiveInteger(this.units,"units"),this.activation=getActivation(null==e.activation?this.DEFAULT_ACTIVATION:e.activation),this.useBias=null==e.useBias||e.useBias,this.kernelInitializer=getInitializer(e.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.recurrentInitializer=getInitializer(e.recurrentInitializer||this.DEFAULT_RECURRENT_INITIALIZER),this.biasInitializer=getInitializer(e.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.kernelRegularizer=getRegularizer(e.kernelRegularizer),this.recurrentRegularizer=getRegularizer(e.recurrentRegularizer),this.biasRegularizer=getRegularizer(e.biasRegularizer),this.kernelConstraint=getConstraint(e.kernelConstraint),this.recurrentConstraint=getConstraint(e.recurrentConstraint),this.biasConstraint=getConstraint(e.biasConstraint),this.dropout=min$2([1,max$2([0,null==e.dropout?0:e.dropout])]),this.recurrentDropout=min$2([1,max$2([0,null==e.recurrentDropout?0:e.recurrentDropout])]),this.stateSize=this.units,this.dropoutMask=null,this.recurrentDropoutMask=null}build(e){e=getExactlyOneShape(e),this.kernel=this.addWeight("kernel",[e[e.length-1],this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.recurrentKernel=this.addWeight("recurrent_kernel",[this.units,this.units],null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.bias=this.useBias?this.addWeight("bias",[this.units],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint):null,this.built=!0}call(e,t){return tidy(()=>{if(2!==(e=e).length)throw new ValueError(`SimpleRNNCell expects 2 input Tensors, got ${e.length}.`);let n=e[1];e=e[0];const r=null!=t.training&&t.training;let a;0<this.dropout&&this.dropout<1&&null==this.dropoutMask&&(this.dropoutMask=generateDropoutMask({ones:()=>onesLike$2(e),rate:this.dropout,training:r})),0<this.recurrentDropout&&this.recurrentDropout<1&&null==this.recurrentDropoutMask&&(this.recurrentDropoutMask=generateDropoutMask({ones:()=>onesLike$2(n),rate:this.recurrentDropout,training:r}));const s=this.dropoutMask,o=this.recurrentDropoutMask;a=dot$1(null!=s?mul(e,s):e,this.kernel.read()),null!=this.bias&&(a=biasAdd(a,this.bias.read())),null!=o&&(n=mul(n,o));let i=add$2(a,dot$1(n,this.recurrentKernel.read()));return null!=this.activation&&(i=this.activation.apply(i)),[i,i]})}getConfig(){const e=super.getConfig(),t={units:this.units,activation:serializeActivation(this.activation),useBias:this.useBias,kernelInitializer:serializeInitializer(this.kernelInitializer),recurrentInitializer:serializeInitializer(this.recurrentInitializer),biasInitializer:serializeInitializer(this.biasInitializer),kernelRegularizer:serializeRegularizer(this.kernelRegularizer),recurrentRegularizer:serializeRegularizer(this.recurrentRegularizer),biasRegularizer:serializeRegularizer(this.biasRegularizer),activityRegularizer:serializeRegularizer(this.activityRegularizer),kernelConstraint:serializeConstraint(this.kernelConstraint),recurrentConstraint:serializeConstraint(this.recurrentConstraint),biasConstraint:serializeConstraint(this.biasConstraint),dropout:this.dropout,recurrentDropout:this.recurrentDropout};return Object.assign({},e,t)}}SimpleRNNCell.className="SimpleRNNCell",registerClass(SimpleRNNCell);class SimpleRNN extends RNN{constructor(e){e.cell=new SimpleRNNCell(e),super(e)}call(e,t){return tidy(()=>(null!=this.cell.dropoutMask&&(dispose(this.cell.dropoutMask),this.cell.dropoutMask=null),null!=this.cell.recurrentDropoutMask&&(dispose(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null),super.call(e,{mask:null==t?null:t.mask,training:null==t?null:t.training,initialState:null==t?null:t.initialState})))}static fromConfig(e,t){return new e(t)}}SimpleRNN.className="SimpleRNN",registerClass(SimpleRNN);class GRUCell extends RNNCell{constructor(e){if(super(e),this.DEFAULT_ACTIVATION="tanh",this.DEFAULT_RECURRENT_ACTIVATION="hardSigmoid",this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_RECURRENT_INITIALIZER="orthogonal",this.DEFAULT_BIAS_INITIALIZER="zeros",e.resetAfter)throw new ValueError("GRUCell does not support reset_after parameter set to true.");this.units=e.units,assertPositiveInteger(this.units,"units"),this.activation=getActivation(void 0===e.activation?this.DEFAULT_ACTIVATION:e.activation),this.recurrentActivation=getActivation(void 0===e.recurrentActivation?this.DEFAULT_RECURRENT_ACTIVATION:e.recurrentActivation),this.useBias=null==e.useBias||e.useBias,this.kernelInitializer=getInitializer(e.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.recurrentInitializer=getInitializer(e.recurrentInitializer||this.DEFAULT_RECURRENT_INITIALIZER),this.biasInitializer=getInitializer(e.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.kernelRegularizer=getRegularizer(e.kernelRegularizer),this.recurrentRegularizer=getRegularizer(e.recurrentRegularizer),this.biasRegularizer=getRegularizer(e.biasRegularizer),this.kernelConstraint=getConstraint(e.kernelConstraint),this.recurrentConstraint=getConstraint(e.recurrentConstraint),this.biasConstraint=getConstraint(e.biasConstraint),this.dropout=min$2([1,max$2([0,null==e.dropout?0:e.dropout])]),this.recurrentDropout=min$2([1,max$2([0,null==e.recurrentDropout?0:e.recurrentDropout])]),this.implementation=e.implementation,this.stateSize=this.units,this.dropoutMask=null,this.recurrentDropoutMask=null}build(e){e=getExactlyOneShape(e),this.kernel=this.addWeight("kernel",[e[e.length-1],3*this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.recurrentKernel=this.addWeight("recurrent_kernel",[this.units,3*this.units],null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.bias=this.useBias?this.addWeight("bias",[3*this.units],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint):null,this.built=!0}call(e,t){return tidy(()=>{if(2!==(e=e).length)throw new ValueError(`GRUCell expects 2 input Tensors (inputs, h, c), got ${e.length}.`);const n=null!=t.training&&t.training;let r=e[1];e=e[0],0<this.dropout&&this.dropout<1&&null==this.dropoutMask&&(this.dropoutMask=generateDropoutMask({ones:()=>onesLike$2(e),rate:this.dropout,training:n,count:3})),0<this.recurrentDropout&&this.recurrentDropout<1&&null==this.recurrentDropoutMask&&(this.recurrentDropoutMask=generateDropoutMask({ones:()=>onesLike$2(r),rate:this.recurrentDropout,training:n,count:3}));const a=this.recurrentDropoutMask;let s,o,i;0<this.dropout&&this.dropout<1&&(e=mul(e,this.dropoutMask[0]));let l=dot$1(e,this.kernel.read());this.useBias&&(l=biasAdd(l,this.bias.read())),0<this.recurrentDropout&&this.recurrentDropout<1&&(r=mul(r,a[0]));const u=this.recurrentKernel.read(),[c,p]=split$2(u,[2*this.units,this.units],u.rank-1),d=dot$1(r,c),[h,m,f]=split$2(l,3,l.rank-1),[g,$]=split$2(d,2,d.rank-1);s=this.recurrentActivation.apply(add$2(h,g)),o=this.recurrentActivation.apply(add$2(m,$));const y=dot$1(mul(o,r),p);i=this.activation.apply(add$2(f,y));const b=add$2(mul(s,r),mul(add$2(1,neg$2(s)),i));return[b,b]})}getConfig(){const e=super.getConfig(),t={units:this.units,activation:serializeActivation(this.activation),recurrentActivation:serializeActivation(this.recurrentActivation),useBias:this.useBias,kernelInitializer:serializeInitializer(this.kernelInitializer),recurrentInitializer:serializeInitializer(this.recurrentInitializer),biasInitializer:serializeInitializer(this.biasInitializer),kernelRegularizer:serializeRegularizer(this.kernelRegularizer),recurrentRegularizer:serializeRegularizer(this.recurrentRegularizer),biasRegularizer:serializeRegularizer(this.biasRegularizer),activityRegularizer:serializeRegularizer(this.activityRegularizer),kernelConstraint:serializeConstraint(this.kernelConstraint),recurrentConstraint:serializeConstraint(this.recurrentConstraint),biasConstraint:serializeConstraint(this.biasConstraint),dropout:this.dropout,recurrentDropout:this.recurrentDropout,implementation:this.implementation,resetAfter:!1};return Object.assign({},e,t)}}GRUCell.className="GRUCell",registerClass(GRUCell);class GRU extends RNN{constructor(e){0===e.implementation&&console.warn("`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call."),e.cell=new GRUCell(e),super(e)}call(e,t){return tidy(()=>(null!=this.cell.dropoutMask&&(dispose(this.cell.dropoutMask),this.cell.dropoutMask=null),null!=this.cell.recurrentDropoutMask&&(dispose(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null),super.call(e,{mask:null==t?null:t.mask,training:null==t?null:t.training,initialState:null==t?null:t.initialState})))}static fromConfig(e,t){return 0===t.implmentation&&(t.implementation=1),new e(t)}}GRU.className="GRU",registerClass(GRU);class LSTMCell extends RNNCell{constructor(e){super(e),this.DEFAULT_ACTIVATION="tanh",this.DEFAULT_RECURRENT_ACTIVATION="hardSigmoid",this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_RECURRENT_INITIALIZER="orthogonal",this.DEFAULT_BIAS_INITIALIZER="zeros",this.units=e.units,assertPositiveInteger(this.units,"units"),this.activation=getActivation(void 0===e.activation?this.DEFAULT_ACTIVATION:e.activation),this.recurrentActivation=getActivation(void 0===e.recurrentActivation?this.DEFAULT_RECURRENT_ACTIVATION:e.recurrentActivation),this.useBias=null==e.useBias||e.useBias,this.kernelInitializer=getInitializer(e.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.recurrentInitializer=getInitializer(e.recurrentInitializer||this.DEFAULT_RECURRENT_INITIALIZER),this.biasInitializer=getInitializer(e.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.unitForgetBias=e.unitForgetBias,this.kernelRegularizer=getRegularizer(e.kernelRegularizer),this.recurrentRegularizer=getRegularizer(e.recurrentRegularizer),this.biasRegularizer=getRegularizer(e.biasRegularizer),this.kernelConstraint=getConstraint(e.kernelConstraint),this.recurrentConstraint=getConstraint(e.recurrentConstraint),this.biasConstraint=getConstraint(e.biasConstraint),this.dropout=min$2([1,max$2([0,null==e.dropout?0:e.dropout])]),this.recurrentDropout=min$2([1,max$2([0,null==e.recurrentDropout?0:e.recurrentDropout])]),this.implementation=e.implementation,this.stateSize=[this.units,this.units],this.dropoutMask=null,this.recurrentDropoutMask=null}build(e){var t;let n;if(e=getExactlyOneShape(e),this.kernel=this.addWeight("kernel",[e[e.length-1],4*this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.recurrentKernel=this.addWeight("recurrent_kernel",[this.units,4*this.units],null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.useBias){if(this.unitForgetBias){const e=this.biasInitializer,r=this.units;n=new((t=class extends Initializer{apply(t,n){const a=e.apply([r]),s=(new Ones).apply([r]),o=e.apply([2*r]);return concatAlongFirstAxis(concatAlongFirstAxis(a,s),o)}}).className="CustomInit",t)}else n=this.biasInitializer;this.bias=this.addWeight("bias",[4*this.units],null,n,this.biasRegularizer,!0,this.biasConstraint)}else this.bias=null;this.built=!0}call(e,t){return tidy(()=>{const n=null!=t.training&&t.training;if(3!==(e=e).length)throw new ValueError(`LSTMCell expects 3 input Tensors (inputs, h, c), got ${e.length}.`);let r=e[1];const a=e[2];e=e[0],0<this.dropout&&this.dropout<1&&null==this.dropoutMask&&(this.dropoutMask=generateDropoutMask({ones:()=>onesLike$2(e),rate:this.dropout,training:n,count:4})),0<this.recurrentDropout&&this.recurrentDropout<1&&null==this.recurrentDropoutMask&&(this.recurrentDropoutMask=generateDropoutMask({ones:()=>onesLike$2(r),rate:this.recurrentDropout,training:n,count:4}));const s=this.recurrentDropoutMask;let o,i,l,u;0<this.dropout&&this.dropout<1&&(e=mul(e,this.dropoutMask[0]));let c=dot$1(e,this.kernel.read());0<this.recurrentDropout&&this.recurrentDropout<1&&(r=mul(r,s[0])),c=add$2(c,dot$1(r,this.recurrentKernel.read())),this.useBias&&(c=biasAdd(c,this.bias.read()));const[p,d,h,m]=split$2(c,4,c.rank-1);o=this.recurrentActivation.apply(p),i=this.recurrentActivation.apply(d),l=add$2(mul(i,a),mul(o,this.activation.apply(h))),u=this.recurrentActivation.apply(m);const f=mul(u,this.activation.apply(l));return[f,f,l]})}getConfig(){const e=super.getConfig(),t={units:this.units,activation:serializeActivation(this.activation),recurrentActivation:serializeActivation(this.recurrentActivation),useBias:this.useBias,kernelInitializer:serializeInitializer(this.kernelInitializer),recurrentInitializer:serializeInitializer(this.recurrentInitializer),biasInitializer:serializeInitializer(this.biasInitializer),unitForgetBias:this.unitForgetBias,kernelRegularizer:serializeRegularizer(this.kernelRegularizer),recurrentRegularizer:serializeRegularizer(this.recurrentRegularizer),biasRegularizer:serializeRegularizer(this.biasRegularizer),activityRegularizer:serializeRegularizer(this.activityRegularizer),kernelConstraint:serializeConstraint(this.kernelConstraint),recurrentConstraint:serializeConstraint(this.recurrentConstraint),biasConstraint:serializeConstraint(this.biasConstraint),dropout:this.dropout,recurrentDropout:this.recurrentDropout,implementation:this.implementation};return Object.assign({},e,t)}}LSTMCell.className="LSTMCell",registerClass(LSTMCell);class LSTM extends RNN{constructor(e){0===e.implementation&&console.warn("`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call."),e.cell=new LSTMCell(e),super(e)}call(e,t){return tidy(()=>(null!=this.cell.dropoutMask&&(dispose(this.cell.dropoutMask),this.cell.dropoutMask=null),null!=this.cell.recurrentDropoutMask&&(dispose(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null),super.call(e,{mask:null==t?null:t.mask,training:null==t?null:t.training,initialState:null==t?null:t.initialState})))}static fromConfig(e,t){return 0===t.implmentation&&(t.implementation=1),new e(t)}}LSTM.className="LSTM",registerClass(LSTM);class StackedRNNCells extends RNNCell{constructor(e){super(e),this.cells=e.cells}get stateSize(){const e=[];for(const t of this.cells.slice().reverse())Array.isArray(t.stateSize)?e.push(...t.stateSize):e.push(t.stateSize);return e}call(e,t){return tidy(()=>{let n=(e=e).slice(1);const r=[];for(const e of this.cells.slice().reverse())Array.isArray(e.stateSize)?r.push(n.splice(0,e.stateSize.length)):r.push(n.splice(0,1));r.reverse();const a=[];let s;for(let o=0;o<this.cells.length;++o){const i=this.cells[o];n=r[o],s=0===o?[e[0]].concat(n):[s[0]].concat(n),s=i.call(s,t),a.push(s.slice(1))}n=[];for(const e of a.slice().reverse())n.push(...e);return[s[0]].concat(n)})}build(e){let t;isArrayOfShapes(e)&&(e=e[0]),e=e,this.cells.forEach((n,r)=>{nameScope(`RNNCell_${r}`,()=>{n.build(e),t=Array.isArray(n.stateSize)?n.stateSize[0]:n.stateSize,e=[e[0],t]})}),this.built=!0}getConfig(){const e=super.getConfig(),t=this.cells.map(e=>({className:e.getClassName(),config:e.getConfig()}));return Object.assign({},e,{cells:t})}static fromConfig(e,t,n={}){const r=[];for(const e of t.cells)r.push(deserialize(e,n));return new e({cells:r})}get trainableWeights(){if(!this.trainable)return[];const e=[];for(const t of this.cells)e.push(...t.trainableWeights);return e}get nonTrainableWeights(){const e=[];for(const t of this.cells)e.push(...t.nonTrainableWeights);if(!this.trainable){const t=[];for(const e of this.cells)t.push(...e.trainableWeights);return t.concat(e)}return e}getWeights(){const e=[];for(const t of this.cells)e.push(...t.weights);return batchGetValue(e)}setWeights(e){const t=[];for(const n of this.cells){const r=e.splice(n.weights.length);for(let e=0;e<n.weights.length;++e)t.push([n.weights[e],r[e]])}batchSetValue(t)}}function generateDropoutMask(e){const{ones:t,rate:n,training:r=!1,count:a=1}=e,s=()=>dropout$1(t(),n),o=()=>inTrainPhase(s,t,r);return!a||a<=1?keep(o().clone()):Array(a).fill(void 0).map(o).map(e=>keep(e.clone()))}StackedRNNCells.className="StackedRNNCells",registerClass(StackedRNNCells);var __rest=function(e,t){var n={};for(var r in e)Object.prototype.hasOwnProperty.call(e,r)&&t.indexOf(r)<0&&(n[r]=e[r]);if(null!=e&&"function"==typeof Object.getOwnPropertySymbols){var a=0;for(r=Object.getOwnPropertySymbols(e);a<r.length;a++)t.indexOf(r[a])<0&&Object.prototype.propertyIsEnumerable.call(e,r[a])&&(n[r[a]]=e[r[a]])}return n};class ConvRNN2D extends RNN{constructor(e){if(e.unroll)throw new NotImplementedError("Unrolling is not possible with convolutional RNNs.");if(Array.isArray(e.cell))throw new NotImplementedError("It is not possible at the moment to stack convolutional cells.");super(e),this.inputSpec=[new InputSpec({ndim:5})]}call(e,t){return tidy(()=>{if(null!=this.cell.dropoutMask&&(dispose(this.cell.dropoutMask),this.cell.dropoutMask=null),null!=this.cell.recurrentDropoutMask&&(dispose(this.cell.recurrentDropoutMask),this.cell.recurrentDropoutMask=null),t&&t.constants)throw new ValueError("ConvRNN2D cell does not support constants");return super.call(e,{mask:null==t?null:t.mask,training:null==t?null:t.training,initialState:null==t?null:t.initialState})})}computeOutputShape(e){let t=this.computeSingleOutputShape(e);return this.returnSequences||(t=[t[0],...t.slice(2)]),this.returnState&&(t=[t,...Array(2).fill([e[0],...t.slice(-3)])]),t}getInitialState(e){return tidy(()=>{const{stateSize:t}=this.cell,n=this.computeSingleOutputShape(e.shape),r=zeros$2([n[0],...n.slice(2)]);return Array.isArray(t)?Array(t.length).fill(r):[r]})}resetStates(e,t=!1){tidy(()=>{if(!this.stateful)throw new AttributeError("Cannot call resetStates() on an RNN Layer that is not stateful.");const n=this.inputSpec[0].shape,r=this.computeSingleOutputShape(n),a=[r[0],...r.slice(2)];if(null==n[0])throw new ValueError("If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.");if(null==this.getStates())this.states_=Array.isArray(this.cell.stateSize)?this.cell.stateSize.map(()=>zeros$2(a)):[zeros$2(a)];else if(null==e)dispose(this.states_),null!=this.keptStates&&(dispose(this.keptStates),this.keptStates=[]),Array.isArray(this.cell.stateSize)?this.states_=this.cell.stateSize.map(()=>zeros$2(a)):this.states_[0]=zeros$2(a);else{if(Array.isArray(e)||(e=[e]),e.length!==this.states_.length)throw new ValueError(`Layer ${this.name} expects ${this.states_.length} state(s), but it received ${e.length} state value(s). Input received: ${e}`);t?this.keptStates.push(this.states_.slice()):dispose(this.states_);for(let t=0;t<this.states_.length;++t){const n=e[t],r=a;if(!arraysEqual(n.shape,r))throw new ValueError(`State ${t} is incompatible with layer ${this.name}: expected shape=${r}, received shape=${n.shape}`);this.states_[t]=n}}this.states_=this.states_.map(e=>keep(e.clone()))})}computeSingleOutputShape(e){const{dataFormat:t,filters:n,kernelSize:r,padding:a,strides:s,dilationRate:o}=this.cell,i="channelsFirst"===t,l=e[i?4:3],u=convOutputLength(e[i?3:2],r[0],a,s[0],o[0]),c=convOutputLength(l,r[1],a,s[1],o[1]);return[...e.slice(0,2),...i?[n,u,c]:[u,c,n]]}}ConvRNN2D.className="ConvRNN2D";class ConvLSTM2DCell extends LSTMCell{constructor(e){const{filters:t,kernelSize:n,strides:r,padding:a,dataFormat:s,dilationRate:o}=e;super(Object.assign({},e,{units:t})),this.filters=t,assertPositiveInteger(this.filters,"filters"),this.kernelSize=normalizeArray(n,2,"kernelSize"),this.kernelSize.forEach(e=>assertPositiveInteger(e,"kernelSize")),this.strides=normalizeArray(r||1,2,"strides"),this.strides.forEach(e=>assertPositiveInteger(e,"strides")),this.padding=a||"valid",checkPaddingMode(this.padding),this.dataFormat=s||"channelsLast",checkDataFormat(this.dataFormat),this.dilationRate=normalizeArray(o||1,2,"dilationRate"),this.dilationRate.forEach(e=>assertPositiveInteger(e,"dilationRate"))}build(e){var t;e=getExactlyOneShape(e);const n="channelsFirst"===this.dataFormat?1:e.length-1;if(null==e[n])throw new ValueError(`The channel dimension of the input should be defined. Found ${e[n]}`);const r=this.kernelSize.concat([e[n],4*this.filters]);this.kernel=this.addWeight("kernel",r,null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint);const a=this.kernelSize.concat([this.filters,4*this.filters]);if(this.recurrentKernel=this.addWeight("recurrent_kernel",a,null,this.recurrentInitializer,this.recurrentRegularizer,!0,this.recurrentConstraint),this.useBias){let e;if(this.unitForgetBias){const n=this.biasInitializer,r=this.filters;e=new((t=class extends Initializer{apply(e,t){return concatenate$1([n.apply([r]),ones$1([r]),n.apply([2*r])])}}).className="CustomInit",t)}else e=this.biasInitializer;this.bias=this.addWeight("bias",[4*this.filters],null,e,this.biasRegularizer,!0,this.biasConstraint)}this.built=!0}call(e,t){return tidy(()=>{if(3!==e.length)throw new ValueError(`ConvLSTM2DCell expects 3 input Tensors (inputs, h, c), got ${e.length}.`);const n=t.training||!1,r=e[0],a=e[1],s=e[2];0<this.dropout&&this.dropout<1&&null==this.dropoutMask&&(this.dropoutMask=generateDropoutMask({ones:()=>onesLike$2(r),rate:this.dropout,training:n,count:4}));const o=this.dropoutMask,i=(e,t,n)=>t&&t[n]?mul(t[n],e):e;let l=i(r,o,0),u=i(r,o,1),c=i(r,o,2),p=i(r,o,3);0<this.recurrentDropout&&this.recurrentDropout<1&&null==this.recurrentDropoutMask&&(this.recurrentDropoutMask=generateDropoutMask({ones:()=>onesLike$2(a),rate:this.recurrentDropout,training:n,count:4}));const d=this.recurrentDropoutMask;let h=i(a,d,0),m=i(a,d,1),f=i(a,d,2),g=i(a,d,3);const[$,y,b,x]=split$2(this.kernel.read(),4,3),[v,I,C,S]=this.useBias?split$2(this.bias.read(),4):[null,null,null,null];l=this.inputConv(l,$,v,this.padding),u=this.inputConv(u,y,I,this.padding),c=this.inputConv(c,b,C,this.padding),p=this.inputConv(p,x,S,this.padding);const[k,T,N,w]=split$2(this.recurrentKernel.read(),4,3);h=this.recurrentConv(h,k),m=this.recurrentConv(m,T),f=this.recurrentConv(f,N),g=this.recurrentConv(g,w);const E=this.recurrentActivation.apply(add$2(l,h)),A=this.recurrentActivation.apply(add$2(u,m)),D=add$2(mul(A,s),mul(E,this.activation.apply(add$2(c,f)))),R=mul(this.recurrentActivation.apply(add$2(p,g)),this.activation.apply(D));return[R,R,D]})}getConfig(){const e=super.getConfig(),t=__rest(e,["units"]);return Object.assign({},t,{filters:this.filters,kernelSize:this.kernelSize,padding:this.padding,dataFormat:this.dataFormat,dilationRate:this.dilationRate,strides:this.strides})}inputConv(e,t,n,r){const a=conv2d$3(e,t,this.strides,r||"valid","channelsFirst"===this.dataFormat?"NCHW":"NHWC",this.dilationRate);return n?biasAdd(a,n,this.dataFormat):a}recurrentConv(e,t){return conv2d$3(e,t,1,"same","channelsFirst"===this.dataFormat?"NCHW":"NHWC")}}ConvLSTM2DCell.className="ConvLSTM2DCell",registerClass(ConvLSTM2DCell);class ConvLSTM2D extends ConvRNN2D{constructor(e){const t=new ConvLSTM2DCell(e);super(Object.assign({},e,{cell:t}))}static fromConfig(e,t){return new e(t)}}ConvLSTM2D.className="ConvLSTM2D",registerClass(ConvLSTM2D);class Dropout extends Layer{constructor(e){super(e),this.rate=Math.max(Math.min(e.rate,1),0),this.noiseShape=e.noiseShape,this.seed=e.seed,this.supportsMasking=!0}getNoiseShape(e){if(null==this.noiseShape)return this.noiseShape;const t=e.shape,n=[];for(let e=0;e<this.noiseShape.length;++e)n.push(null==this.noiseShape[e]?t[e]:this.noiseShape[e]);return n}call(e,t){return tidy(()=>{this.invokeCallHook(e,t);const n=getExactlyOneTensor(e);if(0<this.rate&&this.rate<1){const e=null!=t.training&&t.training,r=this.getNoiseShape(n);return inTrainPhase(()=>dropout$1(n,this.rate,r,this.seed),()=>n,e)}return e})}getConfig(){const e={rate:this.rate,noiseShape:this.noiseShape,seed:this.seed},t=super.getConfig();return Object.assign(e,t),e}dispose(){return super.dispose()}}Dropout.className="Dropout",registerClass(Dropout);class SpatialDropout1D extends Dropout{constructor(e){super(e),this.inputSpec=[{ndim:3}]}getNoiseShape(e){const t=e.shape;return[t[0],1,t[2]]}}SpatialDropout1D.className="SpatialDropout1D",registerClass(SpatialDropout1D);class Dense extends Layer{constructor(e){if(super(e),this.activation=null,this.useBias=!0,this.kernel=null,this.bias=null,this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_BIAS_INITIALIZER="zeros",null==e.batchInputShape&&null==e.inputShape&&null!=e.inputDim){let t=null;null!=e.batchSize&&(t=e.batchSize),this.batchInputShape=[t,e.inputDim]}this.units=e.units,assertPositiveInteger(this.units,"units"),this.activation=getActivation(e.activation),null!=e.useBias&&(this.useBias=e.useBias),this.kernelInitializer=getInitializer(e.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.biasInitializer=getInitializer(e.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.kernelConstraint=getConstraint(e.kernelConstraint),this.biasConstraint=getConstraint(e.biasConstraint),this.kernelRegularizer=getRegularizer(e.kernelRegularizer),this.biasRegularizer=getRegularizer(e.biasRegularizer),this.activityRegularizer=getRegularizer(e.activityRegularizer),this.supportsMasking=!0,this.inputSpec=[{minNDim:2}]}build(e){const t=(e=getExactlyOneShape(e))[e.length-1];null==this.kernel&&(this.kernel=this.addWeight("kernel",[t,this.units],null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.units],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint))),this.inputSpec=[{minNDim:2,axes:{[-1]:t}}],this.built=!0}computeOutputShape(e){const t=(e=getExactlyOneShape(e)).slice();return t[t.length-1]=this.units,t}call(e,t){return tidy(()=>{this.invokeCallHook(e,t);const n=getExactlyOneTensor(e),r=mapActivationToFusedKernel(this.activation.getClassName());let a;return null!=r?a=dot$1(n,this.kernel.read(),r,this.bias?this.bias.read():null):(a=dot$1(n,this.kernel.read()),null!=this.bias&&(a=biasAdd(a,this.bias.read())),null!=this.activation&&(a=this.activation.apply(a))),a})}getConfig(){const e={units:this.units,activation:serializeActivation(this.activation),useBias:this.useBias,kernelInitializer:serializeInitializer(this.kernelInitializer),biasInitializer:serializeInitializer(this.biasInitializer),kernelRegularizer:serializeRegularizer(this.kernelRegularizer),biasRegularizer:serializeRegularizer(this.biasRegularizer),activityRegularizer:serializeRegularizer(this.activityRegularizer),kernelConstraint:serializeConstraint(this.kernelConstraint),biasConstraint:serializeConstraint(this.biasConstraint)},t=super.getConfig();return Object.assign(e,t),e}}Dense.className="Dense",registerClass(Dense);class Flatten extends Layer{constructor(e){super(e=e||{}),this.inputSpec=[{minNDim:3}],this.dataFormat=e.dataFormat}computeOutputShape(e){e=getExactlyOneShape(e);for(const t of e.slice(1))if(null==t)throw new ValueError(`The shape of the input to "Flatten" is not fully defined (got ${e.slice(1)}). Make sure to pass a complete "input_shape" or "batch_input_shape" argument to the first layer in your model.`);return[e[0],arrayProd(e,1)]}call(e,t){return tidy(()=>{this.invokeCallHook(e,t);let n=getExactlyOneTensor(e);if("channelsFirst"===this.dataFormat&&n.rank>1){const e=[0];for(let t=2;t<n.rank;++t)e.push(t);e.push(1),n=transpose$2(n,e)}return batchFlatten(n)})}getConfig(){const e={};null!=this.dataFormat&&(e.dataFormat=this.dataFormat);const t=super.getConfig();return Object.assign(e,t),e}}Flatten.className="Flatten",registerClass(Flatten);class Activation extends Layer{constructor(e){super(e),this.supportsMasking=!0,this.activation=getActivation(e.activation)}call(e,t){return tidy(()=>{this.invokeCallHook(e,t);const n=getExactlyOneTensor(e);return this.activation.apply(n)})}getConfig(){const e={activation:serializeActivation(this.activation)},t=super.getConfig();return Object.assign(e,t),e}}Activation.className="Activation",registerClass(Activation);class RepeatVector extends Layer{constructor(e){super(e),this.n=e.n,this.inputSpec=[{ndim:2}]}computeOutputShape(e){return[e[0],this.n,e[1]]}call(e,t){return tidy(()=>repeat$1(e=getExactlyOneTensor(e),this.n))}getConfig(){const e={n:this.n},t=super.getConfig();return Object.assign(e,t),e}}RepeatVector.className="RepeatVector",registerClass(RepeatVector);class Reshape extends Layer{constructor(e){super(e),this.targetShape=e.targetShape;for(let e=0;e<this.targetShape.length;++e)this.isUnknown(this.targetShape[e])&&(this.targetShape[e]=null)}isUnknown(e){return e<0||null==e}fixUnknownDimension(e,t){const n="Total size of new array must be unchanged.",r=t.slice();let a=1,s=null;for(let e=0;e<r.length;++e){const t=r[e];if(this.isUnknown(t)){if(null!==s)throw new ValueError("Can only specifiy one unknown dimension.");s=e}else a*=t}const o=arrayProd(e);if(null!==s){if(0===a||o%a!=0)throw new ValueError(n);r[s]=o/a}else if(o!==a)throw new ValueError(n);return r}computeOutputShape(e){let t=!1;for(let n=0;n<e.length;++n)if(this.isUnknown(e[n])){t=!0;break}return t?e.slice(0,1).concat(this.targetShape):e.slice(0,1).concat(this.fixUnknownDimension(e.slice(1),this.targetShape))}call(e,t){return tidy(()=>{this.invokeCallHook(e,t);const n=getExactlyOneTensor(e),r=n.shape,a=r.slice(0,1).concat(this.fixUnknownDimension(r.slice(1),this.targetShape));return reshape$3(n,a)})}getConfig(){const e={targetShape:this.targetShape},t=super.getConfig();return Object.assign(e,t),e}}Reshape.className="Reshape",registerClass(Reshape);class Permute extends Layer{constructor(e){if(super(e),null==e.dims)throw new Error("Required configuration field `dims` is missing during Permute constructor call.");if(!Array.isArray(e.dims))throw new Error(`Permute constructor requires \`dims\` to be an Array, but received ${e.dims} instead.`);const t=range$3(1,e.dims.length+1);if(!arraysEqual(e.dims.slice().sort(),t))throw new Error("Invalid permutation `dims`: "+JSON.stringify(e.dims)+" `dims` must contain consecutive integers starting from 1.");this.dims=e.dims,this.dimsIncludingBatch=[0].concat(this.dims),this.inputSpec=[new InputSpec({ndim:this.dims.length+1})]}computeOutputShape(e){const t=(e=getExactlyOneShape(e)).slice();return this.dims.forEach((n,r)=>{t[r+1]=e[n]}),t}call(e,t){return transpose$2(getExactlyOneTensor(e),this.dimsIncludingBatch)}getConfig(){const e={dims:this.dims},t=super.getConfig();return Object.assign(e,t),e}}Permute.className="Permute",registerClass(Permute);class Masking extends Layer{constructor(e){super(null==e?{}:e),this.supportsMasking=!0,this.maskValue=null!=e?null==e.maskValue?0:e.maskValue:0}computeOutputShape(e){return e}getConfig(){const e=super.getConfig(),t={maskValue:this.maskValue};return Object.assign(t,e),t}computeMask(e,t){const n=getExactlyOneTensor(e);return any$2(notEqual$2(n,this.maskValue),-1)}call(e,t){return tidy(()=>{this.invokeCallHook(e,t);const n=getExactlyOneTensor(e),r=any$2(notEqual$2(n,this.maskValue),-1,!0);return mul(n,cast$3(r,n.dtype))})}}Masking.className="Masking",registerClass(Masking);class Embedding extends Layer{constructor(e){if(super(e),this.embeddings=null,this.DEFAULT_EMBEDDINGS_INITIALIZER="randomUniform",null==e.batchInputShape&&null==e.inputShape){let t=null;null!=e.batchSize&&(t=e.batchSize),this.batchInputShape=null==e.inputLength?[t,null]:[t].concat(toList(e.inputLength))}this.inputDim=e.inputDim,assertPositiveInteger(this.inputDim,"inputDim"),this.outputDim=e.outputDim,assertPositiveInteger(this.outputDim,"outputDim"),this.embeddingsInitializer=getInitializer(e.embeddingsInitializer||this.DEFAULT_EMBEDDINGS_INITIALIZER),this.embeddingsRegularizer=getRegularizer(e.embeddingsRegularizer),this.activityRegularizer=getRegularizer(e.activityRegularizer),this.embeddingsConstraint=getConstraint(e.embeddingsConstraint),this.maskZero=e.maskZero,this.supportsMasking=e.maskZero,this.inputLength=e.inputLength}build(e){this.embeddings=this.addWeight("embeddings",[this.inputDim,this.outputDim],this.dtype,this.embeddingsInitializer,this.embeddingsRegularizer,!0,this.embeddingsConstraint),this.built=!0}warnOnIncompatibleInputShape(e){}computeMask(e,t){return tidy(()=>this.maskZero?(e=getExactlyOneTensor(e),notEqual$2(e,zerosLike$2(e))):null)}computeOutputShape(e){if(e=getExactlyOneShape(e),null==this.inputLength)return[...e,this.outputDim];const t=toList(this.inputLength);if(t.length!==e.length-1)throw new ValueError(`"inputLength" is ${this.inputLength}, but received input shape has shape ${e}`);{let n=0;for(let r=0;r<t.length;++r){const a=t[r],s=e[r+1];if(null!=a&&null!=s&&a!==s)throw new ValueError(`"inputLength" is ${this.inputLength}, but received input shape has shape ${e}`);null==a&&(t[n]=s),n++}}return[e[0],...t,this.outputDim]}call(e,t){return tidy(()=>{this.invokeCallHook(e,t);let n=getExactlyOneTensor(e);"int32"!==n.dtype&&(n=cast$2(n,"int32"));const r=gather(this.embeddings.read(),reshape$3(n,[n.size]));return reshape$3(r,getExactlyOneShape(this.computeOutputShape(n.shape)))})}getConfig(){const e={inputDim:this.inputDim,outputDim:this.outputDim,embeddingsInitializer:serializeInitializer(this.embeddingsInitializer),embeddingsRegularizer:serializeRegularizer(this.embeddingsRegularizer),activityRegularizer:serializeRegularizer(this.activityRegularizer),embeddingsConstraint:serializeConstraint(this.embeddingsConstraint),maskZero:this.maskZero,inputLength:this.inputLength},t=super.getConfig();return Object.assign(e,t),e}}Embedding.className="Embedding",registerClass(Embedding);class Merge extends Layer{constructor(e){super(e||{}),this.supportsMasking=!0}mergeFunction(e){throw new NotImplementedError}computeElementwiseOpOutputShape(e,t){if(null==e||null==t)return null;if(e.length<t.length)return this.computeElementwiseOpOutputShape(t,e);if(0===t.length)return e;const n=e.slice(0,e.length-t.length);for(let r=0;r<t.length;++r){const a=e[e.length-t.length+r],s=t[r];if(null==a||null==s||a<0||s<0)n.push(null);else if(1===a)n.push(s);else if(1===s)n.push(a);else{if(a!==s)throw new ValueError("Operands could not be broadcast together with shapes "+JSON.stringify(e)+" "+JSON.stringify(t));n.push(a)}}return n}build(e){if(Array.isArray(e)&&!Array.isArray(e[0])&&(e=[getExactlyOneShape(e)]),(e=e).length<2)throw new ValueError(`A merge layer should be called on an Array of at least 2 inputs. Got ${e.length} input(s).`);let t=[];for(const n of e)null!=n&&null!==n[0]&&t.push(n[0]);if(t=unique$2(t),t.length>1)throw new ValueError(`Can not merge tensors with different batch sizes. Got tensors with shapes: ${JSON.stringify(e)}.`);let n=null==e[0]?null:e[0].slice(1);for(let t=1;t<e.length;++t){const r=null==e[t]?null:e[t].slice(1);n=this.computeElementwiseOpOutputShape(n,r)}const r=e.map(e=>e.length);this.reshapeRequired=-1!==e.indexOf(null)||1!==unique$2(r).length}call(e,t){return tidy(()=>{if(e=e,this.reshapeRequired){const t=[],n=e.map(e=>e.rank);if(-1===n.indexOf(null)){const r=max$2(n);for(let n of e){const e=n.rank;for(let t=0;t<r-e;++t)n=expandDims$2(n,1);t.push(n)}return this.mergeFunction(t)}{let n=!1;for(const r of e){const e=r.rank;if(null==e){const e=r.shape,a=e[0],s=e.slice(1).concat([a]);let o=reshape$3(r,[a].concat(arrayProd(e.slice(1))));o=transpose$2(o,[1,0]),o=reshape$3(o,s),t.push(o),n=!0}else if(e>1){const a=range$3(1,e).concat([0]);t.push(transpose$2(r,a)),n=!0}else t.push(r)}let r=this.mergeFunction(t);const a=r.rank;if(n)if(null==a){const e=r.shape,t=e[e.length-1],n=[t].concat(e.slice(0,e.length-1));r=reshape$3(transpose$2(reshape$3(r,[-1,t]),[1,0]),n)}else if(a>1){const e=[a-1].concat(range$3(0,a-1));r=transpose$2(r,e)}return r}}return this.mergeFunction(e)})}computeOutputShape(e){let t;t=null==(e=e)[0]?null:e[0].slice(1);for(let n=1;n<e.length;++n){const r=null==e[n]?null:e[n].slice(1);t=this.computeElementwiseOpOutputShape(t,r)}let n=[];for(const t of e)null!=t&&null!==t[0]&&n.push(t[0]);return n=unique$2(n),t=1===n.length?n.concat(t):[null].concat(t),t}computeMask(e,t){return tidy(()=>{if(null==t)return null;if(!Array.isArray(t))throw new ValueError("`mask` should be an Array");if(!Array.isArray(e))throw new ValueError("`inputs` should be an Array");if(t.length!==e.length)throw new ValueError(`The Array 'inputs' and 'mask' are expected to have the same length, but have different lengths (${e.length} vs ${t.length})`);if(t.every(e=>null==e))return null;let n=(t=t.map(e=>null==e?e:expandDims$3(e,0)))[0];for(let e=1;e<t.length-1;++e)n=logicalAnd$2(n,t[e]);return n})}}class Add extends Merge{constructor(e){super(e)}mergeFunction(e){return tidy(()=>{let t=e[0].clone();for(let n=1;n<e.length;++n)t=add$2(t,e[n]);return t})}}Add.className="Add",registerClass(Add);class Multiply extends Merge{constructor(e){super(e)}mergeFunction(e){return tidy(()=>{let t=e[0].clone();for(let n=1;n<e.length;++n)t=mul(t,e[n]);return t})}}Multiply.className="Multiply",registerClass(Multiply);class Average extends Merge{constructor(e){super(e)}mergeFunction(e){return tidy(()=>{let t=e[0].clone();for(let n=1;n<e.length;++n)t=add$2(t,e[n]);return mul(1/e.length,t)})}}Average.className="Average",registerClass(Average);class Maximum extends Merge{constructor(e){super(e)}mergeFunction(e){return tidy(()=>{let t=e[0];for(let n=1;n<e.length;++n)t=maximum$3(t,e[n]);return t})}}Maximum.className="Maximum",registerClass(Maximum);class Minimum extends Merge{constructor(e){super(e)}mergeFunction(e){return tidy(()=>{let t=e[0];for(let n=1;n<e.length;++n)t=minimum$3(t,e[n]);return t})}}Minimum.className="Minimum",registerClass(Minimum);class Concatenate extends Merge{constructor(e){super(e),this.DEFAULT_AXIS=-1,null==e&&(e={}),this.axis=null==e.axis?this.DEFAULT_AXIS:e.axis,this.supportsMasking=!0,this.reshapeRequired=!1}build(e){if(!Array.isArray(e)||!Array.isArray(e[0])||1===e.length)throw new ValueError("A `Concatenate` layer should be called on a list of at least 2 inputs");e=e;let t=!0;for(const n of e)if(null!=n){t=!1;break}if(t)return;const n=[];for(let t=0;t<e.length;++t){const r=e[t].slice();r.splice(this.axis,1);let a=!1;for(const e of n)if(arraysEqual(e,r)){a=!0;break}a||n.push(r)}if(n.length>1)throw new ValueError("A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got input shapes: "+JSON.stringify(e))}mergeFunction(e){return tidy(()=>concatenate$1(e,this.axis))}computeOutputShape(e){if(!Array.isArray(e)||!Array.isArray(e[0]))throw new ValueError("A `Concatenate` layer should be called on a list of inputs.");const t=e,n=t[0].slice(),r=this.axis<0?n.length+this.axis:this.axis;for(const e of t.slice(1)){if(null==n[r]||null==e[r]){n[r]=null;break}n[r]+=e[r]}return n}computeMask(e,t){if(null==t)return null;if(!Array.isArray(t))throw new ValueError("`mask` should be an array for Concatenate");if(!Array.isArray(e))throw new ValueError("`inputs` should be an array for Concatenate");if(t.length!==e.length)throw new ValueError(`Mismatch in the length of mask (${t.length}) and the legnth of inputs (${e.length})`);return tidy(()=>{let n=!0;if(t.forEach(e=>{null==e||(n=!1)}),n)return null;const r=[];for(let n=0;n<e.length;++n)r.push(null==t[n]?cast$3(onesLike$2(e[n]),"bool"):t[n].rank<e[n].rank?expandDims$3(t[n],-1):t[n]);const a=concat$2(r,this.axis);return all$2(a,-1,!1)})}getConfig(){const e={axis:this.axis},t=super.getConfig();return Object.assign(e,t),e}}function interpretAxis(e,t){for(;e<0;)e+=t;return e}function batchDot(e,t,n){if(e.shape.length>3||t.shape.length>3)throw new NotImplementedError("batchDot is not implemented for tensors of 4D or higher rank yet");if(assert$4(e.shape.length>=2,()=>`batchDot requires the rank of x to be >= 2, but got ${e.shape.length}`),assert$4(e.shape.length>=2,()=>`batchDot requires the rank of y to be >= 2, but got ${t.shape.length}`),"number"==typeof n&&(n=[n,n]),"complex64"===e.dtype||"complex64"===t.dtype)throw new NotImplementedError("batchDot is not implemented for complex64-type Tensors yet.");const r=e.shape.length,a=t.shape.length;null==n&&(n=[r-1,a-2]);const s=n;return tidy(()=>{let n,o;if(r>a){n=r-a;const e=[];for(let t=0;t<n;++t)e.push(1);t=reshape$3(t,t.shape.concat(e))}else if(a>r){n=a-r;const t=[];for(let e=0;e<n;++e)t.push(1);e=reshape$3(e,e.shape.concat(t))}else n=0;if(o=2===e.shape.length&&2===t.shape.length?s[0]===s[1]?sum$2(mul(e,t),s[0]):sum$2(mul(transpose$2(e,[1,0]),t),s[1]):matMul$1(e,t,s[0]!==e.shape.length-1,s[1]===t.shape.length-1),n>0){let e;e=r>a?r+a-3:r-1;const t=[];for(let r=e;r<e+n;++r)t.push(r);o=squeeze(o,t)}return 1===o.shape.length&&(o=expandDims$3(o,1)),o})}Concatenate.className="Concatenate",registerClass(Concatenate);class Dot extends Merge{constructor(e){super(e),this.axes=e.axes,this.normalize=null!=e.normalize&&e.normalize,this.supportsMasking=!0,this.reshapeRequired=!1}build(e){assert$4(Array.isArray(e)&&2===e.length&&Array.isArray(e[0])&&Array.isArray(e[1]),()=>"A `Dot` layer should be called on a list of exactly 2 inputs.");const t=e[0],n=e[1];if(t.length>3||n.length>3)throw new NotImplementedError("Dot layer does not support tensors of 4D or higher rank yet.");const r=this.interpretAxes(t,n);if(t[r[0]]!==n[r[1]])throw new ValueError(`Dimension incompatibility: ${t[r[0]]} !== ${n[r[1]]}`)}mergeFunction(e){if(2!==e.length)throw new ValueError(`A \`Dot\` layer must be called on exactly 2 inputs, but received ${e.length} input(s).`);let t,n=e[0],r=e[1];return t=Array.isArray(this.axes)?this.axes.map((t,n)=>interpretAxis(t,e[n].shape.length)):[interpretAxis(this.axes,n.shape.length),interpretAxis(this.axes,r.shape.length)],this.normalize&&(n=l2Normalize(n,t[0]),r=l2Normalize(r,t[1])),batchDot(n,r,t)}interpretAxes(e,t){let n;return n=Array.isArray(this.axes)?this.axes:[interpretAxis(this.axes,e.length),interpretAxis(this.axes,t.length)],n}computeOutputShape(e){assert$4(Array.isArray(e)&&2===e.length&&Array.isArray(e[0])&&Array.isArray(e[1]),()=>"A `Dot` layer should be called on a list of exactly 2 inputs.");const t=e[0].slice(),n=e[1].slice();if(t.length>3||n.length>3)throw new NotImplementedError("Dot layer does not support tensors of 4D or higher rank yet.");const r=this.interpretAxes(t,n);t.splice(r[0],1),n.splice(r[1],1),n.splice(0,1);const a=t.concat(n);return 1===a.length&&a.push(1),a}computeMask(e,t){return null}getConfig(){const e={axes:this.axes,normalize:this.normalize},t=super.getConfig();return Object.assign(e,t),e}}Dot.className="Dot",registerClass(Dot);class GaussianNoise extends Layer{constructor(e){super(e),this.supportsMasking=!0,this.stddev=e.stddev}computeOutputShape(e){return e}getConfig(){const e=super.getConfig(),t={stddev:this.stddev};return Object.assign(t,e),t}call(e,t){return tidy(()=>{this.invokeCallHook(e,t);const n=getExactlyOneTensor(e);return inTrainPhase(()=>add$2(randomNormal$1(n.shape,0,this.stddev),n),()=>n,t.training||!1)})}}GaussianNoise.className="GaussianNoise",registerClass(GaussianNoise);class GaussianDropout extends Layer{constructor(e){super(e),this.supportsMasking=!0,this.rate=e.rate}computeOutputShape(e){return e}getConfig(){const e=super.getConfig(),t={rate:this.rate};return Object.assign(t,e),t}call(e,t){return tidy(()=>{this.invokeCallHook(e,t);const n=getExactlyOneTensor(e);return this.rate>0&&this.rate<1?inTrainPhase(()=>{const e=Math.sqrt(this.rate/(1-this.rate));return mul(n,randomNormal$1(n.shape,1,e))},()=>n,t.training||!1):n})}}GaussianDropout.className="GaussianDropout",registerClass(GaussianDropout);class AlphaDropout extends Layer{constructor(e){super(e),this.supportsMasking=!0,this.rate=e.rate,this.noiseShape=e.noiseShape}_getNoiseShape(e){return this.noiseShape||getExactlyOneTensor(e).shape}computeOutputShape(e){return e}getConfig(){const e=super.getConfig(),t={rate:this.rate};return Object.assign(t,e),t}call(e,t){return tidy(()=>{if(this.rate<1&&this.rate>0){const n=this._getNoiseShape(e);return inTrainPhase(()=>{const t=getExactlyOneTensor(e),r=-1.7580993408473766;let a=greaterEqual$2(randomUniform$1(n),this.rate);a=cast$2(a,"float32");const s=((1-this.rate)*(1+this.rate*r**2))**-.5,o=-s*r*this.rate,i=add$2(mul(t,a),mul(add$2(a,-1),r));return add$2(mul(i,s),o)},()=>getExactlyOneTensor(e),t.training||!1)}return e})}}function batchNormalization$1(e,t,n,r,a,s=.001){let o;if(2===e.rank)o=batchNorm2d(e,t,n,r,a,s);else if(3===e.rank)o=batchNorm3d(e,t,n,r,a,s);else{if(4!==e.rank)throw new NotImplementedError(`batchNormalization is not implemented for array of rank ${e.rank} yet`);o=batchNorm4d(e,t,n,r,a,s)}return o}function regularNormalizeBatchInTraining(e,t,n,r,a=.001){return tidy(()=>{const s=moments(e,r),o=s.mean,i=s.variance;return[batchNormalization$1(e,o,i,n,t,a),o,i]})}function broadcastNormalizeBatchInTraining(e,t,n,r,a=.001){return tidy(()=>{const s=moments(e,r),o=s.mean,i=s.variance,l=[];for(const t of range$3(0,e.rank))-1!==r.indexOf(t)?l.push(1):l.push(e.shape[t]);const u=reshape$3(o,l),c=reshape$3(i,l),p=null==t?null:reshape$3(t,l),d=null==n?null:reshape$3(n,l);return[batchNormalization$1(e,u,c,d,p,a),o,i]})}function normalizeBatchInTraining(e,t,n,r,a=.001){return arraysEqual(r.slice().sort(),range$3(0,e.rank-1))?regularNormalizeBatchInTraining(e,t,n,r,a):broadcastNormalizeBatchInTraining(e,t,n,r,a)}AlphaDropout.className="AlphaDropout",registerClass(AlphaDropout);class BatchNormalization extends Layer{constructor(e){null==e&&(e={}),super(e),this.supportsMasking=!0,this.axis=null==e.axis?-1:e.axis,this.momentum=null==e.momentum?.99:e.momentum,this.epsilon=null==e.epsilon?.001:e.epsilon,this.center=null==e.center||e.center,this.scale=null==e.scale||e.scale,this.betaInitializer=getInitializer(e.betaInitializer||"zeros"),this.gammaInitializer=getInitializer(e.gammaInitializer||"ones"),this.movingMeanInitializer=getInitializer(e.movingMeanInitializer||"zeros"),this.movingVarianceInitializer=getInitializer(e.movingVarianceInitializer||"ones"),this.betaConstraint=getConstraint(e.betaConstraint),this.gammaConstraint=getConstraint(e.gammaConstraint),this.betaRegularizer=getRegularizer(e.betaRegularizer),this.gammaRegularizer=getRegularizer(e.gammaRegularizer)}build(e){e=getExactlyOneShape(e);const t=this.axis>=0?this.axis:this.axis+e.length,n=e[t];if(null==n)throw new ValueError(`Axis ${t} of input tensor should have a defined dimension but the layer received an input with shape ${JSON.stringify(e)}.`);this.inputSpec=[new InputSpec({ndim:e.length,axes:{[t]:n}})];const r=[n];this.scale&&(this.gamma=this.addWeight("gamma",r,null,this.gammaInitializer,this.gammaRegularizer,!0,this.gammaConstraint)),this.center&&(this.beta=this.addWeight("beta",r,null,this.betaInitializer,this.betaRegularizer,!0,this.betaConstraint)),this.movingMean=this.addWeight("moving_mean",r,null,this.movingMeanInitializer,null,!1),this.movingVariance=this.addWeight("moving_variance",r,null,this.movingVarianceInitializer,null,!1),this.built=!0}call(e,t){return tidy(()=>{const n=null!=t.training&&t.training,r=getExactlyOneTensor(e),a=r.shape,s=a.length,o=range$3(0,s),i=this.axis>=0?this.axis:this.axis+s;o.splice(i,1);const l=pyListRepeat(1,s);l[i]=a[i];const u=o.slice();u.sort();const c=!arraysEqual(u,range$3(0,s).slice(0,s-1));if(!n)return(()=>{if(c){const e=reshape$3(this.movingMean.read(),l),t=reshape$3(this.movingVariance.read(),l),n=this.center?reshape$3(this.beta.read(),l):null,a=this.scale?reshape$3(this.gamma.read(),l):null;return batchNormalization$1(r,e,t,n,a,this.epsilon)}return batchNormalization$1(r,this.movingMean.read(),this.movingVariance.read(),null==this.beta?null:this.beta.read(),null==this.gamma?null:this.gamma.read(),this.epsilon)})();const[p,d,h]=normalizeBatchInTraining(r,this.gamma.read(),this.beta.read(),o,this.epsilon),m=(e,t,n)=>{tidy(()=>{const r=1-n,a=e.read(),s=mul(sub$2(a,t),r);e.write(sub$2(a,s))})};return(()=>{m(this.movingMean,d,this.momentum),m(this.movingVariance,h,this.momentum)})(),p})}getConfig(){const e={axis:this.axis,momentum:this.momentum,epsilon:this.epsilon,center:this.center,scale:this.scale,betaInitializer:serializeInitializer(this.betaInitializer),gammaInitializer:serializeInitializer(this.gammaInitializer),movingMeanInitializer:serializeInitializer(this.movingMeanInitializer),movingVarianceInitializer:serializeInitializer(this.movingVarianceInitializer),betaRegularizer:serializeRegularizer(this.betaRegularizer),gammaRegularizer:serializeRegularizer(this.gammaRegularizer),betaConstraint:serializeConstraint(this.betaConstraint),gammaConstraint:serializeConstraint(this.gammaConstraint)},t=super.getConfig();return Object.assign(e,t),e}}BatchNormalization.className="BatchNormalization",registerClass(BatchNormalization);class LayerNormalization extends Layer{constructor(e){if(null==e&&(e={}),super(e),this.axis=null==e.axis?-1:e.axis,"number"==typeof this.axis){if(!Number.isInteger(this.axis))throw new Error(`Expected axis to be an integer, but received ${this.axis}`)}else{if(!Array.isArray(this.axis))throw new Error(`Expected axis to be an integer or an array of integers, but received ${JSON.stringify(this.axis)}`);for(const e of this.axis)if(!Number.isInteger(e))throw new Error(`Expected axis to be an array of integers, but received ${JSON.stringify(this.axis)}`)}this.epsilon=null==e.epsilon?.001:e.epsilon,this.center=null==e.center||e.center,this.scale=null==e.scale||e.scale,this.betaInitializer=getInitializer(e.betaInitializer||"zeros"),this.gammaInitializer=getInitializer(e.gammaInitializer||"ones"),this.betaRegularizer=getRegularizer(e.betaRegularizer),this.gammaRegularizer=getRegularizer(e.gammaRegularizer),this.supportsMasking=!0}build(e){const t=(e=getExactlyOneShape(e)).length;"number"==typeof this.axis&&(this.axis=[this.axis]);for(let e=0;e<this.axis.length;++e)this.axis[e]<0&&(this.axis[e]+=t);for(const e of this.axis)if(e<0||e>=t)throw new Error(`Invalid axis: ${e}`);if(this.axis.length!==unique$2(this.axis).length)throw new Error(`Found duplicate axes in: ${this.axis}`);const n=this.axis.map(t=>e[t]);this.gamma=this.scale?this.addWeight("gamma",n,"float32",this.gammaInitializer,this.gammaRegularizer,!0):null,this.beta=this.center?this.addWeight("beta",n,"float32",this.betaInitializer,this.betaRegularizer,!0):null,this.built=!0}call(e,t){const n=getExactlyOneTensor(e),r=n.shape,a=r.length;return tidy(()=>{let{mean:e,variance:t}=moments(n,this.axis,!0);const s=pyListRepeat(1,a);for(const e of this.axis)s[e]=r[e];const o=e=>null!=e&&e.shape.length!==a&&this.axis!==[a-1]?reshape$3(e,s):e;let i=o(this.gamma.read()),l=o(this.beta.read());const u=[],c=[];for(let e=0;e<a;++e)-1!==this.axis.indexOf(e)?(u.push(r[e]),c.push(1)):(u.push(1),c.push(r[e]));return e=tile$3(e,u),t=tile$3(t,u),i=tile$3(i,c),l=tile$3(l,c),batchNormalization$1(n,e,t,l,i,this.epsilon)})}getConfig(){const e={axis:this.axis,epsilon:this.epsilon,center:this.center,scale:this.scale,betaInitializer:serializeInitializer(this.betaInitializer),gammaInitializer:serializeInitializer(this.gammaInitializer),betaRegularizer:serializeRegularizer(this.betaRegularizer),gammaRegularizer:serializeRegularizer(this.gammaRegularizer)},t=super.getConfig();return Object.assign(e,t),e}}function spatial2dPadding(e,t,n){return tidy(()=>{if(4!==e.rank)throw new ValueError(`temporalPadding expects input tensor to be 4-D, but received a ${e.rank}-D tensor.`);if(null==t&&(t=[[1,1],[1,1]]),2!==t.length||2!==t[0].length||2!==t[1].length)throw new ValueError("spatial2dPadding expects `padding` to be an Array of two Arrays, each of which is an Array of two integers.");if(null==n&&(n=imageDataFormat()),"channelsLast"!==n&&"channelsFirst"!==n)throw new ValueError(`Unknown data format: ${n}. Supported data formats are 'channelsLast' and 'channelsFirst.`);let r;return r="channelsFirst"===n?[[0,0],[0,0],t[0],t[1]]:[[0,0],t[0],t[1],[0,0]],pad(e,r)})}LayerNormalization.className="LayerNormalization",registerClass(LayerNormalization);class ZeroPadding2D extends Layer{constructor(e){if(null==e&&(e={}),super(e),this.dataFormat=null==e.dataFormat?imageDataFormat():e.dataFormat,null==e.padding)this.padding=[[1,1],[1,1]];else if("number"==typeof e.padding)this.padding=[[e.padding,e.padding],[e.padding,e.padding]];else{if(e.padding=e.padding,2!==e.padding.length)throw new ValueError(`ZeroPadding2D expects padding to be a length-2 array, but received a length-${e.padding.length} array.`);let t,n;if("number"==typeof e.padding[0])t=[e.padding[0],e.padding[0]],n=[e.padding[1],e.padding[1]];else{if(e.padding=e.padding,2!==e.padding[0].length)throw new ValueError(`ZeroPadding2D expects height padding to be a length-2 array, but received a length-${e.padding[0].length} array.`);if(t=e.padding[0],2!==e.padding[1].length)throw new ValueError(`ZeroPadding2D expects width padding to be a length-2 array, but received a length-${e.padding[1].length} array.`);n=e.padding[1]}this.padding=[t,n]}this.inputSpec=[new InputSpec({ndim:4})]}computeOutputShape(e){let t,n;return e=getExactlyOneShape(e),"channelsFirst"===this.dataFormat?(t=null!=e[2]&&e[2]>=0?e[2]+this.padding[0][0]+this.padding[0][1]:null,n=null!=e[3]&&e[3]>=0?e[3]+this.padding[1][0]+this.padding[1][1]:null,[e[0],e[1],t,n]):(t=null!=e[1]&&e[1]>=0?e[1]+this.padding[0][0]+this.padding[0][1]:null,n=null!=e[2]&&e[2]>=0?e[2]+this.padding[1][0]+this.padding[1][1]:null,[e[0],t,n,e[3]])}call(e,t){return tidy(()=>spatial2dPadding(getExactlyOneTensor(e),this.padding,this.dataFormat))}getConfig(){const e={padding:this.padding,dataFormat:this.dataFormat},t=super.getConfig();return Object.assign(e,t),e}}function pool2d(e,t,n,r,a,s){return tidy(()=>{let o;checkDataFormat(a),checkPoolMode(s),checkPaddingMode(r),null==n&&(n=[1,1]),null==r&&(r="valid"),null==a&&(a=imageDataFormat()),null==s&&(s="max"),e=preprocessConv2DInput(e,a);const i="same"===r?"same":"valid";return o="max"===s?maxPool$2(e,t,n,i):avgPool$2(e,t,n,i),"channelsFirst"===a&&(o=transpose$2(o,[0,3,1,2])),o})}function pool3d$1(e,t,n,r,a,s){return tidy(()=>{let o;checkDataFormat(a),checkPoolMode(s),checkPaddingMode(r),null==n&&(n=[1,1,1]),null==r&&(r="valid"),null==a&&(a=imageDataFormat()),null==s&&(s="max"),e=preprocessConv3DInput(e,a);const i="same"===r?"same":"valid";return o="max"===s?maxPool3d$1(e,t,n,i):avgPool3d$1(e,t,n,i),"channelsFirst"===a&&(o=transpose$2(o,[0,4,1,2,3])),o})}ZeroPadding2D.className="ZeroPadding2D",registerClass(ZeroPadding2D);class Pooling1D extends Layer{constructor(e){if(null==e.poolSize&&(e.poolSize=2),super(e),"number"==typeof e.poolSize)this.poolSize=[e.poolSize];else{if(!Array.isArray(e.poolSize)||1!==e.poolSize.length||"number"!=typeof e.poolSize[0])throw new ValueError(`poolSize for 1D convolutional layer must be a number or an Array of a single number, but received ${JSON.stringify(e.poolSize)}`);this.poolSize=e.poolSize}if(assertPositiveInteger(this.poolSize,"poolSize"),null==e.strides)this.strides=this.poolSize;else if("number"==typeof e.strides)this.strides=[e.strides];else{if(!Array.isArray(e.strides)||1!==e.strides.length||"number"!=typeof e.strides[0])throw new ValueError(`strides for 1D convolutional layer must be a number or an Array of a single number, but received ${JSON.stringify(e.strides)}`);this.strides=e.strides}assertPositiveInteger(this.strides,"strides"),this.padding=null==e.padding?"valid":e.padding,checkPaddingMode(this.padding),this.inputSpec=[new InputSpec({ndim:3})]}computeOutputShape(e){const t=convOutputLength((e=getExactlyOneShape(e))[1],this.poolSize[0],this.padding,this.strides[0]);return[e[0],t,e[2]]}call(e,t){return tidy(()=>{this.invokeCallHook(e,t),e=expandDims$2(getExactlyOneTensor(e),2);const n=this.poolingFunction(getExactlyOneTensor(e),[this.poolSize[0],1],[this.strides[0],1],this.padding,"channelsLast");return squeeze(n,[2])})}getConfig(){const e={poolSize:this.poolSize,padding:this.padding,strides:this.strides},t=super.getConfig();return Object.assign(e,t),e}}class MaxPooling1D extends Pooling1D{constructor(e){super(e)}poolingFunction(e,t,n,r,a){return checkDataFormat(a),checkPaddingMode(r),pool2d(e,t,n,r,a,"max")}}MaxPooling1D.className="MaxPooling1D",registerClass(MaxPooling1D);class AveragePooling1D extends Pooling1D{constructor(e){super(e)}poolingFunction(e,t,n,r,a){return checkDataFormat(a),checkPaddingMode(r),pool2d(e,t,n,r,a,"avg")}}AveragePooling1D.className="AveragePooling1D",registerClass(AveragePooling1D);class Pooling2D extends Layer{constructor(e){if(null==e.poolSize&&(e.poolSize=[2,2]),super(e),this.poolSize=Array.isArray(e.poolSize)?e.poolSize:[e.poolSize,e.poolSize],null==e.strides)this.strides=this.poolSize;else if(Array.isArray(e.strides)){if(2!==e.strides.length)throw new ValueError(`If the strides property of a 2D pooling layer is an Array, it is expected to have a length of 2, but received length ${e.strides.length}.`);this.strides=e.strides}else this.strides=[e.strides,e.strides];assertPositiveInteger(this.poolSize,"poolSize"),assertPositiveInteger(this.strides,"strides"),this.padding=null==e.padding?"valid":e.padding,this.dataFormat=null==e.dataFormat?"channelsLast":e.dataFormat,checkDataFormat(this.dataFormat),checkPaddingMode(this.padding),this.inputSpec=[new InputSpec({ndim:4})]}computeOutputShape(e){e=getExactlyOneShape(e);let t="channelsFirst"===this.dataFormat?e[2]:e[1],n="channelsFirst"===this.dataFormat?e[3]:e[2];return t=convOutputLength(t,this.poolSize[0],this.padding,this.strides[0]),n=convOutputLength(n,this.poolSize[1],this.padding,this.strides[1]),"channelsFirst"===this.dataFormat?[e[0],e[1],t,n]:[e[0],t,n,e[3]]}call(e,t){return tidy(()=>(this.invokeCallHook(e,t),this.poolingFunction(getExactlyOneTensor(e),this.poolSize,this.strides,this.padding,this.dataFormat)))}getConfig(){const e={poolSize:this.poolSize,padding:this.padding,strides:this.strides,dataFormat:this.dataFormat},t=super.getConfig();return Object.assign(e,t),e}}class MaxPooling2D extends Pooling2D{constructor(e){super(e)}poolingFunction(e,t,n,r,a){return checkDataFormat(a),checkPaddingMode(r),pool2d(e,t,n,r,a,"max")}}MaxPooling2D.className="MaxPooling2D",registerClass(MaxPooling2D);class AveragePooling2D extends Pooling2D{constructor(e){super(e)}poolingFunction(e,t,n,r,a){return checkDataFormat(a),checkPaddingMode(r),pool2d(e,t,n,r,a,"avg")}}AveragePooling2D.className="AveragePooling2D",registerClass(AveragePooling2D);class Pooling3D extends Layer{constructor(e){if(null==e.poolSize&&(e.poolSize=[2,2,2]),super(e),this.poolSize=Array.isArray(e.poolSize)?e.poolSize:[e.poolSize,e.poolSize,e.poolSize],null==e.strides)this.strides=this.poolSize;else if(Array.isArray(e.strides)){if(3!==e.strides.length)throw new ValueError(`If the strides property of a 3D pooling layer is an Array, it is expected to have a length of 3, but received length ${e.strides.length}.`);this.strides=e.strides}else this.strides=[e.strides,e.strides,e.strides];assertPositiveInteger(this.poolSize,"poolSize"),assertPositiveInteger(this.strides,"strides"),this.padding=null==e.padding?"valid":e.padding,this.dataFormat=null==e.dataFormat?"channelsLast":e.dataFormat,checkDataFormat(this.dataFormat),checkPaddingMode(this.padding),this.inputSpec=[new InputSpec({ndim:5})]}computeOutputShape(e){e=getExactlyOneShape(e);let t="channelsFirst"===this.dataFormat?e[2]:e[1],n="channelsFirst"===this.dataFormat?e[3]:e[2],r="channelsFirst"===this.dataFormat?e[4]:e[3];return t=convOutputLength(t,this.poolSize[0],this.padding,this.strides[0]),n=convOutputLength(n,this.poolSize[1],this.padding,this.strides[1]),r=convOutputLength(r,this.poolSize[2],this.padding,this.strides[2]),"channelsFirst"===this.dataFormat?[e[0],e[1],t,n,r]:[e[0],t,n,r,e[4]]}call(e,t){return tidy(()=>(this.invokeCallHook(e,t),this.poolingFunction(getExactlyOneTensor(e),this.poolSize,this.strides,this.padding,this.dataFormat)))}getConfig(){const e={poolSize:this.poolSize,padding:this.padding,strides:this.strides,dataFormat:this.dataFormat},t=super.getConfig();return Object.assign(e,t),e}}class MaxPooling3D extends Pooling3D{constructor(e){super(e)}poolingFunction(e,t,n,r,a){return checkDataFormat(a),checkPaddingMode(r),pool3d$1(e,t,n,r,a,"max")}}MaxPooling3D.className="MaxPooling3D",registerClass(MaxPooling3D);class AveragePooling3D extends Pooling3D{constructor(e){super(e)}poolingFunction(e,t,n,r,a){return checkDataFormat(a),checkPaddingMode(r),pool3d$1(e,t,n,r,a,"avg")}}AveragePooling3D.className="AveragePooling3D",registerClass(AveragePooling3D);class GlobalPooling1D extends Layer{constructor(e){super(e),this.inputSpec=[new InputSpec({ndim:3})]}computeOutputShape(e){return[e[0],e[2]]}call(e,t){throw new NotImplementedError}}class GlobalAveragePooling1D extends GlobalPooling1D{constructor(e){super(e||{})}call(e,t){return tidy(()=>{const t=getExactlyOneTensor(e);return mean$1(t,1)})}}GlobalAveragePooling1D.className="GlobalAveragePooling1D",registerClass(GlobalAveragePooling1D);class GlobalMaxPooling1D extends GlobalPooling1D{constructor(e){super(e||{})}call(e,t){return tidy(()=>{const t=getExactlyOneTensor(e);return max$3(t,1)})}}GlobalMaxPooling1D.className="GlobalMaxPooling1D",registerClass(GlobalMaxPooling1D);class GlobalPooling2D extends Layer{constructor(e){super(e),this.dataFormat=null==e.dataFormat?"channelsLast":e.dataFormat,checkDataFormat(this.dataFormat),this.inputSpec=[new InputSpec({ndim:4})]}computeOutputShape(e){return e=e,"channelsLast"===this.dataFormat?[e[0],e[3]]:[e[0],e[1]]}call(e,t){throw new NotImplementedError}getConfig(){const e={dataFormat:this.dataFormat},t=super.getConfig();return Object.assign(e,t),e}}class GlobalAveragePooling2D extends GlobalPooling2D{call(e,t){return tidy(()=>{const t=getExactlyOneTensor(e);return mean$1(t,"channelsLast"===this.dataFormat?[1,2]:[2,3])})}}GlobalAveragePooling2D.className="GlobalAveragePooling2D",registerClass(GlobalAveragePooling2D);class GlobalMaxPooling2D extends GlobalPooling2D{call(e,t){return tidy(()=>{const t=getExactlyOneTensor(e);return max$3(t,"channelsLast"===this.dataFormat?[1,2]:[2,3])})}}GlobalMaxPooling2D.className="GlobalMaxPooling2D",registerClass(GlobalMaxPooling2D);class Wrapper extends Layer{constructor(e){super(e),this.layer=e.layer}build(e){this.built=!0}get trainable(){return null!=this.layer&&this.layer.trainable}set trainable(e){null!=this.layer&&(this.layer.trainable=e)}get trainableWeights(){return this.layer.trainableWeights}get nonTrainableWeights(){return this.layer.nonTrainableWeights}get updates(){return this.layer._updates}get losses(){return this.layer.losses}getWeights(){return this.layer.getWeights()}setWeights(e){this.layer.setWeights(e)}getConfig(){const e={layer:{className:this.layer.getClassName(),config:this.layer.getConfig()}},t=super.getConfig();return Object.assign(e,t),e}setFastWeightInitDuringBuild(e){super.setFastWeightInitDuringBuild(e),null!=this.layer&&this.layer.setFastWeightInitDuringBuild(e)}static fromConfig(e,t,n={}){const r=deserialize(t.layer,n);delete t.layer;const a={layer:r};return Object.assign(a,t),new e(a)}}class TimeDistributed extends Wrapper{constructor(e){super(e),this.supportsMasking=!0}build(e){if((e=getExactlyOneShape(e)).length<3)throw new ValueError(`TimeDistributed layer expects an input shape >= 3D, but received input shape ${JSON.stringify(e)}`);this.inputSpec=[{shape:e}];const t=[e[0]].concat(e.slice(2));this.layer.built||(this.layer.build(t),this.layer.built=!0),super.build(e)}computeOutputShape(e){const t=[(e=getExactlyOneShape(e))[0]].concat(e.slice(2)),n=this.layer.computeOutputShape(t);return[n[0],e[1]].concat(n.slice(1))}call(e,t){return tidy(()=>rnn$1((e,n)=>[getExactlyOneTensor(this.layer.call(e,t)),[]],e=getExactlyOneTensor(e),[],!1,null,null,!1,!0)[1])}}function checkBidirectionalMergeMode(e){checkStringTypeUnionValue(VALID_BIDIRECTIONAL_MERGE_MODES,"BidirectionalMergeMode",e)}TimeDistributed.className="TimeDistributed",registerClass(TimeDistributed);const DEFAULT_BIDIRECTIONAL_MERGE_MODE="concat";class Bidirectional extends Wrapper{constructor(e){super(e);const t=e.layer.getConfig(),n={};n.className=e.layer.getClassName(),n.config=t,this.forwardLayer=deserialize(n),t.goBackwards=!0!==t.goBackwards;const r={};if(r.className=e.layer.getClassName(),r.config=t,this.backwardLayer=deserialize(r),this.forwardLayer.name="forward_"+this.forwardLayer.name,this.backwardLayer.name="backward_"+this.backwardLayer.name,this.mergeMode=void 0===e.mergeMode?DEFAULT_BIDIRECTIONAL_MERGE_MODE:e.mergeMode,checkBidirectionalMergeMode(this.mergeMode),e.weights)throw new NotImplementedError("weights support is not implemented for Bidirectional layer yet.");this._stateful=e.layer.stateful,this.returnSequences=e.layer.returnSequences,this.returnState=e.layer.returnState,this.supportsMasking=!0,this._trainable=!0,this.inputSpec=e.layer.inputSpec,this.numConstants=null}get trainable(){return this._trainable}set trainable(e){this._trainable=e,null!=this.forwardLayer&&(this.forwardLayer.trainable=e),null!=this.backwardLayer&&(this.backwardLayer.trainable=e)}getWeights(){return this.forwardLayer.getWeights().concat(this.backwardLayer.getWeights())}setWeights(e){const t=Math.floor(e.length/2);this.forwardLayer.setWeights(e.slice(0,t)),this.backwardLayer.setWeights(e.slice(t))}computeOutputShape(e){let t,n,r,a=this.forwardLayer.computeOutputShape(e);return Array.isArray(a)&&Array.isArray(a[0])||(a=[a]),a=a,this.returnState?(r=a.slice(1),t=a[0]):t=a[0],t=t,"concat"===this.mergeMode?(t[t.length-1]*=2,n=[t]):n=null==this.mergeMode?[t,t.slice()]:[t],this.returnState?null==this.mergeMode?n.concat(r).concat(r.slice()):[t].concat(r).concat(r.slice()):singletonOrArray(n)}apply(e,t){let n=null==t?null:t.initialState,r=null==t?null:t.constants;null==t&&(t={});const a=standardizeArgs(e,n,r,this.numConstants);if(e=a.inputs,n=a.initialState,r=a.constants,Array.isArray(e)&&(n=e.slice(1),e=e[0]),(null==n||0===n.length)&&null==r)return super.apply(e,t);const s=[],o=[];if(null!=n){const e=n.length;if(e%2>0)throw new ValueError("When passing `initialState` to a Bidrectional RNN, the state should be an Array containing the states of the underlying RNNs.");t.initialState=n,s.push(...n);const r=n.map(e=>new InputSpec({shape:e.shape}));this.forwardLayer.stateSpec=r.slice(0,e/2),this.backwardLayer.stateSpec=r.slice(e/2),o.push(...r)}if(null!=r)throw new NotImplementedError("Support for constants in Bidirectional layers is not implemented yet.");const i=s[0]instanceof SymbolicTensor;for(const e of s)if(e instanceof SymbolicTensor!==i)throw new ValueError("The initial state of a Bidirectional layer cannot be specified as a mix of symbolic and non-symbolic tensors");if(i){const n=[e].concat(s),r=this.inputSpec.concat(o),a=this.inputSpec;this.inputSpec=r;const i=super.apply(n,t);return this.inputSpec=a,i}return super.apply(e,t)}call(e,t){return tidy(()=>{const n=t.initialState;let r,a,s,o;if(null==n)r=this.forwardLayer.call(e,t),a=this.backwardLayer.call(e,t);else{const s=n.slice(0,n.length/2),o=n.slice(n.length/2);r=this.forwardLayer.call(e,Object.assign(t,{initialState:s})),a=this.backwardLayer.call(e,Object.assign(t,{initialState:o}))}return this.returnState&&(Array.isArray(r)&&(s=r.slice(1).concat(a.slice(1))),r=r[0],a=a[0]),this.returnSequences&&(a=reverse$2(a,1)),"concat"===this.mergeMode?o=concatenate$1([r,a]):"sum"===this.mergeMode?o=add$2(r,a):"ave"===this.mergeMode?o=mul(.5,add$2(r,a)):"mul"===this.mergeMode?o=mul(r,a):null==this.mergeMode&&(o=[r,a]),this.returnState?null==this.mergeMode?o.concat(s):[o].concat(s):o})}resetStates(e){this.forwardLayer.resetStates(),this.backwardLayer.resetStates()}build(e){nameScope(this.forwardLayer.name,()=>{this.forwardLayer.build(e)}),nameScope(this.backwardLayer.name,()=>{this.backwardLayer.build(e)}),this.built=!0}computeMask(e,t){let n;if(Array.isArray(t)&&(t=t[0]),n=this.returnSequences?null==this.mergeMode?[t,t]:t:null==this.mergeMode?[null,null]:null,this.returnState){const e=this.forwardLayer.states.map(e=>null);return Array.isArray(n)?n.concat(e).concat(e):[n].concat(e).concat(e)}return n}get trainableWeights(){return this.forwardLayer.trainableWeights.concat(this.backwardLayer.trainableWeights)}get nonTrainableWeights(){return this.forwardLayer.nonTrainableWeights.concat(this.backwardLayer.nonTrainableWeights)}setFastWeightInitDuringBuild(e){super.setFastWeightInitDuringBuild(e),null!=this.forwardLayer&&this.forwardLayer.setFastWeightInitDuringBuild(e),null!=this.backwardLayer&&this.backwardLayer.setFastWeightInitDuringBuild(e)}getConfig(){const e={mergeMode:this.mergeMode},t=super.getConfig();return Object.assign(e,t),e}static fromConfig(e,t){const n=deserialize(t.layer);if(delete t.layer,null!=t.numConstants)throw new NotImplementedError("Deserialization of a Bidirectional layer with numConstants present is not supported yet.");const r=t;return r.layer=n,new e(r)}}function inputLayer(e){return new InputLayer(e)}function elu$2(e){return new ELU$3(e)}function reLU(e){return new ReLU(e)}function leakyReLU(e){return new LeakyReLU(e)}function prelu$2(e){return new PReLU(e)}function softmax$2(e){return new Softmax(e)}function thresholdedReLU(e){return new ThresholdedReLU(e)}function conv1d(e){return new Conv1D(e)}function conv2d$1(e){return new Conv2D(e)}function conv2dTranspose(e){return new Conv2DTranspose(e)}function conv3d(e){return new Conv3D(e)}function conv3dTranspose(e){return new Conv3DTranspose(e)}function separableConv2d(e){return new SeparableConv2D(e)}function cropping2D(e){return new Cropping2D(e)}function upSampling2d(e){return new UpSampling2D(e)}function depthwiseConv2d(e){return new DepthwiseConv2D(e)}function activation(e){return new Activation(e)}function dense(e){return new Dense(e)}function dropout(e){return new Dropout(e)}function spatialDropout1d(e){return new SpatialDropout1D(e)}function flatten$1(e){return new Flatten(e)}function repeatVector(e){return new RepeatVector(e)}function reshape$2(e){return new Reshape(e)}function permute(e){return new Permute(e)}function embedding(e){return new Embedding(e)}function add$1(e){return new Add(e)}function average(e){return new Average(e)}function concatenate(e){return new Concatenate(e)}function maximum$2(e){return new Maximum(e)}function minimum$2(e){return new Minimum(e)}function multiply$2(e){return new Multiply(e)}function dot(e){return new Dot(e)}function batchNormalization(e){return new BatchNormalization(e)}function layerNormalization(e){return new LayerNormalization(e)}function zeroPadding2d(e){return new ZeroPadding2D(e)}function averagePooling1d(e){return new AveragePooling1D(e)}function avgPool1d(e){return averagePooling1d(e)}function avgPooling1d(e){return averagePooling1d(e)}function averagePooling2d(e){return new AveragePooling2D(e)}function avgPool2d(e){return averagePooling2d(e)}function avgPooling2d(e){return averagePooling2d(e)}function averagePooling3d(e){return new AveragePooling3D(e)}function avgPool3d(e){return averagePooling3d(e)}function avgPooling3d(e){return averagePooling3d(e)}function globalAveragePooling1d(e){return new GlobalAveragePooling1D(e)}function globalAveragePooling2d(e){return new GlobalAveragePooling2D(e)}function globalMaxPooling1d(e){return new GlobalMaxPooling1D(e)}function globalMaxPooling2d(e){return new GlobalMaxPooling2D(e)}function maxPooling1d(e){return new MaxPooling1D(e)}function maxPooling2d(e){return new MaxPooling2D(e)}function maxPooling3d(e){return new MaxPooling3D(e)}function gru(e){return new GRU(e)}function gruCell(e){return new GRUCell(e)}function lstm(e){return new LSTM(e)}function lstmCell(e){return new LSTMCell(e)}function simpleRNN(e){return new SimpleRNN(e)}function simpleRNNCell(e){return new SimpleRNNCell(e)}function convLstm2d(e){return new ConvLSTM2D(e)}function convLstm2dCell(e){return new ConvLSTM2DCell(e)}function rnn(e){return new RNN(e)}function stackedRNNCells(e){return new StackedRNNCells(e)}function bidirectional(e){return new Bidirectional(e)}function timeDistributed(e){return new TimeDistributed(e)}Bidirectional.className="Bidirectional",registerClass(Bidirectional);const globalMaxPool1d=globalMaxPooling1d,globalMaxPool2d=globalMaxPooling2d,maxPool1d=maxPooling1d,maxPool2d=maxPooling2d;function gaussianNoise(e){return new GaussianNoise(e)}function gaussianDropout(e){return new GaussianDropout(e)}function alphaDropout(e){return new AlphaDropout(e)}function masking(e){return new Masking(e)}var exports_layers={__proto__:null,inputLayer,elu:elu$2,reLU,leakyReLU,prelu:prelu$2,softmax:softmax$2,thresholdedReLU,conv1d,conv2d:conv2d$1,conv2dTranspose,conv3d,conv3dTranspose,separableConv2d,cropping2D,upSampling2d,depthwiseConv2d,activation,dense,dropout,spatialDropout1d,flatten:flatten$1,repeatVector,reshape:reshape$2,permute,embedding,add:add$1,average,concatenate,maximum:maximum$2,minimum:minimum$2,multiply:multiply$2,dot,batchNormalization,layerNormalization,zeroPadding2d,averagePooling1d,avgPool1d,avgPooling1d,averagePooling2d,avgPool2d,avgPooling2d,averagePooling3d,avgPool3d,avgPooling3d,globalAveragePooling1d,globalAveragePooling2d,globalMaxPooling1d,globalMaxPooling2d,maxPooling1d,maxPooling2d,maxPooling3d,gru,gruCell,lstm,lstmCell,simpleRNN,simpleRNNCell,convLstm2d,convLstm2dCell,rnn,stackedRNNCells,bidirectional,timeDistributed,globalMaxPool1d,globalMaxPool2d,maxPool1d,maxPool2d,Layer,RNN,RNNCell,input,gaussianNoise,gaussianDropout,alphaDropout,masking};function binaryAccuracy(e,t){return binaryAccuracy$1(e,t)}function binaryCrossentropy(e,t){return binaryCrossentropy$1(e,t)}function sparseCategoricalAccuracy(e,t){return sparseCategoricalAccuracy$1(e,t)}function categoricalAccuracy(e,t){return categoricalAccuracy$1(e,t)}function categoricalCrossentropy(e,t){return categoricalCrossentropy$1(e,t)}function precision(e,t){return precision$1(e,t)}function recall(e,t){return recall$1(e,t)}function cosineProximity(e,t){return cosineProximity$1(e,t)}function meanAbsoluteError(e,t){return meanAbsoluteError$1(e,t)}function meanAbsolutePercentageError(e,t){return meanAbsolutePercentageError$1(e,t)}function MAPE(e,t){return meanAbsolutePercentageError$1(e,t)}function mape(e,t){return meanAbsolutePercentageError$1(e,t)}function meanSquaredError(e,t){return meanSquaredError$1(e,t)}function MSE(e,t){return meanSquaredError$1(e,t)}function mse(e,t){return meanSquaredError$1(e,t)}var exports_metrics={__proto__:null,binaryAccuracy,binaryCrossentropy,sparseCategoricalAccuracy,categoricalAccuracy,categoricalCrossentropy,precision,recall,cosineProximity,meanAbsoluteError,meanAbsolutePercentageError,MAPE,mape,meanSquaredError,MSE,mse},exports_models={__proto__:null,modelFromJSON};function l1l2(e){return new L1L2(e)}function l1(e){return l1$1(e)}function l2(e){return l2$1(e)}var exports_regularizers={__proto__:null,l1l2,l1,l2};class Callback extends BaseCallback{constructor(){super(...arguments),this.model=null}setModel(e){if(!(e instanceof LayersModel))throw new Error("model must be a LayersModel, not some other Container");this.model=e}}function less$2(e,t){return e<t}function greater$2(e,t){return e>t}class EarlyStopping extends Callback{constructor(e){if(super(),null==e&&(e={}),e.restoreBestWeights)throw new NotImplementedError("restoreBestWeights = True is not implemented in EarlyStopping yet.");this.monitor=e.monitor||"val_loss",this.minDelta=Math.abs(e.minDelta||0),this.patience=e.patience||0,this.verbose=e.verbose||0,this.mode=e.mode||"auto",this.baseline=e.baseline,-1===["auto","min","max"].indexOf(this.mode)&&(console.warn(`EarlyStopping mode '${this.mode}' is invalid. Falling back to mode 'auto'.`),this.mode="auto"),this.monitorFunc="min"===this.mode?less$2:"max"===this.mode||-1!==this.monitor.indexOf("acc")?greater$2:less$2,this.monitorFunc===less$2&&(this.minDelta*=-1)}async onTrainBegin(e){this.wait=0,this.stoppedEpoch=0,this.best=null!=this.baseline?this.baseline:this.monitorFunc===less$2?Infinity:-Infinity}async onEpochEnd(e,t){await resolveScalarsInLogs(t);const n=this.getMonitorValue(t);null!=n&&(this.monitorFunc(n-this.minDelta,this.best)?(this.best=n,this.wait=0):(this.wait++,this.wait>=this.patience&&(this.stoppedEpoch=e,this.model.stopTraining=!0)))}async onTrainEnd(e){this.stoppedEpoch>0&&this.verbose&&console.log(`Epoch ${this.stoppedEpoch}: early stopping.`)}getMonitorValue(e){null==e&&(e={});const t=e[this.monitor];return null==t&&console.warn(`Metric for EarlyStopping ${this.monitor} is not available. Available metrics are: ${Object.keys(e)}`),t}}function earlyStopping(e){return new EarlyStopping(e)}const callbacks={earlyStopping};var DataType,SaverDef;!function(e){e[e.DT_INVALID=0]="DT_INVALID",e[e.DT_FLOAT=1]="DT_FLOAT",e[e.DT_DOUBLE=2]="DT_DOUBLE",e[e.DT_INT32=3]="DT_INT32",e[e.DT_UINT8=4]="DT_UINT8",e[e.DT_INT16=5]="DT_INT16",e[e.DT_INT8=6]="DT_INT8",e[e.DT_STRING=7]="DT_STRING",e[e.DT_COMPLEX64=8]="DT_COMPLEX64",e[e.DT_INT64=9]="DT_INT64",e[e.DT_BOOL=10]="DT_BOOL",e[e.DT_QINT8=11]="DT_QINT8",e[e.DT_QUINT8=12]="DT_QUINT8",e[e.DT_QINT32=13]="DT_QINT32",e[e.DT_BFLOAT16=14]="DT_BFLOAT16",e[e.DT_FLOAT_REF=101]="DT_FLOAT_REF",e[e.DT_DOUBLE_REF=102]="DT_DOUBLE_REF",e[e.DT_INT32_REF=103]="DT_INT32_REF",e[e.DT_UINT8_REF=104]="DT_UINT8_REF",e[e.DT_INT16_REF=105]="DT_INT16_REF",e[e.DT_INT8_REF=106]="DT_INT8_REF",e[e.DT_STRING_REF=107]="DT_STRING_REF",e[e.DT_COMPLEX64_REF=108]="DT_COMPLEX64_REF",e[e.DT_INT64_REF=109]="DT_INT64_REF",e[e.DT_BOOL_REF=110]="DT_BOOL_REF",e[e.DT_QINT8_REF=111]="DT_QINT8_REF",e[e.DT_QUINT8_REF=112]="DT_QUINT8_REF",e[e.DT_QINT32_REF=113]="DT_QINT32_REF",e[e.DT_BFLOAT16_REF=114]="DT_BFLOAT16_REF"}(DataType||(DataType={})),function(e){var t;(t=e.CheckpointFormatVersion||(e.CheckpointFormatVersion={}))[t.LEGACY=0]="LEGACY",t[t.V1=1]="V1",t[t.V2=2]="V2"}(SaverDef||(SaverDef={}));const CUSTOM_OPS={};function registerOp(e,t){CUSTOM_OPS[e]={tfOpName:e,category:"custom",inputs:[],attrs:[],customExecutor:t}}function getRegisteredOp(e){return CUSTOM_OPS[e]}function deregisterOp(e){delete CUSTOM_OPS[e]}function getParamValue(e,t,n,r,a){const s=t.inputParams[e];if(s&&void 0!==s.inputIndexStart){const e=s.inputIndexStart,o=0===s.inputIndexEnd?void 0:void 0===s.inputIndexEnd?e+1:s.inputIndexEnd;if("tensor"===s.type)return getTensor(t.inputNames[s.inputIndexStart],n,r,a);if("tensors"===s.type)return t.inputNames.slice(e,o).map(e=>getTensor(e,n,r,a));const i=getTensor(t.inputNames.slice(e)[0],n,r,a),l=i.dataSync();return"number"===s.type?l[0]:toNestedArray(i.shape,l)}const o=t.attrParams[e];return o&&o.value}function getTensor(e,t,n,r){const[a,s]=parseNodeName(e);if(null!=r){const e=r.getHashTableHandleByName(a);if(null!=e)return e}const o=n.currentContextIds.find(e=>!!t[getNodeNameWithContextId(a,e)]);return void 0!==o?t[getNodeNameWithContextId(a,o)][s]:void 0}function getTensorsForCurrentContenxt(e,t,n){return t[getNodeNameWithContextId(e,n.currentContextId)]}function getNodeNameAndIndex(e,t){const[n,r,a]=parseNodeName(e);return[getNodeNameWithContextId(n,t&&t.currentContextId),r,a]}function getNodeNameWithContextId(e,t){return t?`${e}-${t}`:e}function parseNodeName(e){const t=e.split(":");if(1===t.length)return[e,0,void 0];const n=3===t.length?t[1]:void 0;return[t[0],Number(t[t.length-1]),n]}function getPadding(e,t,n){let r=getParamValue("pad",e,t,n);if("explicit"===r){r=getParamValue("explicitPaddings",e,t,n);const a=[[0,0],[0,0],[0,0],[0,0]];for(let e=0;e<4;e++)a[e][0]=r[2*e],a[e][1]=r[2*e+1];return a}return r}function cloneTensor(e){return e.kept?e:clone(e)}const json$i=[{tfOpName:"Add",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"AddV2",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"AddN",category:"arithmetic",inputs:[{start:0,end:0,name:"tensors",type:"tensors"}]},{tfOpName:"BiasAdd",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0}]},{tfOpName:"Sub",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"RealDiv",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Div",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"DivNoNan",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"FloorDiv",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Mul",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Maximum",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Minimum",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Pow",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"SquaredDifference",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Mod",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"FloorMod",category:"arithmetic",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]}];var arithmetic={__proto__:null,json:json$i};const json$h=[{tfOpName:"Abs",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Acos",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Asin",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Atan",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Atan2",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"y",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Ceil",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"ClipByValue",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"clipValueMin",type:"number"},{start:2,name:"clipValueMax",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Complex",category:"basic_math",inputs:[{start:0,name:"real",type:"tensor"},{start:1,name:"imag",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"ComplexAbs",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Cos",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Cosh",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Elu",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Exp",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Floor",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Log",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Imag",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"Tout",name:"outputType",type:"dtype",notSupported:!0}]},{tfOpName:"Neg",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Real",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"Tout",name:"outputType",type:"dtype",notSupported:!0}]},{tfOpName:"Prelu",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"alpha",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Relu",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Relu6",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Selu",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Sigmoid",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Sin",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Sinh",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Sqrt",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Rsqrt",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Square",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Tan",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Tanh",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Sign",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Round",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Expm1",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Log1p",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Reciprocal",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Softplus",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Asinh",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Acosh",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Atanh",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Erf",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Prod",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axes",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool",notSupported:!0},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"LeakyRelu",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"alpha",name:"alpha",type:"number",defaultValue:.2},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"IsNan",category:"basic_math",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]}];var basicMath={__proto__:null,json:json$h};const json$g=[{tfOpName:"EmptyTensorList",category:"control",inputs:[{start:0,name:"elementShape",type:"shape"},{start:1,name:"maxNumElements",type:"number"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"LoopCond",category:"control",inputs:[{start:0,name:"pred",type:"tensor"}]},{tfOpName:"Switch",category:"control",inputs:[{start:0,name:"data",type:"tensor"},{start:1,name:"pred",type:"tensor"}]},{tfOpName:"Merge",category:"control",inputs:[{start:0,end:0,name:"tensors",type:"tensors"}]},{tfOpName:"Enter",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"frame_name",name:"frameName",type:"string"},{tfName:"is_constant",name:"isConstant",type:"bool"}]},{tfOpName:"Exit",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"NextIteration",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"TensorArrayV3",category:"control",inputs:[{start:0,name:"size",type:"number"}],attrs:[{tfName:"dtype",name:"dtype",type:"dtype"},{tfName:"element_shape",name:"elementShape",type:"shape"},{tfName:"dynamic_size",name:"dynamicSize",type:"bool"},{tfName:"clear_after_read",name:"clearAfterRead",type:"bool"},{tfName:"identical_element_shapes",name:"identicalElementShapes",type:"bool"},{tfName:"tensor_array_name",name:"name",type:"string"}]},{tfOpName:"TensorArrayWriteV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"index",type:"number"},{start:2,name:"tensor",type:"tensor"},{start:3,name:"flowIn",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"TensorArrayReadV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"index",type:"number"},{start:2,name:"flowIn",type:"number"}],attrs:[{tfName:"dtype",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"TensorArrayGatherV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"indices",type:"number[]"},{start:2,name:"flowIn",type:"number"}],attrs:[{tfName:"dtype",name:"dtype",type:"dtype"},{tfName:"element_shape",name:"elementShape",type:"shape"}]},{tfOpName:"TensorArrayScatterV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"indices",type:"number[]"},{start:2,name:"tensor",type:"tensor"},{start:3,name:"flowIn",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"TensorArrayConcatV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"flowIn",type:"number"}],attrs:[{tfName:"dtype",name:"dtype",type:"dtype"},{tfName:"element_shape_except0",name:"elementShapeExcept0",type:"shape",notSupported:!0}]},{tfOpName:"TensorArraySplitV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"tensor",type:"tensor"},{start:2,name:"lengths",type:"number[]"},{start:3,name:"flowIn",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"TensorArraySizeV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"},{start:1,name:"flowIn",type:"number"}]},{tfOpName:"TensorArrayCloseV3",category:"control",inputs:[{start:0,name:"tensorArrayId",type:"tensor"}]},{tfOpName:"StatelessIf",category:"control",inputs:[{start:0,name:"cond",type:"tensor"},{start:1,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"then_branch",name:"thenBranch",type:"func"},{tfName:"else_branch",name:"elseBranch",type:"func"}]},{tfOpName:"If",category:"control",inputs:[{start:0,name:"cond",type:"tensor"},{start:1,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"then_branch",name:"thenBranch",type:"func"},{tfName:"else_branch",name:"elseBranch",type:"func"}]},{tfOpName:"StatelessWhile",category:"control",inputs:[{start:0,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"cond",name:"cond",type:"func"},{tfName:"body",name:"body",type:"func"}]},{tfOpName:"While",category:"control",inputs:[{start:0,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"cond",name:"cond",type:"func"},{tfName:"body",name:"body",type:"func"}]},{tfOpName:"TensorListScatter",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"},{start:1,name:"indices",type:"number[]"},{start:2,name:"elementShape",type:"shape"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListScatterV2",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"},{start:1,name:"indices",type:"number[]"},{start:2,name:"elementShape",type:"shape"},{start:3,name:"numElements",type:"number"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListGather",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"indices",type:"number[]"},{start:2,name:"elementShape",type:"shape"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListGetItem",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"index",type:"number"},{start:2,name:"elementShape",type:"shape"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListSetItem",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"index",type:"number"},{start:2,name:"tensor",type:"tensor"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListReserve",category:"control",inputs:[{start:0,name:"elementShape",type:"shape"},{start:1,name:"numElements",type:"number"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListFromTensor",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"},{start:1,name:"elementShape",type:"shape"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListStack",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"elementShape",type:"shape"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"},{tfName:"num_elements",name:"numElements",type:"dtype"}]},{tfOpName:"TensorListSplit",category:"control",inputs:[{start:0,name:"tensor",type:"tensor"},{start:1,name:"elementShape",type:"shape"},{start:2,name:"lengths",type:"number[]"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListConcat",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"}],attrs:[{tfName:"element_shape",name:"elementShape",type:"shape"},{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListPopBack",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"elementShape",type:"shape"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]},{tfOpName:"TensorListPushBack",category:"control",inputs:[{start:0,name:"tensorListId",type:"tensor"},{start:1,name:"tensor",type:"tensor"}],attrs:[{tfName:"element_dtype",name:"elementDType",type:"dtype"}]}];var control={__proto__:null,json:json$g};const json$f=[{tfOpName:"AvgPool",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0},{tfName:"ksize",name:"kernelSize",type:"number[]"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"MaxPool",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0},{tfName:"ksize",name:"kernelSize",type:"number[]"},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[],notSupported:!0},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"MaxPoolWithArgmax",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"ksize",name:"kernelSize",type:"number[]"},{tfName:"include_batch_in_index",name:"includeBatchInIndex",type:"bool"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"AvgPool3D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0},{tfName:"ksize",name:"kernelSize",type:"number[]"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"MaxPool3D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0},{tfName:"ksize",name:"kernelSize",type:"number[]"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Conv1D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"}],attrs:[{tfName:"stride",name:"stride",type:"number"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NWC"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"dilation",name:"dilation",type:"number",defaultValue:1}]},{tfOpName:"Conv2D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"useCudnnOnGpu",name:"useCudnnOnGpu",type:"bool"},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NHWC"},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[]},{tfName:"dilations",name:"dilations",type:"number[]"}]},{tfOpName:"_FusedConv2D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"},{start:2,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"num_args",name:"numArgs",type:"number"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[]},{tfName:"use_cudnn_on_gpu",name:"useCudnnOnGpu",type:"bool",defaultValue:!0},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NHWC"},{tfName:"dilations",name:"dilations",type:"number[]",defaultValue:[1,1,1,1]},{tfName:"fused_ops",name:"fusedOps",type:"string[]",defaultValue:[]},{tfName:"epsilon",name:"epsilon",type:"number",defaultValue:1e-4},{tfName:"leakyrelu_alpha",name:"leakyreluAlpha",type:"number"}]},{tfOpName:"Conv2DBackpropInput",category:"convolution",inputs:[{start:2,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"},{start:0,name:"outputShape",type:"number[]"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[]},{tfName:"dilations",name:"dilations",type:"number[]",notSupported:!0}]},{tfOpName:"DepthwiseConv2d",category:"convolution",inputs:[{start:0,name:"input",type:"tensor"},{start:1,name:"filter",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NHWC"},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[]},{tfName:"dilations",name:"dilations",type:"number[]"}]},{tfOpName:"DepthwiseConv2dNative",category:"convolution",inputs:[{start:0,name:"input",type:"tensor"},{start:1,name:"filter",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NHWC"},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[]},{tfName:"dilations",name:"dilations",type:"number[]"}]},{tfOpName:"FusedDepthwiseConv2dNative",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"},{start:2,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"num_args",name:"numArgs",type:"number"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NHWC"},{tfName:"dilations",name:"dilations",type:"number[]",defaultValue:[1,1,1,1]},{tfName:"fused_ops",name:"fusedOps",type:"string[]",defaultValue:[]},{tfName:"explicit_paddings",name:"explicitPaddings",type:"number[]",defaultValue:[]}]},{tfOpName:"Conv3D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"padding",name:"pad",type:"string"},{tfName:"data_format",name:"dataFormat",type:"string",defaultValue:"NHWC"},{tfName:"dilations",name:"dilations",type:"number[]"}]},{tfOpName:"Dilation2D",category:"convolution",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"filter",type:"tensor"}],attrs:[{tfName:"strides",name:"strides",type:"number[]"},{tfName:"rates",name:"dilations",type:"number[]"},{tfName:"padding",name:"pad",type:"string"}]}];var convolution={__proto__:null,json:json$f};const json$e=[{tfOpName:"Fill",category:"creation",inputs:[{start:0,name:"shape",type:"number[]"},{start:1,name:"value",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"LinSpace",category:"creation",inputs:[{start:0,name:"start",type:"number"},{start:1,name:"stop",type:"number"},{start:2,name:"num",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"OneHot",category:"creation",inputs:[{start:0,name:"indices",type:"tensor"},{start:1,name:"depth",type:"number"},{start:2,name:"onValue",type:"number",defaultValue:1},{start:3,name:"offValue",type:"number",defaultValue:0}],attrs:[{tfName:"axis",name:"axis",type:"number",notSupported:!0},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Ones",category:"creation",inputs:[{start:0,name:"shape",type:"number[]"}],attrs:[{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"OnesLike",category:"creation",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"dtype",name:"dtype",type:"dtype"}]},{tfOpName:"RandomUniform",category:"creation",inputs:[{start:0,name:"shape",type:"number[]"}],attrs:[{tfName:"minval",name:"minval",type:"number",defaultValue:0},{tfName:"maxval",name:"maxval",type:"number",defaultValue:1},{tfName:"dtype",name:"dtype",type:"dtype"},{tfName:"seed",name:"seed",type:"number",defaultValue:0},{tfName:"seed2",name:"seed2",type:"number",defaultValue:0,notSupported:!0},{tfName:"T",name:"T",type:"number",notSupported:!0}]},{tfOpName:"Range",category:"creation",inputs:[{start:0,name:"start",type:"number"},{start:1,name:"stop",type:"number"},{start:2,name:"step",type:"number",defaultValue:0}],attrs:[{tfName:"Tidx",name:"dtype",type:"dtype"}]},{tfOpName:"TruncatedNormal",category:"creation",inputs:[{start:0,name:"shape",type:"number[]"}],attrs:[{tfName:"means",name:"mean",type:"number",defaultValue:0},{tfName:"stddev",name:"stdDev",type:"number",defaultValue:1},{tfName:"seed",name:"seed",type:"number"},{tfName:"seed2",name:"seed2",type:"number",defaultValue:0,notSupported:!0},{tfName:"dtype",name:"dtype",type:"dtype"},{tfName:"T",name:"T",type:"number",notSupported:!0}]},{tfOpName:"Zeros",category:"creation",inputs:[{start:0,name:"shape",type:"number[]"}],attrs:[{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"ZerosLike",category:"creation",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype"}]},{tfOpName:"Multinomial",category:"creation",inputs:[{start:0,name:"logits",type:"tensor"},{start:1,name:"numSamples",type:"number"}],attrs:[{tfName:"seed",name:"seed",type:"number"},{tfName:"seed2",name:"seed2",type:"number"},{tfName:"T",name:"dtype",type:"dtype"},{tfName:"output_dtype",name:"output_dtype",type:"dtype"}]}];var creation={__proto__:null,json:json$e};const json$d=[{tfOpName:"NonMaxSuppressionV2",category:"dynamic",inputs:[{start:0,name:"boxes",type:"tensor"},{start:1,name:"scores",type:"tensor"},{start:2,name:"maxOutputSize",type:"number"},{start:3,name:"iouThreshold",type:"number"}]},{tfOpName:"NonMaxSuppressionV3",category:"dynamic",inputs:[{start:0,name:"boxes",type:"tensor"},{start:1,name:"scores",type:"tensor"},{start:2,name:"maxOutputSize",type:"number"},{start:3,name:"iouThreshold",type:"number"},{start:4,name:"scoreThreshold",type:"number"}]},{tfOpName:"NonMaxSuppressionV4",category:"dynamic",inputs:[{start:0,name:"boxes",type:"tensor"},{start:1,name:"scores",type:"tensor"},{start:2,name:"maxOutputSize",type:"number"},{start:3,name:"iouThreshold",type:"number"},{start:4,name:"scoreThreshold",type:"number"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0},{tfName:"T_threshold",name:"threshold",type:"dtype",notSupported:!0},{tfName:"pad_to_max_output_size",name:"padToMaxOutputSize",type:"bool"}]},{tfOpName:"NonMaxSuppressionV5",category:"dynamic",inputs:[{start:0,name:"boxes",type:"tensor"},{start:1,name:"scores",type:"tensor"},{start:2,name:"maxOutputSize",type:"number"},{start:3,name:"iouThreshold",type:"number"},{start:4,name:"scoreThreshold",type:"number"},{start:5,name:"softNmsSigma",type:"number"}]},{tfOpName:"Where",category:"dynamic",inputs:[{start:0,name:"condition",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"ListDiff",category:"dynamic",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"y",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]}];var dynamic={__proto__:null,json:json$d};const json$c=[{tfOpName:"TopKV2",category:"evaluation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"k",type:"number"}],attrs:[{tfName:"sorted",name:"sorted",type:"bool"}]},{tfOpName:"Unique",category:"evaluation",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"UniqueV2",category:"evaluation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number"}]}];var evaluation={__proto__:null,json:json$c};const json$b=[{tfOpName:"PlaceholderWithDefault",category:"graph",inputs:[{start:0,name:"default",type:"tensor"}],attrs:[{tfName:"shape",name:"shape",type:"shape"},{tfName:"dtype",name:"dtype",type:"dtype"}]},{tfOpName:"Placeholder",category:"graph",attrs:[{tfName:"shape",name:"shape",type:"shape"},{tfName:"dtype",name:"dtype",type:"dtype"}]},{tfOpName:"Const",category:"graph"},{tfOpName:"Identity",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"IdentityN",category:"graph",inputs:[{start:0,end:0,name:"x",type:"tensors"}]},{tfOpName:"Snapshot",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"Rank",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"Size",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"Shape",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"ShapeN",category:"graph",inputs:[{start:0,end:0,name:"x",type:"tensors"}]},{tfOpName:"Print",category:"graph",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"data",type:"tensors"}],attrs:[{tfName:"message",name:"message",type:"string"},{tfName:"first_n",name:"firstN",type:"number",notSupported:!0},{tfName:"summarize",name:"summarize",type:"number",defaultValue:3}]},{tfOpName:"NoOp",category:"graph",inputs:[]},{tfOpName:"StopGradient",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"FakeQuantWithMinMaxVars",category:"graph",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"min",name:"min",type:"number"},{tfName:"max",name:"max",type:"number"}]}];var graph={__proto__:null,json:json$b};const json$a=[{tfOpName:"HashTable",category:"hash_table",inputs:[],attrs:[{tfName:"shared_name",name:"sharedName",type:"string"},{tfName:"use_node_name_sharing",name:"useNodeNameSharing",type:"bool"},{tfName:"key_dtype",name:"keyDType",type:"dtype"},{tfName:"value_dtype",name:"valueDType",type:"dtype"}]},{tfOpName:"HashTableV2",category:"hash_table",inputs:[],attrs:[{tfName:"shared_name",name:"sharedName",type:"string"},{tfName:"use_node_name_sharing",name:"useNodeNameSharing",type:"bool"},{tfName:"key_dtype",name:"keyDType",type:"dtype"},{tfName:"value_dtype",name:"valueDType",type:"dtype"}]},{tfOpName:"LookupTableImport",category:"hash_table",inputs:[{start:0,name:"tableHandle",type:"tensor"},{start:1,name:"keys",type:"tensor"},{start:2,name:"values",type:"tensor"}],attrs:[{tfName:"Tin",name:"tIn",type:"dtype",notSupported:!0},{tfName:"Tout",name:"tOut",type:"dtype",notSupported:!0}]},{tfOpName:"LookupTableImportV2",category:"hash_table",inputs:[{start:0,name:"tableHandle",type:"tensor"},{start:1,name:"keys",type:"tensor"},{start:2,name:"values",type:"tensor"}],attrs:[{tfName:"Tin",name:"tIn",type:"dtype",notSupported:!0},{tfName:"Tout",name:"tOut",type:"dtype",notSupported:!0}]},{tfOpName:"LookupTableFind",category:"hash_table",inputs:[{start:0,name:"tableHandle",type:"tensor"},{start:1,name:"keys",type:"tensor"},{start:2,name:"defaultValue",type:"tensor"}],attrs:[{tfName:"Tin",name:"tIn",type:"dtype",notSupported:!0},{tfName:"Tout",name:"tOut",type:"dtype",notSupported:!0}]},{tfOpName:"LookupTableFindV2",category:"hash_table",inputs:[{start:0,name:"tableHandle",type:"tensor"},{start:1,name:"keys",type:"tensor"},{start:2,name:"defaultValue",type:"tensor"}],attrs:[{tfName:"Tin",name:"tIn",type:"dtype",notSupported:!0},{tfName:"Tout",name:"tOut",type:"dtype",notSupported:!0}]},{tfOpName:"LookupTableSize",category:"hash_table",inputs:[{start:0,name:"tableHandle",type:"tensor"}]},{tfOpName:"LookupTableSizeV2",category:"hash_table",inputs:[{start:0,name:"tableHandle",type:"tensor"}]}];var hashTable={__proto__:null,json:json$a};const json$9=[{tfOpName:"ResizeBilinear",category:"image",inputs:[{start:0,name:"images",type:"tensor"},{start:1,name:"size",type:"number[]"}],attrs:[{tfName:"align_corners",name:"alignCorners",type:"bool"},{tfName:"half_pixel_centers",name:"halfPixelCenters",type:"bool"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"ResizeNearestNeighbor",category:"image",inputs:[{start:0,name:"images",type:"tensor"},{start:1,name:"size",type:"number[]"}],attrs:[{tfName:"align_corners",name:"alignCorners",type:"bool"},{tfName:"half_pixel_centers",name:"halfPixelCenters",type:"bool"},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"CropAndResize",category:"image",inputs:[{start:0,name:"image",type:"tensor"},{start:1,name:"boxes",type:"tensor"},{start:2,name:"boxInd",type:"tensor"},{start:3,name:"cropSize",type:"number[]"}],attrs:[{tfName:"method",name:"method",type:"string"},{tfName:"extrapolation_value",name:"extrapolationValue",type:"number"}]}];var image={__proto__:null,json:json$9};const json$8=[{tfOpName:"Equal",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"NotEqual",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Greater",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"GreaterEqual",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Less",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"LessEqual",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"LogicalAnd",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"LogicalNot",category:"logical",inputs:[{start:0,name:"a",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"LogicalOr",category:"logical",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Select",category:"logical",inputs:[{start:0,name:"condition",type:"tensor"},{start:1,name:"a",type:"tensor"},{start:2,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"SelectV2",category:"logical",inputs:[{start:0,name:"condition",type:"tensor"},{start:1,name:"a",type:"tensor"},{start:2,name:"b",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]}];var logical={__proto__:null,json:json$8};const json$7=[{tfOpName:"_FusedMatMul",category:"matrices",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"},{start:2,end:0,name:"args",type:"tensors"}],attrs:[{tfName:"num_args",name:"numArgs",type:"number"},{tfName:"fused_ops",name:"fusedOps",type:"string[]",defaultValue:[]},{tfName:"epsilon",name:"epsilon",type:"number",defaultValue:1e-4},{tfName:"transpose_a",name:"transposeA",type:"bool",defaultValue:!1},{tfName:"transpose_b",name:"transposeB",type:"bool",defaultValue:!1},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"MatMul",category:"matrices",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"transpose_a",name:"transposeA",type:"bool",defaultValue:!1},{tfName:"transpose_b",name:"transposeB",type:"bool",defaultValue:!1},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"BatchMatMul",category:"matrices",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"adj_x",name:"transposeA",type:"bool",defaultValue:!1},{tfName:"adj_y",name:"transposeB",type:"bool",defaultValue:!1},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"BatchMatMulV2",category:"matrices",inputs:[{start:0,name:"a",type:"tensor"},{start:1,name:"b",type:"tensor"}],attrs:[{tfName:"adj_x",name:"transposeA",type:"bool",defaultValue:!1},{tfName:"adj_y",name:"transposeB",type:"bool",defaultValue:!1},{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Transpose",category:"matrices",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"perm",type:"number[]"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"Einsum",category:"matrices",inputs:[{start:0,end:0,name:"tensors",type:"tensors"}],attrs:[{tfName:"equation",name:"equation",type:"string"},{tfName:"N",name:"n",type:"number",defaultValue:2},{tfName:"T",name:"dtype",type:"dtype"}]}];var matrices={__proto__:null,json:json$7};const json$6=[{tfOpName:"FusedBatchNorm",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"scale",type:"tensor"},{start:2,name:"offset",type:"tensor"},{start:3,name:"mean",type:"tensor"},{start:4,name:"variance",type:"tensor"}],attrs:[{tfName:"epsilon",name:"epsilon",type:"number",defaultValue:.001},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0}]},{tfOpName:"FusedBatchNormV2",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"scale",type:"tensor"},{start:2,name:"offset",type:"tensor"},{start:3,name:"mean",type:"tensor"},{start:4,name:"variance",type:"tensor"}],attrs:[{tfName:"epsilon",name:"epsilon",type:"number",defaultValue:.001},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0}]},{tfOpName:"FusedBatchNormV3",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"scale",type:"tensor"},{start:2,name:"offset",type:"tensor"},{start:3,name:"mean",type:"tensor"},{start:4,name:"variance",type:"tensor"}],attrs:[{tfName:"epsilon",name:"epsilon",type:"number",defaultValue:.001},{tfName:"data_format",name:"dataFormat",type:"string",notSupported:!0}]},{tfOpName:"LRN",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"depth_radius",name:"radius",type:"number",defaultValue:5},{tfName:"bias",name:"bias",type:"number",defaultValue:1},{tfName:"alpha",name:"alpha",type:"number",defaultValue:1},{tfName:"beta",name:"beta",type:"number",defaultValue:.5}]},{tfOpName:"Softmax",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"LogSoftmax",category:"normalization",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"SparseToDense",category:"normalization",inputs:[{start:0,name:"sparseIndices",type:"tensor"},{start:1,name:"outputShape",type:"number[]"},{start:2,name:"sparseValues",type:"tensor"},{start:3,name:"defaultValue",type:"tensor"}],attrs:[{tfName:"validate_indices",name:"validateIndices",type:"bool",defaultValue:!0,notSupported:!0}]}];var normalization={__proto__:null,json:json$6};const json$5=[{tfOpName:"Bincount",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"size",type:"number"},{start:2,name:"weights",type:"tensor"}]},{tfOpName:"DenseBincount",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"size",type:"number"},{start:2,name:"weights",type:"tensor"}],attrs:[{tfName:"binary_output",name:"binaryOutput",type:"bool"}]},{tfOpName:"Max",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"Mean",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"Min",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"Sum",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"All",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"Any",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"ArgMax",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number"}]},{tfOpName:"ArgMin",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number"}]},{tfOpName:"Prod",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}],attrs:[{tfName:"keep_dims",name:"keepDims",type:"bool"}]},{tfOpName:"Cumsum",category:"reduction",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number"}],attrs:[{tfName:"exclusive",name:"exclusive",type:"bool"},{tfName:"reverse",name:"reverse",type:"bool"}]}];var reduction={__proto__:null,json:json$5};const json$4=[{tfOpName:"ConcatV2",category:"slice_join",inputs:[{start:0,end:-1,name:"tensors",type:"tensors"},{start:-1,name:"axis",type:"number"}],attrs:[{tfName:"N",name:"n",type:"number",defaultValue:2}]},{tfOpName:"Concat",category:"slice_join",inputs:[{start:1,end:0,name:"tensors",type:"tensors"},{start:0,name:"axis",type:"number"}],attrs:[{tfName:"N",name:"n",type:"number",defaultValue:2}]},{tfOpName:"GatherV2",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"indices",type:"tensor"},{start:2,name:"axis",type:"number",defaultValue:0}],attrs:[{tfName:"batch_dims",name:"batchDims",type:"number",defaultValue:0}]},{tfOpName:"Gather",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"indices",type:"tensor"}],attrs:[{tfName:"validate_indices",name:"validateIndices",type:"bool",notSupported:!0}]},{tfOpName:"Reverse",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"dims",type:"bool[]"}]},{tfOpName:"ReverseV2",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number[]"}]},{tfOpName:"Slice",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"begin",type:"number[]"},{start:2,name:"size",type:"number[]"}]},{tfOpName:"StridedSlice",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"begin",type:"number[]"},{start:2,name:"end",type:"number[]"},{start:3,name:"strides",type:"number[]"}],attrs:[{tfName:"begin_mask",name:"beginMask",type:"number",defaultValue:0},{tfName:"end_mask",name:"endMask",type:"number",defaultValue:0},{tfName:"new_axis_mask",name:"newAxisMask",type:"number",defaultValue:0},{tfName:"ellipsis_mask",name:"ellipsisMask",type:"number",defaultValue:0},{tfName:"shrink_axis_mask",name:"shrinkAxisMask",type:"number",defaultValue:0}]},{tfOpName:"Pack",category:"slice_join",inputs:[{start:0,end:0,name:"tensors",type:"tensors"}],attrs:[{tfName:"axis",name:"axis",type:"number",defaultValue:0}]},{tfOpName:"Unpack",category:"slice_join",inputs:[{start:0,name:"tensor",type:"tensor"}],attrs:[{tfName:"axis",name:"axis",type:"number",defaultValue:0},{tfName:"num",name:"num",type:"number",defaultValue:0,notSupported:!0}]},{tfOpName:"Tile",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"reps",type:"number[]"}]},{tfOpName:"Split",category:"slice_join",inputs:[{start:0,name:"axis",type:"number",defaultValue:0},{start:1,name:"x",type:"tensor"}],attrs:[{tfName:"num_split",name:"numOrSizeSplits",type:"number",defaultValue:1}]},{tfOpName:"SplitV",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"numOrSizeSplits",type:"number[]"},{start:2,name:"axis",type:"number",defaultValue:0}]},{tfOpName:"ScatterNd",category:"slice_join",inputs:[{start:0,name:"indices",type:"tensor"},{start:1,name:"values",type:"tensor"},{start:2,name:"shape",type:"number[]"}]},{tfOpName:"GatherNd",category:"slice_join",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"indices",type:"tensor"}]},{tfOpName:"SparseToDense",category:"slice_join",inputs:[{start:0,name:"sparseIndices",type:"tensor"},{start:1,name:"outputShape",type:"number[]"},{start:2,name:"sparseValues",type:"tensor"},{start:3,name:"defaultValue",type:"tensor"}],attrs:[{tfName:"validate_indices",name:"validateIndices",type:"bool",defaultValue:!1,notSupported:!0}]}];var sliceJoin={__proto__:null,json:json$4};const json$3=[{tfOpName:"SparseFillEmptyRows",category:"sparse",inputs:[{start:0,name:"indices",type:"tensor"},{start:1,name:"values",type:"tensor"},{start:2,name:"denseShape",type:"tensor"},{start:3,name:"defaultValue",type:"tensor"}]},{tfOpName:"SparseReshape",category:"sparse",inputs:[{start:0,name:"inputIndices",type:"tensor"},{start:1,name:"inputShape",type:"tensor"},{start:2,name:"newShape",type:"tensor"}],attrs:[{tfName:"T",name:"dtype",type:"dtype",notSupported:!0}]},{tfOpName:"SparseSegmentMean",category:"sparse",inputs:[{start:0,name:"data",type:"tensor"},{start:1,name:"indices",type:"tensor"},{start:2,name:"segmentIds",type:"tensor"}]},{tfOpName:"SparseSegmentSum",category:"sparse",inputs:[{start:0,name:"data",type:"tensor"},{start:1,name:"indices",type:"tensor"},{start:2,name:"segmentIds",type:"tensor"}]}];var sparse={__proto__:null,json:json$3};const json$2=[{tfOpName:"FFT",category:"spectral",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"IFFT",category:"spectral",inputs:[{start:0,name:"x",type:"tensor"}]},{tfOpName:"RFFT",category:"spectral",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"fft_length",type:"number",notSupported:!0}]},{tfOpName:"IRFFT",category:"spectral",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"fft_length",type:"number",notSupported:!0}]}];var spectral={__proto__:null,json:json$2};const json$1=[{tfOpName:"StringNGrams",category:"string",inputs:[{start:0,name:"data",type:"tensor"},{start:1,name:"dataSplits",type:"tensor"}],attrs:[{tfName:"separator",name:"separator",type:"string"},{tfName:"ngram_widths",name:"nGramWidths",type:"number[]"},{tfName:"left_pad",name:"leftPad",type:"string"},{tfName:"right_pad",name:"rightPad",type:"string"},{tfName:"pad_width",name:"padWidth",type:"number"},{tfName:"preserve_short_sequences",name:"preserveShortSequences",type:"bool"}],outputs:["ngrams","ngrams_splits"]},{tfOpName:"StringSplit",category:"string",inputs:[{start:0,name:"input",type:"tensor"},{start:1,name:"delimiter",type:"tensor"}],attrs:[{tfName:"skip_empty",name:"skipEmpty",type:"bool"}],outputs:["indices","values","shape"]},{tfOpName:"StringToHashBucketFast",category:"string",inputs:[{start:0,name:"input",type:"tensor"}],attrs:[{tfName:"num_buckets",name:"numBuckets",type:"number"}]}];var string={__proto__:null,json:json$1};const json=[{tfOpName:"Cast",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"SrcT",name:"sdtype",type:"dtype",notSupported:!0},{tfName:"DstT",name:"dtype",type:"dtype"}]},{tfOpName:"ExpandDims",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"axis",type:"number"}]},{tfOpName:"MirrorPad",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"padding",type:"number[]"}],attrs:[{tfName:"mode",name:"mode",type:"string"}]},{tfOpName:"Pad",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"padding",type:"number[]"}],attrs:[{tfName:"constant_value",name:"constantValue",type:"number",defaultValue:0}]},{tfOpName:"PadV2",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"padding",type:"number[]"},{start:2,name:"constantValue",type:"number",defaultValue:0}]},{tfOpName:"Reshape",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"shape",type:"number[]"}]},{tfOpName:"Squeeze",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"axis",tfDeprecatedName:"squeeze_dims",name:"axis",type:"number[]"}]},{tfOpName:"SpaceToBatchND",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"blockShape",type:"number[]"},{start:2,name:"paddings",type:"number[]"}]},{tfOpName:"BatchToSpaceND",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"blockShape",type:"number[]"},{start:2,name:"crops",type:"number[]"}]},{tfOpName:"DepthToSpace",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"}],attrs:[{tfName:"block_size",name:"blockSize",type:"number"},{tfName:"data_format",name:"dataFormat",type:"string"}]},{tfOpName:"BroadcastTo",category:"transformation",inputs:[{start:0,name:"x",type:"tensor"},{start:1,name:"shape",type:"number[]"}],attrs:[]}];var transformation={__proto__:null,json};class OperationMapper{static get Instance(){return this._instance||(this._instance=new this)}constructor(){const e=[].concat(...[arithmetic,basicMath,control,convolution,creation,dynamic,evaluation,graph,hashTable,image,logical,matrices,normalization,reduction,sliceJoin,sparse,spectral,string,transformation].map(e=>e.json));this.opMappers=e.reduce((e,t)=>(e[t.tfOpName]=t,e),{})}transformGraph(e,t={}){const n=[],r=[],a=[],s=e.node.reduce((e,t)=>(e[t.name]=this.mapNode(t),t.op.startsWith("Placeholder")?n.push(e[t.name]):"Const"===t.op?r.push(e[t.name]):null!=t.input&&0!==t.input.length||a.push(e[t.name]),e),{});let o=[];const i=[];let l={},u={};null!=t&&(l=this.mapSignatureEntries(t.inputs),u=this.mapSignatureEntries(t.outputs));const c=Object.keys(s);c.forEach(e=>{const t=s[e];t.inputNames.forEach((e,n)=>{const[r,,a]=getNodeNameAndIndex(e),o=s[r];if(null!=o.outputs){const e=o.outputs.indexOf(a);-1!==e&&(t.inputNames[n]=`${r}:${e}`)}t.inputs.push(o),o.children.push(t)})}),0===Object.keys(u).length?c.forEach(e=>{const t=s[e];0===t.children.length&&i.push(t)}):Object.keys(u).forEach(e=>{const[t]=getNodeNameAndIndex(e),n=s[t];null!=n&&(n.signatureKey=u[e],i.push(n))}),Object.keys(l).length>0?Object.keys(l).forEach(e=>{const[t]=getNodeNameAndIndex(e),n=s[t];n&&(n.signatureKey=l[e],o.push(n))}):o=n;let p={};null!=e.library&&null!=e.library.function&&(p=e.library.function.reduce((e,t)=>(e[t.signature.name]=this.mapFunction(t),e),{}));const d={nodes:s,inputs:o,outputs:i,weights:r,placeholders:n,signature:t,functions:p};return a.length>0&&(d.initNodes=a),d}mapSignatureEntries(e){return Object.keys(e||{}).reduce((t,n)=>(t[e[n].name]=n,t),{})}mapNode(e){const t=getRegisteredOp(e.op)||this.opMappers[e.op]||{};null==e.attr&&(e.attr={});const n={name:e.name,op:e.op,category:t.category,inputNames:(e.input||[]).map(e=>e.startsWith("^")?e.substr(1):e),inputs:[],children:[],inputParams:{},attrParams:{},rawAttrs:e.attr,outputs:t.outputs};return null!=t.inputs&&(n.inputParams=t.inputs.reduce((e,t)=>(e[t.name]={type:t.type,inputIndexStart:t.start,inputIndexEnd:t.end},e),{})),null!=t.attrs&&(n.attrParams=t.attrs.reduce((t,n)=>{const r=n.type;let a;switch(n.type){case"string":a=getStringParam(e.attr,n.tfName,n.defaultValue),void 0===a&&n.tfDeprecatedName&&(a=getStringParam(e.attr,n.tfDeprecatedName,n.defaultValue));break;case"string[]":a=getStringArrayParam(e.attr,n.tfName,n.defaultValue),void 0===a&&n.tfDeprecatedName&&(a=getStringArrayParam(e.attr,n.tfDeprecatedName,n.defaultValue));break;case"number":a=getNumberParam(e.attr,n.tfName,n.defaultValue||0),void 0===a&&n.tfDeprecatedName&&(a=getNumberParam(e.attr,n.tfDeprecatedName,n.defaultValue));break;case"number[]":a=getNumericArrayParam(e.attr,n.tfName,n.defaultValue),void 0===a&&n.tfDeprecatedName&&(a=getNumericArrayParam(e.attr,n.tfDeprecatedName,n.defaultValue));break;case"bool":a=getBoolParam(e.attr,n.tfName,n.defaultValue),void 0===a&&n.tfDeprecatedName&&(a=getBoolParam(e.attr,n.tfDeprecatedName,n.defaultValue));break;case"bool[]":a=getBoolArrayParam(e.attr,n.tfName,n.defaultValue),void 0===a&&n.tfDeprecatedName&&(a=getBoolArrayParam(e.attr,n.tfDeprecatedName,n.defaultValue));break;case"shape":a=getTensorShapeParam(e.attr,n.tfName,n.defaultValue),void 0===a&&n.tfDeprecatedName&&(a=getTensorShapeParam(e.attr,n.tfDeprecatedName,n.defaultValue));break;case"shape[]":a=getTensorShapeArrayParam(e.attr,n.tfName,n.defaultValue),void 0===a&&n.tfDeprecatedName&&(a=getTensorShapeArrayParam(e.attr,n.tfDeprecatedName,n.defaultValue));break;case"dtype":a=getDtypeParam(e.attr,n.tfName,n.defaultValue),void 0===a&&n.tfDeprecatedName&&(a=getDtypeParam(e.attr,n.tfDeprecatedName,n.defaultValue));break;case"dtype[]":a=getDtypeArrayParam(e.attr,n.tfName,n.defaultValue),void 0===a&&n.tfDeprecatedName&&(a=getDtypeArrayParam(e.attr,n.tfDeprecatedName,n.defaultValue));break;case"func":a=getFuncParam(e.attr,n.tfName,n.defaultValue),void 0===a&&n.tfDeprecatedName&&(a=getFuncParam(e.attr,n.tfDeprecatedName,n.defaultValue));break;case"tensor":case"tensors":break;default:throw new Error(`Unsupported param type: ${n.type} for op: ${e.op}`)}return t[n.name]={value:a,type:r},t},{})),n}mapFunction(e){const t=e.nodeDef,n=[];let r={};null!=t&&(r=t.reduce((e,t)=>(e[t.name]=this.mapNode(t),"Const"===t.op&&n.push(e[t.name]),e),{}));const a=[],s=[];e.signature.inputArg.forEach(e=>{const[t]=getNodeNameAndIndex(e.name),n={name:t,op:"Placeholder",inputs:[],inputNames:[],category:"graph",inputParams:{},attrParams:{dtype:{value:parseDtypeParam(e.type),type:"dtype"}},children:[]};n.signatureKey=e.name,a.push(n),r[t]=n}),Object.keys(r).forEach(e=>{const t=r[e];t.inputNames.forEach((e,n)=>{const[a,,s]=getNodeNameAndIndex(e),o=r[a];if(null!=o.outputs){const e=o.outputs.indexOf(s);-1!==e&&(t.inputNames[n]=`${a}:${e}`)}t.inputs.push(o),o.children.push(t)})});const o=e.ret;e.signature.outputArg.forEach(e=>{const[t,n]=getNodeNameAndIndex(o[e.name]),a=r[t];null!=a&&(a.defaultOutput=n,s.push(a))});const i=this.mapArgsToSignature(e);return{nodes:r,inputs:a,outputs:s,weights:n,placeholders:[],signature:i}}mapArgsToSignature(e){return{methodName:e.signature.name,inputs:e.signature.inputArg.reduce((e,t)=>(e[t.name]=this.mapArgToTensorInfo(t),e),{}),outputs:e.signature.outputArg.reduce((t,n)=>(t[n.name]=this.mapArgToTensorInfo(n,e.ret),t),{})}}mapArgToTensorInfo(e,t){let n=e.name;return null!=t&&(n=t[n]),{name:n,dtype:e.type}}}function decodeBase64(e){const t=env().global;if(void 0!==t.atob)return t.atob(e);if("undefined"!=typeof Buffer)return new Buffer(e,"base64").toString();throw new Error("Unable to decode base64 in this environment. Missing built-in atob() or Buffer()")}function parseStringParam(e,t){const n=Array.isArray(e)?String.fromCharCode.apply(null,e):decodeBase64(e);return t?n:n.toLowerCase()}function getStringParam(e,t,n,r=!1){const a=e[t];return null!=a?parseStringParam(a.s,r):n}function getBoolParam(e,t,n){const r=e[t];return r?r.b:n}function getNumberParam(e,t,n){const r=e[t]||{},a=null!=r.i?r.i:null!=r.f?r.f:n;return"number"==typeof a?a:parseInt(a,10)}function parseDtypeParam(e){switch("string"==typeof e&&(e=DataType[e]),e){case DataType.DT_FLOAT:return"float32";case DataType.DT_INT32:case DataType.DT_INT64:case DataType.DT_INT8:case DataType.DT_UINT8:return"int32";case DataType.DT_BOOL:return"bool";case DataType.DT_DOUBLE:return"float32";case DataType.DT_STRING:return"string";default:return null}}function getFuncParam(e,t,n){const r=e[t];return r&&r.func?r.func.name:n}function getDtypeParam(e,t,n){const r=e[t];return r&&r.type?parseDtypeParam(r.type):n}function getDtypeArrayParam(e,t,n){const r=e[t];return r&&r.list&&r.list.type?r.list.type.map(e=>parseDtypeParam(e)):n}function parseTensorShapeParam(e){if(!e.unknownRank)return null!=e.dim?e.dim.map(e=>"number"==typeof e.size?e.size:parseInt(e.size,10)):[]}function getTensorShapeParam(e,t,n){const r=e[t];return r&&r.shape?parseTensorShapeParam(r.shape):n}function getNumericArrayParam(e,t,n){const r=e[t];return r?((r.list.f&&r.list.f.length?r.list.f:r.list.i)||[]).map(e=>"number"==typeof e?e:parseInt(e,10)):n}function getStringArrayParam(e,t,n,r=!1){const a=e[t];return a&&a.list&&a.list.s?a.list.s.map(e=>parseStringParam(e,r)):n}function getTensorShapeArrayParam(e,t,n){const r=e[t];return r&&r.list&&r.list.shape?r.list.shape.map(e=>parseTensorShapeParam(e)):n}function getBoolArrayParam(e,t,n){const r=e[t];return r&&r.list&&r.list.b?r.list.b:n}class NodeValueImpl{constructor(e,t,n){this.node=e,this.tensorMap=t,this.context=n,this.inputs=[],this.attrs={},this.inputs=e.inputNames.map(e=>this.getInput(e)),null!=e.rawAttrs&&(this.attrs=Object.keys(e.rawAttrs).reduce((e,t)=>(e[t]=this.getAttr(t),e),{}))}getInput(e){return getTensor(e,this.tensorMap,this.context)}getAttr(e,t){const n=this.node.rawAttrs[e];if(null!=n.tensor)return getTensor(e,this.tensorMap,this.context);if(null!=n.i||null!=n.f)return getNumberParam(this.node.rawAttrs,e,t);if(null!=n.s)return getStringParam(this.node.rawAttrs,e,t);if(null!=n.b)return getBoolParam(this.node.rawAttrs,e,t);if(null!=n.shape)return getTensorShapeParam(this.node.rawAttrs,e,t);if(null!=n.type)return getDtypeParam(this.node.rawAttrs,e,t);if(null!=n.list){if(null!=n.list.i||null!=n.list.f)return getNumericArrayParam(this.node.rawAttrs,e,t);if(null!=n.list.s)return getStringArrayParam(this.node.rawAttrs,e,t);if(null!=n.list.shape)return getTensorShapeArrayParam(this.node.rawAttrs,e,t);if(null!=n.list.b)return getBoolArrayParam(this.node.rawAttrs,e,t);if(null!=n.list.type)return getDtypeArrayParam(this.node.rawAttrs,e,t)}return t}}const executeOp$j=(e,t,n)=>{switch(e.op){case"BiasAdd":case"AddV2":case"Add":return[add$2(getParamValue("a",e,t,n),getParamValue("b",e,t,n))];case"AddN":return[addN$2(getParamValue("tensors",e,t,n))];case"FloorMod":case"Mod":return[mod$2(getParamValue("a",e,t,n),getParamValue("b",e,t,n))];case"Mul":return[mul(getParamValue("a",e,t,n),getParamValue("b",e,t,n))];case"RealDiv":case"Div":return[div$1(getParamValue("a",e,t,n),getParamValue("b",e,t,n))];case"DivNoNan":return[divNoNan(getParamValue("a",e,t,n),getParamValue("b",e,t,n))];case"FloorDiv":return[floorDiv$2(getParamValue("a",e,t,n),getParamValue("b",e,t,n))];case"Sub":return[sub$2(getParamValue("a",e,t,n),getParamValue("b",e,t,n))];case"Minimum":return[minimum$3(getParamValue("a",e,t,n),getParamValue("b",e,t,n))];case"Maximum":return[maximum$3(getParamValue("a",e,t,n),getParamValue("b",e,t,n))];case"Pow":return[pow$2(getParamValue("a",e,t,n),getParamValue("b",e,t,n))];case"SquaredDifference":return[squaredDifference$2(getParamValue("a",e,t,n),getParamValue("b",e,t,n))];default:throw TypeError(`Node type ${e.op} is not implemented`)}},executeOp$i=(e,t,n)=>{switch(e.op){case"Abs":case"ComplexAbs":return[abs$2(getParamValue("x",e,t,n))];case"Acos":return[acos$2(getParamValue("x",e,t,n))];case"Acosh":return[acosh$2(getParamValue("x",e,t,n))];case"Asin":return[asin$2(getParamValue("x",e,t,n))];case"Asinh":return[asinh$2(getParamValue("x",e,t,n))];case"Atan":return[atan$2(getParamValue("x",e,t,n))];case"Atan2":return[atan2$2(getParamValue("x",e,t,n),getParamValue("y",e,t,n))];case"Atanh":return[atanh$2(getParamValue("x",e,t,n))];case"Ceil":return[ceil$2(getParamValue("x",e,t,n))];case"Complex":return[complex$2(getParamValue("real",e,t,n),getParamValue("imag",e,t,n))];case"Cos":return[cos$2(getParamValue("x",e,t,n))];case"Cosh":return[cosh$2(getParamValue("x",e,t,n))];case"Elu":return[elu$4(getParamValue("x",e,t,n))];case"Erf":return[erf$2(getParamValue("x",e,t,n))];case"Exp":return[exp$2(getParamValue("x",e,t,n))];case"Expm1":return[expm1$2(getParamValue("x",e,t,n))];case"Floor":return[floor$2(getParamValue("x",e,t,n))];case"Log":return[log$3(getParamValue("x",e,t,n))];case"Log1p":return[log1p$2(getParamValue("x",e,t,n))];case"Imag":return[imag$2(getParamValue("x",e,t,n))];case"Neg":return[neg$2(getParamValue("x",e,t,n))];case"Reciprocal":return[reciprocal$2(getParamValue("x",e,t,n))];case"Real":return[real$2(getParamValue("x",e,t,n))];case"Relu":return[relu$3(getParamValue("x",e,t,n))];case"Round":return[round$2(getParamValue("x",e,t,n))];case"Selu":return[selu$2(getParamValue("x",e,t,n))];case"Sigmoid":return[sigmoid$2(getParamValue("x",e,t,n))];case"Sin":return[sin$2(getParamValue("x",e,t,n))];case"Sign":return[sign$2(getParamValue("x",e,t,n))];case"Sinh":return[sinh$2(getParamValue("x",e,t,n))];case"Softplus":return[softplus$2(getParamValue("x",e,t,n))];case"Sqrt":return[sqrt$2(getParamValue("x",e,t,n))];case"Square":return[square$2(getParamValue("x",e,t,n))];case"Tanh":return[tanh$2(getParamValue("x",e,t,n))];case"Tan":return[tan$2(getParamValue("x",e,t,n))];case"ClipByValue":return[clipByValue$1(getParamValue("x",e,t,n),getParamValue("clipValueMin",e,t,n),getParamValue("clipValueMax",e,t,n))];case"Relu6":return[relu6$2(getParamValue("x",e,t,n))];case"Rsqrt":return[rsqrt$2(getTensor(e.inputNames[0],t,n))];case"Prod":return[prod$2(getParamValue("x",e,t,n),getParamValue("axes",e,t,n))];case"LeakyRelu":return[leakyRelu$2(getParamValue("x",e,t,n),getParamValue("alpha",e,t,n))];case"Prelu":return[prelu$3(getParamValue("x",e,t,n),getParamValue("alpha",e,t,n))];case"IsNan":return[isNaN$3(getTensor(e.inputNames[0],t,n))];default:throw TypeError(`Node type ${e.op} is not implemented`)}};function assertShapesMatchAllowUndefinedSize(e,t,n=""){if("number"!=typeof e&&"number"!=typeof t){assert$4(e.length===t.length,()=>n+` Shapes ${e} and ${t} must match`);for(let r=0;r<e.length;r++){const a=e[r],s=t[r];assert$4(a<0||s<0||a===s,()=>n+` Shapes ${e} and ${t} must match`)}}}function fullDefinedShape(e){return"number"!=typeof e&&!e.some(e=>e<0)}function inferElementShape(e,t,n){let r=mergeElementShape(e,n);const a=!fullDefinedShape(r);if(a&&0===t.length)throw new Error(`Tried to calculate elements of an empty list with non-fully-defined elementShape: ${r}`);if(a&&t.forEach(e=>{r=mergeElementShape(e.shape,r)}),!fullDefinedShape(r))throw new Error(`Non-fully-defined elementShape: ${r}`);return r}function mergeElementShape(e,t){if("number"==typeof e)return t;if("number"==typeof t)return e;if(e.length!==t.length)throw new Error(`Incompatible ranks during merge: ${e} vs. ${t}`);const n=[];for(let r=0;r<e.length;++r){const a=e[r],s=t[r];if(a>=0&&s>=0&&a!==s)throw new Error(`Incompatible shape during merge: ${e} vs. ${t}`);n[r]=a>=0?a:s}return n}class TensorArray{constructor(e,t,n,r,a,s,o){this.name=e,this.dtype=t,this.maxSize=n,this.elementShape=r,this.identicalElementShapes=a,this.dynamicSize=s,this.clearAfterRead=o,this.tensors=[],this.closed_=!1,this.idTensor=scalar(0),keep(this.idTensor)}get id(){return this.idTensor.id}get closed(){return this.closed_}clearAndClose(e){this.tensors.forEach(t=>{null!=e&&e.has(t.tensor.id)||t.tensor.dispose()}),this.tensors=[],this.closed_=!0,this.idTensor.dispose()}size(){return this.tensors.length}read(e){if(this.closed_)throw new Error(`TensorArray ${this.name} has already been closed.`);if(e<0||e>=this.size())throw new Error(`Tried to read from index ${e}, but array size is: ${this.size()}`);const t=this.tensors[e];if(t.cleared)throw new Error(`TensorArray ${this.name}: Could not read index ${e} twice because it was cleared after a previous read (perhaps try setting clear_after_read = false?).`);return this.clearAfterRead&&(t.cleared=!0),t.read=!0,t.tensor}readMany(e){return e.map(e=>this.read(e))}write(e,t){if(this.closed_)throw new Error(`TensorArray ${this.name} has already been closed.`);if(e<0||!this.dynamicSize&&e>=this.maxSize)throw new Error(`Tried to write to index ${e}, but array is not resizeable and size is: ${this.maxSize}`);const n=this.tensors[e]||{};if(t.dtype!==this.dtype)throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${e},\n          because the value dtype is ${t.dtype}, but TensorArray dtype is ${this.dtype}.`);if(0!==this.size()||null!=this.elementShape&&0!==this.elementShape.length||(this.elementShape=t.shape),assertShapesMatchAllowUndefinedSize(this.elementShape,t.shape,`TensorArray ${this.name}: Could not write to TensorArray index ${e}.`),n.read)throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${e}, because it has already been read.`);if(n.written)throw new Error(`TensorArray ${this.name}: Could not write to TensorArray index ${e}, because it has already been written.`);n.tensor=t,keep(t),n.written=!0,this.tensors[e]=n}writeMany(e,t){if(e.length!==t.length)throw new Error(`TensorArray ${this.name}: could not write multiple tensors,because the index size: ${e.length} is not the same as tensors size: ${t.length}.`);e.forEach((e,n)=>this.write(e,t[n]))}gather(e,t){if(t&&t!==this.dtype)throw new Error(`TensorArray dtype is ${this.dtype} but gather requested dtype ${t}`);if(e)e=e.slice(0,this.size());else{e=[];for(let t=0;t<this.size();t++)e.push(t)}if(0===e.length)return tensor([],[0].concat(this.elementShape));const n=this.readMany(e);return assertShapesMatchAllowUndefinedSize(this.elementShape,n[0].shape,"TensorArray shape mismatch: "),stack(n,0)}concat(e){if(e&&e!==this.dtype)throw new Error(`TensorArray dtype is ${this.dtype} but concat requested dtype ${e}`);if(0===this.size())return tensor([],[0].concat(this.elementShape));const t=[];for(let e=0;e<this.size();e++)t.push(e);const n=this.readMany(t);return assertShapesMatchAllowUndefinedSize(this.elementShape,n[0].shape,`TensorArray shape mismatch: tensor array shape (${this.elementShape}) vs first tensor shape (${n[0].shape})`),concat$2(n,0)}scatter(e,t){if(t.dtype!==this.dtype)throw new Error(`TensorArray dtype is ${this.dtype} but tensor has dtype ${t.dtype}`);if(e.length!==t.shape[0])throw new Error(`Expected len(indices) == tensor.shape[0], but saw: ${e.length} vs. ${t.shape[0]}`);const n=Math.max(...e);if(!this.dynamicSize&&n>=this.maxSize)throw new Error(`Max index must be < array size (${n}  vs. ${this.maxSize})`);this.writeMany(e,unstack(t,0))}split(e,t){if(t.dtype!==this.dtype)throw new Error(`TensorArray dtype is ${this.dtype} but tensor has dtype ${t.dtype}`);let n=0;const r=e.map(e=>(n+=e,n));if(n!==t.shape[0])throw new Error(`Expected sum of lengths to be equal to\n          tensor.shape[0], but sum of lengths is\n        ${n}, and tensor's shape is: ${t.shape}`);if(!this.dynamicSize&&e.length!==this.maxSize)throw new Error(`TensorArray's size is not equal to the size of lengths (${this.maxSize} vs. ${e.length}), and the TensorArray is not marked as dynamically resizeable`);const a=0===n?0:t.size/n,s=[];tidy(()=>{t=reshape$3(t,[1,n,a]);for(let n=0;n<e.length;++n)s[n]=reshape$3(slice$2(t,[0,0===n?0:r[n-1],0],[1,e[n],a]),this.elementShape);return s});const o=[];for(let t=0;t<e.length;t++)o[t]=t;this.writeMany(o,s)}}class TensorList{constructor(e,t,n,r=-1){this.tensors=e,this.elementShape=t,this.elementDtype=n,null!=e&&e.forEach(e=>{if(n!==e.dtype)throw new Error(`Invalid data types; op elements ${n}, but list elements ${e.dtype}`);assertShapesMatchAllowUndefinedSize(t,e.shape,"TensorList shape mismatch: "),keep(e)}),this.idTensor=scalar(0),this.maxNumElements=r,keep(this.idTensor)}get id(){return this.idTensor.id}copy(){return new TensorList([...this.tensors],this.elementShape,this.elementDtype)}clearAndClose(e){this.tensors.forEach(t=>{null!=e&&e.has(t.id)||t.dispose()}),this.tensors.length=0,this.idTensor.dispose()}size(){return this.tensors.length}stack(e,t,n=-1){if(t!==this.elementDtype)throw new Error(`Invalid data types; op elements ${t}, but list elements ${this.elementDtype}`);if(-1!==n&&this.tensors.length!==n)throw new Error(`Operation expected a list with ${n} elements but got a list with ${this.tensors.length} elements.`);assertShapesMatchAllowUndefinedSize(e,this.elementShape,"TensorList shape mismatch: ");const r=inferElementShape(this.elementShape,this.tensors,e);return tidy(()=>{const e=this.tensors.map(e=>reshape$3(e,r));return stack(e,0)})}popBack(e,t){if(t!==this.elementDtype)throw new Error(`Invalid data types; op elements ${t}, but list elements ${this.elementDtype}`);if(0===this.size())throw new Error("Trying to pop from an empty list.");const n=inferElementShape(this.elementShape,this.tensors,e),r=this.tensors.pop();return assertShapesMatchAllowUndefinedSize(r.shape,e,"TensorList shape mismatch: "),reshape$3(r,n)}pushBack(e){if(e.dtype!==this.elementDtype)throw new Error(`Invalid data types; op elements ${e.dtype}, but list elements ${this.elementDtype}`);if(assertShapesMatchAllowUndefinedSize(e.shape,this.elementShape,"TensorList shape mismatch: "),this.maxNumElements===this.size())throw new Error("Trying to push element into a full list.");keep(e),this.tensors.push(e)}resize(e){if(e<0)throw new Error(`TensorListResize expects size to be non-negative. Got: ${e}`);if(-1!==this.maxNumElements&&e>this.maxNumElements)throw new Error(`TensorListResize input size ${e} is greater maxNumElement ${this.maxNumElements}.`);this.tensors.length=e}getItem(e,t,n){if(n!==this.elementDtype)throw new Error(`Invalid data types; op elements ${n}, but list elements ${this.elementDtype}`);if(e<0||e>this.tensors.length)throw new Error(`Trying to access element ${e} in a list with ${this.tensors.length} elements.`);if(null==this.tensors[e])throw new Error(`element at index ${e} is null.`);assertShapesMatchAllowUndefinedSize(this.tensors[e].shape,t,"TensorList shape mismatch: ");const r=inferElementShape(this.elementShape,this.tensors,t);return reshape$3(this.tensors[e],r)}setItem(e,t){if(t.dtype!==this.elementDtype)throw new Error(`Invalid data types; op elements ${t.dtype}, but list elements ${this.elementDtype}`);if(e<0||-1!==this.maxNumElements&&e>=this.maxNumElements)throw new Error(`Trying to set element ${e} in a list with max ${this.maxNumElements} elements.`);assertShapesMatchAllowUndefinedSize(this.elementShape,t.shape,"TensorList shape mismatch: "),keep(t),this.tensors[e]=t}gather(e,t,n){if(t!==this.elementDtype)throw new Error(`Invalid data types; op elements ${t}, but list elements ${this.elementDtype}`);assertShapesMatchAllowUndefinedSize(this.elementShape,n,"TensorList shape mismatch: "),e=e.slice(0,this.size());const r=inferElementShape(this.elementShape,this.tensors,n);return 0===e.length?tensor([],[0].concat(r)):tidy(()=>{const t=e.map(e=>reshape$3(this.tensors[e],r));return stack(t,0)})}concat(e,t){if(e&&e!==this.elementDtype)throw new Error(`TensorList dtype is ${this.elementDtype} but concat requested dtype ${e}`);assertShapesMatchAllowUndefinedSize(this.elementShape,t,"TensorList shape mismatch: ");const n=inferElementShape(this.elementShape,this.tensors,t);return 0===this.size()?tensor([],[0].concat(n)):tidy(()=>{const e=this.tensors.map(e=>reshape$3(e,n));return concat$2(e,0)})}}function fromTensor(e,t,n){const r=e.dtype;if(e.shape.length<1)throw new Error(`Tensor must be at least a vector, but saw shape: ${e.shape}`);if(e.dtype!==n)throw new Error(`Invalid data types; op elements ${e.dtype}, but list elements ${n}`);assertShapesMatchAllowUndefinedSize(e.shape.slice(1),t,"TensorList shape mismatch: ");const a=unstack(e);return new TensorList(a,t,r)}function reserve(e,t,n){return new TensorList([],e,t,n)}function scatter(e,t,n,r){if(t.length!==e.shape[0])throw new Error(`Expected len(indices) == tensor.shape[0], but saw: ${t.length} vs. ${e.shape[0]}`);const a=Math.max(...t);if(null!=r&&-1!==r&&a>=r)throw new Error(`Max index must be < array size (${a}  vs. ${r})`);const s=new TensorList([],n,e.dtype,r),o=unstack(e,0);return t.forEach((e,t)=>{s.setItem(e,o[t])}),s}function split$1(e,t,n){let r=0;const a=t.map(e=>(r+=e,r));if(r!==e.shape[0])throw new Error(`Expected sum of lengths to be equal to\n          tensor.shape[0], but sum of lengths is\n        ${r}, and tensor's shape is: ${e.shape}`);const s=mergeElementShape(e.shape.slice(1),n),o=0===r?0:e.size/r,i=tidy(()=>{const n=[];e=reshape$3(e,[1,r,o]);for(let r=0;r<t.length;++r)n[r]=reshape$3(slice$2(e,[0,0===r?0:a[r-1],0],[1,t[r],o]),s);return e.dispose(),n}),l=new TensorList([],n,e.dtype,t.length);for(let e=0;e<i.length;e++)l.setItem(e,i[e]);return l}const executeOp$h=async(e,t,n)=>{switch(e.op){case"If":case"StatelessIf":{const r=getParamValue("thenBranch",e,t,n),a=getParamValue("elseBranch",e,t,n),s=getParamValue("cond",e,t,n),o=getParamValue("args",e,t,n);return(await s.data())[0]?n.functionMap[r].executeFunctionAsync(o,n.tensorArrayMap,n.tensorListMap):n.functionMap[a].executeFunctionAsync(o,n.tensorArrayMap,n.tensorListMap)}case"While":case"StatelessWhile":{const r=getParamValue("body",e,t,n),a=getParamValue("cond",e,t,n),s=getParamValue("args",e,t,n),o=await n.functionMap[a].executeFunctionAsync(s,n.tensorArrayMap,n.tensorListMap),i=s.map(e=>e.id);let l=await o[0].data();o.forEach(e=>{e.kept||-1!==i.indexOf(e.id)||e.dispose()});let u=s;for(;l[0];){const e=u;u=await n.functionMap[r].executeFunctionAsync(u,n.tensorArrayMap,n.tensorListMap);const t=u.map(e=>e.id);e.forEach(e=>{e.kept||-1!==i.indexOf(e.id)||-1!==t.indexOf(e.id)||e.dispose()});const s=await n.functionMap[a].executeFunctionAsync(u,n.tensorArrayMap,n.tensorListMap);l=await s[0].data(),s.forEach(e=>{e.kept||-1!==i.indexOf(e.id)||-1!==t.indexOf(e.id)||e.dispose()})}return u}case"LoopCond":return[cloneTensor(getParamValue("pred",e,t,n))];case"Switch":{const r=getParamValue("pred",e,t,n);let a=getParamValue("data",e,t,n);return a.kept||(a=cloneTensor(a)),(await r.data())[0]?[void 0,a]:[a,void 0]}case"Merge":{const r=e.inputNames.find(e=>void 0!==getTensor(e,t,n));return r?[cloneTensor(getTensor(r,t,n))]:void 0}case"Enter":{const r=getParamValue("frameName",e,t,n),a=getParamValue("tensor",e,t,n);return n.enterFrame(r),[cloneTensor(a)]}case"Exit":{const r=getParamValue("tensor",e,t,n);return n.exitFrame(),[cloneTensor(r)]}case"NextIteration":{const r=getParamValue("tensor",e,t,n);return n.nextIteration(),[cloneTensor(r)]}case"TensorArrayV3":{const r=getParamValue("size",e,t,n),a=getParamValue("dtype",e,t,n),s=getParamValue("elementShape",e,t,n),o=getParamValue("dynamicSize",e,t,n),i=getParamValue("clearAfterRead",e,t,n),l=getParamValue("identicalElementShapes",e,t,n),u=getParamValue("name",e,t,n),c=new TensorArray(u,a,r,s,l,o,i);return n.addTensorArray(c),[c.idTensor,scalar(1)]}case"TensorArrayWriteV3":{const r=getParamValue("tensorArrayId",e,t,n),a=getParamValue("index",e,t,n),s=getParamValue("tensor",e,t,n),o=n.getTensorArray(r.id);return o.write(a,s),[o.idTensor]}case"TensorArrayReadV3":{const r=getParamValue("tensorArrayId",e,t,n),a=getParamValue("index",e,t,n);return[n.getTensorArray(r.id).read(a)]}case"TensorArrayGatherV3":{const r=getParamValue("tensorArrayId",e,t,n),a=getParamValue("indices",e,t,n),s=getParamValue("dtype",e,t,n);return[n.getTensorArray(r.id).gather(a,s)]}case"TensorArrayScatterV3":{const r=getParamValue("tensorArrayId",e,t,n),a=getParamValue("indices",e,t,n),s=getParamValue("tensor",e,t,n),o=n.getTensorArray(r.id);return o.scatter(a,s),[o.idTensor]}case"TensorArrayConcatV3":{const r=getParamValue("tensorArrayId",e,t,n),a=n.getTensorArray(r.id),s=getParamValue("dtype",e,t,n);return[a.concat(s)]}case"TensorArraySplitV3":{const r=getParamValue("tensorArrayId",e,t,n),a=getParamValue("tensor",e,t,n),s=getParamValue("lengths",e,t,n),o=n.getTensorArray(r.id);return o.split(s,a),[o.idTensor]}case"TensorArraySizeV3":{const r=getParamValue("tensorArrayId",e,t,n);return[scalar(n.getTensorArray(r.id).size(),"int32")]}case"TensorArrayCloseV3":{const r=getParamValue("tensorArrayId",e,t,n),a=n.getTensorArray(r.id);return a.clearAndClose(),[a.idTensor]}case"TensorListSetItem":{const r=getParamValue("tensorListId",e,t,n),a=getParamValue("index",e,t,n),s=getParamValue("tensor",e,t,n),o=n.getTensorList(r.id);return o.setItem(a,s),[o.idTensor]}case"TensorListGetItem":{const r=getParamValue("tensorListId",e,t,n),a=getParamValue("index",e,t,n),s=getParamValue("elementShape",e,t,n),o=getParamValue("elementDType",e,t,n);return[n.getTensorList(r.id).getItem(a,s,o)]}case"TensorListScatterV2":case"TensorListScatter":{const r=getParamValue("indices",e,t,n),a=scatter(getParamValue("tensor",e,t,n),r,getParamValue("elementShape",e,t,n),getParamValue("numElements",e,t,n));return n.addTensorList(a),[a.idTensor]}case"TensorListReserve":case"EmptyTensorList":{const r=getParamValue("elementShape",e,t,n),a=getParamValue("elementDType",e,t,n);let s;s="TensorListReserve"===e.op?"numElements":"maxNumElements";const o=reserve(r,a,getParamValue(s,e,t,n));return n.addTensorList(o),[o.idTensor]}case"TensorListGather":{const r=getParamValue("tensorListId",e,t,n),a=getParamValue("indices",e,t,n),s=getParamValue("elementShape",e,t,n),o=getParamValue("elementDType",e,t,n);return[n.getTensorList(r.id).gather(a,o,s)]}case"TensorListStack":{const r=getParamValue("tensorListId",e,t,n),a=getParamValue("elementShape",e,t,n),s=getParamValue("elementDType",e,t,n),o=getParamValue("numElements",e,t,n);return[n.getTensorList(r.id).stack(a,s,o)]}case"TensorListFromTensor":{const r=fromTensor(getParamValue("tensor",e,t,n),getParamValue("elementShape",e,t,n),getParamValue("elementDType",e,t,n));return n.addTensorList(r),[r.idTensor]}case"TensorListConcat":{const r=getParamValue("tensorListId",e,t,n),a=n.getTensorList(r.id),s=getParamValue("dtype",e,t,n),o=getParamValue("elementShape",e,t,n);return[a.concat(s,o)]}case"TensorListPushBack":{const r=getParamValue("tensorListId",e,t,n),a=getParamValue("tensor",e,t,n),s=n.getTensorList(r.id);return s.pushBack(a),[s.idTensor]}case"TensorListPopBack":{const r=getParamValue("tensorListId",e,t,n),a=getParamValue("elementShape",e,t,n),s=getParamValue("elementDType",e,t,n);return[n.getTensorList(r.id).popBack(a,s)]}case"TensorListSplit":{const r=getParamValue("tensor",e,t,n),a=getParamValue("elementShape",e,t,n),s=split$1(r,getParamValue("lengths",e,t,n),a);return n.addTensorList(s),[s.idTensor]}default:throw TypeError(`Node type ${e.op} is not implemented`)}};function fusedConvAndDepthWiseParams(e,t,n){const[r,a]=getParamValue("fusedOps",e,t,n),s="biasadd"===r,o=!s,i="prelu"===a,l="fusedbatchnorm"===r,u=getParamValue("numArgs",e,t,n);if(s){if(i&&2!==u)throw new Error("FusedConv2d and DepthwiseConv2d with BiasAdd and Prelu must have two extra arguments: bias and alpha.");if(!i&&s&&1!==u)throw new Error("FusedConv2d and DepthwiseConv2d with BiasAdd must have one extra argument: bias.")}if(l)throw new Error("FusedConv2d and DepthwiseConv2d with FusedBatchNorm is not supported");const c=getParamValue("strides",e,t,n),p=getPadding(e,t,n),d=getParamValue("dataFormat",e,t,n).toUpperCase(),h=getParamValue("dilations",e,t,n);let[m,f]=getParamValue("args",e,t,n);return o&&(f=m,m=void 0),{stride:c,pad:p,dataFormat:d,dilations:h,biasArg:m,preluArg:f,activationFunc:a,leakyreluAlpha:getParamValue("leakyreluAlpha",e,t,n)}}const executeOp$g=(e,t,n)=>{switch(e.op){case"Conv1D":{const r=getParamValue("stride",e,t,n),a=getParamValue("pad",e,t,n),s=getParamValue("dataFormat",e,t,n).toUpperCase(),o=getParamValue("dilation",e,t,n);return[conv1d$1(getParamValue("x",e,t,n),getParamValue("filter",e,t,n),r,a,s,o)]}case"Conv2D":{const r=getParamValue("strides",e,t,n),a=getPadding(e,t,n),s=getParamValue("dataFormat",e,t,n).toUpperCase(),o=getParamValue("dilations",e,t,n);return[conv2d$3(getParamValue("x",e,t,n),getParamValue("filter",e,t,n),[r[1],r[2]],a,s,[o[1],o[2]])]}case"_FusedConv2D":{const{stride:r,pad:a,dataFormat:s,dilations:o,biasArg:i,preluArg:l,activationFunc:u,leakyreluAlpha:c}=fusedConvAndDepthWiseParams(e,t,n);return[conv2d$2({x:getParamValue("x",e,t,n),filter:getParamValue("filter",e,t,n),strides:[r[1],r[2]],pad:a,dataFormat:s,dilations:[o[1],o[2]],bias:i,activation:u,preluActivationWeights:l,leakyreluAlpha:c})]}case"FusedDepthwiseConv2dNative":{const{stride:r,pad:a,dataFormat:s,dilations:o,biasArg:i,preluArg:l,activationFunc:u,leakyreluAlpha:c}=fusedConvAndDepthWiseParams(e,t,n);return[depthwiseConv2d$2({x:getParamValue("x",e,t,n),filter:getParamValue("filter",e,t,n),strides:[r[1],r[2]],pad:a,dataFormat:s,dilations:[o[1],o[2]],bias:i,activation:u,preluActivationWeights:l,leakyreluAlpha:c})]}case"Conv2DBackpropInput":case"Conv2dTranspose":{const r=getParamValue("outputShape",e,t,n),a=getParamValue("strides",e,t,n),s=getPadding(e,t,n);return[conv2dTranspose$1(getParamValue("x",e,t,n),getParamValue("filter",e,t,n),r,[a[1],a[2]],s)]}case"DepthwiseConv2dNative":case"DepthwiseConv2d":{const r=getParamValue("strides",e,t,n),a=getPadding(e,t,n),s=getParamValue("dilations",e,t,n),o=getParamValue("dataFormat",e,t,n).toUpperCase();return[depthwiseConv2d$3(getParamValue("input",e,t,n),getParamValue("filter",e,t,n),[r[1],r[2]],a,o,[s[1],s[2]])]}case"Conv3D":{const r=getParamValue("strides",e,t,n),a=getParamValue("pad",e,t,n),s=getParamValue("dataFormat",e,t,n).toUpperCase(),o=getParamValue("dilations",e,t,n);return[conv3d$1(getParamValue("x",e,t,n),getParamValue("filter",e,t,n),[r[1],r[2],r[3]],a,s,[o[1],o[2],o[3]])]}case"AvgPool":{const r=getParamValue("strides",e,t,n),a=getParamValue("pad",e,t,n),s=getParamValue("kernelSize",e,t,n);return[avgPool$2(getParamValue("x",e,t,n),[s[1],s[2]],[r[1],r[2]],a)]}case"MaxPool":{const r=getParamValue("strides",e,t,n),a=getParamValue("pad",e,t,n),s=getParamValue("kernelSize",e,t,n);return[maxPool$2(getParamValue("x",e,t,n),[s[1],s[2]],[r[1],r[2]],a)]}case"MaxPoolWithArgmax":{const r=getParamValue("strides",e,t,n),a=getParamValue("pad",e,t,n),s=getParamValue("kernelSize",e,t,n),o=getParamValue("includeBatchInIndex",e,t,n),{result:i,indexes:l}=maxPoolWithArgmax(getParamValue("x",e,t,n),[s[1],s[2]],[r[1],r[2]],a,o);return[i,l]}case"AvgPool3D":{const r=getParamValue("strides",e,t,n),a=getParamValue("pad",e,t,n),s=getParamValue("kernelSize",e,t,n);return[avgPool3d$1(getParamValue("x",e,t,n),[s[1],s[2],s[3]],[r[1],r[2],r[3]],a)]}case"MaxPool3D":{const r=getParamValue("strides",e,t,n),a=getParamValue("pad",e,t,n),s=getParamValue("kernelSize",e,t,n);return[maxPool3d$1(getParamValue("x",e,t,n),[s[1],s[2],s[3]],[r[1],r[2],r[3]],a)]}case"Dilation2D":{const r=getParamValue("strides",e,t,n),a=getParamValue("pad",e,t,n),s=getParamValue("dilations",e,t,n),o=r[1],i=r[2],l=s[1],u=s[2];return[dilation2d(getParamValue("x",e,t,n),getParamValue("filter",e,t,n),[o,i],a,[l,u],"NHWC")]}default:throw TypeError(`Node type ${e.op} is not implemented`)}},executeOp$f=(e,t,n)=>{switch(e.op){case"Fill":{const r=getParamValue("shape",e,t,n),a=getParamValue("dtype",e,t,n);return[fill$2(r,getParamValue("value",e,t,n),a)]}case"LinSpace":return[linspace(getParamValue("start",e,t,n),getParamValue("stop",e,t,n),getParamValue("num",e,t,n))];case"Multinomial":{const r=getParamValue("logits",e,t,n),a=getParamValue("numSamples",e,t,n),s=getParamValue("seed",e,t,n);return[multinomial$2(r,a,s)]}case"OneHot":{const r=getParamValue("indices",e,t,n),a=getParamValue("depth",e,t,n),s=getParamValue("onValue",e,t,n),o=getParamValue("offValue",e,t,n);return[oneHot$2(r,a,s,o)]}case"Ones":return[ones$1(getParamValue("shape",e,t,n),getParamValue("dtype",e,t,n))];case"OnesLike":return[onesLike$2(getParamValue("x",e,t,n))];case"RandomUniform":return[randomUniform$1(getParamValue("shape",e,t,n),getParamValue("minval",e,t,n),getParamValue("maxval",e,t,n),getParamValue("dtype",e,t,n))];case"Range":return[range$4(getParamValue("start",e,t,n),getParamValue("stop",e,t,n),getParamValue("step",e,t,n),getParamValue("dtype",e,t,n))];case"TruncatedNormal":{const r=getParamValue("shape",e,t,n),a=getParamValue("mean",e,t,n),s=getParamValue("stdDev",e,t,n),o=getParamValue("seed",e,t,n);return[truncatedNormal$1(r,a,s,getParamValue("dtype",e,t,n),o)]}case"Zeros":return[zeros$2(getParamValue("shape",e,t,n),getParamValue("dtype",e,t,n))];case"ZerosLike":return[zerosLike$2(getParamValue("x",e,t,n))];default:throw TypeError(`Node type ${e.op} is not implemented`)}};function nmsParams(e,t,n){return{boxes:getParamValue("boxes",e,t,n),scores:getParamValue("scores",e,t,n),maxOutputSize:getParamValue("maxOutputSize",e,t,n),iouThreshold:getParamValue("iouThreshold",e,t,n),scoreThreshold:getParamValue("scoreThreshold",e,t,n),softNmsSigma:getParamValue("softNmsSigma",e,t,n)}}const executeOp$e=async(e,t,n)=>{switch(e.op){case"NonMaxSuppressionV5":{const{boxes:r,scores:a,maxOutputSize:s,iouThreshold:o,scoreThreshold:i,softNmsSigma:l}=nmsParams(e,t,n),u=await image$1.nonMaxSuppressionWithScoreAsync(r,a,s,o,i,l);return[u.selectedIndices,u.selectedScores]}case"NonMaxSuppressionV4":{const{boxes:r,scores:a,maxOutputSize:s,iouThreshold:o,scoreThreshold:i}=nmsParams(e,t,n),l=getParamValue("padToMaxOutputSize",e,t,n),u=await image$1.nonMaxSuppressionPaddedAsync(r,a,s,o,i,l);return[u.selectedIndices,u.validOutputs]}case"NonMaxSuppressionV3":case"NonMaxSuppressionV2":{const{boxes:r,scores:a,maxOutputSize:s,iouThreshold:o,scoreThreshold:i}=nmsParams(e,t,n);return[await image$1.nonMaxSuppressionAsync(r,a,s,o,i)]}case"Where":{const r=cast$3(getParamValue("condition",e,t,n),"bool"),a=[await whereAsync(r)];return r.dispose(),a}case"ListDiff":return setdiff1dAsync(getParamValue("x",e,t,n),getParamValue("y",e,t,n));default:throw TypeError(`Node type ${e.op} is not implemented`)}},executeOp$d=(e,t,n)=>{switch(e.op){case"TopKV2":{const r=getParamValue("x",e,t,n),a=getParamValue("k",e,t,n),s=getParamValue("sorted",e,t,n),o=topk(r,a,s);return[o.values,o.indices]}case"Unique":{const r=getParamValue("x",e,t,n),a=unique$3(r);return[a.values,a.indices]}case"UniqueV2":{const r=getParamValue("x",e,t,n),a=getParamValue("axis",e,t,n),s=unique$3(r,a);return[s.values,s.indices]}default:throw TypeError(`Node type ${e.op} is not implemented`)}},executeOp$c=(e,t,n)=>{switch(e.op){case"Const":return t[e.name];case"PlaceholderWithDefault":const r=getParamValue("default",e,t,n);return[getTensor(e.name,t,n)||r];case"Placeholder":return[getTensor(e.name,t,n)];case"Identity":case"StopGradient":case"FakeQuantWithMinMaxVars":return[cloneTensor(getParamValue("x",e,t,n))];case"IdentityN":return getParamValue("x",e,t,n).map(e=>cloneTensor(e));case"Snapshot":return[cloneTensor(getParamValue("x",e,t,n))];case"Shape":return[tensor1d(getParamValue("x",e,t,n).shape,"int32")];case"ShapeN":return getParamValue("x",e,t,n).map(e=>tensor1d(e.shape));case"Size":return[scalar(getParamValue("x",e,t,n).size,"int32")];case"Rank":return[scalar(getParamValue("x",e,t,n).rank,"int32")];case"NoOp":return[scalar(1)];case"Print":const a=getParamValue("x",e,t,n),s=getParamValue("data",e,t,n),o=getParamValue("message",e,t,n),i=getParamValue("summarize",e,t,n);console.warn("The graph has a tf.print() operation,usually used for debugging, which slows down performance."),console.log(o);for(let e=0;e<s.length;e++)console.log(Array.prototype.slice.call(s[e].dataSync()).slice(0,i));return[a];default:throw TypeError(`Node type ${e.op} is not implemented`)}};class HashTable{constructor(e,t){this.keyDType=e,this.valueDType=t,this.handle=scalar(0),this.tensorMap=new Map,keep(this.handle)}get id(){return this.handle.id}clearAndClose(){this.tensorMap.forEach(e=>e.dispose()),this.tensorMap.clear(),this.handle.dispose()}size(){return this.tensorMap.size}tensorSize(){return scalar(this.size(),"int32")}async import(e,t){this.checkKeyAndValueTensor(e,t);const n=await e.data();return this.tensorMap.forEach(e=>e.dispose()),this.tensorMap.clear(),tidy(()=>{const e=unstack(t),r=n.length,a=e.length;assert$4(r===a,()=>`The number of elements doesn't match, keys has ${r} elements, the values has ${a} elements.`);for(let t=0;t<r;t++){const r=n[t],a=e[t];keep(a),this.tensorMap.set(r,a)}return this.handle})}async find(e,t){this.checkKeyAndValueTensor(e,t);const n=await e.data();return tidy(()=>{const e=[];for(let r=0;r<n.length;r++){const a=this.findWithDefault(n[r],t);e.push(a)}return stack(e)})}findWithDefault(e,t){const n=this.tensorMap.get(e);return null!=n?n:t}checkKeyAndValueTensor(e,t){if(e.dtype!==this.keyDType)throw new Error(`Expect key dtype ${this.keyDType}, but got ${e.dtype}`);if(t.dtype!==this.valueDType)throw new Error(`Expect value dtype ${this.valueDType}, but got ${t.dtype}`)}}const executeOp$b=async(e,t,n,r)=>{switch(e.op){case"HashTable":case"HashTableV2":{const a=getParamValue("keyDType",e,t,n),s=getParamValue("valueDType",e,t,n),o=new HashTable(a,s);return r.addHashTable(e.name,o),[o.handle]}case"LookupTableImport":case"LookupTableImportV2":{const a=getParamValue("tableHandle",e,t,n,r),s=getParamValue("keys",e,t,n),o=getParamValue("values",e,t,n),i=r.getHashTableById(a.id);return[await i.import(s,o)]}case"LookupTableFind":case"LookupTableFindV2":{const a=getParamValue("tableHandle",e,t,n,r),s=getParamValue("keys",e,t,n),o=getParamValue("defaultValue",e,t,n),i=r.getHashTableById(a.id);return[await i.find(s,o)]}case"LookupTableSize":case"LookupTableSizeV2":{const a=getParamValue("tableHandle",e,t,n,r);return[r.getHashTableById(a.id).tensorSize()]}default:throw TypeError(`Node type ${e.op} is not implemented`)}},executeOp$a=(e,t,n)=>{switch(e.op){case"ResizeBilinear":{const r=getParamValue("images",e,t,n),a=getParamValue("size",e,t,n),s=getParamValue("alignCorners",e,t,n),o=getParamValue("halfPixelCenters",e,t,n);return[image$1.resizeBilinear(r,[a[0],a[1]],s,o)]}case"ResizeNearestNeighbor":{const r=getParamValue("images",e,t,n),a=getParamValue("size",e,t,n),s=getParamValue("alignCorners",e,t,n),o=getParamValue("halfPixelCenters",e,t,n);return[image$1.resizeNearestNeighbor(r,[a[0],a[1]],s,o)]}case"CropAndResize":{const r=getParamValue("image",e,t,n),a=getParamValue("boxes",e,t,n),s=getParamValue("boxInd",e,t,n),o=getParamValue("cropSize",e,t,n),i=getParamValue("method",e,t,n),l=getParamValue("extrapolationValue",e,t,n);return[image$1.cropAndResize(r,a,s,o,i,l)]}default:throw TypeError(`Node type ${e.op} is not implemented`)}},executeOp$9=(e,t,n)=>{switch(e.op){case"Equal":return[equal$2(getParamValue("a",e,t,n),getParamValue("b",e,t,n))];case"NotEqual":return[notEqual$2(getParamValue("a",e,t,n),getParamValue("b",e,t,n))];case"Greater":return[greater$3(getParamValue("a",e,t,n),getParamValue("b",e,t,n))];case"GreaterEqual":return[greaterEqual$2(getParamValue("a",e,t,n),getParamValue("b",e,t,n))];case"Less":return[less$3(getParamValue("a",e,t,n),getParamValue("b",e,t,n))];case"LessEqual":return[lessEqual$2(getParamValue("a",e,t,n),getParamValue("b",e,t,n))];case"LogicalAnd":return[logicalAnd$2(getParamValue("a",e,t,n),getParamValue("b",e,t,n))];case"LogicalNot":return[logicalNot$2(getParamValue("a",e,t,n))];case"LogicalOr":return[logicalOr$2(getParamValue("a",e,t,n),getParamValue("b",e,t,n))];case"Select":case"SelectV2":return[where(getParamValue("condition",e,t,n),getParamValue("a",e,t,n),getParamValue("b",e,t,n))];default:throw TypeError(`Node type ${e.op} is not implemented`)}},executeOp$8=(e,t,n)=>{switch(e.op){case"BatchMatMul":case"BatchMatMulV2":case"MatMul":return[matMul$1(getParamValue("a",e,t,n),getParamValue("b",e,t,n),getParamValue("transposeA",e,t,n),getParamValue("transposeB",e,t,n))];case"Einsum":return[einsum$2(getParamValue("equation",e,t,n),...getParamValue("tensors",e,t,n))];case"Transpose":return[transpose$2(getParamValue("x",e,t,n),getParamValue("perm",e,t,n))];case"_FusedMatMul":const[r,a]=getParamValue("fusedOps",e,t,n),s="biasadd"===r,o="prelu"===a,i=getParamValue("numArgs",e,t,n),l=getParamValue("leakyreluAlpha",e,t,n);if(s){if(o&&2!==i)throw new Error("Fused MatMul with BiasAdd and Prelu must have two extra arguments: bias and alpha.");if(!o&&1!==i)throw new Error("Fused MatMul with BiasAdd must have one extra argument: bias.")}const[u,c]=getParamValue("args",e,t,n);return[matMul({a:getParamValue("a",e,t,n),b:getParamValue("b",e,t,n),transposeA:getParamValue("transposeA",e,t,n),transposeB:getParamValue("transposeB",e,t,n),bias:u,activation:a,preluActivationWeights:c,leakyreluAlpha:l})];default:throw TypeError(`Node type ${e.op} is not implemented`)}},executeOp$7=(e,t,n)=>{switch(e.op){case"FusedBatchNorm":case"FusedBatchNormV2":case"FusedBatchNormV3":return[batchNorm$2(getParamValue("x",e,t,n),getParamValue("mean",e,t,n),getParamValue("variance",e,t,n),getParamValue("offset",e,t,n),getParamValue("scale",e,t,n),getParamValue("epsilon",e,t,n))];case"LRN":return[localResponseNormalization(getParamValue("x",e,t,n),getParamValue("radius",e,t,n),getParamValue("bias",e,t,n),getParamValue("alpha",e,t,n),getParamValue("beta",e,t,n))];case"Softmax":return[softmax$3(getParamValue("x",e,t,n))];case"LogSoftmax":return[logSoftmax(getParamValue("x",e,t,n))];case"SparseToDense":return[sparseToDense$2(getParamValue("sparseIndices",e,t,n),getParamValue("outputShape",e,t,n),getParamValue("sparseValues",e,t,n),getParamValue("defaultValue",e,t,n))];default:throw TypeError(`Node type ${e.op} is not implemented`)}},executeOp$6=(e,t,n)=>{switch(e.op){case"Max":{const r=getParamValue("axis",e,t,n),a=getParamValue("keepDims",e,t,n);return[max$3(getParamValue("x",e,t,n),r,a)]}case"Mean":{const r=getParamValue("axis",e,t,n),a=getParamValue("keepDims",e,t,n);return[mean$1(getParamValue("x",e,t,n),r,a)]}case"Min":{const r=getParamValue("axis",e,t,n),a=getParamValue("keepDims",e,t,n);return[min$3(getParamValue("x",e,t,n),r,a)]}case"Sum":{const r=getParamValue("axis",e,t,n),a=getParamValue("keepDims",e,t,n);return[sum$2(getParamValue("x",e,t,n),r,a)]}case"All":{const r=getParamValue("axis",e,t,n),a=getParamValue("keepDims",e,t,n);return[all$2(getParamValue("x",e,t,n),r,a)]}case"Any":{const r=getParamValue("axis",e,t,n),a=getParamValue("keepDims",e,t,n);return[any$2(getParamValue("x",e,t,n),r,a)]}case"ArgMax":{const r=getParamValue("axis",e,t,n);return[argMax$2(getParamValue("x",e,t,n),r)]}case"ArgMin":{const r=getParamValue("axis",e,t,n);return[argMin$2(getParamValue("x",e,t,n),r)]}case"Prod":{const r=getParamValue("axis",e,t,n),a=getParamValue("keepDims",e,t,n);return[prod$2(getParamValue("x",e,t,n),r,a)]}case"Cumsum":{const r=getParamValue("axis",e,t,n),a=getParamValue("exclusive",e,t,n),s=getParamValue("reverse",e,t,n);return[cumsum$2(getParamValue("x",e,t,n),r,a,s)]}case"Bincount":const r=getParamValue("x",e,t,n),a=getParamValue("weights",e,t,n),s=getParamValue("size",e,t,n);return[bincount$2(r,a,s)];case"DenseBincount":{const r=getParamValue("x",e,t,n),a=getParamValue("weights",e,t,n),s=getParamValue("size",e,t,n),o=getParamValue("binaryOutput",e,t,n);return[denseBincount$2(r,a,s,o)]}default:throw TypeError(`Node type ${e.op} is not implemented`)}},executeOp$5=(e,t,n)=>{switch(e.op){case"ConcatV2":case"Concat":{const r=getParamValue("n",e,t,n),a=getParamValue("axis",e,t,n);let s=getParamValue("tensors",e,t,n);return s=s.slice(0,r),[concat$2(s,a)]}case"Gather":{const r=getParamValue("x",e,t,n),a=getParamValue("indices",e,t,n);return[gather$1(r,cast$3(a,"int32"),0)]}case"GatherV2":{const r=getParamValue("axis",e,t,n),a=getParamValue("batchDims",e,t,n),s=getParamValue("x",e,t,n),o=getParamValue("indices",e,t,n);return[gather$1(s,cast$3(o,"int32"),r,a)]}case"Reverse":{const r=getParamValue("dims",e,t,n),a=[];for(let e=0;e<r.length;e++)r[e]&&a.push(e);const s=getParamValue("x",e,t,n);return[reverse$2(s,a)]}case"ReverseV2":{const r=getParamValue("axis",e,t,n),a=getParamValue("x",e,t,n);return[reverse$2(a,r)]}case"Slice":{const r=getParamValue("begin",e,t,n),a=getParamValue("size",e,t,n);return[slice$2(getParamValue("x",e,t,n),r,a)]}case"StridedSlice":{const r=getParamValue("begin",e,t,n),a=getParamValue("end",e,t,n),s=getParamValue("strides",e,t,n),o=getParamValue("beginMask",e,t,n),i=getParamValue("endMask",e,t,n),l=getParamValue("ellipsisMask",e,t,n),u=getParamValue("newAxisMask",e,t,n),c=getParamValue("shrinkAxisMask",e,t,n),p=getParamValue("x",e,t,n);return[stridedSlice$2(p,r,a,s,o,i,l,u,c)]}case"Pack":return tidy(()=>{const r=getParamValue("axis",e,t,n),a=getParamValue("tensors",e,t,n),s=a[0].shape,o=squeeze(a[0]).shape,i=a.map(e=>{const t=arraysEqual(e.shape,s);if(!t&&!arraysEqual(squeeze(e).shape,o))throw new Error("the input tensors shape does not match");return t?e:reshape$3(e,s)});return[stack(i,r)]});case"Unpack":{const r=getParamValue("axis",e,t,n),a=getParamValue("tensor",e,t,n);return unstack(a,r)}case"Tile":{const r=getParamValue("reps",e,t,n);return[tile$3(getParamValue("x",e,t,n),r)]}case"Split":case"SplitV":{const r=getParamValue("axis",e,t,n),a=getParamValue("numOrSizeSplits",e,t,n),s=getParamValue("x",e,t,n);return split$2(s,a,r)}case"ScatterNd":{const r=getParamValue("indices",e,t,n),a=getParamValue("values",e,t,n),s=getParamValue("shape",e,t,n);return[scatterND(r,a,s)]}case"GatherNd":{const r=getParamValue("x",e,t,n),a=getParamValue("indices",e,t,n);return[gatherND(r,a)]}case"SparseToDense":{const r=getParamValue("sparseIndices",e,t,n),a=getParamValue("outputShape",e,t,n),s=getParamValue("sparseValues",e,t,n),o=getParamValue("defaultValue",e,t,n);return[sparseToDense$2(r,s,a,s.dtype===o.dtype?o:cast$3(o,s.dtype))]}default:throw TypeError(`Node type ${e.op} is not implemented`)}},executeOp$4=(e,t,n)=>{switch(e.op){case"SparseFillEmptyRows":{const{outputIndices:r,outputValues:a,emptyRowIndicator:s,reverseIndexMap:o}=sparse$1.sparseFillEmptyRows(getParamValue("indices",e,t,n),getParamValue("values",e,t,n),getParamValue("denseShape",e,t,n),getParamValue("defaultValue",e,t,n));return[r,a,s,o]}case"SparseReshape":{const{outputIndices:r,outputShape:a}=sparse$1.sparseReshape(getParamValue("inputIndices",e,t,n),getParamValue("inputShape",e,t,n),getParamValue("newShape",e,t,n));return[r,a]}case"SparseSegmentMean":return[sparse$1.sparseSegmentMean(getParamValue("data",e,t,n),getParamValue("indices",e,t,n),getParamValue("segmentIds",e,t,n))];case"SparseSegmentSum":return[sparse$1.sparseSegmentSum(getParamValue("data",e,t,n),getParamValue("indices",e,t,n),getParamValue("segmentIds",e,t,n))];default:throw TypeError(`Node type ${e.op} is not implemented`)}},executeOp$3=(e,t,n)=>{switch(e.op){case"FFT":return[fft$2(getParamValue("x",e,t,n))];case"IFFT":return[ifft$2(getParamValue("x",e,t,n))];case"RFFT":return[rfft(getParamValue("x",e,t,n))];case"IRFFT":return[irfft(getParamValue("x",e,t,n))];default:throw TypeError(`Node type ${e.op} is not implemented`)}},executeOp$2=(e,t,n)=>{switch(e.op){case"StringNGrams":{const{nGrams:r,nGramsSplits:a}=string$1.stringNGrams(getParamValue("data",e,t,n),getParamValue("dataSplits",e,t,n),getParamValue("separator",e,t,n),getParamValue("nGramWidths",e,t,n),getParamValue("leftPad",e,t,n),getParamValue("rightPad",e,t,n),getParamValue("padWidth",e,t,n),getParamValue("preserveShortSequences",e,t,n));return[r,a]}case"StringSplit":{const{indices:r,values:a,shape:s}=string$1.stringSplit(getParamValue("input",e,t,n),getParamValue("delimiter",e,t,n),getParamValue("skipEmpty",e,t,n));return[r,a,s]}case"StringToHashBucketFast":return[string$1.stringToHashBucketFast(getParamValue("input",e,t,n),getParamValue("numBuckets",e,t,n))];default:throw TypeError(`Node type ${e.op} is not implemented`)}},executeOp$1=(e,t,n)=>{switch(e.op){case"Cast":return[cast$3(getParamValue("x",e,t,n),getParamValue("dtype",e,t,n))];case"ExpandDims":{const r=getParamValue("axis",e,t,n);return[expandDims$3(getParamValue("x",e,t,n),r)]}case"Squeeze":{const r=getParamValue("axis",e,t,n);return[squeeze(getParamValue("x",e,t,n),r)]}case"Reshape":return[reshape$3(getParamValue("x",e,t,n),getParamValue("shape",e,t,n))];case"MirrorPad":return[mirrorPad$1(getParamValue("x",e,t,n),getParamValue("padding",e,t,n),getParamValue("mode",e,t,n))];case"PadV2":case"Pad":return[pad(getParamValue("x",e,t,n),getParamValue("padding",e,t,n),getParamValue("constantValue",e,t,n))];case"SpaceToBatchND":{const r=getParamValue("blockShape",e,t,n),a=getParamValue("paddings",e,t,n);return[spaceToBatchND$2(getParamValue("x",e,t,n),r,a)]}case"BatchToSpaceND":{const r=getParamValue("blockShape",e,t,n),a=getParamValue("crops",e,t,n);return[batchToSpaceND$2(getParamValue("x",e,t,n),r,a)]}case"DepthToSpace":{const r=getParamValue("blockSize",e,t,n),a=getParamValue("dataFormat",e,t,n).toUpperCase();return[depthToSpace$2(getParamValue("x",e,t,n),r,a)]}case"BroadcastTo":return[broadcastTo(getParamValue("x",e,t,n),getParamValue("shape",e,t,n))];default:throw TypeError(`Node type ${e.op} is not implemented`)}};function executeOp(e,t,n,r){const a=((e,t,n)=>{switch(e.category){case"arithmetic":return tidy(()=>executeOp$j(e,t,n));case"basic_math":return tidy(()=>executeOp$i(e,t,n));case"control":return executeOp$h(e,t,n);case"convolution":return tidy(()=>executeOp$g(e,t,n));case"creation":return tidy(()=>executeOp$f(e,t,n));case"dynamic":return executeOp$e(e,t,n);case"evaluation":return tidy(()=>executeOp$d(e,t,n));case"image":return tidy(()=>executeOp$a(e,t,n));case"graph":return tidy(()=>executeOp$c(e,t,n));case"logical":return tidy(()=>executeOp$9(e,t,n));case"matrices":return tidy(()=>executeOp$8(e,t,n));case"normalization":return tidy(()=>executeOp$7(e,t,n));case"reduction":return tidy(()=>executeOp$6(e,t,n));case"slice_join":return tidy(()=>executeOp$5(e,t,n));case"sparse":return tidy(()=>executeOp$4(e,t,n));case"spectral":return tidy(()=>executeOp$3(e,t,n));case"string":return tidy(()=>executeOp$2(e,t,n));case"transformation":return tidy(()=>executeOp$1(e,t,n));case"hash_table":return executeOp$b(e,t,n,r);case"custom":const a=getRegisteredOp(e.op);if(a&&a.customExecutor)return a.customExecutor(new NodeValueImpl(e,t,n));throw TypeError(`Custom op ${e.op} is not registered.`);default:throw TypeError(`Unknown op '${e.op}'. File an issue at https://github.com/tensorflow/tfjs/issues so we can add it, or register a custom execution with tf.registerOp()`)}})(e,t,n);return isPromise(a)?a.then(e=>[].concat(e)):[].concat(a)}class ExecutionContext{constructor(e={},t={},n={},r={}){this.weightMap=e,this.tensorArrayMap=t,this.tensorListMap=n,this.functionMap=r,this.rootContext={id:0,frameName:"",iterationId:0},this.contexts=[this.rootContext],this.lastId=0,this.generateCurrentContextIds()}newFrame(e,t){return{id:e,frameName:t,iterationId:0}}set currentContext(e){this.contexts!==e&&(this.contexts=e,this.generateCurrentContextIds())}get currentContext(){return this.contexts}get currentContextId(){return this._currentContextIds[0]}get currentContextIds(){return this._currentContextIds}generateCurrentContextIds(){const e=[];for(let t=0;t<this.contexts.length-1;t++){const n=this.contexts.slice(0,this.contexts.length-t);e.push(this.contextIdforContexts(n))}e.push(""),this._currentContextIds=e}contextIdforContexts(e){return e?e.map(e=>0===e.id&&0===e.iterationId?"":`${e.frameName}-${e.iterationId}`).join("/"):""}enterFrame(e){this.contexts&&(this.lastId++,this.contexts=this.contexts.slice(),this.contexts.push(this.newFrame(this.lastId,e)),this._currentContextIds.unshift(this.contextIdforContexts(this.contexts)))}exitFrame(){if(!(this.contexts&&this.contexts.length>1))throw new Error("Cannot exit frame, the context is empty");this.contexts=this.contexts.slice(),this.contexts.splice(-1),this.currentContextIds.shift()}nextIteration(){if(!(this.contexts&&this.contexts.length>0))throw new Error("Cannot increase frame iteration, the context is empty");{this.contexts=this.contexts.slice(),this.lastId++;const e=Object.assign({},this.contexts[this.contexts.length-1]);e.iterationId+=1,e.id=this.lastId,this.contexts.splice(-1,1,e),this._currentContextIds.splice(0,1,this.contextIdforContexts(this.contexts))}}getWeight(e){return this.weightMap[e]}addTensorArray(e){this.tensorArrayMap[e.id]=e}getTensorArray(e){return this.tensorArrayMap[e]}addTensorList(e){this.tensorListMap[e.id]=e}getTensorList(e){return this.tensorListMap[e]}dispose(e){for(const t in this.tensorArrayMap)this.tensorArrayMap[t].clearAndClose(e);for(const t in this.tensorListMap)this.tensorListMap[t].clearAndClose(e)}}function getExecutionSubgraph(e,t,n,r){const a=new Set,s=[];let o=null,i=null;const l=new Set,u=Object.keys(e).map(e=>parseNodeName(e)[0]);let c=[];null!=r&&(c=r.map(e=>parseNodeName(e.name)[0]));const p=[...t];for(;p.length>0;){const e=p.pop();(isControlFlow(e)||isDynamicShape(e)||isHashTable(e))&&null==o&&(o=e,i=o.children.map(e=>e.name).filter(e=>a.has(e))),a.add(e.name),null==n[e.name]&&-1===u.indexOf(e.name)&&-1===c.indexOf(e.name)&&(0!==e.inputs.length?e.inputs.forEach(e=>{l.has(e.name)||(l.add(e.name),p.push(e))}):s.push(e.name))}return{inputs:e,outputs:t,usedNodes:a,missingInputs:s,dynamicNode:o,syncInputs:i}}function getNodesInTopologicalOrder(e,t,n){const{usedNodes:r,inputs:a}=n,s=[],o=Object.keys(a).map(e=>parseNodeName(e)[0]).map(t=>e.nodes[t]),i=e.initNodes;o.forEach(e=>{r.has(e.name)&&s.push(e)}),e.weights.forEach(e=>{r.has(e.name)&&s.push(e)}),null!=i&&i.forEach(e=>{r.has(e.name)&&s.push(e)});const l=new Set,u=[];for(;s.length>0;){const e=s.pop();l.add(e.name),t[e.name]||u.push(e),e.children.forEach(e=>{!l.has(e.name)&&r.has(e.name)&&e.inputs.every(e=>l.has(e.name))&&s.push(e)})}return u}const CONTROL_FLOW_OPS=["Switch","Merge","Enter","Exit","NextIteration","StatelessIf","StatelessWhile","if","While"],DYNAMIC_SHAPE_OPS=["NonMaxSuppressionV2","NonMaxSuppressionV3","NonMaxSuppressionV5","Where"],HASH_TABLE_OPS=["HashTable","HashTableV2","LookupTableImport","LookupTableImportV2","LookupTableFind","LookupTableFindV2","LookupTableSize","LookupTableSizeV2"];function isControlFlow(e){return CONTROL_FLOW_OPS.indexOf(e.op)>=0}function isDynamicShape(e){return DYNAMIC_SHAPE_OPS.indexOf(e.op)>=0}function isHashTable(e){return HASH_TABLE_OPS.indexOf(e.op)>=0}class GraphExecutor{constructor(e,t){this.graph=e,this.parent=t,this.compiledMap=new Map,this._weightMap={},this.SEPERATOR=",",this._functions={},this._functionExecutorMap={},this._outputs=e.outputs,this._inputs=e.inputs,this._initNodes=e.initNodes,this._signature=e.signature,this._functions=e.functions,null!=e.functions&&Object.keys(e.functions).forEach(t=>{this._functionExecutorMap[t]=new GraphExecutor(e.functions[t],this)})}get weightIds(){return this.parent?this.parent.weightIds:this._weightIds}get functionExecutorMap(){return this.parent?this.parent.functionExecutorMap:this._functionExecutorMap}get weightMap(){return this.parent?this.parent.weightMap:this._weightMap}set weightMap(e){const t=Object.keys(e).map(t=>e[t].map(e=>e.id));this._weightIds=[].concat(...t),this._weightMap=e}set resourceManager(e){this._resourceManager=e}get inputs(){return this._inputs.map(e=>({name:e.name,shape:e.attrParams.shape?e.attrParams.shape.value:void 0,dtype:e.attrParams.dtype?e.attrParams.dtype.value:void 0}))}get outputs(){return this._outputs.map(e=>({name:e.name,shape:e.attrParams.shape?e.attrParams.shape.value:void 0,dtype:e.attrParams.dtype?e.attrParams.dtype.value:void 0}))}get inputNodes(){return this._inputs.map(e=>e.signatureKey||e.name)}get outputNodes(){return this._outputs.map(e=>{const t=e.signatureKey||e.name;return e.defaultOutput?`${t}:${e.defaultOutput}`:t})}get functions(){return Object.keys(this._functions).reduce((e,t)=>(e[t]=this._functions[t].signature,e),{})}getCompilationKey(e,t){const n=e.map(e=>e.name).sort(),r=t.map(e=>e.name).sort();return n.join(this.SEPERATOR)+"--"+r.join(this.SEPERATOR)}compile(e,t){const n=getExecutionSubgraph(e,t,this.weightMap,this._initNodes),{missingInputs:r,dynamicNode:a,syncInputs:s}=n;if(null!=a)throw new Error(`This execution contains the node '${a.name}', which has the dynamic op '${a.op}'. Please use model.executeAsync() instead. Alternatively, to avoid the dynamic ops, specify the inputs [${s}]`);if(r.length>0){const n=t.map(e=>e.name),a=Object.keys(e);throw new Error(`Cannot compute the outputs [${n}] from the provided inputs [${a}]. Missing the following inputs: [${r}]`)}return getNodesInTopologicalOrder(this.graph,this.weightMap,n)}execute(e,t){e=this.mapInputs(e);const n=Object.keys(e).sort();this.checkInputs(e),this.checkInputShapeAndType(e),t=this.mapOutputs(t),this.checkOutputs(t);const r=n.map(e=>this.graph.nodes[parseNodeName(e)[0]]),a=t.map(e=>parseNodeName(e)[0]);let s=a.map(e=>this.graph.nodes[e]);0===s.length&&(s=this._outputs);const o=this.getCompilationKey(r,s);let i=this.compiledMap.get(o);null==i&&(i=this.compile(e,s),this.compiledMap.set(o,i));const l={},u={};return tidy(()=>{const n=new ExecutionContext(this.weightMap,l,u,this.functionExecutorMap),r=Object.assign({},this.weightMap);Object.keys(e).forEach(t=>{const[n,a]=parseNodeName(t),s=[];s[a]=e[t],r[n]=s});const s=this.getFrozenTensorIds(r),o={};for(let e=0;e<i.length;e++){const t=i[e];if(!r[t.name]){const e=executeOp(t,r,n,this._resourceManager);if(isPromise(e))throw new Error(`The execution of the op '${t.op}' returned a promise. Please use model.executeAsync() instead.`);r[t.name]=e,this.checkTensorForDisposal(t.name,t,r,n,s,a,o)}}return null==this.parent&&n.dispose(s),t.map(e=>getTensor(e,r,n))})}getFrozenTensorIds(e){const t=[].concat.apply([],Object.keys(e).map(t=>e[t]).map(e=>e.map(e=>e.id)));return new Set(t)}checkTensorForDisposal(e,t,n,r,a,s,o){"control"!==t.category&&-1===s.indexOf(e)&&(n[e].forEach(e=>{null!=e&&(o[e.id]=(o[e.id]||0)+t.children.length)}),t.inputs.forEach(e=>{if("control"!==e.category){const t=getTensorsForCurrentContenxt(e.name,n,r);null!=t&&t.forEach(e=>{if(e&&!e.kept&&!a.has(e.id)){const t=o[e.id];1===t?(e.dispose(),delete o[e.id]):null!=t&&o[e.id]--}})}}))}async executeAsync(e,t){return this._executeAsync(e,t)}async _executeAsync(e,t,n=!1,r={},a={}){n||(e=this.mapInputs(e),this.checkInputs(e),this.checkInputShapeAndType(e),t=this.mapOutputs(t),this.checkOutputs(t));const s=new ExecutionContext(this.weightMap,r,a,this.functionExecutorMap),o=await this.executeWithControlFlow(e,s,t,n),i=t.map(e=>getTensor(e,o,s)),l=i.map(e=>e.id),u=Object.keys(e).map(t=>e[t].id),c=new Set([...l,...u,...this.weightIds]);return Object.keys(o).forEach(e=>{o[e].forEach(e=>{!e||e.kept||e.isDisposed||c.has(e.id)||e.dispose()})}),null==this.parent&&s.dispose(c),i}async executeFunctionAsync(e,t,n){const r=e.reduce((e,t,n)=>(e[this.inputs[n].name]=t,e),{});return this._executeAsync(r,this.outputNodes,!0,t,n)}async executeWithControlFlow(e,t,n,r){const a=Object.keys(e),s=a.map(e=>this.graph.nodes[parseNodeName(e)[0]]),o=n.map(e=>parseNodeName(e)[0]);let i=o.map(e=>this.graph.nodes[e]);0===i.length&&(i=this._outputs);const{usedNodes:l,missingInputs:u,dynamicNode:c,syncInputs:p}=getExecutionSubgraph(e,i,this.weightMap,this._initNodes),d=[...s,...this.graph.weights,...this._initNodes||[]].map(e=>({node:e,contexts:t.currentContext})),h=Object.assign({},this.weightMap);Object.keys(e).forEach(t=>{const[n,r]=parseNodeName(t),a=[];a[r]=e[t],h[n]=a});const m={},f=this.getFrozenTensorIds(h),g={};for(;d.length>0;){const e=this.processStack(s,d,t,h,g,f,o,m,l);await Promise.all(e)}null!=c||r||console.warn("This model execution did not contain any nodes with control flow or dynamic output shapes. You can use model.execute() instead.");const $=i.filter(e=>!isControlFlow(e)&&!getTensor(e.name,h,t)).map(e=>e.name);if($.length>0){let e="";throw null!=c&&(e=`Alternatively, to avoid the dynamic ops, use model.execute() and specify the inputs [${p}]`),new Error(`Cannot compute the outputs [${$}] from the provided inputs [${a}]. Consider providing the following inputs: [${u}]. ${e}`)}return h}processStack(e,t,n,r,a,s,o,i,l){const u=[];for(;t.length>0;){const e=t.pop();n.currentContext=e.contexts;let c="";if("Enter"===e.node.op&&getParamValue("isConstant",e.node,r,n)&&([c]=getNodeNameAndIndex(e.node.name,n)),null==r[e.node.name]){const p=executeOp(e.node,r,n,this._resourceManager);c||([c]=getNodeNameAndIndex(e.node.name,n));const d=n.currentContext;isPromise(p)?u.push(p.then(u=>(r[c]=u,n.currentContext=d,this.checkTensorForDisposal(c,e.node,r,n,s,o,i),this.processChildNodes(e.node,t,n,r,a,l),u))):(r[c]=p,this.checkTensorForDisposal(c,e.node,r,n,s,o,i),this.processChildNodes(e.node,t,n,r,a,l))}else this.processChildNodes(e.node,t,n,r,a,l)}return u}processChildNodes(e,t,n,r,a,s){e.children.forEach(e=>{const[o]=getNodeNameAndIndex(e.name,n);!a[o]&&s.has(e.name)&&("Merge"===e.op?e.inputNames.some(e=>!!getTensor(e,r,n))&&(a[o]=!0,t.push({contexts:n.currentContext,node:e})):e.inputNames.every(e=>!!getTensor(e,r,n))&&(a[o]=!0,t.push({contexts:n.currentContext,node:e})))})}dispose(){Object.keys(this.weightMap).forEach(e=>this.weightMap[e].forEach(e=>e.dispose()))}checkInputShapeAndType(e){Object.keys(e).forEach(t=>{const n=e[t],[r]=parseNodeName(t),a=this.graph.nodes[r];if(a.attrParams.shape&&a.attrParams.shape.value){const e=a.attrParams.shape.value;assert$4(e.length===n.shape.length&&n.shape.every((t,n)=>-1===e[n]||e[n]===t),()=>`The shape of dict['${a.name}'] provided in model.execute(dict) must be [${e}], but was [${n.shape}]`)}a.attrParams.dtype&&a.attrParams.dtype.value&&assert$4(n.dtype===a.attrParams.dtype.value,()=>`The dtype of dict['${a.name}'] provided in model.execute(dict) must be ${a.attrParams.dtype.value}, but was ${n.dtype}`)})}mapInputs(e){const t={};for(const n in e)null!=this._signature&&null!=this._signature.inputs&&null!=this._signature.inputs[n]?t[this._signature.inputs[n].name]=e[n]:t[n]=e[n];return t}checkInputs(e){const t=Object.keys(e).filter(e=>{const[t]=parseNodeName(e);return null==this.graph.nodes[t]});if(t.length>0)throw new Error(`The dict provided in model.execute(dict) has keys: [${t}] that are not part of graph`)}mapOutputs(e){return e.map(e=>null!=this._signature&&null!=this._signature.outputs&&null!=this._signature.outputs[e]?this._signature.outputs[e].name:e,{})}checkOutputs(e){e.forEach(e=>{const[t]=parseNodeName(e);if(!this.graph.nodes[t])throw new Error(`The output '${e}' is not found in the graph`)})}}class ResourceManager{constructor(e={},t={}){this.hashTableNameToHandle=e,this.hashTableMap=t}addHashTable(e,t){this.hashTableNameToHandle[e]=t.handle,this.hashTableMap[t.id]=t}getHashTableHandleByName(e){return this.hashTableNameToHandle[e]}getHashTableById(e){return this.hashTableMap[e]}dispose(){for(const e in this.hashTableMap)this.hashTableMap[e].clearAndClose(),delete this.hashTableMap[e];for(const e in this.hashTableNameToHandle)this.hashTableNameToHandle[e].dispose(),delete this.hashTableNameToHandle[e]}}const TFHUB_SEARCH_PARAM="?tfjs-format=file",DEFAULT_MODEL_NAME="model.json";class GraphModel{constructor(e,t={}){this.modelUrl=e,this.loadOptions=t,this.version="n/a",null==t&&(this.loadOptions={}),this.resourceManager=new ResourceManager}get modelVersion(){return this.version}get inputNodes(){return this.executor.inputNodes}get outputNodes(){return this.executor.outputNodes}get inputs(){return this.executor.inputs}get outputs(){return this.executor.outputs}get weights(){return this.executor.weightMap}get metadata(){return this.artifacts.userDefinedMetadata}get modelSignature(){return this.signature}findIOHandler(){const e=this.modelUrl;if(null!=e.load)this.handler=e;else if(null!=this.loadOptions.requestInit)this.handler=browserHTTPRequest(e,this.loadOptions);else{const t=getLoadHandlers(e,this.loadOptions);if(0===t.length)t.push(browserHTTPRequest(e,this.loadOptions));else if(t.length>1)throw new Error(`Found more than one (${t.length}) load handlers for URL '${[e]}'`);this.handler=t[0]}}async load(){if(this.findIOHandler(),null==this.handler.load)throw new Error("Cannot proceed with model loading because the IOHandler provided does not have the `load` method implemented.");const e=await this.handler.load();return this.loadSync(e)}loadSync(e){this.artifacts=e;const t=this.artifacts.modelTopology;let n;n=null!=this.artifacts.userDefinedMetadata&&null!=this.artifacts.userDefinedMetadata.signature?this.artifacts.userDefinedMetadata.signature:this.artifacts.signature,this.signature=n,this.version=`${t.versions.producer}.${t.versions.minConsumer}`;const r=decodeWeights(this.artifacts.weightData,this.artifacts.weightSpecs);if(this.executor=new GraphExecutor(OperationMapper.Instance.transformGraph(t,this.signature)),this.executor.weightMap=this.convertTensorMapToTensorsMap(r),this.executor.resourceManager=this.resourceManager,null!=e.modelInitializer&&null!=e.modelInitializer.node){const t=OperationMapper.Instance.transformGraph(e.modelInitializer);this.initializer=new GraphExecutor(t),this.initializer.weightMap=this.executor.weightMap,this.initializer.resourceManager=this.resourceManager,this.initializer.executeAsync({},[])}return!0}async save(e,t){if("string"==typeof e){const t=getSaveHandlers(e);if(0===t.length)throw new Error(`Cannot find any save handlers for URL '${e}'`);if(t.length>1)throw new Error(`Found more than one (${t.length}) save handlers for URL '${e}'`);e=t[0]}if(null==e.save)throw new Error("GraphModel.save() cannot proceed because the IOHandler provided does not have the `save` attribute defined.");return e.save(this.artifacts)}predict(e,t){return this.execute(e,this.outputNodes)}normalizeInputs(e){if(!(e instanceof Tensor||Array.isArray(e)))return e;if((e=Array.isArray(e)?e:[e]).length!==this.inputNodes.length)throw new Error(`Input tensor count mismatch,the graph model has ${this.inputNodes.length} placeholders, while there are ${e.length} input tensors.`);return this.inputNodes.reduce((t,n,r)=>(t[n]=e[r],t),{})}normalizeOutputs(e){return e=e||this.outputNodes,Array.isArray(e)?e:[e]}execute(e,t){e=this.normalizeInputs(e),t=this.normalizeOutputs(t);const n=this.executor.execute(e,t);return n.length>1?n:n[0]}async executeAsync(e,t){e=this.normalizeInputs(e),t=this.normalizeOutputs(t);const n=await this.executor.executeAsync(e,t);return n.length>1?n:n[0]}convertTensorMapToTensorsMap(e){return Object.keys(e).reduce((t,n)=>(t[n]=[e[n]],t),{})}dispose(){this.executor.dispose(),this.initializer&&this.initializer.dispose(),this.resourceManager.dispose()}}async function loadGraphModel(e,t={}){if(null==e)throw new Error("modelUrl in loadGraphModel() cannot be null. Please provide a url or an IOHandler that loads the model");null==t&&(t={}),t.fromTFHub&&null==e.load&&(e.endsWith("/")||(e+="/"),e=`${e}${DEFAULT_MODEL_NAME}${TFHUB_SEARCH_PARAM}`);const n=new GraphModel(e,t);return await n.load(),n}const version$5="3.8.0";function deepMap(e,t){return deepMapInternal(e,t)}function deepMapInternal(e,t,n=new Map,r=new Set){if(null==e)return null;if(r.has(e))throw new Error("Circular references are not supported.");if(n.has(e))return n.get(e);const a=t(e);if(a.recurse&&null!==a.value)throw new Error("A deep map function may not return both a value and recurse=true.");if(a.recurse){if(isIterable(e)){const a=Array.isArray(e)?[]:{};r.add(e);for(const s in e){const o=deepMapInternal(e[s],t,n,r);a[s]=o}return r.delete(e),a}throw new Error(`Can't recurse into non-iterable type: ${e}`)}return n.set(e,a.value),a.value}function deepZip(e,t=zipToList){return deepZipInternal(e,t)}function deepZipInternal(e,t,n=new Set){const r=e[0];if(n.has(r))throw new Error("Circular references are not supported.");const a=t(e);if(a.recurse&&null!==a.value)throw new Error("A deep zip function may not return both a value and recurse=true.");if(a.recurse){if(isIterable(r)){const a=Array.isArray(r)?[]:{};n.add(r);for(const s in r){const r=deepZipInternal(e.map(e=>e[s]),t,n);a[s]=r}return n.delete(r),a}throw new Error(`Can't recurse into non-iterable type: ${r}`)}return a.value}function zipToList(e){return null===e?null:isIterable(e[0])?{value:null,recurse:!0}:{value:e,recurse:!1}}async function deepMapAndAwaitAll(e,t){const n=new Map;deepMapInternal(e,t,n);for(const e of Array.from(n.keys())){const t=n.get(e);if(isPromise(t)){const r=await t;n.set(e,r)}}return deepMapInternal(e,t,n)}function isIterable(e){return null!=e&&!ArrayBuffer.isView(e)&&(Array.isArray(e)||"object"==typeof e&&!(e instanceof Tensor))}function canTensorify(e){return null==e||isPrimitive(e)||Array.isArray(e)||"object"==typeof e&&e instanceof Tensor||isTypedArray(e)}function isPrimitive(e){return null===e||"object"!=typeof e&&"function"!=typeof e}function deepClone(e){return deepMap(e,cloneIfTensor)}function cloneIfTensor(e){return e instanceof Tensor?{value:e.clone(),recurse:!1}:isIterable(e)?{value:null,recurse:!0}:{value:e,recurse:!1}}class RingBuffer{constructor(e){if(this.capacity=e,this.begin=0,this.end=0,null==e)throw new RangeError("Can't create a ring buffer of unknown capacity.");if(e<1)throw new RangeError("Can't create ring buffer of capacity < 1.");this.data=new Array(e),this.doubledCapacity=2*e}wrap(e){for(;e<0;)e+=this.doubledCapacity;return e%this.doubledCapacity}get(e){if(e<0)throw new RangeError("Can't get item at a negative index.");return this.data[e%this.capacity]}set(e,t){if(e<0)throw new RangeError("Can't set item at a negative index.");this.data[e%this.capacity]=t}length(){let e=this.end-this.begin;return e<0&&(e=this.doubledCapacity+e),e}isFull(){return this.length()===this.capacity}isEmpty(){return 0===this.length()}push(e){if(this.isFull())throw new RangeError("Ring buffer is full.");this.set(this.end,e),this.end=this.wrap(this.end+1)}pushAll(e){for(const t of e)this.push(t)}pop(){if(this.isEmpty())throw new RangeError("Ring buffer is empty.");this.end=this.wrap(this.end-1);const e=this.get(this.end);return this.set(this.end,void 0),e}unshift(e){if(this.isFull())throw new RangeError("Ring buffer is full.");this.begin=this.wrap(this.begin-1),this.set(this.begin,e)}shift(){if(this.isEmpty())throw new RangeError("Ring buffer is empty.");const e=this.get(this.begin);return this.set(this.begin,void 0),this.begin=this.wrap(this.begin+1),e}shuffleExcise(e){if(this.isEmpty())throw new RangeError("Ring buffer is empty.");const t=this.wrap(this.begin+e),n=this.get(t);return this.set(t,this.pop()),n}}class GrowingRingBuffer extends RingBuffer{constructor(){super(GrowingRingBuffer.INITIAL_CAPACITY)}isFull(){return!1}push(e){super.isFull()&&this.expand(),super.push(e)}unshift(e){super.isFull()&&this.expand(),super.unshift(e)}expand(){const e=2*this.capacity,t=new Array(e),n=this.length();for(let e=0;e<n;e++)t[e]=this.get(this.wrap(this.begin+e));this.data=t,this.capacity=e,this.doubledCapacity=2*this.capacity,this.begin=0,this.end=n}}function iteratorFromItems(e){return new ArrayIterator(e)}function iteratorFromFunction(e){return new FunctionCallIterator(e)}function iteratorFromConcatenated(e,t){return new ChainedIterator(e,t)}function iteratorFromZipped(e,t=ZipMismatchMode.FAIL){return new ZipIterator(e,t)}GrowingRingBuffer.INITIAL_CAPACITY=32;class LazyIterator{async toArray(){const e=[];let t=await this.next();for(;!t.done;)e.push(t.value),t=await this.next();return e}async toArrayForTest(){const e=this.prefetch(100),t=[];let n=await e.next();for(;!n.done;)t.push(n.value),n=await e.next();return t}async resolveFully(){let e=await this.next();for(;!e.done;)e=await this.next()}async resolveWhile(e){let t=await this.next(),n=e(t.value);for(;!t.done&&n;)t=await this.next(),n=e(t.value)}handleErrors(e){return new ErrorHandlingLazyIterator(this,e)}filter(e){return new FilterIterator(this,e)}map(e){return new MapIterator(this,e)}mapAsync(e){return new AsyncMapIterator(this,e)}serialMapAsync(e){return new AsyncMapIterator(this,e).serial()}flatmap(e){return new FlatmapIterator(this,e)}async forEachAsync(e){return this.map(e).resolveFully()}async serialForEach(e){return this.serialMapAsync(e).resolveWhile(e=>!0===e)}rowMajorBatch(e,t=!0){return new RowMajorBatchIterator(this,e,t)}columnMajorBatch(e,t=!0,n=zipToList){return this.rowMajorBatch(e,t).map(e=>deepZip(e,n))}concatenate(e,t){return new ChainedIterator(iteratorFromItems([this,e]),t)}take(e){return e<0||null==e?this:new TakeIterator(this,e)}skip(e){return e<0||null==e?this:new SkipIterator(this,e)}prefetch(e){return new PrefetchIterator(this,e)}shuffle(e,t){return new ShuffleIterator(this,e,t)}serial(){return new SerialIterator(this)}}class ArrayIterator extends LazyIterator{constructor(e){super(),this.items=e,this.trav=0}summary(){return`Array of ${this.items.length} items`}async next(){if(this.trav>=this.items.length)return{value:null,done:!0};const e=this.items[this.trav];return this.trav++,{value:deepClone(e),done:!1}}}class FunctionCallIterator extends LazyIterator{constructor(e){super(),this.nextFn=e}summary(){return"Function call"}async next(){try{return this.nextFn()}catch(e){throw e.message=`Error thrown while iterating through a dataset: ${e.message}`,e}}}class SerialIterator extends LazyIterator{constructor(e){super(),this.upstream=e,this.lastRead=Promise.resolve({value:null,done:!1})}summary(){return`${this.upstream.summary()} -> Serial`}async next(){return this.lastRead=this.lastRead.then(()=>this.serialNext()),this.lastRead}async serialNext(){return this.upstream.next()}}class SkipIterator extends LazyIterator{constructor(e,t){super(),this.upstream=e,this.maxCount=t,this.count=0,this.lastRead=Promise.resolve({value:null,done:!1})}summary(){return`${this.upstream.summary()} -> Skip`}async next(){return this.lastRead=this.lastRead.then(()=>this.serialNext()),this.lastRead}async serialNext(){for(;this.count++<this.maxCount;){const e=await this.upstream.next();if(e.done)return e;dispose(e.value)}return this.upstream.next()}}class TakeIterator extends LazyIterator{constructor(e,t){super(),this.upstream=e,this.maxCount=t,this.count=0}summary(){return`${this.upstream.summary()} -> Take`}async next(){return this.count++>=this.maxCount?{value:null,done:!0}:this.upstream.next()}}class RowMajorBatchIterator extends LazyIterator{constructor(e,t,n=!0){super(),this.upstream=e,this.batchSize=t,this.enableSmallLastBatch=n,this.lastRead=Promise.resolve({value:null,done:!1})}summary(){return`${this.upstream.summary()} -> RowMajorBatch`}async next(){return this.lastRead=this.lastRead.then(()=>this.serialNext()),this.lastRead}async serialNext(){const e=[];for(;e.length<this.batchSize;){const t=await this.upstream.next();if(t.done)return this.enableSmallLastBatch&&e.length>0?{value:e,done:!1}:{value:null,done:!0};e.push(t.value)}return{value:e,done:!1}}}class FilterIterator extends LazyIterator{constructor(e,t){super(),this.upstream=e,this.predicate=t,this.lastRead=Promise.resolve({value:null,done:!1})}summary(){return`${this.upstream.summary()} -> Filter`}async next(){return this.lastRead=this.lastRead.then(()=>this.serialNext()),this.lastRead}async serialNext(){for(;;){const e=await this.upstream.next();if(e.done||this.predicate(e.value))return e;dispose(e.value)}}}class MapIterator extends LazyIterator{constructor(e,t){super(),this.upstream=e,this.transform=t}summary(){return`${this.upstream.summary()} -> Map`}async next(){const e=await this.upstream.next();if(e.done)return{value:null,done:!0};const t=getTensorsInContainer(e.value),n=this.transform(e.value),r=getTensorsInContainer(n);for(const e of t)isTensorInList(e,r)||e.dispose();return{value:n,done:!1}}}class ErrorHandlingLazyIterator extends LazyIterator{constructor(e,t){super(),this.upstream=e,this.handler=t,this.count=0,this.lastRead=Promise.resolve({value:null,done:!1})}summary(){return`${this.upstream.summary()} -> handleErrors`}async next(){return this.lastRead=this.lastRead.then(()=>this.serialNext()),this.lastRead}async serialNext(){for(;;)try{return await this.upstream.next()}catch(e){if(!this.handler(e))return{value:null,done:!0}}}}class AsyncMapIterator extends LazyIterator{constructor(e,t){super(),this.upstream=e,this.transform=t}summary(){return`${this.upstream.summary()} -> AsyncMap`}async next(){const e=await this.upstream.next();if(e.done)return{value:null,done:!0};const t=getTensorsInContainer(e.value),n=await this.transform(e.value),r=getTensorsInContainer(n);for(const e of t)isTensorInList(e,r)||e.dispose();return{value:n,done:!1}}}class OneToManyIterator extends LazyIterator{constructor(){super(),this.outputQueue=new GrowingRingBuffer,this.lastRead=Promise.resolve({value:null,done:!1})}async next(){return this.lastRead=this.lastRead.then(()=>this.serialNext()),this.lastRead}async serialNext(){for(;0===this.outputQueue.length();)if(!await this.pump())return{value:null,done:!0};return{value:this.outputQueue.shift(),done:!1}}}class FlatmapIterator extends OneToManyIterator{constructor(e,t){super(),this.upstream=e,this.transform=t}summary(){return`${this.upstream.summary()} -> Flatmap`}async pump(){const e=await this.upstream.next();if(e.done)return!1;const t=getTensorsInContainer(e.value),n=this.transform(e.value),r=getTensorsInContainer(n);this.outputQueue.pushAll(n);for(const e of t)isTensorInList(e,r)||e.dispose();return!0}}class ChainedIterator extends LazyIterator{constructor(e,t){super(),this.baseErrorHandler=t,this.lastRead=null,this.iterator=null,this.moreIterators=e}summary(){return"TODO: fill in upstream of chained summaries -> Chained"}async next(){return this.lastRead=this.readFromChain(this.lastRead),this.lastRead}async readFromChain(e){if(await e,null==this.iterator){const e=await this.moreIterators.next();if(e.done)return{value:null,done:!0};this.iterator=e.value,null!=this.baseErrorHandler&&(this.iterator=this.iterator.handleErrors(this.baseErrorHandler))}const t=await this.iterator.next();return t.done?(this.iterator=null,this.readFromChain(e)):t}}var ZipMismatchMode;!function(e){e[e.FAIL=0]="FAIL",e[e.SHORTEST=1]="SHORTEST",e[e.LONGEST=2]="LONGEST"}(ZipMismatchMode||(ZipMismatchMode={}));class ZipIterator extends LazyIterator{constructor(e,t=ZipMismatchMode.FAIL){super(),this.iterators=e,this.mismatchMode=t,this.count=0,this.currentPromise=null}summary(){return"{TODO: fill in upstream of zip summaries} -> Zip"}async nextState(e){await e;let t=0,n=0;const r=await deepMapAndAwaitAll(this.iterators,function(e){return e instanceof LazyIterator?{value:e.next().then(e=>(t++,e.done&&n++,e.value)),recurse:!1}:{value:null,recurse:!0}});if(t===n)return{value:null,done:!0};if(n>0)switch(this.mismatchMode){case ZipMismatchMode.FAIL:throw new Error(`Zipped streams should have the same length. Mismatched at element ${this.count}.`);case ZipMismatchMode.SHORTEST:return{value:null,done:!0}}return this.count++,{value:r,done:!1}}async next(){return this.currentPromise=this.nextState(this.currentPromise),this.currentPromise}}class PrefetchIterator extends LazyIterator{constructor(e,t){super(),this.upstream=e,this.bufferSize=t,this.buffer=new RingBuffer(t)}summary(){return`${this.upstream.summary()} -> Prefetch`}refill(){for(;!this.buffer.isFull();){const e=this.upstream.next();this.buffer.push(e)}}next(){return this.refill(),this.buffer.shift()}}class ShuffleIterator extends PrefetchIterator{constructor(e,t,n){super(e,t),this.upstream=e,this.windowSize=t,this.upstreamExhausted=!1,this.random=seedrandom.alea(n||now().toString()),this.lastRead=Promise.resolve({value:null,done:!1})}async next(){return this.lastRead=this.lastRead.then(()=>this.serialNext()),this.lastRead}randomInt(e){return Math.floor(this.random()*e)}chooseIndex(){return this.randomInt(this.buffer.length())}async serialNext(){for(this.upstreamExhausted||this.refill();!this.buffer.isEmpty();){const e=this.chooseIndex(),t=await this.buffer.shuffleExcise(e);if(!t.done)return this.refill(),t;this.upstreamExhausted=!0}return{value:null,done:!0}}}class Dataset{constructor(){this.size=null}batch(e,t=!0){const n=this;let r;return assert$4(e>0,()=>`batchSize needs to be positive, but it is\n      ${e}`),r=Infinity===this.size||null==this.size?this.size:t?Math.ceil(this.size/e):Math.floor(this.size/e),datasetFromIteratorFn(async function(){return(await n.iterator()).columnMajorBatch(e,t,deepBatchConcat)},r)}concatenate(e){const t=this;let n;return n=Infinity===this.size||Infinity===e.size?Infinity:null!=this.size&&null!=e.size?this.size+e.size:null,datasetFromIteratorFn(async function(){return(await t.iterator()).concatenate(await e.iterator())},n)}filter(e){const t=this;let n;return n=Infinity===this.size?Infinity:null,datasetFromIteratorFn(async function(){return(await t.iterator()).filter(t=>tidy(()=>e(t)))},n)}async forEachAsync(e){return(await this.iterator()).forEachAsync(e)}map(e){const t=this;return datasetFromIteratorFn(async function(){return(await t.iterator()).map(t=>tidy(()=>e(t)))},this.size)}mapAsync(e){const t=this;return datasetFromIteratorFn(async function(){return(await t.iterator()).mapAsync(e)},this.size)}prefetch(e){if(null==e)throw new RangeError("`Dataset.prefetch()` requires bufferSize to be specified.");const t=this;return datasetFromIteratorFn(async function(){return(await t.iterator()).prefetch(e)},this.size)}repeat(e){const t=this;let n;return n=null!=this.size&&e>0?this.size*e:0===e?0:null!=this.size&&(void 0===e||e<0)?Infinity:null,datasetFromIteratorFn(async function(){return iteratorFromConcatenated(iteratorFromFunction(async function(){return{value:await t.iterator(),done:!1}}).take(e))},n)}skip(e){const t=this;let n;return n=null!=this.size&&e>=0&&this.size>=e?this.size-e:null!=this.size&&(this.size<e||void 0===e||e<0)?0:null,datasetFromIteratorFn(async function(){return(await t.iterator()).skip(e)},n)}shuffle(e,t,n=!0){if(null==e||e<0)throw null==this.size?new RangeError("`Dataset.shuffle()` requires bufferSize to be specified."):new RangeError(`\`Dataset.shuffle()\` requires bufferSize to be specified.  If your data fits in main memory (for regular JS objects), and/or GPU memory (for \`tf.Tensor\`s), consider setting bufferSize to the dataset size (${this.size} elements)`);const r=this,a=seedrandom.alea(t||now().toString());return datasetFromIteratorFn(async function(){let t=a.int32();return n&&(t+=a.int32()),(await r.iterator()).shuffle(e,t.toString())},this.size)}take(e){const t=this;let n;return n=null!=this.size&&this.size>e?e:null!=this.size&&this.size<=e?this.size:null,datasetFromIteratorFn(async function(){return(await t.iterator()).take(e)},n)}async toArray(){if(Infinity===this.size)throw new Error("Can not convert infinite data stream to array.");return(await this.iterator()).toArray()}async toArrayForTest(){if(Infinity===this.size)throw new Error("Can not convert infinite data stream to array.");return(await this.iterator()).toArrayForTest()}}function datasetFromIteratorFn(e,t=null){return new class extends Dataset{constructor(){super(...arguments),this.size=t}async iterator(){return e()}}}function array(e){return datasetFromIteratorFn(async()=>iteratorFromItems(e),e.length)}function zip(e){if(!isIterable(e))throw new Error("The argument to zip() must be an object or array.");let t;if(Array.isArray(e))for(let n=0;n<e.length;n++)t=null==t?e[n].size:Math.min(t,e[n].size);else if(e instanceof Object)for(const n in e)t=null==t?e[n].size:Math.min(t,e[n].size);return datasetFromIteratorFn(async()=>iteratorFromZipped(await deepMapAndAwaitAll(e,e=>{if(e instanceof Dataset)return{value:e.iterator(),recurse:!1};if(isIterable(e))return{value:null,recurse:!0};throw new Error("Leaves of the structure passed to zip() must be Datasets, not primitives.")}),ZipMismatchMode.SHORTEST),t)}function deepBatchConcat(e){return null===e?null:canTensorify(e[0])?{value:batchConcat(e),recurse:!1}:{value:null,recurse:!0}}function batchConcat(e){if(0===e.length)throw new Error("Can't make a batch of zero elements.");return e[0]instanceof Tensor?stack(e):tensor(e)}Dataset.MAX_BUFFER_SIZE=1e4;class TextLineDataset extends Dataset{constructor(e){super(),this.input=e}async iterator(){return(await this.input.iterator()).decodeUTF8().split("\n").map(e=>(e.endsWith("\r")&&(e=e.slice(0,-1)),e))}}const CODE_QUOTE='"',STATE_OUT=Symbol("out"),STATE_FIELD=Symbol("field"),STATE_QUOTE=Symbol("quote"),STATE_QUOTE_AFTER_QUOTE=Symbol("quoteafterquote"),STATE_WITHIN_QUOTE_IN_QUOTE=Symbol("quoteinquote");class CSVDataset extends Dataset{constructor(e,t){super(),this.input=e,this.hasHeader=!0,this.fullColumnNames=null,this.columnNamesValidated=!1,this.columnConfigs=null,this.configuredColumnsOnly=!1,this.delimiter=",",this.delimWhitespace=!1,this.base=new TextLineDataset(e),t||(t={}),this.hasHeader=!1!==t.hasHeader,this.fullColumnNames=t.columnNames,this.columnConfigs=t.columnConfigs,this.configuredColumnsOnly=t.configuredColumnsOnly,t.delimWhitespace?(assert$4(null==t.delimiter,()=>"Delimiter should not be provided when delimWhitespace is true."),this.delimWhitespace=!0,this.delimiter=" "):this.delimiter=t.delimiter?t.delimiter:","}async columnNames(){return this.columnNamesValidated||await this.setColumnNames(),this.configuredColumnsOnly?Object.keys(this.columnConfigs):this.fullColumnNames}async setColumnNames(){const e=await this.maybeReadHeaderLine();if(!this.fullColumnNames&&!e)throw new Error("Column names must be provided if there is no header line.");this.fullColumnNames&&e&&assert$4(e.length===this.fullColumnNames.length,()=>"The length of provided columnNames ("+this.fullColumnNames.length.toString()+") does not match the length of the header line read from file ("+e.length.toString()+")."),this.fullColumnNames||(this.fullColumnNames=e);const t=this.fullColumnNames.reduce((e,t)=>(e[t]=e[t]+1||1,e),{}),n=Object.keys(t).filter(e=>t[e]>1);if(assert$4(0===n.length,()=>"Duplicate column names found: "+n.toString()),this.columnConfigs)for(const e of Object.keys(this.columnConfigs))if(-1===this.fullColumnNames.indexOf(e))throw new Error('The key "'+e+'" provided in columnConfigs does not match any of the column names ('+this.fullColumnNames.toString()+").");this.columnNamesValidated=!0}async maybeReadHeaderLine(){if(this.hasHeader){const e=await this.base.iterator(),t=await e.next();if(t.done)throw new Error("No data was found for CSV parsing.");return this.parseRow(t.value,!1)}return null}async iterator(){this.columnNamesValidated||await this.setColumnNames();let e=await this.base.iterator();return this.hasHeader&&(e=e.skip(1)),e.map(e=>this.makeDataElement(e))}makeDataElement(e){const t=this.parseRow(e),n={},r={};for(let a=0;a<this.fullColumnNames.length;a++){const s=this.fullColumnNames[a],o=this.columnConfigs?this.columnConfigs[s]:null;if(!this.configuredColumnsOnly||o){const i=t[a];let l=null;if(""===i)if(o&&void 0!==o.default)l=o.default;else{if(o&&(o.required||o.isLabel))throw new Error(`Required column ${s} is empty in this line: ${e}`);l=void 0}else{const e=Number(i);if(isNaN(e))l=o&&"bool"===o.dtype?this.getBoolean(i):i;else if(o&&o.dtype)switch(o.dtype){case"float32":l=e;break;case"int32":l=Math.floor(e);break;case"bool":l=this.getBoolean(i);break;default:l=e}else l=e}o&&o.isLabel?r[s]=l:n[s]=l}}return 0===Object.keys(r).length?n:{xs:n,ys:r}}getBoolean(e){return"1"===e||"true"===e.toLowerCase()?1:0}parseRow(e,t=!0){const n=[];let r=0;const a=e.length;let s=STATE_OUT;for(let t=0;t<a;t++)switch(s){case STATE_OUT:switch(e.charAt(t)){case CODE_QUOTE:r=t+1,s=STATE_QUOTE;break;case this.delimiter:if(r=t+1," "===this.delimiter&&this.delimWhitespace)break;n.push(""),s=STATE_OUT;break;default:s=STATE_FIELD,r=t}break;case STATE_FIELD:switch(e.charAt(t)){case this.delimiter:n.push(e.substring(r,t)),s=STATE_OUT,r=t+1}break;case STATE_QUOTE:switch(e.charAt(t)){case CODE_QUOTE:s=STATE_QUOTE_AFTER_QUOTE}break;case STATE_QUOTE_AFTER_QUOTE:switch(e.charAt(t)){case this.delimiter:n.push(e.substring(r,t-1)),s=STATE_OUT,r=t+1;break;case CODE_QUOTE:s=STATE_QUOTE;break;default:s=STATE_WITHIN_QUOTE_IN_QUOTE}break;case STATE_WITHIN_QUOTE_IN_QUOTE:switch(e.charAt(t)){case CODE_QUOTE:s=STATE_QUOTE}}if(n.push(s===STATE_QUOTE_AFTER_QUOTE?e.substring(r,a-1):e.substring(r)),t&&n.length!==this.fullColumnNames.length)throw new Error(`Invalid row in csv file. Should have ${this.fullColumnNames.length} elements in a row, but got ${n}`);return n}}class MicrophoneIterator extends LazyIterator{constructor(e){super(),this.microphoneConfig=e,this.isClosed=!1,this.fftSize=e.fftSize||1024;const t=Math.log2(this.fftSize);if(this.fftSize<0||t<4||t>14||!Number.isInteger(t))throw new Error(`Invalid fftSize: it must be a power of 2 between 2 to 4 and 2 to 14, but got ${this.fftSize}`);if(this.numFrames=e.numFramesPerSpectrogram||43,this.sampleRateHz=e.sampleRateHz,this.columnTruncateLength=e.columnTruncateLength||this.fftSize,this.audioTrackConstraints=e.audioTrackConstraints,this.smoothingTimeConstant=e.smoothingTimeConstant||0,this.includeSpectrogram=!1!==e.includeSpectrogram,this.includeWaveform=!0===e.includeWaveform,!this.includeSpectrogram&&!this.includeWaveform)throw new Error("Both includeSpectrogram and includeWaveform are false. At least one type of data should be returned.")}summary(){return"microphone"}static async create(e={}){if(env().get("IS_NODE"))throw new Error("microphone API is only supported in browser environment.");const t=new MicrophoneIterator(e);return await t.start(),t}async start(){try{this.stream=await navigator.mediaDevices.getUserMedia({audio:null==this.audioTrackConstraints||this.audioTrackConstraints,video:!1})}catch(e){throw new Error(`Error thrown while initializing video stream: ${e.message}`)}if(!this.stream)throw new Error("Could not obtain audio from microphone.");const e=window.AudioContext||window.webkitAudioContext;if(this.audioContext=new e,this.sampleRateHz){if(this.audioContext.sampleRate!==this.sampleRateHz)throw new Error(`Mismatch in sampling rate: Expected: ${this.sampleRateHz}; Actual: ${this.audioContext.sampleRate}`)}else this.sampleRateHz=this.audioContext.sampleRate;const t=this.audioContext.createMediaStreamSource(this.stream);this.analyser=this.audioContext.createAnalyser(),this.analyser.fftSize=2*this.fftSize,this.analyser.smoothingTimeConstant=this.smoothingTimeConstant,t.connect(this.analyser),this.freqData=new Float32Array(this.fftSize),this.timeData=new Float32Array(this.fftSize)}async next(){if(this.isClosed)return{value:null,done:!0};let e,t;const n=await this.getAudioData();if(this.includeSpectrogram){const t=this.flattenQueue(n.freqDataQueue);e=this.getTensorFromAudioDataArray(t,[this.numFrames,this.columnTruncateLength,1])}if(this.includeWaveform){const e=this.flattenQueue(n.timeDataQueue);t=this.getTensorFromAudioDataArray(e,[this.numFrames*this.fftSize,1])}return{value:{spectrogram:e,waveform:t},done:!1}}async capture(){return(await this.next()).value}async getAudioData(){const e=[],t=[];let n=0;return new Promise(r=>{const a=setInterval(()=>{this.includeSpectrogram&&(this.analyser.getFloatFrequencyData(this.freqData),-Infinity===this.freqData[0]&&r({freqDataQueue:e,timeDataQueue:t}),e.push(this.freqData.slice(0,this.columnTruncateLength))),this.includeWaveform&&(this.analyser.getFloatTimeDomainData(this.timeData),t.push(this.timeData.slice())),++n===this.numFrames&&(clearInterval(a),r({freqDataQueue:e,timeDataQueue:t}))},this.fftSize/this.sampleRateHz*1e3)})}stop(){this.isClosed||(this.isClosed=!0,this.analyser.disconnect(),this.audioContext.close(),null!=this.stream&&this.stream.getTracks().length>0&&this.stream.getTracks()[0].stop())}toArray(){throw new Error("Can not convert infinite audio stream to array.")}getSampleRate(){return this.sampleRateHz}flattenQueue(e){const t=e[0].length,n=new Float32Array(e.length*t);return e.forEach((e,r)=>n.set(e,r*t)),n}getTensorFromAudioDataArray(e,t){const n=new Float32Array(sizeFromShape(t));return n.set(e,n.length-e.length),tensor(n,t)}}class WebcamIterator extends LazyIterator{constructor(e,t){if(super(),this.webcamVideoElement=e,this.webcamConfig=t,this.isClosed=!0,this.resize=!1,this.needToResize())if(this.resize=!0,this.cropSize=[this.webcamConfig.resizeHeight,this.webcamConfig.resizeWidth],this.cropBoxInd=tensor1d([0],"int32"),this.webcamConfig.centerCrop){const e=1*this.webcamConfig.resizeWidth/this.webcamVideoElement.width,t=1*this.webcamConfig.resizeHeight/this.webcamVideoElement.height,n=(1-e)/2,r=(1-t)/2;this.cropBox=tensor2d([r,n,t+r,n+e],[1,4])}else this.cropBox=tensor2d([0,0,1,1],[1,4])}summary(){return"webcam"}static async create(e,t={}){if(env().get("IS_NODE"))throw new Error("tf.data.webcam is only supported in browser environment.");if(!e){if(e=document.createElement("video"),!t.resizeWidth||!t.resizeHeight)throw new Error("Please provide webcam video element, or resizeWidth and resizeHeight to create a hidden video element.");e.width=t.resizeWidth,e.height=t.resizeHeight}const n=new WebcamIterator(e,t);return await n.start(),n}async start(){this.webcamConfig.facingMode&&assert$4("user"===this.webcamConfig.facingMode||"environment"===this.webcamConfig.facingMode,()=>`Invalid webcam facing mode: ${this.webcamConfig.facingMode}. Please provide 'user' or 'environment'`);try{this.stream=await navigator.mediaDevices.getUserMedia({video:{deviceId:this.webcamConfig.deviceId,facingMode:this.webcamConfig.facingMode?this.webcamConfig.facingMode:"user",width:this.webcamVideoElement.width,height:this.webcamVideoElement.height}})}catch(e){throw e.message=`Error thrown while initializing video stream: ${e.message}`,e}if(!this.stream)throw new Error("Could not obtain video from webcam.");try{this.webcamVideoElement.srcObject=this.stream}catch(e){console.log(e),this.webcamVideoElement.src=window.URL.createObjectURL(this.stream)}return this.webcamVideoElement.play(),this.isClosed=!1,new Promise(e=>{this.webcamVideoElement.onloadedmetadata=()=>{e()}})}async next(){if(this.isClosed)return{value:null,done:!0};let e;try{e=fromPixels$1(this.webcamVideoElement)}catch(e){throw new Error(`Error thrown converting video to pixels: ${JSON.stringify(e)}`)}if(!this.resize)return{value:e,done:!1};try{return{value:this.cropAndResizeFrame(e),done:!1}}catch(e){throw new Error(`Error thrown cropping the video: ${e.message}`)}finally{e.dispose()}}needToResize(){return!(!this.webcamConfig.resizeWidth||!this.webcamConfig.resizeHeight||this.webcamVideoElement.width===this.webcamConfig.resizeWidth&&this.webcamVideoElement.height===this.webcamConfig.resizeHeight)}cropAndResizeFrame(e){return tidy(()=>{const t=expandDims$3(cast$3(e,"float32"),0);let n;return n=image$1.cropAndResize(t,this.cropBox,this.cropBoxInd,this.cropSize,"bilinear"),reshape$3(n,n.shape.slice(1))})}async capture(){return(await this.next()).value}stop(){this.stream.getTracks().forEach(e=>e.stop());try{this.webcamVideoElement.srcObject=null}catch(e){console.log(e),this.webcamVideoElement.src=null}this.isClosed=!0}toArray(){throw new Error("Can not convert infinite video stream to array.")}}class DataSource{}class StringIterator extends LazyIterator{split(e){return new SplitIterator(this,e)}}class SplitIterator extends StringIterator{constructor(e,t){super(),this.upstream=e,this.impl=new SplitIteratorImpl(e,t)}summary(){return this.impl.summary()}async next(){return this.impl.next()}}class SplitIteratorImpl extends OneToManyIterator{constructor(e,t){super(),this.upstream=e,this.separator=t,this.carryover=""}summary(){return`${this.upstream.summary()} -> Split('${this.separator}')`}async pump(){const e=await this.upstream.next();if(e.done)return""!==this.carryover&&(this.outputQueue.push(this.carryover),this.carryover="",!0);const t=e.value.split(this.separator);t[0]=this.carryover+t[0];for(const e of t.slice(0,-1))this.outputQueue.push(e);return this.carryover=t[t.length-1],!0}}class ByteChunkIterator extends LazyIterator{decodeUTF8(){return new Utf8Iterator(this)}}class Utf8Iterator extends StringIterator{constructor(e){super(),this.upstream=e,this.impl=new Utf8IteratorImpl(e)}summary(){return this.impl.summary()}async next(){return this.impl.next()}}class Utf8IteratorImpl extends OneToManyIterator{constructor(e){if(super(),this.upstream=e,env().get("IS_BROWSER"))this.decoder=new TextDecoder("utf-8");else{const{StringDecoder:e}=require("string_decoder");this.decoder=new e("utf8")}}summary(){return`${this.upstream.summary()} -> Utf8`}async pump(){const e=await this.upstream.next();let t,n;return!e.done&&(t=e.value,n=env().get("IS_BROWSER")?this.decoder.decode(t,{stream:!0}):this.decoder.write(Buffer.from(t.buffer)),this.outputQueue.push(n),!0)}}class FileChunkIterator extends ByteChunkIterator{constructor(e,t={}){super(),this.file=e,this.options=t,assert$4(e instanceof Uint8Array||!!env().get("IS_BROWSER")&&(e instanceof File||e instanceof Blob),()=>"FileChunkIterator only supports File, Blob and Uint8Array right now."),this.offset=t.offset||0,this.chunkSize=t.chunkSize||1048576}summary(){return`FileChunks ${this.file}`}async next(){if(this.offset>=(this.file instanceof Uint8Array?this.file.byteLength:this.file.size))return{value:null,done:!0};const e=new Promise((e,t)=>{const n=this.offset+this.chunkSize;if(this.file instanceof Uint8Array)e(new Uint8Array(this.file.slice(this.offset,n)));else{const r=new FileReader;r.onload=n=>{let a=r.result;if(a instanceof ArrayBuffer&&(a=new Uint8Array(a)),!(a instanceof Uint8Array))return t(new TypeError("FileReader returned unknown type."));e(a)},r.onabort=e=>t(new Error("Aborted")),r.onerror=e=>t(new Error(e.type));const a=this.file.slice(this.offset,n);r.readAsArrayBuffer(a)}this.offset=n});return{value:await e,done:!1}}}async function urlChunkIterator(e,t={}){let n,r;"string"==typeof e?n=e:(n=e.url,r=getRequestInitFromRequest(e));const a=await fetch$1(n,r);if(a.ok){const e=new Uint8Array(await a.arrayBuffer());return new FileChunkIterator(e,t)}throw new Error(a.statusText)}const getRequestInitFromRequest=e=>({method:e.method,headers:e.headers,body:e.body,mode:e.mode,credentials:e.credentials,cache:e.cache,redirect:e.redirect,referrer:e.referrer,integrity:e.integrity});function isLocalPath(e){return"string"==typeof e&&"file://"===e.substr(0,7)}class FileDataSource extends DataSource{constructor(e,t={}){super(),this.input=e,this.options=t}async iterator(){if(isLocalPath(this.input)&&env().get("IS_NODE")){const e=require("fs");this.input=e.readFileSync(this.input.substr(7))}return new FileChunkIterator(this.input,this.options)}}class URLDataSource extends DataSource{constructor(e,t={}){super(),this.url=e,this.fileOptions=t}async iterator(){return isLocalPath(this.url)?new FileDataSource(this.url,this.fileOptions).iterator():urlChunkIterator(this.url,this.fileOptions)}}function csv(e,t={}){return new CSVDataset(new URLDataSource(e),t)}function func(e){const t=iteratorFromFunction(e);return datasetFromIteratorFn(async()=>t)}function generator(e){return datasetFromIteratorFn(async()=>{const t=await e();return iteratorFromFunction(()=>t.next())})}async function webcam(e,t){return WebcamIterator.create(e,t)}async function microphone(e){return MicrophoneIterator.create(e)}const version$4="3.8.0";var index={__proto__:null,array,Dataset,zip,CSVDataset,TextLineDataset,csv,func,generator,microphone,webcam,FileDataSource,URLDataSource,version_data:version$4};function assertNotComplex$1(e,t){Array.isArray(e)||(e=[e]),e.forEach(e=>{null!=e&&assert$4("complex64"!==e.dtype,()=>`${t} does not support complex64 tensors in the CPU backend.`)})}const whereImpl$1=whereImpl$2;class MathBackendCPU extends KernelBackend{constructor(){super(),this.blockSize=48,this.firstUse=!0,this.data=new DataStorage(this,engine())}nextDataId(){return MathBackendCPU.nextDataId++}write(e,t,n){this.firstUse&&(this.firstUse=!1,env().get("IS_NODE")&&warn("\n============================\nHi there 👋. Looks like you are running TensorFlow.js in Node.js. To speed things up dramatically, install our node backend, which binds to TensorFlow C++, by running npm i @tensorflow/tfjs-node, or npm i @tensorflow/tfjs-node-gpu if you have CUDA. Then call require('@tensorflow/tfjs-node'); (-gpu suffix for CUDA) at the start of your program. Visit https://github.com/tensorflow/tfjs-node for more details.\n============================"));const r={id:this.nextDataId()};return this.data.set(r,{values:e,dtype:n,refCount:1}),r}makeTensorInfo(e,t,n){let r;if("string"===t&&null!=n&&n.length>0&&isString(n[0])){const a=n.map(e=>encodeString(e));r=this.write(a,e,t)}else r=this.write(n,e,t);return{dataId:r,shape:e,dtype:t}}refCount(e){return this.data.has(e)?this.data.get(e).refCount:0}incRef(e){this.data.get(e).refCount++}decRef(e){this.data.has(e)&&this.data.get(e).refCount--}move(e,t,n,r,a){this.data.set(e,{values:t,dtype:r,refCount:a})}numDataIds(){return this.data.numDataIds()}async read(e){return this.readSync(e)}readSync(e){const{dtype:t,complexTensorInfos:n}=this.data.get(e);return"complex64"===t?mergeRealAndImagArrays(this.readSync(n.real.dataId),this.readSync(n.imag.dataId)):this.data.get(e).values}bufferSync(e){const t=this.readSync(e.dataId);let n=t;if("string"===e.dtype)try{n=t.map(e=>decodeString(e))}catch(e){throw new Error("Failed to decode encoded string bytes into utf-8")}return buffer(e.shape,e.dtype,n)}makeOutput(e,t,n){const r=this.write(e,t,n);return engine().makeTensorFromDataId(r,t,n,this)}disposeData(e,t=!1){if(this.data.has(e)){if(this.data.get(e).refCount--,!t&&this.data.get(e).refCount>0)return!1;const{complexTensorInfos:n}=this.data.get(e);null!=n&&(this.disposeData(n.real.dataId,!0),this.disposeData(n.imag.dataId,!0)),this.data.delete(e)}return!0}disposeIntermediateTensorInfo(e){this.disposeData(e.dataId)}async time(e){const t=now();return e(),{kernelMs:now()-t}}memory(){return{unreliable:!0,reasons:["The reported memory is an upper bound. Due to automatic garbage collection, the true allocated memory may be less."]}}where(e){assertNotComplex$1([e],"where");const t=this.readSync(e.dataId);return whereImpl$1(e.shape,t)}dispose(){}floatPrecision(){return 32}epsilon(){return super.epsilon()}}function simpleAbsImpl(e){const t=new Float32Array(e.length);for(let n=0;n<e.length;++n)t[n]=Math.abs(e[n]);return t}MathBackendCPU.nextDataId=0;const abs$1=e=>{const{x:t}=e.inputs,n=e.backend;assertNotComplex$1(t,"abs");let r=new Float32Array(sizeFromShape(t.shape));return r=simpleAbsImpl(n.data.get(t.dataId).values),n.makeOutput(r,t.shape,"float32")},absConfig$1={kernelName:Abs,backendName:"cpu",kernelFunc:abs$1};function createSimpleBinaryKernelImpl(e){return(t,n,r,a,s)=>{const o=assertAndGetBroadcastShape(t,n),i=o.length,l=computeStrides(o),u=getTypedArrayFromDType(s,sizeFromShape(o)),c=t.length,p=n.length,d=computeStrides(t),h=computeStrides(n),m=getBroadcastDims$1(t,o),f=getBroadcastDims$1(n,o);if(m.length+f.length===0)for(let t=0;t<u.length;++t)u[t]=e(r[t%r.length],a[t%a.length]);else for(let t=0;t<u.length;++t){const n=indexToLoc(t,i,l),s=n.slice(-c);m.forEach(e=>s[e]=0);const o=locToIndex(s,c,d),g=n.slice(-p);f.forEach(e=>g[e]=0);const $=locToIndex(g,p,h);u[t]=e(r[o],a[$])}return[u,o]}}function complex$1(e){const{inputs:t,backend:n}=e,{real:r,imag:a}=t,s=n.data.get(r.dataId).values,o=n.data.get(a.dataId).values,i=n.makeTensorInfo(r.shape,"complex64");return n.data.get(i.dataId).complexTensorInfos={real:n.makeTensorInfo(r.shape,"float32",s),imag:n.makeTensorInfo(a.shape,"float32",o)},i}const complexConfig$1={kernelName:Complex,backendName:"cpu",kernelFunc:complex$1};function zeros(e,t,n="float32"){if("complex64"===n)return complex$1({inputs:{real:zeros(e,t,"float32"),imag:zeros(e,t,"float32")},backend:e});const r=makeZerosTypedArray(sizeFromShape(t),n);return e.makeTensorInfo(t,n,r)}function identity$1(e){const{inputs:t,backend:n}=e,{x:r}=t;return n.incRef(r.dataId),{dataId:r.dataId,shape:r.shape,dtype:r.dtype}}const identityConfig$1={kernelName:Identity$1,backendName:"cpu",kernelFunc:identity$1};function real$1(e){const{inputs:t,backend:n}=e,{input:r}=t,a=n.data.get(r.dataId).complexTensorInfos.real,s=n.data.get(a.dataId).values;return n.makeTensorInfo(a.shape,a.dtype,s)}const realConfig$1={kernelName:Real,backendName:"cpu",kernelFunc:real$1};function cast$1(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{dtype:s}=r;if("complex64"===s){if("complex64"===a.dtype)return identity$1({inputs:{x:a},backend:n});const e=zeros(n,a.shape,a.dtype),t=cast$1({inputs:{x:a},backend:n,attrs:{dtype:"float32"}}),r=complex$1({inputs:{real:t,imag:e},backend:n});return n.disposeIntermediateTensorInfo(e),n.disposeIntermediateTensorInfo(t),r}if("complex64"===a.dtype){const e=real$1({inputs:{input:a},backend:n}),t=cast$1({inputs:{x:e},backend:n,attrs:{dtype:s}});return n.disposeIntermediateTensorInfo(e),t}if(!hasEncodingLoss(a.dtype,s)){const e=identity$1({inputs:{x:a},backend:n});return{dataId:e.dataId,shape:e.shape,dtype:s}}if("int32"===s){const e=n.data.get(a.dataId).values,t=Int32Array.from(e);return n.makeTensorInfo(a.shape,"int32",t)}if("bool"===s){const e=n.data.get(a.dataId).values,t=toTypedArray([0],a.dtype),[r,s]=createSimpleBinaryKernelImpl((e,t)=>e!==t?1:0)(a.shape,[],e,t,"bool");return n.makeTensorInfo(s,"bool",r)}throw new Error(`Error in Cast: failed to cast ${a.dtype} to ${s}`)}const castConfig$1={kernelName:Cast,backendName:"cpu",kernelFunc:cast$1};function binaryKernelFunc$1(e,t,n,r){return null==n?({inputs:n,backend:a})=>{const{a:s,b:o}=n,i=a;assertNotComplex$1([s,o],e);const l=i.data.get(s.dataId).values,u=i.data.get(o.dataId).values,c="string"===s.dtype?fromUint8ToStringArray(l):l,p="string"===s.dtype?fromUint8ToStringArray(u):u,d=r||s.dtype,[h,m]=t(s.shape,o.shape,c,p,d);return i.makeTensorInfo(m,d,h)}:({inputs:e,backend:a})=>{const{a:s,b:o}=e,i=a;if("complex64"===s.dtype||"complex64"===o.dtype){const e=cast$1({inputs:{x:s},backend:i,attrs:{dtype:"complex64"}}),t=i.data.get(e.dataId),r=t.complexTensorInfos.imag,a=i.data.get(t.complexTensorInfos.real.dataId).values,l=i.data.get(r.dataId).values,u=cast$1({inputs:{x:o},backend:i,attrs:{dtype:"complex64"}}),c=i.data.get(u.dataId),p=c.complexTensorInfos.imag,d=i.data.get(c.complexTensorInfos.real.dataId).values,h=i.data.get(p.dataId).values,[m,f,g]=n(s.shape,o.shape,a,l,d,h),$=i.makeTensorInfo(g,"float32",m),y=i.makeTensorInfo(g,"float32",f),b=complex$1({inputs:{real:$,imag:y},backend:i});return i.disposeIntermediateTensorInfo(e),i.disposeIntermediateTensorInfo(u),i.disposeIntermediateTensorInfo($),i.disposeIntermediateTensorInfo(y),b}{const e=i.data.get(s.dataId).values,n=i.data.get(o.dataId).values,a=r||s.dtype,[l,u]=t(s.shape,o.shape,e,n,a);return i.makeTensorInfo(u,a,l)}}}function createComplexBinaryKernelImpl(e){return(t,n,r,a,s,o)=>{const i=assertAndGetBroadcastShape(t,n),l=sizeFromShape(i),u=i.length,c=computeStrides(i),p=getTypedArrayFromDType("float32",l),d=getTypedArrayFromDType("float32",l),h=getBroadcastDims$1(t,i),m=getBroadcastDims$1(n,i),f=mergeRealAndImagArrays(r,a),g=mergeRealAndImagArrays(s,o),$=t.length,y=computeStrides(t),b=n.length,x=computeStrides(n);if(h.length+m.length===0)for(let t=0;t<p.length;t++){const n=t%f.length,r=t%g.length,a=e(f[2*n],f[2*n+1],g[2*r],g[2*r+1]);p[t]=a.real,d[t]=a.imag}else for(let t=0;t<p.length;t++){const n=indexToLoc(t,u,c),r=n.slice(-$);h.forEach(e=>r[e]=0);const a=locToIndex(r,$,y),s=n.slice(-b);m.forEach(e=>s[e]=0);const o=locToIndex(s,b,x),i=e(f[2*a],f[2*a+1],g[2*o],g[2*o+1]);p[t]=i.real,d[t]=i.imag}return[p,d,i]}}const addImpl=createSimpleBinaryKernelImpl((e,t)=>e+t),addComplexImpl=createComplexBinaryKernelImpl((e,t,n,r)=>({real:e+n,imag:t+r})),add=binaryKernelFunc$1(Add$1,addImpl,addComplexImpl),addConfig$1={kernelName:Add$1,backendName:"cpu",kernelFunc:add};function bincountImpl(e,t,n,r,a){const s=sizeFromShape(r),o=makeZerosTypedArray(a,n);for(let n=0;n<e.length;n++){const r=e[n];if(r<0)throw new Error("Input x must be non-negative!");r>=a||(o[r]+=s>0?t[n]:1)}return o}function bincountReduceImpl(e,t,n,r=!1){const a=e.shape[0],s=e.shape[1],o=buffer([a,n],t.dtype);for(let i=0;i<a;i++)for(let a=0;a<s;a++){const s=e.get(i,a);if(s<0)throw new Error("Input x must be non-negative!");s>=n||o.set(r?1:t.size>0?o.get(i,s)+t.get(i,a):o.get(i,s)+1,i,s)}return o}function createSimpleUnaryImpl(e){return(t,n,r)=>{const a=getTypedArrayFromDType(n,t.length);for(let n=0;n<t.length;++n)a[n]=e(t[n],r);return a}}function unaryKernelFunc$1(e,t,n){return({inputs:r,attrs:a,backend:s})=>{const{x:o}=r;if(assertNotComplex$1(o,e),"string"===o.dtype||"string"===n)throw new Error("unaryKernelFunc does not support string input/output");const i=s,l=i.data.get(o.dataId).values,u=sizeFromShape(o.shape),c=n||o.dtype,p=getArrayFromDType(c,u);for(let e=0;e<u;++e)p[e]=t(l[e],a);return i.makeTensorInfo(o.shape,c,p)}}function unaryKernelFuncFromImpl(e,t,n){return({inputs:r,attrs:a,backend:s})=>{const{x:o}=r;if(assertNotComplex$1(o,e),"string"===o.dtype||"string"===n)throw new Error("unaryKernelFunc does not support string input/output");const i=s,l=i.data.get(o.dataId).values,u=n||o.dtype,c=t(l,u,a);return i.makeTensorInfo(o.shape,u,c)}}const ceilImpl=createSimpleUnaryImpl(e=>Math.ceil(e)),ceil$1=unaryKernelFuncFromImpl(Ceil,ceilImpl),ceilConfig$1={kernelName:Ceil,backendName:"cpu",kernelFunc:ceil$1};function concatImpl$1(e,t,n,r){const a=getArrayFromDType(n,sizeFromShape(t));if(r&&"string"!==n){let t=0;e.forEach(e=>{const n=sizeFromShape(e.shape);a.set(e.vals,t),t+=n})}else{let r=0;e.forEach(e=>{const s="string"===n?fromUint8ToStringArray(e.vals):e.vals;let o=0;for(let n=0;n<e.shape[0];++n){const i=n*t[1]+r;for(let t=0;t<e.shape[1];++t)a[i+t]=s[o++]}r+=e.shape[1]})}return a}const equalImpl=createSimpleBinaryKernelImpl((e,t)=>e===t?1:0),equal$1=binaryKernelFunc$1(Equal,equalImpl,null,"bool"),equalConfig$1={kernelName:Equal,backendName:"cpu",kernelFunc:equal$1},expImpl=createSimpleUnaryImpl(e=>Math.exp(e)),exp$1=unaryKernelFuncFromImpl(Exp,expImpl),expConfig$1={kernelName:Exp,backendName:"cpu",kernelFunc:exp$1},expm1Impl=createSimpleUnaryImpl(e=>Math.expm1(e)),expm1$1=unaryKernelFuncFromImpl(Expm1,expm1Impl),expm1Config$1={kernelName:Expm1,backendName:"cpu",kernelFunc:expm1$1},floorImpl=createSimpleUnaryImpl(e=>Math.floor(e)),floor$1=unaryKernelFuncFromImpl(Floor,floorImpl),floorConfig$1={kernelName:Floor,backendName:"cpu",kernelFunc:floor$1};function gatherNdImpl(e,t,n,r,a,s,o,i,l){const u=buffer([r,s],n);for(let n=0;n<r;n++){const r=[];let c=0;for(let t=0;t<a;t++){const s=e[n*a+t];c+=s*o[t],r.push(s)}if(c<0||c>=l/s)throw new Error(`Invalid indices: ${r} does not index into ${i}`);for(let e=0;e<s;e++)u.values[n*s+e]=t.get(...t.indexToLoc(c*s+e))}return u}function gatherV2Impl(e,t,n){const r=buffer(n,e.dtype);for(let n=0;n<r.size;++n){const a=r.indexToLoc(n).slice(),s=t.locToIndex([a[0],a[2]]);a[2]=t.values[s];const o=e.locToIndex(a);r.values[n]=e.values[o]}return r}const greaterImpl=createSimpleBinaryKernelImpl((e,t)=>e>t?1:0),greater$1=binaryKernelFunc$1(Greater,greaterImpl,null,"bool"),greaterConfig$1={kernelName:Greater,backendName:"cpu",kernelFunc:greater$1},greaterEqualImpl=createSimpleBinaryKernelImpl((e,t)=>e>=t?1:0),greaterEqual$1=binaryKernelFunc$1(GreaterEqual,greaterEqualImpl,null,"bool"),greaterEqualConfig$1={kernelName:GreaterEqual,backendName:"cpu",kernelFunc:greaterEqual$1},lessImpl=createSimpleBinaryKernelImpl((e,t)=>e<t?1:0),less$1=binaryKernelFunc$1(Less,lessImpl,null,"bool"),lessConfig$1={kernelName:Less,backendName:"cpu",kernelFunc:less$1},lessEqualImpl=createSimpleBinaryKernelImpl((e,t)=>e<=t?1:0),lessEqual$1=binaryKernelFunc$1(LessEqual,lessEqualImpl,null,"bool"),lessEqualConfig$1={kernelName:LessEqual,backendName:"cpu",kernelFunc:lessEqual$1};function linSpaceImpl(e,t,n){const r=(t-e)/(n-1),a=makeZerosTypedArray(n,"float32");a[0]=e;for(let e=1;e<a.length;e++)a[e]=a[e-1]+r;return a}const logImpl=createSimpleUnaryImpl(e=>Math.log(e)),log$1=unaryKernelFuncFromImpl(Log,logImpl),logConfig$1={kernelName:Log,backendName:"cpu",kernelFunc:log$1};function maxImpl$1(e,t,n,r){const a=getTypedArrayFromDType(r,sizeFromShape(n));for(let n=0;n<a.length;++n){const r=n*t;let s=e[r];for(let n=0;n<t;++n){const t=e[r+n];(Number.isNaN(t)||t>s)&&(s=t)}a[n]=s}return a}const maximumImpl=createSimpleBinaryKernelImpl((e,t)=>Math.max(e,t)),maximum$1=binaryKernelFunc$1(Maximum$1,maximumImpl),maximumConfig$1={kernelName:Maximum$1,backendName:"cpu",kernelFunc:maximum$1},minimumImpl=createSimpleBinaryKernelImpl((e,t)=>Math.min(e,t)),minimum$1=binaryKernelFunc$1(Minimum$1,minimumImpl),minimumConfig$1={kernelName:Minimum$1,backendName:"cpu",kernelFunc:minimum$1},multiplyImpl=createSimpleBinaryKernelImpl((e,t)=>e*t),multiplyComplexImpl=createComplexBinaryKernelImpl((e,t,n,r)=>({real:e*n-t*r,imag:e*r+t*n})),multiply$1=binaryKernelFunc$1(Multiply$1,multiplyImpl,multiplyComplexImpl),multiplyConfig$1={kernelName:Multiply$1,backendName:"cpu",kernelFunc:multiply$1};function negImpl(e,t,n){const r=createScalarValue(-1,n);return multiplyImpl([],t,r,e,n)}function neg$1(e){const{inputs:t,backend:n}=e,{x:r}=t;assertNotComplex$1(r,"neg");const a=n.data.get(r.dataId).values,[s,o]=negImpl(a,r.shape,r.dtype);return n.makeTensorInfo(o,r.dtype,s)}const negConfig$1={kernelName:Neg,backendName:"cpu",kernelFunc:neg$1},notEqualImpl=createSimpleBinaryKernelImpl((e,t)=>e!==t?1:0),notEqual$1=binaryKernelFunc$1(NotEqual,notEqualImpl,null,"bool"),notEqualConfig$1={kernelName:NotEqual,backendName:"cpu",kernelFunc:notEqual$1};function transposeImpl$1(e,t,n,r,a){const s=t.length,o=sizeFromShape(t),i=computeStrides(t),l=computeStrides(a),u=getTypedArrayFromDType(n,sizeFromShape(a));for(let t=0;t<o;++t){const n=indexToLoc(t,s,i),a=new Array(n.length);for(let e=0;e<a.length;e++)a[e]=n[r[e]];u[locToIndex(a,s,l)]=e[t]}return u}function transpose$1(e){const{inputs:t,attrs:n,backend:r}=e,{x:a}=t,{perm:s}=n;assertNotComplex$1(a,"transpose");const o=new Array(a.shape.length);for(let e=0;e<o.length;e++)o[e]=a.shape[s[e]];const i=transposeImpl$1(r.data.get(a.dataId).values,a.shape,a.dtype,s,o);return{dataId:r.write(i,o,a.dtype),shape:o,dtype:a.dtype}}const transposeConfig$1={kernelName:Transpose,backendName:"cpu",kernelFunc:transpose$1};function prodImpl(e,t,n,r){const[a,s]=computeOutAndReduceShapes(e,r),o=upcastType(t,"int32"),i=makeZerosTypedArray(sizeFromShape(a),o),l=sizeFromShape(s);for(let e=0;e<i.length;++e){const t=e*l;let r=1;for(let e=0;e<l;++e)r*=n[t+e];i[e]=r}return{outVals:i,outShape:a,outDtype:o}}function prod$1(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{axis:s,keepDims:o}=r;assertNotComplex$1(a,"prod");const i=a.shape.length,l=parseAxisParam(s,a.shape),u=getAxesPermutation(l,i);let c=l,p=a;const d=[];null!=u&&(p=transpose$1({inputs:{x:a},backend:n,attrs:{perm:u}}),d.push(p),c=getInnerMostAxes(c.length,i));const h=n.data.get(p.dataId).values,{outVals:m,outShape:f,outDtype:g}=prodImpl(p.shape,p.dtype,h,c);let $=f;return o&&($=expandShapeToKeepDim(f,l)),d.forEach(e=>n.disposeIntermediateTensorInfo(e)),n.makeTensorInfo($,g,m)}const prodConfig$1={kernelName:Prod,backendName:"cpu",kernelFunc:prod$1};function rangeImpl(e,t,n,r){if(e===t||e<t&&n<0||t<e&&n>1)return makeZerosTypedArray(0,r);const a=makeZerosTypedArray(Math.abs(Math.ceil((t-e)/n)),r);t<e&&1===n&&(n=-1),a[0]=e;for(let e=1;e<a.length;e++)a[e]=a[e-1]+n;return a}const rsqrtImpl=createSimpleUnaryImpl(e=>1/Math.sqrt(e)),rsqrt$1=unaryKernelFuncFromImpl(Rsqrt,rsqrtImpl),rsqrtConfig$1={kernelName:Rsqrt,backendName:"cpu",kernelFunc:rsqrt$1};function sliceImpl(e,t,n,r,a){const s=isSliceContinous(r,t,n),o=sizeFromShape(n),i=computeStrides(r);if(s){const n=computeFlatOffset(t,i);return"string"===a?e.slice(n,n+o):e.subarray(n,n+o)}const l=buffer(r,a,"string"===a?fromUint8ToStringArray(e):e),u=buffer(n,a);for(let e=0;e<u.size;++e){const n=u.indexToLoc(e),r=n.map((e,n)=>e+t[n]);u.set(l.get(...r),...n)}return"string"===a?fromStringArrayToUint8(u.values):u.values}function slice$1(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{begin:s,size:o}=r;assertNotComplex$1(a,"slice");const[i,l]=parseSliceParams(a,s,o);assertParamsValid(a,i,l);const u=sliceImpl(n.data.get(a.dataId).values,i,l,a.shape,a.dtype);return n.makeTensorInfo(l,a.dtype,u)}const sliceConfig$1={kernelName:Slice,backendName:"cpu",kernelFunc:slice$1};function sparseFillEmptyRowsImpl(e,t,n,r,a,s,o){const i=t[0],l=s[0],u=new Array(l),c=new Array(i),p=t[1];if(0===l){if(0!==i)throw new Error(`Received SparseTensor with denseShape[0] = 0 but\n         indices.shape[0] = ${i}`);return[getArrayFromDType(n,0),[0,p],getArrayFromDType(a,0),u,c]}let d=!0,h=0;const m=new Array(l).fill(0);for(let t=0;t<i;++t){const n=e[t*p];if(n<0)throw new Error(`indices(${t}, 0) is invalid: ${n} < 0`);if(n>=l)throw new Error(`indices(${t}, 0) is invalid: ${n} >= ${l}`);++m[n],d=d&&n>=h,h=n}let f=!0;for(let e=0;e<l;++e){const t=0===m[e];u[e]=t,f=f&&!t,m[e]=Math.max(m[e],1),e>0&&(m[e]+=m[e-1])}if(f&&d){const t=e,n=r;for(let e=0;e<i;++e)c[e]=e;return[t,[i,p],n,u,c]}{const t=m[l-1],s=getArrayFromDType(n,t*p),d=getArrayFromDType(a,t),h=new Array(l).fill(0);for(let t=0;t<i;++t){const n=e[t*p],a=(0===n?0:m[n-1])+h[n];h[n]++;for(let n=0;n<p;++n)s[a*p+n]=e[t*p+n];d[a]=r[t],c[t]=a}for(let e=0;e<l;++e)if(0===h[e]){const t=0===e?0:m[e-1];s[t*p+0]=e;for(let e=1;e<p;++e)s[t*p+e]=0;d[t]=o}return[s,[t,p],d,u,c]}}function sparseReshapeImpl(e,t,n,r,a){const s=sizeFromShape(r),o=t[0],i=a.length,l=[];let u=1,c=-1;for(let e=0;e<i;++e){const t=a[e];if(-1===t){if(-1!==c)throw new Error(`only one output dimension may be -1, not both ${c} and ${e}`);c=e,l.push(1)}else{if(t<0)throw new Error(`size ${e} must be non-negative, not ${t}`);u*=t,l.push(t)}}if(-1!==c){if(u<=0)throw new Error("reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero");const e=Math.trunc(s/u);if(u*e!==s)throw new Error(`Input to reshape is a SparseTensor with ${s}\n          dense values, but the requested shape requires a multiple of ${u}. inputShape=${r} outputShape= ${l}`);l[c]=e}const p=sizeFromShape(l);if(p!==s)throw new Error(`Input to reshape is a tensor with ${s} dense values, but the requested shape has ${p}. inputShape=${r} outputShape=${l}`);const d=r.length,h=[];if(d>0){h[d-1]=1;for(let e=d-2;e>=0;--e)h[e]=h[e+1]*r[e+1]}const m=[];if(i>0){m[i-1]=1;for(let e=i-2;e>=0;--e)m[e]=m[e+1]*l[e+1]}const f=getArrayFromDType(n,o*i);for(let t=0;t<o;++t){let n=0;for(let r=0;r<d;++r)n+=e[t*d+r]*h[r];for(let e=0;e<i;++e)f[t*i+e]=Math.trunc(n/m[e]),n%=m[e]}return[f,[o,i],l]}function sparseSegmentReductionImpl(e,t,n,r,a,s=!1,o=0){const i=r.length;if(i!==a.length)throw new Error("segmentIds and indices should have same size.");const l=[t[0],e.length/t[0]],u=l[1],c=i>0?a[i-1]+1:0;if(c<0)throw new Error("segment ids must be >= 0");const p=t.slice();p[0]=c;const d=getArrayFromDType(n,p.reduce((e,t)=>e*t,1));if(0===i)return c>0&&d.fill(o),[d,p];if(c<=0)throw new Error("segment ids must be >= 0");let h=0,m=1,f=0,g=a[h];for(;;){let t=0;if(m<i){if(t=a[m],g===t){++m;continue}if(g>=t)throw new Error("segment ids are not increasing")}if(g<0||g>=c)throw new Error(`Segment id ${g} out of range [0, ${c}), possibly because segmentIds input is not sorted.`);g>f&&d.fill(o,f*u,g*u);for(let t=h;t<m;++t){const n=r[t];if(n<0||n>=l[0])throw new Error(`Bad: indices[${t}] == ${r[t]} out of range [0, ${l[0]})`);for(let t=0;t<u;t++)d[g*u+t]+=e[n*u+t]}if(s)for(let e=0;e<u;e++)d[g*u+e]/=m-h;if(h=m,++m,f=g+1,g=t,m>i)break}return f<c&&d.fill(o,f*u,c*u),[d,p]}const squaredDifferenceImpl=createSimpleBinaryKernelImpl((e,t)=>{const n=e-t;return n*n}),squaredDifference$1=binaryKernelFunc$1(SquaredDifference,squaredDifferenceImpl),squaredDifferenceConfig$1={kernelName:SquaredDifference,backendName:"cpu",kernelFunc:squaredDifference$1};function stridedSliceImpl(e,t,n,r){const a=buffer(e,t.dtype);for(let e=0;e<a.size;e++){const s=a.indexToLoc(e),o=new Array(s.length);for(let e=0;e<o.length;e++)o[e]=s[e]*n[e]+r[e];a.set(t.get(...o),...s)}return a}class StringNGramsOp{constructor(e,t,n,r,a,s){this.separator=encodeString(e),this.nGramWidths=t,this.leftPad=encodeString(n),this.rightPad=encodeString(r),this.padWidth=a,this.preserveShort=s}getPadWidth(e){return Math.min(this.padWidth<0?e-1:this.padWidth,e-1)}getNumNGrams(e,t){const n=this.getPadWidth(t);return Math.max(0,e+2*n-t+1)}createNGrams(e,t,n,r,a,s){for(let o=0;o<a;++o){const i=this.getPadWidth(s),l=Math.max(0,i-o),u=Math.max(0,i-(a-(o+1))),c=s-(l+u),p=t+(l>0?0:o-i);let d=0;d+=l*this.leftPad.length;for(let t=0;t<c;++t)d+=e[p+t].length;d+=u*this.rightPad.length,d+=(l+u+c-1)*this.separator.length,n[r+o]=new Uint8Array(d);const h=n[r+o];let m=0;const f=e=>e.forEach(e=>h[m++]=e);for(let e=0;e<l;++e)f(this.leftPad),f(this.separator);for(let t=0;t<c-1;++t)f(e[p+t]),f(this.separator);if(c>0){f(e[p+c-1]);for(let e=0;e<u;++e)f(this.separator),f(this.rightPad)}else{for(let e=0;e<u-1;++e)f(this.rightPad),f(this.separator);f(this.rightPad)}}}compute(e,t){const n=e.length,r=t.length;if(r>0){let e=t[0];if(0!==e)throw new Error(`First split value must be 0, got ${e}`);for(let a=1;a<r;++a){let r=t[a]>=e;if(r=r&&t[a]<=n,!r)throw new Error(`Invalid split value ${t[a]}, must be in [${e}, ${n}]`);e=t[a]}if(e!==n)throw new Error(`Last split value must be data size. Expected ${n}, got ${e}`)}const a=r-1,s=getArrayFromDType("int32",r);if(0===n||0===r){const e=new Array(n);for(let e=0;e<=a;++e)s[e]=0;return[e,s]}s[0]=0;for(let e=1;e<=a;++e){const n=t[e]-t[e-1];let r=0;this.nGramWidths.forEach(e=>{r+=this.getNumNGrams(n,e)}),this.preserveShort&&n>0&&0===r&&(r=1),s[e]=s[e-1]+r}const o=new Array(s[a]);for(let n=0;n<a;++n){const r=t[n];let a=s[n];if(this.nGramWidths.forEach(s=>{const i=this.getNumNGrams(t[n+1]-t[n],s);this.createNGrams(e,r,o,a,i,s),a+=i}),this.preserveShort&&a===s[n]){const s=t[n+1]-t[n];if(0===s)continue;this.createNGrams(e,r,o,a,1,s+2*this.padWidth)}}return[o,s]}}function stringNGramsImpl(e,t,n,r,a,s,o,i){return new StringNGramsOp(n,r,a,s,o,i).compute(e,t)}function split(e,t,n){if(!e.length)return[];if(0===t.length){const t=new Array(e.length);for(let n=0;n<e.length;++n)t[n]=e.subarray(n,n+1);return t}if(1===t.length){const r=t[0],a=[];let s=e.indexOf(r);for(;-1!==s;){const t=e.subarray(0,s);n&&0===t.length||a.push(t),s=(e=e.subarray(s+1)).indexOf(r)}return n&&0===e.length||a.push(e),a}const r=[];let a=0;for(let s=0;s<e.length+1;s++)if(s===e.length||-1!==t.indexOf(e[s])){const t=e.subarray(a,s);n&&0===t.length||r.push(t),a=s+1}return r}function stringSplitImpl(e,t,n){const r=e.length,a=[];let s=0,o=0;const i=new Array(r);for(let l=0;l<r;++l){const r=split(e[l],t,n),u=r.length;i[l]=u,s+=u,o=Math.max(o,u),a.push(...r)}const l=getArrayFromDType("int32",2*s),u=new Array(s),c=[r,o];let p=0;for(let e=0;e<r;++e)for(let t=0;t<i[e];++t)l[2*p]=e,l[2*p+1]=t,u[p]=a[p],++p;return[l,u,c]}function stringToHashBucketFastImpl(e,t){const n=getArrayFromDType("int32",e.length);for(let r=0;r<e.length;++r)n[r]=fingerPrint64(e[r]).modulo(t).getLowBitsUnsigned();return n}const subImpl=createSimpleBinaryKernelImpl((e,t)=>e-t),subComplexImpl=createComplexBinaryKernelImpl((e,t,n,r)=>({real:e-n,imag:t-r})),sub$1=binaryKernelFunc$1(Sub,subImpl,subComplexImpl),subConfig$1={kernelName:Sub,backendName:"cpu",kernelFunc:sub$1};function tileImpl(e,t){const n=new Array(e.rank);for(let r=0;r<n.length;r++)n[r]=e.shape[r]*t[r];const r=buffer(n,e.dtype);for(let t=0;t<r.values.length;++t){const n=r.indexToLoc(t),a=new Array(e.rank);for(let t=0;t<a.length;t++)a[t]=n[t]%e.shape[t];const s=e.locToIndex(a);r.values[t]=e.values[s]}return r}const comparePair=(e,t)=>{const n=t.value-e.value;return 0===n?e.index-t.index:n};function select$2(e,t,n=0,r=e.length-1){for(;r>n;){if(r-n>600){const a=r-n+1,s=t-n+1,o=Math.log(a),i=.5*Math.exp(2*o/3),l=.5*Math.sqrt(o*i*(a-i)/a)*Math.sign(s-a/2);select$2(e,t,Math.max(n,Math.floor(t-s*i/a+l)),Math.min(r,Math.floor(t+(a-s)*i/a+l)))}const a=e[t];let s=n,o=r;for(swap(e,n,t),comparePair(e[r],a)>0&&swap(e,n,r);s<o;){for(swap(e,s,o),s++,o--;comparePair(e[s],a)<0;)s+=1;for(;comparePair(e[o],a)>0;)o-=1}0===comparePair(e[n],a)?swap(e,n,o):(o+=1,swap(e,o,r)),o<=t&&(n=o+1),t<=o&&(r=o-1)}}function topKImpl(e,t,n,r,a){const s=t[t.length-1],[o,i]=[e.length/s,s],l=getTypedArrayFromDType(n,o*r),u=getTypedArrayFromDType("int32",o*r);for(let t=0;t<o;t++){const n=t*i,s=e.subarray(n,n+i);let o=new Array(s.length);s.forEach((e,t)=>o[t]={value:e,index:t}),r<o.length&&(select$2(o,r),o=o.slice(0,r)),a&&o.sort(comparePair);const c=t*r,p=l.subarray(c,c+r),d=u.subarray(c,c+r);for(let e=0;e<r;e++)p[e]=o[e].value,d[e]=o[e].index}const c=t.slice();return c[c.length-1]=r,[buffer(c,n,l),buffer(c,"int32",u)]}function uniqueImpl(e,t,n,r){const a=parseAxisParam(t,n)[0],s=[1,n[0],1];for(let e=0;e<a;e++)s[0]*=n[e];s[1]=n[a];for(let e=a+1;e<n.length;e++)s[2]*=n[e];const o={},i=new Int32Array(n[a]),l=new TensorBuffer(s,r,e),u=[],c=1===s[0]&&1===s[2];for(let t=0;t<n[a];t++){let n;if(c)n=e[t].toString();else{const e=[];for(let n=0;n<s[0];n++)for(let r=0;r<s[2];r++)e.push(l.get(n,t,r));n=e.join(",")}if(void 0!==o[n])i[t]=o[n];else{const e=Object.keys(o).length;o[n]=e,i[t]=e,u.push(t)}}const p=s.slice();p[1]=Object.keys(o).length;const d=new TensorBuffer(p,r);u.forEach((e,t)=>{for(let n=0;n<s[0];n++)for(let r=0;r<s[2];r++)d.set(l.get(n,e,r),n,t,r)});const h=n.slice();return h[a]=p[1],{outputValues:d.values,outputShape:h,indices:i}}var shared={__proto__:null,simpleAbsImpl,addImpl,bincountImpl,bincountReduceImpl,ceilImpl,concatImpl:concatImpl$1,equalImpl,expImpl,expm1Impl,floorImpl,gatherNdImpl,gatherV2Impl,greaterImpl,greaterEqualImpl,lessImpl,lessEqualImpl,linSpaceImpl,logImpl,maxImpl:maxImpl$1,maximumImpl,minimumImpl,multiplyImpl,negImpl,notEqualImpl,prodImpl,rangeImpl,rsqrtImpl,sliceImpl,sparseFillEmptyRowsImpl,sparseReshapeImpl,sparseSegmentReductionImpl,squaredDifferenceImpl,stridedSliceImpl,stringNGramsImpl,stringSplitImpl,stringToHashBucketFastImpl,subImpl,tileImpl,topKImpl,transposeImpl:transposeImpl$1,uniqueImpl};const version$3="3.8.0";registerBackend("cpu",()=>new MathBackendCPU,1);const elu$1=unaryKernelFunc$1(Elu$1,e=>e>=0?e:Math.exp(e)-1),eluConfig$1={kernelName:Elu$1,backendName:"cpu",kernelFunc:elu$1};function leakyRelu$1(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{alpha:s}=r;assertNotComplex$1([a],"leakyRelu");const o=sizeFromShape(a.shape),i=n.data.get(a.dataId).values,l=getTypedArrayFromDType("float32",o);for(let e=0;e<i.length;e++)l[e]=i[e]<0?s*i[e]:i[e];return n.makeTensorInfo(a.shape,"float32",l)}const leakyReluConfig$1={kernelName:LeakyRelu,backendName:"cpu",kernelFunc:leakyRelu$1},preluImpl=createSimpleBinaryKernelImpl((e,t)=>e<0?t*e:e);function prelu$1(e){const{inputs:t,backend:n}=e,{x:r,alpha:a}=t;assertNotComplex$1([r,a],"prelu");const s=n.data.get(r.dataId).values,o=n.data.get(a.dataId).values,[i,l]=preluImpl(r.shape,a.shape,s,o,r.dtype);return n.makeTensorInfo(l,r.dtype,i)}const preluConfig$1={kernelName:Prelu,backendName:"cpu",kernelFunc:prelu$1},relu$2=unaryKernelFunc$1(Relu$1,e=>Math.max(0,e)),reluConfig$1={kernelName:Relu$1,backendName:"cpu",kernelFunc:relu$2},relu6$1=unaryKernelFunc$1(Relu6$1,e=>Math.min(Math.max(0,e),6)),relu6Config$1={kernelName:Relu6$1,backendName:"cpu",kernelFunc:relu6$1},sigmoid$1=unaryKernelFunc$1(Sigmoid$1,e=>1/(1+Math.exp(-e))),sigmoidConfig$1={kernelName:Sigmoid$1,backendName:"cpu",kernelFunc:sigmoid$1};function applyActivation(e,t,n,r,a){if("linear"===n)return identity$1({inputs:{x:t},backend:e});if("relu"===n)return relu$2({inputs:{x:t},backend:e});if("elu"===n)return elu$1({inputs:{x:t},backend:e});if("relu6"===n)return relu6$1({inputs:{x:t},backend:e});if("prelu"===n)return prelu$1({inputs:{x:t,alpha:r},backend:e});if("leakyrelu"===n)return leakyRelu$1({inputs:{x:t},backend:e,attrs:{alpha:a}});if("sigmoid"===n)return sigmoid$1({inputs:{x:t},backend:e});throw new Error(`Activation ${n} has not been implemented for the CPU backend.`)}function reshape$1(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{shape:s}=r,o=sizeFromShape(a.shape),i=inferFromImplicitShape(s,o),l=sizeFromShape(i);assert$4(o===l,()=>`The new shape (${i}) has ${l} elements and the old shape (${a.shape}) has ${o} elements. The new shape and old shape must have the same number of elements.`),n.incRef(a.dataId);const u=n.data.get(a.dataId);if(null!=u.complexTensorInfos){const e=u.complexTensorInfos.imag;u.complexTensorInfos.real.shape=i,e.shape=i}return{dataId:a.dataId,shape:i,dtype:a.dtype}}const reshapeConfig$1={kernelName:Reshape$1,backendName:"cpu",kernelFunc:reshape$1};function batchMatMul$1(e){const{inputs:t,backend:n,attrs:r}=e,{a,b:s}=t,{transposeA:o,transposeB:i}=r;assertNotComplex$1([a,s],"matMul");const l=a.shape.length,u=s.shape.length,c=o?a.shape[l-2]:a.shape[l-1],p=i?s.shape[u-1]:s.shape[u-2],d=o?a.shape[l-1]:a.shape[l-2],h=i?s.shape[u-2]:s.shape[u-1],m=a.shape.slice(0,-2),f=s.shape.slice(0,-2),g=sizeFromShape(m),$=sizeFromShape(f);assert$4(l>=2&&u>=2&&(g===$||1===g||1===$),()=>`Error in matMul: the input batch dimensions must either be the same or at least one input batch dimension must be 1. Got input batch dimensions of (${m}) and (${f}).`);const y=(g>$?a.shape.slice(0,-2):s.shape.slice(0,-2)).concat([d,h]);assert$4(c===p,()=>`Error in matMul: inner shapes (${c}) and (${p}) of Tensors with shapes ${a.shape} and ${s.shape} and transposeA=${o} and transposeB=${i} must match.`);const b=i?[$,h,p]:[$,p,h],x=reshape$1({inputs:{x:a},backend:n,attrs:{shape:o?[g,c,d]:[g,d,c]}}),v=reshape$1({inputs:{x:s},backend:n,attrs:{shape:b}}),I=o?x.shape[1]:x.shape[2],C=o?x.shape[2]:x.shape[1],S=i?v.shape[1]:v.shape[2],k=Math.max(g,$),T=n.data.get(x.dataId).values,N=n.data.get(v.dataId).values,w=computeStrides(x.shape),E=computeStrides(v.shape),[A,D,R]=o?[w[0],1,w[1]]:[w[0],w[1],1],[_,F,P]=i?[1,E[1],E[0]]:[E[1],1,E[0]],O=C*S,M=buffer([k,C,S],x.dtype),L=M.values,z=n.blockSize;for(let e=0;e<k;e++)for(let t=0;t<C;t+=z)for(let n=0;n<S;n+=z)for(let r=0;r<I;r+=z){const a=Math.min(t+z,C),s=Math.min(n+z,S),o=Math.min(r+z,I);for(let i=t;i<a;i++)for(let t=n;t<s;t++){let n=0;for(let a=r;a<o;a++){const r=Math.min(e,g-1)*A,s=Math.min(e,$-1)*P;n+=T[r+i*D+a*R]*N[a*_+t*F+s]}L[e*O+(i*S+t)]+=n}}return n.disposeIntermediateTensorInfo(x),n.disposeIntermediateTensorInfo(v),n.makeTensorInfo(y,M.dtype,M.values)}const batchMatMulConfig$1={kernelName:BatchMatMul,backendName:"cpu",kernelFunc:batchMatMul$1};function _fusedMatMul$1(e){const{inputs:t,backend:n,attrs:r}=e,{a,b:s,bias:o,preluActivationWeights:i}=t,{transposeA:l,transposeB:u,activation:c,leakyreluAlpha:p}=r;let d,h,m;const f=[];d=batchMatMul$1({inputs:{a,b:s},attrs:{transposeA:l,transposeB:u},backend:n}),o&&(h=add({inputs:{a:d,b:o},backend:n}),f.push(d),d=h),c&&(m=applyActivation(n,d,c,i,p),f.push(d),d=m);for(const e of f)n.disposeIntermediateTensorInfo(e);return d}const _fusedMatMulConfig$1={kernelName:_FusedMatMul,backendName:"cpu",kernelFunc:_fusedMatMul$1},acos$1=unaryKernelFunc$1(Acos,e=>Math.acos(e)),acosConfig$1={kernelName:Acos,backendName:"cpu",kernelFunc:acos$1},acosh$1=unaryKernelFunc$1(Acosh,e=>Math.acosh(e)),acoshConfig$1={kernelName:Acosh,backendName:"cpu",kernelFunc:acosh$1};function addN$1(e){const{inputs:t,backend:n}=e,r=t;assertNotComplex$1(t,"addN");const a=r.map(e=>n.data.get(e.dataId).values),s=buffer(r[0].shape,r[0].dtype),o=s.values;for(let e=0;e<r.length;e++){const t=a[e];for(let e=0;e<o.length;e++)o[e]+=t[e]}return n.makeTensorInfo(s.shape,s.dtype,s.values)}const addNConfig$1={kernelName:AddN,backendName:"cpu",kernelFunc:addN$1};function all$1(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{axis:s,keepDims:o}=r;assertNotComplex$1(a,"all");const i=parseAxisParam(s,a.shape);let l=i;const u=getAxesPermutation(l,a.shape.length);let c=a;null!=u&&(c=transpose$1({inputs:{x:a},backend:n,attrs:{perm:u}}),l=getInnerMostAxes(l.length,a.shape.length)),assertAxesAreInnerMostDims("all",l,c.shape.length);const[p,d]=computeOutAndReduceShapes(c.shape,l),h=sizeFromShape(d),m=makeZerosTypedArray(sizeFromShape(p),c.dtype),f=n.data.get(c.dataId).values;for(let e=0;e<m.length;++e){const t=e*h;let n=f[t];for(let e=0;e<h;++e){const r=f[t+e];n=n&&r}m[e]=n}null!=u&&n.disposeIntermediateTensorInfo(c);const g=n.makeTensorInfo(p,c.dtype,m);if(o){const e=reshape$1({inputs:{x:g},backend:n,attrs:{shape:expandShapeToKeepDim(p,i)}});return n.disposeIntermediateTensorInfo(g),e}return g}const allConfig$1={kernelName:All,backendName:"cpu",kernelFunc:all$1};function any$1(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{axis:s,keepDims:o}=r;assertNotComplex$1(a,"any");const i=parseAxisParam(s,a.shape);let l=i;const u=getAxesPermutation(l,a.shape.length);let c=a;null!=u&&(c=transpose$1({inputs:{x:a},backend:n,attrs:{perm:u}}),l=getInnerMostAxes(l.length,a.shape.length)),assertAxesAreInnerMostDims("any",l,c.shape.length);const[p,d]=computeOutAndReduceShapes(c.shape,l),h=sizeFromShape(d),m=makeZerosTypedArray(sizeFromShape(p),c.dtype),f=n.data.get(c.dataId).values;for(let e=0;e<m.length;++e){const t=e*h;let n=f[t];for(let e=0;e<h;++e){const r=f[t+e];n=n||r}m[e]=n}null!=u&&n.disposeIntermediateTensorInfo(c);const g=n.makeTensorInfo(p,c.dtype,m);if(o){const e=reshape$1({inputs:{x:g},backend:n,attrs:{shape:expandShapeToKeepDim(p,i)}});return n.disposeIntermediateTensorInfo(g),e}return g}const anyConfig$1={kernelName:Any,backendName:"cpu",kernelFunc:any$1};function argMax$1(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{axis:s}=r;assertNotComplex$1(a,"argMax");let o=parseAxisParam(s,a.shape);const i=getAxesPermutation(o,a.shape.length);let l=a;const u=[];null!=i&&(l=transpose$1({inputs:{x:a},backend:n,attrs:{perm:i}}),u.push(l),o=getInnerMostAxes(o.length,l.shape.length)),o=[o[0]],assertAxesAreInnerMostDims("argMax",o,l.shape.length);const[c,p]=computeOutAndReduceShapes(l.shape,o),d=makeZerosTypedArray(sizeFromShape(c),"int32"),h=sizeFromShape(p),m=n.data.get(l.dataId).values;for(let e=0;e<d.length;++e){const t=e*h;let n=m[t],r=0;for(let e=0;e<h;++e){const a=m[t+e];a>n&&(n=a,r=e)}d[e]=r}return u.forEach(e=>n.disposeIntermediateTensorInfo(e)),n.makeTensorInfo(c,"int32",d)}const argMaxConfig$1={kernelName:ArgMax,backendName:"cpu",kernelFunc:argMax$1};function argMin$1(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{axis:s}=r;assertNotComplex$1(a,"argMin");let o=parseAxisParam(s,a.shape);const i=getAxesPermutation(o,a.shape.length);let l=a;const u=[];null!=i&&(l=transpose$1({inputs:{x:a},backend:n,attrs:{perm:i}}),u.push(l),o=getInnerMostAxes(o.length,l.shape.length)),o=[o[0]],assertAxesAreInnerMostDims("argMin",o,l.shape.length);const[c,p]=computeOutAndReduceShapes(l.shape,o),d=makeZerosTypedArray(sizeFromShape(c),"int32"),h=sizeFromShape(p),m=n.data.get(l.dataId).values;for(let e=0;e<d.length;++e){const t=e*h;let n=m[t],r=0;for(let e=0;e<h;++e){const a=m[t+e];a<n&&(n=a,r=e)}d[e]=r}return u.forEach(e=>n.disposeIntermediateTensorInfo(e)),n.makeTensorInfo(c,"int32",d)}const argMinConfig$1={kernelName:ArgMin,backendName:"cpu",kernelFunc:argMin$1},asin$1=unaryKernelFunc$1(Asin,e=>Math.asin(e)),asinConfig$1={kernelName:Asin,backendName:"cpu",kernelFunc:asin$1},asinh$1=unaryKernelFunc$1(Asinh,e=>Math.asinh(e)),asinhConfig$1={kernelName:Asinh,backendName:"cpu",kernelFunc:asinh$1},atan$1=unaryKernelFunc$1(Atan,e=>Math.atan(e)),atanConfig$1={kernelName:Atan,backendName:"cpu",kernelFunc:atan$1},atan2Impl=createSimpleBinaryKernelImpl((e,t)=>Math.atan2(e,t)),atan2$1=binaryKernelFunc$1(Atan2,atan2Impl),atan2Config$1={kernelName:Atan2,backendName:"cpu",kernelFunc:atan2$1},atanh$1=unaryKernelFunc$1(Atanh,e=>Math.atanh(e)),atanhConfig$1={kernelName:Atanh,backendName:"cpu",kernelFunc:atanh$1};function pool(e,t,n,r,a,s){const o=a.strideHeight,i=a.strideWidth,l=a.dilationHeight,u=a.dilationWidth,c=a.effectiveFilterHeight,p=a.effectiveFilterWidth,d=a.padInfo.top,h=a.padInfo.left,m="max"===s?Number.NEGATIVE_INFINITY:Number.POSITIVE_INFINITY,f=buffer(a.outShape,n),g=f.values,$=a.outShape[1]*a.outShape[2]*a.outShape[3],y=a.outShape[2]*a.outShape[3],b=a.outShape[3];for(let t=0;t<a.batchSize;++t){const n=t*$,f=t*r[0];for(let t=0;t<a.inChannels;++t)for(let $=0;$<a.outHeight;++$){const x=$*o-d,v=Math.max(0,x),I=Math.min(a.inHeight,c+x),C=n+$*y;for(let n=0;n<a.outWidth;++n){const o=n*i-h,c=Math.max(0,o),d=Math.min(a.inWidth,p+o);let $=m,y=0,x=0;for(let n=v;n<I;n+=l){const a=f+n*r[1];for(let n=c;n<d;n+=u){const o=e[a+n*r[2]+t];"max"===s&&o>$?$=o:"avg"===s&&(y+=o,x++)}if(isNaN($))break}g[C+n*b+t]="avg"===s?y/x:$}}}return f}function maxPoolPositions(e,t,n,r,a=!1,s=!1){const o=buffer(r.outShape,"int32"),i=r.strideHeight,l=r.strideWidth,u=r.dilationHeight,c=r.dilationWidth,p=r.effectiveFilterHeight,d=r.effectiveFilterWidth,h=r.padInfo.top,m=r.padInfo.left,f=buffer(t,n,e);for(let e=0;e<r.batchSize;++e)for(let t=0;t<r.inChannels;++t)for(let n=0;n<r.outHeight;++n){const g=n*i-h;let $=g;for(;$<0;)$+=u;const y=Math.min(r.inHeight,p+g);for(let i=0;i<r.outWidth;++i){const p=i*l-m;let h=p;for(;h<0;)h+=c;const b=Math.min(r.inWidth,d+p);let x=Number.NEGATIVE_INFINITY,v=-1;for(let n=$;n<y;n+=u){const o=n-g;for(let i=h;i<b;i+=c){const l=i-p,u=f.get(e,n,i,t);u>x&&(x=u,v=a?s?((e*r.inHeight+n)*r.inWidth+i)*r.inChannels+t:(n*r.inWidth+i)*r.inChannels+t:o*d+l)}}o.set(v,e,n,i,t)}}return o}function pool3d(e,t,n,r,a,s){const o=a.strideDepth,i=a.strideHeight,l=a.strideWidth,u=a.dilationDepth,c=a.dilationHeight,p=a.dilationWidth,d=a.effectiveFilterDepth,h=a.effectiveFilterHeight,m=a.effectiveFilterWidth,f=a.padInfo.front,g=a.padInfo.top,$=a.padInfo.left,y="max"===s?Number.NEGATIVE_INFINITY:Number.POSITIVE_INFINITY,b=buffer(a.outShape,n),x=b.values,v=a.outShape[1]*a.outShape[2]*a.outShape[3]*a.outShape[4],I=a.outShape[2]*a.outShape[3]*a.outShape[4],C=a.outShape[3]*a.outShape[4],S=a.outShape[4];for(let t=0;t<a.batchSize;++t){const n=t*v,b=t*r[0];for(let t=0;t<a.inChannels;++t)for(let v=0;v<a.outDepth;++v){const k=v*o-f;let T=k;for(;T<0;)T+=u;const N=Math.min(a.inDepth,d+k),w=n+v*I;for(let n=0;n<a.outHeight;++n){const o=n*i-g;let d=o;for(;d<0;)d+=c;const f=Math.min(a.inHeight,h+o),v=w+n*C;for(let n=0;n<a.outWidth;++n){const o=n*l-$;let i=o;for(;i<0;)i+=p;const h=Math.min(a.inWidth,m+o),g=v+n*S;let I=y,C=0,k=0;for(let n=T;n<N;n+=u){const a=b+n*r[1];for(let n=d;n<f;n+=c){const o=a+n*r[2];for(let n=i;n<h;n+=p){const a=e[o+n*r[3]+t];if("max"===s&&a>I?I=a:"avg"===s&&(C+=a,k++),isNaN(I))break}if(isNaN(I))break}if(isNaN(I))break}x[g+t]="avg"===s?C/k:I}}}}return b}function maxPool3dPositions(e,t){const n=buffer(t.outShape,"int32"),r=t.strideDepth,a=t.strideHeight,s=t.strideWidth,o=t.dilationDepth,i=t.dilationHeight,l=t.dilationWidth,u=t.effectiveFilterDepth,c=t.effectiveFilterHeight,p=t.effectiveFilterWidth,d=t.padInfo.front,h=t.padInfo.top,m=t.padInfo.left;for(let f=0;f<t.batchSize;++f)for(let g=0;g<t.inChannels;++g)for(let $=0;$<t.outDepth;++$){const y=$*r-d;let b=y;for(;b<0;)b+=o;const x=Math.min(t.inDepth,u+y);for(let r=0;r<t.outHeight;++r){const u=r*a-h;let d=u;for(;d<0;)d+=i;const v=Math.min(t.inHeight,c+u);for(let a=0;a<t.outWidth;++a){const h=a*s-m;let I=h;for(;I<0;)I+=l;const C=Math.min(t.inWidth,p+h);let S=Number.NEGATIVE_INFINITY,k=-1;for(let t=b;t<x;t+=o){const n=t-y;for(let r=d;r<v;r+=i){const a=r-u;for(let s=I;s<C;s+=l){const o=s-h,i=e.get(f,t,r,s,g);i>=S&&(S=i,k=n*c*p+a*c+o)}}}n.set(k,f,$,r,a,g)}}}return n}function avgPool$1(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t;assertNotComplex$1(a,"avgPool");const{filterSize:s,strides:o,pad:i,dimRoundingMode:l}=r;assert$4(eitherStridesOrDilationsAreOne(o,1),()=>`Error in avgPool: Either strides or dilations must be 1. Got strides ${o} and dilations '1'`);const u=computePool2DInfo(a.shape,s,o,1,i,l);let c;if(1===u.filterWidth&&1===u.filterHeight&&arraysEqual(u.inShape,u.outShape))c=identity$1({inputs:{x:a},backend:n});else{const e=n.data.get(a.dataId).values,t=computeStrides(a.shape),r=pool(e,a.shape,a.dtype,t,u,"avg");c=n.makeTensorInfo(u.outShape,a.dtype,r.values)}return c}const avgPoolConfig$1={kernelName:AvgPool,backendName:"cpu",kernelFunc:avgPool$1};function avgPool3D$1(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{filterSize:s,strides:o,pad:i,dimRoundingMode:l,dataFormat:u}=r;assertNotComplex$1(a,"avgPool3d");const c=computePool3DInfo(a.shape,s,o,1,i,l,u),p=pool3d(n.data.get(a.dataId).values,a.shape,a.dtype,computeStrides(a.shape),c,"avg");return n.makeTensorInfo(p.shape,"float32",p.values)}const avgPool3DConfig$1={kernelName:AvgPool3D,backendName:"cpu",kernelFunc:avgPool3D$1};function avgPool3DGrad$1(e){const{inputs:t,backend:n,attrs:r}=e,{dy:a,input:s}=t,{filterSize:o,strides:i,pad:l,dimRoundingMode:u}=r;assertNotComplex$1([a,s],"avgPool3DGrad");const c=computePool3DInfo(s.shape,o,i,1,l,u),p=c.strideDepth,d=c.strideHeight,h=c.strideWidth,m=c.filterDepth,f=c.filterHeight,g=c.filterWidth,$=c.dilationDepth,y=c.dilationHeight,b=c.dilationWidth,x=c.effectiveFilterDepth,v=c.effectiveFilterHeight,I=c.effectiveFilterWidth,C=x-1-c.padInfo.front,S=I-1-c.padInfo.left,k=v-1-c.padInfo.top,T=buffer(s.shape,"float32"),N=1/(m*f*g),w=n.bufferSync(a);for(let e=0;e<c.batchSize;++e)for(let t=0;t<c.inChannels;++t)for(let n=0;n<c.inDepth;++n)for(let r=0;r<c.inHeight;++r)for(let a=0;a<c.inWidth;++a){const s=n-C,o=r-k,i=a-S;let l=0;for(let n=0;n<x;n+=$){const r=(s+n)/p;if(!(r<0||r>=c.outDepth||Math.floor(r)!==r))for(let n=0;n<v;n+=y){const a=(o+n)/d;if(!(a<0||a>=c.outHeight||Math.floor(a)!==a))for(let n=0;n<I;n+=b){const s=(i+n)/h;s<0||s>=c.outWidth||Math.floor(s)!==s||(l+=w.get(e,r,a,s,t))}}}T.set(l*N,e,n,r,a,t)}return n.makeTensorInfo(T.shape,T.dtype,T.values)}const avgPool3DGradConfig={kernelName:AvgPool3DGrad,backendName:"cpu",kernelFunc:avgPool3DGrad$1};function avgPoolGrad$1(e){const{inputs:t,backend:n,attrs:r}=e,{dy:a,input:s}=t,o=s;assertNotComplex$1([a,s],"avgPoolGrad");const{filterSize:i,strides:l,pad:u}=r,c=computePool2DInfo(o.shape,i,l,1,u),p=c.strideHeight,d=c.strideWidth,h=c.filterHeight,m=c.filterWidth,f=c.dilationHeight,g=c.dilationWidth,$=c.effectiveFilterHeight,y=c.effectiveFilterWidth,b=y-1-c.padInfo.left,x=$-1-c.padInfo.top,v=buffer(o.shape,"float32"),I=1/(h*m),C=n.data.get(a.dataId).values,S=buffer(a.shape,"float32",C);for(let e=0;e<c.batchSize;++e)for(let t=0;t<c.inChannels;++t)for(let n=0;n<c.inHeight;++n)for(let r=0;r<c.inWidth;++r){const a=n-x,s=r-b;let o=0;for(let n=0;n<$;n+=f){const r=(a+n)/p;if(!(r<0||r>=c.outHeight||Math.floor(r)!==r))for(let n=0;n<y;n+=g){const a=(s+n)/d;a<0||a>=c.outWidth||Math.floor(a)!==a||(o+=S.get(e,r,a,t))}}v.set(o*I,e,n,r,t)}return n.makeTensorInfo(v.shape,v.dtype,v.values)}const avgPoolGradConfig$1={kernelName:AvgPoolGrad,backendName:"cpu",kernelFunc:avgPoolGrad$1};function batchNorm$1(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,scale:s,offset:o,mean:i,variance:l}=t;assert$4(i.shape.length===l.shape.length,()=>"Batch normalization gradient requires mean and variance to have equal ranks."),assert$4(null==o||i.shape.length===o.shape.length,()=>"Batch normalization gradient requires mean and offset to have equal ranks."),assert$4(null==s||i.shape.length===s.shape.length,()=>"Batch normalization gradient requires mean and scale to have equal ranks."),assertNotComplex$1([a,i,l,s,o],"batchNorm");let{varianceEpsilon:u}=r;null==u&&(u=.001);const c=n.data.get(a.dataId).values,p=n.data.get(i.dataId).values,d=n.data.get(l.dataId).values,h=s?n.data.get(s.dataId).values:new Float32Array([1]),m=o?n.data.get(o.dataId).values:new Float32Array([0]),f=new Float32Array(c.length),g=m.length,$=h.length,y=d.length,b=p.length;let x=0,v=0,I=0,C=0;for(let e=0;e<c.length;++e)f[e]=m[x++]+(c[e]-p[v++])*h[I++]/Math.sqrt(d[C++]+u),x>=g&&(x=0),v>=b&&(v=0),I>=$&&(I=0),C>=y&&(C=0);return n.makeTensorInfo(a.shape,a.dtype,f)}const batchNormConfig$1={kernelName:FusedBatchNorm,backendName:"cpu",kernelFunc:batchNorm$1};function batchToSpaceND$1(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{blockShape:s,crops:o}=r;assertNotComplex$1([a],"batchToSpaceND");const i=s.reduce((e,t)=>e*t),l=getReshaped(a.shape,s,i),u=getPermuted(l.length,s.length),c=getReshapedPermuted(a.shape,s,i),p=getSliceBeginCoords(o,s.length),d=getSliceSize(c,o,s.length),h=reshape$1({inputs:{x:a},backend:n,attrs:{shape:l}}),m=transpose$1({inputs:{x:h},backend:n,attrs:{perm:u}}),f=reshape$1({inputs:{x:m},backend:n,attrs:{shape:c}}),g=slice$1({inputs:{x:f},backend:n,attrs:{begin:p,size:d}});return n.disposeIntermediateTensorInfo(h),n.disposeIntermediateTensorInfo(m),n.disposeIntermediateTensorInfo(f),g}const batchToSpaceNDConfig$1={kernelName:BatchToSpaceND,backendName:"cpu",kernelFunc:batchToSpaceND$1};function bincount$1(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,weights:s}=t,{size:o}=r,i=bincountImpl(n.data.get(a.dataId).values,n.data.get(s.dataId).values,s.dtype,s.shape,o);return n.makeTensorInfo([o],s.dtype,i)}const bincountConfig$1={kernelName:Bincount,backendName:"cpu",kernelFunc:bincount$1},clip=unaryKernelFunc$1(ClipByValue,(e,t)=>e>t.clipValueMax?t.clipValueMax:e<t.clipValueMin?t.clipValueMin:e),clipConfig={kernelName:ClipByValue,backendName:"cpu",kernelFunc:clip},complexAbs$1=e=>{const{x:t}=e.inputs,n=e.backend,r=new Float32Array(sizeFromShape(t.shape)),a=n.data.get(t.dataId),s=a.complexTensorInfos.imag,o=n.data.get(a.complexTensorInfos.real.dataId).values,i=n.data.get(s.dataId).values;for(let e=0;e<o.length;e++)r[e]=Math.hypot(o[e],i[e]);return n.makeOutput(r,t.shape,"float32")},complexAbsConfig$1={kernelName:ComplexAbs,backendName:"cpu",kernelFunc:complexAbs$1};function imag$1(e){const{inputs:t,backend:n}=e,{input:r}=t,a=n.data.get(r.dataId).complexTensorInfos.imag,s=n.data.get(a.dataId).values;return n.makeTensorInfo(a.shape,a.dtype,s)}const imagConfig$1={kernelName:Imag,backendName:"cpu",kernelFunc:imag$1};function concat$1(e){const{inputs:t,backend:n,attrs:r}=e,{axis:a}=r,s=parseAxisParam(a,t[0].shape)[0];let o=computeOutShape$1(t.map(e=>e.shape),s);if(0===sizeFromShape(o))return n.makeTensorInfo(o,t[0].dtype,[]);const i=t.filter(e=>sizeFromShape(e.shape)>0);if(1===i.length)return identity$1({inputs:{x:i[0]},backend:n});if(assertParamsConsistent(i.map(e=>e.shape),s),"complex64"===i[0].dtype){const e=i.map(e=>real$1({inputs:{input:e},backend:n})),t=i.map(e=>imag$1({inputs:{input:e},backend:n})),r=concat$1({inputs:e,backend:n,attrs:{axis:s}}),a=concat$1({inputs:t,backend:n,attrs:{axis:s}}),o=complex$1({inputs:{real:r,imag:a},backend:n});return e.forEach(e=>n.disposeIntermediateTensorInfo(e)),t.forEach(e=>n.disposeIntermediateTensorInfo(e)),n.disposeIntermediateTensorInfo(r),n.disposeIntermediateTensorInfo(a),o}const l=i.map(e=>{const t=sizeFromShape(e.shape.slice(s));return reshape$1({inputs:{x:e},backend:n,attrs:{shape:[-1,t]}})}),u=l.map(e=>({vals:n.data.get(e.dataId).values,shape:e.shape}));o=computeOutShape$1(l.map(e=>e.shape),1);const c=concatImpl$1(u,o,t[0].dtype,1===l[0].shape[0]),p=computeOutShape$1(i.map(e=>e.shape),s),d=n.makeTensorInfo(p,t[0].dtype,c);return l.forEach(e=>n.disposeIntermediateTensorInfo(e)),d}const concatConfig$1={kernelName:Concat,backendName:"cpu",kernelFunc:concat$1};function conv2D(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,filter:s}=t,{strides:o,pad:i,dataFormat:l,dilations:u,dimRoundingMode:c}=r;assertNotComplex$1([a,s],"conv2d");const p=convertConv2DDataFormat(l),d=computeConv2DInfo(a.shape,s.shape,o,u,i,c,!1,p),h=d.filterHeight,m=d.filterWidth,f=d.dilationHeight,g=d.dilationWidth,$=d.padInfo.left,y=d.padInfo.top,b="channelsLast"===d.dataFormat,x=new TensorBuffer(d.outShape,a.dtype),v=computeStrides(a.shape),I=computeStrides(s.shape),C=v[0],S=b?v[1]:v[2],k=b?v[2]:1,T=b?1:v[1],N=x.strides[0],w=b?x.strides[1]:x.strides[2],E=b?x.strides[2]:1,A=b?1:x.strides[1],D=n.data.get(a.dataId).values,R=n.data.get(s.dataId).values,_=x.values;for(let e=0;e<d.batchSize;++e){const t=e*C,n=e*N;for(let e=0;e<d.outHeight;++e){const r=n+e*w,a=e*d.strideHeight-y;for(let e=0;e<h;++e){const n=a+e*f;if(n<0||n>=d.inHeight)continue;const s=e*I[0],o=t+n*S;for(let e=0;e<d.outWidth;++e){const t=r+e*E,n=e*d.strideWidth-$;for(let e=0;e<m;++e){const r=n+e*g;if(r<0||r>=d.inWidth)continue;const a=o+r*k;let i=s+e*I[1];for(let e=0;e<d.inChannels;++e){const n=D[a+e*T];for(let e=0;e<d.outChannels;++e)_[t+e*A]+=n*R[i+e];i+=d.outChannels}}}}}}return n.makeTensorInfo(x.shape,x.dtype,_)}const conv2DConfig$1={kernelName:Conv2D$1,backendName:"cpu",kernelFunc:conv2D};function conv2DBackpropFilter$1(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,dy:s}=t,{strides:o,pad:i,dataFormat:l,dimRoundingMode:u,filterShape:c}=r;assertNotComplex$1([a,s],"conv2dBackpropFilter");const p=convertConv2DDataFormat(l),d=computeConv2DInfo(a.shape,c,o,1,i,u,!1,p),{strideHeight:h,strideWidth:m,filterHeight:f,filterWidth:g}=d,$="channelsLast"===d.dataFormat,y=new TensorBuffer(d.filterShape,"float32"),b=d.padInfo.left,x=d.padInfo.top,v=n.data.get(a.dataId).values,I=n.data.get(s.dataId).values,C=new TensorBuffer(a.shape,a.dtype,v),S=new TensorBuffer(s.shape,s.dtype,I);for(let e=0;e<f;++e){const t=Math.max(0,Math.ceil((x-e)/h)),n=Math.min(d.outHeight,(d.inHeight+x-e)/h);for(let r=0;r<g;++r){const a=Math.max(0,Math.ceil((b-r)/m)),s=Math.min(d.outWidth,(d.inWidth+b-r)/m);for(let o=0;o<d.inChannels;++o)for(let i=0;i<d.outChannels;++i){let l=0;for(let u=0;u<d.batchSize;++u)for(let c=t;c<n;++c){const t=e+c*h-x;for(let e=a;e<s;++e){const n=r+e*m-b;l+=$?C.get(u,t,n,o)*S.get(u,c,e,i):C.get(u,o,t,n)*S.get(u,i,c,e)}}y.set(l,e,r,o,i)}}}return n.makeTensorInfo(y.shape,y.dtype,y.values)}const conv2DBackpropFilterConfig$1={kernelName:Conv2DBackpropFilter,backendName:"cpu",kernelFunc:conv2DBackpropFilter$1};function conv2DBackpropInput$1(e){const{inputs:t,backend:n,attrs:r}=e,{dy:a,filter:s}=t,{inputShape:o,strides:i,pad:l,dataFormat:u,dimRoundingMode:c}=r;assertNotComplex$1([a,s],"conv2dBackpropInput");const p=computeStrides(s.shape),d=computeStrides(a.shape);let h=convertConv2DDataFormat(u);const m=computeConv2DInfo(o,s.shape,i,1,l,c,!1,h),f=new TensorBuffer(m.inShape,"float32"),g=f.values,$=n.data.get(a.dataId).values,y=n.data.get(s.dataId).values,[b,x,v]=p,{batchSize:I,filterHeight:C,filterWidth:S,inChannels:k,inHeight:T,inWidth:N,outChannels:w,outHeight:E,outWidth:A,strideHeight:D,strideWidth:R}=m;h=m.dataFormat;const _=C-1-m.padInfo.top,F=S-1-m.padInfo.left,P="channelsLast"===h,O=f.strides[0],M=P?f.strides[1]:f.strides[2],L=P?f.strides[2]:1,z=P?1:f.strides[1],B=d[0],V=P?d[1]:d[2],G=P?d[2]:1,U=P?1:d[1];for(let e=0;e<I;++e)for(let t=0;t<k;++t)for(let n=0;n<T;++n){const r=n-_,a=Math.max(0,Math.ceil(r/D)),s=Math.min(E,(C+r)/D);for(let o=0;o<N;++o){const i=o-F,l=Math.max(0,Math.ceil(i/R)),u=Math.min(A,(S+i)/R);let c=0;for(let n=a;n<s;++n){const a=n*D-r;for(let r=l;r<u;++r){const s=B*e+V*n+G*r,o=b*(C-1-a)+x*(S-1-(r*R-i))+v*t;for(let e=0;e<w;++e)c+=$[s+U*e]*y[o+e]}}g[O*e+M*n+L*o+z*t]=c}}return n.makeTensorInfo(f.shape,f.dtype,f.values)}const conv2DBackpropInputConfig$1={kernelName:Conv2DBackpropInput,backendName:"cpu",kernelFunc:conv2DBackpropInput$1};function conv3D$1(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,filter:s}=t,{strides:o,pad:i,dilations:l}=r;assertNotComplex$1([a,s],"conv3d");const u=computeConv3DInfo(a.shape,s.shape,o,l,i),{filterDepth:c,filterHeight:p,filterWidth:d,dilationDepth:h,dilationHeight:m,dilationWidth:f,padInfo:g}=u,$=g.front,y=g.left,b=g.top,x=new TensorBuffer(u.outShape,a.dtype),v=n.data.get(a.dataId).values,I=n.data.get(s.dataId).values,C=x.values,S=computeStrides(a.shape),k=computeStrides(s.shape);for(let e=0;e<u.batchSize;++e){const t=e*S[0],n=e*x.strides[0];for(let e=0;e<u.outDepth;++e){const r=n+e*x.strides[1],a=e*u.strideDepth-$;for(let e=0;e<c;++e){const n=a+e*h;if(n<0||n>=u.inDepth)continue;const s=e*k[0],o=t+n*S[1];for(let e=0;e<u.outHeight;++e){const t=r+e*x.strides[2],n=e*u.strideHeight-b;for(let e=0;e<p;++e){const r=n+e*m;if(r<0||r>=u.inHeight)continue;const a=s+e*k[1],i=o+r*S[2];for(let e=0;e<u.outWidth;++e){const n=t+e*u.outChannels,r=e*u.strideWidth-y;for(let e=0;e<d;++e){const t=r+e*f;if(t<0||t>=u.inWidth)continue;const s=i+t*u.inChannels;let o=a+e*k[2];for(let e=0;e<u.inChannels;++e){const t=v[s+e];for(let e=0;e<u.outChannels;++e)C[n+e]+=t*I[o+e];o+=u.outChannels}}}}}}}}return n.makeTensorInfo(x.shape,x.dtype,x.values)}const conv3DConfig$1={kernelName:Conv3D$1,backendName:"cpu",kernelFunc:conv3D$1};function conv3DBackpropFilterV2$1(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,dy:s}=t,{strides:o,pad:i,filterShape:l}=r;assertNotComplex$1([a,s],"conv3dBackpropFilterV2");const u=computeStrides(a.shape),c=computeStrides(s.shape),p=computeConv3DInfo(a.shape,l,o,1,i),d=p.strideDepth,h=p.strideHeight,m=p.strideWidth,f=p.filterDepth,g=p.filterHeight,$=p.filterWidth,y=new TensorBuffer(p.filterShape,"float32"),b=y.values,[x,v,I,C]=y.strides,S=n.data.get(s.dataId).values,[k,T,N,w]=c,E=n.data.get(a.dataId).values,[A,D,R,_]=u,F=p.padInfo.front,P=p.padInfo.left,O=p.padInfo.top;for(let e=0;e<f;++e){const t=Math.max(0,Math.ceil((F-e)/d)),n=Math.min(p.outDepth,(p.inDepth+F-e)/d),r=e*x;for(let a=0;a<g;++a){const s=Math.max(0,Math.ceil((O-a)/h)),o=Math.min(p.outHeight,(p.inHeight+O-a)/h),i=a*v+r;for(let r=0;r<$;++r){const l=Math.max(0,Math.ceil((P-r)/m)),u=Math.min(p.outWidth,(p.inWidth+P-r)/m),c=r*I+i;for(let i=0;i<p.inChannels;++i){const f=i*C+c;for(let c=0;c<p.outChannels;++c){let g=0;for(let f=0;f<p.batchSize;++f){const p=f*A,$=f*k;for(let f=t;f<n;++f){const t=(e+f*d-F)*D+p,n=f*T+$;for(let e=s;e<o;++e){const s=(a+e*h-O)*R+t,o=e*N+n;for(let e=l;e<u;++e)g+=E[(r+e*m-P)*_+s+i]*S[e*w+o+c]}}}b[f+c]=g}}}}}return n.makeTensorInfo(y.shape,y.dtype,y.values)}const conv3DBackpropFilterV2Config$1={kernelName:Conv3DBackpropFilterV2,backendName:"cpu",kernelFunc:conv3DBackpropFilterV2$1};function conv3DBackpropInputV2(e){const{inputs:t,backend:n,attrs:r}=e,{dy:a,filter:s}=t,{pad:o,strides:i,inputShape:l}=r;assertNotComplex$1([a],"conv3dBackpropInputV2");const u=computeStrides(a.shape),c=computeStrides(s.shape),p=computeConv3DInfo(l,s.shape,i,1,o),d=new TensorBuffer(p.inShape,"float32"),h=d.values,[m,f,g,$]=d.strides,y=n.data.get(a.dataId).values,[b,x,v,I]=u,C=n.data.get(s.dataId).values,[S,k,T,N]=c,{batchSize:w,filterDepth:E,filterHeight:A,filterWidth:D,inChannels:R,inDepth:_,inHeight:F,inWidth:P,outChannels:O,outDepth:M,outHeight:L,outWidth:z,strideDepth:B,strideHeight:V,strideWidth:G}=p,U=E-1-p.padInfo.front,W=A-1-p.padInfo.top,q=D-1-p.padInfo.left;for(let e=0;e<w;++e)for(let t=0;t<R;++t)for(let n=0;n<_;++n){const r=n-U,a=Math.max(0,Math.ceil(r/B)),s=Math.min(M,(E+r)/B);for(let o=0;o<F;++o){const i=o-W,l=Math.max(0,Math.ceil(i/V)),u=Math.min(L,(A+i)/V);for(let c=0;c<P;++c){const p=c-q,d=Math.max(0,Math.ceil(p/G)),w=Math.min(z,(D+p)/G);let R=0;for(let n=a;n<s;++n){const a=n*B-r;for(let r=l;r<u;++r){const s=r*V-i;for(let o=d;o<w;++o){const i=b*e+x*n+v*r+I*o,l=S*(E-1-a)+k*(A-1-s)+T*(D-1-(o*G-p))+N*t;for(let e=0;e<O;++e)R+=y[i+e]*C[l+e]}}}h[m*e+f*n+g*o+$*c+t]=R}}}return n.makeTensorInfo(d.shape,d.dtype,d.values)}const conv3DBackpropInputV2Config={kernelName:Conv3DBackpropInputV2,backendName:"cpu",kernelFunc:conv3DBackpropInputV2},cos$1=unaryKernelFunc$1(Cos,e=>Math.cos(e)),cosConfig$1={kernelName:Cos,backendName:"cpu",kernelFunc:cos$1},cosh$1=unaryKernelFunc$1(Cosh,e=>Math.cosh(e)),coshConfig$1={kernelName:Cosh,backendName:"cpu",kernelFunc:cosh$1};function cropAndResize$1(e){const{inputs:t,backend:n,attrs:r}=e,{image:a,boxes:s,boxInd:o}=t,{cropSize:i,method:l,extrapolationValue:u}=r,[c,p,d,h]=a.shape,m=s.shape[0],[f,g]=i,$=buffer([m,f,g,h],"float32"),y=n.data.get(s.dataId).values,b=n.data.get(o.dataId).values,x=n.data.get(a.dataId).values,v=computeStrides(a.shape),I=computeStrides($.shape);for(let e=0;e<m;e++){const t=4*e,n=y[t],r=y[t+1],a=y[t+2],s=y[t+3],o=b[e];if(o>=c)continue;const i=f>1?(a-n)*(p-1)/(f-1):0,m=g>1?(s-r)*(d-1)/(g-1):0;for(let t=0;t<f;t++){const c=f>1?n*(p-1)+t*i:.5*(n+a)*(p-1);if(c<0||c>p-1)for(let n=0;n<g;n++)for(let r=0;r<h;r++)$.values[r+n*I[2]+t*I[1]+e*I[0]]=u;else if("bilinear"===l){const n=Math.floor(c),a=Math.ceil(c),i=c-n;for(let l=0;l<g;l++){const c=g>1?r*(d-1)+l*m:.5*(r+s)*(d-1);if(c<0||c>d-1){for(let n=0;n<h;n++)$.values[n+l*I[2]+t*I[1]+e*I[0]]=u;continue}const p=Math.floor(c),f=Math.ceil(c),y=c-p;for(let r=0;r<h;r++){let s=r+p*v[2]+n*v[1]+o*v[0];const u=x[s];s=r+f*v[2]+n*v[1]+o*v[0];const c=x[s];s=r+p*v[2]+a*v[1]+o*v[0];const d=x[s];s=r+f*v[2]+a*v[1]+o*v[0];const h=x[s],m=u+(c-u)*y;s=r+l*I[2]+t*I[1]+e*I[0],$.values[s]=m+(d+(h-d)*y-m)*i}}}else for(let n=0;n<g;++n){const a=g>1?r*(d-1)+n*m:.5*(r+s)*(d-1);if(a<0||a>d-1){for(let r=0;r<h;r++)$.values[r+n*I[2]+t*I[1]+e*I[0]]=u;continue}const i=Math.round(a),l=Math.round(c);for(let r=0;r<h;r++)$.values[r+n*I[2]+t*I[1]+e*I[0]]=x[r+i*v[2]+l*v[1]+o*v[0]]}}}return n.makeTensorInfo($.shape,$.dtype,$.values)}const cropAndResizeConfig$1={kernelName:CropAndResize,backendName:"cpu",kernelFunc:cropAndResize$1};function cumsum$1(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{axis:s,exclusive:o,reverse:i}=r;assertNotComplex$1(a,"cumsum");const l=getAxesPermutation([s],a.shape.length);let u=a;null!=l&&(u=transpose$1({inputs:{x:a},backend:n,attrs:{perm:l}}));const c=getInnerMostAxes(1,a.shape.length)[0];if(c!==u.shape.length-1)throw new Error(`backend.cumsum in CPU expects an inner-most axis=${u.shape.length-1} but got axis=${c}`);const p=upcastType(u.dtype,"int32"),d=makeZerosTypedArray(sizeFromShape(u.shape),p),h=n.data.get(u.dataId).values,m=u.shape[u.shape.length-1],f=i?(e,t)=>e+m-t-1:(e,t)=>e+t;for(let e=0;e<h.length;e+=m)for(let t=0;t<m;t++){const n=f(e,t);if(0===t)d[n]=o?0:h[n];else{const r=f(e,t-1);d[n]=o?h[r]+d[r]:h[n]+d[r]}}const g=n.makeTensorInfo(u.shape,p,d);if(null!=l){const e=transpose$1({inputs:{x:g},backend:n,attrs:{perm:getUndoAxesPermutation(l)}});return n.disposeIntermediateTensorInfo(g),n.disposeIntermediateTensorInfo(u),e}return g}const cumsumConfig$1={kernelName:Cumsum,backendName:"cpu",kernelFunc:cumsum$1};function denseBincount$1(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,weights:s}=t,{size:o,binaryOutput:i}=r;if(1===a.shape.length){const e=bincountImpl(n.data.get(a.dataId).values,n.data.get(s.dataId).values,s.dtype,s.shape,o);return n.makeTensorInfo([o],s.dtype,e)}if(2===a.shape.length){const e=bincountReduceImpl(n.bufferSync(a),n.bufferSync(s),o,i);return n.makeTensorInfo(e.shape,s.dtype,e.values)}throw new Error(`Error in denseBincount: input must be at most rank 2, but got rank${a.shape.length}.`)}const denseBincountConfig$1={kernelName:DenseBincount,backendName:"cpu",kernelFunc:denseBincount$1};function depthToSpace$1(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{blockSize:s,dataFormat:o}=r;assert$4("NHWC"===o,()=>`Only NHWC dataFormat supported on CPU for depthToSpace. Got ${o}`),assert$4(s>1,()=>`blockSize should be > 1 for depthToSpace, but was: ${s}`);const i=a.shape[0],l=a.shape[1],u=a.shape[2],c=a.shape[3],p=l*s,d=u*s,h=c/(s*s),m=n.data.get(a.dataId).values,f=new Float32Array(i*p*d*h);let g=0;for(let e=0;e<i;++e)for(let t=0;t<p;++t){const n=Math.floor(t/s),r=t%s;for(let t=0;t<d;++t){const a=Math.floor(t/s),o=(r*s+t%s)*h;for(let t=0;t<h;++t)f[g++]=m[t+o+c*(a+u*(n+l*e))]}}return n.makeTensorInfo([i,p,d,h],a.dtype,f)}const depthToSpaceConfig$1={kernelName:DepthToSpace,backendName:"cpu",kernelFunc:depthToSpace$1};function depthwiseConv2dNative$1(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,filter:s}=t,{strides:o,pad:i,dilations:l,dimRoundingMode:u}=r;assertNotComplex$1([a,s],"depthwiseConv2DNative");const c=computeStrides(a.shape),p=computeStrides(s.shape);let d=l;null==d&&(d=[1,1]),assert$4(eitherStridesOrDilationsAreOne(o,d),()=>`Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ${o} and dilations '${d}'`);const h=computeConv2DInfo(a.shape,s.shape,o,d,i,u,!0),{filterHeight:m,filterWidth:f,dilationHeight:g,dilationWidth:$,padInfo:y}=h,b=y.left,x=y.top,v=h.outChannels/h.inChannels,I=new TensorBuffer(h.outShape,a.dtype),C=n.data.get(a.dataId).values,S=n.data.get(s.dataId).values,k=I.values;for(let e=0;e<h.batchSize;++e){const t=e*c[0],n=e*I.strides[0];for(let e=0;e<h.outHeight;++e){const r=n+e*I.strides[1],a=e*h.strideHeight-x;for(let e=0;e<m;++e){const n=a+e*g;if(n<0||n>=h.inHeight)continue;const s=e*p[0],o=t+n*c[1];for(let e=0;e<h.outWidth;++e){const t=r+e*I.strides[2],n=e*h.strideWidth-b;for(let e=0;e<f;++e){const r=n+e*$;if(r<0||r>=h.inWidth)continue;const a=o+r*h.inChannels;let i=t,l=s+e*p[1];for(let e=0;e<h.inChannels;++e){const t=C[a+e];for(let e=0;e<v;++e)k[i+e]+=t*S[l+e];i+=v,l+=v}}}}}}return n.makeTensorInfo(I.shape,I.dtype,I.values)}const depthwiseConv2dNativeConfig$1={kernelName:DepthwiseConv2dNative,backendName:"cpu",kernelFunc:depthwiseConv2dNative$1};function depthwiseConv2dNativeBackpropFilter$1(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,dy:s}=t,{strides:o,dilations:i,pad:l,dimRoundingMode:u,filterShape:c}=r;assertNotComplex$1([a,s],"depthwiseConv2dNativeBackpropFilter");const p=computeConv2DInfo(a.shape,c,o,i,l,u,!0),{strideHeight:d,strideWidth:h,filterHeight:m,filterWidth:f}=p,g=new TensorBuffer(p.filterShape,"float32"),$=p.padInfo.left,y=p.padInfo.top,b=p.outChannels/p.inChannels,x=n.data.get(a.dataId).values,v=new TensorBuffer(a.shape,a.dtype,x),I=n.data.get(s.dataId).values,C=new TensorBuffer(s.shape,s.dtype,I);for(let e=0;e<m;++e){const t=Math.max(0,Math.ceil((y-e)/d)),n=Math.min(p.outHeight,(p.inHeight+y-e)/d);for(let r=0;r<f;++r){const a=Math.max(0,Math.ceil(($-r)/h)),s=Math.min(p.outWidth,(p.inWidth+$-r)/h);for(let o=0;o<p.outChannels;++o){const i=Math.trunc(o/b),l=o%b;let u=0;for(let l=0;l<p.batchSize;++l)for(let c=t;c<n;++c){const t=e+c*d-y;for(let e=a;e<s;++e)u+=v.get(l,t,r+e*h-$,i)*C.get(l,c,e,o)}g.set(u,e,r,i,l)}}}return n.makeTensorInfo(g.shape,g.dtype,g.values)}const depthwiseConv2dNativeBackpropFilterConfig$1={kernelName:DepthwiseConv2dNativeBackpropFilter,backendName:"cpu",kernelFunc:depthwiseConv2dNativeBackpropFilter$1};function depthwiseConv2dNativeBackpropInput$1(e){const{inputs:t,backend:n,attrs:r}=e,{dy:a,filter:s}=t,{strides:o,dilations:i,pad:l,dimRoundingMode:u,inputShape:c}=r;assertNotComplex$1([a,s],"depthwiseConv2DNativeBackpropInput");const p=computeStrides(a.shape),d=computeStrides(s.shape),h=computeConv2DInfo(c,s.shape,o,i,l,u,!0),m=new TensorBuffer(h.inShape,"float32"),f=m.values,[g,$,y]=m.strides,b=n.data.get(a.dataId).values,[x,v,I]=p,C=n.data.get(s.dataId).values,[S,k,T]=d,{batchSize:N,filterHeight:w,filterWidth:E,inChannels:A,inHeight:D,inWidth:R,outChannels:_,outHeight:F,outWidth:P,strideHeight:O,strideWidth:M}=h,L=w-1-h.padInfo.top,z=E-1-h.padInfo.left,B=_/A;for(let e=0;e<N;++e)for(let t=0;t<A;++t)for(let n=0;n<D;++n){const r=n-L,a=Math.max(0,Math.ceil(r/O)),s=Math.min(F,(w+r)/O);for(let o=0;o<R;++o){const i=o-z,l=Math.max(0,Math.ceil(i/M)),u=Math.min(P,(E+i)/M);let c=0;for(let n=a;n<s;++n){const a=n*O-r;for(let r=l;r<u;++r){const s=x*e+v*n+I*r,o=S*(w-1-a)+k*(E-1-(r*M-i))+T*t;for(let e=0;e<B;++e)c+=b[s+(t*B+e)]*C[o+e]}}f[g*e+$*n+y*o+t]=c}}return n.makeTensorInfo(m.shape,m.dtype,m.values)}const depthwiseConv2dNativeBackpropInputConfig$1={kernelName:DepthwiseConv2dNativeBackpropInput,backendName:"cpu",kernelFunc:depthwiseConv2dNativeBackpropInput$1};function diag$1(e){const{inputs:t,backend:n}=e,{x:r}=t,a=sizeFromShape(r.shape),s=n.data.get(r.dataId).values,o=buffer([a,a],r.dtype),i=o.values;for(let e=0;e<s.length;e++)i[e*a+e]=s[e];const l=[...r.shape,...r.shape];return n.makeTensorInfo(l,o.dtype,o.values)}const diagConfig$1={kernelName:Diag,backendName:"cpu",kernelFunc:diag$1},dilation2dConfig={kernelName:Dilation2D,backendName:"cpu",kernelFunc:({inputs:e,backend:t,attrs:n})=>{const{x:r,filter:a}=e,{strides:s,pad:o,dilations:i}=n,l=t,u=l.data.get(r.dataId).values,c=r.shape.length,p=l.data.get(a.dataId).values,d=a.shape.length,{batchSize:h,inHeight:m,inWidth:f,inChannels:g,outHeight:$,outWidth:y,padInfo:b,strideHeight:x,strideWidth:v,filterHeight:I,filterWidth:C,dilationHeight:S,dilationWidth:k,outShape:T}=computeDilation2DInfo(r.shape,a.shape,s,o,"NHWC",i),N=sizeFromShape(T),w=T.length,E=getArrayFromDType(r.dtype,N);for(let e=0;e<h;++e)for(let t=0;t<$;++t){const n=t*x-b.top;for(let s=0;s<y;++s){const o=s*v-b.left;for(let i=0;i<g;++i){let l=Number.MIN_SAFE_INTEGER;for(let t=0;t<I;++t){const s=n+t*S;if(s>=0&&s<m)for(let n=0;n<C;++n){const h=o+n*k;if(h>=0&&h<f){const o=locToIndex([e,s,h,i],c,computeStrides(r.shape)),m=locToIndex([t,n,i],d,computeStrides(a.shape)),f=u[o]+p[m];f>l&&(l=f)}}}E[locToIndex([e,t,s,i],w,computeStrides(T))]=l}}}return{dataId:l.write(toTypedArray(E,r.dtype),T,r.dtype),shape:T,dtype:r.dtype}}},dilation2dBackpropFilterConfig={kernelName:Dilation2DBackpropFilter,backendName:"cpu",kernelFunc:({inputs:e,backend:t,attrs:n})=>{const{x:r,filter:a,dy:s}=e,{strides:o,pad:i,dilations:l}=n,u=t,c=toNestedArray(r.shape,u.data.get(r.dataId).values),p=toNestedArray(a.shape,u.data.get(a.dataId).values),{batchSize:d,inHeight:h,inWidth:m,inChannels:f,outHeight:g,outWidth:$,padInfo:y,strideHeight:b,strideWidth:x,filterHeight:v,filterWidth:I,dilationHeight:C,dilationWidth:S,outShape:k}=computeDilation2DInfo(r.shape,a.shape,o,i,"NHWC",l);assert$4(s.rank===k.length,()=>`Error in ${Dilation2DBackpropFilter}, dy must have the same rank as output ${k.length}, but got ${s.rank}`);const T=toNestedArray(k,u.data.get(s.dataId).values),N=makeZerosNestedTypedArray(a.shape,a.dtype);for(let e=0;e<d;++e)for(let t=0;t<g;++t){const n=t*b-y.top;for(let r=0;r<$;++r){const a=r*x-y.left;for(let s=0;s<f;++s){let o=Number.MIN_SAFE_INTEGER,i=0,l=0;for(let t=0;t<v;++t){const r=n+t*C;if(r>=0&&r<h)for(let n=0;n<I;++n){const u=a+n*S;if(u>=0&&u<m){const a=c[e][r][u][s]+p[t][n][s];a>o&&(o=a,i=t,l=n)}}}N[i][l][s]+=T[e][t][r][s]}}}return{dataId:u.write(toTypedArray(N,r.dtype),a.shape,a.dtype),shape:a.shape,dtype:a.dtype}}},dilation2dBackpropInputConfig={kernelName:Dilation2DBackpropInput,backendName:"cpu",kernelFunc:({inputs:e,backend:t,attrs:n})=>{const{x:r,filter:a,dy:s}=e,{strides:o,pad:i,dilations:l}=n,u=t,c=toNestedArray(r.shape,u.data.get(r.dataId).values),p=toNestedArray(a.shape,u.data.get(a.dataId).values),{batchSize:d,inHeight:h,inWidth:m,inChannels:f,outHeight:g,outWidth:$,padInfo:y,strideHeight:b,strideWidth:x,filterHeight:v,filterWidth:I,dilationHeight:C,dilationWidth:S,outShape:k}=computeDilation2DInfo(r.shape,a.shape,o,i,"NHWC",l);assert$4(s.rank===k.length,()=>`Error in ${Dilation2DBackpropInput}, dy must have the same rank as output ${k.length}, but got ${s.rank}`);const T=toNestedArray(k,u.data.get(s.dataId).values),N=makeZerosNestedTypedArray(r.shape,r.dtype);for(let e=0;e<d;++e)for(let t=0;t<g;++t){const n=t*b-y.top;for(let r=0;r<$;++r){const a=r*x-y.left;for(let s=0;s<f;++s){let o=Number.MIN_SAFE_INTEGER,i=n<0?0:n,l=a<0?0:a;for(let t=0;t<v;++t){const r=n+t*C;if(r>=0&&r<h)for(let n=0;n<I;++n){const u=a+n*S;if(u>=0&&u<m){const a=c[e][r][u][s]+p[t][n][s];a>o&&(o=a,i=r,l=u)}}}N[e][i][l][s]+=T[e][t][r][s]}}}return{dataId:u.write(toTypedArray(N,r.dtype),r.shape,r.dtype),shape:r.shape,dtype:r.dtype}}};function sum$1(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{axis:s,keepDims:o}=r;let i;assertNotComplex$1(a,"sum"),i="bool"===a.dtype?cast$1({inputs:{x:a},backend:n,attrs:{dtype:"int32"}}):identity$1({inputs:{x:a},backend:n});const l=i.shape.length,u=parseAxisParam(s,i.shape),c=getAxesPermutation(u,l);let p=u,d=i;null!=c&&(d=transpose$1({inputs:{x:i},backend:n,attrs:{perm:c}}),p=getInnerMostAxes(p.length,l)),assertAxesAreInnerMostDims("sum",p,d.shape.length);const[h,m]=computeOutAndReduceShapes(d.shape,p);let f=zeros(n,h,upcastType(d.dtype,"int32"));const g=sizeFromShape(m),$=n.data.get(f.dataId).values,y=n.data.get(d.dataId).values;for(let e=0;e<$.length;++e){const t=e*g;let n=0;for(let e=0;e<g;++e)n+=y[t+e];$[e]=n}if(o){const e=f;f=reshape$1({inputs:{x:f},backend:n,attrs:{shape:expandShapeToKeepDim(f.shape,u)}}),n.disposeIntermediateTensorInfo(e)}return n.disposeIntermediateTensorInfo(i),null!=c&&n.disposeIntermediateTensorInfo(d),f}const sumConfig$1={kernelName:Sum,backendName:"cpu",kernelFunc:sum$1};function einsum$1(e){const{inputs:t,backend:n,attrs:r}=e,{equation:a}=r,s=t,{allDims:o,summedDims:i,idDims:l}=decodeEinsumEquation(a,s.length);checkEinsumDimSizes(o.length,l,s);const{path:u,steps:c}=getEinsumComputePath(i,l),p=c.length;let d=null,h=o.length;const m=[];for(let e=0;e<p;++e){for(const t of c[e]){const{permutationIndices:e,expandDims:r}=getEinsumPermutation(h,l[t]);let a;isIdentityPermutation(e)?a=s[t]:(a=transpose$1({inputs:{x:s[t]},backend:n,attrs:{perm:e}}),m.push(a));const o=a.shape.slice();for(let e=0;e<r.length;++e)o.splice(r[e],0,1);arraysEqual(a.shape,o)||(a=reshape$1({inputs:{x:a},backend:n,attrs:{shape:o}}),m.push(a)),null===d?d=a:(d=multiply$1({inputs:{a,b:d},backend:n}),m.push(d))}e<p-1&&(u[e]>=0&&(d=sum$1({inputs:{x:d},backend:n,attrs:{axis:u[e]-(o.length-h),keepDims:!1}}),m.push(d)),h--)}for(const e of m)e!==d&&n.disposeIntermediateTensorInfo(e);return d}const einsumConfig$1={kernelName:Einsum,backendName:"cpu",kernelFunc:einsum$1};function eluGrad$1(e){const{inputs:t,backend:n}=e,{dy:r,y:a}=t;assertNotComplex$1([r,a],"eluGrad");const s=new Float32Array(sizeFromShape(a.shape)),o=n.data.get(a.dataId).values,i=n.data.get(r.dataId).values;for(let e=0;e<o.length;++e){const t=o[e];s[e]=t>=1?i[e]:i[e]*(t+1)}return n.makeTensorInfo(a.shape,"float32",s)}const eluGradConfig$1={kernelName:EluGrad,backendName:"cpu",kernelFunc:eluGrad$1},p=ERF_P,a1=ERF_A1,a2=ERF_A2,a3=ERF_A3,a4=ERF_A4,a5=ERF_A5,erf$1=unaryKernelFunc$1(Erf,e=>{const t=Math.sign(e),n=Math.abs(e),r=1/(1+p*n);return t*(1-((((a5*r+a4)*r+a3)*r+a2)*r+a1)*r*Math.exp(-n*n))}),erfConfig$1={kernelName:Erf,backendName:"cpu",kernelFunc:erf$1};function expandDims$1(e){const{inputs:t,backend:n,attrs:r}=e,{input:a}=t,{dim:s}=r,o=a.shape.length,i=a.shape.slice();let l=s;return s<0&&(assert$4(-(o+1)<=s,()=>`Axis must be in the interval [${-(o+1)}, ${o}]`),l=o+s+1),i.splice(l,0,1),reshape$1({inputs:{x:a},backend:n,attrs:{shape:i}})}const expandDimsConfig$1={kernelName:ExpandDims,backendName:"cpu",kernelFunc:expandDims$1},realDivImpl=createSimpleBinaryKernelImpl((e,t)=>e/t),div=binaryKernelFunc$1(RealDiv,realDivImpl),realDivConfig$1={kernelName:RealDiv,backendName:"cpu",kernelFunc:div};function fftBatch(e,t,n){const r=e.shape,a=r[0],s=r[1],o=n.data.get(e.dataId),i=o.complexTensorInfos.real,l=o.complexTensorInfos.imag,u=[a,s],c=sizeFromShape(u),p=getTypedArrayFromDType("float32",c),d=getTypedArrayFromDType("float32",c);for(let e=0;e<a;e++){const r=slice$1({inputs:{x:i},backend:n,attrs:{begin:[e,0],size:[1,s]}}),a=slice$1({inputs:{x:l},backend:n,attrs:{begin:[e,0],size:[1,s]}}),o=complex$1({inputs:{real:r,imag:a},backend:n}),{real:u,imag:c}=fftImpl$1(o,t,n),h=mergeRealAndImagArrays(u,c);for(let t=0;t<s;t++){const n=getComplexWithIndex(h,t);p[e*s+t]=n.real,d[e*s+t]=n.imag}n.disposeIntermediateTensorInfo(r),n.disposeIntermediateTensorInfo(a),n.disposeIntermediateTensorInfo(o)}const h=n.makeTensorInfo(u,"float32",p),m=n.makeTensorInfo(u,"float32",d),f=complex$1({inputs:{real:h,imag:m},backend:n});return n.disposeIntermediateTensorInfo(h),n.disposeIntermediateTensorInfo(m),f}function fftImpl$1(e,t,n){const r=sizeFromShape(e.shape),a=n.data.get(e.dataId),s=n.data.get(a.complexTensorInfos.real.dataId).values,o=n.data.get(a.complexTensorInfos.imag.dataId).values;if(isExponentOf2(r)){const a=fftRadix2(s,o,r,t,n),i=[e.shape[0],e.shape[1]];if(t){const e=n.makeTensorInfo(i,"float32",a.real),t=n.makeTensorInfo(i,"float32",a.imag),s=n.makeTensorInfo([],"float32",createScalarValue(r,"float32")),o=identity$1({inputs:{x:s},backend:n}),l=realDivConfig$1.kernelFunc({inputs:{a:e,b:s},backend:n}),u=realDivConfig$1.kernelFunc({inputs:{a:t,b:o},backend:n}),c=n.data.get(l.dataId).values,p=n.data.get(u.dataId).values;return n.disposeIntermediateTensorInfo(e),n.disposeIntermediateTensorInfo(t),n.disposeIntermediateTensorInfo(s),n.disposeIntermediateTensorInfo(o),n.disposeIntermediateTensorInfo(l),n.disposeIntermediateTensorInfo(u),{real:c,imag:p}}return a}return splitRealAndImagArrays(fourierTransformByMatmul(mergeRealAndImagArrays(s,o),r,t))}function isExponentOf2(e){return 0==(e&e-1)}function fftRadix2(e,t,n,r,a){if(1===n)return{real:e,imag:t};const s=mergeRealAndImagArrays(e,t),o=n/2,i=complexWithEvenIndex(s),l=i.real,u=i.imag,c=[l.length],p=a.makeTensorInfo(c,"float32",l),d=a.makeTensorInfo(c,"float32",u),h=complex$1({inputs:{real:p,imag:d},backend:a}),m=complexWithOddIndex(s),f=m.real,g=m.imag,$=[f.length],y=a.makeTensorInfo($,"float32",f),b=a.makeTensorInfo($,"float32",g),x=complex$1({inputs:{real:y,imag:b},backend:a}),v=fftRadix2(l,u,o,r,a),I=v.real,C=v.imag,S=[I.length],k=a.makeTensorInfo(S,"float32",I),T=a.makeTensorInfo(S,"float32",C),N=complex$1({inputs:{real:k,imag:T},backend:a}),w=fftRadix2(f,g,o,r,a),E=w.real,A=w.imag,D=[E.length],R=a.makeTensorInfo(D,"float32",E),_=a.makeTensorInfo(D,"float32",A),F=complex$1({inputs:{real:R,imag:_},backend:a}),P=exponents(n,r),O=[P.real.length],M=a.makeTensorInfo(O,"float32",P.real),L=a.makeTensorInfo(O,"float32",P.imag),z=complex$1({inputs:{real:M,imag:L},backend:a}),B=multiply$1({inputs:{a:z,b:F},backend:a}),V=add({inputs:{a:N,b:B},backend:a}),G=sub$1({inputs:{a:N,b:B},backend:a}),U=real$1({inputs:{input:V},backend:a}),W=real$1({inputs:{input:G},backend:a}),q=imag$1({inputs:{input:V},backend:a}),H=imag$1({inputs:{input:G},backend:a}),K=concat$1({inputs:[U,W],backend:a,attrs:{axis:0}}),j=concat$1({inputs:[q,H],backend:a,attrs:{axis:0}}),X=a.data.get(K.dataId).values,Y=a.data.get(j.dataId).values;return a.disposeIntermediateTensorInfo(p),a.disposeIntermediateTensorInfo(d),a.disposeIntermediateTensorInfo(h),a.disposeIntermediateTensorInfo(y),a.disposeIntermediateTensorInfo(b),a.disposeIntermediateTensorInfo(x),a.disposeIntermediateTensorInfo(k),a.disposeIntermediateTensorInfo(T),a.disposeIntermediateTensorInfo(N),a.disposeIntermediateTensorInfo(R),a.disposeIntermediateTensorInfo(_),a.disposeIntermediateTensorInfo(F),a.disposeIntermediateTensorInfo(M),a.disposeIntermediateTensorInfo(L),a.disposeIntermediateTensorInfo(z),a.disposeIntermediateTensorInfo(B),a.disposeIntermediateTensorInfo(V),a.disposeIntermediateTensorInfo(G),a.disposeIntermediateTensorInfo(U),a.disposeIntermediateTensorInfo(q),a.disposeIntermediateTensorInfo(W),a.disposeIntermediateTensorInfo(H),a.disposeIntermediateTensorInfo(K),a.disposeIntermediateTensorInfo(j),{real:X,imag:Y}}function fourierTransformByMatmul(e,t,n){const r=new Float32Array(2*t);for(let a=0;a<t;a++){let s=0,o=0;for(let r=0;r<t;r++){const i=exponent(a*r,t,n),l=getComplexWithIndex(e,r);s+=l.real*i.real-l.imag*i.imag,o+=l.real*i.imag+l.imag*i.real}n&&(s/=t,o/=t),assignToTypedArray(r,s,o,a)}return r}function fft$1(e){const{inputs:t,backend:n}=e,{input:r}=t,a=sizeFromShape(r.shape),s=r.shape[r.shape.length-1],o=reshape$1({inputs:{x:r},backend:n,attrs:{shape:[a/s,s]}}),i=fftBatch(o,!1,n),l=reshape$1({inputs:{x:i},backend:n,attrs:{shape:r.shape}});return n.disposeIntermediateTensorInfo(o),n.disposeIntermediateTensorInfo(i),l}const fftConfig$1={kernelName:FFT,backendName:"cpu",kernelFunc:fft$1};function fill$1(e){const{backend:t,attrs:n}=e,{shape:r,value:a,dtype:s}=n,o=s||inferDtype(a),i=getArrayFromDType(o,sizeFromShape(r));return fillValues(i,a,o),t.makeTensorInfo(r,o,i)}const fillConfig$1={kernelName:Fill,backendName:"cpu",kernelFunc:fill$1};function fillValues(e,t,n){e.fill(t)}const flipLeftRightConfig$1={kernelName:FlipLeftRight,backendName:"cpu",kernelFunc:({inputs:e,backend:t})=>{const{image:n}=e,r=t,a=getTypedArrayFromDType(n.dtype,sizeFromShape(n.shape)),[s,o,i,l]=n.shape,u=r.data.get(n.dataId).values;for(let e=0;e<s;e++){const t=e*i*o*l;for(let e=0;e<o;e++){const n=e*(i*l);for(let e=0;e<i;e++){const r=e*l;for(let s=0;s<l;s++){const o=Math.round(i-e-1),c=t+n+r+s;let p=u[c];o>=0&&o<i&&(p=u[t+n+o*l+s]),a[c]=p}}}}return{dataId:r.write(a,n.shape,n.dtype),shape:n.shape,dtype:n.dtype}}},floorDivImpl=createSimpleBinaryKernelImpl((e,t)=>Math.floor(e/t)),floorDiv$1=binaryKernelFunc$1(FloorDiv,floorDivImpl,null,"int32"),floorDivConfig$1={kernelName:FloorDiv,backendName:"cpu",kernelFunc:floorDiv$1};function fusedConv2D(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,filter:s,bias:o,preluActivationWeights:i}=t,{strides:l,pad:u,dataFormat:c,dilations:p,dimRoundingMode:d,activation:h,leakyreluAlpha:m}=r;let f=conv2D({inputs:{x:a,filter:s},backend:n,attrs:{strides:l,pad:u,dataFormat:c,dilations:p,dimRoundingMode:d}});if(o){const e=f;f=add({inputs:{a:f,b:o},backend:n}),n.disposeIntermediateTensorInfo(e)}if(h){const e=f;f=applyActivation(n,f,h,i,m),n.disposeIntermediateTensorInfo(e)}return f}const fusedConv2DConfig$1={kernelName:FusedConv2D,backendName:"cpu",kernelFunc:fusedConv2D};function fusedDepthwiseConv2D$1(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,filter:s,bias:o,preluActivationWeights:i}=t,{strides:l,pad:u,dataFormat:c,dilations:p,dimRoundingMode:d,activation:h,leakyreluAlpha:m}=r;let f=depthwiseConv2dNative$1({inputs:{x:a,filter:s},backend:n,attrs:{strides:l,pad:u,dataFormat:c,dilations:p,dimRoundingMode:d}});if(o){const e=f;f=add({inputs:{a:f,b:o},backend:n}),n.disposeIntermediateTensorInfo(e)}if(h){const e=f;f=applyActivation(n,f,h,i,m),n.disposeIntermediateTensorInfo(e)}return f}const fusedDepthwiseConv2DConfig$1={kernelName:FusedDepthwiseConv2D,backendName:"cpu",kernelFunc:fusedDepthwiseConv2D$1};function gatherNd$1(e){const{inputs:t,backend:n}=e,{params:r,indices:a}=t,s=sizeFromShape(r.shape),o=a.shape,i=o[o.length-1],[l,u,c,p]=prepareAndValidate(r,a);if(0===u)return n.makeTensorInfo(l,r.dtype,[]);const d=gatherNdImpl(n.data.get(a.dataId).values,n.bufferSync(r),r.dtype,u,i,c,p,r.shape,s);return n.makeTensorInfo(l,r.dtype,d.values)}const gatherNdConfig$1={kernelName:GatherNd,backendName:"cpu",kernelFunc:gatherNd$1};function gatherV2$1(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,indices:s}=t,{axis:o,batchDims:i}=r;assertNotComplex$1([a,s],"gatherV2");let l=i;null==i&&(l=0);const u=sizeFromShape(s.shape),c=collectGatherOpShapeInfo(a,s,parseAxisParam(o,a.shape)[0],l),p=reshape$1({inputs:{x:a},backend:n,attrs:{shape:[c.batchSize,c.outerSize,c.dimSize,c.sliceSize]}}),d=reshape$1({inputs:{x:s},backend:n,attrs:{shape:[c.batchSize,u/c.batchSize]}}),h=[c.batchSize,c.outerSize,u/c.batchSize,c.sliceSize],m=n.bufferSync(d),f=gatherV2Impl(n.bufferSync(p),m,h);return n.disposeIntermediateTensorInfo(p),n.disposeIntermediateTensorInfo(d),n.makeTensorInfo(c.outputShape,f.dtype,f.values)}const gatherV2Config$1={kernelName:GatherV2,backendName:"cpu",kernelFunc:gatherV2$1};function ifft$1(e){const{inputs:t,backend:n}=e,{input:r}=t,a=sizeFromShape(r.shape),s=r.shape[r.shape.length-1],o=reshape$1({inputs:{x:r},backend:n,attrs:{shape:[a/s,s]}}),i=fftBatch(o,!0,n),l=reshape$1({inputs:{x:i},backend:n,attrs:{shape:r.shape}});return n.disposeIntermediateTensorInfo(o),n.disposeIntermediateTensorInfo(i),l}const ifftConfig$1={kernelName:IFFT,backendName:"cpu",kernelFunc:ifft$1},isFinite$2=unaryKernelFunc$1(IsFinite,e=>Number.isFinite(e)?1:0,"bool"),isFiniteConfig$1={kernelName:IsFinite,backendName:"cpu",kernelFunc:isFinite$2},isInf$1=unaryKernelFunc$1(IsInf,e=>Infinity===Math.abs(e)?1:0,"bool"),isInfConfig$1={kernelName:IsInf,backendName:"cpu",kernelFunc:isInf$1},isNaN$2=unaryKernelFunc$1(IsNan,e=>Number.isNaN(e)?1:0,"bool"),isNaNConfig$1={kernelName:IsNan,backendName:"cpu",kernelFunc:isNaN$2};function linSpace$1(e){const{backend:t,attrs:n}=e,{start:r,stop:a,num:s}=n,o=linSpaceImpl(r,a,s);return t.makeTensorInfo([o.length],"float32",o)}const linSpaceConfig$1={kernelName:LinSpace,backendName:"cpu",kernelFunc:linSpace$1},log1p$1=unaryKernelFunc$1(Log1p,e=>Math.log1p(e)),log1pConfig$1={kernelName:Log1p,backendName:"cpu",kernelFunc:log1p$1},logicalAndImpl=createSimpleBinaryKernelImpl((e,t)=>e&&t),logicalAnd$1=binaryKernelFunc$1(LogicalAnd,logicalAndImpl,null,"bool"),logicalAndConfig$1={kernelName:LogicalAnd,backendName:"cpu",kernelFunc:logicalAnd$1},logicalNot$1=unaryKernelFunc$1(LogicalNot,e=>e?0:1,"bool"),logicalNotConfig$1={kernelName:LogicalNot,backendName:"cpu",kernelFunc:logicalNot$1},logicalOrImpl=createSimpleBinaryKernelImpl((e,t)=>e||t),logicalOr$1=binaryKernelFunc$1(LogicalOr,logicalOrImpl,null,"bool"),logicalOrConfig$1={kernelName:LogicalOr,backendName:"cpu",kernelFunc:logicalOr$1};function lRN(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{depthRadius:s,bias:o,alpha:i,beta:l}=r;assertNotComplex$1(a,"LRN");const u=a.shape[3],c=u-1,p=n.data.get(a.dataId).values,d=sizeFromShape(a.shape),h=new Float32Array(d);function m(e){const t=e%u;let n=e-t+Math.max(0,t-s);const r=e-t+Math.min(t+s,c);let a=0;for(;n<=r;n++){const e=p[n];a+=e*e}return a}for(let e=0;e<d;e++){const t=m(e),n=p[e]*Math.pow(o+i*t,-l);h[e]=n}return n.makeTensorInfo(a.shape,a.dtype,h)}const lRNConfig={kernelName:LRN,backendName:"cpu",kernelFunc:lRN};function lRNGrad(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,y:s,dy:o}=t,{depthRadius:i,bias:l,alpha:u,beta:c}=r;assertNotComplex$1(o,"LRNGrad");const p=sizeFromShape(o.shape),d=o.shape[3],h=n.data.get(o.dataId).values,m=n.data.get(a.dataId).values,f=n.data.get(s.dataId).values,g=new Float32Array(p),$=p;for(let e=0;e<$;e++){const t=e%d,n=e-t+Math.max(0,t-i),r=e-t+Math.min(d,t+i+1);let a=0;for(let e=n;e<r;e++)a+=Math.pow(m[e],2);a=u*a+l;for(let t=n;t<r;t++){let n=-2*u*c*m[t]*f[e]/a;e===t&&(n+=Math.pow(a,-c)),n*=h[e],g[t]+=n}}return n.makeTensorInfo(o.shape,a.dtype,g)}const lRNGradConfig={kernelName:LRNGrad,backendName:"cpu",kernelFunc:lRNGrad};function max$1(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{reductionIndices:s,keepDims:o}=r,i=n;let l=a.shape;const u=l.length,c=parseAxisParam(s,l);let p=c;const d=getAxesPermutation(p,u);let h=i.data.get(a.dataId).values;if(null!=d){const e=new Array(u);for(let t=0;t<e.length;t++)e[t]=l[d[t]];h=transposeImpl$1(h,l,a.dtype,d,e),p=getInnerMostAxes(p.length,u),l=e}assertNotComplex$1(a,"max"),assertAxesAreInnerMostDims("max",p,u);const[m,f]=computeOutAndReduceShapes(l,p),g=maxImpl$1(h,sizeFromShape(f),m,a.dtype),$=i.write(g,m,a.dtype);let y=m;return o&&(y=expandShapeToKeepDim(m,c)),{dataId:$,shape:y,dtype:a.dtype}}const maxConfig$1={kernelName:Max,backendName:"cpu",kernelFunc:max$1};function maxPool$1(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t;assertNotComplex$1(a,"maxPool");const{filterSize:s,strides:o,pad:i,dimRoundingMode:l}=r;assert$4(eitherStridesOrDilationsAreOne(o,1),()=>`Error in maxPool: Either strides or dilations must be 1. Got strides ${o} and dilations '1'`);const u=computePool2DInfo(a.shape,s,o,1,i,l);let c;if(1===u.filterWidth&&1===u.filterHeight&&arraysEqual(u.inShape,u.outShape))c=identity$1({inputs:{x:a},backend:n});else{const e=n.data.get(a.dataId).values,t=computeStrides(a.shape),r=pool(e,a.shape,a.dtype,t,u,"max");c=n.makeTensorInfo(u.outShape,a.dtype,r.values)}return c}const maxPoolConfig$1={kernelName:MaxPool,backendName:"cpu",kernelFunc:maxPool$1};function maxPool3D(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{filterSize:s,strides:o,pad:i,dimRoundingMode:l,dataFormat:u}=r;assertNotComplex$1(a,"maxPool3d");const c=computePool3DInfo(a.shape,s,o,1,i,l,u),p=pool3d(n.data.get(a.dataId).values,a.shape,a.dtype,computeStrides(a.shape),c,"max");return n.makeTensorInfo(p.shape,"float32",p.values)}const maxPool3DConfig$1={kernelName:MaxPool3D,backendName:"cpu",kernelFunc:maxPool3D};function maxPool3DGrad$1(e){const{inputs:t,backend:n,attrs:r}=e,{dy:a,input:s}=t,{filterSize:o,strides:i,pad:l,dimRoundingMode:u}=r;assertNotComplex$1([a,s],"maxPool3DGrad");const c=computePool3DInfo(s.shape,o,i,1,l,u),p=maxPool3dPositions(n.bufferSync(s),c),d=c.strideDepth,h=c.strideHeight,m=c.strideWidth,f=c.dilationDepth,g=c.dilationHeight,$=c.dilationWidth,y=c.effectiveFilterDepth,b=c.effectiveFilterHeight,x=c.effectiveFilterWidth,v=y-1-c.padInfo.front,I=x-1-c.padInfo.left,C=b-1-c.padInfo.top,S=buffer(s.shape,"float32"),k=n.bufferSync(a);for(let e=0;e<c.batchSize;++e)for(let t=0;t<c.inChannels;++t)for(let n=0;n<c.inDepth;++n)for(let r=0;r<c.inHeight;++r)for(let a=0;a<c.inWidth;++a){const s=n-v,o=r-C,i=a-I;let l=0;for(let n=0;n<y;n+=f){const r=(s+n)/d;if(!(r<0||r>=c.outDepth||Math.floor(r)!==r))for(let a=0;a<b;a+=g){const s=(o+a)/h;if(!(s<0||s>=c.outHeight||Math.floor(s)!==s))for(let o=0;o<x;o+=$){const u=(i+o)/m;if(u<0||u>=c.outWidth||Math.floor(u)!==u)continue;const d=y*b*x-1-p.get(e,r,s,u,t)===n*b*x+a*x+o?1:0;0!==d&&(l+=k.get(e,r,s,u,t)*d)}}}S.set(l,e,n,r,a,t)}return n.makeTensorInfo(S.shape,S.dtype,S.values)}const maxPool3DGradConfig={kernelName:MaxPool3DGrad,backendName:"cpu",kernelFunc:maxPool3DGrad$1};function maxPoolGrad$1(e){const{inputs:t,backend:n,attrs:r}=e,{dy:a,input:s,output:o}=t,i=s;assertNotComplex$1([s,o],"maxPoolGrad");const{filterSize:l,strides:u,pad:c,dimRoundingMode:p}=r,d=computePool2DInfo(i.shape,l,u,1,c,p),h=n.data.get(i.dataId).values,m=buffer(d.outShape,i.dtype,maxPoolPositions(h,i.shape,i.dtype,d).values),f=d.strideHeight,g=d.strideWidth,$=d.dilationHeight,y=d.dilationWidth,b=d.effectiveFilterHeight,x=d.effectiveFilterWidth,v=x-1-d.padInfo.left,I=b-1-d.padInfo.top,C=buffer(i.shape,"float32"),S=n.data.get(a.dataId).values,k=buffer(a.shape,"float32",S);for(let e=0;e<d.batchSize;++e)for(let t=0;t<d.inChannels;++t)for(let n=0;n<d.inHeight;++n)for(let r=0;r<d.inWidth;++r){const a=n-I,s=r-v;let o=0;for(let n=0;n<b;n+=$){const r=(a+n)/f;if(!(r<0||r>=d.outHeight||Math.floor(r)!==r))for(let a=0;a<x;a+=y){const i=(s+a)/g;if(i<0||i>=d.outWidth||Math.floor(i)!==i)continue;const l=b*x-1-m.get(e,r,i,t)===n*x+a?1:0;0!==l&&(o+=k.get(e,r,i,t)*l)}}C.set(o,e,n,r,t)}return n.makeTensorInfo(C.shape,C.dtype,C.values)}const maxPoolGradConfig$1={kernelName:MaxPoolGrad,backendName:"cpu",kernelFunc:maxPoolGrad$1};function maxPoolWithArgmaxImpl$1(e,t,n,r,a){const s=pool(e,t,n,computeStrides(t),a,"max"),o=maxPoolPositions(e,t,n,a,!0,r);return[s.values,o.values]}const maxPoolWithArgmaxConfig$1={kernelName:MaxPoolWithArgmax,backendName:"cpu",kernelFunc:({inputs:e,attrs:t,backend:n})=>{const{x:r}=e,{filterSize:a,strides:s,pad:o,includeBatchInIndex:i}=t,l=n;assertNotComplex$1(r,"MaxPoolWithArgmax");const u=l.data.get(r.dataId).values,c=computePool2DInfo(r.shape,a,s,[1,1],o),[p,d]=maxPoolWithArgmaxImpl$1(u,r.shape,r.dtype,i,c),h=l.write(p,c.outShape,r.dtype),m=l.write(d,c.outShape,r.dtype);return[{dataId:h,shape:c.outShape,dtype:r.dtype},{dataId:m,shape:c.outShape,dtype:"int32"}]}};function mean(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{axis:s,keepDims:o}=r,i=parseAxisParam(s,a.shape),l=sizeFromShape(computeOutAndReduceShapes(a.shape,i)[1]),u=[],c=n.makeTensorInfo([],"float32",new Float32Array([l]));u.push(c);const p=cast$1({inputs:{x:a},backend:n,attrs:{dtype:"float32"}});u.push(p);const d=div({inputs:{a:p,b:c},backend:n});u.push(d);const h=sum$1({inputs:{x:d},backend:n,attrs:{axis:s,keepDims:o}});return u.forEach(e=>n.disposeIntermediateTensorInfo(e)),h}const meanConfig$1={kernelName:Mean,backendName:"cpu",kernelFunc:mean};function min$1(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{axis:s,keepDims:o}=r;assertNotComplex$1(a,"min");const i=parseAxisParam(s,a.shape);let l=i;const u=getAxesPermutation(l,a.shape.length);let c=a;null!=u&&(c=transpose$1({inputs:{x:a},backend:n,attrs:{perm:u}}),l=getInnerMostAxes(l.length,a.shape.length)),assertAxesAreInnerMostDims("min",l,c.shape.length);const[p,d]=computeOutAndReduceShapes(c.shape,l),h=sizeFromShape(d),m=makeZerosTypedArray(sizeFromShape(p),c.dtype),f=n.data.get(c.dataId).values;for(let e=0;e<m.length;++e){const t=e*h;let n=f[t];for(let e=0;e<h;++e){const r=f[t+e];(Number.isNaN(r)||r<n)&&(n=r)}m[e]=n}null!=u&&n.disposeIntermediateTensorInfo(c);const g=n.makeTensorInfo(p,c.dtype,m);if(o){const e=reshape$1({inputs:{x:g},backend:n,attrs:{shape:expandShapeToKeepDim(p,i)}});return n.disposeIntermediateTensorInfo(g),e}return g}const minConfig$1={kernelName:Min,backendName:"cpu",kernelFunc:min$1};function mirrorPad(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{paddings:s,mode:o}=r;assertNotComplex$1(a,"mirrorPad");const i=s.map((e,t)=>e[0]+a.shape[t]+e[1]),l=s.map(e=>e[0]),u=s.map((e,t)=>e[0]+a.shape[t]),c="reflect"===o?0:1,p=n.data.get(a.dataId).values,d=a.shape.length,h=computeStrides(a.shape),m=sizeFromShape(i),f=i.length,g=computeStrides(i),$=getTypedArrayFromDType(a.dtype,m);for(let e=0;e<m;e++){let t=indexToLoc(e,f,g);for(let e=0;e<f;e++)t[e]<l[e]?t[e]=2*l[e]-t[e]-c:t[e]>=u[e]&&(t[e]=2*(u[e]-1)-t[e]+c);t=t.map((e,t)=>e-l[t]);const n=locToIndex(t,d,h);$[e]=p[n]}return{dataId:n.write($,i,a.dtype),shape:i,dtype:a.dtype}}const mirrorPadConfig$1={kernelName:MirrorPad,backendName:"cpu",kernelFunc:mirrorPad},modImpl=createSimpleBinaryKernelImpl((e,t)=>{const n=e%t;return e<0&&t<0||e>=0&&t>=0?n:(n+t)%t}),mod$1=binaryKernelFunc$1(Mod,modImpl),modConfig$1={kernelName:Mod,backendName:"cpu",kernelFunc:mod$1};function softmax$1(e){const{inputs:t,backend:n,attrs:r}=e,{logits:a}=t,{dim:s}=r,o=a.shape.length;let i=s;if(-1===i&&(i=o-1),i!==o-1)throw Error(`Softmax along a non-last dimension is not yet supported. Logits was rank ${o} and dim was ${i}`);const l=parseAxisParam([i],a.shape),u=max$1({inputs:{x:a},backend:n,attrs:{reductionIndices:l,keepDims:!1}}),c=expandShapeToKeepDim(u.shape,l),p=reshape$1({inputs:{x:u},backend:n,attrs:{shape:c}}),d=sub$1({inputs:{a,b:p},backend:n}),h=exp$1({inputs:{x:d},backend:n}),m=sum$1({inputs:{x:h},backend:n,attrs:{axis:l,keepDims:!1}}),f=reshape$1({inputs:{x:m},backend:n,attrs:{shape:c}}),g=div({inputs:{a:h,b:f},backend:n});return n.disposeIntermediateTensorInfo(u),n.disposeIntermediateTensorInfo(p),n.disposeIntermediateTensorInfo(d),n.disposeIntermediateTensorInfo(h),n.disposeIntermediateTensorInfo(m),n.disposeIntermediateTensorInfo(f),g}const softmaxConfig$1={kernelName:Softmax$2,backendName:"cpu",kernelFunc:softmax$1};function multinomial$1(e){const{inputs:t,backend:n,attrs:r}=e,{logits:a}=t,{numSamples:s,seed:o,normalized:i}=r;assertNotComplex$1(a,"multinomial");const l=i?a:softmax$1({inputs:{logits:a},backend:n,attrs:{dim:-1}}),u=l.shape[0],c=l.shape[1],p=n.data.get(l.dataId).values,d=[u,s],h=makeZerosTypedArray(sizeFromShape(d),"int32");for(let e=0;e<u;++e){const t=e*c,n=new Float32Array(c-1);n[0]=p[t];for(let e=1;e<n.length;++e)n[e]=n[e-1]+p[t+e];const r=seedrandom.alea(o.toString()),a=e*s;for(let e=0;e<s;++e){const t=r();h[a+e]=n.length;for(let r=0;r<n.length;r++)if(t<n[r]){h[a+e]=r;break}}}return i||n.disposeIntermediateTensorInfo(l),n.makeTensorInfo(d,"int32",h)}const multinomialConfig$1={kernelName:Multinomial,backendName:"cpu",kernelFunc:multinomial$1},nonMaxSuppressionV3Impl$1=nonMaxSuppressionV3Impl$2;function nonMaxSuppressionV3$1(e){const{inputs:t,backend:n,attrs:r}=e,{boxes:a,scores:s}=t,{maxOutputSize:o,iouThreshold:i,scoreThreshold:l}=r;assertNotComplex$1(a,"NonMaxSuppression");const u=n.data.get(a.dataId).values,c=n.data.get(s.dataId).values,{selectedIndices:p}=nonMaxSuppressionV3Impl$1(u,c,o,i,l);return n.makeTensorInfo([p.length],"int32",new Int32Array(p))}const nonMaxSuppressionV3Config$1={kernelName:NonMaxSuppressionV3,backendName:"cpu",kernelFunc:nonMaxSuppressionV3$1},nonMaxSuppressionV4Impl$1=nonMaxSuppressionV4Impl$2;function nonMaxSuppressionV4$1(e){const{inputs:t,backend:n,attrs:r}=e,{boxes:a,scores:s}=t,{maxOutputSize:o,iouThreshold:i,scoreThreshold:l,padToMaxOutputSize:u}=r;assertNotComplex$1(a,"NonMaxSuppressionPadded");const c=n.data.get(a.dataId).values,p=n.data.get(s.dataId).values,{selectedIndices:d,validOutputs:h}=nonMaxSuppressionV4Impl$1(c,p,o,i,l,u);return[n.makeTensorInfo([d.length],"int32",new Int32Array(d)),n.makeTensorInfo([],"int32",new Int32Array([h]))]}const nonMaxSuppressionV4Config$1={kernelName:NonMaxSuppressionV4,backendName:"cpu",kernelFunc:nonMaxSuppressionV4$1},nonMaxSuppressionV5Impl$1=nonMaxSuppressionV5Impl$2;function nonMaxSuppressionV5$1(e){const{inputs:t,backend:n,attrs:r}=e,{boxes:a,scores:s}=t,{maxOutputSize:o,iouThreshold:i,scoreThreshold:l,softNmsSigma:u}=r;assertNotComplex$1(a,"NonMaxSuppressionWithScore");const c=n.data.get(a.dataId).values,p=n.data.get(s.dataId).values,d=o,h=i,m=l,f=u,{selectedIndices:g,selectedScores:$}=nonMaxSuppressionV5Impl$1(c,p,d,h,m,f);return[n.makeTensorInfo([g.length],"int32",new Int32Array(g)),n.makeTensorInfo([$.length],"float32",new Float32Array($))]}const nonMaxSuppressionV5Config$1={kernelName:NonMaxSuppressionV5,backendName:"cpu",kernelFunc:nonMaxSuppressionV5$1};function oneHot$1(e){const{inputs:t,backend:n,attrs:r}=e,{indices:a}=t,{depth:s,onValue:o,offValue:i}=r;assertNotComplex$1(a,"oneHot");const l=sizeFromShape(a.shape),u=new Float32Array(l*s);u.fill(i);const c=n.data.get(a.dataId).values;for(let e=0;e<l;++e)c[e]>=0&&c[e]<s&&(u[e*s+c[e]]=o);return n.makeTensorInfo([...a.shape,s],"int32",u)}const oneHotConfig$1={kernelName:OneHot,backendName:"cpu",kernelFunc:oneHot$1};function zerosLike$1(e){const{inputs:t,backend:n}=e,{x:r}=t;if("string"===r.dtype)throw new Error("zerosLike is not supported for string tensors");if("complex64"===r.dtype){const e=real$1({inputs:{input:r},backend:n}),t=zerosLike$1({inputs:{x:e},backend:n}),a=imag$1({inputs:{input:r},backend:n}),s=zerosLike$1({inputs:{x:a},backend:n}),o=complex$1({inputs:{real:t,imag:s},backend:n});return n.disposeIntermediateTensorInfo(e),n.disposeIntermediateTensorInfo(t),n.disposeIntermediateTensorInfo(a),n.disposeIntermediateTensorInfo(s),o}return fill$1({backend:n,attrs:{shape:r.shape,value:0,dtype:r.dtype}})}const zerosLikeConfig$1={kernelName:ZerosLike,backendName:"cpu",kernelFunc:zerosLike$1};function onesLike$1(e){const{inputs:t,backend:n}=e,{x:r}=t;if("string"===r.dtype)throw new Error("onesLike is not supported for string tensors");if("complex64"===r.dtype){const e=real$1({inputs:{input:r},backend:n}),t=onesLike$1({inputs:{x:e},backend:n}),a=imag$1({inputs:{input:r},backend:n}),s=zerosLike$1({inputs:{x:a},backend:n}),o=complex$1({inputs:{real:t,imag:s},backend:n});return n.disposeIntermediateTensorInfo(e),n.disposeIntermediateTensorInfo(t),n.disposeIntermediateTensorInfo(a),n.disposeIntermediateTensorInfo(s),o}return fill$1({backend:n,attrs:{shape:r.shape,value:1,dtype:r.dtype}})}const onesLikeConfig$1={kernelName:OnesLike,backendName:"cpu",kernelFunc:onesLike$1};function pack$1(e){const{inputs:t,backend:n,attrs:r}=e,{axis:a}=r;if(1===t.length)return expandDims$1({inputs:{input:t[0]},backend:n,attrs:{dim:a}});const s=t[0].shape,o=t[0].dtype;t.forEach(e=>{assertShapesMatch(s,e.shape,"All tensors passed to stack must have matching shapes"),assert$4(o===e.dtype,()=>"All tensors passed to stack must have matching dtypes")});const i=[],l=concat$1({inputs:t.map(e=>{const t=expandDims$1({inputs:{input:e},backend:n,attrs:{dim:a}});return i.push(t),t}),backend:n,attrs:{axis:a}});return i.forEach(e=>n.disposeIntermediateTensorInfo(e)),l}const packConfig$1={kernelName:Pack,backendName:"cpu",kernelFunc:pack$1};function padV2$1(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{paddings:s,constantValue:o}=r;assertNotComplex$1(a,"pad");const i=s.map((e,t)=>e[0]+a.shape[t]+e[1]),l=s.map(e=>e[0]),u=n.data.get(a.dataId).values,c=sizeFromShape(a.shape),p=a.shape.length,d=computeStrides(a.shape),h=sizeFromShape(i),m=i.length,f=computeStrides(i),g=getTypedArrayFromDType(a.dtype,h);0!==o&&g.fill(o);for(let e=0;e<c;e++)g[locToIndex(indexToLoc(e,p,d).map((e,t)=>e+l[t]),m,f)]=u[e];return{dataId:n.write(g,i,a.dtype),shape:i,dtype:a.dtype}}const padV2Config$1={kernelName:PadV2,backendName:"cpu",kernelFunc:padV2$1},powImpl=createSimpleBinaryKernelImpl((e,t)=>Math.pow(e,t)),pow$1=binaryKernelFunc$1(Pow,powImpl),powConfig$1={kernelName:Pow,backendName:"cpu",kernelFunc:pow$1};function range$2(e){const{backend:t,attrs:n}=e,{start:r,stop:a,dtype:s,step:o}=n,i=rangeImpl(r,a,o,s);return t.makeTensorInfo([i.length],s,i)}const rangeConfig$1={kernelName:Range,backendName:"cpu",kernelFunc:range$2},reciprocal$1=unaryKernelFunc$1(Reciprocal,e=>1/e),reciprocalConfig$1={kernelName:Reciprocal,backendName:"cpu",kernelFunc:reciprocal$1};function resizeBilinear$1(e){const{inputs:t,backend:n,attrs:r}=e,{images:a}=t,{alignCorners:s,halfPixelCenters:o,size:i}=r;assertNotComplex$1(a,"resizeBilinear");const l=computeStrides(a.shape),[u,c]=i,[p,d,h,m]=a.shape,f=n.data.get(a.dataId).values,g=new Float32Array(sizeFromShape([p,u,c,m])),$=[s&&u>1?d-1:d,s&&c>1?h-1:h],y=[s&&u>1?u-1:u,s&&c>1?c-1:c];let b=0;const x=$[0]/y[0],v=$[1]/y[1];for(let e=0;e<p;e++)for(let t=0;t<u;t++){let n;n=o?x*(t+.5)-.5:x*t;const r=Math.max(0,Math.floor(n)),a=n-r,s=Math.min(d-1,Math.ceil(n)),i=e*l[0]+r*l[1],u=e*l[0]+s*l[1];for(let e=0;e<c;e++){let t;t=o?v*(e+.5)-.5:v*e;const n=Math.max(0,Math.floor(t)),r=t-n,s=Math.min(h-1,Math.ceil(t)),c=i+n*l[2],p=u+n*l[2],d=i+s*l[2],$=u+s*l[2];for(let e=0;e<m;e++){const t=f[c+e],n=f[p+e],s=t+(f[d+e]-t)*r;g[b++]=s+(n+(f[$+e]-n)*r-s)*a}}}return n.makeTensorInfo([p,u,c,m],"float32",g)}const resizeBilinearConfig$1={kernelName:ResizeBilinear,backendName:"cpu",kernelFunc:resizeBilinear$1};function resizeBilinearGrad$1(e){const{inputs:t,backend:n,attrs:r}=e,{images:a,dy:s}=t,{alignCorners:o}=r;assertNotComplex$1([s,a],"resizeBilinearGrad");const i=computeStrides(a.shape),[l,u,c,p]=a.shape,[,d,h]=s.shape,m=new Float32Array(l*u*c*p),f=[o&&d>1?u-1:u,o&&h>1?c-1:c],g=[o&&d>1?d-1:d,o&&h>1?h-1:h],$=f[0]/g[0],y=f[1]/g[1],b=n.data.get(s.dataId).values;let x=0;for(let e=0;e<l;e++){const t=e*i[0];for(let e=0;e<d;e++){const n=e*$,r=Math.floor(n),a=Math.min(Math.ceil(n),u-1),s=t+r*i[1],o=t+a*i[1],l=n-r,d=1-l;for(let e=0;e<h;e++){const t=e*y,n=Math.floor(t),r=Math.min(Math.ceil(t),c-1),a=t-n,u=1-a,h=s+n*i[2],f=s+r*i[2],g=o+n*i[2],$=o+r*i[2],v=d*u,I=d*a,C=l*u,S=l*a;for(let e=0;e<p;e++){const t=b[x++];m[h+e]+=t*v,m[f+e]+=t*I,m[g+e]+=t*C,m[$+e]+=t*S}}}}return n.makeTensorInfo([l,c,u,p],"float32",m)}const resizeBilinearGradConfig$1={kernelName:ResizeBilinearGrad,backendName:"cpu",kernelFunc:resizeBilinearGrad$1};function resizeNearestNeighbor$1(e){const{inputs:t,backend:n,attrs:r}=e,{images:a}=t,{alignCorners:s,halfPixelCenters:o,size:i}=r;assertNotComplex$1(a,"resizeNearestNeighbor");const l=computeStrides(a.shape),[u,c]=i,[p,d,h,m]=a.shape,f=n.data.get(a.dataId).values,g=new Float32Array(p*u*c*m),$=[s&&u>1?d-1:d,s&&c>1?h-1:h],y=[s&&u>1?u-1:u,s&&c>1?c-1:c],b=$[0]/y[0],x=$[1]/y[1];let v=0;for(let e=0;e<p;e++){const t=e*l[0];for(let e=0;e<u;e++){const n=o?b*(e+.5):b*e;let r=Math.min(d-1,s?Math.round(n):Math.floor(n));o&&(r=Math.max(0,r));const a=t+r*l[1];for(let e=0;e<c;e++){const t=o?x*(e+.5):x*e;let n=Math.min(h-1,s?Math.round(t):Math.floor(t));o&&(n=Math.max(0,n));const r=a+n*l[2];for(let e=0;e<m;e++)g[v++]=f[r+e]}}}return n.makeTensorInfo([p,u,c,m],a.dtype,g)}const resizeNearestNeighborConfig$1={kernelName:ResizeNearestNeighbor,backendName:"cpu",kernelFunc:resizeNearestNeighbor$1};function resizeNearestNeighborGrad$1(e){const{inputs:t,backend:n,attrs:r}=e,{images:a,dy:s}=t,{alignCorners:o}=r;assertNotComplex$1([s,a],"resizeNearestNeighborGrad");const i=computeStrides(a.shape),l=computeStrides(s.shape),[u,c,p,d]=a.shape,[,h,m]=s.shape,f=new Float32Array(u*c*p*d),g=n.data.get(s.dataId).values,$=[o&&h>1?c-1:c,o&&m>1?p-1:p],y=[o&&h>1?h-1:h,o&&m>1?m-1:m],b=$[0]/y[0],x=$[1]/y[1],v=1/b,I=1/x,C=2*Math.ceil(v)+2,S=2*Math.ceil(I)+2;for(let e=0;e<u;e++){const t=e*i[0];for(let e=0;e<c;e++){const n=t+e*i[1],r=Math.floor(e*v),a=Math.floor(r-C/2);for(let r=0;r<p;r++){const s=n+r*i[2],u=Math.floor(r*I),$=Math.floor(u-S/2);for(let n=0;n<d;n++){let i=0;for(let s=0;s<C;s++){const u=s+a;if(u<0||u>=h)continue;const d=t+u*l[1],f=u*b;if(e===Math.min(c-1,o?Math.round(f):Math.floor(f)))for(let e=0;e<S;e++){const t=e+$;if(t<0||t>=m)continue;const a=d+t*l[2],s=t*x;r===Math.min(p-1,o?Math.round(s):Math.floor(s))&&(i+=g[a+n])}}f[s+n]=i}}}}return n.makeTensorInfo(a.shape,a.dtype,f)}const resizeNearestNeighborGradConfig$1={kernelName:ResizeNearestNeighborGrad,backendName:"cpu",kernelFunc:resizeNearestNeighborGrad$1};function reverse$1(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{dims:s}=r;assertNotComplex$1(a,"reverse");const o=a.shape.length,i=parseAxisParam(s,a.shape);if(0===o)return identity$1({inputs:{x:a},backend:n});const l=new TensorBuffer(a.shape,a.dtype),u=n.bufferSync(a);for(let e=0;e<l.size;e++){const t=l.indexToLoc(e),n=t.slice();i.forEach(e=>n[e]=a.shape[e]-1-n[e]),l.set(u.get(...n),...t)}return n.makeTensorInfo(l.shape,l.dtype,l.values)}const reverseConfig$1={kernelName:Reverse,backendName:"cpu",kernelFunc:reverse$1},rotateWithOffsetConfig$1={kernelName:RotateWithOffset,backendName:"cpu",kernelFunc:({inputs:e,attrs:t,backend:n})=>{const{image:r}=e,{radians:a,fillValue:s,center:o}=t,i=n,l=getTypedArrayFromDType(r.dtype,sizeFromShape(r.shape)),[u,c,p,d]=r.shape,[h,m]=getImageCenter(o,c,p),f=Math.sin(a),g=Math.cos(a),$=i.data.get(r.dataId).values;for(let e=0;e<u;e++){const t=e*p*c*d;for(let e=0;e<c;e++){const n=e*(p*d);for(let r=0;r<p;r++){const a=r*d;for(let o=0;o<d;o++){const i=[u,e,r,o],y=i[2],b=i[1];let x=(y-h)*g-(b-m)*f,v=(y-h)*f+(b-m)*g;x=Math.round(x+h),v=Math.round(v+m);let I=s;"number"!=typeof s&&(I=3===o?255:s[o]),x>=0&&x<p&&v>=0&&v<c&&(I=$[t+v*(p*d)+x*d+o]),l[t+n+a+o]=I}}}}return{dataId:i.write(l,r.shape,r.dtype),shape:r.shape,dtype:r.dtype}}},round$1=unaryKernelFunc$1(Round,e=>{const t=Math.floor(e);return e-t<.5?Math.floor(e):e-t>.5?Math.ceil(e):t%2==0?t:t+1}),roundConfig$1={kernelName:Round,backendName:"cpu",kernelFunc:round$1};function scatterImpl(e,t,n,r,a,s,o,i,l,u){const c=[r/a,a],p=e.values,d=t.values;if(0===r)return buffer(n,t.dtype);const h=buffer(c,t.dtype);h.values.fill(l);for(let e=0;e<s;e++){const s=[];let l=0;for(let t=0;t<o;t++){const n=p[e*o+t];s.push(n),l+=n*i[t]}if(l<0||l>=r/a)throw new Error(`Invalid indices: ${s} does not index into ${n}`);for(let n=0;n<a;n++)u?h.values[l*a+n]+=d[e*a+n]:h.values[l*a+n]=0===t.rank?d[0]:d[e*a+n]}return h}function scatterNd$1(e){const{inputs:t,backend:n,attrs:r}=e,{indices:a,updates:s}=t,{shape:o}=r,{sliceRank:i,numUpdates:l,sliceSize:u,strides:c,outputSize:p}=calculateShapes(s,a,o),d=scatterImpl(n.bufferSync(a),n.bufferSync(s),o,p,u,l,i,c,0,!0);return n.makeTensorInfo(o,d.dtype,d.values)}const scatterNdConfig$1={kernelName:ScatterNd,backendName:"cpu",kernelFunc:scatterNd$1};function select$1(e){const{inputs:t,backend:n}=e,{condition:r,t:a,e:s}=t;assertNotComplex$1([r,a,s],"select");const o=r.shape.length,i=n.data.get(r.dataId).values,l=n.data.get(a.dataId).values,u=n.data.get(s.dataId).values,c=upcastType(a.dtype,s.dtype),p=makeZerosTypedArray(sizeFromShape(a.shape),c);let d=0;const h=0===o||o>1||1===a.shape.length?1:sizeFromShape(a.shape.slice(1));for(let e=0;e<i.length;e++)for(let t=0;t<h;t++)p[d++]=1===i[e]?l[e]:u[e];return n.makeTensorInfo(a.shape,c,p)}const selectConfig$1={kernelName:Select,backendName:"cpu",kernelFunc:select$1},scaleAlpha=SELU_SCALEALPHA,scale=SELU_SCALE,selu$1=unaryKernelFunc$1(Selu$1,e=>e>=0?scale*e:scaleAlpha*(Math.exp(e)-1)),seluConfig$1={kernelName:Selu$1,backendName:"cpu",kernelFunc:selu$1},sign$1=unaryKernelFunc$1(Sign,e=>e<0?-1:e>0?1:0),signConfig$1={kernelName:Sign,backendName:"cpu",kernelFunc:sign$1},sin$1=unaryKernelFunc$1(Sin,e=>Math.sin(e)),sinConfig$1={kernelName:Sin,backendName:"cpu",kernelFunc:sin$1},sinh$1=unaryKernelFunc$1(Sinh,e=>Math.sinh(e)),sinhConfig$1={kernelName:Sinh,backendName:"cpu",kernelFunc:sinh$1},epsilon=1.1920928955078125e-7,threshold=Math.log(epsilon)+2,softplus$1=unaryKernelFunc$1(Softplus$1,e=>{const t=e>-threshold,n=e<threshold,r=Math.exp(e);let a;return a=n?r:t?e:Math.log(1+r),a}),softplusConfig$1={kernelName:Softplus$1,backendName:"cpu",kernelFunc:softplus$1};function spaceToBatchND$1(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{blockShape:s,paddings:o}=r;assertNotComplex$1([a],"spaceToBatchND");const i=sizeFromShape(s),l=[[0,0]];l.push(...o);for(let e=1+s.length;e<a.shape.length;++e)l.push([0,0]);const u=padV2Config$1.kernelFunc({inputs:{x:a},backend:n,attrs:{paddings:l,constantValue:0}}),c=getReshaped(u.shape,s,i,!1),p=getPermuted(c.length,s.length,!1),d=getReshapedPermuted(u.shape,s,i,!1),h=reshape$1({inputs:{x:u},backend:n,attrs:{shape:c}}),m=transpose$1({inputs:{x:h},backend:n,attrs:{perm:p}}),f=reshape$1({inputs:{x:m},backend:n,attrs:{shape:d}});return n.disposeIntermediateTensorInfo(u),n.disposeIntermediateTensorInfo(h),n.disposeIntermediateTensorInfo(m),f}const spaceToBatchNDConfig$1={kernelName:SpaceToBatchND,backendName:"cpu",kernelFunc:spaceToBatchND$1};function sparseFillEmptyRows$1(e){const{inputs:t,backend:n}=e,{indices:r,values:a,denseShape:s,defaultValue:o}=t;if(1!==s.shape.length)throw new Error(`Dense shape must be a vector, saw:\n        ${s.shape}`);if(2!==r.shape.length)throw new Error(`Indices must be a matrix, saw:\n        ${r.shape}`);if(1!==a.shape.length)throw new Error(`Values must be a vector, saw:\n        ${a.shape}`);if(0!==o.shape.length)throw new Error(`Default value must be a scalar, saw:\n        ${o.shape}`);const i=n.data.get(r.dataId).values,l=n.data.get(a.dataId).values,u=n.data.get(s.dataId).values,c=n.data.get(o.dataId).values[0],[p,d,h,m,f]=sparseFillEmptyRowsImpl(i,r.shape,r.dtype,l,a.dtype,u,c);return[n.makeTensorInfo(d,r.dtype,p),n.makeTensorInfo([d[0]],a.dtype,h),n.makeTensorInfo([m.length],"bool",new Uint8Array(m.map(e=>Number(e)))),n.makeTensorInfo([f.length],r.dtype,new Int32Array(f))]}const sparseFillEmptyRowsConfig$1={kernelName:SparseFillEmptyRows,backendName:"cpu",kernelFunc:sparseFillEmptyRows$1};function sparseReshape$1(e){const{inputs:t,backend:n}=e,{inputIndices:r,inputShape:a,newShape:s}=t;if(2!==r.shape.length)throw new Error(`Input indices should be a matrix but received shape\n        ${r.shape}`);if(1!==a.shape.length)throw new Error(`Input shape should be a vector but received shape\n        ${a.shape}`);if(1!==s.shape.length)throw new Error(`Target shape should be a vector but received shape ${s.shape}`);const o=Array.from(n.data.get(a.dataId).values),i=n.data.get(r.dataId).values,l=Array.from(n.data.get(s.dataId).values),[u,c,p]=sparseReshapeImpl(i,r.shape,r.dtype,o,l);return[n.makeTensorInfo(c,r.dtype,u),n.makeTensorInfo([p.length],s.dtype,new Int32Array(p))]}const sparseReshapeConfig$1={kernelName:SparseReshape,backendName:"cpu",kernelFunc:sparseReshape$1};function sparseSegmentMean$1(e){const{inputs:t,backend:n}=e,{data:r,indices:a,segmentIds:s}=t;if(r.shape.length<1)throw new Error("Data should be at least 1 dimensional but received scalar");if(1!==a.shape.length)throw new Error(`Indices should be a vector but received shape\n          ${a.shape}`);if(1!==s.shape.length)throw new Error(`Segment ids should be a vector but received shape\n          ${s.shape}`);const o=n.data.get(r.dataId).values,i=n.data.get(a.dataId).values,l=n.data.get(s.dataId).values,[u,c]=sparseSegmentReductionImpl(o,r.shape,r.dtype,i,l,!0);return n.makeTensorInfo(c,r.dtype,u)}const sparseSegmentMeanConfig$1={kernelName:SparseSegmentMean,backendName:"cpu",kernelFunc:sparseSegmentMean$1};function sparseSegmentSum$1(e){const{inputs:t,backend:n}=e,{data:r,indices:a,segmentIds:s}=t;if(r.shape.length<1)throw new Error("Data should be at least 1 dimensional but received scalar");if(1!==a.shape.length)throw new Error(`Indices should be a vector but received shape\n         ${a.shape}`);if(1!==s.shape.length)throw new Error(`Segment ids should be a vector but received shape\n         ${s.shape}`);const o=n.data.get(r.dataId).values,i=n.data.get(a.dataId).values,l=n.data.get(s.dataId).values,[u,c]=sparseSegmentReductionImpl(o,r.shape,r.dtype,i,l);return n.makeTensorInfo(c,r.dtype,u)}const sparseSegmentSumConfig$1={kernelName:SparseSegmentSum,backendName:"cpu",kernelFunc:sparseSegmentSum$1};function sparseToDense$1(e){const{inputs:t,backend:n,attrs:r}=e,{sparseIndices:a,sparseValues:s,defaultValue:o}=t,{outputShape:i}=r,{sliceRank:l,numUpdates:u,sliceSize:c,strides:p,outputSize:d}=calculateShapes(s,a,i),h=scatterImpl(n.bufferSync(a),n.bufferSync(s),i,d,c,u,l,p,n.data.get(o.dataId).values[0],!1);return n.makeTensorInfo(i,h.dtype,h.values)}const sparseToDenseConfig$1={kernelName:SparseToDense,backendName:"cpu",kernelFunc:sparseToDense$1};function splitV$1(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{numOrSizeSplits:s,axis:o}=r,i=parseAxisParam(o,a.shape)[0],l=prepareSplitSize(a,s,i),u=new Array(a.shape.length).fill(0),c=a.shape.slice();return l.map(e=>{const t=[...c];t[i]=e;const r=slice$1({inputs:{x:a},backend:n,attrs:{begin:u,size:t}});return u[i]+=e,r})}const splitVConfig$1={kernelName:SplitV,backendName:"cpu",kernelFunc:splitV$1},sqrt$1=unaryKernelFunc$1(Sqrt,e=>Math.sqrt(e)),sqrtConfig$1={kernelName:Sqrt,backendName:"cpu",kernelFunc:sqrt$1},squareConfig$1={kernelName:Square,backendName:"cpu",kernelFunc:({inputs:e,backend:t})=>{const{x:n}=e,r=t;assertNotComplex$1(n,"square");const a=r.data.get(n.dataId).values,s=new Float32Array(a.length);for(let e=0;e<a.length;++e){const t=a[e];s[e]=t*t}return{dataId:r.write(s,n.shape,n.dtype),shape:n.shape,dtype:n.dtype}}},step$1=unaryKernelFunc$1(Step,(e,t)=>{const n=t;return isNaN(e)?NaN:e>0?1:n.alpha}),stepConfig$1={kernelName:Step,backendName:"cpu",kernelFunc:step$1};function stridedSlice$1(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{begin:s,end:o,strides:i,beginMask:l,endMask:u,ellipsisMask:c,newAxisMask:p,shrinkAxisMask:d}=r;assertNotComplex$1(a,"stridedSlice");const{nonStrided:h,$begin:m,$strides:f,size:g,newShape:$,outShape:y}=sliceInfo(a.shape,s,o,i,l,u,c,p,d),b=reshape$1({inputs:{x:a},backend:n,attrs:{shape:$}});let x;if(h){const e=slice$1({inputs:{x:b},backend:n,attrs:{begin:m,size:g}});x=reshape$1({inputs:{x:e},backend:n,attrs:{shape:y}}),n.disposeIntermediateTensorInfo(e)}else if(y.some(e=>0===e))x=n.makeTensorInfo(y,a.dtype,[]);else{const e=stridedSliceImpl(y,n.bufferSync(b),f,m);x=n.makeTensorInfo(e.shape,e.dtype,e.values)}const v=reshape$1({inputs:{x},backend:n,attrs:{shape:y}});return n.disposeIntermediateTensorInfo(b),n.disposeIntermediateTensorInfo(x),v}const stridedSliceConfig$1={kernelName:StridedSlice,backendName:"cpu",kernelFunc:stridedSlice$1};function stringNGrams$1(e){const{inputs:t,backend:n,attrs:r}=e,{separator:a,nGramWidths:s,leftPad:o,rightPad:i,padWidth:l,preserveShortSequences:u}=r,{data:c,dataSplits:p}=t,d=n.data.get(c.dataId).values,h=n.data.get(p.dataId).values,[m,f]=stringNGramsImpl(d,h,a,s,o,i,l,u);return[n.makeTensorInfo([m.length],"string",m),n.makeTensorInfo(p.shape,"int32",f)]}const stringNGramsConfig$1={kernelName:StringNGrams,backendName:"cpu",kernelFunc:stringNGrams$1};function stringSplit$1(e){const{inputs:t,backend:n,attrs:r}=e,{skipEmpty:a}=r,{input:s,delimiter:o}=t;if("string"!==s.dtype)throw new Error("Input must be of datatype string");if(1!==s.shape.length)throw new Error(`Input must be a vector, got shape: ${s.shape}`);if(0!==o.shape.length)throw new Error(`Delimiter must be a scalar, got shape: ${o.shape}`);const i=n.data.get(s.dataId).values,l=n.data.get(o.dataId).values[0],[u,c,p]=stringSplitImpl(i,l,a),d=c.length;return[n.makeTensorInfo([d,2],"int32",u),n.makeTensorInfo([d],"string",c),n.makeTensorInfo([2],"int32",new Int32Array(p))]}const stringSplitConfig$1={kernelName:StringSplit,backendName:"cpu",kernelFunc:stringSplit$1};function stringToHashBucketFast$1(e){const{inputs:t,backend:n,attrs:r}=e,{numBuckets:a}=r,{input:s}=t;if("string"!==s.dtype)throw new Error("Input must be of datatype string");if(a<=0)throw new Error("Number of buckets must be at least 1");const o=stringToHashBucketFastImpl(n.data.get(s.dataId).values,a);return n.makeTensorInfo(s.shape,"int32",o)}const stringToHashBucketFastConfig$1={kernelName:StringToHashBucketFast,backendName:"cpu",kernelFunc:stringToHashBucketFast$1},tan$1=unaryKernelFunc$1(Tan,e=>Math.tan(e)),tanConfig$1={kernelName:Tan,backendName:"cpu",kernelFunc:tan$1},tanh$1=unaryKernelFunc$1(Tanh$1,e=>Math.tanh(e)),tanhConfig$1={kernelName:Tanh$1,backendName:"cpu",kernelFunc:tanh$1};function tile$1(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{reps:s}=r;assertNotComplex$1(a,"tile");const o=tileImpl(n.bufferSync(a),s);return n.makeTensorInfo(o.shape,o.dtype,o.values)}const tileConfig$1={kernelName:Tile,backendName:"cpu",kernelFunc:tile$1};function topK$1(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{k:s,sorted:o}=r;assertNotComplex$1(a,"topk");const i=n.data.get(a.dataId).values,[l,u]=topKImpl(i,a.shape,a.dtype,s,o);return[n.makeTensorInfo(l.shape,l.dtype,l.values),n.makeTensorInfo(u.shape,u.dtype,u.values)]}const topKConfig$1={kernelName:TopK,backendName:"cpu",kernelFunc:topK$1};function transform$1(e){const{inputs:t,attrs:n,backend:r}=e,{image:a,transforms:s}=t,{interpolation:o,fillMode:i,fillValue:l,outputShape:u}=n,[c,p,d,h]=a.shape,[m,f]=null!=u?u:[p,d],g=[c,m,f,h],$=computeStrides(a.shape),y=$[0],b=$[1],x=$[2],v=getTypedArrayFromDType(a.dtype,sizeFromShape(g));v.fill(l);const I=r.data.get(a.dataId).values,C=r.data.get(s.dataId).values;for(let e=0;e<c;++e){const t=1===s.shape[0]?C:C.subarray(8*e,8*e+8);for(let n=0;n<m;++n)for(let r=0;r<f;++r)for(let a=0;a<h;++a){let s;const u=t[6]*r+t[7]*n+1;if(0===u)continue;const c=(t[3]*r+t[4]*n+t[5])/u,h=mapCoord((t[0]*r+t[1]*n+t[2])/u,d,i),m=mapCoord(c,p,i);switch(o){case"nearest":s=nearestInterpolation(I,p,d,y,b,x,e,m,h,a,l);break;case"bilinear":s=bilinearInterpolation(I,p,d,y,b,x,e,m,h,a,l);break;default:throw new Error(`Error in Transform: Expect 'nearest' or 'bilinear', but got ${o}`)}v[e*y+n*b+r*x+a]=s}return r.makeTensorInfo(g,a.dtype,v)}return{dataId:r.write(v,g,a.dtype),shape:a.shape,dtype:a.dtype}}const transformConfig$1={kernelName:Transform,backendName:"cpu",kernelFunc:transform$1};function mapCoord(e,t,n){switch(n){case"reflect":return mapCoordReflect(e,t);case"wrap":return mapCoordWrap(e,t);case"nearest":return mapCoordNearest(e,t);case"constant":default:return mapCoordConstant(e)}}function mapCoordReflect(e,t){let n=e;if(n<0)if(t<=1)n=0;else{const e=2*t;n<e&&(n=e*Math.trunc(-n/e)+n),n=n<-t?n+e:-n-1}else if(n>t-1)if(t<=1)n=0;else{const e=2*t;n-=e*Math.trunc(n/e),n>=t&&(n=e-n-1)}return clamp(0,n,t-1)}function mapCoordWrap(e,t){let n=e;return n<0?t<=1?n=0:n+=t*(Math.trunc(-n/(t-1))+1):n>t-1&&(t<=1?n=0:n-=t*Math.trunc(n/(t-1))),clamp(0,n,t-1)}function mapCoordConstant(e,t){return e}function mapCoordNearest(e,t){return clamp(0,e,t-1)}function readWithFillValue(e,t,n,r,a,s,o,i,l,u,c){return 0<=i&&i<t&&0<=l&&l<n?e[o*r+i*a+l*s+u]:c}function nearestInterpolation(e,t,n,r,a,s,o,i,l,u,c){return readWithFillValue(e,t,n,r,a,s,o,Math.round(i),Math.round(l),u,c)}function bilinearInterpolation(e,t,n,r,a,s,o,i,l,u,c){const p=Math.floor(i),d=Math.floor(l),h=p+1,m=d+1;return(h-i)*((m-l)*readWithFillValue(e,t,n,r,a,s,o,p,d,u,c)+(l-d)*readWithFillValue(e,t,n,r,a,s,o,p,m,u,c))+(i-p)*((m-l)*readWithFillValue(e,t,n,r,a,s,o,h,d,u,c)+(l-d)*readWithFillValue(e,t,n,r,a,s,o,h,m,u,c))}function unique$1(e){const{inputs:t,attrs:n,backend:r}=e,{axis:a}=n,{x:s}=t;assertNotComplex$1(s,"unique");const o=r.data.get(s.dataId).values,{outputValues:i,outputShape:l,indices:u}=uniqueImpl(o,a,s.shape,s.dtype);return[r.makeTensorInfo(l,s.dtype,i),r.makeTensorInfo([u.length],"int32",u)]}const uniqueConfig$1={kernelName:Unique,backendName:"cpu",kernelFunc:unique$1};function unpack$1(e){const{inputs:t,backend:n,attrs:r}=e,{value:a}=t;let{axis:s}=r;s<0&&(s+=a.shape.length);const o=a.shape.length,i=a.shape[s],l=new Array(o-1);let u=0;for(let e=0;e<o;e++)e!==s&&(l[u++]=a.shape[e]);const c=new Array(o).fill(0),p=a.shape.slice();p[s]=1;const d=new Array(i);for(let e=0;e<d.length;e++){c[s]=e;const t=slice$1({inputs:{x:a},backend:n,attrs:{begin:c,size:p}});d[e]=reshape$1({inputs:{x:t},backend:n,attrs:{shape:l}}),n.disposeIntermediateTensorInfo(t)}return d}const unpackConfig$1={kernelName:Unpack,backendName:"cpu",kernelFunc:unpack$1};function unsortedSegmentSum$1(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,segmentIds:s}=t,{numSegments:o}=r;assertNotComplex$1(a,"unsortedSegmentSum");const i=[],l=[],u=a.shape.length-s.shape.length;let c=s;for(let e=0;e<u;++e){const t=expandDims$1({inputs:{input:c},backend:n,attrs:{dim:e+1}});c=t,l.push(t)}for(let e=0;e<o;++e){const t=createScalarValue(e,"int32"),r=n.makeTensorInfo([],"int32",t),s=equal$1({inputs:{a:r,b:c},backend:n}),o=cast$1({inputs:{x:s},backend:n,attrs:{dtype:"float32"}}),u=multiply$1({inputs:{a:o,b:a},backend:n}),p=sum$1({inputs:{x:u},backend:n,attrs:{axis:0,keepDims:!1}});i.push(p),l.push(r),l.push(s),l.push(o),l.push(u),l.push(p)}const p=pack$1({inputs:i,backend:n,attrs:{axis:0}});return l.forEach(e=>n.disposeIntermediateTensorInfo(e)),p}const unsortedSegmentSumConfig$1={kernelName:UnsortedSegmentSum,backendName:"cpu",kernelFunc:unsortedSegmentSum$1},kernelConfigs$1=[_fusedMatMulConfig$1,absConfig$1,acosConfig$1,acoshConfig$1,addConfig$1,addNConfig$1,allConfig$1,anyConfig$1,argMaxConfig$1,argMinConfig$1,asinConfig$1,asinhConfig$1,atanConfig$1,atan2Config$1,atanhConfig$1,avgPoolConfig$1,avgPool3DConfig$1,avgPool3DGradConfig,avgPoolGradConfig$1,batchMatMulConfig$1,batchNormConfig$1,batchToSpaceNDConfig$1,bincountConfig$1,castConfig$1,ceilConfig$1,clipConfig,complexConfig$1,complexAbsConfig$1,concatConfig$1,conv2DBackpropFilterConfig$1,conv2DBackpropInputConfig$1,conv2DConfig$1,conv3DBackpropFilterV2Config$1,conv3DBackpropInputV2Config,conv3DConfig$1,cosConfig$1,coshConfig$1,cropAndResizeConfig$1,cumsumConfig$1,denseBincountConfig$1,depthToSpaceConfig$1,depthwiseConv2dNativeConfig$1,depthwiseConv2dNativeBackpropFilterConfig$1,depthwiseConv2dNativeBackpropInputConfig$1,diagConfig$1,dilation2dConfig,dilation2dBackpropInputConfig,dilation2dBackpropFilterConfig,realDivConfig$1,einsumConfig$1,eluConfig$1,eluGradConfig$1,equalConfig$1,erfConfig$1,expConfig$1,expandDimsConfig$1,expm1Config$1,fftConfig$1,fillConfig$1,flipLeftRightConfig$1,floorConfig$1,floorDivConfig$1,fusedConv2DConfig$1,fusedDepthwiseConv2DConfig$1,gatherNdConfig$1,gatherV2Config$1,greaterConfig$1,greaterEqualConfig$1,identityConfig$1,ifftConfig$1,imagConfig$1,isFiniteConfig$1,isInfConfig$1,isNaNConfig$1,leakyReluConfig$1,lessConfig$1,lessEqualConfig$1,linSpaceConfig$1,logConfig$1,log1pConfig$1,logicalAndConfig$1,logicalNotConfig$1,logicalOrConfig$1,lRNConfig,lRNGradConfig,maximumConfig$1,maxPoolConfig$1,maxPool3DConfig$1,maxPool3DGradConfig,maxPoolGradConfig$1,maxPoolWithArgmaxConfig$1,maxConfig$1,meanConfig$1,minConfig$1,minimumConfig$1,mirrorPadConfig$1,modConfig$1,multinomialConfig$1,multiplyConfig$1,negConfig$1,nonMaxSuppressionV3Config$1,nonMaxSuppressionV4Config$1,nonMaxSuppressionV5Config$1,notEqualConfig$1,oneHotConfig$1,onesLikeConfig$1,packConfig$1,padV2Config$1,powConfig$1,preluConfig$1,prodConfig$1,rangeConfig$1,realConfig$1,reciprocalConfig$1,reluConfig$1,relu6Config$1,reshapeConfig$1,resizeBilinearConfig$1,resizeBilinearGradConfig$1,resizeNearestNeighborConfig$1,resizeNearestNeighborGradConfig$1,reverseConfig$1,rotateWithOffsetConfig$1,roundConfig$1,rsqrtConfig$1,scatterNdConfig$1,selectConfig$1,seluConfig$1,sigmoidConfig$1,signConfig$1,sinConfig$1,sinhConfig$1,sliceConfig$1,softmaxConfig$1,softplusConfig$1,spaceToBatchNDConfig$1,sparseFillEmptyRowsConfig$1,sparseReshapeConfig$1,sparseSegmentMeanConfig$1,sparseSegmentSumConfig$1,sparseToDenseConfig$1,splitVConfig$1,sqrtConfig$1,squareConfig$1,squaredDifferenceConfig$1,stepConfig$1,stridedSliceConfig$1,stringNGramsConfig$1,stringSplitConfig$1,stringToHashBucketFastConfig$1,subConfig$1,sumConfig$1,tanConfig$1,tanhConfig$1,tileConfig$1,topKConfig$1,transposeConfig$1,transformConfig$1,uniqueConfig$1,unpackConfig$1,unsortedSegmentSumConfig$1,zerosLikeConfig$1];for(const e of kernelConfigs$1)registerKernel(e);const contexts={},WEBGL_ATTRIBUTES={alpha:!1,antialias:!1,premultipliedAlpha:!1,preserveDrawingBuffer:!1,depth:!1,stencil:!1,failIfMajorPerformanceCaveat:!0};function setWebGLContext(e,t){contexts[e]=t}function getWebGLContext(e){if(!(e in contexts)){const t=getWebGLRenderingContext(e);if(null===t)return console.log("Could not get context for WebGL version",e),null;contexts[e]=t}const t=contexts[e];return t.isContextLost()?(delete contexts[e],getWebGLContext(e)):(t.disable(t.DEPTH_TEST),t.disable(t.STENCIL_TEST),t.disable(t.BLEND),t.disable(t.DITHER),t.disable(t.POLYGON_OFFSET_FILL),t.disable(t.SAMPLE_COVERAGE),t.enable(t.SCISSOR_TEST),t.enable(t.CULL_FACE),t.cullFace(t.BACK),contexts[e])}function createCanvas(e){if("undefined"!=typeof OffscreenCanvas&&2===e)return new OffscreenCanvas(300,150);if("undefined"!=typeof document)return document.createElement("canvas");throw new Error("Cannot create a canvas in this context")}function getWebGLRenderingContext(e){if(1!==e&&2!==e)throw new Error("Cannot get WebGL rendering context, WebGL is disabled.");const t=createCanvas(e);return t.addEventListener("webglcontextlost",t=>{t.preventDefault(),delete contexts[e]},!1),1===e?t.getContext("webgl",WEBGL_ATTRIBUTES)||t.getContext("experimental-webgl",WEBGL_ATTRIBUTES):t.getContext("webgl2",WEBGL_ATTRIBUTES)}var PackingScheme,TextureUsage,PhysicalTextureType;function getUnpackedMatrixTextureShapeWidthHeight(e,t){return[t,e]}function getUnpackedArraySizeFromMatrixSize(e,t){return e*t}function getDenseTexShape(e){const t=sizeFromShape(e);return sizeToSquarishShape(Math.ceil(t/4))}function getPackedMatrixTextureShapeWidthHeight(e,t){return[Math.max(1,Math.ceil(t/2)),Math.max(1,Math.ceil(e/2))]}function getPackedRGBAArraySizeFromMatrixShape(e,t){const[n,r]=getPackedMatrixTextureShapeWidthHeight(e,t);return n*r*4}function getTextureConfig(e,t){const n=e;let r,a,s,o,i,l,u,c,p,d;return 2===env().getNumber("WEBGL_VERSION")?(r=n.R32F,a=n.R16F,s=n.RGBA16F,o=n.RGBA32F,i=n.RED,u=4,c=1,p=n.HALF_FLOAT,d=n.FLOAT):(r=e.RGBA,a=e.RGBA,s=e.RGBA,o=n.RGBA,i=e.RGBA,u=4,c=4,p=null!=t?t.HALF_FLOAT_OES:null,d=e.FLOAT),l=e.RGBA,{internalFormatFloat:r,internalFormatHalfFloat:a,internalFormatPackedHalfFloat:s,internalFormatPackedFloat:o,textureFormatFloat:i,downloadTextureFormat:l,downloadUnpackNumChannels:u,defaultNumChannels:c,textureTypeHalfFloat:p,textureTypeFloat:d}}function callAndCheck(e,t){const n=t();return env().getBool("DEBUG")&&checkWebGLError(e),n}function checkWebGLError(e){const t=e.getError();if(t!==e.NO_ERROR)throw new Error("WebGL Error: "+getWebGLErrorMessage(e,t))}!function(e){e[e.DENSE=0]="DENSE",e[e.SHARED_BATCH=1]="SHARED_BATCH"}(PackingScheme||(PackingScheme={})),function(e){e[e.RENDER=0]="RENDER",e[e.UPLOAD=1]="UPLOAD",e[e.PIXELS=2]="PIXELS",e[e.DOWNLOAD=3]="DOWNLOAD"}(TextureUsage||(TextureUsage={})),function(e){e[e.UNPACKED_FLOAT16=0]="UNPACKED_FLOAT16",e[e.UNPACKED_FLOAT32=1]="UNPACKED_FLOAT32",e[e.PACKED_4X1_UNSIGNED_BYTE=2]="PACKED_4X1_UNSIGNED_BYTE",e[e.PACKED_2X2_FLOAT32=3]="PACKED_2X2_FLOAT32",e[e.PACKED_2X2_FLOAT16=4]="PACKED_2X2_FLOAT16"}(PhysicalTextureType||(PhysicalTextureType={}));const MIN_FLOAT16=5.96e-8,MAX_FLOAT16=65504;function canBeRepresented(e){return!!(env().getBool("WEBGL_RENDER_FLOAT32_ENABLED")||0===e||MIN_FLOAT16<Math.abs(e)&&Math.abs(e)<MAX_FLOAT16)}function getWebGLErrorMessage(e,t){switch(t){case e.NO_ERROR:return"NO_ERROR";case e.INVALID_ENUM:return"INVALID_ENUM";case e.INVALID_VALUE:return"INVALID_VALUE";case e.INVALID_OPERATION:return"INVALID_OPERATION";case e.INVALID_FRAMEBUFFER_OPERATION:return"INVALID_FRAMEBUFFER_OPERATION";case e.OUT_OF_MEMORY:return"OUT_OF_MEMORY";case e.CONTEXT_LOST_WEBGL:return"CONTEXT_LOST_WEBGL";default:return`Unknown error code ${t}`}}function getExtensionOrThrow(e,t){return throwIfNull(e,()=>e.getExtension(t),'Extension "'+t+'" not supported on this browser.')}function createVertexShader$1(e,t){const n=throwIfNull(e,()=>e.createShader(e.VERTEX_SHADER),"Unable to create vertex WebGLShader.");if(callAndCheck(e,()=>e.shaderSource(n,t)),callAndCheck(e,()=>e.compileShader(n)),!1===e.getShaderParameter(n,e.COMPILE_STATUS))throw console.log(e.getShaderInfoLog(n)),new Error("Failed to compile vertex shader.");return n}function createFragmentShader(e,t){const n=throwIfNull(e,()=>e.createShader(e.FRAGMENT_SHADER),"Unable to create fragment WebGLShader.");if(callAndCheck(e,()=>e.shaderSource(n,t)),callAndCheck(e,()=>e.compileShader(n)),!1===e.getShaderParameter(n,e.COMPILE_STATUS))throw logShaderSourceAndInfoLog(t,e.getShaderInfoLog(n)),new Error("Failed to compile fragment shader.");return n}const lineNumberRegex=/ERROR: [0-9]+:([0-9]+):/g;function logShaderSourceAndInfoLog(e,t){const n=lineNumberRegex.exec(t);if(null==n)return console.log(`Couldn't parse line number in error: ${t}`),void console.log(e);const r=+n[1],a=e.split("\n"),s=a.length.toString().length+2,o=a.map((e,t)=>rightPad((t+1).toString(),s)+e);let i=0;for(let e=0;e<o.length;e++)i=Math.max(o[e].length,i);const l=o.slice(0,r-1),u=o.slice(r-1,r),c=o.slice(r);console.log(l.join("\n")),console.log(t.split("\n")[0]),console.log(`%c ${rightPad(u[0],i)}`,"border:1px solid red; background-color:#e3d2d2; color:#a61717"),console.log(c.join("\n"))}function createProgram(e){return throwIfNull(e,()=>e.createProgram(),"Unable to create WebGLProgram.")}function linkProgram(e,t){if(callAndCheck(e,()=>e.linkProgram(t)),!1===e.getProgramParameter(t,e.LINK_STATUS))throw console.log(e.getProgramInfoLog(t)),new Error("Failed to link vertex and fragment shaders.")}function validateProgram(e,t){if(callAndCheck(e,()=>e.validateProgram(t)),!1===e.getProgramParameter(t,e.VALIDATE_STATUS))throw console.log(e.getProgramInfoLog(t)),new Error("Shader program validation failed.")}function createStaticVertexBuffer(e,t){const n=throwIfNull(e,()=>e.createBuffer(),"Unable to create WebGLBuffer");return callAndCheck(e,()=>e.bindBuffer(e.ARRAY_BUFFER,n)),callAndCheck(e,()=>e.bufferData(e.ARRAY_BUFFER,t,e.STATIC_DRAW)),n}function createStaticIndexBuffer(e,t){const n=throwIfNull(e,()=>e.createBuffer(),"Unable to create WebGLBuffer");return callAndCheck(e,()=>e.bindBuffer(e.ELEMENT_ARRAY_BUFFER,n)),callAndCheck(e,()=>e.bufferData(e.ELEMENT_ARRAY_BUFFER,t,e.STATIC_DRAW)),n}function createTexture(e){return throwIfNull(e,()=>e.createTexture(),"Unable to create WebGLTexture.")}function validateTextureSize(e,t){const n=env().getNumber("WEBGL_MAX_TEXTURE_SIZE");if(e<=0||t<=0)throw new Error(`Requested texture size [${e}x${t}] is invalid.`);if(e>n||t>n)throw new Error(`Requested texture size [${e}x${t}] greater than WebGL maximum on this browser / GPU [${n}x${n}].`)}function createFramebuffer(e){return throwIfNull(e,()=>e.createFramebuffer(),"Unable to create WebGLFramebuffer.")}function bindVertexBufferToProgramAttribute(e,t,n,r,a,s,o){const i=e.getAttribLocation(t,n);return-1!==i&&(callAndCheck(e,()=>e.bindBuffer(e.ARRAY_BUFFER,r)),callAndCheck(e,()=>e.vertexAttribPointer(i,a,e.FLOAT,!1,s,o)),callAndCheck(e,()=>e.enableVertexAttribArray(i)),!0)}function bindTextureUnit(e,t,n){validateTextureUnit(e,n),callAndCheck(e,()=>e.activeTexture(e.TEXTURE0+n)),callAndCheck(e,()=>e.bindTexture(e.TEXTURE_2D,t))}function getProgramUniformLocationOrThrow(e,t,n){return throwIfNull(e,()=>e.getUniformLocation(t,n),'uniform "'+n+'" not present in program.')}function getProgramUniformLocation(e,t,n){return e.getUniformLocation(t,n)}function bindTextureToProgramUniformSampler(e,t,n,r){callAndCheck(e,()=>bindTextureUnit(e,t,r)),callAndCheck(e,()=>e.uniform1i(n,r))}function bindColorTextureToFramebuffer(e,t,n){callAndCheck(e,()=>e.bindFramebuffer(e.FRAMEBUFFER,n)),callAndCheck(e,()=>e.framebufferTexture2D(e.FRAMEBUFFER,e.COLOR_ATTACHMENT0,e.TEXTURE_2D,t,0))}function unbindColorTextureFromFramebuffer(e,t){callAndCheck(e,()=>e.bindFramebuffer(e.FRAMEBUFFER,t)),callAndCheck(e,()=>e.framebufferTexture2D(e.FRAMEBUFFER,e.COLOR_ATTACHMENT0,e.TEXTURE_2D,null,0))}function validateFramebuffer(e){const t=e.checkFramebufferStatus(e.FRAMEBUFFER);if(t!==e.FRAMEBUFFER_COMPLETE)throw new Error("Error binding framebuffer: "+getFramebufferErrorMessage(e,t))}function getFramebufferErrorMessage(e,t){switch(t){case e.FRAMEBUFFER_INCOMPLETE_ATTACHMENT:return"FRAMEBUFFER_INCOMPLETE_ATTACHMENT";case e.FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT:return"FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT";case e.FRAMEBUFFER_INCOMPLETE_DIMENSIONS:return"FRAMEBUFFER_INCOMPLETE_DIMENSIONS";case e.FRAMEBUFFER_UNSUPPORTED:return"FRAMEBUFFER_UNSUPPORTED";default:return`unknown error ${t}`}}function throwIfNull(e,t,n){const r=callAndCheck(e,()=>t());if(null==r)throw new Error(n);return r}function validateTextureUnit(e,t){const n=e.MAX_COMBINED_TEXTURE_IMAGE_UNITS-1,r=t+e.TEXTURE0;if(r<e.TEXTURE0||r>n)throw new Error(`textureUnit must be in [gl.TEXTURE0, gl.TEXTURE${n}].`)}function getBatchDim(e,t=2){return sizeFromShape(e.slice(0,e.length-t))}function getRowsCols(e){if(0===e.length)throw Error("Cannot get rows and columns of an empty shape array.");return[e.length>1?e[e.length-2]:1,e[e.length-1]]}function getShapeAs3D(e){let t=[1,1,1];return 0===e.length||1===e.length&&1===e[0]||(t=[getBatchDim(e),...getRowsCols(e)]),t}function getTextureShapeFromLogicalShape(e,t=!1){let n=env().getNumber("WEBGL_MAX_TEXTURE_SIZE");if(t&&(n*=2,1===(e=e.map((t,n)=>n>=e.length-2?nearestLargerEven(e[n]):e[n])).length&&(e=[2,e[0]])),2!==e.length){const t=squeezeShape(e);e=t.newShape}let r=sizeFromShape(e);if(e.length<=1&&r<=n)return[1,r];if(2===e.length&&e[0]<=n&&e[1]<=n)return e;if(3===e.length&&e[0]*e[1]<=n&&e[2]<=n)return[e[0]*e[1],e[2]];if(3===e.length&&e[0]<=n&&e[1]*e[2]<=n)return[e[0],e[1]*e[2]];if(4===e.length&&e[0]*e[1]*e[2]<=n&&e[3]<=n)return[e[0]*e[1]*e[2],e[3]];if(4===e.length&&e[0]<=n&&e[1]*e[2]*e[3]<=n)return[e[0],e[1]*e[2]*e[3]];if(t){const t=getBatchDim(e);let n=2,a=2;return e.length&&([n,a]=getRowsCols(e)),r=t*(n/2)*(a/2),sizeToSquarishShape(r).map(e=>2*e)}return sizeToSquarishShape(r)}function isEven(e){return e%2==0}function isReshapeFree(e,t){if(arraysEqual(e=e.slice(-2),t=t.slice(-2)))return!0;if(!e.length||!t.length)return!0;if(0===e[0]||0===e[1]||0===t[0]||0===t[1])return!0;if(e.length!==t.length){const n=e.slice(-1)[0],r=t.slice(-1)[0];if(n===r)return!0;if(isEven(n)&&isEven(r)&&(1===e[0]||1===t[0]))return!0}return e[1]===t[1]&&isEven(e[0])&&isEven(t[0])}let MAX_TEXTURE_SIZE,MAX_TEXTURES_IN_SHADER;function getWebGLMaxTextureSize(e){if(null==MAX_TEXTURE_SIZE){const t=getWebGLContext(e);MAX_TEXTURE_SIZE=t.getParameter(t.MAX_TEXTURE_SIZE)}return MAX_TEXTURE_SIZE}function getMaxTexturesInShader(e){if(null==MAX_TEXTURES_IN_SHADER){const t=getWebGLContext(e);MAX_TEXTURES_IN_SHADER=t.getParameter(t.MAX_TEXTURE_IMAGE_UNITS)}return Math.min(16,MAX_TEXTURES_IN_SHADER)}function getWebGLDisjointQueryTimerVersion(e){if(0===e)return 0;let t;const n=getWebGLContext(e);return t=hasExtension(n,"EXT_disjoint_timer_query_webgl2")&&2===e?2:hasExtension(n,"EXT_disjoint_timer_query")?1:0,t}function hasExtension(e,t){return null!=e.getExtension(t)}function isWebGLVersionEnabled(e){try{if(null!=getWebGLContext(e))return!0}catch(e){return console.log("Error when getting WebGL context: ",e),!1}return!1}function isCapableOfRenderingToFloatTexture(e){if(0===e)return!1;const t=getWebGLContext(e);if(1===e){if(!hasExtension(t,"OES_texture_float"))return!1}else if(!hasExtension(t,"EXT_color_buffer_float"))return!1;return createFloatTextureAndBindToFramebuffer(t)}function isDownloadFloatTextureEnabled(e){if(0===e)return!1;const t=getWebGLContext(e);if(1!==e){if(hasExtension(t,"EXT_color_buffer_float"))return createFloatTextureAndBindToFramebuffer(t);const e="EXT_color_buffer_half_float";if(hasExtension(t,e)){const n=t.getExtension(e);return createHalfFloatTextureAndBindToFramebuffer(t,n)}return!1}return!!hasExtension(t,"OES_texture_float")&&!!hasExtension(t,"WEBGL_color_buffer_float")&&createFloatTextureAndBindToFramebuffer(t)}function createFloatTextureAndBindToFramebuffer(e){const t=getTextureConfig(e),n=e.createTexture();e.bindTexture(e.TEXTURE_2D,n),e.texImage2D(e.TEXTURE_2D,0,t.internalFormatFloat,1,1,0,t.textureFormatFloat,t.textureTypeFloat,null);const r=e.createFramebuffer();e.bindFramebuffer(e.FRAMEBUFFER,r),e.framebufferTexture2D(e.FRAMEBUFFER,e.COLOR_ATTACHMENT0,e.TEXTURE_2D,n,0);const a=e.checkFramebufferStatus(e.FRAMEBUFFER)===e.FRAMEBUFFER_COMPLETE;return e.bindTexture(e.TEXTURE_2D,null),e.bindFramebuffer(e.FRAMEBUFFER,null),e.deleteTexture(n),e.deleteFramebuffer(r),a}function createHalfFloatTextureAndBindToFramebuffer(e,t){const n=getTextureConfig(e,t),r=e.createTexture();e.bindTexture(e.TEXTURE_2D,r),e.texImage2D(e.TEXTURE_2D,0,n.internalFormatHalfFloat,1,1,0,n.textureFormatFloat,n.textureTypeHalfFloat,null);const a=e.createFramebuffer();e.bindFramebuffer(e.FRAMEBUFFER,a),e.framebufferTexture2D(e.FRAMEBUFFER,e.COLOR_ATTACHMENT0,e.TEXTURE_2D,r,0);const s=e.checkFramebufferStatus(e.FRAMEBUFFER)===e.FRAMEBUFFER_COMPLETE;return e.bindTexture(e.TEXTURE_2D,null),e.bindFramebuffer(e.FRAMEBUFFER,null),e.deleteTexture(r),e.deleteFramebuffer(a),s}function isWebGLFenceEnabled(e){return 2===e&&null!=getWebGLContext(e).fenceSync}function assertNotComplex(e,t){Array.isArray(e)||(e=[e]),e.forEach(e=>{null!=e&&assert$4("complex64"!==e.dtype,()=>`${t} does not support complex64 tensors in the WebGL backend.`)})}const ENV=env();function getGlslDifferences(){let e,t,n,r,a,s,o,i,l,u;return 2===env().getNumber("WEBGL_VERSION")?(e="#version 300 es",t="in",n="out",r="in",a="texture",s="outputColor",o="out vec4 outputColor;",i="\n      bool isnan_custom(float val) {\n        return (val > 0.0 || val < 0.0) ? false : val != 0.0;\n      }\n\n      bvec4 isnan_custom(vec4 val) {\n        return bvec4(isnan_custom(val.x),\n          isnan_custom(val.y), isnan_custom(val.z), isnan_custom(val.w));\n      }\n\n      #define isnan(value) isnan_custom(value)\n    ",l="",u="\n      #define round(value) newRound(value)\n      int newRound(float value) {\n        return int(floor(value + 0.5));\n      }\n\n      ivec4 newRound(vec4 value) {\n        return ivec4(floor(value + vec4(0.5)));\n      }\n    "):(e="",t="attribute",n="varying",r="varying",a="texture2D",s="gl_FragColor",o="",i="\n      #define isnan(value) isnan_custom(value)\n      bool isnan_custom(float val) {\n        return (val > 0. || val < 1. || val == 0.) ? false : true;\n      }\n      bvec4 isnan_custom(vec4 val) {\n        return bvec4(isnan(val.x), isnan(val.y), isnan(val.z), isnan(val.w));\n      }\n    ",l="\n      uniform float INFINITY;\n\n      bool isinf(float val) {\n        return abs(val) == INFINITY;\n      }\n      bvec4 isinf(vec4 val) {\n        return equal(abs(val), vec4(INFINITY));\n      }\n    ",u="\n      int round(float value) {\n        return int(floor(value + 0.5));\n      }\n\n      ivec4 round(vec4 value) {\n        return ivec4(floor(value + vec4(0.5)));\n      }\n    "),{version:e,attribute:t,varyingVs:n,varyingFs:r,texture2D:a,output:s,defineOutput:o,defineSpecialNaN:i,defineSpecialInf:l,defineRound:u}}function getLogicalCoordinatesFromFlatIndex(e,t,n="index"){const r=computeStrides(t);return r.map((t,a)=>`int ${e[a]} = ${n} / ${t}; ${a===r.length-1?`int ${e[a+1]} = ${n} - ${e[a]} * ${t}`:`index -= ${e[a]} * ${t}`};`).join("")}function getLogicalCoordinatesFromFlatIndexByUniform(e,t,n="index"){const r=computeStrides(t);return r.map((t,a)=>`int ${e[a]} = ${n} / outShapeStrides[${a}]; ${a===r.length-1?`int ${e[a+1]} = ${n} - ${e[a]} * outShapeStrides[${a}]`:`index -= ${e[a]} * outShapeStrides[${a}]`};`).join("")}function getFlatIndexFrom3D(e){const t=computeStrides(e).map(e=>e.toString());return`\n  int getFlatIndex(ivec3 coords) {\n    return coords.x * ${t[0]} + coords.y * ${t[1]} + coords.z;\n  }\n`}ENV.registerFlag("HAS_WEBGL",()=>ENV.getNumber("WEBGL_VERSION")>0),ENV.registerFlag("WEBGL_VERSION",()=>isWebGLVersionEnabled(2)?2:isWebGLVersionEnabled(1)?1:0),ENV.registerFlag("WEBGL_CHECK_NUMERICAL_PROBLEMS",()=>!1),ENV.registerFlag("WEBGL_BUFFER_SUPPORTED",()=>2===ENV.get("WEBGL_VERSION")),ENV.registerFlag("WEBGL_CPU_FORWARD",()=>!0),ENV.registerFlag("WEBGL_FORCE_F16_TEXTURES",()=>!1),ENV.registerFlag("WEBGL_PACK",()=>ENV.getBool("HAS_WEBGL")),ENV.registerFlag("WEBGL_PACK_NORMALIZATION",()=>ENV.getBool("WEBGL_PACK")),ENV.registerFlag("WEBGL_PACK_CLIP",()=>ENV.getBool("WEBGL_PACK")),ENV.registerFlag("WEBGL_PACK_DEPTHWISECONV",()=>ENV.getBool("WEBGL_PACK")),ENV.registerFlag("WEBGL_PACK_BINARY_OPERATIONS",()=>ENV.getBool("WEBGL_PACK")),ENV.registerFlag("WEBGL_PACK_UNARY_OPERATIONS",()=>ENV.getBool("WEBGL_PACK")),ENV.registerFlag("WEBGL_PACK_ARRAY_OPERATIONS",()=>ENV.getBool("WEBGL_PACK")),ENV.registerFlag("WEBGL_PACK_IMAGE_OPERATIONS",()=>ENV.getBool("WEBGL_PACK")),ENV.registerFlag("WEBGL_PACK_REDUCE",()=>ENV.getBool("WEBGL_PACK")),ENV.registerFlag("WEBGL_LAZILY_UNPACK",()=>ENV.getBool("WEBGL_PACK")),ENV.registerFlag("WEBGL_CONV_IM2COL",()=>ENV.getBool("WEBGL_PACK")),ENV.registerFlag("WEBGL_MAX_TEXTURE_SIZE",()=>getWebGLMaxTextureSize(ENV.getNumber("WEBGL_VERSION"))),ENV.registerFlag("WEBGL_MAX_TEXTURES_IN_SHADER",()=>getMaxTexturesInShader(ENV.getNumber("WEBGL_VERSION"))),ENV.registerFlag("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION",()=>{const e=ENV.getNumber("WEBGL_VERSION");return 0===e?0:getWebGLDisjointQueryTimerVersion(e)}),ENV.registerFlag("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE",()=>ENV.getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")>0&&!isMobile()),ENV.registerFlag("WEBGL_RENDER_FLOAT32_CAPABLE",()=>isCapableOfRenderingToFloatTexture(ENV.getNumber("WEBGL_VERSION"))),ENV.registerFlag("WEBGL_RENDER_FLOAT32_ENABLED",()=>!ENV.getBool("WEBGL_FORCE_F16_TEXTURES")&&ENV.getBool("WEBGL_RENDER_FLOAT32_CAPABLE")),ENV.registerFlag("WEBGL_DOWNLOAD_FLOAT_ENABLED",()=>isDownloadFloatTextureEnabled(ENV.getNumber("WEBGL_VERSION"))),ENV.registerFlag("WEBGL_FENCE_API_ENABLED",()=>isWebGLFenceEnabled(ENV.getNumber("WEBGL_VERSION"))),ENV.registerFlag("WEBGL_SIZE_UPLOAD_UNIFORM",()=>ENV.getBool("WEBGL_RENDER_FLOAT32_ENABLED")?4:0),ENV.registerFlag("WEBGL_DELETE_TEXTURE_THRESHOLD",()=>-1,e=>{if(e<0&&-1!==e)throw new Error(`WEBGL_DELETE_TEXTURE_THRESHOLD must be -1 (indicating never delete) or at least 0, but got ${e}.`)}),ENV.registerFlag("WEBGL_FLUSH_THRESHOLD",()=>isMobile()&&ENV.getBool("IS_CHROME")?1:-1,e=>{if(e<0&&-1!==e)throw new Error(`WEBGL_FLUSH_THRESHOLD must be -1 (indicating never manual flush) or at least 0, but got ${e}.`)}),ENV.registerFlag("CPU_HANDOFF_SIZE_THRESHOLD",()=>128),ENV.registerFlag("WEBGL_USE_SHAPES_UNIFORMS",()=>!1),ENV.registerFlag("TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD",()=>1e5),ENV.registerFlag("TOPK_K_CPU_HANDOFF_THRESHOLD",()=>128);const ENCODE_FLOAT_SNIPPET="\n  const float FLOAT_MAX = 1.70141184e38;\n  const float FLOAT_MIN = 1.17549435e-38;\n\n  lowp vec4 encode_float(highp float v) {\n    if (isnan(v)) {\n      return vec4(255, 255, 255, 255);\n    }\n\n    highp float av = abs(v);\n\n    if(av < FLOAT_MIN) {\n      return vec4(0.0, 0.0, 0.0, 0.0);\n    } else if(v > FLOAT_MAX) {\n      return vec4(0.0, 0.0, 128.0, 127.0) / 255.0;\n    } else if(v < -FLOAT_MAX) {\n      return vec4(0.0, 0.0,  128.0, 255.0) / 255.0;\n    }\n\n    highp vec4 c = vec4(0,0,0,0);\n\n    highp float e = floor(log2(av));\n    highp float m = exp2(fract(log2(av))) - 1.0;\n\n    c[2] = floor(128.0 * m);\n    m -= c[2] / 128.0;\n    c[1] = floor(32768.0 * m);\n    m -= c[1] / 32768.0;\n    c[0] = floor(8388608.0 * m);\n\n    highp float ebias = e + 127.0;\n    c[3] = floor(ebias / 2.0);\n    ebias -= c[3] * 2.0;\n    c[2] += floor(ebias) * 128.0;\n\n    c[3] += 128.0 * step(0.0, -v);\n\n    return c / 255.0;\n  }\n";class DecodeMatrixProgram{constructor(e){this.variableNames=["A"],this.packedInputs=!1,this.packedOutput=!0,this.outPackingScheme=PackingScheme.DENSE;const t=getDenseTexShape(e),n=getGlslDifferences();this.outputShape=e,this.userCode=`\n      ivec3 outCoordsFromFlatIndex(int index) {\n        ${getLogicalCoordinatesFromFlatIndex(["r","c","d"],e)}\n        return ivec3(r, c, d);\n      }\n\n      void main() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n          vec2(${t[0]}, ${t[1]}));\n        int index = 4 * (resTexRC.x * ${t[1]} + resTexRC.y);\n\n        vec4 result = vec4(0.);\n\n        for (int i=0; i<4; i++) {\n          int flatIndex = index + i;\n          ivec3 rc = outCoordsFromFlatIndex(flatIndex);\n          result[i] = getA(rc.x, rc.y, rc.z);\n        }\n\n        ${n.output} = result;\n      }\n    `}}class DecodeMatrixPackedProgram{constructor(e){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,this.outPackingScheme=PackingScheme.DENSE;const t=getDenseTexShape(e),n=getGlslDifferences();this.outputShape=e,this.userCode=`\n      ivec3 outCoordsFromFlatIndex(int index) {\n        ${getLogicalCoordinatesFromFlatIndex(["r","c","d"],e)}\n        return ivec3(r, c, d);\n      }\n\n      void main() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n          vec2(${t[0]}, ${t[1]}));\n        int index = 4 * (resTexRC.x * ${t[1]} + resTexRC.y);\n\n        vec4 result = vec4(0.);\n\n        for (int i=0; i<4; i++) {\n          int flatIndex = index + i;\n          ivec3 rc = outCoordsFromFlatIndex(flatIndex);\n          result[i] = getChannel(getA(rc.x, rc.y, rc.z), vec2(rc.y, rc.z));\n        }\n\n        ${n.output} = result;\n      }\n    `}}class EncodeFloatProgram{constructor(e){this.variableNames=["A"],this.outTexUsage=TextureUsage.DOWNLOAD;const t=getGlslDifferences();this.outputShape=e,this.userCode=`\n      ${ENCODE_FLOAT_SNIPPET}\n\n      void main() {\n        float x = getAAtOutCoords();\n        ${t.output} = encode_float(x);\n      }\n    `}}class EncodeFloatPackedProgram{constructor(e){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!1,this.outTexUsage=TextureUsage.DOWNLOAD;const t=getGlslDifferences();this.outputShape=e,this.userCode=`\n      ${ENCODE_FLOAT_SNIPPET}\n\n      void main() {\n        ivec3 coords = getOutputCoords();\n        float x = getChannel(getAAtOutCoords(), vec2(coords.y, coords.z));\n        ${t.output} = encode_float(x);\n      }\n    `}}class EncodeMatrixProgram{constructor(e,t,n=!1){this.variableNames=["A"];const r=getGlslDifferences(),[a,s]=t;this.outputShape=e;let o="result";n&&(o="floor(result * 255. + 0.5)"),this.userCode=`\n      ${getFlatIndexFrom3D(e)}\n\n      void main() {\n        ivec3 coords = getOutputCoords();\n\n        int flatIndex = getFlatIndex(coords);\n        int offset = imod(flatIndex, 4);\n\n        flatIndex = idiv(flatIndex, 4, 1.);\n\n        int r = flatIndex / ${s};\n        int c = imod(flatIndex, ${s});\n        vec2 uv = (vec2(c, r) + halfCR) / vec2(${s}.0, ${a}.0);\n        vec4 values = ${r.texture2D}(A, uv);\n\n        float result;\n\n        if(offset == 0) {\n          result = values[0];\n        } else if(offset == 1) {\n          result = values[1];\n        } else if(offset == 2) {\n          result = values[2];\n        } else {\n          result = values[3];\n        }\n\n        ${r.output} = vec4(${o}, 0., 0., 0.);\n      }\n    `}}class EncodeMatrixPackedProgram{constructor(e,t,n=!1){this.variableNames=["A"],this.packedInputs=!1,this.packedOutput=!0;const r=getGlslDifferences(),[a,s]=t;this.outputShape=e;let o="",i="result";n&&(i="floor(result * 255. + 0.5)");for(let t=0;t<=1;t++)for(let n=0;n<=1;n++){const i=2*t+n;o+=`\n          localCoords = coords;\n          if(localCoords[2] + ${n} < ${e[2]}) {\n            localCoords[2] += ${n};\n            if(localCoords[1] + ${t} < ${e[1]}) {\n              localCoords[1] += ${t};\n\n              flatIndex = getFlatIndex(localCoords);\n              offset = imod(flatIndex, 4);\n\n              flatIndex = idiv(flatIndex, 4, 1.);\n\n              r = flatIndex / ${s};\n              c = imod(flatIndex, ${s});\n              uv = (vec2(c, r) + halfCR) / vec2(${s}.0, ${a}.0);\n              values = ${r.texture2D}(A, uv);\n\n              if(offset == 0) {\n                result[${i}] = values[0];\n              } else if(offset == 1) {\n                result[${i}] = values[1];\n              } else if(offset == 2) {\n                result[${i}] = values[2];\n              } else {\n                result[${i}] = values[3];\n              }\n            }\n          }\n        `}this.userCode=`\n      ${getFlatIndexFrom3D(e)}\n\n      void main() {\n        ivec3 coords = getOutputCoords();\n\n        vec4 result = vec4(0.);\n        int flatIndex, r, c, offset;\n        ivec3 localCoords;\n        vec2 uv;\n        vec4 values;\n\n        ${o}\n\n        ${r.output} = ${i};\n      }\n    `}}function createVertexShader(e){const t=getGlslDifferences();return createVertexShader$1(e,`${t.version}\n    precision highp float;\n    ${t.attribute} vec3 clipSpacePos;\n    ${t.attribute} vec2 uv;\n    ${t.varyingVs} vec2 resultUV;\n\n    void main() {\n      gl_Position = vec4(clipSpacePos, 1);\n      resultUV = uv;\n    }`)}function createVertexBuffer(e){return createStaticVertexBuffer(e,new Float32Array([-1,1,0,0,1,-1,-1,0,0,0,1,1,0,1,1,1,-1,0,1,0]))}function createIndexBuffer(e){return createStaticIndexBuffer(e,new Uint16Array([0,1,2,2,1,3]))}function createAndConfigureTexture(e,t,n,r,a,s){validateTextureSize(t,n);const o=createTexture(e),i=e.TEXTURE_2D;return callAndCheck(e,()=>e.bindTexture(i,o)),callAndCheck(e,()=>e.texParameteri(i,e.TEXTURE_WRAP_S,e.CLAMP_TO_EDGE)),callAndCheck(e,()=>e.texParameteri(i,e.TEXTURE_WRAP_T,e.CLAMP_TO_EDGE)),callAndCheck(e,()=>e.texParameteri(i,e.TEXTURE_MIN_FILTER,e.NEAREST)),callAndCheck(e,()=>e.texParameteri(i,e.TEXTURE_MAG_FILTER,e.NEAREST)),callAndCheck(e,()=>e.texImage2D(i,0,r,t,n,0,a,s,null)),callAndCheck(e,()=>e.bindTexture(e.TEXTURE_2D,null)),o}function getInternalFormatForFloat32MatrixTexture(e){return e.internalFormatFloat}function createFloat32MatrixTexture(e,t,n,r){const[a,s]=getUnpackedMatrixTextureShapeWidthHeight(t,n);return createAndConfigureTexture(e,a,s,getInternalFormatForFloat32MatrixTexture(r),r.textureFormatFloat,e.FLOAT)}function getInternalFormatForFloat16MatrixTexture(e){return e.internalFormatHalfFloat}function createFloat16MatrixTexture(e,t,n,r){const[a,s]=getUnpackedMatrixTextureShapeWidthHeight(t,n);return createAndConfigureTexture(e,a,s,getInternalFormatForFloat16MatrixTexture(r),r.textureFormatFloat,r.textureTypeHalfFloat)}function getInternalFormatForUnsignedBytesMatrixTexture(e){return e.downloadTextureFormat}function createUnsignedBytesMatrixTexture(e,t,n,r){const[a,s]=getUnpackedMatrixTextureShapeWidthHeight(t,n);return createAndConfigureTexture(e,a,s,getInternalFormatForUnsignedBytesMatrixTexture(r),e.RGBA,e.UNSIGNED_BYTE)}function getInternalFormatForPackedMatrixTexture(e){return e.internalFormatPackedFloat}function createPackedMatrixTexture(e,t,n,r){const[a,s]=getPackedMatrixTextureShapeWidthHeight(t,n);return createAndConfigureTexture(e,a,s,getInternalFormatForPackedMatrixTexture(r),e.RGBA,e.FLOAT)}function getInternalFormatForFloat16PackedMatrixTexture(e){return e.internalFormatPackedHalfFloat}function createFloat16PackedMatrixTexture(e,t,n,r){const[a,s]=getPackedMatrixTextureShapeWidthHeight(t,n);return createAndConfigureTexture(e,a,s,getInternalFormatForFloat16PackedMatrixTexture(r),e.RGBA,r.textureTypeHalfFloat)}function bindVertexProgramAttributeStreams(e,t,n){return callAndCheck(e,()=>e.bindBuffer(e.ARRAY_BUFFER,n)),bindVertexBufferToProgramAttribute(e,t,"clipSpacePos",n,3,20,0)&&bindVertexBufferToProgramAttribute(e,t,"uv",n,2,20,12)}function uploadDenseMatrixToTexture(e,t,n,r,a,s){let o,i,l;callAndCheck(e,()=>e.bindTexture(e.TEXTURE_2D,t)),a instanceof Uint8Array?(o=new Uint8Array(n*r*4),i=e.UNSIGNED_BYTE,l=e.RGBA):(o=new Float32Array(n*r*4),i=e.FLOAT,l=s.internalFormatPackedFloat),o.set(a),callAndCheck(e,()=>e.texImage2D(e.TEXTURE_2D,0,l,n,r,0,e.RGBA,i,o)),callAndCheck(e,()=>e.bindTexture(e.TEXTURE_2D,null))}function uploadPixelDataToTexture(e,t,n){callAndCheck(e,()=>e.bindTexture(e.TEXTURE_2D,t)),n.data instanceof Uint8Array?callAndCheck(e,()=>e.texImage2D(e.TEXTURE_2D,0,e.RGBA,n.width,n.height,0,e.RGBA,e.UNSIGNED_BYTE,n.data)):callAndCheck(e,()=>e.texImage2D(e.TEXTURE_2D,0,e.RGBA,e.RGBA,e.UNSIGNED_BYTE,n)),callAndCheck(e,()=>e.bindTexture(e.TEXTURE_2D,null))}function createBufferFromOutputTexture(e,t,n,r){const a=e.createBuffer();callAndCheck(e,()=>e.bindBuffer(e.PIXEL_PACK_BUFFER,a));const s=16*t*n;return callAndCheck(e,()=>e.bufferData(e.PIXEL_PACK_BUFFER,s,e.STREAM_READ)),callAndCheck(e,()=>e.readPixels(0,0,n,t,e.RGBA,e.FLOAT,0)),callAndCheck(e,()=>e.bindBuffer(e.PIXEL_PACK_BUFFER,null)),a}function downloadFloat32MatrixFromBuffer(e,t,n){const r=e,a=new Float32Array(n);return r.bindBuffer(r.PIXEL_PACK_BUFFER,t),r.getBufferSubData(r.PIXEL_PACK_BUFFER,0,a),r.bindBuffer(r.PIXEL_PACK_BUFFER,null),a}function downloadByteEncodedFloatMatrixFromOutputTexture(e,t,n,r){const[a,s]=getUnpackedMatrixTextureShapeWidthHeight(t,n),o=new Uint8Array(getUnpackedArraySizeFromMatrixSize(t*n,4));return callAndCheck(e,()=>e.readPixels(0,0,a,s,r.downloadTextureFormat,e.UNSIGNED_BYTE,o)),new Float32Array(o.buffer)}function downloadPackedMatrixFromBuffer(e,t,n,r,a,s,o,i){const l=e,u=new Float32Array(getPackedRGBAArraySizeFromMatrixShape(s,o));return l.bindBuffer(l.PIXEL_PACK_BUFFER,t),l.getBufferSubData(l.PIXEL_PACK_BUFFER,0,u),l.bindBuffer(l.PIXEL_PACK_BUFFER,null),u}function downloadMatrixFromPackedOutputTexture(e,t,n){const r=new Float32Array(t*n*4);return callAndCheck(e,()=>e.readPixels(0,0,n,t,e.RGBA,e.FLOAT,r)),r}class GPGPUContext{constructor(e){this.outputTexture=null,this.program=null,this.disposed=!1,this.vertexAttrsAreBound=!1,this.itemsToPoll=[];const t=env().getNumber("WEBGL_VERSION");null!=e?(this.gl=e,setWebGLContext(t,e)):this.gl=getWebGLContext(t);let n="WEBGL_color_buffer_float";const r="EXT_color_buffer_half_float";if(1===env().getNumber("WEBGL_VERSION")){const e="OES_texture_half_float";if(this.textureFloatExtension=getExtensionOrThrow(this.gl,"OES_texture_float"),hasExtension(this.gl,e))this.textureHalfFloatExtension=getExtensionOrThrow(this.gl,e);else if(env().get("WEBGL_FORCE_F16_TEXTURES"))throw new Error("GL context does not support half float textures, yet the environment flag WEBGL_FORCE_F16_TEXTURES is set to true.");if(this.colorBufferFloatExtension=this.gl.getExtension(n),hasExtension(this.gl,r))this.colorBufferHalfFloatExtension=getExtensionOrThrow(this.gl,r);else if(env().get("WEBGL_FORCE_F16_TEXTURES"))throw new Error("GL context does not support color renderable half floats, yet the environment flag WEBGL_FORCE_F16_TEXTURES is set to true.")}else if(n="EXT_color_buffer_float",hasExtension(this.gl,n))this.colorBufferFloatExtension=this.gl.getExtension(n);else{if(!hasExtension(this.gl,r))throw new Error("GL context does not support color renderable floats");this.colorBufferHalfFloatExtension=this.gl.getExtension(r)}this.vertexBuffer=createVertexBuffer(this.gl),this.indexBuffer=createIndexBuffer(this.gl),this.framebuffer=createFramebuffer(this.gl),this.textureConfig=getTextureConfig(this.gl,this.textureHalfFloatExtension)}get debug(){return env().getBool("DEBUG")}dispose(){if(this.disposed)return;null!=this.program&&console.warn("Disposing a GPGPUContext that still has a bound WebGLProgram. This is probably a resource leak, delete the program with GPGPUContext.deleteProgram before disposing."),null!=this.outputTexture&&console.warn("Disposing a GPGPUContext that still has a bound output matrix texture.  This is probably a resource leak, delete the output matrix texture with GPGPUContext.deleteMatrixTexture before disposing.");const e=this.gl;callAndCheck(e,()=>e.finish()),callAndCheck(e,()=>e.bindFramebuffer(e.FRAMEBUFFER,null)),callAndCheck(e,()=>e.deleteFramebuffer(this.framebuffer)),callAndCheck(e,()=>e.bindBuffer(e.ARRAY_BUFFER,null)),callAndCheck(e,()=>e.bindBuffer(e.ELEMENT_ARRAY_BUFFER,null)),callAndCheck(e,()=>e.deleteBuffer(this.indexBuffer)),this.disposed=!0}createFloat32MatrixTexture(e,t){return this.throwIfDisposed(),createFloat32MatrixTexture(this.gl,e,t,this.textureConfig)}createFloat16MatrixTexture(e,t){return this.throwIfDisposed(),createFloat16MatrixTexture(this.gl,e,t,this.textureConfig)}createUnsignedBytesMatrixTexture(e,t){return this.throwIfDisposed(),createUnsignedBytesMatrixTexture(this.gl,e,t,this.textureConfig)}uploadPixelDataToTexture(e,t){this.throwIfDisposed(),uploadPixelDataToTexture(this.gl,e,t)}uploadDenseMatrixToTexture(e,t,n,r){this.throwIfDisposed(),uploadDenseMatrixToTexture(this.gl,e,t,n,r,this.textureConfig)}createFloat16PackedMatrixTexture(e,t){return this.throwIfDisposed(),createFloat16PackedMatrixTexture(this.gl,e,t,this.textureConfig)}createPackedMatrixTexture(e,t){return this.throwIfDisposed(),createPackedMatrixTexture(this.gl,e,t,this.textureConfig)}deleteMatrixTexture(e){this.throwIfDisposed(),this.outputTexture===e&&(unbindColorTextureFromFramebuffer(this.gl,this.framebuffer),this.outputTexture=null),callAndCheck(this.gl,()=>this.gl.deleteTexture(e))}downloadByteEncodedFloatMatrixFromOutputTexture(e,t,n){return this.downloadMatrixDriver(e,()=>downloadByteEncodedFloatMatrixFromOutputTexture(this.gl,t,n,this.textureConfig))}downloadPackedMatrixFromBuffer(e,t,n,r,a,s){return downloadPackedMatrixFromBuffer(this.gl,e,t,n,r,a,s)}downloadFloat32MatrixFromBuffer(e,t){return downloadFloat32MatrixFromBuffer(this.gl,e,t)}createBufferFromTexture(e,t,n){this.bindTextureToFrameBuffer(e);const r=createBufferFromOutputTexture(this.gl,t,n);return this.unbindTextureToFrameBuffer(),r}createAndWaitForFence(){const e=this.createFence(this.gl);return this.pollFence(e)}createFence(e){let t,n;if(env().getBool("WEBGL_FENCE_API_ENABLED")){const r=e,a=r.fenceSync(r.SYNC_GPU_COMMANDS_COMPLETE,0);e.flush(),n=()=>{const e=r.clientWaitSync(a,0,0);return e===r.ALREADY_SIGNALED||e===r.CONDITION_SATISFIED},t=a}else env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")>0?(t=this.beginQuery(),this.endQuery(),n=()=>this.isQueryAvailable(t,env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"))):n=()=>!0;return{query:t,isFencePassed:n}}downloadMatrixFromPackedTexture(e,t,n){return this.downloadMatrixDriver(e,()=>downloadMatrixFromPackedOutputTexture(this.gl,t,n))}createProgram(e){this.throwIfDisposed();const t=this.gl,n=createFragmentShader(t,e);null==this.vertexShader&&(this.vertexShader=createVertexShader(t));const r=createProgram(t);return callAndCheck(t,()=>t.attachShader(r,this.vertexShader)),callAndCheck(t,()=>t.attachShader(r,n)),linkProgram(t,r),this.debug&&validateProgram(t,r),this.vertexAttrsAreBound||(this.setProgram(r),this.vertexAttrsAreBound=bindVertexProgramAttributeStreams(t,this.program,this.vertexBuffer)),r}deleteProgram(e){this.throwIfDisposed(),e===this.program&&(this.program=null),null!=e&&callAndCheck(this.gl,()=>this.gl.deleteProgram(e))}setProgram(e){this.throwIfDisposed(),this.program=e,null!=this.program&&this.debug&&validateProgram(this.gl,this.program),callAndCheck(this.gl,()=>this.gl.useProgram(e))}getUniformLocation(e,t,n=!0){return this.throwIfDisposed(),n?getProgramUniformLocationOrThrow(this.gl,e,t):getProgramUniformLocation(this.gl,e,t)}getAttributeLocation(e,t){return this.throwIfDisposed(),callAndCheck(this.gl,()=>this.gl.getAttribLocation(e,t))}getUniformLocationNoThrow(e,t){return this.throwIfDisposed(),this.gl.getUniformLocation(e,t)}setInputMatrixTexture(e,t,n){this.throwIfDisposed(),this.throwIfNoProgram(),bindTextureToProgramUniformSampler(this.gl,e,t,n)}setOutputMatrixTexture(e,t,n){this.setOutputMatrixTextureDriver(e,n,t)}setOutputPackedMatrixTexture(e,t,n){this.throwIfDisposed();const[r,a]=getPackedMatrixTextureShapeWidthHeight(t,n);this.setOutputMatrixTextureDriver(e,r,a)}setOutputMatrixWriteRegion(e,t,n,r){this.setOutputMatrixWriteRegionDriver(n,e,r,t)}setOutputPackedMatrixWriteRegion(e,t,n,r){throw new Error("setOutputPackedMatrixWriteRegion not implemented.")}debugValidate(){null!=this.program&&validateProgram(this.gl,this.program),validateFramebuffer(this.gl)}executeProgram(){this.throwIfDisposed(),this.throwIfNoProgram();const e=this.gl;this.debug&&this.debugValidate(),callAndCheck(e,()=>e.drawElements(e.TRIANGLES,6,e.UNSIGNED_SHORT,0))}blockUntilAllProgramsCompleted(){this.throwIfDisposed(),callAndCheck(this.gl,()=>this.gl.finish())}getQueryTimerExtension(){return null==this.disjointQueryTimerExtension&&(this.disjointQueryTimerExtension=getExtensionOrThrow(this.gl,2===env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")?"EXT_disjoint_timer_query_webgl2":"EXT_disjoint_timer_query")),this.disjointQueryTimerExtension}getQueryTimerExtensionWebGL2(){return this.getQueryTimerExtension()}getQueryTimerExtensionWebGL1(){return this.getQueryTimerExtension()}beginQuery(){if(2===env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")){const e=this.gl,t=this.getQueryTimerExtensionWebGL2(),n=e.createQuery();return e.beginQuery(t.TIME_ELAPSED_EXT,n),n}const e=this.getQueryTimerExtensionWebGL1(),t=e.createQueryEXT();return e.beginQueryEXT(e.TIME_ELAPSED_EXT,t),t}endQuery(){if(2===env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")){const e=this.gl,t=this.getQueryTimerExtensionWebGL2();return void e.endQuery(t.TIME_ELAPSED_EXT)}const e=this.getQueryTimerExtensionWebGL1();e.endQueryEXT(e.TIME_ELAPSED_EXT)}async waitForQueryAndGetTime(e){return await repeatedTry(()=>this.disposed||this.isQueryAvailable(e,env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"))),this.getQueryTime(e,env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"))}getQueryTime(e,t){if(0===t)return null;if(2===t){const t=this.gl;return t.getQueryParameter(e,t.QUERY_RESULT)/1e6}{const t=this.getQueryTimerExtensionWebGL1();return t.getQueryObjectEXT(e,t.QUERY_RESULT_EXT)/1e6}}isQueryAvailable(e,t){if(0===t)return!0;if(2===t){const t=this.gl,n=this.getQueryTimerExtensionWebGL2(),r=t.getQueryParameter(e,t.QUERY_RESULT_AVAILABLE);return null==this.disjoint&&(this.disjoint=this.gl.getParameter(n.GPU_DISJOINT_EXT)),r&&!this.disjoint}{const t=this.getQueryTimerExtensionWebGL1(),n=t.getQueryObjectEXT(e,t.QUERY_RESULT_AVAILABLE_EXT);return null==this.disjoint&&(this.disjoint=this.gl.getParameter(t.GPU_DISJOINT_EXT)),n&&!this.disjoint}}pollFence(e){return new Promise(t=>{this.addItemToPoll(()=>e.isFencePassed(),()=>t())})}pollItems(){const e=linearSearchLastTrue(this.itemsToPoll.map(e=>e.isDoneFn));for(let t=0;t<=e;++t){const{resolveFn:e}=this.itemsToPoll[t];e()}this.itemsToPoll=this.itemsToPoll.slice(e+1)}addItemToPoll(e,t){this.itemsToPoll.push({isDoneFn:e,resolveFn:t}),this.itemsToPoll.length>1||repeatedTry(()=>(this.pollItems(),0===this.itemsToPoll.length))}bindTextureToFrameBuffer(e){this.throwIfDisposed(),bindColorTextureToFramebuffer(this.gl,e,this.framebuffer),this.debug&&validateFramebuffer(this.gl)}unbindTextureToFrameBuffer(){null!=this.outputTexture?(bindColorTextureToFramebuffer(this.gl,this.outputTexture,this.framebuffer),this.debug&&validateFramebuffer(this.gl)):unbindColorTextureFromFramebuffer(this.gl,this.framebuffer)}downloadMatrixDriver(e,t){this.bindTextureToFrameBuffer(e);const n=t();return this.unbindTextureToFrameBuffer(),n}setOutputMatrixTextureDriver(e,t,n){this.throwIfDisposed();const r=this.gl;bindColorTextureToFramebuffer(r,e,this.framebuffer),this.debug&&validateFramebuffer(r),this.outputTexture=e,callAndCheck(r,()=>r.viewport(0,0,t,n)),callAndCheck(r,()=>r.scissor(0,0,t,n))}setOutputMatrixWriteRegionDriver(e,t,n,r){this.throwIfDisposed(),callAndCheck(this.gl,()=>this.gl.scissor(e,t,n,r))}throwIfDisposed(){if(this.disposed)throw new Error("Attempted to use disposed GPGPUContext.")}throwIfNoProgram(){if(null==this.program)throw new Error("No GPU program is currently set.")}}function linearSearchLastTrue(e){let t=0;for(;t<e.length&&e[t]();++t);return t-1}const{getBroadcastDims}=backend_util;function makeShader(e,t,n){const r=[];if(e.forEach(e=>{const t=sizeFromShape(e.shapeInfo.logicalShape);if(e.shapeInfo.isUniform?r.push(`uniform float ${e.name}${t>1?`[${t}]`:""};`):(r.push(`uniform sampler2D ${e.name};`),r.push(`uniform int offset${e.name};`)),n.enableShapeUniforms){const{uniformShape:t}=getUniformInfoFromShape(n.packedInputs,e.shapeInfo.logicalShape,e.shapeInfo.texShape);switch(t.length){case 1:r.push(`uniform int ${e.name}Shape;`);break;case 2:r.push(`uniform ivec2 ${e.name}Shape;`);break;case 3:r.push(`uniform ivec3 ${e.name}Shape;`);break;case 4:r.push(`uniform ivec4 ${e.name}Shape;`)}r.push(`uniform ivec2 ${e.name}TexShape;`)}}),n.enableShapeUniforms){switch(t.logicalShape.length){case 1:r.push("uniform int outShape;");break;case 2:r.push("uniform ivec2 outShape;"),r.push("uniform int outShapeStrides;");break;case 3:r.push("uniform ivec3 outShape;"),r.push("uniform ivec2 outShapeStrides;");break;case 4:r.push("uniform ivec4 outShape;"),r.push("uniform ivec3 outShapeStrides;")}r.push("uniform ivec2 outTexShape;")}n.customUniforms&&n.customUniforms.forEach(e=>{r.push(`uniform ${e.type} ${e.name}${e.arrayIndex?`[${e.arrayIndex}]`:""};`)});const a=r.join("\n"),s=e.map(e=>getInputSamplingSnippet(e,t,n.packedInputs,n.enableShapeUniforms)).join("\n"),o=t.texShape,i=getGlslDifferences(),l=getFloatTextureSampleSnippet(i);let u,c,p=getShaderPrefix(i);return t.isPacked?(u=getPackedOutputSamplingSnippet(t.logicalShape,o,n.enableShapeUniforms),c=getFloatTextureSetRGBASnippet(i)):(u=getOutputSamplingSnippet(t.logicalShape,o,n.enableShapeUniforms),c=getFloatTextureSetRSnippet(i)),n.packedInputs&&(p+=SHADER_PACKED_PREFIX),[p,l,c,a,u,s,n.userCode].join("\n")}function getSamplerFromInInfo(e,t=!1){const n=e.shapeInfo.logicalShape;switch(n.length){case 0:return getSamplerScalar(e,t);case 1:return getSampler1D(e,t);case 2:return getSampler2D(e,t);case 3:return getSampler3D(e,t);case 4:return getSampler4D(e,t);case 5:return getSampler5D(e);case 6:return getSampler6D(e);default:throw new Error(`${n.length}-D input sampling is not yet supported`)}}function getPackedSamplerFromInInfo(e,t){switch(e.shapeInfo.logicalShape.length){case 0:return getPackedSamplerScalar(e);case 1:return getPackedSampler1D(e,t);case 2:return getPackedSampler2D(e,t);case 3:return getPackedSampler3D(e,t);default:return getPackedSamplerND(e,t)}}function getInputSamplingSnippet(e,t,n=!1,r){let a="";return a+=n?getPackedSamplerFromInInfo(e,r):getSamplerFromInInfo(e,r),e.shapeInfo.logicalShape.length<=t.logicalShape.length&&(a+=n?getPackedSamplerAtOutputCoords(e,t):getSamplerAtOutputCoords(e,t)),a}function getPackedOutputSamplingSnippet(e,t,n){switch(e.length){case 0:return getOutputScalarCoords();case 1:return getOutputPacked1DCoords(e,t,n);case 2:return getOutputPacked2DCoords(e,t,n);case 3:return getOutputPacked3DCoords(e,t,n);default:return getOutputPackedNDCoords(e,t,n)}}function getOutputSamplingSnippet(e,t,n){switch(e.length){case 0:return getOutputScalarCoords();case 1:return getOutput1DCoords(e,t,n);case 2:return getOutput2DCoords(e,t,n);case 3:return getOutput3DCoords(e,t,n);case 4:return getOutput4DCoords(e,t,n);case 5:return getOutput5DCoords(e,t);case 6:return getOutput6DCoords(e,t);default:throw new Error(`${e.length}-D output sampling is not yet supported`)}}function getFloatTextureSampleSnippet(e){return`\n    float sampleTexture(sampler2D textureSampler, vec2 uv) {\n      return ${e.texture2D}(textureSampler, uv).r;\n    }\n  `}function getFloatTextureSetRSnippet(e){return`\n    void setOutput(float val) {\n      ${e.output} = vec4(val, 0, 0, 0);\n    }\n  `}function getFloatTextureSetRGBASnippet(e){return`\n    void setOutput(vec4 val) {\n      ${e.output} = val;\n    }\n  `}function getShaderPrefix(e){return`${e.version}\n    precision highp float;\n    precision highp int;\n    precision highp sampler2D;\n    ${e.varyingFs} vec2 resultUV;\n    ${e.defineOutput}\n    const vec2 halfCR = vec2(0.5, 0.5);\n\n    struct ivec5\n    {\n      int x;\n      int y;\n      int z;\n      int w;\n      int u;\n    };\n\n    struct ivec6\n    {\n      int x;\n      int y;\n      int z;\n      int w;\n      int u;\n      int v;\n    };\n\n    uniform float NAN;\n    ${e.defineSpecialNaN}\n    ${e.defineSpecialInf}\n    ${e.defineRound}\n\n    int imod(int x, int y) {\n      return x - y * (x / y);\n    }\n\n    int idiv(int a, int b, float sign) {\n      int res = a / b;\n      int mod = imod(a, b);\n      if (sign < 0. && mod != 0) {\n        res -= 1;\n      }\n      return res;\n    }\n\n    //Based on the work of Dave Hoskins\n    //https://www.shadertoy.com/view/4djSRW\n    #define HASHSCALE1 443.8975\n    float random(float seed){\n      vec2 p = resultUV * seed;\n      vec3 p3  = fract(vec3(p.xyx) * HASHSCALE1);\n      p3 += dot(p3, p3.yzx + 19.19);\n      return fract((p3.x + p3.y) * p3.z);\n    }\n\n    ${SAMPLE_1D_SNIPPET}\n    ${SAMPLE_2D_SNIPPET}\n    ${SAMPLE_3D_SNIPPET}\n  `}const SAMPLE_1D_SNIPPET="\nvec2 uvFromFlat(int texNumR, int texNumC, int index) {\n  int texR = index / texNumC;\n  int texC = index - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\nvec2 packedUVfrom1D(int texNumR, int texNumC, int index) {\n  int texelIndex = index / 2;\n  int texR = texelIndex / texNumC;\n  int texC = texelIndex - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\n",SAMPLE_2D_SNIPPET="\nvec2 packedUVfrom2D(int texelsInLogicalRow, int texNumR,\n  int texNumC, int row, int col) {\n  int texelIndex = (row / 2) * texelsInLogicalRow + (col / 2);\n  int texR = texelIndex / texNumC;\n  int texC = texelIndex - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\n",SAMPLE_3D_SNIPPET="\nvec2 packedUVfrom3D(int texNumR, int texNumC,\n    int texelsInBatch, int texelsInLogicalRow, int b,\n    int row, int col) {\n  int index = b * texelsInBatch + (row / 2) * texelsInLogicalRow + (col / 2);\n  int texR = index / texNumC;\n  int texC = index - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\n",SHADER_PACKED_PREFIX="\n  float getChannel(vec4 frag, vec2 innerDims) {\n    vec2 modCoord = mod(innerDims, 2.);\n    return modCoord.x == 0. ?\n      (modCoord.y == 0. ? frag.r : frag.g) :\n      (modCoord.y == 0. ? frag.b : frag.a);\n  }\n  float getChannel(vec4 frag, int dim) {\n    float modCoord = mod(float(dim), 2.);\n    return modCoord == 0. ? frag.r : frag.g;\n  }\n";function getOutputScalarCoords(){return"\n    int getOutputCoords() {\n      return 0;\n    }\n  "}function getOutputPacked1DCoords(e,t,n){const r=[Math.ceil(t[0]/2),Math.ceil(t[1]/2)];return 1===r[0]?n?"\n      int getOutputCoords() {\n        return 2 * int(resultUV.x * ceil(float(outTexShape[1]) / 2.0));\n      }\n    ":`\n      int getOutputCoords() {\n        return 2 * int(resultUV.x * ${r[1]}.0);\n      }\n    `:1===r[1]?n?"\n      int getOutputCoords() {\n        return 2 * int(resultUV.y * ceil(float(outTexShape[0]) / 2.0));\n      }\n    ":`\n      int getOutputCoords() {\n        return 2 * int(resultUV.y * ${r[0]}.0);\n      }\n    `:n?"\n    int getOutputCoords() {\n      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(packedTexShape[0], packedTexShape[1]));\n      return 2 * (resTexRC.x * packedTexShape[1] + resTexRC.y);\n    }\n  ":`\n    int getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${r[0]}, ${r[1]}));\n      return 2 * (resTexRC.x * ${r[1]} + resTexRC.y);\n    }\n  `}function getOutput1DCoords(e,t,n){return 1===t[0]?n?"\n      int getOutputCoords() {\n        return int(resultUV.x * float(outTexShape[1]));\n      }\n    ":`\n      int getOutputCoords() {\n        return int(resultUV.x * ${t[1]}.0);\n      }\n    `:1===t[1]?n?"\n      int getOutputCoords() {\n        return int(resultUV.y * float(outTexShape[0]));\n      }\n    ":`\n      int getOutputCoords() {\n        return int(resultUV.y * ${t[0]}.0);\n      }\n    `:n?"\n    int getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(outTexShape[0], outTexShape[1]));\n      return resTexRC.x * outTexShape[1] + resTexRC.y;\n    }\n  ":`\n    int getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${t[0]}, ${t[1]}));\n      return resTexRC.x * ${t[1]} + resTexRC.y;\n    }\n  `}function getOutputPacked3DCoords(e,t,n){if(n)return"\n    ivec3 getOutputCoords() {\n      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\n      int texelsInLogicalRow = int(ceil(float(outShape[2]) / 2.0));\n      int texelsInBatch = texelsInLogicalRow * int(ceil(float(outShape[1]) / 2.0));\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(packedTexShape[0], packedTexShape[1]));\n      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;\n\n      int b = index / texelsInBatch;\n      index -= b * texelsInBatch;\n\n      int r = 2 * (index / texelsInLogicalRow);\n      int c = imod(index, texelsInLogicalRow) * 2;\n\n      return ivec3(b, r, c);\n    }\n  ";const r=[Math.ceil(t[0]/2),Math.ceil(t[1]/2)],a=Math.ceil(e[2]/2),s=a*Math.ceil(e[1]/2);return`\n    ivec3 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${r[0]}, ${r[1]}));\n      int index = resTexRC.x * ${r[1]} + resTexRC.y;\n\n      int b = index / ${s};\n      index -= b * ${s};\n\n      int r = 2 * (index / ${a});\n      int c = imod(index, ${a}) * 2;\n\n      return ivec3(b, r, c);\n    }\n  `}function getOutput3DCoords(e,t,n){if(n)return`\n  ivec3 getOutputCoords() {\n    ivec2 resTexRC = ivec2(resultUV.yx *\n                           vec2(outTexShape[0], outTexShape[1]));\n    int index = resTexRC.x * outTexShape[1] + resTexRC.y;\n    ${getLogicalCoordinatesFromFlatIndexByUniform(["r","c","d"],e)}\n    return ivec3(r, c, d);\n  }\n`;const r=getLogicalCoordinatesFromFlatIndex(["r","c","d"],e);return`\n    ivec3 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${t[0]}, ${t[1]}));\n      int index = resTexRC.x * ${t[1]} + resTexRC.y;\n      ${r}\n      return ivec3(r, c, d);\n    }\n  `}function getOutputPackedNDCoords(e,t,n){if(n)return"\n    ivec4 getOutputCoords() {\n      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(packedTexShape[0], packedTexShape[1]));\n      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;\n\n      int texelsInLogicalRow = int(ceil(float(outShape[3]) / 2.0));\n      int texelsInBatch = texelsInLogicalRow * int(ceil(float(outShape[2]) / 2.0));\n      int texelsInBatchN = texelsInBatch * outShape[1];\n\n      int b2 = index / texelsInBatchN;\n      index -= b2 * texelsInBatchN;\n\n      int b = index / texelsInBatch;\n      index -= b * texelsInBatch;\n\n      int r = 2 * (index / texelsInLogicalRow);\n      int c = imod(index, texelsInLogicalRow) * 2;\n\n      return ivec4(b2, b, r, c);\n    }\n  ";const r=[Math.ceil(t[0]/2),Math.ceil(t[1]/2)],a=Math.ceil(e[e.length-1]/2),s=a*Math.ceil(e[e.length-2]/2);let o=s,i="",l="b, r, c";for(let t=2;t<e.length-1;t++)o*=e[e.length-t-1],i=`\n      int b${t} = index / ${o};\n      index -= b${t} * ${o};\n    `+i,l=`b${t}, `+l;return`\n    ivec${e.length} getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${r[0]}, ${r[1]}));\n      int index = resTexRC.x * ${r[1]} + resTexRC.y;\n\n      ${i}\n\n      int b = index / ${s};\n      index -= b * ${s};\n\n      int r = 2 * (index / ${a});\n      int c = imod(index, ${a}) * 2;\n\n      return ivec${e.length}(${l});\n    }\n  `}function getOutput4DCoords(e,t,n){if(n)return`\n    ivec4 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n        vec2(outTexShape[0], outTexShape[1]));\n      int index = resTexRC.x * outTexShape[1] + resTexRC.y;\n      ${getLogicalCoordinatesFromFlatIndexByUniform(["r","c","d","d2"],e)}\n      return ivec4(r, c, d, d2);\n    }\n  `;const r=getLogicalCoordinatesFromFlatIndex(["r","c","d","d2"],e);return`\n    ivec4 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n        vec2(${t[0]}, ${t[1]}));\n      int index = resTexRC.x * ${t[1]} + resTexRC.y;\n      ${r}\n      return ivec4(r, c, d, d2);\n    }\n  `}function getOutput5DCoords(e,t){const n=getLogicalCoordinatesFromFlatIndex(["r","c","d","d2","d3"],e);return`\n    ivec5 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx * vec2(${t[0]},\n                             ${t[1]}));\n\n      int index = resTexRC.x * ${t[1]} + resTexRC.y;\n\n      ${n}\n\n      ivec5 outShape = ivec5(r, c, d, d2, d3);\n      return outShape;\n    }\n  `}function getOutput6DCoords(e,t){const n=getLogicalCoordinatesFromFlatIndex(["r","c","d","d2","d3","d4"],e);return`\n    ivec6 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n        vec2(${t[0]}, ${t[1]}));\n      int index = resTexRC.x * ${t[1]} + resTexRC.y;\n\n      ${n}\n\n      ivec6 result = ivec6(r, c, d, d2, d3, d4);\n      return result;\n    }\n  `}function getOutputPacked2DCoords(e,t,n){const r=[Math.ceil(t[0]/2),Math.ceil(t[1]/2)];if(arraysEqual(e,t))return n?"\n      ivec2 getOutputCoords() {\n        ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\n        return 2 * ivec2(resultUV.yx * vec2(packedTexShape[0], packedTexShape[1]));\n      }\n    ":`\n      ivec2 getOutputCoords() {\n        return 2 * ivec2(resultUV.yx * vec2(${r[0]}, ${r[1]}));\n      }\n    `;const a=Math.ceil(e[1]/2);return n?"\n    ivec2 getOutputCoords() {\n      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\n      int texelsInLogicalRow = int(ceil(float(outShape[1]) / 2.0));\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(packedTexShape[0], packedTexShape[1]));\n\n      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;\n      int r = 2 * (index / texelsInLogicalRow);\n      int c = imod(index, texelsInLogicalRow) * 2;\n\n      return ivec2(r, c);\n    }\n  ":`\n    ivec2 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${r[0]}, ${r[1]}));\n\n      int index = resTexRC.x * ${r[1]} + resTexRC.y;\n      int r = 2 * (index / ${a});\n      int c = imod(index, ${a}) * 2;\n\n      return ivec2(r, c);\n    }\n  `}function getOutput2DCoords(e,t,n){return arraysEqual(e,t)?n?"\n      ivec2 getOutputCoords() {\n        return ivec2(resultUV.yx * vec2(outTexShape[0], outTexShape[1]));\n      }\n    ":`\n      ivec2 getOutputCoords() {\n        return ivec2(resultUV.yx * vec2(${t[0]}, ${t[1]}));\n      }\n    `:1===e[1]?n?"\n      ivec2 getOutputCoords() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n                               vec2(outTexShape[0], outTexShape[1]));\n        int index = resTexRC.x * outTexShape[1] + resTexRC.y;\n        return ivec2(index, 0);\n      }\n    ":`\n      ivec2 getOutputCoords() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n                               vec2(${t[0]}, ${t[1]}));\n        int index = resTexRC.x * ${t[1]} + resTexRC.y;\n        return ivec2(index, 0);\n      }\n    `:1===e[0]?n?"\n      ivec2 getOutputCoords() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n                               vec2(outTexShape[0], outTexShape[1]));\n        int index = resTexRC.x * outTexShape[1] + resTexRC.y;\n        return ivec2(0, index);\n      }\n    ":`\n      ivec2 getOutputCoords() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n                               vec2(${t[0]}, ${t[1]}));\n        int index = resTexRC.x * ${t[1]} + resTexRC.y;\n        return ivec2(0, index);\n      }\n    `:n?"\n    ivec2 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(outTexShape[0], outTexShape[1]));\n      int index = resTexRC.x * outTexShape[1] + resTexRC.y;\n      int r = index / outShape[1];\n      int c = index - r * outShape[1];\n      return ivec2(r, c);\n    }\n  ":`\n    ivec2 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(${t[0]}, ${t[1]}));\n      int index = resTexRC.x * ${t[1]} + resTexRC.y;\n      int r = index / ${e[1]};\n      int c = index - r * ${e[1]};\n      return ivec2(r, c);\n    }\n  `}function getFlatOffsetUniformName(e){return`offset${e}`}function getPackedSamplerScalar(e){const t=e.name;return`\n    vec4 ${"get"+t.charAt(0).toUpperCase()+t.slice(1)}() {\n      return ${getGlslDifferences().texture2D}(${t}, halfCR);\n    }\n  `}function getSamplerScalar(e,t){const n=e.name,r="get"+n.charAt(0).toUpperCase()+n.slice(1);if(e.shapeInfo.isUniform)return`float ${r}() {return ${n};}`;const[a,s]=e.shapeInfo.texShape;if(1===a&&1===s)return`\n      float ${r}() {\n        return sampleTexture(${n}, halfCR);\n      }\n    `;const o=getFlatOffsetUniformName(n);if(t)return`\n    float ${r}() {\n      vec2 uv = uvFromFlat(${n}TexShape[0], ${n}TexShape[1], ${o});\n      return sampleTexture(${n}, uv);\n    }\n  `;const[i,l]=e.shapeInfo.texShape;return`\n    float ${r}() {\n      vec2 uv = uvFromFlat(${i}, ${l}, ${o});\n      return sampleTexture(${n}, uv);\n    }\n  `}function getPackedSampler1D(e,t){const n=e.name,r="get"+n.charAt(0).toUpperCase()+n.slice(1),a=e.shapeInfo.texShape,s=getGlslDifferences();if(t)return`\n    vec4 ${r}(int index) {\n      ivec2 packedTexShape = ivec2(ceil(float(${n}TexShape[0]) / 2.0), ceil(float(${n}TexShape[1]) / 2.0));\n      vec2 uv = packedUVfrom1D(\n        packedTexShape[0], packedTexShape[1], index);\n      return ${s.texture2D}(${n}, uv);\n    }\n  `;const o=[Math.ceil(a[0]/2),Math.ceil(a[1]/2)];return`\n    vec4 ${r}(int index) {\n      vec2 uv = packedUVfrom1D(\n        ${o[0]}, ${o[1]}, index);\n      return ${s.texture2D}(${n}, uv);\n    }\n  `}function getSampler1D(e,t){const n=e.name,r="get"+n.charAt(0).toUpperCase()+n.slice(1);if(e.shapeInfo.isUniform)return`\n      float ${r}(int index) {\n        ${getUniformSampler(e)}\n      }\n    `;const a=e.shapeInfo.texShape,s=a[0],o=a[1];if(1===o&&1===s)return`\n      float ${r}(int index) {\n        return sampleTexture(${n}, halfCR);\n      }\n    `;const i=getFlatOffsetUniformName(n);return 1===o?t?`\n      float ${r}(int index) {\n        vec2 uv = vec2(0.5, (float(index + ${i}) + 0.5) / float(${n}TexShape[0]));\n        return sampleTexture(${n}, uv);\n      }\n    `:`\n      float ${r}(int index) {\n        vec2 uv = vec2(0.5, (float(index + ${i}) + 0.5) / ${s}.0);\n        return sampleTexture(${n}, uv);\n      }\n    `:1===s?t?`\n      float ${r}(int index) {\n        vec2 uv = vec2((float(index + ${i}) + 0.5) / float(${n}TexShape[1]), 0.5);\n        return sampleTexture(${n}, uv);\n      }\n    `:`\n      float ${r}(int index) {\n        vec2 uv = vec2((float(index + ${i}) + 0.5) / ${o}.0, 0.5);\n        return sampleTexture(${n}, uv);\n      }\n    `:t?`\n    float ${r}(int index) {\n      vec2 uv = uvFromFlat(${n}TexShape[0], ${n}TexShape[1], index + ${i});\n      return sampleTexture(${n}, uv);\n    }\n  `:`\n    float ${r}(int index) {\n      vec2 uv = uvFromFlat(${s}, ${o}, index + ${i});\n      return sampleTexture(${n}, uv);\n    }\n  `}function getPackedSampler2D(e,t){const n=e.shapeInfo.logicalShape,r=e.name,a="get"+r.charAt(0).toUpperCase()+r.slice(1),s=e.shapeInfo.texShape,o=s[0],i=s[1],l=getGlslDifferences();if(null!=s&&arraysEqual(n,s))return t?`\n      vec4 ${a}(int row, int col) {\n        vec2 uv = (vec2(col, row) + halfCR) / vec2(${r}TexShape[1], ${r}TexShape[0]);\n\n        return ${l.texture2D}(${r}, uv);\n      }\n    `:`\n      vec4 ${a}(int row, int col) {\n        vec2 uv = (vec2(col, row) + halfCR) / vec2(${i}.0, ${o}.0);\n\n        return ${l.texture2D}(${r}, uv);\n      }\n    `;if(t)return`\n    vec4 ${a}(int row, int col) {\n      ivec2 packedTexShape = ivec2(ceil(float(${r}TexShape[0]) / 2.0), ceil(float(${r}TexShape[1]) / 2.0));\n      int valuesPerRow = int(ceil(float(${r}Shape[1]) / 2.0));\n      vec2 uv = packedUVfrom2D(valuesPerRow, packedTexShape[0], packedTexShape[1], row, col);\n      return ${l.texture2D}(${r}, uv);\n    }\n  `;const u=[Math.ceil(s[0]/2),Math.ceil(s[1]/2)];return`\n    vec4 ${a}(int row, int col) {\n      vec2 uv = packedUVfrom2D(${Math.ceil(n[1]/2)}, ${u[0]}, ${u[1]}, row, col);\n      return ${l.texture2D}(${r}, uv);\n    }\n  `}function getSampler2D(e,t){const n=e.shapeInfo.logicalShape,r=e.name,a="get"+r.charAt(0).toUpperCase()+r.slice(1),s=e.shapeInfo.texShape;if(null!=s&&arraysEqual(n,s))return t?`\n      float ${a}(int row, int col) {\n        vec2 uv = (vec2(col, row) + halfCR) / vec2(${r}TexShape[1], ${r}TexShape[0]);\n        return sampleTexture(${r}, uv);\n      }\n    `:`\n    float ${a}(int row, int col) {\n      vec2 uv = (vec2(col, row) + halfCR) / vec2(${s[1]}.0, ${s[0]}.0);\n      return sampleTexture(${r}, uv);\n    }\n  `;const{newShape:o,keptDims:i}=squeezeShape(n);if(o.length<n.length){const n=["row","col"];return`\n      ${getSamplerFromInInfo(squeezeInputInfo(e,o),t)}\n      float ${a}(int row, int col) {\n        return ${a}(${getSqueezedParams(n,i)});\n      }\n    `}if(e.shapeInfo.isUniform)return`\n      float ${a}(int row, int col) {\n        int index = round(dot(vec2(row, col), vec2(${n[1]}, 1)));\n        ${getUniformSampler(e)}\n      }\n    `;const l=s[0],u=s[1],c=getFlatOffsetUniformName(r);return 1===u?t?`\n      float ${a}(int row, int col) {\n        float index = dot(vec3(row, col, ${c}), vec3(${r}Shape[1], 1, 1));\n        vec2 uv = vec2(0.5, (index + 0.5) / float(${r}TexShape[0]));\n        return sampleTexture(${r}, uv);\n      }\n    `:`\n    float ${a}(int row, int col) {\n      float index = dot(vec3(row, col, ${c}), vec3(${n[1]}, 1, 1));\n      vec2 uv = vec2(0.5, (index + 0.5) / ${l}.0);\n      return sampleTexture(${r}, uv);\n    }\n  `:1===l?t?`\n      float ${a}(int row, int col) {\n        float index = dot(vec3(row, col, ${c}), vec3(${r}Shape[1], 1, 1));\n        vec2 uv = vec2((index + 0.5) / float(${r}TexShape[1]), 0.5);\n        return sampleTexture(${r}, uv);\n      }\n    `:`\n    float ${a}(int row, int col) {\n      float index = dot(vec3(row, col, ${c}), vec3(${n[1]}, 1, 1));\n      vec2 uv = vec2((index + 0.5) / ${u}.0, 0.5);\n      return sampleTexture(${r}, uv);\n    }\n  `:t?`\n      float ${a}(int row, int col) {\n        // Explicitly use integer operations as dot() only works on floats.\n        int index = row * ${r}Shape[1] + col + ${c};\n        vec2 uv = uvFromFlat(${r}TexShape[0], ${r}TexShape[1], index);\n        return sampleTexture(${r}, uv);\n      }\n    `:`\n  float ${a}(int row, int col) {\n    // Explicitly use integer operations as dot() only works on floats.\n    int index = row * ${n[1]} + col + ${c};\n    vec2 uv = uvFromFlat(${l}, ${u}, index);\n    return sampleTexture(${r}, uv);\n  }\n`}function getPackedSampler3D(e,t){const n=e.shapeInfo.logicalShape,r=e.name,a="get"+r.charAt(0).toUpperCase()+r.slice(1),s=e.shapeInfo.texShape,o=[Math.ceil(s[0]/2),Math.ceil(s[1]/2)];if(1===n[0]){const r=[1,2],s=["b","row","col"];return`\n        ${getPackedSamplerFromInInfo(squeezeInputInfo(e,n.slice(1)),t)}\n        vec4 ${a}(int b, int row, int col) {\n          return ${a}(${getSqueezedParams(s,r)});\n        }\n      `}const i=getGlslDifferences();if(t)return`\n    vec4 ${a}(int b, int row, int col) {\n      ivec2 packedTexShape = ivec2(ceil(float(${r}TexShape[0]) / 2.0), ceil(float(${r}TexShape[1]) / 2.0));\n      int valuesPerRow = int(ceil(float(${r}Shape[2]) / 2.0));\n      int texelsInBatch = valuesPerRow * int(ceil(float(${r}Shape[1]) / 2.0));\n      vec2 uv = packedUVfrom3D(\n        packedTexShape[0], packedTexShape[1], texelsInBatch, valuesPerRow, b, row, col);\n      return ${i.texture2D}(${r}, uv);\n    }\n  `;const l=o[0],u=o[1],c=Math.ceil(n[2]/2);return`\n    vec4 ${a}(int b, int row, int col) {\n      vec2 uv = packedUVfrom3D(\n        ${l}, ${u}, ${c*Math.ceil(n[1]/2)}, ${c}, b, row, col);\n      return ${i.texture2D}(${r}, uv);\n    }\n  `}function getSampler3D(e,t){const n=e.shapeInfo.logicalShape,r=e.name,a="get"+r.charAt(0).toUpperCase()+r.slice(1),s=n[1]*n[2],o=n[2],{newShape:i,keptDims:l}=squeezeShape(n);if(i.length<n.length){const n=["row","col","depth"];return`\n        ${getSamplerFromInInfo(squeezeInputInfo(e,i),t)}\n        float ${a}(int row, int col, int depth) {\n          return ${a}(${getSqueezedParams(n,l)});\n        }\n      `}if(e.shapeInfo.isUniform)return`\n      float ${a}(int row, int col, int depth) {\n        int index = round(dot(vec3(row, col, depth),\n                          vec3(${s}, ${o}, 1)));\n        ${getUniformSampler(e)}\n      }\n    `;const u=e.shapeInfo.texShape,c=u[0],p=u[1],d=e.shapeInfo.flatOffset;if(p===s&&null==d)return t?`\n      float ${a}(int row, int col, int depth) {\n        int stride1 = ${r}Shape[2];\n        float texR = float(row);\n        float texC = dot(vec2(col, depth), vec2(stride1, 1));\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(${r}TexShape[1], ${r}TexShape[0]);\n        return sampleTexture(${r}, uv);\n      }\n    `:`\n        float ${a}(int row, int col, int depth) {\n          float texR = float(row);\n          float texC = dot(vec2(col, depth), vec2(${o}, 1));\n          vec2 uv = (vec2(texC, texR) + halfCR) /\n                     vec2(${p}.0, ${c}.0);\n          return sampleTexture(${r}, uv);\n        }\n      `;if(p===o&&null==d)return t?`\n      float ${a}(int row, int col, int depth) {\n        float texR = dot(vec2(row, col), vec2(${r}Shape[1], 1));\n        float texC = float(depth);\n        vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${r}TexShape[1], ${r}TexShape[0]);\n        return sampleTexture(${r}, uv);\n      }\n    `:`\n    float ${a}(int row, int col, int depth) {\n      float texR = dot(vec2(row, col), vec2(${n[1]}, 1));\n      float texC = float(depth);\n      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${p}.0, ${c}.0);\n      return sampleTexture(${r}, uv);\n    }\n  `;const h=getFlatOffsetUniformName(r);return t?`\n    float ${a}(int row, int col, int depth) {\n      // Explicitly use integer operations as dot() only works on floats.\n      int stride0 = ${r}Shape[1] * ${r}Shape[2];\n      int stride1 = ${r}Shape[2];\n      int index = row * ${s} + col * ${o} + depth + ${h};\n      vec2 uv = uvFromFlat(${r}TexShape[0], ${r}TexShape[1], index);\n      return sampleTexture(${r}, uv);\n    }\n    `:`\n      float ${a}(int row, int col, int depth) {\n        // Explicitly use integer operations as dot() only works on floats.\n        int index = row * ${s} + col * ${o} + depth + ${h};\n        vec2 uv = uvFromFlat(${c}, ${p}, index);\n        return sampleTexture(${r}, uv);\n      }\n  `}function getPackedSamplerND(e,t){const n=e.name,r="get"+n.charAt(0).toUpperCase()+n.slice(1),a=getGlslDifferences();if(t)return`\n    vec4 ${r}(int b2, int b, int row, int col) {\n      int valuesPerRow = int(ceil(float(${n}Shape[3]) / 2.0));\n      int texelsInBatch = valuesPerRow * int(ceil(float(${n}Shape[2]) / 2.0));\n      int index = b * texelsInBatch + (row / 2) * valuesPerRow + (col / 2);\n      texelsInBatch *= ${n}Shape[1];\n      index = b2 * texelsInBatch + index;\n      ivec2 packedTexShape = ivec2(ceil(float(${n}TexShape[0]) / 2.0), ceil(float(${n}TexShape[1]) / 2.0));\n      int texR = index / packedTexShape[1];\n      int texC = index - texR * packedTexShape[1];\n      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(packedTexShape[1], packedTexShape[0]); return ${a.texture2D}(${n}, uv);\n    }\n  `;const s=e.shapeInfo.logicalShape,o=s.length,i=e.shapeInfo.texShape,l=[Math.ceil(i[0]/2),Math.ceil(i[1]/2)],u=l[0],c=l[1],p=Math.ceil(s[o-1]/2);let d=p*Math.ceil(s[o-2]/2),h="int b, int row, int col",m=`b * ${d} + (row / 2) * ${p} + (col / 2)`;for(let e=2;e<o-1;e++)h=`int b${e}, `+h,d*=s[o-e-1],m=`b${e} * ${d} + `+m;return`\n    vec4 ${r}(${h}) {\n      int index = ${m};\n      int texR = index / ${c};\n      int texC = index - texR * ${c};\n      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${c}, ${u});\n      return ${a.texture2D}(${n}, uv);\n    }\n  `}function getSampler4D(e,t){const n=e.shapeInfo.logicalShape,r=e.name,a="get"+r.charAt(0).toUpperCase()+r.slice(1),s=n[3],o=n[2]*s,i=n[1]*o,{newShape:l,keptDims:u}=squeezeShape(n);if(l.length<n.length){const n=["row","col","depth","depth2"];return`\n      ${getSamplerFromInInfo(squeezeInputInfo(e,l),t)}\n      float ${a}(int row, int col, int depth, int depth2) {\n        return ${a}(${getSqueezedParams(n,u)});\n      }\n    `}if(e.shapeInfo.isUniform)return`\n      float ${a}(int row, int col, int depth, int depth2) {\n        int index = round(dot(vec4(row, col, depth, depth2),\n                          vec4(${i}, ${o}, ${s}, 1)));\n        ${getUniformSampler(e)}\n      }\n    `;const c=e.shapeInfo.flatOffset,p=e.shapeInfo.texShape,d=p[0],h=p[1],m=`int stride2 = ${r}Shape[3];`,f=`int stride1 = ${r}Shape[2] * stride2;`,g=`int stride0 = ${r}Shape[1] * stride1;`;if(h===i&&null==c)return t?`\n      float ${a}(int row, int col, int depth, int depth2) {\n        ${m}\n        ${f}\n        float texR = float(row);\n        float texC =\n            dot(vec3(col, depth, depth2),\n                vec3(stride1, stride2, 1));\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(${r}TexShape[1], ${r}TexShape[0]);\n        return sampleTexture(${r}, uv);\n      }\n    `:`\n      float ${a}(int row, int col, int depth, int depth2) {\n        float texR = float(row);\n        float texC =\n            dot(vec3(col, depth, depth2),\n                vec3(${o}, ${s}, 1));\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(${h}.0, ${d}.0);\n        return sampleTexture(${r}, uv);\n      }\n    `;if(h===s&&null==c)return t?`\n      float ${a}(int row, int col, int depth, int depth2) {\n        float texR = dot(vec3(row, col, depth),\n                         vec3(${r}Shape[1] * ${r}Shape[2], ${r}Shape[2], 1));\n        float texC = float(depth2);\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                  vec2(${r}TexShape[1], ${r}TexShape[0]);\n        return sampleTexture(${r}, uv);\n      }\n    `:`\n      float ${a}(int row, int col, int depth, int depth2) {\n        float texR = dot(vec3(row, col, depth),\n                         vec3(${n[1]*n[2]}, ${n[2]}, 1));\n        float texC = float(depth2);\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                  vec2(${h}.0, ${d}.0);\n        return sampleTexture(${r}, uv);\n      }\n    `;const $=getFlatOffsetUniformName(r);return t?`\n    float ${a}(int row, int col, int depth, int depth2) {\n      // Explicitly use integer operations as dot() only works on floats.\n      ${m}\n      ${f}\n      ${g}\n      int index = row * stride0 + col * stride1 +\n          depth * stride2 + depth2;\n      vec2 uv = uvFromFlat(${r}TexShape[0], ${r}TexShape[1], index + ${$});\n      return sampleTexture(${r}, uv);\n    }\n  `:`\n    float ${a}(int row, int col, int depth, int depth2) {\n      // Explicitly use integer operations as dot() only works on floats.\n      int index = row * ${i} + col * ${o} +\n          depth * ${s} + depth2;\n      vec2 uv = uvFromFlat(${d}, ${h}, index + ${$});\n      return sampleTexture(${r}, uv);\n    }\n  `}function getSampler5D(e){const t=e.shapeInfo.logicalShape,n=e.name,r="get"+n.charAt(0).toUpperCase()+n.slice(1),a=t[4],s=t[3]*a,o=t[2]*s,i=t[1]*o,{newShape:l,keptDims:u}=squeezeShape(t);if(l.length<t.length){const t=["row","col","depth","depth2","depth3"];return`\n      ${getSamplerFromInInfo(squeezeInputInfo(e,l))}\n      float ${r}(int row, int col, int depth, int depth2, int depth3) {\n        return ${r}(${getSqueezedParams(t,u)});\n      }\n    `}if(e.shapeInfo.isUniform)return`\n      float ${r}(int row, int col, int depth, int depth2, int depth3) {\n        float index = dot(\n          vec4(row, col, depth, depth2),\n          vec4(${i}, ${o}, ${s}, ${a})) +\n          depth3;\n        ${getUniformSampler(e)}\n      }\n    `;const c=e.shapeInfo.flatOffset,p=e.shapeInfo.texShape,d=p[0],h=p[1];return h===i&&null==c?`\n      float ${r}(int row, int col, int depth, int depth2, int depth3) {\n        int texR = row;\n        float texC = dot(vec4(col, depth, depth2, depth3),\n                         vec4(${o}, ${s}, ${a}, 1));\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(${h}.0, ${d}.0);\n        return sampleTexture(${n}, uv);\n      }\n    `:h===a&&null==c?`\n      float ${r}(int row, int col, int depth, int depth2, int depth3) {\n        float texR = dot(\n          vec4(row, col, depth, depth2),\n          vec4(${t[1]*t[2]*t[3]},\n               ${t[2]*t[3]}, ${t[3]}, 1));\n        int texC = depth3;\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                  vec2(${h}.0, ${d}.0);\n        return sampleTexture(${n}, uv);\n      }\n    `:`\n    float ${r}(int row, int col, int depth, int depth2, int depth3) {\n      // Explicitly use integer operations as dot() only works on floats.\n      int index = row * ${i} + col * ${o} + depth * ${s} +\n          depth2 * ${a} + depth3 + ${getFlatOffsetUniformName(n)};\n      vec2 uv = uvFromFlat(${d}, ${h}, index);\n      return sampleTexture(${n}, uv);\n    }\n  `}function getSampler6D(e){const t=e.shapeInfo.logicalShape,n=e.name,r="get"+n.charAt(0).toUpperCase()+n.slice(1),{newShape:a,keptDims:s}=squeezeShape(t);if(a.length<t.length){const t=["row","col","depth","depth2","depth3","depth4"];return`\n      ${getSamplerFromInInfo(squeezeInputInfo(e,a))}\n      float ${r}(int row, int col, int depth,\n                    int depth2, int depth3, int depth4) {\n        return ${r}(${getSqueezedParams(t,s)});\n      }\n    `}const o=t[5],i=t[4]*o,l=t[3]*i,u=t[2]*l,c=t[1]*u;if(e.shapeInfo.isUniform)return`\n      float ${r}(int row, int col, int depth,\n                  int depth2, int depth3, int depth4) {\n        int index = round(dot(\n          vec4(row, col, depth, depth2),\n          vec4(${c}, ${u}, ${l}, ${i})) +\n          dot(\n            vec2(depth3, depth4),\n            vec2(${o}, 1)));\n        ${getUniformSampler(e)}\n      }\n    `;const p=e.shapeInfo.flatOffset,d=e.shapeInfo.texShape,h=d[0],m=d[1];return m===c&&null==p?`\n      float ${r}(int row, int col, int depth,\n                    int depth2, int depth3, int depth4) {\n        int texR = row;\n        float texC = dot(vec4(col, depth, depth2, depth3),\n          vec4(${u}, ${l}, ${i}, ${o})) +\n               float(depth4);\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(${m}.0, ${h}.0);\n        return sampleTexture(${n}, uv);\n      }\n    `:m===o&&null==p?`\n      float ${r}(int row, int col, int depth,\n                    int depth2, int depth3, int depth4) {\n        float texR = dot(vec4(row, col, depth, depth2),\n          vec4(${t[1]*t[2]*t[3]*t[4]},\n               ${t[2]*t[3]*t[4]},\n               ${t[3]*t[4]},\n               ${t[4]})) + float(depth3);\n        int texC = depth4;\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                  vec2(${m}.0, ${h}.0);\n        return sampleTexture(${n}, uv);\n      }\n    `:`\n    float ${r}(int row, int col, int depth,\n                  int depth2, int depth3, int depth4) {\n      // Explicitly use integer operations as dot() only works on floats.\n      int index = row * ${c} + col * ${u} + depth * ${l} +\n          depth2 * ${i} + depth3 * ${o} + depth4 + ${getFlatOffsetUniformName(n)};\n      vec2 uv = uvFromFlat(${h}, ${m}, index);\n      return sampleTexture(${n}, uv);\n    }\n  `}function getUniformSampler(e){const t=e.name,n=sizeFromShape(e.shapeInfo.logicalShape);return n<2?`return ${t};`:`\n    for (int i = 0; i < ${n}; i++) {\n      if (i == index) {\n        return ${t}[i];\n      }\n    }\n  `}function getPackedSamplerAtOutputCoords(e,t){const n=e.name,r=n.charAt(0).toUpperCase()+n.slice(1),a="get"+r+"AtOutCoords",s=e.shapeInfo.logicalShape.length,o=t.logicalShape.length,i=getBroadcastDims(e.shapeInfo.logicalShape,t.logicalShape),l=getCoordsDataType(o),u=o-s;let c;const p=["x","y","z","w","u","v"];c=0===s?"":o<2&&i.length>=1?"coords = 0;":i.map(e=>`coords.${p[e+u]} = 0;`).join("\n");let d="";d=o<2&&s>0?"coords":e.shapeInfo.logicalShape.map((e,t)=>`coords.${p[t+u]}`).join(", ");let h="return outputValue;";const m=1===sizeFromShape(e.shapeInfo.logicalShape),f=1===sizeFromShape(t.logicalShape);if(1!==s||m||f){if(m&&!f)h=1===o?"\n        return vec4(outputValue.x, outputValue.x, 0., 0.);\n      ":"\n        return vec4(outputValue.x);\n      ";else if(i.length){const e=s-2,t=s-1;i.indexOf(e)>-1&&i.indexOf(t)>-1?h="return vec4(outputValue.x);":i.indexOf(e)>-1?h="return vec4(outputValue.x, outputValue.y, outputValue.x, outputValue.y);":i.indexOf(t)>-1&&(h="return vec4(outputValue.xx, outputValue.zz);")}}else h="\n      return vec4(outputValue.xy, outputValue.xy);\n    ";return`\n    vec4 ${a}() {\n      ${l} coords = getOutputCoords();\n      ${c}\n      vec4 outputValue = get${r}(${d});\n      ${h}\n    }\n  `}function getSamplerAtOutputCoords(e,t){const n=e.name,r=n.charAt(0).toUpperCase()+n.slice(1),a="get"+r+"AtOutCoords",s=e.shapeInfo.logicalShape.length,o=t.logicalShape.length;if(!e.shapeInfo.isUniform&&s===o&&null==e.shapeInfo.flatOffset&&arraysEqual(e.shapeInfo.texShape,t.texShape))return`\n      float ${a}() {\n        return sampleTexture(${n}, resultUV);\n      }\n    `;const i=getCoordsDataType(o),l=getBroadcastDims(e.shapeInfo.logicalShape,t.logicalShape),u=o-s;let c;const p=["x","y","z","w","u","v"];c=0===s?"":o<2&&l.length>=1?"coords = 0;":l.map(e=>`coords.${p[e+u]} = 0;`).join("\n");let d="";return d=o<2&&s>0?"coords":e.shapeInfo.logicalShape.map((e,t)=>`coords.${p[t+u]}`).join(", "),`\n    float ${a}() {\n      ${i} coords = getOutputCoords();\n      ${c}\n      return get${r}(${d});\n    }\n  `}function getCoordsDataType(e){if(e<=1)return"int";if(2===e)return"ivec2";if(3===e)return"ivec3";if(4===e)return"ivec4";if(5===e)return"ivec5";if(6===e)return"ivec6";throw Error(`GPU for rank ${e} is not yet supported`)}function getUniformInfoFromShape(e,t,n){const{newShape:r}=squeezeShape(t),a=t.length,s=e&&3===a&&1===t[0],o=s?t.slice(1):r,i=!e&&a>1&&!arraysEqual(t,n)&&r.length<a||s;return{useSqueezeShape:i,uniformShape:i?o:t}}function squeezeInputInfo(e,t){const n=JSON.parse(JSON.stringify(e));return n.shapeInfo.logicalShape=t,n}function getSqueezedParams(e,t){return t.map(t=>e[t]).join(", ")}function compileProgram(e,t,n,r){const a=n.map((e,n)=>{const r={logicalShape:e.shape,texShape:e.isUniform?null:e.texData.texShape,isUniform:e.isUniform,isPacked:!e.isUniform&&e.texData.isPacked,flatOffset:null};return null!=e.texData&&null!=e.texData.slice&&e.texData.slice.flatOffset>0&&(r.flatOffset=e.texData.slice.flatOffset),{name:t.variableNames[n],shapeInfo:r}}),s=a.map(e=>e.shapeInfo),o={logicalShape:r.shape,texShape:r.texData.texShape,isUniform:!1,isPacked:r.texData.isPacked,flatOffset:null},i=makeShader(a,o,t),l=e.createProgram(i);let u=null;const c=e.getUniformLocation(l,"NAN",!1);1===env().getNumber("WEBGL_VERSION")&&(u=e.getUniformLocation(l,"INFINITY",!1));const p=!1,d={},h={},m={};for(let n=0;n<t.variableNames.length;n++){const r=t.variableNames[n];d[r]=e.getUniformLocation(l,r,p),d[`offset${r}`]=e.getUniformLocation(l,`offset${r}`,p),t.enableShapeUniforms&&(h[`${r}Shape`]=e.getUniformLocation(l,`${r}Shape`,p),m[`${r}TexShape`]=e.getUniformLocation(l,`${r}TexShape`,p))}let f,g,$;t.enableShapeUniforms&&(f=e.getUniformLocation(l,"outShape",p),$=e.getUniformLocation(l,"outShapeStrides",p),g=e.getUniformLocation(l,"outTexShape",p));const y=[];return t.customUniforms&&t.customUniforms.forEach((t,n)=>{y[n]=e.getUniformLocation(l,t.name,p)}),{program:t,source:i,webGLProgram:l,uniformLocations:d,customUniformLocations:y,inShapeInfos:s,outShapeInfo:o,infLoc:u,nanLoc:c,inShapesLocations:h,inTexShapesLocations:m,outShapeLocation:f,outShapeStridesLocation:$,outTexShapeLocation:g}}function validateBinaryAndProgram(e,t){if(e.length!==t.length)throw Error(`Binary was compiled with ${e.length} inputs, but was executed with ${t.length} inputs`);e.forEach((e,n)=>{const r=e.logicalShape,a=t[n],s=a.shape;if(!arraysEqual(r,s))throw Error(`Binary was compiled with different shapes than the current args. Shapes ${r} and ${s} must match`);if(e.isUniform&&a.isUniform)return;const o=e.texShape,i=a.isUniform?null:a.texData.texShape;if(!arraysEqual(o,i))throw Error(`Binary was compiled with different texture shapes than the current args. Shape ${o} and ${i} must match`)})}function runProgram(e,t,n,r,a){t.program.enableShapeUniforms||(validateBinaryAndProgram(t.inShapeInfos,n),validateBinaryAndProgram([t.outShapeInfo],[r]));const s=r.texData.texture,o=r.texData.texShape;r.texData.isPacked?e.setOutputPackedMatrixTexture(s,o[0],o[1]):e.setOutputMatrixTexture(s,o[0],o[1]),e.setProgram(t.webGLProgram),1===env().getNumber("WEBGL_VERSION")&&null!==t.infLoc&&e.gl.uniform1f(t.infLoc,Infinity),null!==t.nanLoc&&e.gl.uniform1f(t.nanLoc,NaN),n.forEach((n,r)=>{const a=t.program.variableNames[r],s=t.uniformLocations[a],o=t.uniformLocations[`offset${a}`],i=t.inShapesLocations[`${a}Shape`],l=t.inTexShapesLocations[`${a}TexShape`];if(i){const{uniformShape:r}=getUniformInfoFromShape(t.program.packedInputs,n.shape,n.texData.texShape);switch(r.length){case 1:e.gl.uniform1iv(i,new Int32Array(r));break;case 2:e.gl.uniform2iv(i,new Int32Array(r));break;case 3:e.gl.uniform3iv(i,new Int32Array(r));break;case 4:e.gl.uniform4iv(i,new Int32Array(r))}}if(l&&e.gl.uniform2i(l,n.texData.texShape[0],n.texData.texShape[1]),null!=s)if(n.isUniform)if(sizeFromShape(n.shape)<2)e.gl.uniform1f(s,n.uniformValues[0]);else{let t=n.uniformValues;t instanceof Float32Array||(t=new Float32Array(t)),e.gl.uniform1fv(s,t)}else null!=n.texData.slice&&null!=o&&e.gl.uniform1i(o,n.texData.slice.flatOffset),e.setInputMatrixTexture(n.texData.texture,s,r)});const i=t.outShapeLocation;if(i)switch(r.shape.length){case 1:e.gl.uniform1iv(i,new Int32Array(r.shape));break;case 2:e.gl.uniform2iv(i,new Int32Array(r.shape));break;case 3:e.gl.uniform3iv(i,new Int32Array(r.shape));break;case 4:e.gl.uniform4iv(i,new Int32Array(r.shape))}if(t.outShapeStridesLocation){const n=computeStrides(r.shape);switch(r.shape.length){case 2:e.gl.uniform1iv(t.outShapeStridesLocation,new Int32Array(n));break;case 3:e.gl.uniform2iv(t.outShapeStridesLocation,new Int32Array(n));break;case 4:e.gl.uniform3iv(t.outShapeStridesLocation,new Int32Array(n))}}t.outTexShapeLocation&&e.gl.uniform2i(t.outTexShapeLocation,r.texData.texShape[0],r.texData.texShape[1]),t.program.customUniforms&&a&&t.program.customUniforms.forEach((n,r)=>{const s=t.customUniformLocations[r],o=a[r];if("float"===n.type)e.gl.uniform1fv(s,o);else if("vec2"===n.type)e.gl.uniform2fv(s,o);else if("vec3"===n.type)e.gl.uniform3fv(s,o);else if("vec4"===n.type)e.gl.uniform4fv(s,o);else if("int"===n.type)e.gl.uniform1iv(s,o);else if("ivec2"===n.type)e.gl.uniform2iv(s,o);else if("ivec3"===n.type)e.gl.uniform3iv(s,o);else{if("ivec4"!==n.type)throw Error(`uniform type ${n.type} is not supported yet.`);e.gl.uniform4iv(s,o)}}),e.executeProgram()}function makeShaderKey(e,t,n){let r="";t.concat(n).forEach(t=>{const a=null!=t.texData&&null!=t.texData.slice&&t.texData.slice.flatOffset>0;if(e.enableShapeUniforms&&!t.isUniform){const s=t.texData.texShape,{useSqueezeShape:o,uniformShape:i}=getUniformInfoFromShape(e.packedInputs,t.shape,s);let l="",u="",c="";if(1===i.length&&e.packedInputs){const e=[Math.ceil(s[0]/2),Math.ceil(s[1]/2)];l=`${e[0]>1}_${e[1]>1}`}else if(2!==i.length||e.packedInputs){if(i.length>2&&!e.packedInputs){const e=computeStrides(i);c=`${e[0]===s[1]}_${e[e.length-1]===s[1]}`}}else u=`${i[0]>1}_${i[1]>1}`;const p=t.shape.length,d=2===p&&arraysEqual(t.shape,s),h=1===sizeFromShape(t.shape),m=getBroadcastDims$1(t.shape,n.shape),f=!e.packedInputs&&p===n.shape.length&&arraysEqual(s,n.texData.texShape);r+=`${p}_${f}_${o}_${i.length}_${h}_${m}_${d}_${l}_${u}_${c}_${e.packedInputs||p>2?"":`${s[0]>1}_${s[1]>1}`}_${a}`}else r+=`${t.shape}_${t.isUniform?"uniform":t.texData.texShape}_${a}`});let a=e.constructor.name;return a+="_"+r+"_"+e.userCode+`${env().getNumber("WEBGL_VERSION")}`,a}function useShapeUniforms(e){return env().getBool("WEBGL_USE_SHAPES_UNIFORMS")&&e<=4}const{addImpl:addImplCPU,bincountImpl:bincountImplCPU,bincountReduceImpl:bincountReduceImplCPU,ceilImpl:ceilImplCPU,concatImpl:concatImplCPU,equalImpl:equalImplCPU,expImpl:expImplCPU,expm1Impl:expm1ImplCPU,floorImpl:floorImplCPU,gatherNdImpl:gatherNdImplCPU,gatherV2Impl:gatherV2ImplCPU,greaterImpl:greaterImplCPU,greaterEqualImpl:greaterEqualImplCPU,lessImpl:lessImplCPU,lessEqualImpl:lessEqualImplCPU,linSpaceImpl:linSpaceImplCPU,logImpl:logImplCPU,maxImpl:maxImplCPU,maximumImpl:maximumImplCPU,minimumImpl:minimumImplCPU,multiplyImpl:multiplyImplCPU,negImpl:negImplCPU,notEqualImpl:notEqualImplCPU,prodImpl:prodImplCPU,rangeImpl:rangeImplCPU,rsqrtImpl:rsqrtImplCPU,simpleAbsImpl:simpleAbsImplCPU,sliceImpl:sliceImplCPU,sparseFillEmptyRowsImpl:sparseFillEmptyRowsImplCPU,sparseReshapeImpl:sparseReshapeImplCPU,sparseSegmentReductionImpl:sparseSegmentReductionImplCPU,stridedSliceImpl:stridedSliceImplCPU,stringNGramsImpl:stringNGramsImplCPU,stringSplitImpl:stringSplitImplCPU,stringToHashBucketFastImpl:stringToHashBucketFastImplCPU,subImpl:subImplCPU,tileImpl:tileImplCPU,topKImpl:topKImplCPU,transposeImpl:transposeImplCPU,uniqueImpl:uniqueImplCPU}=shared;function getVecChannels(e,t){return["x","y","z","w","u","v"].slice(0,t).map(t=>`${e}.${t}`)}function getChannels(e,t){return 1===t?[e]:getVecChannels(e,t)}function getSourceCoords$2(e,t){if(1===e)return"rc";let n="";for(let r=0;r<e;r++)n+=t[r],r<e-1&&(n+=",");return n}class PackProgram{constructor(e){this.variableNames=["A"],this.packedInputs=!1,this.packedOutput=!0,this.outputShape=e;const t=e.length;if(0===t)this.userCode="\n        void main() {\n          setOutput(vec4(getA(), 0., 0., 0.));\n        }\n      ";else{const n=getChannels("rc",t),r=getCoordsDataType(t),a=getOutOfBoundsCondition(t,e,n),s=getSetup(t,e[e.length-1],e[e.length-2],n),o=getOutput(e,n);this.userCode=`\n        void main() {\n          ${r} rc = getOutputCoords();\n\n          if(${a}) {\n            setOutput(vec4(0));\n          } else {\n            ${s}\n\n            setOutput(vec4(${o}));\n          }\n        }\n      `}}}function getSourceCoordsArr(e,t){const n=[];for(let r=0;r<=1;r++)for(let a=0;a<=1;a++){let s=`${0===r?"r":"rp1"}, ${0===a?"c":"cp1"}`;for(let n=2;n<e;n++)s=`${t[t.length-1-n]},`+s;n.push(s)}return n}function getOutOfBoundsCondition(e,t,n){if(1===e)return`rc > ${t[0]}`;let r="";for(let a=e-2;a<e;a++)r+=`${n[a]} >= ${t[a]}`,a<e-1&&(r+="||");return r}function getSetup(e,t,n,r){if(1===e)return"";const a=r.slice(-2);return`\n    int r = ${a[0]};\n    int c = ${a[1]};\n    int rp1 = r + 1;\n    int cp1 = c + 1;\n\n    bool cEdge = cp1 >= ${t};\n    bool rEdge = rp1 >= ${n};\n  `}function getOutput(e,t){const n=e.length,r=getSourceCoordsArr(n,t);return 1===n?`getA(rc),\n            rc + 1 >= ${e[0]} ? 0. : getA(rc + 1),\n            0, 0`:`getA(${r[0]}),\n          cEdge ? 0. : getA(${r[1]}),\n          rEdge ? 0. : getA(${r[2]}),\n          rEdge || cEdge ? 0. : getA(${r[3]})`}class ReshapePackedProgram{constructor(e,t){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=e;let n="";for(let e=0;e<4;e++){let t="thisRC = rc;";e%2==1&&(t+="thisRC.z += 1;"),e>1&&(t+="thisRC.y += 1;"),n+=`\n        ${t}\n        ${e>0?"if(thisRC.y < rows && thisRC.z < cols){":""}\n          int flatIndex = getFlatIndex(thisRC);\n\n          ivec3 inputRC = inputCoordsFromReshapedOutCoords(flatIndex);\n          vec2 inputRCInnerDims = vec2(float(inputRC.y),float(inputRC.z));\n\n          result[${e}] =\n            getChannel(getA(inputRC.x, inputRC.y, inputRC.z), inputRCInnerDims);\n        ${e>0?"}":""}\n      `}this.userCode=`\n      ${getReshapedInputCoords(t)}\n      ${getFlatIndexFrom3D(e)}\n\n      void main() {\n        ivec3 rc = getOutputCoords();\n\n        vec4 result = vec4(0.);\n\n        ivec3 thisRC;\n        int rows = ${e[1]};\n        int cols = ${e[2]};\n\n        ${n}\n\n        setOutput(result);\n      }\n    `}}function getReshapedInputCoords(e){return`\n    ivec3 inputCoordsFromReshapedOutCoords(int index) {\n      ${getLogicalCoordinatesFromFlatIndex(["r","c","d"],e)}\n      return ivec3(r, c, d);\n    }\n  `}class TextureManager{constructor(e){this.gpgpu=e,this.numUsedTextures=0,this.numFreeTextures=0,this._numBytesAllocated=0,this._numBytesFree=0,this.freeTextures={},this.logEnabled=!1,this.usedTextures={}}acquireTexture(e,t,n){const r=getPhysicalFromLogicalTextureType(t,n),a=getKeyFromTextureShape(e,r,n);a in this.freeTextures||(this.freeTextures[a]=[]),a in this.usedTextures||(this.usedTextures[a]=[]);const s=computeBytes(e,r,this.gpgpu.gl,this.gpgpu.textureConfig,n);if(this.freeTextures[a].length>0){this.numFreeTextures--,this.numUsedTextures++,this._numBytesFree-=s,this.log();const e=this.freeTextures[a].shift();return this.usedTextures[a].push(e),e}let o;return r===PhysicalTextureType.PACKED_2X2_FLOAT32?o=this.gpgpu.createPackedMatrixTexture(e[0],e[1]):r===PhysicalTextureType.PACKED_2X2_FLOAT16?o=this.gpgpu.createFloat16PackedMatrixTexture(e[0],e[1]):r===PhysicalTextureType.UNPACKED_FLOAT32?o=this.gpgpu.createFloat32MatrixTexture(e[0],e[1]):r===PhysicalTextureType.UNPACKED_FLOAT16?o=this.gpgpu.createFloat16MatrixTexture(e[0],e[1]):r===PhysicalTextureType.PACKED_4X1_UNSIGNED_BYTE&&(o=this.gpgpu.createUnsignedBytesMatrixTexture(e[0],e[1])),this.usedTextures[a].push(o),this.numUsedTextures++,this._numBytesAllocated+=s,this.log(),o}releaseTexture(e,t,n,r){if(null==this.freeTextures)return;const a=getPhysicalFromLogicalTextureType(n,r),s=getKeyFromTextureShape(t,a,r);s in this.freeTextures||(this.freeTextures[s]=[]);const o=computeBytes(t,a,this.gpgpu.gl,this.gpgpu.textureConfig,r),i=env().get("WEBGL_DELETE_TEXTURE_THRESHOLD");-1!==i&&this._numBytesAllocated>i?(this.gpgpu.deleteMatrixTexture(e),this._numBytesAllocated-=o):(this.freeTextures[s].push(e),this.numFreeTextures++,this._numBytesFree+=o),this.numUsedTextures--;const l=this.usedTextures[s],u=l.indexOf(e);if(u<0)throw new Error("Cannot release a texture that was never provided by this texture manager");l.splice(u,1),this.log()}log(){if(!this.logEnabled)return;console.log("Free/Used",`${this.numFreeTextures} / ${this.numUsedTextures}`,`(${this.numFreeTextures+this.numUsedTextures})`);const e=this._numBytesFree/this._numBytesAllocated;console.log(`Bytes allocated: ${this._numBytesAllocated}`),console.log(`Bytes unused: ${this._numBytesFree} (${Math.round(100*e)}%)`)}get numBytesAllocated(){return this._numBytesAllocated}get numBytesFree(){return this._numBytesFree}getNumUsedTextures(){return this.numUsedTextures}getNumFreeTextures(){return this.numFreeTextures}dispose(){if(null!=this.freeTextures){for(const e in this.freeTextures)this.freeTextures[e].forEach(e=>{this.gpgpu.deleteMatrixTexture(e)});for(const e in this.usedTextures)this.usedTextures[e].forEach(e=>{this.gpgpu.deleteMatrixTexture(e)});this.freeTextures=null,this.usedTextures=null,this.numUsedTextures=0,this.numFreeTextures=0,this._numBytesAllocated=0,this._numBytesFree=0}}}function numBytesForInternalFormat(e,t){if(t===e.R32F)return 4;if(t===e.R16F)return 2;if(t===e.RGBA32F)return 16;if(t===e.RGBA)return 16;if(t===e.RGBA16F)return 8;throw new Error(`Unknown internal format ${t}`)}function computeBytes(e,t,n,r,a){const s=internalFormatForPhysicalTexType(t,r);let o;if(a){const[t,n]=getPackedMatrixTextureShapeWidthHeight(e[0],e[1]);o=t*n}else{const[t,n]=getUnpackedMatrixTextureShapeWidthHeight(e[0],e[1]);o=t*n}return o*numBytesForInternalFormat(n,s)}function internalFormatForPhysicalTexType(e,t){switch(e){case PhysicalTextureType.PACKED_2X2_FLOAT32:return getInternalFormatForPackedMatrixTexture(t);case PhysicalTextureType.PACKED_2X2_FLOAT16:return getInternalFormatForFloat16PackedMatrixTexture(t);case PhysicalTextureType.UNPACKED_FLOAT32:return getInternalFormatForFloat32MatrixTexture(t);case PhysicalTextureType.UNPACKED_FLOAT16:return getInternalFormatForFloat16MatrixTexture(t);case PhysicalTextureType.PACKED_4X1_UNSIGNED_BYTE:return getInternalFormatForUnsignedBytesMatrixTexture(t);default:throw new Error(`Unknown physical texture type ${e}`)}}function getPhysicalTextureForRendering(e){return env().getBool("WEBGL_RENDER_FLOAT32_ENABLED")?e?PhysicalTextureType.PACKED_2X2_FLOAT32:PhysicalTextureType.UNPACKED_FLOAT32:e?PhysicalTextureType.PACKED_2X2_FLOAT16:PhysicalTextureType.UNPACKED_FLOAT16}function getPhysicalFromLogicalTextureType(e,t){if(e===TextureUsage.UPLOAD)return PhysicalTextureType.PACKED_2X2_FLOAT32;if(e===TextureUsage.RENDER||null==e)return getPhysicalTextureForRendering(t);if(e===TextureUsage.DOWNLOAD||e===TextureUsage.PIXELS)return PhysicalTextureType.PACKED_4X1_UNSIGNED_BYTE;throw new Error(`Unknown logical texture type ${e}`)}function getKeyFromTextureShape(e,t,n){return`${e[0]}_${e[1]}_${t}_${n}`}class UnaryOpProgram{constructor(e,t){this.variableNames=["A"],this.outputShape=e,this.enableShapeUniforms=useShapeUniforms(this.outputShape.length),this.userCode=`\n      float unaryOperation(float x) {\n        ${t}\n      }\n\n      void main() {\n        float x = getAAtOutCoords();\n        float y = unaryOperation(x);\n\n        setOutput(y);\n      }\n    `}}const CHECK_NAN_SNIPPET$2="if (isnan(x)) return x;",LINEAR$1="return x;",ABS$1="return abs(x);",ELU$2="return (x >= 0.0) ? x : (exp(x) - 1.0);",RELU$2=CHECK_NAN_SNIPPET$2+"\n  return (x < 0.0) ? 0.0 : x;\n",RELU6$2=CHECK_NAN_SNIPPET$2+"\n  return (x < 0.0) ? 0.0 : min(6.0, x);\n",CLONE="return x;",SIGMOID$2="return 1.0 / (1.0 + exp(-1.0 * x));",LINEAR="return x;",ELU$1="\n  vec4 result;\n\n  result.r = (x.r >= 0.0) ? x.r : (exp(x.r) - 1.0);\n  result.g = (x.g >= 0.0) ? x.g : (exp(x.g) - 1.0);\n  result.b = (x.b >= 0.0) ? x.b : (exp(x.b) - 1.0);\n  result.a = (x.a >= 0.0) ? x.a : (exp(x.a) - 1.0);\n\n  return result;\n",RELU$1="\n  vec4 result = x * vec4(greaterThanEqual(x, vec4(0.0)));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n",RELU6$1="\n  vec4 result = min(x, vec4(6.)) * vec4(greaterThanEqual(x, vec4(0.0)));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n",SIGMOID$1="return 1.0 / (1.0 + exp(-1.0 * x));";class UnaryOpPackedProgram{constructor(e,t){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=e,this.enableShapeUniforms=useShapeUniforms(this.outputShape.length),this.userCode=`\n      vec4 unaryOperation(vec4 x) {\n        ${t}\n      }\n\n      void main() {\n        vec4 x = getAAtOutCoords();\n        vec4 y = unaryOperation(x);\n\n        setOutput(y);\n      }\n    `}}class UnpackProgram{constructor(e){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!1,this.outputShape=e;const t=e.length,n=getChannels("rc",t),r=getCoordsDataType(t),a=getSourceCoords$2(t,n),s=n.slice(-2),o=t<=1?"rc":`vec2(${s.join(",")})`;this.userCode=`\n      void main() {\n        ${r} rc = getOutputCoords();\n        vec4 packedInput = getA(${a});\n\n        setOutput(getChannel(packedInput, ${o}));\n      }\n    `}}const whereImpl=whereImpl$2,EPSILON_FLOAT32=1e-7,EPSILON_FLOAT16=1e-4,binaryCaches={};function getBinaryCache(e){return e in binaryCaches||(binaryCaches[e]={}),binaryCaches[e]}const CPU_HANDOFF_SIZE_THRESHOLD=env().getNumber("CPU_HANDOFF_SIZE_THRESHOLD"),BEFORE_PAGING_CONSTANT=600;function numMBBeforeWarning(){return null==env().global.screen?1024:env().global.screen.height*env().global.screen.width*window.devicePixelRatio*BEFORE_PAGING_CONSTANT/1024/1024}class MathBackendWebGL extends KernelBackend{constructor(e){if(super(),this.pendingRead=new WeakMap,this.pendingDisposal=new WeakSet,this.dataRefCount=new WeakMap,this.numBytesInGPU=0,this.uploadWaitMs=0,this.downloadWaitMs=0,this.lastGlFlushTime=0,this.warnedAboutMemory=!1,this.pendingDeletes=0,this.disposed=!1,!env().getBool("HAS_WEBGL"))throw new Error("WebGL is not supported on this device");if(null==e){const e=getWebGLContext(env().getNumber("WEBGL_VERSION"));this.binaryCache=getBinaryCache(env().getNumber("WEBGL_VERSION")),this.gpgpu=new GPGPUContext(e),this.canvas=e.canvas,this.gpgpuCreatedLocally=!0}else this.gpgpu=e,this.binaryCache={},this.gpgpuCreatedLocally=!1,this.canvas=e.gl.canvas;this.textureManager=new TextureManager(this.gpgpu),this.numMBBeforeWarning=numMBBeforeWarning(),this.texData=new DataStorage(this,engine())}nextDataId(){return MathBackendWebGL.nextDataId++}numDataIds(){return this.texData.numDataIds()-this.pendingDeletes}write(e,t,n){if((env().getBool("WEBGL_CHECK_NUMERICAL_PROBLEMS")||env().getBool("DEBUG"))&&this.checkNumericalProblems(e),"complex64"===n&&null!=e)throw new Error("Cannot write to a complex64 dtype. Please use tf.complex(real, imag).");const r={id:this.nextDataId()};return this.texData.set(r,{shape:t,dtype:n,values:e,usage:TextureUsage.UPLOAD,refCount:1}),r}refCount(e){return this.texData.has(e)?this.texData.get(e).refCount:0}incRef(e){this.texData.get(e).refCount++}decRef(e){this.texData.has(e)&&this.texData.get(e).refCount--}move(e,t,n,r,a){if(env().getBool("DEBUG")&&this.checkNumericalProblems(t),"complex64"===r)throw new Error("Cannot write to a complex64 dtype. Please use tf.complex(real, imag).");this.texData.set(e,{shape:n,dtype:r,values:t,usage:TextureUsage.UPLOAD,refCount:a})}disposeIntermediateTensorInfo(e){this.disposeData(e.dataId)}readSync(e){const t=this.texData.get(e),{values:n,dtype:r,complexTensorInfos:a,slice:s,shape:o,isPacked:i}=t;if(null!=s){let t;t=i?new UnaryOpPackedProgram(o,CLONE):new UnaryOpProgram(o,CLONE);const n=this.runWebGLProgram(t,[{dataId:e,shape:o,dtype:r}],r),a=this.readSync(n.dataId);return this.disposeIntermediateTensorInfo(n),a}if(null!=n)return this.convertAndCacheOnCPU(e);if("string"===r)return n;const l=null!=this.activeTimers;let u,c;return l&&(u=now()),c="complex64"===r?mergeRealAndImagArrays(this.readSync(a.real.dataId),this.readSync(a.imag.dataId)):this.getValuesFromTexture(e),l&&(this.downloadWaitMs+=now()-u),this.convertAndCacheOnCPU(e,c)}async read(e){if(this.pendingRead.has(e)){const t=this.pendingRead.get(e);return new Promise(e=>t.push(e))}const t=this.texData.get(e),{values:n,shape:r,slice:a,dtype:s,complexTensorInfos:o,isPacked:i}=t;if(null!=a){let t;t=i?new UnaryOpPackedProgram(r,CLONE):new UnaryOpProgram(r,CLONE);const n=this.runWebGLProgram(t,[{dataId:e,shape:r,dtype:s}],s),a=this.read(n.dataId);return this.disposeIntermediateTensorInfo(n),a}if(null!=n)return this.convertAndCacheOnCPU(e);if(!env().getBool("WEBGL_DOWNLOAD_FLOAT_ENABLED")&&2===env().getNumber("WEBGL_VERSION"))throw new Error("tensor.data() with WEBGL_DOWNLOAD_FLOAT_ENABLED=false and WEBGL_VERSION=2 not yet supported.");let l,u,c=null;if("complex64"!==s&&env().get("WEBGL_BUFFER_SUPPORTED")){l=this.decode(e);const t=this.texData.get(l.dataId);c=this.gpgpu.createBufferFromTexture(t.texture,...getDenseTexShape(r))}if(this.pendingRead.set(e,[]),"complex64"!==s&&await this.gpgpu.createAndWaitForFence(),"complex64"===s){const e=await Promise.all([this.read(o.real.dataId),this.read(o.imag.dataId)]);u=mergeRealAndImagArrays(e[0],e[1])}else if(null==c)u=this.getValuesFromTexture(e);else{const e=sizeFromShape(r);u=this.gpgpu.downloadFloat32MatrixFromBuffer(c,e)}if(null!=l&&this.disposeIntermediateTensorInfo(l),null!=c){const e=this.gpgpu.gl;callAndCheck(e,()=>e.deleteBuffer(c))}const p=this.convertAndCacheOnCPU(e,u),d=this.pendingRead.get(e);return this.pendingRead.delete(e),d.forEach(e=>e(p)),this.pendingDisposal.has(e)&&(this.pendingDisposal.delete(e),this.disposeData(e)&&engine().removeDataId(e,this),this.pendingDeletes--),p}bufferSync(e){const t=this.readSync(e.dataId);let n=t;if("string"===e.dtype)try{n=t.map(e=>decodeString(e))}catch(e){throw new Error("Failed to decode encoded string bytes into utf-8")}return buffer(e.shape,e.dtype,n)}checkNumericalProblems(e){if(null!=e)for(let t=0;t<e.length;t++){const n=e[t];if(!canBeRepresented(n)){if(env().getBool("WEBGL_RENDER_FLOAT32_CAPABLE"))throw Error(`The value ${n} cannot be represented with your current settings. Consider enabling float32 rendering: 'tf.env().set('WEBGL_RENDER_FLOAT32_ENABLED', true);'`);throw Error(`The value ${n} cannot be represented on this device.`)}}}getValuesFromTexture(e){const{shape:t,dtype:n,isPacked:r}=this.texData.get(e),a=sizeFromShape(t);if(env().getBool("WEBGL_DOWNLOAD_FLOAT_ENABLED")){const n=this.decode(e),r=this.texData.get(n.dataId),s=this.gpgpu.downloadMatrixFromPackedTexture(r.texture,...getDenseTexShape(t)).subarray(0,a);return this.disposeIntermediateTensorInfo(n),s}const s=env().getBool("WEBGL_PACK")&&!0===r,o=s?getShapeAs3D(t):t,i=s?new EncodeFloatPackedProgram(o):new EncodeFloatProgram(o),l=this.runWebGLProgram(i,[{shape:o,dtype:n,dataId:e}],"float32"),u=this.texData.get(l.dataId),c=this.gpgpu.downloadByteEncodedFloatMatrixFromOutputTexture(u.texture,u.texShape[0],u.texShape[1]).subarray(0,a);return this.disposeIntermediateTensorInfo(l),c}timerAvailable(){return env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE")>0}async time(e){const t=this.activeTimers,n=[];let r=!1;null==this.programTimersStack?(this.programTimersStack=n,r=!0):this.activeTimers.push(n),this.activeTimers=n,e();const a=flatten$3(this.activeTimers.map(e=>e.query)).filter(e=>null!=e),s=flatten$3(this.activeTimers.map(e=>e.name)).filter(e=>null!=e);this.activeTimers=t,r&&(this.programTimersStack=null);const o={uploadWaitMs:this.uploadWaitMs,downloadWaitMs:this.downloadWaitMs,kernelMs:null,wallMs:null};if(env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE")>0){const e=await Promise.all(a);o.kernelMs=sum$3(e),o.getExtraProfileInfo=()=>e.map((e,t)=>({name:s[t],ms:e})).map(e=>`${e.name}: ${e.ms}`).join(", ")}else o.kernelMs={error:"WebGL query timers are not supported in this environment."};return this.uploadWaitMs=0,this.downloadWaitMs=0,o}memory(){return{unreliable:!1,numBytesInGPU:this.numBytesInGPU,numBytesInGPUAllocated:this.textureManager.numBytesAllocated,numBytesInGPUFree:this.textureManager.numBytesFree}}startTimer(){return env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE")>0?this.gpgpu.beginQuery():{startMs:now(),endMs:null}}endTimer(e){return env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE")>0?(this.gpgpu.endQuery(),e):(e.endMs=now(),e)}async getQueryTime(e){return env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE")>0?this.gpgpu.waitForQueryAndGetTime(e):e.endMs-e.startMs}disposeData(e,t=!1){if(this.pendingDisposal.has(e))return!1;if(!this.texData.has(e))return!0;if(t?this.texData.get(e).refCount=0:this.texData.get(e).refCount--,!t&&this.texData.get(e).refCount>0)return!1;if(this.pendingRead.has(e))return this.pendingDisposal.add(e),this.pendingDeletes++,!1;this.releaseGPUData(e);const{complexTensorInfos:n}=this.texData.get(e);return null!=n&&(this.disposeData(n.real.dataId,t),this.disposeData(n.imag.dataId,t)),this.texData.delete(e),!0}releaseGPUData(e){const{texture:t,dtype:n,texShape:r,usage:a,isPacked:s,slice:o}=this.texData.get(e),i=o&&o.origDataId||e,l=this.dataRefCount.get(i);l>1?this.dataRefCount.set(i,l-1):(this.dataRefCount.delete(i),null!=t&&(this.numBytesInGPU-=this.computeBytes(r,n),this.textureManager.releaseTexture(t,r,a,s)));const u=this.texData.get(e);u.texture=null,u.texShape=null,u.isPacked=!1,u.slice=null}getTexture(e){return this.uploadToGPU(e),this.texData.get(e).texture}getDataInfo(e){return this.texData.get(e)}shouldExecuteOnCPU(e,t=CPU_HANDOFF_SIZE_THRESHOLD){return env().getBool("WEBGL_CPU_FORWARD")&&e.every(e=>null==this.texData.get(e.dataId).texture&&sizeFromShape(e.shape)<t)}getGPGPUContext(){return this.gpgpu}where(e){warn("tf.where() in webgl locks the UI thread. Call tf.whereAsync() instead");const t=e.dataSync();return whereImpl(e.shape,t)}packedUnaryOp(e,t,n){const r=new UnaryOpPackedProgram(e.shape,t),a=this.compileAndRun(r,[e],n);return engine().makeTensorFromDataId(a.dataId,a.shape,a.dtype)}abs(e){if(this.shouldExecuteOnCPU([e])&&"complex64"!==e.dtype){const t=simpleAbsImplCPU(this.texData.get(e.dataId).values);return this.makeOutput(e.shape,e.dtype,t)}if(env().getBool("WEBGL_PACK_UNARY_OPERATIONS"))return this.packedUnaryOp(e,ABS$1,e.dtype);const t=new UnaryOpProgram(e.shape,ABS$1),n=this.compileAndRun(t,[e]);return engine().makeTensorFromDataId(n.dataId,n.shape,n.dtype)}makeTensorInfo(e,t,n){let r;if("string"===t&&null!=n&&n.length>0&&isString(n[0])){const a=n.map(e=>encodeString(e));r=this.write(a,e,t)}else r=this.write(n,e,t);return this.texData.get(r).usage=null,{dataId:r,shape:e,dtype:t}}makeOutput(e,t,n){const{dataId:r}=this.makeTensorInfo(e,t,n);return engine().makeTensorFromDataId(r,e,t,this)}unpackTensor(e){const t=new UnpackProgram(e.shape);return this.runWebGLProgram(t,[e],e.dtype)}packTensor(e){const t=new PackProgram(e.shape);return this.runWebGLProgram(t,[e],e.dtype,null,!0)}packedReshape(e,t){const n=[getBatchDim(e.shape),...getRowsCols(e.shape)],r={dtype:e.dtype,shape:n,dataId:e.dataId},a=[getBatchDim(t),...getRowsCols(t)],s=new ReshapePackedProgram(a,n),o=this.runWebGLProgram(s,[r],e.dtype,null,!0);return{dataId:o.dataId,shape:t,dtype:o.dtype}}decode(e){const t=this.texData.get(e),{isPacked:n,shape:r,dtype:a}=t,s=getShapeAs3D(r);let o;return o=n?new DecodeMatrixPackedProgram(s):new DecodeMatrixProgram(s),{dtype:a,shape:r,dataId:this.runWebGLProgram(o,[{shape:s,dtype:a,dataId:e}],a,null,!0).dataId}}runWebGLProgram(e,t,n,r,a=!1){const s=this.makeTensorInfo(e.outputShape,n),o=this.texData.get(s.dataId);if(e.packedOutput&&(o.isPacked=!0),e.outPackingScheme===PackingScheme.DENSE){const t=getDenseTexShape(e.outputShape);o.texShape=t.map(e=>2*e)}if(null!=e.outTexUsage&&(o.usage=e.outTexUsage),0===sizeFromShape(s.shape))return o.values=getTypedArrayFromDType(s.dtype,0),s;const i=[],l=t.map(t=>{if("complex64"===t.dtype)throw new Error("GPGPUProgram does not support complex64 input. For complex64 dtypes, please separate the program into real and imaginary parts.");let n=this.texData.get(t.dataId);if(null==n.texture){if(!e.packedInputs&&sizeFromShape(t.shape)<=env().getNumber("WEBGL_SIZE_UPLOAD_UNIFORM"))return{shape:t.shape,texData:null,isUniform:!0,uniformValues:n.values};e.packedInputs&&(n.isPacked=!0,n.shape=t.shape)}else if(!!n.isPacked!=!!e.packedInputs)t=n.isPacked?this.unpackTensor(t):this.packTensor(t),i.push(t),n=this.texData.get(t.dataId);else if(n.isPacked&&!isReshapeFree(n.shape,t.shape)){const e=t,r=t.shape;t.shape=n.shape,t=this.packedReshape(t,r),i.push(t),n=this.texData.get(t.dataId),e.shape=r}return this.uploadToGPU(t.dataId),{shape:t.shape,texData:n,isUniform:!1}});this.uploadToGPU(s.dataId);const u={shape:s.shape,texData:o,isUniform:!1},c=makeShaderKey(e,l,u),p=this.getAndSaveBinary(c,()=>compileProgram(this.gpgpu,e,l,u)),d=null!=this.activeTimers;let h;d&&(h=this.startTimer()),runProgram(this.gpgpu,p,l,u,r),i.forEach(e=>this.disposeIntermediateTensorInfo(e)),d&&(h=this.endTimer(h),this.activeTimers.push({name:e.constructor.name,query:this.getQueryTime(h)}));const m=env().get("WEBGL_FLUSH_THRESHOLD");if(m>0){const e=now();e-this.lastGlFlushTime>m&&(this.gpgpu.gl.flush(),this.lastGlFlushTime=e)}if(!env().getBool("WEBGL_LAZILY_UNPACK")&&o.isPacked&&!1===a){const e=this.unpackTensor(s);return this.disposeIntermediateTensorInfo(s),e}return s}compileAndRun(e,t,n,r,a=!1){return this.runWebGLProgram(e,t,n=n||t[0].dtype,r,a)}getAndSaveBinary(e,t){return e in this.binaryCache||(this.binaryCache[e]=t()),this.binaryCache[e]}getTextureManager(){return this.textureManager}dispose(){this.disposed||(env().getBool("IS_TEST")||Object.keys(this.binaryCache).forEach(e=>{this.gpgpu.deleteProgram(this.binaryCache[e].webGLProgram),delete this.binaryCache[e]}),this.textureManager.dispose(),null!=this.canvas&&"undefined"!=typeof HTMLCanvasElement&&this.canvas instanceof HTMLCanvasElement?this.canvas.remove():this.canvas=null,this.gpgpuCreatedLocally&&(this.gpgpu.program=null,this.gpgpu.dispose()),this.disposed=!0)}floatPrecision(){return null==this.floatPrecisionValue&&(this.floatPrecisionValue=tidy(()=>{if(!env().get("WEBGL_RENDER_FLOAT32_ENABLED")){const e=env().getBool("DEBUG");env().set("DEBUG",!1);const t=this.abs(scalar(1e-8)).dataSync()[0];if(env().set("DEBUG",e),t>0)return 32}return 16})),this.floatPrecisionValue}epsilon(){return 32===this.floatPrecision()?EPSILON_FLOAT32:EPSILON_FLOAT16}uploadToGPU(e){const t=this.texData.get(e),{shape:n,dtype:r,values:a,texture:s,usage:o,isPacked:i}=t;if(null!=s)return;const l=null!=this.activeTimers;let u;l&&(u=now());let c=t.texShape;if(null==c&&(c=getTextureShapeFromLogicalShape(n,i),t.texShape=c),null!=a){const e=getShapeAs3D(n);let s,o=c[1],p=c[0];const d=a instanceof Uint8Array;i?([o,p]=getPackedMatrixTextureShapeWidthHeight(c[0],c[1]),s=new EncodeMatrixPackedProgram(e,[p,o],d)):s=new EncodeMatrixProgram(e,[p,o],d);const h=this.makeTensorInfo([p,o],r);this.texData.get(h.dataId).usage=d?TextureUsage.PIXELS:TextureUsage.UPLOAD,this.gpgpu.uploadDenseMatrixToTexture(this.getTexture(h.dataId),o,p,a);const m=this.runWebGLProgram(s,[h],r,null,!0),f=this.texData.get(m.dataId);t.texture=f.texture,t.texShape=f.texShape,t.isPacked=f.isPacked,t.usage=f.usage,this.disposeIntermediateTensorInfo(h),this.texData.delete(m.dataId),t.values=null,l&&(this.uploadWaitMs+=now()-u)}else{const e=this.acquireTexture(c,o,r,i);t.texture=e}}convertAndCacheOnCPU(e,t){const n=this.texData.get(e),{dtype:r}=n;return this.releaseGPUData(e),null!=t&&(n.values=float32ToTypedArray(t,r)),n.values}acquireTexture(e,t,n,r){if(this.numBytesInGPU+=this.computeBytes(e,n),!this.warnedAboutMemory&&this.numBytesInGPU>1024*this.numMBBeforeWarning*1024){const e=(this.numBytesInGPU/1024/1024).toFixed(2);this.warnedAboutMemory=!0,console.warn(`High memory usage in GPU: ${e} MB, most likely due to a memory leak`)}return this.textureManager.acquireTexture(e,t,r)}computeBytes(e,t){return e[0]*e[1]*bytesPerElement(t)}}function float32ToTypedArray(e,t){if("float32"===t||"complex64"===t)return e;if("int32"===t||"bool"===t){const n="int32"===t?new Int32Array(e.length):new Uint8Array(e.length);for(let t=0;t<n.length;++t)n[t]=Math.round(e[t]);return n}throw new Error(`Unknown dtype ${t}`)}MathBackendWebGL.nextDataId=0;const version$2="3.8.0";isBrowser()&&registerBackend("webgl",()=>new MathBackendWebGL,2);const CHECK_NAN_SNIPPET$1="\n  if (isnan(a)) return a;\n  if (isnan(b)) return b;\n";class BinaryOpProgram{constructor(e,t,n){this.variableNames=["A","B"],this.outputShape=assertAndGetBroadcastShape(t,n),this.enableShapeUniforms=useShapeUniforms(this.outputShape.length),this.userCode=`\n      float binaryOperation(float a, float b) {\n        ${e}\n      }\n\n      void main() {\n        float a = getAAtOutCoords();\n        float b = getBAtOutCoords();\n        setOutput(binaryOperation(a, b));\n      }\n    `}}const CHECK_NAN_SNIPPET="\n  result.r = isNaN.r > 0. ? NAN : result.r;\n  result.g = isNaN.g > 0. ? NAN : result.g;\n  result.b = isNaN.b > 0. ? NAN : result.b;\n  result.a = isNaN.a > 0. ? NAN : result.a;\n";class BinaryOpPackedProgram{constructor(e,t,n,r=!1){this.variableNames=["A","B"],this.supportsBroadcasting=!0,this.packedInputs=!0,this.packedOutput=!0,this.outputShape=assertAndGetBroadcastShape(t,n);const a=this.outputShape.length;this.enableShapeUniforms=useShapeUniforms(a);let s="";if(r)if(0===a||1===sizeFromShape(this.outputShape))s="\n          result.y = 0.;\n          result.z = 0.;\n          result.w = 0.;\n        ";else if(s=`\n          ${getCoordsDataType(a)} coords = getOutputCoords();\n        `,1===a)s+=this.enableShapeUniforms?"\n            result.y = (coords + 1) >= outShape ? 0. : result.y;\n            result.z = 0.;\n            result.w = 0.;\n          ":`\n            result.y = (coords + 1) >= ${this.outputShape[0]} ? 0. : result.y;\n            result.z = 0.;\n            result.w = 0.;\n          `;else{const e=getChannels("coords",a);s+=this.enableShapeUniforms?`\n            bool nextRowOutOfBounds =\n              (${e[a-2]} + 1) >= outShape[${a} - 2];\n            bool nextColOutOfBounds =\n              (${e[a-1]} + 1) >= outShape[${a} - 1];\n            result.y = nextColOutOfBounds ? 0. : result.y;\n            result.z = nextRowOutOfBounds ? 0. : result.z;\n            result.w = nextColOutOfBounds || nextRowOutOfBounds ? 0. : result.w;\n          `:`\n            bool nextRowOutOfBounds =\n              (${e[a-2]} + 1) >= ${this.outputShape[a-2]};\n            bool nextColOutOfBounds =\n              (${e[a-1]} + 1) >= ${this.outputShape[a-1]};\n            result.y = nextColOutOfBounds ? 0. : result.y;\n            result.z = nextRowOutOfBounds ? 0. : result.z;\n            result.w = nextColOutOfBounds || nextRowOutOfBounds ? 0. : result.w;\n          `}this.userCode=`\n      vec4 binaryOperation(vec4 a, vec4 b) {\n        ${e}\n      }\n\n      void main() {\n        vec4 a = getAAtOutCoords();\n        vec4 b = getBAtOutCoords();\n\n        vec4 result = binaryOperation(a, b);\n        ${s}\n\n        setOutput(result);\n      }\n    `}}function identity(e){const{inputs:t,backend:n}=e,{x:r}=t;return n.incRef(r.dataId),{dataId:r.dataId,shape:r.shape,dtype:r.dtype}}const identityConfig={kernelName:Identity$1,backendName:"webgl",kernelFunc:identity};function complex(e){const{inputs:t,backend:n}=e,{real:r,imag:a}=t,s=n.makeTensorInfo(r.shape,"complex64"),o=n.texData.get(s.dataId),i=identity({inputs:{x:r},backend:n}),l=identity({inputs:{x:a},backend:n});return o.complexTensorInfos={real:i,imag:l},s}const complexConfig={kernelName:Complex,backendName:"webgl",kernelFunc:complex},LEAKYRELU="return (a < 0.) ? b * a : a;",LEAKYRELU_PACKED="\n  vec4 aLessThanZero = vec4(lessThan(a, vec4(0.)));\n  return (aLessThanZero * (b * a)) + ((vec4(1.0) - aLessThanZero) * a);\n";function leakyRelu(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{alpha:s}=r,o=n.makeTensorInfo([],"float32",createScalarValue(s,"float32")),i=env().getBool("WEBGL_PACK_BINARY_OPERATIONS")?new BinaryOpPackedProgram(LEAKYRELU_PACKED,a.shape,o.shape):new BinaryOpProgram(LEAKYRELU,a.shape,o.shape),l=n.runWebGLProgram(i,[a,o],a.dtype);return n.disposeIntermediateTensorInfo(o),l}const leakyReluConfig={kernelName:LeakyRelu,backendName:"webgl",kernelFunc:leakyRelu},PRELU="return (a < 0.) ? b * a : a;",PRELU_PACKED="\n  vec4 aLessThanZero = vec4(lessThan(a, vec4(0.)));\n  return (aLessThanZero * (b * a)) + ((vec4(1.0) - aLessThanZero) * a);\n";function prelu(e){const{inputs:t,backend:n}=e,{x:r,alpha:a}=t,s=env().getBool("WEBGL_PACK_BINARY_OPERATIONS")?new BinaryOpPackedProgram(PRELU_PACKED,r.shape,a.shape):new BinaryOpProgram(PRELU,r.shape,a.shape);return n.runWebGLProgram(s,[r,a],r.dtype)}const preluConfig={kernelName:Prelu,backendName:"webgl",kernelFunc:prelu},CHECK_NAN_SNIPPET_UNARY="if (isnan(x)) return x;",CHECK_NAN_SNIPPET_BINARY="\n  if (isnan(a)) return a;\n  if (isnan(b)) return b;\n",CHECK_NAN_SNIPPET_BINARY_PACKED="\n  result.r = isNaN.r > 0. ? NAN : result.r;\n  result.g = isNaN.g > 0. ? NAN : result.g;\n  result.b = isNaN.b > 0. ? NAN : result.b;\n  result.a = isNaN.a > 0. ? NAN : result.a;\n";function unaryKernelFunc({opSnippet:e,packedOpSnippet:t,cpuKernelImpl:n,dtype:r}){return({inputs:a,backend:s})=>{const{x:o}=a,i=s,l=r||o.dtype;if(i.shouldExecuteOnCPU([o])&&null!=n){const e=i.texData.get(o.dataId),t=n(e.values,l);return i.makeTensorInfo(o.shape,l,t)}let u;return u=env().getBool("WEBGL_PACK_UNARY_OPERATIONS")&&null!=t?new UnaryOpPackedProgram(o.shape,t):new UnaryOpProgram(o.shape,e),i.runWebGLProgram(u,[o],l)}}function binaryKernelFunc({opSnippet:e,packedOpSnippet:t,checkOutOfBounds:n=!1,supportsComplex:r=!1,cpuKernelImpl:a,dtype:s}){return({inputs:o,backend:i})=>{const{a:l,b:u}=o,c=i;if(r&&"complex64"===l.dtype){const t=c.texData.get(l.dataId),n=c.texData.get(u.dataId),[r,a]=[[t.complexTensorInfos.real,n.complexTensorInfos.real],[t.complexTensorInfos.imag,n.complexTensorInfos.imag]].map(t=>{const[n,r]=t,a={dataId:n.dataId,dtype:n.dtype,shape:l.shape},s={dataId:r.dataId,dtype:r.dtype,shape:u.shape},o=new BinaryOpProgram(e,l.shape,u.shape);return c.runWebGLProgram(o,[a,s],upcastType(n.dtype,r.dtype))}),s=complex({inputs:{real:r,imag:a},backend:c});return c.disposeIntermediateTensorInfo(r),c.disposeIntermediateTensorInfo(a),s}const p=s||upcastType(l.dtype,u.dtype);if(("string"===l.dtype||"string"===u.dtype||c.shouldExecuteOnCPU([l,u]))&&null!=a){const e=c.texData.get(l.dataId).values,t=c.texData.get(u.dataId).values,n="string"===l.dtype?fromUint8ToStringArray(e):e,r="string"===l.dtype?fromUint8ToStringArray(t):t,[s,o]=a(l.shape,u.shape,n,r,p),i=c.makeTensorInfo(o,p);return c.texData.get(i.dataId).values=s,i}let d;return d=env().getBool("WEBGL_PACK_BINARY_OPERATIONS")&&null!=t?new BinaryOpPackedProgram(t,l.shape,u.shape,n):new BinaryOpProgram(e,l.shape,u.shape),c.runWebGLProgram(d,[l,u],p)}}function mapActivationToShaderProgram(e,t=!1){if("linear"===e)return t?LINEAR:LINEAR$1;if("relu"===e)return t?RELU$1:RELU$2;if("elu"===e)return t?ELU$1:ELU$2;if("relu6"===e)return t?RELU6$1:RELU6$2;if("prelu"===e)return t?PRELU_PACKED:PRELU;if("leakyrelu"===e)return t?LEAKYRELU_PACKED:LEAKYRELU;if("sigmoid"===e)return t?SIGMOID$1:SIGMOID$2;throw new Error(`Activation ${e} has not been implemented for the WebGL backend.`)}class MatMulPackedProgram{constructor(e,t,n,r=!1,a=!1,s=!1,o=null,i=!1,l=!1){this.variableNames=["matrixA","matrixB"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=n;const u=Math.ceil((r?e[1]:e[2])/2),c=r?"i * 2, rc.y":"rc.y, i * 2",p=a?"rc.z, i * 2":"i * 2, rc.z",d=r?["a.xxyy","a.zzww"]:["a.xxzz","a.yyww"],h=a?["b.xzxz","b.ywyw"]:["b.xyxy","b.zwzw"];let m="",f="";o&&(m=i?`vec4 activation(vec4 a) {\n          vec4 b = getPreluActivationWeightsAtOutCoords();\n          ${o}\n        }`:l?`vec4 activation(vec4 a) {\n          vec4 b = getLeakyreluAlphaAtOutCoords();\n          ${o}\n        }`:`vec4 activation(vec4 x) {\n          ${o}\n        }`,f="result = activation(result);");const g=s?"result += getBiasAtOutCoords();":"";s&&this.variableNames.push("bias"),i&&this.variableNames.push("preluActivationWeights"),l&&this.variableNames.push("leakyreluAlpha");let $="rc.x",y="rc.x";e[0]<t[0]?$=`int(min(float(rc.x), ${e[0]-1}.))`:t[0]<e[0]&&(y=`int(min(float(rc.x), ${t[0]-1}.))`),this.userCode=`\n      ${m}\n\n      const float sharedDimension = ${u}.0;\n\n      vec4 dot2x2ARowBCol(ivec3 rc) {\n        vec4 result = vec4(0);\n        for (int i = 0; i < ${u}; i++) {\n          int batchA = ${$};\n          int batchB = ${y};\n          vec4 a = getMatrixA(batchA, ${c});\n          vec4 b = getMatrixB(batchB, ${p});\n\n          // These swizzled products need to be separately added.\n          // See: https://github.com/tensorflow/tfjs/issues/1735\n          result += (${d[0]} * ${h[0]});\n          result += (${d[1]} * ${h[1]});\n        }\n        return result;\n      }\n\n      void main() {\n        ivec3 rc = getOutputCoords();\n        vec4 result = dot2x2ARowBCol(rc);\n\n        ${g}\n\n        ${f}\n\n        setOutput(result);\n      }\n    `}}const COMPLEX_MULTIPLY={REAL:"return areal * breal - aimag * bimag;",IMAG:"return areal * bimag + aimag * breal;"};class BinaryOpComplexProgram{constructor(e,t,n){this.variableNames=["AReal","AImag","BReal","BImag"],this.outputShape=assertAndGetBroadcastShape(t,n),this.userCode=`\n      float binaryOpComplex(\n          float areal, float aimag, float breal, float bimag) {\n        ${e}\n      }\n\n      void main() {\n        float areal = getARealAtOutCoords();\n        float aimag = getAImagAtOutCoords();\n        float breal = getBRealAtOutCoords();\n        float bimag = getBImagAtOutCoords();\n        setOutput(binaryOpComplex(areal, aimag, breal, bimag));\n      }\n    `}}const MUL="return a * b;";function multiply(e){const{inputs:t,backend:n}=e,{a:r,b:a}=t,s=upcastType(r.dtype,a.dtype);if("complex64"===r.dtype){const e=n.texData.get(r.dataId),t=n.texData.get(a.dataId),s=new BinaryOpComplexProgram(COMPLEX_MULTIPLY.REAL,r.shape,a.shape),o=new BinaryOpComplexProgram(COMPLEX_MULTIPLY.IMAG,r.shape,a.shape),i=[{dataId:e.complexTensorInfos.real.dataId,dtype:e.complexTensorInfos.real.dtype,shape:r.shape},{dataId:e.complexTensorInfos.imag.dataId,dtype:e.complexTensorInfos.imag.dtype,shape:r.shape},{dataId:t.complexTensorInfos.real.dataId,dtype:t.complexTensorInfos.real.dtype,shape:a.shape},{dataId:t.complexTensorInfos.imag.dataId,dtype:t.complexTensorInfos.imag.dtype,shape:a.shape}],l=n.runWebGLProgram(s,i,"float32"),u=n.runWebGLProgram(o,i,"float32"),c=complex({inputs:{real:l,imag:u},backend:n});return n.disposeIntermediateTensorInfo(l),n.disposeIntermediateTensorInfo(u),c}if(n.shouldExecuteOnCPU([r,a])){const e=n.texData.get(r.dataId),t=n.texData.get(a.dataId),[o,i]=multiplyImplCPU(r.shape,a.shape,e.values,t.values,s),l=n.makeTensorInfo(i,s);return n.texData.get(l.dataId).values=o,l}let o;return o=env().getBool("WEBGL_PACK_BINARY_OPERATIONS")?new BinaryOpPackedProgram(MUL,r.shape,a.shape):new BinaryOpProgram(MUL,r.shape,a.shape),n.runWebGLProgram(o,[r,a],s)}const multiplyConfig={kernelName:Multiply$1,backendName:"webgl",kernelFunc:multiply};function packedReshape(e,t,n){const r=[getBatchDim(e.shape),...getRowsCols(e.shape)],a={dtype:e.dtype,shape:r,dataId:e.dataId},s=[getBatchDim(t),...getRowsCols(t)],o=new ReshapePackedProgram(s,r),i=n.runWebGLProgram(o,[a],e.dtype,null,!0);return{dataId:i.dataId,shape:t,dtype:i.dtype}}function reshape(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{shape:s}=r,o=n,i=sizeFromShape(a.shape),l=inferFromImplicitShape(s,i),u=sizeFromShape(l);assert$4(i===u,()=>`The new shape (${l}) has ${u} elements and the old shape (${a.shape}) has ${i} elements. The new shape and old shape must have the same number of elements.`);const c=o.texData.get(a.dataId);return!c.isPacked||isReshapeFree(a.shape,l)||null!==c.texture&&isReshapeFree(c.shape,l)?(o.incRef(a.dataId),{dataId:a.dataId,shape:l,dtype:a.dtype}):packedReshape(a,l,o)}const reshapeConfig={kernelName:Reshape$1,backendName:"webgl",kernelFunc:reshape};class MeanProgram{constructor(e,t){this.variableNames=["x"];const{windowSize:n,batchSize:r,inSize:a,outSize:s}=e;this.outputShape=[r,s];const o=4*Math.floor(n/4),i=n%4;let l="sumValue += dot(values, ones);";if(null!=t){const e=1/t;l=`sumValue += dot(values * ${isInt(e)?e.toPrecision(2):e}, ones);`}let u="";a%n>0&&(u=`\n        if (inIdx < 0 || inIdx >= ${a}) {\n          return 0.0;\n        }\n      `),this.userCode=`\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\n\n      float getValue(int batch, int inIdx) {\n        ${u}\n        return getX(batch, inIdx);\n      }\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n        int outIdx = coords[1];\n        int inOffset = outIdx * ${n};\n\n        float sumValue = 0.0;\n\n        for (int i = 0; i < ${o}; i += 4) {\n          int inIdx = inOffset + i;\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            getValue(batch, inIdx + 3)\n          );\n\n          ${l}\n        }\n\n        int inIdx = inOffset + ${o};\n        if (${1===i}) {\n          vec4 values = vec4(getValue(batch, inIdx), 0.0, 0.0, 0.0);\n\n          ${l}\n        } else if (${2===i}) {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1), 0.0, 0.0);\n\n          ${l}\n        } else if (${3===i}) {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2), 0.0);\n\n          ${l}\n        }\n        setOutput(sumValue);\n      }\n    `}}class ReduceProgram{constructor(e,t){this.variableNames=["x"];const{windowSize:n,batchSize:r,inSize:a,outSize:s}=e;this.outputShape=[r,s];let o="0.0",i="";"prod"===t?o="1.0":"min"===t?(o="1.0 / 1e-20",i="min"):"max"===t&&(o="-1.0 / 1e-20",i="max");let l=`${t}(${t}(${t}(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])`;"sum"===t?l="sumValue":"prod"===t?l="prodValue":"all"===t?l="allValue":"any"===t&&(l="anyValue");const u=4*Math.floor(n/4),c=n%4;let p=`\n      if (${"sum"===t}) {\n        sumValue += dot(values, ones);\n      } else if (${"prod"===t}) {\n        vec2 tmp = vec2(values[0], values[1]) * vec2(values[2], values[3]);\n        prodValue *= tmp[0] * tmp[1];\n      } else {\n        minMaxValue = ${i}(values, minMaxValue);\n        if (${"min"===t} || ${"max"===t}) {\n          minMaxValue = ${i}(values, minMaxValue);\n          bvec4 isNaN = isnan(values);\n          if (isNaN.r || isNaN.g || isNaN.b || isNaN.a) {\n            minMaxValue = vec4(NAN);\n          }\n        }\n      }\n    `,d="vec4";"all"===t?(o="1.0",p="\n        bool reducedAllValue = all(values);\n        float floatedReducedAllValue = float(reducedAllValue);\n        allValue = float(allValue >= 1.0 && floatedReducedAllValue >= 1.0);\n      ",d="bvec4"):"any"===t&&(o="0.0",p="\n        bool reducedAnyValue = any(values);\n        float floatedReducedAnyValue = float(reducedAnyValue);\n        anyValue = float(anyValue >= 1.0 || floatedReducedAnyValue >= 1.0);\n      ",d="bvec4");let h="";a%n>0&&(h=`\n        if (inIdx < 0 || inIdx >= ${a}) {\n          return initializationValue;\n        }\n      `),this.userCode=`\n      const float initializationValue = ${o};\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\n\n      float getValue(int batch, int inIdx) {\n        ${h}\n        return getX(batch, inIdx);\n      }\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n        int outIdx = coords[1];\n        int inOffset = outIdx * ${n};\n\n        vec4 minMaxValue = vec4(${o});\n        float prodValue = 1.0;\n        float sumValue = 0.0;\n        float allValue = 1.0;\n        float anyValue = 0.0;\n\n        for (int i = 0; i < ${u}; i += 4) {\n          int inIdx = inOffset + i;\n          ${d} values = ${d}(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            getValue(batch, inIdx + 3)\n          );\n\n          ${p}\n        }\n\n        int inIdx = inOffset + ${u};\n        if (${1===c}) {\n          ${d} values = ${d}(\n            getValue(batch, inIdx),\n            initializationValue,\n            initializationValue,\n            initializationValue\n          );\n\n          ${p}\n        } else if (${2===c}) {\n          ${d} values = ${d}(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            initializationValue,\n            initializationValue\n          );\n\n          ${p}\n        } else if (${3===c}) {\n          ${d} values = ${d}(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            initializationValue\n          );\n\n          ${p}\n        }\n        setOutput(${l});\n      }\n    `}}function getReductionStages(e){const t=[];for(;0===t.length||1!==t[t.length-1].outSize;){const n=t.length?t[t.length-1].outSize:e[1],r=computeOptimalWindowSize(n);t.push({inSize:n,windowSize:r,outSize:Math.ceil(n/r)})}return t}function reduce(e,t,n,r){const a=getReductionStages(e.shape);let s=e;for(let o=0;o<a.length;o++){const{inSize:i,windowSize:l,outSize:u}=a[o];let c,p;c="mean"===n?0===o?new MeanProgram({windowSize:l,inSize:i,batchSize:e.shape[0],outSize:u},i):new MeanProgram({windowSize:l,inSize:i,batchSize:e.shape[0],outSize:u}):new ReduceProgram({windowSize:l,inSize:i,batchSize:e.shape[0],outSize:u},n),p=s,s=r.runWebGLProgram(c,[s],t),p.dataId!==e.dataId&&r.disposeIntermediateTensorInfo(p)}return s}class TransposeProgram{constructor(e,t){this.variableNames=["A"];const n=new Array(e.length);for(let r=0;r<n.length;r++)n[r]=e[t[r]];this.outputShape=n,this.rank=n.length;const r=getCoordsDataType(this.rank),a=getSwitchedCoords(t);this.userCode=`\n    void main() {\n      ${r} resRC = getOutputCoords();\n      setOutput(getA(${a}));\n    }\n    `}}function getSwitchedCoords(e){const t=e.length;if(t>6)throw Error(`Transpose for rank ${t} is not yet supported`);const n=["resRC.x","resRC.y","resRC.z","resRC.w","resRC.u","resRC.v"],r=new Array(t);for(let t=0;t<e.length;t++)r[e[t]]=n[t];return r.join()}class TransposePackedProgram{constructor(e,t){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0;const n=new Array(e.length);for(let r=0;r<n.length;r++)n[r]=e[t[r]];if(this.outputShape=n,this.rank=n.length,this.rank>6)throw Error(`Packed transpose for rank ${this.rank} is not yet supported.`);const r=getCoordsDataType(this.rank),a=getVecChannels("rc",this.rank),s=new Array(this.rank);for(let e=0;e<t.length;e++)s[t[e]]=a[e];const o=`vec2(${s.slice(-2).join()})`,i=`++${a[this.rank-1]} < ${n[this.rank-1]}`,l=`getChannel(getA(${s.join()}), ${o})`;this.userCode=`\n    void main() {\n      ${r} rc = getOutputCoords();\n      vec4 result = vec4(0.);\n      result[0] = ${l};\n      if(${i}) {\n        result[1] = ${l};\n      }\n      --${a[this.rank-1]};\n      if(++${a[this.rank-2]} < ${n[this.rank-2]}) {\n        result[2] = ${l};\n        if(${i}) {\n          result[3] = ${l};\n        }\n      }\n      setOutput(result);\n    }\n    `}}function transposeImpl(e,t,n){const r=env().getBool("WEBGL_PACK_ARRAY_OPERATIONS")?new TransposePackedProgram(e.shape,t):new TransposeProgram(e.shape,t);return n.runWebGLProgram(r,[e],e.dtype)}function sumImpl(e,t,n,r){const a=e.shape.length,s=parseAxisParam(t,e.shape);let o=s;const i=getAxesPermutation(o,a),l=null!=i;let u=e;l&&(u=transposeImpl(e,i,r),o=getInnerMostAxes(o.length,a)),assertAxesAreInnerMostDims("sum",o,a);const[c,p]=computeOutAndReduceShapes(u.shape,o);let d=c;n&&(d=expandShapeToKeepDim(c,s));const h=sizeFromShape(p),m=reshape({inputs:{x:u},attrs:{shape:[sizeFromShape(e.shape)/h,h]},backend:r}),f=reduce(m,sumOutType(e.dtype),"sum",r),g=reshape({inputs:{x:f},attrs:{shape:d},backend:r});return r.disposeIntermediateTensorInfo(m),r.disposeIntermediateTensorInfo(f),l&&r.disposeIntermediateTensorInfo(u),g}function sum(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{axis:s,keepDims:o}=r;return sumImpl(a,s,o,n)}const sumConfig={kernelName:Sum,backendName:"webgl",kernelFunc:sum};function transpose(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{perm:s}=r,o=n,i=new Array(a.shape.length);for(let e=0;e<i.length;e++)i[e]=a.shape[s[e]];let l;if(o.shouldExecuteOnCPU([a])){const e=o.texData.get(a.dataId),t=transposeImplCPU(e.values,a.shape,a.dtype,s,i);l=o.makeTensorInfo(i,a.dtype),o.texData.get(l.dataId).values=t}else l=transposeImpl(a,s,o);return l}const transposeConfig={kernelName:Transpose,backendName:"webgl",kernelFunc:transpose},MATMUL_SHARED_DIM_THRESHOLD=1e3;function batchMatMulImpl({a:e,b:t,transposeA:n,transposeB:r,backend:a,bias:s=null,preluActivationWeights:o=null,leakyreluAlpha:i=0,activation:l=null}){const u=e.shape.length,c=t.shape.length,p=n?e.shape[u-2]:e.shape[u-1],d=r?t.shape[c-1]:t.shape[c-2],h=n?e.shape[u-1]:e.shape[u-2],m=r?t.shape[c-2]:t.shape[c-1],f=e.shape.slice(0,-2),g=t.shape.slice(0,-2),$=sizeFromShape(f),y=sizeFromShape(g);assert$4(u>=2&&c>=2&&($===y||1===$||1===y),()=>`Error in matMul: the input batch dimensions must either be the same or at least one input batch dimension must be 1. Got input batch dimensions of (${f}) and (${g}).`);const b=($>y?e.shape.slice(0,-2):t.shape.slice(0,-2)).concat([h,m]);assert$4(p===d,()=>`Error in matMul: inner shapes (${p}) and (${d}) of Tensors with shapes ${e.shape} and ${t.shape} and transposeA=${n} and transposeB=${r} must match.`);const x=n?[$,p,h]:[$,h,p],v=r?[y,m,d]:[y,d,m],I=reshape({inputs:{x:e},backend:a,attrs:{shape:x}}),C=reshape({inputs:{x:t},backend:a,attrs:{shape:v}}),S=[I,C],k=Math.max($,y),T=n?I.shape[1]:I.shape[2],N=null!=s,w=null!=o,E="leakyrelu"===l,A=null!=l?mapActivationToShaderProgram(l,!0):null;let D;if((1===h||1===m)&&T>MATMUL_SHARED_DIM_THRESHOLD&&!1===(N||w||E||null!=A)){let e=I,t=C;n&&(e=transpose({inputs:{x:I},backend:a,attrs:{perm:[0,2,1]}}),S.push(e)),r&&(t=transpose({inputs:{x:C},backend:a,attrs:{perm:[0,2,1]}}),S.push(t));const s=1===m;let o=e;1!==m&&(o=reshape({inputs:{x:e},backend:a,attrs:{shape:[k,T,1]}}),S.push(o));const i=1===m?2:1;let l=t;s&&(l=reshape({inputs:{x:t},backend:a,attrs:{shape:[k,1,T]}}),S.push(l));const u=multiply({inputs:{a:o,b:l},backend:a});D=sum({inputs:{x:u},backend:a,attrs:{axis:i,keepDims:!0}}),S.push(u)}else{const l=upcastType(e.dtype,t.dtype),u=new MatMulPackedProgram(x,v,[k,h,m],n,r,N,A,w,E),c=[I,C];if(null!=s&&c.push(s),w&&c.push(o),E){const e=a.makeTensorInfo([],"float32",createScalarValue(i,"float32"));c.push(e),S.push(e)}D=a.runWebGLProgram(u,c,l)}const R=reshape({inputs:{x:D},backend:a,attrs:{shape:b}});S.push(D);for(const e of S)a.disposeIntermediateTensorInfo(e);return R}function _fusedMatMul(e){const{inputs:t,backend:n,attrs:r}=e,{a,b:s,bias:o,preluActivationWeights:i}=t,{transposeA:l,transposeB:u,activation:c,leakyreluAlpha:p}=r;return batchMatMulImpl({a,b:s,transposeA:l,transposeB:u,backend:n,bias:o,preluActivationWeights:i,leakyreluAlpha:p,activation:c})}const _fusedMatMulConfig={kernelName:_FusedMatMul,backendName:"webgl",kernelFunc:_fusedMatMul},ABS="return abs(x);";function abs(e){const{inputs:t,backend:n}=e,{x:r}=t;if(n.shouldExecuteOnCPU([r])&&"complex64"!==r.dtype){const e=n.texData.get(r.dataId),t=simpleAbsImplCPU(e.values);return n.makeTensorInfo(r.shape,r.dtype,t)}let a;return a=env().getBool("WEBGL_PACK_UNARY_OPERATIONS")?new UnaryOpPackedProgram(r.shape,ABS):new UnaryOpProgram(r.shape,ABS),n.runWebGLProgram(a,[r],r.dtype)}const absConfig={kernelName:Abs,backendName:"webgl",kernelFunc:abs},ACOS=CHECK_NAN_SNIPPET$2+"\n  if (abs(x) > 1.) {\n    return NAN;\n  }\n  return acos(x);\n",acos=unaryKernelFunc({opSnippet:ACOS}),acosConfig={kernelName:Acos,backendName:"webgl",kernelFunc:acos},ACOSH=CHECK_NAN_SNIPPET$2+"\n  if (x < 1.0) return NAN;\nreturn log(x + sqrt(x * x - 1.0));",acosh=unaryKernelFunc({opSnippet:ACOSH}),acoshConfig={kernelName:Acosh,backendName:"webgl",kernelFunc:acosh},ADD="return a + b;",addKernelFunc=binaryKernelFunc({opSnippet:ADD,packedOpSnippet:ADD,supportsComplex:!0,cpuKernelImpl:addImplCPU}),addConfig={kernelName:Add$1,backendName:"webgl",kernelFunc:addKernelFunc};class AddNProgram{constructor(e,t){this.outputShape=[],this.outputShape=e,this.variableNames=t.map((e,t)=>`T${t}`);const n=[];this.variableNames.forEach(e=>{n.push(`float v${e} = get${e}AtOutCoords();`)});const r=this.variableNames.map(e=>`v${e}`).join(" + ");this.userCode=`\n      void main() {\n        ${n.join("\n        ")}\n\n        float result = ${r};\n        setOutput(result);\n      }\n    `}}class AddNPackedProgram{constructor(e,t){this.outputShape=[],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=e,this.variableNames=t.map((e,t)=>`T${t}`);const n=[];this.variableNames.forEach(e=>{n.push(`vec4 v${e} = get${e}AtOutCoords();`)});const r=this.variableNames.map(e=>`v${e}`).join(" + ");this.userCode=`\n      void main() {\n        ${n.join("\n        ")}\n\n        vec4 result = ${r};\n        setOutput(result);\n      }\n    `}}function addN(e){const{inputs:t,backend:n}=e,r=t;if(1===r.length)return identity({inputs:{x:r[0]},backend:n});if(r.length>env().get("WEBGL_MAX_TEXTURES_IN_SHADER")){const e=Math.floor(r.length/2),t=addN({inputs:r.slice(0,e),backend:n}),a=addN({inputs:r.slice(e),backend:n});return addN({inputs:[t,a],backend:n})}const a=r.map(e=>e.dtype).reduce((e,t)=>upcastType(e,t)),s=r.map(e=>e.shape),o=env().getBool("WEBGL_PACK")?new AddNPackedProgram(r[0].shape,s):new AddNProgram(r[0].shape,s);return n.runWebGLProgram(o,r,a)}const addNConfig={kernelName:AddN,backendName:"webgl",kernelFunc:addN};function all(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{axis:s,keepDims:o}=r,i=a.shape.length,l=parseAxisParam(s,a.shape);let u=l;const c=getAxesPermutation(u,i);let p=a;null!=c&&(p=transpose({inputs:{x:a},backend:n,attrs:{perm:c}}),u=getInnerMostAxes(u.length,i)),assertAxesAreInnerMostDims("all",u,i);const[d,h]=computeOutAndReduceShapes(p.shape,u),m=reshape({inputs:{x:p},backend:n,attrs:{shape:[-1,sizeFromShape(h)]}}),f=reduce(m,m.dtype,"all",n);let g;return g=reshape(o?{inputs:{x:f},backend:n,attrs:{shape:expandShapeToKeepDim(d,l)}}:{inputs:{x:f},backend:n,attrs:{shape:d}}),n.disposeIntermediateTensorInfo(m),n.disposeIntermediateTensorInfo(f),null!=c&&n.disposeIntermediateTensorInfo(p),g}const allConfig={kernelName:All,backendName:"webgl",kernelFunc:all};function any(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{axis:s,keepDims:o}=r,i=a.shape.length,l=parseAxisParam(s,a.shape);let u=l;const c=getAxesPermutation(u,i);let p=a;null!=c&&(p=transpose({inputs:{x:a},backend:n,attrs:{perm:c}}),u=getInnerMostAxes(u.length,i)),assertAxesAreInnerMostDims("any",u,i);const[d,h]=computeOutAndReduceShapes(p.shape,u),m=reshape({inputs:{x:p},backend:n,attrs:{shape:[-1,sizeFromShape(h)]}}),f=reduce(m,m.dtype,"any",n);let g;return g=reshape(o?{inputs:{x:f},backend:n,attrs:{shape:expandShapeToKeepDim(d,l)}}:{inputs:{x:f},backend:n,attrs:{shape:d}}),n.disposeIntermediateTensorInfo(m),n.disposeIntermediateTensorInfo(f),null!=c&&n.disposeIntermediateTensorInfo(p),g}const anyConfig={kernelName:Any,backendName:"webgl",kernelFunc:any};class ArgMinMaxProgram{constructor(e,t,n){this.variableNames=["A"];const{windowSize:r,batchSize:a,outSize:s}=e;n||this.variableNames.push("bestIndicesA"),this.outputShape=[a,s],this.userCode=`\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n        int outIdx = coords[1];\n        int inOffset = outIdx * ${r};\n\n        int bestIndex = inOffset;\n        float bestValue = getA(batch, bestIndex);\n\n        for (int i = 0; i < ${r}; i++) {\n          int inIdx = ${n?"inOffset + i;":"round(getBestIndicesA(batch, inOffset + i));"};\n          float candidate = getA(batch, inIdx);\n          if (candidate ${"max"===t?">":"<"} bestValue) {\n            bestValue = candidate;\n            bestIndex = inIdx;\n          }\n        }\n        setOutput(float(bestIndex));\n      }\n    `}}class ArgMinMaxPackedProgram{constructor(e,t,n,r){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,assert$4(e.length>2,()=>`Packed arg${n.charAt(0).toUpperCase()+n.slice(1)} supports only inputs with rank above 2.`);const a=Math.ceil(e[e.length-1]/t);this.outputShape=e.slice(0,-1),a>1&&this.outputShape.push(a),r||this.variableNames.push("bestIndicesA");const s=this.outputShape,o=s.length,i=getCoordsDataType(o),l=getChannels("coords",o);let u,c;if(1===a){c=o+1;const e=getCoordsDataType(c);u=`\n        ${e} sourceLocR = ${e}(${l.join()}, 0);\n        ++${l[o-1]};\n        ${e} sourceLocG = ${e}(${l.join()}, 0);\n        ++${l[o-2]};\n        ${e} sourceLocA = ${e}(${l.join()}, 0);\n        --${l[o-1]};\n        ${e} sourceLocB = ${e}(${l.join()}, 0);\n        --${l[o-2]};`}else c=o,u=`\n        ${i} sourceLocR = coords;\n        ++${l[o-1]};\n        ${i} sourceLocG = coords;\n        ++${l[o-2]};\n        ${i} sourceLocA = coords;\n        --${l[o-1]};\n        ${i} sourceLocB = coords;\n        --${l[o-2]};`;const p=["x","y","z","w","u","v"].slice(0,c),d="."+p[c-1],h=p.map(e=>"int "+e),m=getChannels("sourceLocR",c-1).concat("inIdx.r"),f=getChannels("sourceLocG",c-1).concat("inIdx.g"),g=getChannels("sourceLocB",c-1).concat("inIdx.b"),$=getChannels("sourceLocA",c-1).concat("inIdx.a"),y="max"===n?"greaterThan":"lessThan",b=r?"":`\n          inIdx = round(vec4(getBestIndicesAChannel(${m.join()}),\n                             getBestIndicesAChannel(${f.join()}),\n                             getBestIndicesAChannel(${g.join()}),\n                             getBestIndicesAChannel(${$.join()})));`,x=`vec4(\n            getAChannel(${m.join()}),\n            hasNextCol ? getAChannel(${f.join()}) : 0.,\n            hasNextRow ? getAChannel(${g.join()}) : 0.,\n            hasNextRow && hasNextCol ? getAChannel(${$.join()}) : 0.)`,v=r?"":`\n      float getBestIndicesAChannel(${h.join()}) {\n        return getChannel(getBestIndicesA(${p.join()}),\n                                          vec2(${p.slice(-2).join()}));\n      }`;this.userCode=`\n      float getAChannel(${h.join()}) {\n        return getChannel(getA(${p.join()}),\n                               vec2(${p.slice(-2).join()}));\n      }\n      ${v}\n      void main() {\n        ${i} coords = getOutputCoords();\n        bool hasNextCol = ${l[o-1]} < ${s[o-1]-1};\n        bool hasNextRow = ${l[o-2]} < ${s[o-2]-1};\n        ${u}\n        ivec4 srcIdx = ivec4(sourceLocR${d}, sourceLocG${d},\n          sourceLocB${d}, sourceLocA${d}) * ${t};\n        ivec4 inIdx = srcIdx;\n        vec4 bestIndex = vec4(inIdx);\n        vec4 bestValue = ${x};\n\n        for (int i = 0; i < ${t}; i++) {\n          inIdx = srcIdx;\n          ${b}\n          vec4 candidate = ${x};\n          bvec4 nan = isnan(candidate);\n          bvec4 replace = bvec4(\n            vec4(${y}(candidate, bestValue)) * (vec4(1.0) - vec4(nan)));\n\n          bestValue = vec4(replace.x  ? candidate.x : bestValue.x,\n                           replace.y  ? candidate.y : bestValue.y,\n                           replace.z  ? candidate.z : bestValue.z,\n                           replace.w  ? candidate.w : bestValue.w);\n          bestIndex = mix(bestIndex, vec4(inIdx), vec4(replace));\n          srcIdx++;\n        }\n        setOutput(bestIndex);\n      }\n    `}}function argReduce(e,t,n,r=null){let a=t.shape[0],s=t.shape[1];null!=r&&(a=r.shape[0],s=r.shape[1]);const o=computeOptimalWindowSize(s),i={windowSize:o,inSize:s,batchSize:a,outSize:Math.ceil(s/o)},l=new ArgMinMaxProgram(i,n,null==r),u=[t];null!=r&&u.push(r);const c=e.runWebGLProgram(l,u,"int32");if(1===c.shape[1])return c;const p=argReduce(e,t,n,c);return e.disposeIntermediateTensorInfo(c),p}function argReducePacked(e,t,n,r=null){const a=null!=r?r.shape:t.shape,s=computeOptimalWindowSize(a[a.length-1]),o=new ArgMinMaxPackedProgram(a,s,n,null==r),i=e.runWebGLProgram(o,null==r?[t]:[t,r],"int32");if(i.shape.length===t.shape.length){const r=argReducePacked(e,t,n,i);return e.disposeIntermediateTensorInfo(i),r}return i}function argMinMaxReduce(e,t,n,r){const a=[n];if(assertAxesAreInnerMostDims("arg"+r.charAt(0).toUpperCase()+r.slice(1),a,t.shape.length),!env().getBool("WEBGL_PACK_REDUCE")||t.shape.length<=2){const n=[],[s,o]=computeOutAndReduceShapes(t.shape,a),i=sizeFromShape(o),l=reshape({inputs:{x:t},backend:e,attrs:{shape:[-1,i]}});n.push(l);const u=argReduce(e,l,r);n.push(u);const c=reshape({inputs:{x:u},backend:e,attrs:{shape:s}});return n.forEach(t=>e.disposeIntermediateTensorInfo(t)),c}return argReducePacked(e,t,r)}function argMax(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{axis:s}=r;let o=parseAxisParam(s,a.shape);const i=getAxesPermutation(o,a.shape.length);let l=a;const u=[];null!=i&&(l=transpose({inputs:{x:a},backend:n,attrs:{perm:i}}),u.push(l),o=getInnerMostAxes(o.length,l.shape.length)),assertAxesAreInnerMostDims("argMax",[o[0]],l.shape.length);const c=argMinMaxReduce(n,l,o[0],"max");return u.forEach(e=>n.disposeIntermediateTensorInfo(e)),c}const argMaxConfig={kernelName:ArgMax,backendName:"webgl",kernelFunc:argMax};function argMin(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{axis:s}=r;let o=parseAxisParam(s,a.shape);const i=getAxesPermutation(o,a.shape.length);let l=a;const u=[];null!=i&&(l=transpose({inputs:{x:a},backend:n,attrs:{perm:i}}),u.push(l),o=getInnerMostAxes(o.length,l.shape.length)),assertAxesAreInnerMostDims("argMin",[o[0]],l.shape.length);const c=argMinMaxReduce(n,l,o[0],"min");return u.forEach(e=>n.disposeIntermediateTensorInfo(e)),c}const argMinConfig={kernelName:ArgMin,backendName:"webgl",kernelFunc:argMin},ASIN=CHECK_NAN_SNIPPET$2+"\n  if (abs(x) > 1.) {\n    return NAN;\n  }\n  return asin(x);\n",asin=unaryKernelFunc({opSnippet:ASIN}),asinConfig={kernelName:Asin,backendName:"webgl",kernelFunc:asin},ASINH=CHECK_NAN_SNIPPET$2+"return log(x + sqrt(x * x + 1.0));",asinh=unaryKernelFunc({opSnippet:ASINH}),asinhConfig={kernelName:Asinh,backendName:"webgl",kernelFunc:asinh},ATAN=CHECK_NAN_SNIPPET$2+"\n  return atan(x);\n",atan=unaryKernelFunc({opSnippet:ATAN}),atanConfig={kernelName:Atan,backendName:"webgl",kernelFunc:atan},ATAN2=CHECK_NAN_SNIPPET_BINARY+"\n  return atan(a, b);\n",ATAN2_PACKED="\n  vec4 result = atan(a, b);\n  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));\n  "+CHECK_NAN_SNIPPET_BINARY_PACKED+"\n  return result;\n",atan2=binaryKernelFunc({opSnippet:ATAN2,packedOpSnippet:ATAN2_PACKED}),atan2Config={kernelName:Atan2,backendName:"webgl",kernelFunc:atan2},ATANH=CHECK_NAN_SNIPPET$2+"\n  if ((x < -1.0) || (x > 1.0)) return NAN;\nreturn (log(1.0 + x) - log(1.0 - x)) / 2.0;",atanh=unaryKernelFunc({opSnippet:ATANH}),atanhConfig={kernelName:Atanh,backendName:"webgl",kernelFunc:atanh};class Pool2DProgram{constructor(e,t,n,r=!1,a=!1){if(this.variableNames=["x"],"avg"===t&&n)throw new Error("Cannot compute positions for average pool.");const s=e.filterWidth,o=e.strideHeight,i=e.strideWidth,l=e.dilationHeight,u=e.dilationWidth,c=e.effectiveFilterHeight,p=e.effectiveFilterWidth,d=e.padInfo.top,h=e.padInfo.left;this.outputShape=e.outShape;const m="avg"===t;let f="0.0";if(m||(f="-1.0 / 1e-20"),n)return void(this.userCode=`\n        const ivec2 strides = ivec2(${o}, ${i});\n        const ivec2 pads = ivec2(${d}, ${h});\n\n        void main() {\n          ivec4 coords = getOutputCoords();\n          int batch = coords[0];\n          int d = coords[3];\n\n          ivec2 xRCCorner = coords.yz * strides - pads;\n          int xRCorner = xRCCorner.x;\n          int xCCorner = xRCCorner.y;\n\n          // max/min x(?, ?, d) to get y(yR, yC, d).\n          // ? = to be determined\n          float minMaxValue = 0.0;\n          float minMaxValueFound = 0.0;\n          int minMaxPosition = 0;\n          float avgValue = 0.0;\n\n          for (int wR = 0; wR < ${c};\n              wR += ${l}) {\n            int xR = xRCorner + wR;\n\n            if (xR < 0 || xR >= ${e.inHeight}) {\n              continue;\n            }\n\n            for (int wC = 0; wC < ${p};\n                wC += ${u}) {\n              int xC = xCCorner + wC;\n\n              if (xC < 0 || xC >= ${e.inWidth}) {\n                continue;\n              }\n\n              float value = getX(batch, xR, xC, d);\n\n              // If a min / max value has already been found, use it. If not,\n              // use the current value.\n              float currMinMaxValue = mix(\n                  value, minMaxValue, minMaxValueFound);\n              if (value >= currMinMaxValue) {\n                minMaxValue = value;\n                minMaxValueFound = 1.0;\n                minMaxPosition = ${r?a?`((batch  * ${e.inHeight} + xR) * ${e.inWidth} + xC) * ${e.inChannels} + d`:`(xR * ${e.inWidth} + xC) * ${e.inChannels} + d`:`wR * ${p} + wC`};\n              }\n            }\n          }\n          setOutput(float(minMaxPosition));\n        }\n      `);let g=`${t}(${t}(${t}(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])`;"avg"===t&&(g="avgValue / count");const $=4*Math.floor(s/4),y=s%4,b=`\n      if (${m}) {\n        avgValue += dot(values, ones);\n      } else {\n        minMaxValue = max(values, minMaxValue);\n      }\n    `;this.userCode=`\n      const ivec2 strides = ivec2(${o}, ${i});\n      const ivec2 pads = ivec2(${d}, ${h});\n      const float initializationValue = ${f};\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\n\n      float count = 0.0;\n\n      float getValue(int batch, int xR, int xC, int d) {\n        if (xC < 0 || xC >= ${e.inWidth}) {\n          return initializationValue;\n        }\n        count += 1.0;\n        return getX(batch, xR, xC, d);\n      }\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d = coords[3];\n\n        ivec2 xRCCorner = coords.yz * strides - pads;\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        // max/min x(?, ?, d) to get y(yR, yC, d).\n        // ? = to be determined\n        vec4 minMaxValue = vec4(${f});\n        float avgValue = 0.0;\n        count = 0.0;\n\n        for (int wR = 0; wR < ${c};\n            wR += ${l}) {\n          int xR = xRCorner + wR;\n\n          if (xR < 0 || xR >= ${e.inHeight}) {\n            continue;\n          }\n\n          for (int wC = 0; wC < ${$}; wC += 4) {\n            int xC = xCCorner + wC * ${u};\n\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              getValue(batch, xR, xC + ${u}, d),\n              getValue(batch, xR, xC + 2 * ${u}, d),\n              getValue(batch, xR, xC + 3 * ${u}, d)\n            );\n\n            ${b}\n          }\n\n          int xC = xCCorner + ${$};\n          if (${1===y}) {\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              initializationValue,\n              initializationValue,\n              initializationValue\n            );\n\n            ${b}\n          } else if (${2===y}) {\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              getValue(batch, xR, xC + ${u}, d),\n              initializationValue,\n              initializationValue\n            );\n\n            ${b}\n          } else if (${3===y}) {\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              getValue(batch, xR, xC + ${u}, d),\n              getValue(batch, xR, xC + 2 * ${u}, d),\n              initializationValue\n            );\n\n            ${b}\n          }\n        }\n        setOutput(${g});\n      }\n    `}}class Pool3DProgram{constructor(e,t,n,r=!1,a=!1){if(this.variableNames=["x"],"avg"===t&&n)throw new Error("Cannot compute positions for average pool.");const s=e.filterWidth,o=e.strideDepth,i=e.strideHeight,l=e.strideWidth,u=e.dilationDepth,c=e.dilationHeight,p=e.dilationWidth,d=e.effectiveFilterDepth,h=e.effectiveFilterHeight,m=e.effectiveFilterWidth,f=e.padInfo.front,g=e.padInfo.top,$=e.padInfo.left;this.outputShape=e.outShape;const y="avg"===t;let b="0.0";if(y||(b="-1.0 / 1e-20"),n)return void(this.userCode=`\n        const ivec3 strides =\n            ivec3(${o}, ${i}, ${l});\n        const ivec3 pads = ivec3(${f}, ${g}, ${$});\n\n        void main() {\n          ivec5 coords = getOutputCoords();\n          int batch = coords.x;\n          int ch = coords.u;\n\n          ivec3 xCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\n          int xDCorner = xCorner.x;\n          int xRCorner = xCorner.y;\n          int xCCorner = xCorner.z;\n\n          // max/min x(?, ?, ?, ch) to get y(yD, yR, yC, ch).\n          // ? = to be determined\n          float minMaxValue = 0.0;\n          float minMaxValueFound = 0.0;\n          int minMaxPosition = 0;\n\n          for (int wD = 0; wD < ${d};\n              wD += ${u}) {\n            int xD = xDCorner + wD;\n\n            if (xD < 0 || xD >= ${e.inDepth}) {\n              continue;\n            }\n\n            for (int wR = 0; wR < ${h};\n                wR += ${c}) {\n              int xR = xRCorner + wR;\n\n              if (xR < 0 || xR >= ${e.inHeight}) {\n                continue;\n              }\n\n              for (int wC = 0; wC < ${m};\n                  wC += ${p}) {\n                int xC = xCCorner + wC;\n\n                if (xC < 0 || xC >= ${e.inWidth}) {\n                  continue;\n                }\n\n                float value = getX(batch, xD, xR, xC, ch);\n\n                // If a min / max value has already been found, use it. If not,\n                // use the current value.\n                float currMinMaxValue = mix(\n                    value, minMaxValue, minMaxValueFound);\n                if (value >= currMinMaxValue) {\n                  minMaxValue = value;\n                  minMaxValueFound = 1.0;\n                  minMaxPosition = ${r?a?`(((batch * ${e.inDepth} + xD) * ${e.inHeight} + xR) * ${e.inWidth} + xC) * ${e.inChannels} + ch`:`((xD * ${e.inHeight} + xR) * ${e.inWidth} + xC) * ${e.inChannels} + ch`:`wD * ${h} * ${m} +\n                      wR * ${m} + wC`};\n                }\n              }\n            }\n          }\n          setOutput(float(minMaxPosition));\n        }\n      `);let x=`${t}(${t}(${t}(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])`;"avg"===t&&(x="avgValue / count");const v=4*Math.floor(s/4),I=s%4,C=`\n      if (${y}) {\n        avgValue += dot(values, ones);\n      } else {\n        minMaxValue = max(values, minMaxValue);\n      }\n    `;this.userCode=`\n      const ivec3 strides =\n        ivec3(${o}, ${i}, ${l});\n      const ivec3 pads = ivec3(${f}, ${g}, ${$});\n      const float initializationValue = ${b};\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\n\n      float count = 0.0;\n\n      float getValue(int batch, int xD, int xR, int xC, int ch) {\n        if (xC < 0 || xC >= ${e.inWidth}) {\n          return initializationValue;\n        }\n        count += 1.0;\n        return getX(batch, xD, xR, xC, ch);\n      }\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int ch = coords.u;\n\n        ivec3 xCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\n        int xDCorner = xCorner.x;\n        int xRCorner = xCorner.y;\n        int xCCorner = xCorner.z;\n\n        // max/min x(?, ?, ?, d) to get y(yD, yR, yC, ch).\n        // ? = to be determined\n        vec4 minMaxValue = vec4(${b});\n        float avgValue = 0.0;\n        count = 0.0;\n\n        for (int wD = 0; wD < ${d};\n            wD += ${u}) {\n          int xD = xDCorner + wD;\n\n          if (xD < 0 || xD >= ${e.inDepth}) {\n            continue;\n          }\n\n          for (int wR = 0; wR < ${h};\n            wR += ${c}) {\n            int xR = xRCorner + wR;\n\n            if (xR < 0 || xR >= ${e.inHeight}) {\n              continue;\n            }\n\n            for (int wC = 0; wC < ${v}; wC += 4) {\n              int xC = xCCorner + wC * ${p};\n\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                getValue(batch, xD, xR, xC + ${p}, ch),\n                getValue(batch, xD, xR, xC + 2 * ${p}, ch),\n                getValue(batch, xD, xR, xC + 3 * ${p}, ch)\n              );\n\n              ${C}\n            }\n\n            int xC = xCCorner + ${v};\n            if (${1===I}) {\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                initializationValue,\n                initializationValue,\n                initializationValue\n              );\n\n              ${C}\n            } else if (${2===I}) {\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                getValue(batch, xD, xR, xC + ${p}, ch),\n                initializationValue,\n                initializationValue\n              );\n\n              ${C}\n            } else if (${3===I}) {\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                getValue(batch, xD, xR, xC + ${p}, ch),\n                getValue(batch, xD, xR, xC + 2 * ${p}, ch),\n                initializationValue\n              );\n\n              ${C}\n            }\n          }\n          setOutput(${x});\n        }\n      }\n    `}}function avgPool(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t;assertNotComplex(a,"avgPool");const{filterSize:s,strides:o,pad:i,dimRoundingMode:l}=r;assert$4(eitherStridesOrDilationsAreOne(o,1),()=>`Error in avgPool: Either strides or dilations must be 1. Got strides ${o} and dilations '1'`);const u=computePool2DInfo(a.shape,s,o,1,i,l);if(1===u.filterWidth&&1===u.filterHeight&&arraysEqual(u.inShape,u.outShape))return identity({inputs:{x:a},backend:n});const c=new Pool2DProgram(u,"avg",!1);return n.runWebGLProgram(c,[a],"float32")}const avgPoolConfig={kernelName:AvgPool,backendName:"webgl",kernelFunc:avgPool};function avgPool3D(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{filterSize:s,strides:o,pad:i,dimRoundingMode:l,dataFormat:u}=r,c=computePool3DInfo(a.shape,s,o,[1,1,1],i,l,u),p=new Pool3DProgram(c,"avg",!1);return n.runWebGLProgram(p,[a],"float32")}const avgPool3DConfig={kernelName:AvgPool3D,backendName:"webgl",kernelFunc:avgPool3D};class AvgPool2DBackpropProgram{constructor(e){this.variableNames=["dy"],this.outputShape=e.inShape;const t=e.effectiveFilterHeight,n=e.effectiveFilterWidth;this.userCode=`\n      const ivec2 pads = ivec2(${t-1-e.padInfo.top}, ${n-1-e.padInfo.left});\n      const float avgMultiplier = float(${1/(e.filterHeight*e.filterWidth)});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n\n        ivec2 dyRCCorner = coords.yz - pads;\n        int dyRCorner = dyRCCorner.x;\n        int dyCCorner = dyRCCorner.y;\n\n        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ${t};\n            wR += ${e.dilationHeight}) {\n          float dyR = float(dyRCorner + wR) / ${e.strideHeight}.0;\n\n          if (dyR < 0.0 || dyR >= ${e.outHeight}.0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          for (int wC = 0; wC < ${n};\n            wC+= ${e.dilationWidth}) {\n            float dyC = float(dyCCorner + wC) / ${e.strideWidth}.0;\n\n            if (dyC < 0.0 || dyC >= ${e.outWidth}.0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            float dyValue = getDy(b, idyR, idyC, d);\n\n            dotProd += dyValue * avgMultiplier;\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class AvgPool3DBackpropProgram{constructor(e){this.variableNames=["dy"],this.outputShape=e.inShape;const t=e.effectiveFilterDepth,n=e.effectiveFilterHeight,r=e.effectiveFilterWidth;this.userCode=`\n      const ivec3 pads = ivec3(${t-1-e.padInfo.front}, ${n-1-e.padInfo.top}, ${r-1-e.padInfo.left});\n      const float avgMultiplier = float(${1/(e.filterDepth*e.filterHeight*e.filterWidth)});\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int ch = coords.u;\n\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\n        int dyDCorner = dyCorner.x;\n        int dyRCorner = dyCorner.y;\n        int dyCCorner = dyCorner.z;\n\n        // Convolve dy(?, ?, ?, d) with pos mask(:, :, :, ch) to get\n        // dx(xD, xR, xC, ch).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n\n        for (int wD = 0; wD < ${t};\n            wD += ${e.dilationDepth}) {\n          float dyD = float(dyDCorner + wD) / ${e.strideDepth}.0;\n\n          if (dyD < 0.0 || dyD >= ${e.outDepth}.0 || fract(dyD) > 0.0) {\n            continue;\n          }\n          int idyD = int(dyD);\n\n          for (int wR = 0; wR < ${n};\n              wR += ${e.dilationHeight}) {\n            float dyR = float(dyRCorner + wR) / ${e.strideHeight}.0;\n\n            if (dyR < 0.0 || dyR >= ${e.outHeight}.0 ||\n                fract(dyR) > 0.0) {\n              continue;\n            }\n            int idyR = int(dyR);\n\n            for (int wC = 0; wC < ${r};\n                wC += ${e.dilationWidth}) {\n              float dyC = float(dyCCorner + wC) / ${e.strideWidth}.0;\n\n              if (dyC < 0.0 || dyC >= ${e.outWidth}.0 ||\n                  fract(dyC) > 0.0) {\n                continue;\n              }\n              int idyC = int(dyC);\n\n              float dyValue = getDy(batch, idyD, idyR, idyC, ch);\n\n              dotProd += dyValue * avgMultiplier;\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}function avgPool3DGrad(e){const{inputs:t,backend:n,attrs:r}=e,{dy:a,input:s}=t,o=s,{filterSize:i,strides:l,pad:u,dimRoundingMode:c}=r,p=computePool3DInfo(o.shape,i,l,[1,1,1],u,c),d=new AvgPool3DBackpropProgram(p);return n.runWebGLProgram(d,[a],o.dtype)}const avgPoolGrad3DConfig={kernelName:AvgPool3DGrad,backendName:"webgl",kernelFunc:avgPool3DGrad};function avgPoolGrad(e){const{inputs:t,backend:n,attrs:r}=e,{dy:a,input:s}=t,o=s;assertNotComplex([a,s],"avgPoolGrad");const{filterSize:i,strides:l,pad:u}=r,c=computePool2DInfo(o.shape,i,l,1,u),p=new AvgPool2DBackpropProgram(c);return n.runWebGLProgram(p,[a],o.dtype)}const avgPoolGradConfig={kernelName:AvgPoolGrad,backendName:"webgl",kernelFunc:avgPoolGrad};function batchMatMul(e){const{inputs:t,backend:n,attrs:r}=e,{a,b:s}=t,{transposeA:o,transposeB:i}=r;return batchMatMulImpl({a,b:s,transposeA:o,transposeB:i,backend:n})}const batchMatMulConfig={kernelName:BatchMatMul,backendName:"webgl",kernelFunc:batchMatMul};class BatchNormProgram{constructor(e,t,n,r,a,s){this.outputShape=[],this.variableNames=["x","mean","variance"],assertAndGetBroadcastShape(e,t),assertAndGetBroadcastShape(e,n);let o="0.0";null!=r&&(assertAndGetBroadcastShape(e,r),this.variableNames.push("offset"),o="getOffsetAtOutCoords()");let i="1.0";null!=a&&(assertAndGetBroadcastShape(e,a),this.variableNames.push("scale"),i="getScaleAtOutCoords()"),this.outputShape=e,this.userCode=`\n      void main() {\n        float x = getXAtOutCoords();\n        float mean = getMeanAtOutCoords();\n        float variance = getVarianceAtOutCoords();\n        float offset = ${o};\n        float scale = ${i};\n        float inv = scale * inversesqrt(variance + float(${s}));\n        setOutput(dot(vec3(x, -mean, offset), vec3(inv, inv, 1)));\n      }\n    `}}class BatchNormPackedProgram{constructor(e,t,n,r,a,s){this.packedInputs=!0,this.packedOutput=!0,this.variableNames=["x","mean","variance"],assertAndGetBroadcastShape(e,t),assertAndGetBroadcastShape(e,n);let o="vec4(0.0)";null!=r&&(assertAndGetBroadcastShape(e,r),this.variableNames.push("offset"),o="getOffsetAtOutCoords()");let i="vec4(1.0)";null!=a&&(assertAndGetBroadcastShape(e,a),this.variableNames.push("scale"),i="getScaleAtOutCoords()"),this.outputShape=e,this.userCode=`\n      void main() {\n        vec4 offset = ${o};\n        vec4 scale = ${i};\n\n        vec4 x = getXAtOutCoords();\n        vec4 mean = getMeanAtOutCoords();\n        vec4 variance = getVarianceAtOutCoords();\n\n        vec4 inv = scale * inversesqrt(variance + vec4(${s}));\n\n        setOutput((x - mean) * inv + offset);\n      }\n    `}}const batchNorm=({inputs:e,backend:t,attrs:n})=>{const{x:r,mean:a,variance:s,offset:o,scale:i}=e;assert$4(a.shape.length===s.shape.length,()=>"Batch normalization gradient requires mean and variance to have equal ranks."),assert$4(null==o||a.shape.length===o.shape.length,()=>"Batch normalization gradient requires mean and offset to have equal ranks."),assert$4(null==i||a.shape.length===i.shape.length,()=>"Batch normalization gradient requires mean and scale to have equal ranks.");let{varianceEpsilon:l}=n;null==l&&(l=.001);const u=[r,a,s];let c=null;null!=o&&(c=o.shape,u.push(o));let p=null;null!=i&&(p=i.shape,u.push(i));const d=env().getBool("WEBGL_PACK_NORMALIZATION")?new BatchNormPackedProgram(r.shape,a.shape,s.shape,c,p,l):new BatchNormProgram(r.shape,a.shape,s.shape,c,p,l);return t.runWebGLProgram(d,u,u[0].dtype)},batchNormConfig={kernelName:FusedBatchNorm,backendName:"webgl",kernelFunc:batchNorm};class SliceProgram{constructor(e){this.variableNames=["source"],this.outputShape=e,this.rank=e.length;const t=getCoordsDataType(this.rank);this.customUniforms=[{name:"start",arrayIndex:this.rank,type:"int"}];const n=getCoords$1(this.rank);let r;r=`\n        ${t} sourceLoc;\n        ${t} coords = getOutputCoords();\n        ${e.map((e,t)=>`sourceLoc.${coords[t]} = start[${t}] + coords.${coords[t]};`).join("\n")}\n      `,this.userCode=`\n      void main() {\n        ${r}\n        setOutput(getSource(${n}));\n      }\n    `}}const coords=["x","y","z","w","u","v"];function getCoords$1(e){if(1===e)return"sourceLoc";if(e<=6)return coords.slice(0,e).map(e=>"sourceLoc."+e).join(",");throw Error(`Slicing for rank ${e} is not yet supported`)}class SlicePackedProgram{constructor(e){this.variableNames=["source"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=e,this.rank=e.length,this.customUniforms=[{name:"start",arrayIndex:this.rank,type:"int"}];const t=getCoordsDataType(this.rank),n=getChannels("coords",this.rank),r=getChannels("sourceLoc",this.rank),a=1===this.rank?"sourceLoc":`vec2(${r.slice(-2).join()})`,s=`getChannel(getSource(${r.join()}), ${a})`,o=`\n      result.x = ${s};\n      if (++${n[this.rank-1]} < ${e[this.rank-1]}) {\n        ++${r[this.rank-1]};\n        result.y = ${s};\n        --${r[this.rank-1]};\n      }\n    `,i=1===this.rank?"":`\n      --${n[this.rank-1]};\n      if (++${n[this.rank-2]} < ${e[this.rank-2]}) {\n        ++${r[this.rank-2]};\n        result.z = ${s};\n        if (++${n[this.rank-1]} < ${e[this.rank-1]}) {\n          ++${r[this.rank-1]};\n          result.w = ${s};\n        }\n      }\n    `,l=this.rank<=4?`sourceLoc = coords +\n            ${t}(${e.map((e,t)=>`start[${t}]`).join()});`:e.map((e,t)=>`${r[t]} = ${n[t]} + start[${t}];`).join("\n");this.userCode=`\n      void main() {\n        ${t} coords = getOutputCoords();\n        ${t} sourceLoc;\n        ${l}\n        vec4 result = vec4(0.);\n        ${o}\n        ${i}\n        setOutput(result);\n      }\n    `}}function shallowSlice(e,t,n,r){const a=r.texData.get(e.dataId),s=r.makeTensorInfo(n,e.dtype),o=r.texData.get(s.dataId);Object.assign(o,a),o.refCount=1,o.shape=n,o.dtype=e.dtype;let i=computeFlatOffset(t,computeStrides(e.shape));a.slice&&(i+=a.slice.flatOffset),o.slice={flatOffset:i,origDataId:a.slice&&a.slice.origDataId||e.dataId};const l=r.dataRefCount.get(o.slice.origDataId)||1;return r.dataRefCount.set(o.slice.origDataId,l+1),s}function slice(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{begin:s,size:o}=r,[i,l]=parseSliceParams(a,s,o);if(assertParamsValid(a,i,l),0===sizeFromShape(l))return n.makeTensorInfo(l,a.dtype,[]);if(n.shouldExecuteOnCPU([a])||"string"===a.dtype){const e=n.texData.get(a.dataId),t=sliceImplCPU(e.values,i,l,a.shape,a.dtype);return n.makeTensorInfo(l,a.dtype,t)}const{isPacked:u}=n.texData.get(a.dataId),c=isSliceContinous(a.shape,i,l);if(u||!c){const e=env().getBool("WEBGL_PACK_ARRAY_OPERATIONS")?new SlicePackedProgram(l):new SliceProgram(l);return n.runWebGLProgram(e,[a],a.dtype,[i])}return n.uploadToGPU(a.dataId),shallowSlice(a,i,l,n)}const sliceConfig={kernelName:Slice,backendName:"webgl",kernelFunc:slice},batchToSpaceND=e=>{const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{blockShape:s,crops:o}=r;assert$4(a.shape.length<=4,()=>"batchToSpaceND for rank > 4 with a WebGL backend not implemented yet");const i=s.reduce((e,t)=>e*t),l=getReshaped(a.shape,s,i),u=getPermuted(l.length,s.length),c=getReshapedPermuted(a.shape,s,i),p=getSliceBeginCoords(o,s.length),d=getSliceSize(c,o,s.length),h=[],m=reshape({inputs:{x:a},backend:n,attrs:{shape:l}}),f=transpose({inputs:{x:m},backend:n,attrs:{perm:u}}),g=reshape({inputs:{x:f},backend:n,attrs:{shape:c}}),$=slice({inputs:{x:g},backend:n,attrs:{begin:p,size:d}});return h.push(m),h.push(f),h.push(g),h.forEach(e=>n.disposeIntermediateTensorInfo(e)),$},batchToSpaceNDConfig={kernelName:BatchToSpaceND,backendName:"webgl",kernelFunc:batchToSpaceND};function bincount(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,weights:s}=t,{size:o}=r,i=n.readSync(a.dataId),l=n.readSync(s.dataId),u=bincountImplCPU(i,l,s.dtype,s.shape,o);return n.makeTensorInfo([o],s.dtype,u)}const bincountConfig={kernelName:Bincount,backendName:"webgl",kernelFunc:bincount},NOT_EQUAL="return float(a != b);",notEqual=binaryKernelFunc({opSnippet:NOT_EQUAL,cpuKernelImpl:notEqualImplCPU,dtype:"bool"}),notEqualConfig={kernelName:NotEqual,backendName:"webgl",kernelFunc:notEqual};function real(e){const{inputs:t,backend:n}=e,{input:r}=t;return identity({inputs:{x:n.texData.get(r.dataId).complexTensorInfos.real},backend:n})}const realConfig={kernelName:Real,backendName:"webgl",kernelFunc:real},TO_INT="return float(int(x));";function int(e,t){const n=new UnaryOpProgram(e.shape,TO_INT),r=t.runWebGLProgram(n,[e],"int32");return{dataId:r.dataId,shape:r.shape,dtype:r.dtype}}function cast(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{dtype:s}=r;if("complex64"===s){if("complex64"===a.dtype)return identity({inputs:{x:a},backend:n});const e=zeros$2(a.shape),t=cast({inputs:{x:a},backend:n,attrs:{dtype:"float32"}}),r=complex({inputs:{real:t,imag:e},backend:n});return e.dispose(),n.disposeIntermediateTensorInfo(t),r}if("complex64"===a.dtype){const e=real({inputs:{input:a},backend:n}),t=cast({inputs:{x:e},backend:n,attrs:{dtype:s}});return n.disposeIntermediateTensorInfo(e),t}if(!hasEncodingLoss(a.dtype,s)){const e=identity({inputs:{x:a},backend:n});return{dataId:e.dataId,shape:e.shape,dtype:s}}if("int32"===s)return int(a,n);if("bool"===s){const e=n.makeTensorInfo([],"bool",getTypedArrayFromDType("bool",1)),t=notEqual({inputs:{a,b:e},backend:n});return n.disposeIntermediateTensorInfo(e),t}throw new Error(`Error in Cast: failed to cast ${a.dtype} to ${s}`)}const castConfig={kernelName:Cast,backendName:"webgl",kernelFunc:cast},CEIL="return ceil(x);",ceil=unaryKernelFunc({opSnippet:CEIL,packedOpSnippet:CEIL,cpuKernelImpl:ceilImplCPU}),ceilConfig={kernelName:Ceil,backendName:"webgl",kernelFunc:ceil};class ClipProgram{constructor(e){this.variableNames=["A"],this.customUniforms=[{name:"minVal",type:"float"},{name:"maxVal",type:"float"}],this.outputShape=e,this.userCode="\n\n      void main() {\n        float value = getAAtOutCoords();\n        if (isnan(value)) {\n          setOutput(value);\n          return;\n        }\n\n        setOutput(clamp(value, minVal, maxVal));\n      }\n    "}}class ClipPackedProgram{constructor(e){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,this.customUniforms=[{name:"minVal",type:"float"},{name:"maxVal",type:"float"}],this.outputShape=e,this.userCode="\n      void main() {\n        vec4 value = getAAtOutCoords();\n\n        if (any(isnan(value))) {\n          setOutput(value);\n          return;\n        }\n\n        setOutput(clamp(value, vec4(minVal), vec4(maxVal)));\n      }\n    "}}function clipByValue(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{clipValueMin:s,clipValueMax:o}=r;let i;return i=env().getBool("WEBGL_PACK_CLIP")?new ClipPackedProgram(a.shape):new ClipProgram(a.shape),n.runWebGLProgram(i,[a],a.dtype,[[s],[o]])}const clipByValueConfig={kernelName:ClipByValue,backendName:"webgl",kernelFunc:clipByValue};class ComplexAbsProgram{constructor(e){this.variableNames=["real","imag"],this.outputShape=e,this.userCode="\n      void main() {\n        float re = abs(getRealAtOutCoords());\n        float im = abs(getImagAtOutCoords());\n        float mx = max(re, im);\n\n        // sadly the length function in glsl is not underflow-safe\n        // (at least not on Intel GPUs). So the safe solution is\n        // to ensure underflow-safety in all cases.\n        setOutput(\n          mx == 0.0 ? 0.0 : mx * length(vec2(1, min(re, im)/mx))\n        );\n      }\n    "}}function makeComplexComponentTensorInfo(e,t){return{dataId:t.dataId,dtype:t.dtype,shape:e.shape}}function complexAbs(e){const{inputs:t,backend:n}=e,{x:r}=t,a=n.texData.get(r.dataId),s=new ComplexAbsProgram(r.shape),o=[makeComplexComponentTensorInfo(r,a.complexTensorInfos.real),makeComplexComponentTensorInfo(r,a.complexTensorInfos.imag)];return n.runWebGLProgram(s,o,o[0].dtype)}const complexAbsConfig={kernelName:ComplexAbs,backendName:"webgl",kernelFunc:complexAbs};class ConcatProgram{constructor(e){this.outputShape=[],this.outputShape=computeOutShape$1(e,1),this.variableNames=e.map((e,t)=>`T${t}`);const t=new Array(e.length-1);t[0]=e[0][1];for(let n=1;n<t.length;n++)t[n]=t[n-1]+e[n][1];const n=[`if (yC < ${t[0]}) setOutput(getT0(yR, yC));`];for(let e=1;e<t.length;e++)n.push(`else if (yC < ${t[e]}) setOutput(getT${e}(yR, yC-${t[e-1]}));`);n.push(`else setOutput(getT${t.length}(yR, yC-${t[t.length-1]}));`),this.userCode=`\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int yR = coords.x;\n        int yC = coords.y;\n\n        ${n.join("\n        ")}\n      }\n    `}}class ConcatPackedProgram{constructor(e,t){this.packedInputs=!0,this.packedOutput=!0,this.outputShape=[],this.outputShape=computeOutShape$1(e,t);const n=this.outputShape,r=n.length,a=getCoordsDataType(r),s=getChannels("coords",r),o=["x","y","z","w","u","v"].slice(0,r);this.variableNames=e.map((e,t)=>`T${t}`);const i=new Array(e.length-1);i[0]=e[0][t];for(let n=1;n<i.length;n++)i[n]=i[n-1]+e[n][t];const l=o[t],u=o.slice(-2),c=o.join();let p=`if (${l} < ${i[0]}) {\n        return getChannel(\n            getT0(${c}), vec2(${u.join()}));\n        }`;for(let e=1;e<i.length;e++){const t=i[e-1];p+=`\n        if (${l} < ${i[e]}  && ${l} >= ${i[e-1]}) {\n          return getChannel(\n            getT${e}(${shiftedChannels(o,l,t)}),\n            vec2(${shiftedChannels(u,l,t)}));\n        }`}const d=i[i.length-1];p+=`\n        return getChannel(\n          getT${i.length}(${shiftedChannels(o,l,d)}),\n          vec2(${shiftedChannels(u,l,d)}));`,this.userCode=`\n      float getValue(${o.map(e=>"int "+e)}) {\n        ${p}\n      }\n\n      void main() {\n        ${a} coords = getOutputCoords();\n        vec4 result = vec4(getValue(${s}), 0., 0., 0.);\n\n        ${s[r-1]} = ${s[r-1]} + 1;\n        if (${s[r-1]} < ${n[r-1]}) {\n          result.g = getValue(${s});\n        }\n\n        ${s[r-2]} = ${s[r-2]} + 1;\n        if (${s[r-2]} < ${n[r-2]}) {\n          result.a = getValue(${s});\n        }\n\n        ${s[r-1]} = ${s[r-1]} - 1;\n        if (${s[r-2]} < ${n[r-2]} &&\n            ${s[r-1]} < ${n[r-1]}) {\n          result.b = getValue(${s});\n        }\n        setOutput(result);\n      }\n    `}}function shiftedChannels(e,t,n){const r=e.indexOf(t);return e.map((e,t)=>t===r?`${e} - ${n}`:e).join()}function imag(e){const{inputs:t,backend:n}=e,{input:r}=t;return identity({inputs:{x:n.texData.get(r.dataId).complexTensorInfos.imag},backend:n})}const imagConfig={kernelName:Imag,backendName:"webgl",kernelFunc:imag};function concatImpl(e,t,n){const r=e[0].dtype;if("complex64"===r){const r=e.map(e=>real({inputs:{input:e},backend:n})),a=e.map(e=>imag({inputs:{input:e},backend:n})),s=concatImpl(r,t,n),o=concatImpl(a,t,n),i=complex({inputs:{real:s,imag:o},backend:n});return r.forEach(e=>n.disposeIntermediateTensorInfo(e)),a.forEach(e=>n.disposeIntermediateTensorInfo(e)),n.disposeIntermediateTensorInfo(s),n.disposeIntermediateTensorInfo(o),i}let a=n.shouldExecuteOnCPU(e);if("string"===r&&(a=!0),a){const a=e.map(e=>{const r=sizeFromShape(e.shape.slice(t));return reshape({inputs:{x:e},backend:n,attrs:{shape:[-1,r]}})}),s=a.map(e=>({vals:n.readSync(e.dataId),shape:e.shape})),o=computeOutShape$1(a.map(e=>e.shape),1),i=concatImplCPU(s,o,r,1===a[0].shape[0]),l=computeOutShape$1(e.map(e=>e.shape),t),u=n.makeTensorInfo(l,r,i);return a.forEach(e=>n.disposeIntermediateTensorInfo(e)),u}if(e.length>env().getNumber("WEBGL_MAX_TEXTURES_IN_SHADER")){const r=Math.floor(e.length/2),a=concatImpl(e.slice(0,r),t,n),s=concatImpl(e.slice(r),t,n),o=concatImpl([a,s],t,n);return n.disposeIntermediateTensorInfo(a),n.disposeIntermediateTensorInfo(s),o}if(env().getBool("WEBGL_PACK_ARRAY_OPERATIONS")&&e[0].shape.length>1){const a=new ConcatPackedProgram(e.map(e=>e.shape),t);return n.runWebGLProgram(a,e,r)}const{tensors2D:s,outShape:o}=computeTensors2D(e,t,n),i=new ConcatProgram(s.map(e=>e.shape)),l=n.runWebGLProgram(i,s,r);s.forEach(e=>n.disposeIntermediateTensorInfo(e));const u=reshape({inputs:{x:l},attrs:{shape:o},backend:n});return n.disposeIntermediateTensorInfo(l),u}function computeTensors2D(e,t,n){const r=computeOutShape$1(e.map(e=>e.shape),t);return{tensors2D:e.map(e=>reshape({inputs:{x:e},attrs:{shape:[-1,sizeFromShape(e.shape.slice(t))]},backend:n})),outShape:r}}function concat(e){const{inputs:t,backend:n,attrs:r}=e,{axis:a}=r,s=parseAxisParam(a,t[0].shape)[0],o=computeOutShape$1(t.map(e=>e.shape),s);if(0===sizeFromShape(o))return n.makeTensorInfo(o,t[0].dtype,[]);const i=t.filter(e=>sizeFromShape(e.shape)>0);return 1===i.length?identity({inputs:{x:i[0]},backend:n}):(assertParamsConsistent(i.map(e=>e.shape),s),concatImpl(i,s,n))}const concatConfig={kernelName:Concat,backendName:"webgl",kernelFunc:concat};class Conv2DProgram{constructor(e,t=!1,n=null,r=!1,a=!1){this.variableNames=["x","W"],this.outputShape=e.outShape;const s=e.padInfo.top,o=e.padInfo.left,i=e.strideHeight,l=e.strideWidth,u=e.dilationHeight,c=e.dilationWidth,p=e.filterHeight,d=e.filterWidth,h=4*Math.floor(e.inChannels/4),m=e.inChannels%4,f="channelsLast"===e.dataFormat,g=f?1:2,$=f?2:3,y=f?3:1;let b="",x="";n&&(b=r?`float activation(float a) {\n          float b = getPreluActivationWeightsAtOutCoords();\n          ${n}\n        }`:a?`float activation(float a) {\n          float b = getLeakyreluAlphaAtOutCoords();\n          ${n}\n        }`:`\n          float activation(float x) {\n            ${n}\n          }\n        `,x="result = activation(result);");const v=t?"result += getBiasAtOutCoords();":"";t&&this.variableNames.push("bias"),r&&this.variableNames.push("preluActivationWeights"),a&&this.variableNames.push("leakyreluAlpha"),this.userCode=`\n      ${b}\n\n      const ivec2 strides = ivec2(${i}, ${l});\n      const ivec2 pads = ivec2(${s}, ${o});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d2 = coords[${y}];\n\n        ivec2 xRCCorner =\n            ivec2(coords[${g}], coords[${$}]) * strides - pads;\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        // Convolve x(?, ?, d1) with w(:, :, d1, d2) to get y(yR, yC, d2).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ${p}; wR++) {\n          int xR = xRCorner + wR * ${u};\n\n          if (xR < 0 || xR >= ${e.inHeight}) {\n            continue;\n          }\n\n          for (int wC = 0; wC < ${d}; wC++) {\n            int xC = xCCorner + wC * ${c};\n\n            if (xC < 0 || xC >= ${e.inWidth}) {\n              continue;\n            }\n\n            for (int d1 = 0; d1 < ${h}; d1 += 4) {\n              vec4 wValues = vec4(\n                getW(wR, wC, d1, d2),\n                getW(wR, wC, d1 + 1, d2),\n                getW(wR, wC, d1 + 2, d2),\n                getW(wR, wC, d1 + 3, d2)\n              );\n\n              if (${f}) {\n                vec4 xValues = vec4(\n                  getX(batch, xR, xC, d1),\n                  getX(batch, xR, xC, d1 + 1),\n                  getX(batch, xR, xC, d1 + 2),\n                  getX(batch, xR, xC, d1 + 3)\n                );\n                dotProd += dot(xValues, wValues);\n              } else {\n                vec4 xValues = vec4(\n                  getX(batch, d1, xR, xC),\n                  getX(batch, d1 + 1, xR, xC),\n                  getX(batch, d1 + 2, xR, xC),\n                  getX(batch, d1 + 3, xR, xC)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n            }\n\n            if (${1===m}) {\n\n              if (${f}) {\n                dotProd +=\n                    getX(batch, xR, xC, ${h}) *\n                    getW(wR, wC, ${h}, d2);\n              } else {\n                dotProd +=\n                    getX(batch, ${h}, xR, xC) *\n                    getW(wR, wC, ${h}, d2);\n              }\n\n            } else if (${2===m}) {\n              vec2 wValues = vec2(\n                getW(wR, wC, ${h}, d2),\n                getW(wR, wC, ${h} + 1, d2)\n              );\n\n              if (${f}) {\n                vec2 xValues = vec2(\n                  getX(batch, xR, xC, ${h}),\n                  getX(batch, xR, xC, ${h} + 1)\n                );\n                dotProd += dot(xValues, wValues);\n              } else {\n                vec2 xValues = vec2(\n                  getX(batch, ${h}, xR, xC),\n                  getX(batch, ${h} + 1, xR, xC)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n\n            } else if (${3===m}) {\n              vec3 wValues = vec3(\n                getW(wR, wC, ${h}, d2),\n                getW(wR, wC, ${h} + 1, d2),\n                getW(wR, wC, ${h} + 2, d2)\n              );\n\n              if (${f}) {\n                vec3 xValues = vec3(\n                  getX(batch, xR, xC, ${h}),\n                  getX(batch, xR, xC, ${h} + 1),\n                  getX(batch, xR, xC, ${h} + 2)\n                );\n                dotProd += dot(xValues, wValues);\n              } else {\n                vec3 xValues = vec3(\n                  getX(batch, ${h}, xR, xC),\n                  getX(batch, ${h} + 1, xR, xC),\n                  getX(batch, ${h} + 2, xR, xC)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n\n            }\n          }\n        }\n\n        float result = dotProd;\n        ${v}\n        ${x}\n        setOutput(result);\n      }\n    `}}class Conv3DProgram{constructor(e){this.variableNames=["x","W"],this.outputShape=e.outShape;const t=e.padInfo.front,n=e.padInfo.top,r=e.padInfo.left,a=e.strideDepth,s=e.strideHeight,o=e.strideWidth,i=e.dilationDepth,l=e.dilationHeight,u=e.dilationWidth,c=e.filterDepth,p=e.filterHeight,d=e.filterWidth,h=4*Math.floor(e.inChannels/4),m=e.inChannels%4;this.userCode=`\n      const ivec3 strides = ivec3(${a}, ${s}, ${o});\n      const ivec3 pads = ivec3(${t}, ${n}, ${r});\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int d2 = coords.u;\n\n        ivec3 xFRCCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\n        int xFCorner = xFRCCorner.x;\n        int xRCorner = xFRCCorner.y;\n        int xCCorner = xFRCCorner.z;\n\n        // Convolve x(?, ?, ?, d1) with w(:, :, :, d1, d2) to get\n        // y(yF, yR, yC, d2). ? = to be determined. : = across all\n        // values in that axis.\n        float dotProd = 0.0;\n        for (int wF = 0; wF < ${c}; wF++) {\n          int xF = xFCorner + wF * ${i};\n\n          if (xF < 0 || xF >= ${e.inDepth}) {\n            continue;\n          }\n\n          for (int wR = 0; wR < ${p}; wR++) {\n            int xR = xRCorner + wR * ${l};\n\n            if (xR < 0 || xR >= ${e.inHeight}) {\n              continue;\n            }\n\n            for (int wC = 0; wC < ${d}; wC++) {\n              int xC = xCCorner + wC * ${u};\n\n              if (xC < 0 || xC >= ${e.inWidth}) {\n                continue;\n              }\n\n              for (int d1 = 0; d1 < ${h}; d1 += 4) {\n                vec4 xValues = vec4(\n                  getX(batch, xF, xR, xC, d1),\n                  getX(batch, xF, xR, xC, d1 + 1),\n                  getX(batch, xF, xR, xC, d1 + 2),\n                  getX(batch, xF, xR, xC, d1 + 3)\n                );\n                vec4 wValues = vec4(\n                  getW(wF, wR, wC, d1, d2),\n                  getW(wF, wR, wC, d1 + 1, d2),\n                  getW(wF, wR, wC, d1 + 2, d2),\n                  getW(wF, wR, wC, d1 + 3, d2)\n                );\n\n                dotProd += dot(xValues, wValues);\n              }\n\n              if (${1===m}) {\n                dotProd +=\n                  getX(batch, xF, xR, xC, ${h}) *\n                  getW(wF, wR, wC, ${h}, d2);\n              } else if (${2===m}) {\n                vec2 xValues = vec2(\n                  getX(batch, xF, xR, xC, ${h}),\n                  getX(batch, xF, xR, xC, ${h} + 1)\n                );\n                vec2 wValues = vec2(\n                  getW(wF, wR, wC, ${h}, d2),\n                  getW(wF, wR, wC, ${h} + 1, d2)\n                );\n                dotProd += dot(xValues, wValues);\n              } else if (${3===m}) {\n                vec3 xValues = vec3(\n                  getX(batch, xF, xR, xC, ${h}),\n                  getX(batch, xF, xR, xC, ${h} + 1),\n                  getX(batch, xF, xR, xC, ${h} + 2)\n                );\n                vec3 wValues = vec3(\n                  getW(wF, wR, wC, ${h}, d2),\n                  getW(wF, wR, wC, ${h} + 1, d2),\n                  getW(wF, wR, wC, ${h} + 2, d2)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class Im2ColPackedProgram{constructor(e,t,n){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=e;const{filterWidth:r,inChannels:a,strideWidth:s,strideHeight:o,padInfo:i,outWidth:l,dilationWidth:u,dilationHeight:c,dataFormat:p}=n,{left:d,top:h}=i,m=a*r,f=getGlslDifferences(),g="channelsLast"===p,$=g?0:1,y=g?1:2;let b="";for(let n=0;n<=1;n++)for(let r=0;r<=1;r++)b+=`\n          blockIndex = rc.y + ${r};\n          pos = rc.x + ${n};\n\n          if(blockIndex < ${e[1]} && pos < ${e[0]}) {\n            offsetY = int(blockIndex / (${l})) * ${o} - ${h};\n            d0 = offsetY + ${c} * (pos / ${m});\n\n            if(d0 < ${t[$]} && d0 >= 0) {\n\n              offsetX = int(mod(float(blockIndex), ${l}.) * ${s}. - ${d}.);\n              d1 = offsetX + ${u} * (int(mod(float(pos), ${m}.) / ${a}.));\n\n              if(d1 < ${t[y]} && d1 >= 0) {\n\n                ch = int(mod(float(pos), ${a}.));\n\n                if (${g}) {\n                  innerDims = vec2(d1, ch);\n                  result[${2*n+r}] = getChannel(\n                    getA(d0, int(innerDims.x),\n                    int(innerDims.y)), innerDims);\n                } else {\n                  innerDims = vec2(d0, d1);\n                  result[${2*n+r}] = getChannel(\n                    getA(ch, int(innerDims.x),\n                    int(innerDims.y)), innerDims);\n                }\n              }\n            }\n          }\n        `;this.userCode=`\n      void main() {\n        ivec2 rc = getOutputCoords();\n\n        vec4 result = vec4(0);\n\n        int blockIndex, pos, offsetY, d0, offsetX, d1, ch;\n        vec2 innerDims;\n\n        ${b}\n\n        ${f.output} = result;\n      }\n    `}}function conv2dByMatMul({x:e,filter:t,convInfo:n,backend:r,bias:a=null,preluActivationWeights:s=null,leakyreluAlpha:o=0,activation:i=null}){const l=e.shape,u=r.texData.get(e.dataId),c="channelsLast"===n.dataFormat;let p;const d=[],h=l[2]%2!=0&&!!u.isPacked;if((1!=l[0]*l[1]*l[2]&&1!==n.outChannels||!(n.inChannels>MATMUL_SHARED_DIM_THRESHOLD))&&env().getBool("WEBGL_LAZILY_UNPACK")&&env().getBool("WEBGL_PACK_BINARY_OPERATIONS")&&h){const h={dataId:e.dataId,shape:[1,c?l[0]*l[1]*(l[2]+1):l[0]*l[2]*(l[3]+1),n.inChannels],dtype:e.dtype},m=u.shape;u.shape=u.shape.slice(),u.shape[u.shape.length-2]++,assert$4(isReshapeFree(u.shape,h.shape),()=>`packed reshape ${u.shape} to ${h.shape} isn't free`);const f=reshape({inputs:{x:t},backend:r,attrs:{shape:[1,n.inChannels,n.outChannels]}});d.push(f);const g=batchMatMulImpl({a:h,b:f,backend:r,transposeA:!1,transposeB:!1,bias:a,activation:i,preluActivationWeights:s,leakyreluAlpha:o}),$=r.texData.get(g.dataId);assert$4($.isPacked,()=>"batchMatMul result is expected to be packed"),u.shape=m,$.shape=n.outShape,p=identity({inputs:{x:g},backend:r}),p.shape=n.outShape,d.push(g)}else{const u=reshape({inputs:{x:e},backend:r,attrs:{shape:[1,c?l[0]*l[1]*l[2]:l[0]*l[2]*l[3],n.inChannels]}}),h=reshape({inputs:{x:t},backend:r,attrs:{shape:[1,n.inChannels,n.outChannels]}}),m=batchMatMulImpl({a:u,b:h,transposeA:!1,transposeB:!1,backend:r,bias:a,activation:i,preluActivationWeights:s,leakyreluAlpha:o});p=reshape({inputs:{x:m},backend:r,attrs:{shape:n.outShape}}),d.push(u),d.push(h),d.push(m)}for(const e of d)r.disposeIntermediateTensorInfo(e);return p}function conv2dWithIm2Row({x:e,filter:t,convInfo:n,backend:r,bias:a=null,preluActivationWeights:s=null,leakyreluAlpha:o=0,activation:i=null}){const{filterWidth:l,filterHeight:u,inChannels:c,outWidth:p,outHeight:d,dataFormat:h}=n,m="channelsLast"===h,f=l*u*c,g=d*p,$=[f,g],y=[],b=reshape({inputs:{x:e},backend:r,attrs:{shape:e.shape.slice(1)}}),x=reshape({inputs:{x:t},backend:r,attrs:{shape:[1,f,sizeFromShape(t.shape)/f]}});y.push(b),y.push(x);const v=new Im2ColPackedProgram($,b.shape,n),I=r.runWebGLProgram(v,[b],"float32"),C=reshape({inputs:{x:I},backend:r,attrs:{shape:[1,$[0],$[1]]}});y.push(I),y.push(C);const S=null!=a,k=null!=s,T="leakyrelu"===i,N=i?mapActivationToShaderProgram(i,!0):null,w=new MatMulPackedProgram(C.shape,x.shape,[1,g,n.outChannels],!0,!1,S,N,k,T),E=[C,x];if(a&&E.push(a),k&&E.push(s),T){const e=r.makeTensorInfo([],"float32",createScalarValue(o,"float32"));E.push(e),y.push(e)}const A=r.runWebGLProgram(w,E,"float32"),D=reshape({inputs:{x:A},backend:r,attrs:{shape:m?[1,d,p,n.outChannels]:[1,n.outChannels,d,p]}});y.push(A);for(const e of y)r.disposeIntermediateTensorInfo(e);return D}function conv2d(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,filter:s}=t,{strides:o,pad:i,dataFormat:l,dilations:u,dimRoundingMode:c}=r,p=convertConv2DDataFormat(l),d=computeConv2DInfo(a.shape,s.shape,o,u,i,c,!1,p);let h;if(1!==d.filterHeight||1!==d.filterWidth||1!==d.dilationHeight||1!==d.dilationWidth||1!==d.strideHeight||1!==d.strideWidth||"SAME"!==d.padInfo.type&&"VALID"!==d.padInfo.type)if(env().getBool("WEBGL_CONV_IM2COL")&&1===a.shape[0])h=conv2dWithIm2Row({x:a,filter:s,convInfo:d,backend:n});else{const e=new Conv2DProgram(d);h=n.runWebGLProgram(e,[a,s],"float32")}else h=conv2dByMatMul({x:a,filter:s,convInfo:d,backend:n});const m=reshape({inputs:{x:h},backend:n,attrs:{shape:d.outShape}});return n.disposeIntermediateTensorInfo(h),m}const conv2DConfig={kernelName:Conv2D$1,backendName:"webgl",kernelFunc:conv2d};class Conv2DDerFilterProgram{constructor(e){this.variableNames=["x","dy"],this.outputShape=e.filterShape,this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int wR = coords.x;\n        int wC = coords.y;\n        int d1 = coords.z;\n        int d2 = coords.w;\n\n        // Convolve x(?, ?, d1) with dy(:, :, d2) to get dw(wR, wC, d1, d2).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n\n        for (int b = 0; b < ${e.batchSize}; b++) {\n          for (int yR = 0; yR < ${e.outHeight}; yR++) {\n            int xR = wR + yR * ${e.strideHeight} - ${e.padInfo.top};\n\n            if (xR < 0 || xR >= ${e.inHeight}) {\n              continue;\n            }\n\n            for (int yC = 0; yC < ${e.outWidth}; yC++) {\n              int xC = wC + yC * ${e.strideWidth} - ${e.padInfo.left};\n\n              if (xC < 0 || xC >= ${e.inWidth}) {\n                continue;\n              }\n\n              if (${"channelsLast"===e.dataFormat}) {\n                float dyValue = getDy(b, yR, yC, d2);\n                float xValue = getX(b, xR, xC, d1);\n                dotProd += (xValue * dyValue);\n              } else {\n                float dyValue = getDy(b, d2, yR, yC);\n                float xValue = getX(b, d1, xR, xC);\n                dotProd += (xValue * dyValue);\n              }\n\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class Conv2DDerInputProgram{constructor(e){this.variableNames=["dy","W"],this.outputShape=e.inShape;const t=e.filterHeight,n=e.filterWidth,r="channelsLast"===e.dataFormat;this.userCode=`\n      const ivec2 pads = ivec2(${t-1-e.padInfo.top}, ${n-1-e.padInfo.left});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d1 = coords[${r?3:1}];\n\n        ivec2 dyCorner = ivec2(coords[${r?1:2}], coords[${r?2:3}]) - pads;\n        int dyRCorner = dyCorner.x;\n        int dyCCorner = dyCorner.y;\n\n        // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ${t}; wR++) {\n          float dyR = float(dyRCorner + wR) / ${e.strideHeight}.0;\n\n          if (dyR < 0.0 || dyR >= ${e.outHeight}.0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          int wRPerm = ${t} - 1 - wR;\n\n          for (int wC = 0; wC < ${n}; wC++) {\n            float dyC = float(dyCCorner + wC) / ${e.strideWidth}.0;\n\n            if (dyC < 0.0 || dyC >= ${e.outWidth}.0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            int wCPerm = ${n} - 1 - wC;\n\n            for (int d2 = 0; d2 < ${e.outChannels}; d2++) {\n\n              if (${r}) {\n                float xValue = getDy(batch, idyR, idyC, d2);\n                float wValue = getW(wRPerm, wCPerm, d1, d2);\n                dotProd += xValue * wValue;\n              } else {\n                float xValue = getDy(batch, d2, idyR, idyC);\n                float wValue = getW(wRPerm, wCPerm, d1, d2);\n                dotProd += xValue * wValue;\n              }\n\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class Conv3DDerFilterProgram{constructor(e){this.variableNames=["x","dy"],this.outputShape=e.filterShape,this.userCode=`\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int wF = coords.x;\n        int wR = coords.y;\n        int wC = coords.z;\n        int d1 = coords.w;\n        int d2 = coords.u;\n\n        float dotProd = 0.0;\n\n        for (int b = 0; b < ${e.batchSize}; b++) {\n          for (int yF = 0; yF < ${e.outDepth}; yF++) {\n            int xF = wF + yF * ${e.strideDepth} - ${e.padInfo.front};\n\n            if (xF < 0 || xF >= ${e.inDepth}) {\n              continue;\n            }\n\n            for (int yR = 0; yR < ${e.outHeight}; yR++) {\n              int xR = wR + yR * ${e.strideHeight} - ${e.padInfo.top};\n\n              if (xR < 0 || xR >= ${e.inHeight}) {\n                continue;\n              }\n\n              for (int yC = 0; yC < ${e.outWidth}; yC++) {\n                int xC = wC + yC * ${e.strideWidth} - ${e.padInfo.left};\n\n                if (xC < 0 || xC >= ${e.inWidth}) {\n                  continue;\n                }\n\n                float dyValue = getDy(b, yF, yR, yC, d2);\n                float xValue = getX(b, xF, xR, xC, d1);\n                dotProd += (xValue * dyValue);\n              }\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class Conv3DDerInputProgram{constructor(e){this.variableNames=["dy","W"],this.outputShape=e.inShape;const t=e.filterDepth,n=e.filterHeight,r=e.filterWidth;this.userCode=`\n      const ivec3 pads = ivec3(${t-1-e.padInfo.front}, ${n-1-e.padInfo.top}, ${r-1-e.padInfo.left});\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int d1 = coords.u;\n\n\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\n        int dyFCorner = dyCorner.x;\n        int dyRCorner = dyCorner.y;\n        int dyCCorner = dyCorner.z;\n\n        float dotProd = 0.0;\n        for (int wF = 0; wF < ${t}; wF++) {\n          float dyF = float(dyFCorner + wF) / ${e.strideDepth}.0;\n\n          if (dyF < 0.0 || dyF >= ${e.outDepth}.0 || fract(dyF) > 0.0) {\n            continue;\n          }\n          int idyF = int(dyF);\n\n          int wFPerm = ${t} - 1 - wF;\n\n          for (int wR = 0; wR < ${n}; wR++) {\n            float dyR = float(dyRCorner + wR) / ${e.strideHeight}.0;\n\n            if (dyR < 0.0 || dyR >= ${e.outHeight}.0 ||\n              fract(dyR) > 0.0) {\n              continue;\n            }\n            int idyR = int(dyR);\n\n            int wRPerm = ${n} - 1 - wR;\n\n            for (int wC = 0; wC < ${r}; wC++) {\n              float dyC = float(dyCCorner + wC) / ${e.strideWidth}.0;\n\n              if (dyC < 0.0 || dyC >= ${e.outWidth}.0 ||\n                  fract(dyC) > 0.0) {\n                continue;\n              }\n              int idyC = int(dyC);\n\n              int wCPerm = ${r} - 1 - wC;\n\n              for (int d2 = 0; d2 < ${e.outChannels}; d2++) {\n                float xValue = getDy(batch, idyF, idyR, idyC, d2);\n                float wValue = getW(wFPerm, wRPerm, wCPerm, d1, d2);\n                dotProd += xValue * wValue;\n              }\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}function conv2DBackpropFilter(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,dy:s}=t,{strides:o,pad:i,dataFormat:l,dimRoundingMode:u,filterShape:c}=r,p=convertConv2DDataFormat(l),d=computeConv2DInfo(a.shape,c,o,1,i,u,!1,p),h=new Conv2DDerFilterProgram(d);return n.runWebGLProgram(h,[a,s],"float32")}const conv2DBackpropFilterConfig={kernelName:Conv2DBackpropFilter,backendName:"webgl",kernelFunc:conv2DBackpropFilter};function conv2DBackpropInput(e){const{inputs:t,backend:n,attrs:r}=e,{dy:a,filter:s}=t,{inputShape:o,strides:i,pad:l,dataFormat:u,dimRoundingMode:c}=r,p=convertConv2DDataFormat(u),d=computeConv2DInfo(o,s.shape,i,1,l,c,!1,p),h=new Conv2DDerInputProgram(d);return n.runWebGLProgram(h,[a,s],"float32")}const conv2DBackpropInputConfig={kernelName:Conv2DBackpropInput,backendName:"webgl",kernelFunc:conv2DBackpropInput};function conv3D(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,filter:s}=t,{strides:o,pad:i,dilations:l}=r,u=computeConv3DInfo(a.shape,s.shape,o,l,i),c=new Conv3DProgram(u);return n.runWebGLProgram(c,[a,s],"float32")}const conv3DConfig={kernelName:Conv3D$1,backendName:"webgl",kernelFunc:conv3D};function conv3DBackpropFilterV2(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,dy:s}=t,{strides:o,pad:i,filterShape:l}=r,u=computeConv3DInfo(a.shape,l,o,1,i),c=new Conv3DDerFilterProgram(u);return n.runWebGLProgram(c,[a,s],"float32")}const conv3DBackpropFilterV2Config={kernelName:Conv3DBackpropFilterV2,backendName:"webgl",kernelFunc:conv3DBackpropFilterV2};function conv3DBackpropInput(e){const{inputs:t,backend:n,attrs:r}=e,{dy:a,filter:s}=t,{pad:o,strides:i,inputShape:l}=r,u=computeConv3DInfo(l,s.shape,i,1,o),c=new Conv3DDerInputProgram(u);return n.runWebGLProgram(c,[a,s],"float32")}const conv3DBackpropInputConfig={kernelName:Conv3DBackpropInputV2,backendName:"webgl",kernelFunc:conv3DBackpropInput},COS=CHECK_NAN_SNIPPET_UNARY+"\n  return cos(x);\n",cos=unaryKernelFunc({opSnippet:COS}),cosConfig={kernelName:Cos,backendName:"webgl",kernelFunc:cos},COSH="\n  float e2x = exp(-x);\n  return (e2x + 1.0 / e2x) / 2.0;\n",cosh=unaryKernelFunc({opSnippet:COSH}),coshConfig={kernelName:Cosh,backendName:"webgl",kernelFunc:cosh};class CropAndResizeProgram{constructor(e,t,n,r,a){this.variableNames=["Image","Boxes","BoxInd"],this.outputShape=[];const[s,o,i,l]=e,[u]=t,[c,p]=n;this.outputShape=[u,c,p,l];const d="bilinear"===r?1:0,[h,m]=[o-1+".0",i-1+".0"],[f,g,$]=c>1?[""+(o-1)/(c-1),"(y2-y1) * height_ratio",`y1*${h} + float(y)*(height_scale)`]:["0.0","0.0",`0.5 * (y1+y2) * ${h}`],[y,b,x]=p>1?[""+(i-1)/(p-1),"(x2-x1) * width_ratio",`x1*${m} + float(x)*(width_scale)`]:["0.0","0.0",`0.5 * (x1+x2) * ${m}`];this.userCode=`\n      const float height_ratio = float(${f});\n      const float width_ratio = float(${y});\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int y = coords[1];\n        int x = coords[2];\n        int d = coords[3];\n\n        // get box vals\n        float y1 = getBoxes(b,0);\n        float x1 = getBoxes(b,1);\n        float y2 = getBoxes(b,2);\n        float x2 = getBoxes(b,3);\n\n        // get image in batch index\n        int bInd = round(getBoxInd(b));\n        if(bInd < 0 || bInd >= ${s}) {\n          return;\n        }\n\n        float height_scale = ${g};\n        float width_scale = ${b};\n\n        float in_y = ${$};\n        if( in_y < 0.0 || in_y > ${h} ) {\n          setOutput(float(${a}));\n          return;\n        }\n        float in_x = ${x};\n        if( in_x < 0.0 || in_x > ${m} ) {\n          setOutput(float(${a}));\n          return;\n        }\n\n        vec2 sourceFracIndexCR = vec2(in_x,in_y);\n        if(${d} == 1) {\n          // Compute the four integer indices.\n          ivec2 sourceFloorCR = ivec2(sourceFracIndexCR);\n          ivec2 sourceCeilCR = ivec2(ceil(sourceFracIndexCR));\n\n          float topLeft = getImage(b, sourceFloorCR.y, sourceFloorCR.x, d);\n          float bottomLeft = getImage(b, sourceCeilCR.y, sourceFloorCR.x, d);\n          float topRight = getImage(b, sourceFloorCR.y, sourceCeilCR.x, d);\n          float bottomRight = getImage(b, sourceCeilCR.y, sourceCeilCR.x, d);\n\n          vec2 fracCR = sourceFracIndexCR - vec2(sourceFloorCR);\n\n          float top = topLeft + (topRight - topLeft) * fracCR.x;\n          float bottom = bottomLeft + (bottomRight - bottomLeft) * fracCR.x;\n          float newValue = top + (bottom - top) * fracCR.y;\n          setOutput(newValue);\n        } else {\n          // Compute the coordinators of nearest neighbor point.\n          ivec2 sourceNearestCR = ivec2(floor(\n            sourceFracIndexCR + vec2(0.5,0.5)));\n          float newValue = getImage(b, sourceNearestCR.y, sourceNearestCR.x, d);\n          setOutput(newValue);\n        }\n      }\n    `}}const cropAndResize=e=>{const{inputs:t,backend:n,attrs:r}=e,{image:a,boxes:s,boxInd:o}=t,{cropSize:i,method:l,extrapolationValue:u}=r,c=new CropAndResizeProgram(a.shape,s.shape,i,l,u);return n.runWebGLProgram(c,[a,s,o],"float32")},cropAndResizeConfig={kernelName:CropAndResize,backendName:"webgl",kernelFunc:cropAndResize};class CumSumProgram{constructor(e,t,n){this.variableNames=["x"],this.customUniforms=[{name:"index",type:"float"}],this.outputShape=e;const r=e.length,a=t?"0.0":`getX(${getCoords(r,"coords")})`,s=e[e.length-1];let o="",i="";t?(o=n?"end != "+(s-1):"end != 0",i=n?"end + 1":"end - 1"):(o=n?`end + pow2 < ${s}`:"end >= pow2",i=n?"end + pow2":"end - pow2"),this.userCode=`\n      void main() {\n        ${getCoordsDataType(r)} coords = getOutputCoords();\n        int end = ${getFinalCoord(r,"coords")};\n        float val = ${a};\n        int pow2 = int(pow(2.0, index));\n        if (${o}) {\n          int idx = ${i};\n          ${getFinalCoord(r,"coords")} = idx;\n          val += getX(${getCoords(r,"coords")});\n        }\n        setOutput(val);\n      }\n    `}}function getCoords(e,t){if(1===e)return`${t}`;if(2===e)return`${t}.x, ${t}.y`;if(3===e)return`${t}.x, ${t}.y, ${t}.z`;if(4===e)return`${t}.x, ${t}.y, ${t}.z, ${t}.w`;throw Error(`Cumulative sum for rank ${e} is not yet supported`)}function getFinalCoord(e,t){if(1===e)return`${t}`;if(2===e)return`${t}.y`;if(3===e)return`${t}.z`;if(4===e)return`${t}.w`;throw Error(`Cumulative sum for rank ${e} is not yet supported`)}function cumsum(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{axis:s,exclusive:o,reverse:i}=r,l=a.shape.length,u=getAxesPermutation([s],l);let c=a;null!=u&&(c=transpose({inputs:{x:a},backend:n,attrs:{perm:u}}));const p=getInnerMostAxes(1,l)[0];if(p!==l-1)throw new Error(`WebGL cumsum shader expects an inner-most axis=${a.shape.length-1} but got axis=${s}`);const d=c.shape[p];let h=identity({inputs:{x:c},backend:n});for(let e=0;e<=Math.ceil(Math.log2(d))-1;e++){const t=new CumSumProgram(c.shape,!1,i),r=h;h=n.runWebGLProgram(t,[h],h.dtype,[[e]]),n.disposeIntermediateTensorInfo(r)}if(o){const e=new CumSumProgram(c.shape,o,i),t=h;h=n.runWebGLProgram(e,[h],h.dtype),n.disposeIntermediateTensorInfo(t)}if(null!=u){const e=transpose({inputs:{x:h},backend:n,attrs:{perm:getUndoAxesPermutation(u)}});return n.disposeIntermediateTensorInfo(h),n.disposeIntermediateTensorInfo(c),e}return h}const cumsumConfig={kernelName:Cumsum,backendName:"webgl",kernelFunc:cumsum};function denseBincount(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,weights:s}=t,{size:o,binaryOutput:i}=r;if(1===a.shape.length){const e=n.readSync(a.dataId),t=n.readSync(s.dataId),r=bincountImplCPU(e,t,s.dtype,s.shape,o);return n.makeTensorInfo([o],s.dtype,r)}if(2===a.shape.length){const e=n.bufferSync(a),t=n.bufferSync(s),r=bincountReduceImplCPU(e,t,o,i);return n.makeTensorInfo(r.shape,s.dtype,r.values)}throw new Error(`Error in denseBincount: input must be at most rank 2, but got rank${a.shape.length}.`)}const denseBincountConfig={kernelName:DenseBincount,backendName:"webgl",kernelFunc:denseBincount};class DepthToSpaceProgram{constructor(e,t,n){this.variableNames=["x"],this.outputShape=[],this.outputShape=e,this.blockSize=t,this.dataFormat=n,this.userCode=`\n    void main() {\n      ivec4 coords = getOutputCoords();\n      int b = coords[0];\n      int h = ${this.getHeightCoordString()};\n      int w = ${this.getWidthCoordString()};\n      int d = ${this.getDepthCoordString()};\n\n      int in_h = h / ${t};\n      int offset_h = imod(h, ${t});\n      int in_w = w / ${t};\n      int offset_w = imod(w, ${t});\n      int offset_d = (offset_h * ${t} + offset_w) *\n        ${this.getOutputDepthSize()};\n      int in_d = d + offset_d;\n\n      float result = ${this.getInputSamplingString()};\n      setOutput(result);\n    }\n  `}getHeightCoordString(){return"NHWC"===this.dataFormat?"coords[1]":"coords[2]"}getWidthCoordString(){return"NHWC"===this.dataFormat?"coords[2]":"coords[3]"}getDepthCoordString(){return"NHWC"===this.dataFormat?"coords[3]":"coords[1]"}getOutputDepthSize(){return"NHWC"===this.dataFormat?this.outputShape[3]:this.outputShape[1]}getInputSamplingString(){return"NHWC"===this.dataFormat?"getX(b, in_h, in_w, in_d)":"getX(b, in_d, in_h, in_w)"}}function depthToSpace(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{blockSize:s,dataFormat:o}=r;assert$4(s>1,()=>`blockSize should be > 1 for depthToSpace, but was: ${s}`);const i=a.shape[0],l=("NHWC"===o?a.shape[1]:a.shape[2])*s,u=("NHWC"===o?a.shape[2]:a.shape[3])*s,c=("NHWC"===o?a.shape[3]:a.shape[1])/(s*s),p=new DepthToSpaceProgram("NHWC"===o?[i,l,u,c]:[i,c,l,u],s,o);return n.runWebGLProgram(p,[a],a.dtype)}const depthToSpaceConfig={kernelName:DepthToSpace,backendName:"webgl",kernelFunc:depthToSpace};class DepthwiseConv2DProgram{constructor(e,t=!1,n=null,r=!1,a=!1){this.variableNames=["x","W"],this.outputShape=e.outShape;const s=e.inHeight,o=e.inWidth,i=e.padInfo.top,l=e.padInfo.left,u=e.strideHeight,c=e.strideWidth,p=e.dilationHeight,d=e.dilationWidth,h=e.filterHeight,m=e.filterWidth,f=e.outChannels/e.inChannels;let g="",$="";n&&(g=r?`float activation(float a) {\n          float b = getPreluActivationWeightsAtOutCoords();\n          ${n}\n        }`:a?`float activation(float a) {\n          float b = getLeakyreluAlphaAtOutCoords();\n          ${n}\n        }`:`\n          float activation(float x) {\n            ${n}\n          }\n        `,$="result = activation(result);");const y=t?"result += getBiasAtOutCoords();":"";t&&this.variableNames.push("bias"),r&&this.variableNames.push("preluActivationWeights"),a&&this.variableNames.push("leakyreluAlpha"),this.userCode=`\n      ${g}\n\n      const ivec2 strides = ivec2(${u}, ${c});\n      const ivec2 pads = ivec2(${i}, ${l});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords.x;\n        ivec2 xRCCorner = coords.yz * strides - pads;\n        int d2 = coords.w;\n        int d1 = d2 / ${f};\n        int q = d2 - d1 * ${f};\n\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        // Convolve x(?, ?, d1) with w(:, :, d1, q) to get y(yR, yC, d2).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        // TO DO(dsmilkov): Flatten the two for loops and vec4 the operations.\n        for (int wR = 0; wR < ${h}; wR++) {\n          int xR = xRCorner + wR * ${p};\n\n          if (xR < 0 || xR >= ${s}) {\n            continue;\n          }\n\n          for (int wC = 0; wC < ${m}; wC++) {\n            int xC = xCCorner + wC * ${d};\n\n            if (xC < 0 || xC >= ${o}) {\n              continue;\n            }\n\n            float xVal = getX(batch, xR, xC, d1);\n            float wVal = getW(wR, wC, d1, q);\n            dotProd += xVal * wVal;\n          }\n        }\n\n        float result = dotProd;\n        ${y}\n        ${$}\n        setOutput(result);\n      }\n    `}}class DepthwiseConvPacked2DProgram{constructor(e,t=!1,n=null,r=!1,a=!1){this.variableNames=["x","W"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=e.outShape;const s=e.outChannels/e.inChannels,o=e.inHeight,i=e.inWidth,l=e.padInfo.top,u=e.padInfo.left,c=e.strideHeight,p=e.strideWidth,d=e.dilationHeight,h=e.dilationWidth,m=e.filterHeight,f=e.filterWidth,g=f;let $="\n      int xR; int xC; int xCOffset;\n      vec4 wTexel; vec4 previous; vec4 final;";for(let e=0;e<f;e++)$+=`\n          vec4 xTexelC${2*e};\n          int xTexelC${2*e}Ready;\n          vec4 xTexelC${2*e+1};\n          int xTexelC${2*e+1}Ready;\n          vec4 xC${e};`;for(let e=0;e<m;e++){for(let e=0;e<f;e++)$+=`\n          xTexelC${2*e} = vec4(0.0);\n          xTexelC${2*e}Ready = 0;\n          xTexelC${2*e+1} = vec4(0.0);\n          xTexelC${2*e+1}Ready = 0;\n          xC${e} = vec4(0.0);`;$+=`\n        xR = xRCorner + ${e*d};\n        if (xR >=0 && xR < ${o}) {\n      `;for(let t=0;t<(g+1)/2;t++){const n=2*t,r=n*h;if($+=`\n          xC = xCCorner + ${r};\n          `,1===p){if(n<f&&(u%2==1?($+=`\n                xCOffset = xC + 1;\n                if (xCOffset >= 0 && xCOffset < ${i} && xTexelC${n}Ready == 0) {\n                  xTexelC${n} = getX(batch, xR, xCOffset, d1);\n\n                  // Need to manually clear unused channels in case\n                  // we're reading from recycled texture.\n                  if (xCOffset + 1 >= ${i}) {\n                    xTexelC${n}.zw = vec2(0.0);\n                  }\n                  xTexelC${n}Ready = 1;\n                }\n              `,$+=1===h&&r>0?`\n                xC${n} = vec4(xTexelC${n-2}.zw, xTexelC${n}.xy);\n                `:`\n                  xCOffset = xC + 1 - 2;\n\n                  if (xCOffset >= 0 && xCOffset < ${i}) {\n                    previous = getX(batch, xR, xCOffset, d1);\n\n                    // Need to manually clear unused channels in case\n                    // we're reading from recycled texture.\n                    if (xCOffset + 1 >= ${i}) {\n                      previous.zw = vec2(0.0);\n                    }\n\n                    xC${n} = vec4(previous.zw, xTexelC${n}.xy);\n                  } else {\n                    xC${n} = vec4(0.0, 0.0, xTexelC${n}.xy);\n                  }\n                  `):$+=`\n                if (xC >= 0 && xC < ${i} && xTexelC${n}Ready == 0) {\n                  xTexelC${n} = getX(batch, xR, xC, d1);\n                  if (xC + 1 >= ${i}) {\n                    xTexelC${n}.zw = vec2(0.0);\n                  }\n                  xTexelC${n}Ready = 1;\n                }\n\n                xC${n} = xTexelC${n};\n                `,r+1<f)){const e=u%2==0?nearestLargerEven(h):h;h%2==0&&u%2==1||h%2!=0&&u%2!=1?($+=`\n                  xCOffset = xC + ${u%2} + ${e};\n\n                  if (xCOffset >= 0 && xCOffset < ${i} && xTexelC${n+1}Ready == 0) {\n                    xTexelC${n+1} = getX(batch, xR, xCOffset, d1);\n\n                    // Need to manually clear unused channels in case\n                    // we're reading from recycled texture.\n                    if (xCOffset + 1 >= ${i}) {\n                      xTexelC${n+1}.zw = vec2(0.0);\n                    }\n                    xTexelC${n+1}Ready = 1;\n                  }\n                  `,h>1&&($+=`\n                    xCOffset -= 2;\n                    if (xCOffset >= 0 && xCOffset < ${i} && xTexelC${n}Ready == 0) {\n                      xTexelC${n} = getX(batch, xR, xCOffset, d1);\n                      xTexelC${n}Ready = 1;\n                    }\n                    `),$+=`\n                  xC${n+1} = vec4(xTexelC${n}.zw, xTexelC${n+1}.xy);\n                  `):$+=1===e?`\n                    xC${n+1} = xTexelC${n};\n                    `:`\n                    xCOffset = xC + ${e};\n\n                    if (xCOffset >= 0 && xCOffset < ${i} && xTexelC${n+1}Ready == 0) {\n                      xTexelC${n+1} = getX(batch, xR, xCOffset, d1);\n                      if (xCOffset + 1 >= ${i}) {\n                        xTexelC${n+1}.zw = vec2(0.0);\n                      }\n                      xTexelC${n+1}Ready = 1;\n                    }\n\n                    xC${n+1} = xTexelC${n+1};\n                    `}}else r<f&&(u%2==1?($+=`\n                xCOffset = xC + 1 - ${p};\n                if(xCOffset >= 0 && xCOffset < ${i} && xTexelC${n}Ready == 0) {\n                  xTexelC${n} = getX(batch, xR, xCOffset, d1);\n                  // Need to manually clear unused channels in case\n                  // we're reading from recycled texture.\n                  if (xCOffset + 1 >= ${i}) {\n                    xTexelC${n}.zw = vec2(0.0);\n                  }\n                  xTexelC${n}Ready = 1;\n                }\n\n                if(xC + 1 >= 0 && xC + 1 < ${i} && xTexelC${n+1}Ready == 0) {\n                  xTexelC${n+1} = getX(batch, xR, xC + 1, d1);\n                  // Need to manually clear unused channels in case\n                  // we're reading from recycled texture.\n                  if (xC + 2 >= ${i}) {\n                    xTexelC${n+1}.zw = vec2(0.0);\n                  }\n                  xTexelC${n+1}Ready = 1;\n                }\n\n                xC${n} = vec4(xTexelC${n}.zw, xTexelC${n+1}.zw);\n              `,r+1<f&&($+=`\n                  final = vec4(0.0);\n                  xCOffset = xC + 1 + ${p};\n                  if(xCOffset >= 0 && xCOffset < ${i}) {\n                    final = getX(batch, xR, xCOffset, d1);\n                  }\n                  xC${n+1} = vec4(xTexelC${n+1}.xy, final.xy);\n                `)):($+=`\n                if(xC >= 0 && xC < ${i} && xTexelC${n}Ready == 0) {\n                  xTexelC${n} = getX(batch, xR, xC, d1);\n                  if (xC + 1 >= ${i}) {\n                    xTexelC${n}.zw = vec2(0.0);\n                  }\n                  xTexelC${n}Ready = 1;\n                }\n\n                xCOffset = xC + ${p};\n                if(xCOffset >= 0 && xCOffset < ${i} && xTexelC${n+1}Ready == 0) {\n                  xTexelC${n+1} = getX(batch, xR, xCOffset, d1);\n                  if (xCOffset + 1 >= ${i}) {\n                    xTexelC${n+1}.zw = vec2(0.);\n                  }\n                  xTexelC${n+1}Ready = 1;\n                }\n\n                xC${n} = vec4(\n                  xTexelC${n}.xy, xTexelC${n+1}.xy);\n              `,r+1<f&&($+=`\n                  xC${n+1} = vec4(xTexelC${n}.zw, xTexelC${n+1}.zw);\n                `)));n<f&&($+=`\n            wTexel = getW(${e}, ${r}, d1, q);\n            dotProd += xC${n} * vec4(wTexel.xz, wTexel.xz);\n          `,r+1<f&&($+=`\n              wTexel = getW(${e}, ${r+1}, d1, q);\n              dotProd += xC${n+1} * vec4(wTexel.xz, wTexel.xz);\n            `))}$+="\n        }\n      "}let y="",b="";n&&(y=r?`vec4 activation(vec4 a) {\n          vec4 b = getPreluActivationWeightsAtOutCoords();\n          ${n}\n        }`:a?`vec4 activation(vec4 a) {\n          vec4 b = getLeakyreluAlphaAtOutCoords();\n          ${n}\n        }`:`vec4 activation(vec4 x) {\n          ${n}\n        }`,b="result = activation(result);");const x=t?"result += getBiasAtOutCoords();":"";t&&this.variableNames.push("bias"),r&&this.variableNames.push("preluActivationWeights"),a&&this.variableNames.push("leakyreluAlpha"),this.userCode=`\n      ${y}\n\n      const ivec2 strides = ivec2(${c}, ${p});\n      const ivec2 pads = ivec2(${l}, ${u});\n\n      void main() {\n\n        ivec4 coords = getOutputCoords();\n        int batch = coords.x;\n        ivec2 xRCCorner = coords.yz * strides - pads;\n        int d2 = coords.w;\n        int d1 = d2 / ${s};\n        int q = d2 - d1 * ${s};\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        //intialize dotProd with a small epsilon seems to reduce GPU accuracy loss.\n        vec4 dotProd = vec4(0.000000000000001);\n\n        ${$}\n\n        vec4 result = dotProd - vec4(0.000000000000001);\n        ${x}\n        ${b}\n        setOutput(result);\n      }\n    `}}function depthwiseConv2dNative(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,filter:s}=t,{strides:o,pad:i,dilations:l,dimRoundingMode:u}=r;let c=l;null==c&&(c=[1,1]),assert$4(eitherStridesOrDilationsAreOne(o,c),()=>`Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ${o} and dilations '${c}'`);const p=computeConv2DInfo(a.shape,s.shape,o,c,i,u,!0);let d;return d=env().getBool("WEBGL_PACK_DEPTHWISECONV")&&p.strideWidth<=2&&p.outChannels/p.inChannels==1?new DepthwiseConvPacked2DProgram(p):new DepthwiseConv2DProgram(p),n.runWebGLProgram(d,[a,s],"float32")}const depthwiseConv2dNativeConfig={kernelName:DepthwiseConv2dNative,backendName:"webgl",kernelFunc:depthwiseConv2dNative};class DepthwiseConv2DDerFilterProgram{constructor(e){this.variableNames=["x","dy"],this.outputShape=e.filterShape,this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int wR = coords.x;\n        int wC = coords.y;\n        int d1 = coords.z;\n        int dm = coords.w;\n        int d2 = d1 * ${e.outChannels/e.inChannels} + dm;\n\n        float dotProd = 0.0;\n\n        // TO DO: Vec4 over the batch size\n        for (int b = 0; b < ${e.batchSize}; b++) {\n          for (int yR = 0; yR < ${e.outHeight}; yR++) {\n            int xR = wR + yR * ${e.strideHeight} - ${e.padInfo.top};\n\n            if (xR < 0 || xR >= ${e.inHeight}) {\n              continue;\n            }\n\n            for (int yC = 0; yC < ${e.outWidth}; yC++) {\n              int xC = wC + yC * ${e.strideWidth} - ${e.padInfo.left};\n\n              if (xC < 0 || xC >= ${e.inWidth}) {\n                continue;\n              }\n\n              float dyValue = getDy(b, yR, yC, d2);\n              float xValue = getX(b, xR, xC, d1);\n              dotProd += (xValue * dyValue);\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class DepthwiseConv2DDerInputProgram{constructor(e){this.variableNames=["dy","W"],this.outputShape=e.inShape;const t=e.filterHeight,n=e.filterWidth,r=e.outChannels/e.inChannels;this.userCode=`\n      const ivec2 pads = ivec2(${t-1-e.padInfo.top}, ${n-1-e.padInfo.left});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d1 = coords[3];\n        ivec2 dyCorner = coords.yz - pads;\n        int dyRCorner = dyCorner.x;\n        int dyCCorner = dyCorner.y;\n\n        float dotProd = 0.0;\n\n        for (int wR = 0; wR < ${t}; wR++) {\n          float dyR = float(dyRCorner + wR) / ${e.strideHeight}.0;\n\n          if (dyR < 0.0 || dyR >= ${e.outHeight}.0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          int wRPerm = ${t} - 1 - wR;\n\n          for (int wC = 0; wC < ${n}; wC++) {\n            float dyC = float(dyCCorner + wC) / ${e.strideWidth}.0;\n\n            if (dyC < 0.0 || dyC >= ${e.outWidth}.0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            int wCPerm = ${n} - 1 - wC;\n\n            // TO DO: Vec4 over the channelMul\n            for (int dm = 0; dm < ${r}; dm++) {\n              int d2 = d1 * ${r} + dm;\n              float xValue = getDy(batch, idyR, idyC, d2);\n              float wValue = getW(wRPerm, wCPerm, d1, dm);\n              dotProd += xValue * wValue;\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}function depthwiseConv2dNativeBackpropFilter(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,dy:s}=t,{strides:o,dilations:i,pad:l,dimRoundingMode:u,filterShape:c}=r,p=computeConv2DInfo(a.shape,c,o,i,l,u,!0),d=new DepthwiseConv2DDerFilterProgram(p);return n.runWebGLProgram(d,[a,s],"float32")}const depthwiseConv2dNativeBackpropFilterConfig={kernelName:DepthwiseConv2dNativeBackpropFilter,backendName:"webgl",kernelFunc:depthwiseConv2dNativeBackpropFilter};function depthwiseConv2dNativeBackpropInput(e){const{inputs:t,backend:n,attrs:r}=e,{dy:a,filter:s}=t,{strides:o,dilations:i,pad:l,dimRoundingMode:u,inputShape:c}=r,p=computeConv2DInfo(c,s.shape,o,i,l,u,!0),d=new DepthwiseConv2DDerInputProgram(p);return n.runWebGLProgram(d,[a,s],"float32")}const depthwiseConv2dNativeBackpropInputConfig={kernelName:DepthwiseConv2dNativeBackpropInput,backendName:"webgl",kernelFunc:depthwiseConv2dNativeBackpropInput};class DiagProgram{constructor(e){this.variableNames=["X"],this.outputShape=[e,e],this.userCode="\n      void main() {\n          ivec2 coords = getOutputCoords();\n          float val = coords[0] == coords[1] ? getX(coords[0]) : 0.0;\n          setOutput(val);\n      }\n    "}}function diag(e){const{inputs:t,backend:n}=e,{x:r}=t,a=[...r.shape,...r.shape],s=sizeFromShape(r.shape),o=reshape({inputs:{x:r},backend:n,attrs:{shape:[s]}}),i=new DiagProgram(s),l=n.runWebGLProgram(i,[o],o.dtype),u=reshape({inputs:{x:l},backend:n,attrs:{shape:a}});return n.disposeIntermediateTensorInfo(o),n.disposeIntermediateTensorInfo(l),u}const diagConfig={kernelName:Diag,backendName:"webgl",kernelFunc:diag};class Dilation2DProgram{constructor(e){this.variableNames=["x","W"],this.outputShape=e.outShape;const{inHeight:t,inWidth:n,padInfo:r,strideHeight:a,strideWidth:s,filterHeight:o,filterWidth:i,dilationHeight:l,dilationWidth:u}=e,{top:c,left:p}=r;this.userCode=`\n      const ivec2 strides = ivec2(${a}, ${s});\n      const ivec2 pads = ivec2(${c}, ${p});\n      const float neg_infinity = -3.4e38;\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords.x;\n        int d1 = coords.w;\n        ivec2 outTopLeftCorner =\n            coords.yz * strides - pads;\n        int hBeg = outTopLeftCorner.x;\n        int wBeg = outTopLeftCorner.y;\n\n        float curVal = neg_infinity;\n        for (int h = 0; h < ${o}; h++) {\n          int hIn = hBeg + h * ${l};\n\n          if (hIn >= 0 && hIn < ${t}) {\n            for (int w = 0; w < ${i}; w++) {\n              int wIn = wBeg + w * ${u};\n\n              if (wIn >= 0 && wIn < ${n}) {\n                float xVal = getX(batch, hIn, wIn, d1);\n                float wVal = getW(h, w, d1);\n\n                float val = xVal + wVal;\n                if (val > curVal) {\n                  curVal = val;\n                }\n              }\n            }\n          }\n        }\n\n        float result = curVal;\n        setOutput(result);\n      }\n    `}}function dilation2D(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,filter:s}=t,{strides:o,pad:i,dilations:l}=r,u=computeDilation2DInfo(a.shape,s.shape,o,i,"NHWC",l);let c;const p=new Dilation2DProgram(u);c=n.runWebGLProgram(p,[a,s],"float32");const d=reshape({inputs:{x:c},backend:n,attrs:{shape:u.outShape}});return n.disposeIntermediateTensorInfo(c),d}const dilation2DConfig={kernelName:Dilation2D,backendName:"webgl",kernelFunc:dilation2D};function einsum(e){const{inputs:t,backend:n,attrs:r}=e,{equation:a}=r,s=t,{allDims:o,summedDims:i,idDims:l}=decodeEinsumEquation(a,s.length);checkEinsumDimSizes(o.length,l,s);const{path:u,steps:c}=getEinsumComputePath(i,l),p=c.length;let d=null,h=o.length;const m=[];for(let e=0;e<p;++e){for(const t of c[e]){const{permutationIndices:e,expandDims:r}=getEinsumPermutation(h,l[t]);let a;isIdentityPermutation(e)?a=s[t]:(a=transpose({inputs:{x:s[t]},backend:n,attrs:{perm:e}}),m.push(a));const o=a.shape.slice();for(let e=0;e<r.length;++e)o.splice(r[e],0,1);arraysEqual(a.shape,o)||(a=reshape({inputs:{x:a},backend:n,attrs:{shape:o}}),m.push(a)),null===d?d=a:(d=multiply({inputs:{a,b:d},backend:n}),m.push(d))}e<p-1&&(u[e]>=0&&(d=sum({inputs:{x:d},backend:n,attrs:{axis:u[e]-(o.length-h),keepDims:!1}}),m.push(d)),h--)}for(const e of m)e!==d&&n.disposeIntermediateTensorInfo(e);return d}const einsumConfig={kernelName:Einsum,backendName:"webgl",kernelFunc:einsum},ELU="return (x >= 0.0) ? x : (exp(x) - 1.0);",ELU_PACKED="\n  vec4 result;\n\n  result.r = (x.r >= 0.0) ? x.r : (exp(x.r) - 1.0);\n  result.g = (x.g >= 0.0) ? x.g : (exp(x.g) - 1.0);\n  result.b = (x.b >= 0.0) ? x.b : (exp(x.b) - 1.0);\n  result.a = (x.a >= 0.0) ? x.a : (exp(x.a) - 1.0);\n\n  return result;\n",elu=unaryKernelFunc({opSnippet:ELU,packedOpSnippet:ELU_PACKED}),eluConfig={kernelName:Elu$1,backendName:"webgl",kernelFunc:elu},ELU_DER="return (b >= 1.0) ? a : a * (b + 1.0);",ELU_DER_PACKED="\n  vec4 bGTEZero = vec4(greaterThanEqual(b, vec4(0.)));\n  return (bGTEZero * a) + ((vec4(1.0) - bGTEZero) * (a * (b + vec4(1.0))));\n",eluGrad=e=>{const{inputs:t,backend:n}=e,{dy:r,y:a}=t,s=env().getBool("WEBGL_PACK_BINARY_OPERATIONS")?new BinaryOpPackedProgram(ELU_DER_PACKED,r.shape,a.shape):new BinaryOpProgram(ELU_DER,r.shape,a.shape);return n.runWebGLProgram(s,[r,a],r.dtype)},eluGradConfig={kernelName:EluGrad,backendName:"webgl",kernelFunc:eluGrad},PACKED_EQUAL="\n  return vec4(equal(a, b));\n",EQUAL="return float(a == b);",equal=binaryKernelFunc({opSnippet:EQUAL,packedOpSnippet:PACKED_EQUAL,dtype:"bool",cpuKernelImpl:equalImplCPU}),equalConfig={kernelName:Equal,backendName:"webgl",kernelFunc:equal},ERF=`\n  // Error function is calculated approximately with elementary function.\n  // See "Handbook of Mathematical Functions with Formulas,\n  // Graphs, and Mathematical Tables", Abramowitz and Stegun.\n  float p = ${ERF_P};\n  float a1 = ${ERF_A1};\n  float a2 = ${ERF_A2};\n  float a3 = ${ERF_A3};\n  float a4 = ${ERF_A4};\n  float a5 = ${ERF_A5};\n\n  float sign = sign(x);\n  x = abs(x);\n  float t = 1.0 / (1.0 + p * x);\n  return sign * (1.0 - (((((a5*t + a4)*t) + a3)*t + a2)*t + a1)*t*exp(-x*x));\n`,erf=unaryKernelFunc({opSnippet:ERF}),erfConfig={kernelName:Erf,backendName:"webgl",kernelFunc:erf},EXP="return exp(x);",exp=unaryKernelFunc({opSnippet:EXP,packedOpSnippet:EXP,cpuKernelImpl:expImplCPU}),expConfig={kernelName:Exp,backendName:"webgl",kernelFunc:exp};function expandDims(e){const{inputs:t,attrs:n,backend:r}=e,{dim:a}=n,{input:s}=t,o=s.shape.length,i=s.shape.slice();let l=a;return a<0&&(assert$4(-(o+1)<=a,()=>`Axis must be in the interval [${-(o+1)}, ${o}]`),l=o+a+1),i.splice(l,0,1),reshape({inputs:{x:s},backend:r,attrs:{shape:i}})}const expandDimsConfig={kernelName:ExpandDims,backendName:"webgl",kernelFunc:expandDims},EXPM1="return exp(x) - 1.0;",expm1=unaryKernelFunc({opSnippet:EXPM1,packedOpSnippet:EXPM1,cpuKernelImpl:expm1ImplCPU}),expm1Config={kernelName:Expm1,backendName:"webgl",kernelFunc:expm1};class FFTProgram{constructor(e,t,n){this.variableNames=["real","imag"];const r=t[1];this.outputShape=t;const a=n?`2.0 * ${Math.PI}`:`-2.0 * ${Math.PI}`,s=n?`${r}.0`:"1.0";let o;if("real"===e)o="return real * expR - imag * expI;";else{if("imag"!==e)throw new Error(`FFT component must be either "real" or "imag", got ${e}.`);o="return real * expI + imag * expR;"}this.userCode=`\n      const float exponentMultiplier = ${a};\n\n      float unaryOpComplex(float real, float expR, float imag, float expI) {\n        ${o}\n      }\n\n      float mulMatDFT(int batch, int index) {\n        float indexRatio = float(index) / float(${r});\n        float exponentMultiplierTimesIndexRatio =\n            exponentMultiplier * indexRatio;\n\n        float result = 0.0;\n\n        for (int i = 0; i < ${r}; i++) {\n          // x = (-2|2 * PI / N) * index * i;\n          float x = exponentMultiplierTimesIndexRatio * float(i);\n          float expR = cos(x);\n          float expI = sin(x);\n          float real = getReal(batch, i);\n          float imag = getImag(batch, i);\n\n          result +=\n              unaryOpComplex(real, expR, imag, expI) / ${s};\n        }\n\n        return result;\n      }\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        setOutput(mulMatDFT(coords[0], coords[1]));\n      }\n    `}}function fftImpl(e,t,n){const r=n.texData.get(e.dataId),a=sizeFromShape(e.shape),s=e.shape[e.shape.length-1],o=reshape({inputs:{x:e},backend:n,attrs:{shape:[a/s,s]}}),i=o.shape,l=new FFTProgram("real",i,t),u=new FFTProgram("imag",i,t),c=[{dataId:r.complexTensorInfos.real.dataId,dtype:r.complexTensorInfos.real.dtype,shape:i},{dataId:r.complexTensorInfos.imag.dataId,dtype:r.complexTensorInfos.imag.dtype,shape:i}],p=n.runWebGLProgram(l,c,"float32"),d=n.runWebGLProgram(u,c,"float32"),h=complex({inputs:{real:p,imag:d},backend:n});n.disposeIntermediateTensorInfo(p),n.disposeIntermediateTensorInfo(d);const m=reshape({inputs:{x:h},backend:n,attrs:{shape:e.shape}});return n.disposeIntermediateTensorInfo(o),n.disposeIntermediateTensorInfo(h),m}function fft(e){const{inputs:t,backend:n}=e,{input:r}=t;return fftImpl(r,!1,n)}const fftConfig={kernelName:FFT,backendName:"webgl",kernelFunc:fft};class FillProgram{constructor(e,t){this.outputShape=[],this.customUniforms=[{name:"value",type:"float"}],this.variableNames=["x"],this.outputShape=e,this.userCode="\n      void main() {\n        // Input can be obtained from uniform value.\n        setOutput(value);\n      }\n    "}}function fill(e){const{backend:t,attrs:n}=e,{shape:r,value:a}=n;let{dtype:s}=n;if(s=s||inferDtype(a),"string"===s){const e=getArrayFromDType(s,sizeFromShape(r));return e.fill(a),t.makeTensorInfo(r,s,e)}{const e=new FillProgram(r,a);return t.runWebGLProgram(e,[],s,[[a]])}}const fillConfig={kernelName:Fill,backendName:"webgl",kernelFunc:fill};class FlipLeftRightProgram{constructor(e){this.variableNames=["Image"],this.outputShape=[];const t=e[2];this.outputShape=e,this.userCode=`\n        void main() {\n          ivec4 coords = getOutputCoords();\n          int x = coords[2];\n\n          int coordX = ${t} - x - 1;\n          float outputValue;\n          if(coordX >= 0 && coordX < ${t}) {\n            outputValue = getImage(coords[0], coords[1], coordX, coords[3]);\n          } else {\n            outputValue = getImage(coords[0], coords[1], coords[2], coords[3]);\n          }\n          setOutput(outputValue);\n        }\n    `}}const flipLeftRightConfig={kernelName:FlipLeftRight,backendName:"webgl",kernelFunc:({inputs:e,backend:t})=>{const{image:n}=e,r=t,a=new FlipLeftRightProgram(n.shape);return r.runWebGLProgram(a,[n],n.dtype)}},FLOOR="return floor(x);",floor=unaryKernelFunc({opSnippet:FLOOR,packedOpSnippet:FLOOR,cpuKernelImpl:floorImplCPU}),floorConfig={kernelName:Floor,backendName:"webgl",kernelFunc:floor},INT_DIV="\n  float s = sign(a) * sign(b);\n  int ia = round(a);\n  int ib = round(b);\n  if (ib != 0) {\n    // Windows (D3D) wants guaranteed non-zero int division at compile-time.\n    return float(idiv(ia, ib, s));\n  } else {\n    return NAN;\n  }\n",INT_DIV_PACKED="\n  ivec4 ia = round(a);\n  ivec4 ib = round(b);\n  bvec4 cond = notEqual(ib, ivec4(0));\n  ivec4 result = ivec4(0);\n  vec4 s = sign(a) * sign(b);\n\n  // Windows (D3D) wants guaranteed non-zero int division at compile-time.\n  if (cond[0]) {\n    result[0] = idiv(ia[0], ib[0], s[0]);\n  }\n  if (cond[1]) {\n    result[1] = idiv(ia[1], ib[1], s[1]);\n  }\n  if (cond[2]) {\n    result[2] = idiv(ia[2], ib[2], s[2]);\n  }\n  if (cond[3]) {\n    result[3] = idiv(ia[3], ib[3], s[3]);\n  }\n  return vec4(result);\n",floorDiv=binaryKernelFunc({opSnippet:INT_DIV,packedOpSnippet:INT_DIV_PACKED,dtype:"int32"}),floorDivConfig={kernelName:FloorDiv,backendName:"webgl",kernelFunc:floorDiv};class FromPixelsProgram{constructor(e){this.variableNames=["A"];const t=getGlslDifferences(),[n,r]=e;this.outputShape=e,this.userCode=`\n      void main() {\n        ivec3 coords = getOutputCoords();\n        int texR = coords[0];\n        int texC = coords[1];\n        int depth = coords[2];\n        vec2 uv = (vec2(texC, texR) + halfCR) / vec2(${r}.0, ${n}.0);\n\n        vec4 values = ${t.texture2D}(A, uv);\n        float value;\n        if (depth == 0) {\n          value = values.r;\n        } else if (depth == 1) {\n          value = values.g;\n        } else if (depth == 2) {\n          value = values.b;\n        } else if (depth == 3) {\n          value = values.a;\n        }\n\n        setOutput(floor(value * 255.0 + 0.5));\n      }\n    `}}class FromPixelsPackedProgram{constructor(e){this.variableNames=["A"],this.packedInputs=!1,this.packedOutput=!0;const t=getGlslDifferences(),[n,r]=e;this.outputShape=e,this.userCode=`\n      void main() {\n        ivec3 coords = getOutputCoords();\n        int texR = coords[0];\n        int texC = coords[1];\n        int depth = coords[2];\n\n        vec4 result = vec4(0.);\n\n        for(int row=0; row<=1; row++) {\n          for(int col=0; col<=1; col++) {\n            texC = coords[1] + row;\n            depth = coords[2] + col;\n\n            vec2 uv = (vec2(texC, texR) + halfCR) /\n                       vec2(${r}.0, ${n}.0);\n            vec4 values = ${t.texture2D}(A, uv);\n            float value;\n            if (depth == 0) {\n              value = values.r;\n            } else if (depth == 1) {\n              value = values.g;\n            } else if (depth == 2) {\n              value = values.b;\n            } else if (depth == 3) {\n              value = values.a;\n            }\n\n            result[row * 2 + col] = floor(value * 255.0 + 0.5);\n          }\n        }\n\n        ${t.output} = result;\n      }\n    `}}const fromPixelsConfig={kernelName:FromPixels,backendName:"webgl",kernelFunc:fromPixels};let fromPixels2DContext;function fromPixels(e){const{inputs:t,backend:n,attrs:r}=e;let{pixels:a}=t;const{numChannels:s}=r,o="undefined"!=typeof HTMLVideoElement&&a instanceof HTMLVideoElement,i="undefined"!=typeof HTMLImageElement&&a instanceof HTMLImageElement,[l,u]=o?[a.videoWidth,a.videoHeight]:[a.width,a.height],c=[u,l],p=[u,l,s];(i||o)&&(null==fromPixels2DContext&&(fromPixels2DContext=document.createElement("canvas").getContext("2d")),fromPixels2DContext.canvas.width=l,fromPixels2DContext.canvas.height=u,fromPixels2DContext.drawImage(a,0,0,l,u),a=fromPixels2DContext.canvas);const d=n.makeTensorInfo(c,"int32");n.texData.get(d.dataId).usage=TextureUsage.PIXELS,n.gpgpu.uploadPixelDataToTexture(n.getTexture(d.dataId),a);const h=env().getBool("WEBGL_PACK")?new FromPixelsPackedProgram(p):new FromPixelsProgram(p),m=n.runWebGLProgram(h,[d],"int32");return n.disposeData(d.dataId),m}function fusedConv2d(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,filter:s,bias:o,preluActivationWeights:i}=t,{strides:l,pad:u,dataFormat:c,dilations:p,dimRoundingMode:d,activation:h,leakyreluAlpha:m}=r,f=convertConv2DDataFormat(c),g=computeConv2DInfo(a.shape,s.shape,l,p,u,d,!1,f);let $;const y=[];if(1!==g.filterHeight||1!==g.filterWidth||1!==g.dilationHeight||1!==g.dilationWidth||1!==g.strideHeight||1!==g.strideWidth||"SAME"!==g.padInfo.type&&"VALID"!==g.padInfo.type)if(env().getBool("WEBGL_CONV_IM2COL")&&1===a.shape[0])$=conv2dWithIm2Row({x:a,filter:s,convInfo:g,backend:n,bias:o,activation:h,preluActivationWeights:i,leakyreluAlpha:m});else{const e=null!=o,t=null!=i,r="leakyrelu"===h,l=h?mapActivationToShaderProgram(h,!1):null,u=new Conv2DProgram(g,e,l,t,r),c=[a,s];if(o&&c.push(o),i&&c.push(i),r){const e=n.makeTensorInfo([],"float32",createScalarValue(m,"float32"));c.push(e),y.push(e)}$=n.runWebGLProgram(u,c,"float32")}else $=conv2dByMatMul({x:a,filter:s,convInfo:g,backend:n,bias:o,activation:h,preluActivationWeights:i,leakyreluAlpha:m});const b=reshape({inputs:{x:$},backend:n,attrs:{shape:g.outShape}});return y.push($),y.forEach(e=>n.disposeIntermediateTensorInfo(e)),b}const fusedConv2DConfig={kernelName:FusedConv2D,backendName:"webgl",kernelFunc:fusedConv2d};function fusedDepthwiseConv2D(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,filter:s,bias:o,preluActivationWeights:i}=t,{strides:l,pad:u,dilations:c,dimRoundingMode:p,activation:d,leakyreluAlpha:h}=r,m=[];let f=c;null==f&&(f=[1,1]),assert$4(eitherStridesOrDilationsAreOne(l,f),()=>`Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ${l} and dilations '${f}'`);const g=computeConv2DInfo(a.shape,s.shape,l,f,u,p,!0),$=env().getBool("WEBGL_PACK_DEPTHWISECONV")&&g.strideWidth<=2&&g.outChannels/g.inChannels==1,y=d?mapActivationToShaderProgram(d,$):null,b=[a,s],x=null!=o,v=null!=i,I="leakyrelu"===d;if(x&&b.push(o),v&&b.push(i),I){const e=n.makeTensorInfo([],"float32",createScalarValue(h,"float32"));b.push(e),m.push(e)}let C;C=$?new DepthwiseConvPacked2DProgram(g,x,y,v,I):new DepthwiseConv2DProgram(g,x,y,v,I);const S=n.runWebGLProgram(C,b,"float32");return m.forEach(e=>n.disposeIntermediateTensorInfo(e)),S}const fusedDepthwiseConv2DConfig={kernelName:FusedDepthwiseConv2D,backendName:"webgl",kernelFunc:fusedDepthwiseConv2D};class GatherNDProgram{constructor(e,t,n){this.sliceDim=e,this.strides=t,this.variableNames=["x","indices"],this.outputShape=n;const r=getCoordsDataType(t.length),a=getCoordsDataType(n.length);this.userCode=`\n        ${r} strides = ${r}(${this.strides});\n         void main() {\n          ${a} coords = getOutputCoords();\n          int flattenIndex = 0;\n          for (int j = 0; j < ${this.sliceDim}; j++) {\n            int index = round(getIndices(coords[0], j));\n            flattenIndex += index * ${this.sliceDim>1?"strides[j]":"strides"};\n          }\n          setOutput(getX(flattenIndex, coords[1]));\n        }\n      `}}function gatherNd(e){const{inputs:t,backend:n}=e,{params:r,indices:a}=t,s=a.shape,o=s[s.length-1],i=sizeFromShape(r.shape),[l,u,c,p]=prepareAndValidate(r,a),d=reshape({inputs:{x:a},backend:n,attrs:{shape:[u,o]}}),h=reshape({inputs:{x:r},backend:n,attrs:{shape:[sizeFromShape(r.shape)/c,c]}});if(n.shouldExecuteOnCPU([r,a])||"string"===r.dtype){const e=n.readSync(a.dataId),t=n.bufferSync(r),s=gatherNdImplCPU(e,t,r.dtype,u,o,c,p,r.shape,i);return n.makeTensorInfo(l,r.dtype,s.values)}const m=new GatherNDProgram(o,p,[u,c]),f=n.runWebGLProgram(m,[h,d],h.dtype),g=reshape({inputs:{x:f},backend:n,attrs:{shape:l}});return n.disposeIntermediateTensorInfo(d),n.disposeIntermediateTensorInfo(h),n.disposeIntermediateTensorInfo(f),g}const gatherNdConfig={kernelName:GatherNd,backendName:"webgl",kernelFunc:gatherNd};class GatherProgram{constructor(e,t){this.variableNames=["A","indices"],this.outputShape=t,this.rank=t.length;const n=getCoordsDataType(this.rank),r=getSourceCoords$1(e);this.userCode=`\n      void main() {\n        ${n} resRC = getOutputCoords();\n        setOutput(getA(${r}));\n      }\n    `}}function getSourceCoords$1(e,t){const n=["resRC.x","resRC.y","resRC.z","resRC.w"],r=[];for(let t=0;t<e.length;t++)r.push(2===t?"int(getIndices(resRC.x, resRC.z))":`${n[t]}`);return r.join()}function gatherV2(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,indices:s}=t,{axis:o,batchDims:i}=r,l=collectGatherOpShapeInfo(a,s,parseAxisParam(o,a.shape)[0],i),u=sizeFromShape(s.shape),c=[],p=reshape({inputs:{x:a},backend:n,attrs:{shape:[l.batchSize,l.outerSize,l.dimSize,l.sliceSize]}}),d=reshape({inputs:{x:s},backend:n,attrs:{shape:[l.batchSize,u/l.batchSize]}});c.push(p),c.push(d);const h=[l.batchSize,l.outerSize,u/l.batchSize,l.sliceSize];if(n.shouldExecuteOnCPU([a,s])||"string"===a.dtype){const e=n.bufferSync(d),t=n.bufferSync(p),r=gatherV2ImplCPU(t,e,h);return c.forEach(e=>n.disposeIntermediateTensorInfo(e)),n.makeTensorInfo(l.outputShape,r.dtype,r.values)}const m=new GatherProgram(p.shape,h),f=n.runWebGLProgram(m,[p,d],p.dtype);c.push(f);const g=reshape({inputs:{x:f},backend:n,attrs:{shape:l.outputShape}});return c.forEach(e=>n.disposeIntermediateTensorInfo(e)),g}const gatherV2Config={kernelName:GatherV2,backendName:"webgl",kernelFunc:gatherV2},GREATER="return float(a > b);",GREATER_PACKED="\n  return vec4(greaterThan(a, b));\n",greater=binaryKernelFunc({opSnippet:GREATER,packedOpSnippet:GREATER_PACKED,cpuKernelImpl:greaterImplCPU,dtype:"bool"}),greaterConfig={kernelName:Greater,backendName:"webgl",kernelFunc:greater},GREATER_EQUAL="return float(a >= b);",GREATER_EQUAL_PACKED="\n  return vec4(greaterThanEqual(a, b));\n",greaterEqual=binaryKernelFunc({opSnippet:GREATER_EQUAL,packedOpSnippet:GREATER_EQUAL_PACKED,dtype:"bool",cpuKernelImpl:greaterEqualImplCPU}),greaterEqualConfig={kernelName:GreaterEqual,backendName:"webgl",kernelFunc:greaterEqual};function ifft(e){const{inputs:t,backend:n}=e,{input:r}=t;return fftImpl(r,!0,n)}const ifftConfig={kernelName:IFFT,backendName:"webgl",kernelFunc:ifft},IS_FINITE="return float(!isnan(x) && !isinf(x));",isFinite$1=unaryKernelFunc({opSnippet:IS_FINITE,dtype:"bool"}),isFiniteConfig={kernelName:IsFinite,backendName:"webgl",kernelFunc:isFinite$1},IS_INF="return float(isinf(x));",isInf=unaryKernelFunc({opSnippet:IS_INF,dtype:"bool"}),isInfConfig={kernelName:IsInf,backendName:"webgl",kernelFunc:isInf},IS_NAN="return float(isnan(x));",isNaN$1=unaryKernelFunc({opSnippet:IS_NAN,dtype:"bool"}),isNaNConfig={kernelName:IsNan,backendName:"webgl",kernelFunc:isNaN$1},LESS="return float(a < b);",LESS_PACKED="\n  return vec4(lessThan(a, b));\n",less=binaryKernelFunc({opSnippet:LESS,packedOpSnippet:LESS_PACKED,cpuKernelImpl:lessImplCPU,dtype:"bool"}),lessConfig={kernelName:Less,backendName:"webgl",kernelFunc:less},LESS_EQUAL="return float(a <= b);",LESS_EQUAL_PACKED="\n  return vec4(lessThanEqual(a, b));\n",lessEqual=binaryKernelFunc({opSnippet:LESS_EQUAL,packedOpSnippet:LESS_EQUAL_PACKED,cpuKernelImpl:lessEqualImplCPU,dtype:"bool"}),lessEqualConfig={kernelName:LessEqual,backendName:"webgl",kernelFunc:lessEqual};function linSpace(e){const{backend:t,attrs:n}=e,{start:r,stop:a,num:s}=n,o=linSpaceImplCPU(r,a,s);return t.makeTensorInfo([o.length],"float32",o)}const linSpaceConfig={kernelName:LinSpace,backendName:"webgl",kernelFunc:linSpace},LOG="if (x < 0.0) return NAN;\n  return log(x);",LOG_PACKED="\n  vec4 result = log(x);\n  vec4 isNaN = vec4(lessThan(x, vec4(0.0)));\n  result.r = isNaN.r == 1.0 ? NAN : result.r;\n  result.g = isNaN.g == 1.0 ? NAN : result.g;\n  result.b = isNaN.b == 1.0 ? NAN : result.b;\n  result.a = isNaN.a == 1.0 ? NAN : result.a;\n\n  return result;\n",log=unaryKernelFunc({opSnippet:LOG,packedOpSnippet:LOG_PACKED,cpuKernelImpl:logImplCPU}),logConfig={kernelName:Log,backendName:"webgl",kernelFunc:log},LOG1P="return log(1.0 + x);",log1p=unaryKernelFunc({opSnippet:LOG1P}),log1pConfig={kernelName:Log1p,backendName:"webgl",kernelFunc:log1p},LOGICAL_AND="return float(a >= 1.0 && b >= 1.0);",LOGICAL_AND_PACKED="\n  return vec4(\n    vec4(greaterThanEqual(a, vec4(1.0))) *\n    vec4(greaterThanEqual(b, vec4(1.0))));\n",logicalAnd=binaryKernelFunc({opSnippet:LOGICAL_AND,packedOpSnippet:LOGICAL_AND_PACKED,dtype:"bool"}),logicalAndConfig={kernelName:LogicalAnd,backendName:"webgl",kernelFunc:logicalAnd},LOGICAL_NOT="return float(!(x >= 1.0));",logicalNot=unaryKernelFunc({opSnippet:LOGICAL_NOT}),logicalNotConfig={kernelName:LogicalNot,backendName:"webgl",kernelFunc:logicalNot},LOGICAL_OR="return float(a >= 1.0 || b >= 1.0);",LOGICAL_OR_PACKED="\n  return min(\n    vec4(greaterThanEqual(a, vec4(1.0))) +\n    vec4(greaterThanEqual(b, vec4(1.0))),\n    vec4(1.0));\n",logicalOr=binaryKernelFunc({opSnippet:LOGICAL_OR,packedOpSnippet:LOGICAL_OR_PACKED,dtype:"bool"}),logicalOrConfig={kernelName:LogicalOr,backendName:"webgl",kernelFunc:logicalOr};class LRNProgram{constructor(e,t,n,r,a){this.variableNames=["x"],this.outputShape=[];const s=t,o=e[3]-1;let i;this.outputShape=e;const l=`float(${n}) + float(${r}) * sum`;i=.5===a?`inversesqrt(${l})`:1===a?`1.0/(${l})`:`exp(log(${l}) * float(-${a}));`,this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int r = coords[1];\n        int c = coords[2];\n        int d = coords[3];\n        float x = getX(b, r, c, d);\n        float sum = 0.0;\n        for (int j = -${s}; j <= ${s}; j++) {\n          int idx = d + j;\n          if (idx >= 0 && idx <=  ${o}) {\n            float z = getX(b, r, c, idx);\n            sum += z * z;\n          }\n        }\n        float val = x * ${i};\n        setOutput(val);\n      }\n    `}}class LRNPackedProgram{constructor(e,t,n,r,a){this.variableNames=["x"],this.outputShape=[],this.packedInputs=!0,this.packedOutput=!0;const s=t,o=e[3]-1;let i;this.outputShape=e;const l=`float(${n}) + float(${r}) * sum`;i=.5===a?`inversesqrt(${l})`:1===a?`1.0/(${l})`:`exp(log(${l}) * float(-${a}));`,this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords.x;\n        int r = coords.y;\n        int c = coords.z;\n        int d = coords.w;\n\n        bool hasNextCol = d < ${this.outputShape[3]};\n        bool hasNextRow = c < ${this.outputShape[2]};\n\n        vec4 sum = vec4(0.);\n        vec4 xFragAtOutputCoords = getX(b, r, c, d);\n\n        vec4 xAtOutputCoords = vec4(\n          getChannel(xFragAtOutputCoords, vec2(c, d)),\n          hasNextCol ?\n            getChannel(xFragAtOutputCoords, vec2(c, d + 1)) : 0.0,\n          hasNextRow ?\n            getChannel(xFragAtOutputCoords , vec2(c + 1, d)) : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getChannel(xFragAtOutputCoords, vec2(c + 1, d + 1)) : 0.0\n        );\n\n        int firstChannel = d - ${s};\n        vec2 cache = vec2(0.);\n        if(firstChannel >= 0){\n          vec4 firstChannelFrag = getX(b, r, c, firstChannel);\n          cache.x = getChannel(firstChannelFrag, vec2(c, firstChannel));\n            if(hasNextRow){\n              cache.y = getChannel(firstChannelFrag, vec2(c + 1, firstChannel));\n            }\n        }\n\n        ivec2 depth = ivec2(d, d + 1);\n        for (int j = - ${s}; j <= ${s}; j++) {\n          ivec2 idx = depth + j;\n          bvec2 aboveLowerBound = greaterThanEqual(idx, ivec2(0));\n          bvec2 belowUpperBound = lessThanEqual(idx, ivec2(${o}));\n\n          bool depthInRange = aboveLowerBound.x && belowUpperBound.x;\n          bool depthPlusOneInRange = aboveLowerBound.y && belowUpperBound.y;\n\n          if(depthInRange || depthPlusOneInRange){\n            vec4 z = vec4(0.);\n            vec4 xFragAtCurrentDepth;\n            z.xz = cache.xy;\n            if(depthPlusOneInRange && hasNextCol){\n              xFragAtCurrentDepth = idx.y != d ?\n                getX(b, r, c, idx.y) : xFragAtOutputCoords;\n              z.y = getChannel(xFragAtCurrentDepth, vec2(c, idx.y));\n              if(hasNextRow){\n                z.w = getChannel(xFragAtCurrentDepth, vec2(c + 1, idx.y));\n              }\n            }\n            cache.xy = z.yw;\n            sum += z * z;\n          }\n        }\n        vec4 result = xAtOutputCoords * ${i};\n        setOutput(result);\n      }\n    `}}const lrn=e=>{const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{depthRadius:s,bias:o,alpha:i,beta:l}=r,u=env().getBool("WEBGL_PACK_NORMALIZATION")?new LRNPackedProgram(a.shape,s,o,i,l):new LRNProgram(a.shape,s,o,i,l);return n.runWebGLProgram(u,[a],a.dtype)},LRNConfig={kernelName:LRN,backendName:"webgl",kernelFunc:lrn};class LRNGradProgram{constructor(e,t,n,r,a){this.variableNames=["inputImage","outputImage","dy"],this.outputShape=[],this.outputShape=e,this.depth=e[3],this.depthRadius=t,this.bias=n,this.alpha=r,this.beta=a,this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int r = coords[1];\n        int c = coords[2];\n\n        float result = 0.0;\n        for (int d = 0; d < ${this.depth}; ++d) {\n          int depthBegin = int(max(0.0, float(d - ${t})));\n          int depthEnd = int(min(float(${this.depth}),\n              float(d + ${t} + 1)));\n\n          const int MIN_DEPTH_BEGIN = 0;\n          const int MAX_DEPTH_END = ${this.depth};\n\n          float norm = 0.0;\n          for (int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k) {\n            if (k < depthBegin){\n              continue;\n            }\n            else if (k >= depthBegin && k < depthEnd) {\n              norm += getInputImage(b, r, c, k) * getInputImage(b, r, c, k);\n            }\n            else {\n              break;\n            }\n          }\n\n          norm = float(${r}) * norm + float(${n});\n\n          for(int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k){\n            if (k < depthBegin){\n              continue;\n            }\n            else if (k >= depthBegin && k < depthEnd){\n              float dyi = -2.0 * float(${r})\n                * float(${a})\n                * getInputImage(b ,r ,c, k) * getOutputImage(b, r, c, d)\n                / norm;\n              if (k == d) {\n                dyi += pow(norm, -1.0 * ${a});\n              }\n              if (k == coords[3]) {\n                dyi *= getDy(b, r, c, d);\n                result += dyi;\n              }\n            }\n            else {\n              break;\n            }\n          }\n      }\n      setOutput(result);\n      }\n    `}}const lrnGrad=e=>{const{inputs:t,backend:n,attrs:r}=e,{x:a,y:s,dy:o}=t,{depthRadius:i,bias:l,alpha:u,beta:c}=r,p=new LRNGradProgram(a.shape,i,l,u,c);return n.runWebGLProgram(p,[a,s,o],a.dtype)},LRNGradConfig={kernelName:LRNGrad,backendName:"webgl",kernelFunc:lrnGrad};function maxImpl(e,t,n,r){const a=sizeFromShape(t),s=reshape({inputs:{x:e},attrs:{shape:[sizeFromShape(e.shape)/a,a]},backend:r}),o=reduce(s,e.dtype,"max",r),i=reshape({inputs:{x:o},attrs:{shape:n},backend:r});return r.disposeIntermediateTensorInfo(s),r.disposeIntermediateTensorInfo(o),i}function max(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{reductionIndices:s,keepDims:o}=r,i=a.shape.length,l=parseAxisParam(s,a.shape);let u=l;const c=getAxesPermutation(u,i),p=null!=c,d=n.shouldExecuteOnCPU([a]);let h=a;if(p){if(d){const e=n.texData.get(h.dataId).values,t=new Array(i);for(let e=0;e<t.length;e++)t[e]=a.shape[c[e]];const r=transposeImplCPU(e,a.shape,a.dtype,c,t);h=n.makeTensorInfo(t,a.dtype),n.texData.get(h.dataId).values=r}else h=transposeImpl(a,c,n);u=getInnerMostAxes(u.length,i)}assertAxesAreInnerMostDims("max",u,i);const[m,f]=computeOutAndReduceShapes(h.shape,u);let g,$=m;if(o&&($=expandShapeToKeepDim(m,l)),d){const e=n.texData.get(h.dataId),t=maxImplCPU(e.values,sizeFromShape(f),$,a.dtype);g=n.makeTensorInfo($,a.dtype),n.texData.get(g.dataId).values=t}else g=maxImpl(h,f,$,n);return p&&n.disposeIntermediateTensorInfo(h),g}const maxConfig={kernelName:Max,backendName:"webgl",kernelFunc:max},MAXIMUM=CHECK_NAN_SNIPPET$1+"\n  return max(a, b);\n",MAXIMUM_PACKED="\n  vec4 result = vec4(max(a, b));\n  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));\n  "+CHECK_NAN_SNIPPET+"\n  return result;\n",maximum=binaryKernelFunc({opSnippet:MAXIMUM,packedOpSnippet:MAXIMUM_PACKED,cpuKernelImpl:maximumImplCPU}),maximumConfig={kernelName:Maximum$1,backendName:"webgl",kernelFunc:maximum};function maxPool(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t;assertNotComplex(a,"maxPool");const{filterSize:s,strides:o,pad:i,dimRoundingMode:l}=r;assert$4(eitherStridesOrDilationsAreOne(o,1),()=>`Error in maxPool: Either strides or dilations must be 1. Got strides ${o} and dilations '1'`);const u=computePool2DInfo(a.shape,s,o,1,i,l);if(1===u.filterWidth&&1===u.filterHeight&&arraysEqual(u.inShape,u.outShape))return identity({inputs:{x:a},backend:n});const c=new Pool2DProgram(u,"max",!1);return n.runWebGLProgram(c,[a],a.dtype)}const maxPoolConfig={kernelName:MaxPool,backendName:"webgl",kernelFunc:maxPool};function maxPool3d(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{filterSize:s,strides:o,pad:i,dataFormat:l,dimRoundingMode:u}=r,c=computePool3DInfo(a.shape,s,o,[1,1,1],i,u,l),p=new Pool3DProgram(c,"max",!1);return n.runWebGLProgram(p,[a],a.dtype)}const maxPool3DConfig={kernelName:MaxPool3D,backendName:"webgl",kernelFunc:maxPool3d};class MaxPool2DBackpropProgram{constructor(e){this.variableNames=["dy","maxPos"],this.outputShape=e.inShape;const t=e.effectiveFilterHeight,n=e.effectiveFilterWidth;this.userCode=`\n      const ivec2 pads = ivec2(${t-1-e.padInfo.top}, ${n-1-e.padInfo.left});\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n\n        ivec2 dyRCCorner = coords.yz - pads;\n        int dyRCorner = dyRCCorner.x;\n        int dyCCorner = dyRCCorner.y;\n\n        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ${t};\n          wR += ${e.dilationHeight}) {\n          float dyR = float(dyRCorner + wR) / ${e.strideHeight}.0;\n\n          if (dyR < 0.0 || dyR >= ${e.outHeight}.0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          for (int wC = 0; wC < ${n}; wC++) {\n            float dyC = float(dyCCorner + wC) / ${e.strideWidth}.0;\n\n            if (dyC < 0.0 || dyC >= ${e.outWidth}.0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            float dyValue = getDy(b, idyR, idyC, d);\n            int maxPosValue = ${t*n-1} - int(getMaxPos(b, idyR, idyC, d));\n\n            // Get the current value, check it against the value from the\n            // position matrix.\n            int curPosValue = wR * ${n} + wC;\n            float mask = float(maxPosValue == curPosValue ? 1.0 : 0.0);\n\n            dotProd += dyValue * mask;\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}class MaxPool3DBackpropProgram{constructor(e){this.variableNames=["dy","maxPos"],this.outputShape=e.inShape;const t=e.effectiveFilterDepth,n=e.effectiveFilterHeight,r=e.effectiveFilterWidth;this.userCode=`\n      const ivec3 pads = ivec3(${t-1-e.padInfo.front}, ${n-1-e.padInfo.top}, ${r-1-e.padInfo.left});\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int ch = coords.u;\n\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\n        int dyDCorner = dyCorner.x;\n        int dyRCorner = dyCorner.y;\n        int dyCCorner = dyCorner.z;\n\n        // Convolve dy(?, ?, ?, ch) with pos mask(:, :, :, d) to get\n        // dx(xD, xR, xC, ch).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n\n        for (int wD = 0; wD < ${t};\n           wD += ${e.dilationDepth}) {\n          float dyD = float(dyDCorner + wD) / ${e.strideDepth}.0;\n\n          if (dyD < 0.0 || dyD >= ${e.outDepth}.0 || fract(dyD) > 0.0) {\n            continue;\n          }\n          int idyD = int(dyD);\n\n          for (int wR = 0; wR < ${n};\n              wR += ${e.dilationHeight}) {\n            float dyR = float(dyRCorner + wR) / ${e.strideHeight}.0;\n\n            if (dyR < 0.0 || dyR >= ${e.outHeight}.0 ||\n                fract(dyR) > 0.0) {\n              continue;\n            }\n            int idyR = int(dyR);\n\n            for (int wC = 0; wC < ${r};\n                wC += ${e.dilationWidth}) {\n              float dyC = float(dyCCorner + wC) / ${e.strideWidth}.0;\n\n              if (dyC < 0.0 || dyC >= ${e.outWidth}.0 ||\n                  fract(dyC) > 0.0) {\n                continue;\n              }\n              int idyC = int(dyC);\n\n              float dyValue = getDy(batch, idyD, idyR, idyC, ch);\n              int maxPosValue = ${t*n*r-1} -\n                  int(getMaxPos(batch, idyD, idyR, idyC, ch));\n\n              // Get the current value, check it against the value from the\n              // position matrix.\n              int curPosValue =\n                  wD * ${n} * ${r} +\n                  wR * ${r} + wC;\n              float mask = float(maxPosValue == curPosValue ? 1.0 : 0.0);\n\n              dotProd += dyValue * mask;\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    `}}function maxPool3DGrad(e){const{inputs:t,backend:n,attrs:r}=e,{dy:a,input:s}=t,o=s,{filterSize:i,strides:l,pad:u,dimRoundingMode:c}=r,p=computePool3DInfo(o.shape,i,l,[1,1,1],u,c),d=new Pool3DProgram(p,"max",!0),h=n.runWebGLProgram(d,[o],o.dtype),m=new MaxPool3DBackpropProgram(p),f=n.runWebGLProgram(m,[a,h],o.dtype);return n.disposeIntermediateTensorInfo(h),f}const maxPoolGrad3DConfig={kernelName:MaxPool3DGrad,backendName:"webgl",kernelFunc:maxPool3DGrad};function maxPoolGrad(e){const{inputs:t,backend:n,attrs:r}=e,{dy:a,input:s,output:o}=t,i=s;assertNotComplex([s,o],"maxPoolGrad");const{filterSize:l,strides:u,pad:c,dimRoundingMode:p}=r,d=computePool2DInfo(i.shape,l,u,1,c,p),h=new Pool2DProgram(d,"max",!0),m=n.runWebGLProgram(h,[i],i.dtype),f=new MaxPool2DBackpropProgram(d),g=n.runWebGLProgram(f,[a,m],i.dtype);return n.disposeIntermediateTensorInfo(m),g}const maxPoolGradConfig={kernelName:MaxPoolGrad,backendName:"webgl",kernelFunc:maxPoolGrad};function maxPoolWithArgmaxImpl(e,t,n,r){let a=new Pool2DProgram(n,"max",!1);const s=r.runWebGLProgram(a,[e],"float32");return a=new Pool2DProgram(n,"max",!0,!0,t),[s,r.runWebGLProgram(a,[e],"float32")]}const maxPoolWithArgmaxConfig={kernelName:MaxPoolWithArgmax,backendName:"webgl",kernelFunc:({inputs:e,attrs:t,backend:n})=>{const{x:r}=e,{filterSize:a,strides:s,pad:o,includeBatchInIndex:i}=t,l=n;assert$4(4===r.shape.length,()=>`Error in maxPool: input must be rank 4 but got rank ${r.shape.length}.`);const u=[1,1];assert$4(eitherStridesOrDilationsAreOne(s,u),()=>`Error in maxPool: Either strides or dilations must be 1. Got strides ${s} and dilations '${u}'`);const c=computePool2DInfo(r.shape,a,s,u,o),[p,d]=maxPoolWithArgmaxImpl(r,i,c,l);return[p,d]}};function meanImpl(e,t,n,r){const a=sizeFromShape(t),s=reshape({inputs:{x:e},attrs:{shape:[sizeFromShape(e.shape)/a,a]},backend:r}),o=reduce(s,"float32","mean",r),i=reshape({inputs:{x:o},attrs:{shape:n},backend:r});return r.disposeIntermediateTensorInfo(s),r.disposeIntermediateTensorInfo(o),i}const meanConfig={kernelName:Mean,backendName:"webgl",kernelFunc:({inputs:e,attrs:t,backend:n})=>{const{x:r}=e,{keepDims:a,axis:s}=t,o=n,i=r.shape.length,l=parseAxisParam(s,r.shape);let u=l;const c=getAxesPermutation(u,i),p=null!=c,d=o.shouldExecuteOnCPU([r]),h=[];let m=r;if(p){if(d){const e=o.texData.get(m.dataId).values,t=new Array(i);for(let e=0;e<t.length;e++)t[e]=r.shape[c[e]];const n=transposeImplCPU(e,r.shape,r.dtype,c,t);m=o.makeTensorInfo(t,r.dtype),o.texData.get(m.dataId).values=n}else m=transposeImpl(r,c,o);h.push(m),u=getInnerMostAxes(u.length,i)}assertAxesAreInnerMostDims("sum",u,i);const[f,g]=computeOutAndReduceShapes(m.shape,u);let $=f;a&&($=expandShapeToKeepDim(f,l));const y=meanImpl(m,g,$,o);for(const e of h)o.disposeIntermediateTensorInfo(e);return y}};function min(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{axis:s,keepDims:o}=r,i=a.shape.length,l=parseAxisParam(s,a.shape);let u=l;const c=getAxesPermutation(u,i);let p=a;null!=c&&(p=transpose({inputs:{x:a},backend:n,attrs:{perm:c}}),u=getInnerMostAxes(u.length,a.shape.length)),assertAxesAreInnerMostDims("min",u,i);const[d,h]=computeOutAndReduceShapes(p.shape,u),m=reshape({inputs:{x:p},backend:n,attrs:{shape:[-1,sizeFromShape(h)]}}),f=reduce(m,m.dtype,"min",n);let g;return g=reshape(o?{inputs:{x:f},backend:n,attrs:{shape:expandShapeToKeepDim(d,l)}}:{inputs:{x:f},backend:n,attrs:{shape:d}}),n.disposeIntermediateTensorInfo(m),n.disposeIntermediateTensorInfo(f),null!=c&&n.disposeIntermediateTensorInfo(p),g}const minConfig={kernelName:Min,backendName:"webgl",kernelFunc:min},MINIMUM=CHECK_NAN_SNIPPET$1+"\n  return min(a, b);\n",MINIMUM_PACKED="\n  vec4 result = vec4(min(a, b));\n  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));\n  "+CHECK_NAN_SNIPPET+"\n  return result;\n",minimum=binaryKernelFunc({opSnippet:MINIMUM,packedOpSnippet:MINIMUM_PACKED,cpuKernelImpl:minimumImplCPU}),minimumConfig={kernelName:Minimum$1,backendName:"webgl",kernelFunc:minimum};class MirrorPadProgram{constructor(e,t,n){this.variableNames=["x"],this.outputShape=t.map((t,n)=>t[0]+e[n]+t[1]);const r=e.length,a=getCoordsDataType(r),s=t.map(e=>e[0]).join(","),o=t.map((t,n)=>t[0]+e[n]).join(","),i=["coords[0]","coords[1]","coords[2]","coords[3]"].slice(0,r),l="reflect"===n?0:1;this.userCode=1!==r?`\n      ${a} start = ${a}(${s});\n      ${a} end = ${a}(${o});\n\n      void main() {\n        ${a} outC = getOutputCoords();\n        for (int i = 0; i < ${r}; i++) {\n          if (outC[i] < start[i]) {\n            outC[i] = start[i] * 2 - outC[i] - ${l};\n          } else if(outC[i] >= end[i]) {\n            outC[i] = (end[i] - 1) * 2 - outC[i] + ${l};\n          }\n        }\n        ${a} coords = outC - start;\n        setOutput(getX(${i}));\n      }\n    `:`\n        int start = ${s};\n        int end = ${o};\n\n        void main() {\n          int outC = getOutputCoords();\n          if (outC < start) {\n            outC = start * 2 - outC - ${l};\n          } else if(outC >= end) {\n            outC = (end - 1) * 2 - outC + ${l};\n          }\n          setOutput(getX(outC - start));\n        }\n      `}}class MirrorPadPackedProgram{constructor(e,t,n){this.variableNames=["x"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=t.map((t,n)=>t[0]+e[n]+t[1]);const r=e.length,a=getCoordsDataType(r),s=t.map(e=>e[0]).join(","),o=t.map((t,n)=>t[0]+e[n]).join(","),i=getChannels("rc",r),l=getChannels("source",r),u=`${i[r-1]} < ${this.outputShape[r-1]}`,c=1===r?"source":`vec2(${l.slice(-2).join()})`,p="reflect"===n?0:1;let d="";if(1===r){const e=`\n        ${a} source = rc;\n        if (source < start) {\n          source = start * 2 - source - ${p};\n        } else if (source >= end) {\n          source = (end - 1) * 2 - source + ${p};\n        }\n        source -= start;\n      `;d=`\n        ${a} rc = outputLoc;\n        ${e}\n        result[0] = getChannel(getX(${l.join()}), ${c});\n        ${i[r-1]} += 1;\n        if(${u}) {\n          ${e}\n          result[1] = getChannel(getX(${l.join()}), ${c});\n        }\n      `}else{const e=`\n        ${a} source = rc;\n        ${a} lt = ${a}(lessThan(source, start));\n        ${a} gte = ${a}(greaterThanEqual(source, end));\n        ${a} orig = 1 - (lt + gte);\n        source = orig * source +\n                lt * (start * 2 - source - ${p}) +\n                gte * ((end - 1) * 2 - source + ${p});\n        source -= start;\n      `;d=`\n        ${a} rc = outputLoc;\n        ${e}\n        result[0] = getChannel(getX(${l.join()}), ${c});\n        ${i[r-1]} += 1;\n        if(${u}) {\n          ${e}\n          result[1] = getChannel(getX(${l.join()}), ${c});\n        }\n        rc = outputLoc;\n        ${i[r-2]} += 1;\n        if(${i[r-2]} < ${this.outputShape[r-2]}) {\n          ${e}\n          result[2] = getChannel(getX(${l.join()}), ${c});\n          ${i[r-1]} += 1;\n          if(${u}) {\n            ${e}\n            result[3] = getChannel(getX(${l.join()}), ${c});\n          }\n        }\n      `}this.userCode=`\n      const ${a} start = ${a}(${s});\n      const ${a} end = ${a}(${o});\n\n      void main() {\n        ${a} outputLoc = getOutputCoords();\n        vec4 result = vec4(0.);\n        ${d}\n        setOutput(result);\n      }\n    `}}const mirrorPadKernelFunc=({inputs:e,backend:t,attrs:n})=>{const{x:r}=e,{paddings:a,mode:s}=n,o=env().getBool("WEBGL_PACK_ARRAY_OPERATIONS")?new MirrorPadPackedProgram(r.shape,a,s):new MirrorPadProgram(r.shape,a,s);return t.runWebGLProgram(o,[r],r.dtype)},mirrorPadConfig={kernelName:MirrorPad,backendName:"webgl",kernelFunc:mirrorPadKernelFunc},MOD="if (b == 0.0) return NAN;\n  return mod(a, b);",MOD_PACKED="\n  vec4 result = mod(a, b);\n  vec4 isNaN = vec4(equal(b, vec4(0.0)));\n  "+CHECK_NAN_SNIPPET+"\n  return result;\n",mod=binaryKernelFunc({opSnippet:MOD,packedOpSnippet:MOD_PACKED}),modConfig={kernelName:Mod,backendName:"webgl",kernelFunc:mod};class MultinomialProgram{constructor(e,t,n){this.variableNames=["probs"],this.customUniforms=[{name:"seed",type:"float"}],this.outputShape=[e,n],this.userCode=`\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n\n        float r = random(seed);\n        float cdf = 0.0;\n\n        for (int i = 0; i < ${t-1}; i++) {\n          cdf += getProbs(batch, i);\n\n          if (r < cdf) {\n            setOutput(float(i));\n            return;\n          }\n        }\n\n        // If no other event happened, last event happened.\n        setOutput(float(${t-1}));\n      }\n    `}}const DIV="\nif (a == b) {\n  return 1.0;\n};\nreturn a / b;",DIV_PACKED="\n  // vec4 one = vec4(equal(a, b));\n  // return one + (vec4(1.0) - one) * a / b;\n  vec4 result = a / b;\n  if(a.x == b.x) {\n    result.x = 1.;\n  }\n  if(a.y == b.y) {\n    result.y = 1.;\n  }\n  if(a.z == b.z) {\n    result.z = 1.;\n  }\n  if(a.w == b.w) {\n    result.w = 1.;\n  }\n\n  return result;\n",realDiv=binaryKernelFunc({opSnippet:DIV,packedOpSnippet:DIV_PACKED,checkOutOfBounds:!0}),realDivConfig={kernelName:RealDiv,backendName:"webgl",kernelFunc:realDiv},SUB="return a - b;",sub=binaryKernelFunc({opSnippet:SUB,packedOpSnippet:SUB,supportsComplex:!0,cpuKernelImpl:subImplCPU}),subConfig={kernelName:Sub,backendName:"webgl",kernelFunc:sub};function softmax(e){const{inputs:t,backend:n,attrs:r}=e,{logits:a}=t,{dim:s}=r,o=parseAxisParam([s],a.shape),i=max({inputs:{x:a},backend:n,attrs:{reductionIndices:o,keepDims:!1}}),l=expandShapeToKeepDim(i.shape,o),u=reshape({inputs:{x:i},backend:n,attrs:{shape:l}}),c=sub({inputs:{a,b:u},backend:n}),p=exp({inputs:{x:c},backend:n}),d=sum({inputs:{x:p},backend:n,attrs:{axis:o,keepDims:!1}}),h=reshape({inputs:{x:d},backend:n,attrs:{shape:l}}),m=realDiv({inputs:{a:p,b:h},backend:n});return n.disposeIntermediateTensorInfo(i),n.disposeIntermediateTensorInfo(u),n.disposeIntermediateTensorInfo(c),n.disposeIntermediateTensorInfo(p),n.disposeIntermediateTensorInfo(d),n.disposeIntermediateTensorInfo(h),m}const softmaxConfig={kernelName:Softmax$2,backendName:"webgl",kernelFunc:softmax};function multinomial(e){const{inputs:t,backend:n,attrs:r}=e,{logits:a}=t,{numSamples:s,seed:o,normalized:i}=r,l=i?a:softmax({inputs:{logits:a},backend:n,attrs:{dim:a.shape.length-1}}),u=new MultinomialProgram(l.shape[0],l.shape[1],s),c=n.runWebGLProgram(u,[l],"int32",[[o]]);return i||n.disposeIntermediateTensorInfo(l),c}const multinomialConfig={kernelName:Multinomial,backendName:"webgl",kernelFunc:multinomial},NEG="return -x;";function neg(e){const{inputs:t,backend:n}=e,{x:r}=t;if(n.shouldExecuteOnCPU([r])){const e=n.texData.get(r.dataId),[t,a]=negImplCPU(e.values,r.shape,r.dtype);return n.makeTensorInfo(a,r.dtype,t)}let a;return a=env().getBool("WEBGL_PACK_UNARY_OPERATIONS")?new UnaryOpPackedProgram(r.shape,NEG):new UnaryOpProgram(r.shape,NEG),n.runWebGLProgram(a,[r],r.dtype)}const negConfig={kernelName:Neg,backendName:"webgl",kernelFunc:neg},nonMaxSuppressionV3Impl=nonMaxSuppressionV3Impl$2;function nonMaxSuppressionV3(e){warn("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");const{inputs:t,backend:n,attrs:r}=e,{boxes:a,scores:s}=t,{maxOutputSize:o,iouThreshold:i,scoreThreshold:l}=r,u=n.readSync(a.dataId),c=n.readSync(s.dataId),{selectedIndices:p}=nonMaxSuppressionV3Impl(u,c,o,i,l);return n.makeTensorInfo([p.length],"int32",new Int32Array(p))}const nonMaxSuppressionV3Config={kernelName:NonMaxSuppressionV3,backendName:"webgl",kernelFunc:nonMaxSuppressionV3},nonMaxSuppressionV4Impl=nonMaxSuppressionV4Impl$2;function nonMaxSuppressionV4(e){warn("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");const{inputs:t,backend:n,attrs:r}=e,{boxes:a,scores:s}=t,{maxOutputSize:o,iouThreshold:i,scoreThreshold:l,padToMaxOutputSize:u}=r,c=n.readSync(a.dataId),p=n.readSync(s.dataId),{selectedIndices:d,validOutputs:h}=nonMaxSuppressionV4Impl(c,p,o,i,l,u);return[n.makeTensorInfo([d.length],"int32",new Int32Array(d)),n.makeTensorInfo([],"int32",new Int32Array([h]))]}const nonMaxSuppressionV4Config={kernelName:NonMaxSuppressionV4,backendName:"webgl",kernelFunc:nonMaxSuppressionV4},nonMaxSuppressionV5Impl=nonMaxSuppressionV5Impl$2;function nonMaxSuppressionV5(e){warn("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");const{inputs:t,backend:n,attrs:r}=e,{boxes:a,scores:s}=t,{maxOutputSize:o,iouThreshold:i,scoreThreshold:l,softNmsSigma:u}=r,c=n.readSync(a.dataId),p=n.readSync(s.dataId),d=o,h=i,m=l,f=u,{selectedIndices:g,selectedScores:$}=nonMaxSuppressionV5Impl(c,p,d,h,m,f);return[n.makeTensorInfo([g.length],"int32",new Int32Array(g)),n.makeTensorInfo([$.length],"float32",new Float32Array($))]}const nonMaxSuppressionV5Config={kernelName:NonMaxSuppressionV5,backendName:"webgl",kernelFunc:nonMaxSuppressionV5};class OneHotProgram{constructor(e,t,n,r){this.variableNames=["indices"],this.outputShape=[e,t],this.userCode=`\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int index = round(getIndices(coords.x));\n        setOutput(mix(float(${r}), float(${n}),\n                      float(index == coords.y)));\n      }\n    `}}const oneHot=e=>{const{inputs:t,backend:n,attrs:r}=e,{indices:a}=t,{depth:s,onValue:o,offValue:i}=r,l=sizeFromShape(a.shape),u=new OneHotProgram(l,s,o,i),c=reshape({inputs:{x:a},backend:n,attrs:{shape:[l]}}),p=n.runWebGLProgram(u,[c],a.dtype);n.disposeIntermediateTensorInfo(c);const d=reshape({inputs:{x:p},backend:n,attrs:{shape:[...a.shape,s]}});return n.disposeIntermediateTensorInfo(p),d},oneHotConfig={kernelName:OneHot,backendName:"webgl",kernelFunc:oneHot};function zerosLike(e){const{inputs:t,backend:n}=e,{x:r}=t;if("complex64"===r.dtype){const e=real({inputs:{input:r},backend:n}),t=zerosLike({inputs:{x:e},backend:n}),a=imag({inputs:{input:r},backend:n}),s=zerosLike({inputs:{x:a},backend:n}),o=complex({inputs:{real:t,imag:s},backend:n});return n.disposeIntermediateTensorInfo(e),n.disposeIntermediateTensorInfo(t),n.disposeIntermediateTensorInfo(a),n.disposeIntermediateTensorInfo(s),o}return fill({attrs:{shape:r.shape,dtype:r.dtype,value:"string"===r.dtype?"":0},backend:n})}const zerosLikeConfig={kernelName:ZerosLike,backendName:"webgl",kernelFunc:zerosLike};function onesLike(e){const{inputs:t,backend:n}=e,{x:r}=t;if("string"===r.dtype)throw new Error("onesLike is not supported under string dtype");if("complex64"===r.dtype){const e=real({inputs:{input:r},backend:n}),t=onesLike({inputs:{x:e},backend:n}),a=imag({inputs:{input:r},backend:n}),s=zerosLike({inputs:{x:a},backend:n}),o=complex({inputs:{real:t,imag:s},backend:n});return n.disposeIntermediateTensorInfo(e),n.disposeIntermediateTensorInfo(t),n.disposeIntermediateTensorInfo(a),n.disposeIntermediateTensorInfo(s),o}return fill({attrs:{shape:r.shape,dtype:r.dtype,value:1},backend:n})}const onesLikeConfig={kernelName:OnesLike,backendName:"webgl",kernelFunc:onesLike};function pack(e){const{inputs:t,backend:n,attrs:r}=e,{axis:a}=r;if(1===t.length)return expandDims({inputs:{input:t[0]},backend:n,attrs:{dim:a}});const s=t[0].shape,o=t[0].dtype;t.forEach(e=>{assertShapesMatch(s,e.shape,"All tensors passed to stack must have matching shapes"),assert$4(o===e.dtype,()=>"All tensors passed to stack must have matching dtypes")});const i=[],l=concat({inputs:t.map(e=>{const t=expandDims({inputs:{input:e},backend:n,attrs:{dim:a}});return i.push(t),t}),backend:n,attrs:{axis:a}});return i.forEach(e=>n.disposeIntermediateTensorInfo(e)),l}const packConfig={kernelName:Pack,backendName:"webgl",kernelFunc:pack};class PadProgram{constructor(e,t,n){this.variableNames=["x"],this.customUniforms=[{name:"value",type:"float"}],this.outputShape=t.map((t,n)=>t[0]+e[n]+t[1]);const r=e.length,a=getCoordsDataType(r),s=t.map(e=>e[0]).join(","),o=t.map((t,n)=>t[0]+e[n]).join(","),i=["coords[0]","coords[1]","coords[2]","coords[3]"].slice(0,r);this.userCode=1!==r?`\n      ${a} start = ${a}(${s});\n      ${a} end = ${a}(${o});\n\n      void main() {\n        ${a} outC = getOutputCoords();\n        if (any(lessThan(outC, start)) || any(greaterThanEqual(outC, end))) {\n          setOutput(value);\n        } else {\n          ${a} coords = outC - start;\n          setOutput(getX(${i}));\n        }\n      }\n    `:`\n        int start = ${s};\n        int end = ${o};\n\n        void main() {\n          int outC = getOutputCoords();\n          if (outC < start || outC >= end) {\n            setOutput(value);\n          } else {\n            setOutput(getX(outC - start));\n          }\n        }\n      `}}class PadPackedProgram{constructor(e,t,n){this.variableNames=["x"],this.packedInputs=!0,this.packedOutput=!0,this.customUniforms=[{name:"value",type:"float"}],this.outputShape=t.map((t,n)=>t[0]+e[n]+t[1]);const r=e.length,a=getCoordsDataType(r),s=t.map(e=>e[0]).join(","),o=t.map((t,n)=>t[0]+e[n]).join(","),i=getChannels("rc",r),l=getChannels("source",r),u=`${i[r-1]} < ${this.outputShape[r-1]}`,c=1===r?"source":`vec2(${l.slice(-2).join()})`,p=[`${a} rc = outputLoc;`,`${i[r-1]} += 1;\n       if(${u}) {\n      `,1===r?"":`}\n       rc = outputLoc;\n       ${i[r-2]} += 1;\n       if(${i[r-2]} < ${this.outputShape[r-2]}) {`,1===r?"":`  ${i[r-1]} += 1;\n         if(${u}) {`],d=1===r?"rc < start || rc >= end":"any(lessThan(rc, start)) || any(greaterThanEqual(rc, end))";let h="";for(let e=0,t=1===r?2:4;e<t;e++)h+=`\n        ${p[e]}\n        if (${d}) {\n          result[${e}] = float(value);\n        } else {\n          ${a} source = rc - start;\n          result[${e}] = getChannel(getX(${l.join()}), ${c});\n        }\n      `;h+=1===r?"} ":"}}",this.userCode=`\n      const ${a} start = ${a}(${s});\n      const ${a} end = ${a}(${o});\n\n      void main() {\n        ${a} outputLoc = getOutputCoords();\n        vec4 result = vec4(0.);\n        ${h}\n        setOutput(result);\n      }\n    `}}const padV2=e=>{const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{paddings:s,constantValue:o}=r,i=env().getBool("WEBGL_PACK_ARRAY_OPERATIONS")?new PadPackedProgram(a.shape,s,o):new PadProgram(a.shape,s,o);return n.runWebGLProgram(i,[a],a.dtype,[[o]])},padV2Config={kernelName:PadV2,backendName:"webgl",kernelFunc:padV2},POW="\n  if(a < 0.0 && floor(b) < b){\n    return NAN;\n  }\n  if (b == 0.0) {\n    return 1.0;\n  }\n  return (round(mod(b, 2.0)) != 1) ?\n      pow(abs(a), b) : sign(a) * pow(abs(a), b);\n",POW_PACKED="\n  // isModRound1 has 1 for components with round(mod(b, 2.0)) == 1, 0 otherwise.\n  vec4 isModRound1 = vec4(equal(round(mod(b, 2.0)), ivec4(1)));\n  vec4 multiplier = sign(a) * isModRound1 + (vec4(1.0) - isModRound1);\n  vec4 result = multiplier * pow(abs(a), b);\n\n  // Ensure that a^0 = 1, including 0^0 = 1 as this correspond to TF and JS\n  bvec4 isExpZero = equal(b, vec4(0.0));\n  result.r = isExpZero.r ? 1.0 : result.r;\n  result.g = isExpZero.g ? 1.0 : result.g;\n  result.b = isExpZero.b ? 1.0 : result.b;\n  result.a = isExpZero.a ? 1.0 : result.a;\n\n  vec4 isNaN = vec4(lessThan(a, vec4(0.0))) * vec4(lessThan(floor(b), b));\n  "+CHECK_NAN_SNIPPET+"\n  return result;\n",pow=binaryKernelFunc({opSnippet:POW,packedOpSnippet:POW_PACKED}),powConfig={kernelName:Pow,backendName:"webgl",kernelFunc:pow};function prod(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{axis:s,keepDims:o}=r,i=a.shape.length,l=[],u=parseAxisParam(s,a.shape);let c=u;const p=getAxesPermutation(c,i);let d,h=a;if(null!=p&&(h=transpose({inputs:{x:a},backend:n,attrs:{perm:p}}),c=getInnerMostAxes(c.length,i),l.push(h)),assertAxesAreInnerMostDims("prod",c,i),n.shouldExecuteOnCPU([h])){const e=n.texData.get(h.dataId).values,{outVals:t,outShape:r,outDtype:a}=prodImplCPU(h.shape,h.dtype,e,c);d=n.makeTensorInfo(r,a,t)}else{const[e,t]=computeOutAndReduceShapes(h.shape,c),r=sizeFromShape(t),s=reshape({inputs:{x:h},backend:n,attrs:{shape:[-1,r]}}),o=reduce(s,sumOutType(a.dtype),"prod",n);d=reshape({inputs:{x:o},backend:n,attrs:{shape:e}}),l.push(s),l.push(o)}if(o){l.push(d);const e=expandShapeToKeepDim(d.shape,u);d=reshape({inputs:{x:d},backend:n,attrs:{shape:e}})}return l.forEach(e=>n.disposeIntermediateTensorInfo(e)),d}const prodConfig={kernelName:Prod,backendName:"webgl",kernelFunc:prod},range$1=e=>{const{backend:t,attrs:n}=e,{start:r,stop:a,step:s,dtype:o}=n,i=rangeImplCPU(r,a,s,o);return t.makeTensorInfo([i.length],o,i)},rangeConfig={kernelName:Range,backendName:"webgl",kernelFunc:range$1},RECIPROCAL="return 1.0 / x;",reciprocal=unaryKernelFunc({opSnippet:RECIPROCAL}),reciprocalConfig={kernelName:Reciprocal,backendName:"webgl",kernelFunc:reciprocal},RELU=CHECK_NAN_SNIPPET$2+"\n  return (x < 0.0) ? 0.0 : x;\n",RELU_PACKED="\n  vec4 result = x * vec4(greaterThanEqual(x, vec4(0.0)));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n",relu$1=unaryKernelFunc({opSnippet:RELU,packedOpSnippet:RELU_PACKED}),reluConfig={kernelName:Relu$1,backendName:"webgl",kernelFunc:relu$1},RELU6=CHECK_NAN_SNIPPET$2+"\n  return (x < 0.0) ? 0.0 : min(6.0, x);\n",RELU6_PACKED="\n  vec4 result = min(x, vec4(6.)) * vec4(greaterThanEqual(x, vec4(0.0)));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n",relu6=unaryKernelFunc({opSnippet:RELU6,packedOpSnippet:RELU6_PACKED}),relu6Config={kernelName:Relu6$1,backendName:"webgl",kernelFunc:relu6};class ResizeBilinearProgram{constructor(e,t,n,r,a){this.variableNames=["A"],this.outputShape=[];const[s,o,i,l]=e;this.outputShape=[s,t,n,l];const u=[r&&t>1?o-1:o,r&&n>1?i-1:i],c=[r&&t>1?t-1:t,r&&n>1?n-1:n];let p;p=a?"(vec2(yRC) + vec2(0.5)) * effectiveInputOverOutputRatioRC - vec2(0.5)":"vec2(yRC) * effectiveInputOverOutputRatioRC",this.userCode=`\n      const vec2 effectiveInputOverOutputRatioRC = vec2(\n          ${u[0]/c[0]},\n          ${u[1]/c[1]});\n      const vec2 inputShapeRC = vec2(${o}.0, ${i}.0);\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        ivec2 yRC = coords.yz;\n\n        // Fractional source index.\n        vec2 sourceFracIndexRC = ${p};\n\n        // Compute the four integer indices.\n        ivec2 sourceFloorRC = ivec2(max(sourceFracIndexRC, vec2(0.0)));\n        ivec2 sourceCeilRC = ivec2(\n          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));\n\n        float topLeft = getA(b, sourceFloorRC.x, sourceFloorRC.y, d);\n        float bottomLeft = getA(b, sourceCeilRC.x, sourceFloorRC.y, d);\n        float topRight = getA(b, sourceFloorRC.x, sourceCeilRC.y, d);\n        float bottomRight = getA(b, sourceCeilRC.x, sourceCeilRC.y, d);\n\n        vec2 fracRC = sourceFracIndexRC - vec2(sourceFloorRC);\n\n        float top = topLeft + (topRight - topLeft) * fracRC.y;\n        float bottom = bottomLeft + (bottomRight - bottomLeft) * fracRC.y;\n        float newValue = top + (bottom - top) * fracRC.x;\n\n        setOutput(newValue);\n      }\n    `}}class ResizeBilinearPackedProgram{constructor(e,t,n,r,a){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=[];const[s,o,i,l]=e;this.outputShape=[s,t,n,l];const u=[r&&t>1?o-1:o,r&&n>1?i-1:i],c=[r&&t>1?t-1:t,r&&n>1?n-1:n];let p;p=a?"(vec3(yRC) + vec3(0.5)) * effectiveInputOverOutputRatioRC - vec3(0.5)":"vec3(yRC) * effectiveInputOverOutputRatioRC",this.userCode=`\n      const vec3 effectiveInputOverOutputRatioRC = vec3(\n          ${u[0]/c[0]},\n          ${u[1]/c[1]},\n          ${u[1]/c[1]});\n      const vec3 inputShapeRC = vec3(${o}.0, ${i}.0,\n                                     ${i}.0);\n\n      float getAValue(int b, int r, int c, int d) {\n        return getChannel(getA(b, r, c, d), vec2(c, d));\n      }\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        // Calculate values for next column in yRC.z.\n        ivec3 yRC = coords.yzz + ivec3(0, 0, 1);\n\n        // Fractional source index.\n        vec3 sourceFracIndexRC = ${p};\n\n        // Compute the four integer indices.\n        ivec3 sourceFloorRC = ivec3(max(sourceFracIndexRC, vec3(0.0)));\n        ivec3 sourceCeilRC = ivec3(\n          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));\n\n        // Should we calculate next column and row elements in 2x2 packed cell.\n        bool hasNextCol = d < ${l-1};\n        bool hasNextRow = coords.z < ${n-1};\n\n        // In parallel, construct four corners for all four components in\n        // packed 2x2 cell.\n        vec4 topLeft = vec4(\n          getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d),\n          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d + 1) : 0.0);\n\n        vec4 bottomLeft = vec4(\n          getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d),\n          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d + 1) : 0.0);\n\n        vec4 topRight = vec4(\n          getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d),\n          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d + 1) : 0.0);\n\n        vec4 bottomRight = vec4(\n          getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d),\n          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d + 1) : 0.0);\n\n        vec3 fracRC = sourceFracIndexRC - vec3(sourceFloorRC);\n\n        vec4 top = mix(topLeft, topRight, fracRC.yyzz);\n        vec4 bottom = mix(bottomLeft, bottomRight, fracRC.yyzz);\n        vec4 newValue = mix(top, bottom, fracRC.x);\n\n        setOutput(newValue);\n      }\n    `}}function resizeBilinear(e){const{inputs:t,backend:n,attrs:r}=e,{images:a}=t,{alignCorners:s,halfPixelCenters:o,size:i}=r,[l,u]=i,c=env().getBool("WEBGL_PACK_IMAGE_OPERATIONS")?new ResizeBilinearPackedProgram(a.shape,l,u,s,o):new ResizeBilinearProgram(a.shape,l,u,s,o);return n.runWebGLProgram(c,[a],"float32")}const resizeBilinearConfig={kernelName:ResizeBilinear,backendName:"webgl",kernelFunc:resizeBilinear};class ResizeBilinearBackpropProgram{constructor(e,t,n){this.variableNames=["dy"],this.outputShape=[],this.outputShape=t;const[,r,a]=t,[,s,o]=e,i=[n&&s>1?r-1:r,n&&o>1?a-1:a],l=[n&&s>1?s-1:s,n&&o>1?o-1:o],u=i[0]/l[0],c=i[1]/l[1],p=1/u,d=1/c,h=2*Math.ceil(p)+2,m=2*Math.ceil(d)+2;this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        int r = coords[1];\n        int c = coords[2];\n\n        float accumulator = 0.0;\n\n        const float heightScale = float(${u});\n        const float widthScale = float(${c});\n\n        const float invHeightScale = float(${p});\n        const float invWidthScale = float(${d});\n\n        const int winHeight = int(${h});\n        const int winWidth = int(${m});\n\n        // Compute bounds for where in dy we will look\n        float startRLerp = floor(float(r) * invHeightScale);\n        int startDyR = int(startRLerp - float(winHeight / 2));\n\n        float startCLerp = floor(float(c) * invWidthScale);\n        int startDyC = int(startCLerp - float(winWidth / 2));\n\n        // Loop over dy\n        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {\n          int dyR = dyROffset + startDyR;\n\n          // Guard against the window exceeding the bounds of dy\n          if (dyR < 0 || dyR >= ${s}) {\n            continue;\n          }\n\n          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {\n            int dyC = dyCOffset + startDyC;\n\n            // Guard against the window exceeding the bounds of dy\n            if (dyC < 0 || dyC >= ${o}) {\n              continue;\n            }\n\n            float dxR = float(dyR) * heightScale;\n            int topDxRIndex = int(floor(dxR));\n            int bottomDxRIndex = int(min(ceil(dxR), ${r-1}.0));\n            float dxRLerp = dxR - float(topDxRIndex);\n            float inverseDxRLerp = 1.0 - dxRLerp;\n\n            float dxC = float(dyC) * widthScale;\n            int leftDxCIndex = int(floor(dxC));\n            int rightDxCIndex = int(min(ceil(dxC), ${a-1}.0));\n            float dxCLerp = dxC - float(leftDxCIndex);\n            float inverseDxCLerp = 1.0 - dxCLerp;\n\n            if (r == topDxRIndex && c == leftDxCIndex) {\n              // topLeft\n              accumulator +=\n                getDy(b, dyR, dyC, d) * inverseDxRLerp * inverseDxCLerp;\n            }\n\n            if (r == topDxRIndex && c == rightDxCIndex) {\n              // topRight\n              accumulator += getDy(b, dyR, dyC, d) * inverseDxRLerp * dxCLerp;\n            }\n\n            if (r == bottomDxRIndex && c == leftDxCIndex) {\n              // bottomLeft\n              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * inverseDxCLerp;\n            }\n\n            if (r == bottomDxRIndex && c == rightDxCIndex) {\n              // bottomRight\n              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * dxCLerp;\n            }\n          }\n        }\n        // End loop over dy\n\n        setOutput(accumulator);\n      }\n    `}}function resizeBilinearGrad(e){const{inputs:t,backend:n,attrs:r}=e,{images:a,dy:s}=t,{alignCorners:o}=r,i=new ResizeBilinearBackpropProgram(s.shape,a.shape,o);return n.runWebGLProgram(i,[s],s.dtype)}const resizeBilinearGradConfig={kernelName:ResizeBilinearGrad,backendName:"webgl",kernelFunc:resizeBilinearGrad};class ResizeNearestNeighborProgram{constructor(e,t,n,r,a){this.variableNames=["A"],this.outputShape=[];const[s,o,i,l]=e;this.outputShape=[s,t,n,l];const u=[r&&t>1?o-1:o,r&&n>1?i-1:i],c=[r&&t>1?t-1:t,r&&n>1?n-1:n];let p;p=a?"max((vec2(yRC) + vec2(0.5)) * effectiveInputOverOutputRatioRC, vec2(0.0))":"vec2(yRC) * effectiveInputOverOutputRatioRC",this.userCode=`\n      const vec2 effectiveInputOverOutputRatioRC = vec2(\n          ${u[0]/c[0]},\n          ${u[1]/c[1]});\n      const vec2 inputShapeRC = vec2(${o}.0, ${i}.0);\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        ivec2 yRC = coords.yz;\n\n        // Fractional source index.\n        vec2 sourceFracIndexRC = ${p};\n\n        // Compute the coordinators of nearest neighbor point.\n        ivec2 sourceNearestRC = ivec2(\n          min(inputShapeRC - 1.0, floor(sourceFracIndexRC + ${r?"0.5":"0.0"})));\n        float newValue = getA(b, sourceNearestRC.x, sourceNearestRC.y, d);\n\n        setOutput(newValue);\n      }\n    `}}class ResizeNearestNeighborPackedProgram{constructor(e,t,n,r,a){this.variableNames=["A"],this.packedInputs=!0,this.packedOutput=!0,this.outputShape=[];const[s,o,i,l]=e;this.outputShape=[s,t,n,l];const u=[r&&t>1?o-1:o,r&&n>1?i-1:i],c=[r&&t>1?t-1:t,r&&n>1?n-1:n];let p;p=a?"max((vec3(yRC) + vec3(0.5)) * effectiveInputOverOutputRatioRC, vec3(0.0))":"vec3(yRC) * effectiveInputOverOutputRatioRC",this.userCode=`\n      const vec3 effectiveInputOverOutputRatioRC = vec3(\n          ${u[0]/c[0]},\n          ${u[1]/c[1]},\n          ${u[1]/c[1]});\n      const vec3 inputShapeRC = vec3(${o}.0, ${i}.0,\n                                     ${i}.0);\n\n      float getAValue(int b, int r, int c, int d) {\n        return getChannel(getA(b, r, c, d), vec2(c, d));\n      }\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        // Calculate values for next column in yRC.z.\n        ivec3 yRC = coords.yzz + ivec3(0, 0, 1);\n\n        // Fractional source index.\n        vec3 sourceFracIndexRC = ${p};\n\n        // Compute the coordinators of nearest neighbor point.\n        ivec3 sourceNearestRC = ivec3(\n          min(inputShapeRC - 1.0, floor(sourceFracIndexRC + ${r?"0.5":"0.0"})));\n\n        // Should we calculate next column and row elements in 2x2 packed cell.\n        bool hasNextCol = d < ${l-1};\n        bool hasNextRow = coords.z < ${n-1};\n\n        vec4 newValue = vec4(\n          getAValue(b, sourceNearestRC.x, sourceNearestRC.y, d),\n          hasNextCol ? getAValue(b, sourceNearestRC.x, sourceNearestRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceNearestRC.x, sourceNearestRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceNearestRC.x, sourceNearestRC.z, d + 1) : 0.0);\n\n        setOutput(newValue);\n      }\n    `}}function resizeNearestNeighbor(e){const{inputs:t,backend:n,attrs:r}=e,{images:a}=t,{alignCorners:s,halfPixelCenters:o,size:i}=r,[l,u]=i,c=env().getBool("WEBGL_PACK_IMAGE_OPERATIONS")?new ResizeNearestNeighborPackedProgram(a.shape,l,u,s,o):new ResizeNearestNeighborProgram(a.shape,l,u,s,o);return n.runWebGLProgram(c,[a],a.dtype)}const resizeNearestNeighborConfig={kernelName:ResizeNearestNeighbor,backendName:"webgl",kernelFunc:resizeNearestNeighbor};class ResizeNearestNeigborBackpropProgram{constructor(e,t,n){this.variableNames=["dy"],this.outputShape=[],this.outputShape=t;const[,r,a]=t,[,s,o]=e,i=[n&&s>1?r-1:r,n&&o>1?a-1:a],l=[n&&s>1?s-1:s,n&&o>1?o-1:o],u=i[0]/l[0],c=i[1]/l[1],p=1/u,d=1/c,h=2*Math.ceil(p)+2,m=2*Math.ceil(d)+2;this.userCode=`\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        int r = coords[1];\n        int c = coords[2];\n\n        float accumulator = 0.0;\n\n        const float heightScale = float(${u});\n        const float widthScale = float(${c});\n\n        const float invHeightScale = float(${p});\n        const float invWidthScale = float(${d});\n\n        const int winHeight = int(${h});\n        const int winWidth = int(${m});\n\n        // Compute bounds for where in dy we will look\n        float startRLerp = floor(float(r) * invHeightScale);\n        int startDyR = int(floor(startRLerp - float(winHeight / 2)));\n\n        float startCLerp = floor(float(c) * invWidthScale);\n        int startDyC = int(floor(startCLerp - float(winWidth / 2)));\n\n        // Loop over dy\n        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {\n          int dyR = dyROffset + startDyR;\n\n          // Guard against the window exceeding the bounds of dy\n          if (dyR < 0 || dyR >= ${s}) {\n            continue;\n          }\n\n          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {\n            int dyC = dyCOffset + startDyC;\n\n            // Guard against the window exceeding the bounds of dy\n            if (dyC < 0 || dyC >= ${o}) {\n              continue;\n            }\n\n            float sourceFracRow =\n              float(${i[0]}) *\n                (float(dyR) / float(${l[0]}));\n\n            float sourceFracCol =\n                float(${i[1]}) *\n                  (float(dyC) / float(${l[1]}));\n\n            int sourceNearestRow = int(min(\n                float(int(${r}) - 1),\n                ${n} ? float(round(sourceFracRow)) :\n                                  float(floor(sourceFracRow))));\n\n            int sourceNearestCol = int(min(\n                float(int(${a}) - 1),\n                ${n} ? float(round(sourceFracCol)) :\n                                  float(floor(sourceFracCol))));\n\n            if (r == sourceNearestRow && c == sourceNearestCol) {\n              accumulator += getDy(b, dyR, dyC, d);\n            }\n          }\n        }\n        // End loop over dy\n\n        setOutput(accumulator);\n      }\n    `}}function resizeNearestNeighborGrad(e){const{inputs:t,backend:n,attrs:r}=e,{images:a,dy:s}=t,{alignCorners:o}=r,i=new ResizeNearestNeigborBackpropProgram(s.shape,a.shape,o);return n.runWebGLProgram(i,[s],s.dtype)}const resizeNearestNeighborGradConfig={kernelName:ResizeNearestNeighborGrad,backendName:"webgl",kernelFunc:resizeNearestNeighborGrad};class ReverseProgram{constructor(e,t){this.variableNames=["x"];const n=e.length;if(n>4)throw new Error(`WebGL backend: Reverse of rank-${n} tensor is not yet supported`);if(this.outputShape=e,1===n)return void(this.userCode=`\n        void main() {\n          int coord = getOutputCoords();\n          setOutput(getX(${e[0]} - coord - 1));\n        }\n      `);const r=e.map((n,r)=>(n=>-1!==t.indexOf(n)&&1!==e[n]?`${e[n]} - coords[${n}] - 1`:`coords[${n}]`)(r)).join(","),a=getCoordsDataType(n);this.userCode=`\n      void main() {\n        ${a} coords = getOutputCoords();\n        setOutput(getX(${r}));\n      }\n    `}}class ReversePackedProgram{constructor(e,t){this.variableNames=["x"],this.packedInputs=!0,this.packedOutput=!0;const n=e.length;if(n>4)throw new Error(`WebGL backend: Reverse of rank-${n} tensor is not yet supported`);this.outputShape=e;const r=getChannels("rc",n),a=`${r[n-1]} + 1 < ${this.outputShape[n-1]}`,s=`${r[n-2]} + 1 < ${this.outputShape[n-2]}`,o=getCoordsDataType(n);function i(n){const r=e.map((r,a)=>function(n,r){return-1!==t.indexOf(n)&&1!==e[n]?`${e[n]} - ${r[n]} - 1`:`${r[n]}`}(a,n));return`getChannel(getX(${r.join(",")}), vec2(${r.slice(-2).join(",")}))`}this.userCode=1===n?`\n        void main(){\n          int rc = getOutputCoords();\n          vec4 result = vec4(0.);\n          result.r = getChannel(getX(${e[0]} - rc - 1),\n            ${e[0]} - rc - 1);\n          if(${a}){\n              result.g = getChannel(getX(${e[0]} - (rc  + 1) - 1),\n                ${e[0]} - (rc  + 1) - 1);\n          }\n          setOutput(result);\n        }\n      `:`\n        void main() {\n          ${o} rc = getOutputCoords();\n          vec4 result = vec4(0.);\n          result.r = ${function(e){return i(e)}(r.slice())};\n          if(${a}){\n            result.g = ${function(e){return e[n-1]="("+e[n-1]+" + 1)",i(e)}(r.slice())};\n          }\n          if(${s}) {\n            result.b = ${function(e){return e[n-2]="("+e[n-2]+" + 1)",i(e)}(r.slice())};\n            if(${a}) {\n              result.a = ${function(e){return e[n-1]="("+e[n-1]+" + 1)",e[n-2]="("+e[n-2]+" + 1)",i(e)}(r.slice())};\n            }\n          }\n          setOutput(result);\n        }\n    `}}function reverse(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{dims:s}=r,o=a.shape.length,i=parseAxisParam(s,a.shape);if(0===o)return identity({inputs:{x:a},backend:n});const l=env().getBool("WEBGL_PACK_ARRAY_OPERATIONS")?new ReversePackedProgram(a.shape,i):new ReverseProgram(a.shape,i);return n.runWebGLProgram(l,[a],a.dtype)}const reverseConfig={kernelName:Reverse,backendName:"webgl",kernelFunc:reverse};class RotateProgram{constructor(e,t){this.variableNames=["Image"],this.outputShape=[],this.customUniforms=[{name:"params",type:"vec4"}];const n=e[1],r=e[2];this.outputShape=e;let a="";a="number"==typeof t?`float outputValue = ${t.toFixed(2)};`:`\n        vec3 fill = vec3(${t.join(",")});\n        float outputValue = fill[coords[3]];`,this.userCode=`\n        void main() {\n          ivec4 coords = getOutputCoords();\n          int x = coords[2];\n          int y = coords[1];\n          float coordXFloat = (float(x) - params[0]) * params[3] -\n            (float(y) - params[1]) * params[2];\n          float coordYFloat = (float(x) - params[0]) * params[2] +\n            (float(y) - params[1]) * params[3];\n          int coordX = int(round(coordXFloat + params[0]));\n          int coordY = int(round(coordYFloat + params[1]));\n          ${a}\n          if(coordX >= 0 && coordX < ${r} && coordY >= 0 && coordY < ${n}) {\n            outputValue = getImage(coords[0], coordY, coordX, coords[3]);\n          }\n          setOutput(outputValue);\n        }\n    `}}const rotateWithOffsetConfig={kernelName:RotateWithOffset,backendName:"webgl",kernelFunc:({inputs:e,attrs:t,backend:n})=>{const{image:r}=e,{radians:a,fillValue:s,center:o}=t,i=n,l=new RotateProgram(r.shape,s),[u,c]=getImageCenter(o,r.shape[1],r.shape[2]),p=[[u,c,Math.sin(a),Math.cos(a)]];return i.runWebGLProgram(l,[r],r.dtype,p)}},ROUND="\n  // OpenGL ES does not support round function.\n  // The algorithm is based on banker's rounding.\n  float base = floor(x);\n  if ((x - base) < 0.5) {\n    return floor(x);\n  } else if ((x - base) > 0.5) {\n    return ceil(x);\n  } else {\n    if (mod(base, 2.0) == 0.0) {\n      return base;\n    } else {\n      return base + 1.0;\n    }\n  }\n",round=unaryKernelFunc({opSnippet:ROUND}),roundConfig={kernelName:Round,backendName:"webgl",kernelFunc:round},RSQRT="return inversesqrt(x);",rsqrt=unaryKernelFunc({opSnippet:RSQRT,cpuKernelImpl:rsqrtImplCPU}),rsqrtConfig={kernelName:Rsqrt,backendName:"webgl",kernelFunc:rsqrt};class ScatterProgram{constructor(e,t,n,r,a,s,o=!0){this.variableNames=["updates","indices","defaultValue"],this.outputShape=s;const i=getCoordsDataType(a.length),l=getCoordsDataType(s.length);let u="";1===n?u="i":2===n&&(u="i, j");let c="";1===r?c="i":2===r&&(c="i, coords[1]"),this.userCode=`\n        ${i} strides = ${i}(${a});\n\n        void main() {\n          ${l} coords = getOutputCoords();\n          float sum = 0.0;\n          bool found = false;\n          for (int i = 0; i < ${e}; i++) {\n            int flattenedIndex = 0;\n            for (int j = 0; j < ${t}; j++) {\n              int index = round(getIndices(${u}));\n              flattenedIndex += index * ${t>1?"strides[j]":"strides"};\n            }\n            if (flattenedIndex == coords[0]) {\n              sum += getUpdates(${c});\n              found = true;\n            }\n          }\n          setOutput(mix(getDefaultValue(), sum, float(found)));\n        }\n      `}}function scatterNd(e){const{inputs:t,backend:n,attrs:r}=e,{indices:a,updates:s}=t,{shape:o}=r,{sliceRank:i,numUpdates:l,sliceSize:u,strides:c,outputSize:p}=calculateShapes(s,a,o),d=[p/u,u];if(0===p)return n.makeTensorInfo(o,a.dtype);const h=reshape({inputs:{x:a},backend:n,attrs:{shape:[l,i]}}),m=reshape({inputs:{x:s},backend:n,attrs:{shape:[l,u]}}),f=n.makeTensorInfo([],"float32",new Float32Array([0])),g=new ScatterProgram(l,i,h.shape.length,m.shape.length,c,d),$=n.runWebGLProgram(g,[m,h,f],m.dtype),y=reshape({inputs:{x:$},backend:n,attrs:{shape:o}});return n.disposeIntermediateTensorInfo(h),n.disposeIntermediateTensorInfo(m),n.disposeIntermediateTensorInfo($),n.disposeIntermediateTensorInfo(f),y}const scatterNdConfig={kernelName:ScatterNd,backendName:"webgl",kernelFunc:scatterNd};class SelectProgram{constructor(e,t,n){let r,a;if(this.variableNames=["c","a","b"],this.outputShape=t,n>4)throw Error(`Where for rank ${n} is not yet supported`);if(1===n)a="resRC",r="resRC";else{const n=["resRC.x","resRC.y","resRC.z","resRC.w"],s=[],o=[];for(let r=0;r<t.length;r++)o.push(`${n[r]}`),r<e&&s.push(`${n[r]}`);r=s.join(),a=o.join()}const s=getCoordsDataType(n);this.userCode=`\n      void main() {\n        ${s} resRC = getOutputCoords();\n        float cVal = getC(${r});\n        if (cVal >= 1.0) {\n          setOutput(getA(${a}));\n        } else {\n          setOutput(getB(${a}));\n        }\n      }\n    `}}function select(e){const{inputs:t,backend:n}=e,{condition:r,t:a,e:s}=t,o=new SelectProgram(r.shape.length,a.shape,a.shape.length);return n.runWebGLProgram(o,[r,a,s],upcastType(a.dtype,s.dtype))}const selectConfig={kernelName:Select,backendName:"webgl",kernelFunc:select},SELU=`\n  // Stable and Attracting Fixed Point (0, 1) for Normalized Weights.\n  // see: https://arxiv.org/abs/1706.02515\n  float scaleAlpha = ${SELU_SCALEALPHA};\n  float scale = ${SELU_SCALE};\n  return (x >= 0.0) ? scale * x : scaleAlpha * (exp(x) - 1.0);\n`,selu=unaryKernelFunc({opSnippet:SELU}),seluConfig={kernelName:Selu$1,backendName:"webgl",kernelFunc:selu},SIGMOID="return 1.0 / (1.0 + exp(-1.0 * x));",sigmoid=unaryKernelFunc({opSnippet:SIGMOID}),sigmoidConfig={kernelName:Sigmoid$1,backendName:"webgl",kernelFunc:sigmoid},SIGN="\n  if (isnan(x)) { return 0.0; }\n  return sign(x);\n",sign=unaryKernelFunc({opSnippet:SIGN}),signConfig={kernelName:Sign,backendName:"webgl",kernelFunc:sign},SIN=CHECK_NAN_SNIPPET_UNARY+"\n  return sin(x);\n",sin=unaryKernelFunc({opSnippet:SIN}),sinConfig={kernelName:Sin,backendName:"webgl",kernelFunc:sin},SINH="\n  float e2x = exp(x);\n  return (e2x - 1.0 / e2x) / 2.0;\n",sinh=unaryKernelFunc({opSnippet:SINH}),sinhConfig={kernelName:Sinh,backendName:"webgl",kernelFunc:sinh},SOFTPLUS="\n  float epsilon = 1.1920928955078125e-7;\n  float threshold = log(epsilon) + 2.0;\n\n  bool too_large = x > -threshold;\n  bool too_small = x < threshold;\n\n  float result;\n  float exp_x = exp(x);\n\n  if (too_large){\n    result = x;\n  }\n  else if (too_small){\n    result = exp_x;\n  }\n  else{\n    result = log(exp_x + 1.0);\n  }\n  return result;\n",softplus=unaryKernelFunc({opSnippet:SOFTPLUS}),softplusConfig={kernelName:Softplus$1,backendName:"webgl",kernelFunc:softplus},spaceToBatchND=e=>{const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{blockShape:s,paddings:o}=r;assert$4(a.shape.length<=4,()=>"spaceToBatchND for rank > 4 with a WebGL backend not implemented yet");const i=s.reduce((e,t)=>e*t),l=[[0,0]];l.push(...o);for(let e=1+s.length;e<a.shape.length;++e)l.push([0,0]);const u=[],c=padV2({inputs:{x:a},backend:n,attrs:{paddings:l,constantValue:0}}),p=getReshaped(c.shape,s,i,!1),d=getPermuted(p.length,s.length,!1),h=getReshapedPermuted(c.shape,s,i,!1),m=reshape({inputs:{x:c},backend:n,attrs:{shape:p}}),f=transpose({inputs:{x:m},backend:n,attrs:{perm:d}}),g=reshape({inputs:{x:f},backend:n,attrs:{shape:h}});return u.push(c),u.push(m),u.push(f),u.forEach(e=>n.disposeIntermediateTensorInfo(e)),g},spaceToBatchNDConfig={kernelName:SpaceToBatchND,backendName:"webgl",kernelFunc:spaceToBatchND};function sparseFillEmptyRows(e){const{inputs:t,backend:n}=e,{indices:r,values:a,denseShape:s,defaultValue:o}=t;if(1!==s.shape.length)throw new Error(`Dense shape must be a vector, saw:\n         ${s.shape}`);if(2!==r.shape.length)throw new Error(`Indices must be a matrix, saw:\n         ${r.shape}`);if(1!==a.shape.length)throw new Error(`Values must be a vector, saw:\n         ${a.shape}`);if(0!==o.shape.length)throw new Error(`Default value must be a scalar, saw:\n        ${o.shape}`);const i=n.readSync(r.dataId),l=n.readSync(a.dataId),u=n.readSync(s.dataId),c=n.readSync(o.dataId)[0],[p,d,h,m,f]=sparseFillEmptyRowsImplCPU(i,r.shape,r.dtype,l,a.dtype,u,c);return[n.makeTensorInfo(d,r.dtype,p),n.makeTensorInfo([d[0]],a.dtype,h),n.makeTensorInfo([m.length],"bool",new Uint8Array(m.map(e=>Number(e)))),n.makeTensorInfo([f.length],r.dtype,new Int32Array(f))]}const sparseFillEmptyRowsConfig={kernelName:SparseFillEmptyRows,backendName:"webgl",kernelFunc:sparseFillEmptyRows};function sparseReshape(e){const{inputs:t,backend:n}=e,{inputIndices:r,inputShape:a,newShape:s}=t;if(2!==r.shape.length)throw new Error(`Input indices should be a matrix but received shape ${r.shape}`);if(1!==a.shape.length)throw new Error(`Input shape should be a vector but received shape ${a.shape}`);if(1!==s.shape.length)throw new Error(`Target shape should be a vector but received shape ${s.shape}`);const o=Array.from(n.readSync(a.dataId)),i=n.readSync(r.dataId),l=Array.from(n.readSync(s.dataId)),[u,c,p]=sparseReshapeImplCPU(i,r.shape,r.dtype,o,l);return[n.makeTensorInfo(c,r.dtype,u),n.makeTensorInfo([p.length],s.dtype,new Int32Array(p))]}const sparseReshapeConfig={kernelName:SparseReshape,backendName:"webgl",kernelFunc:sparseReshape};function sparseSegmentMean(e){const{inputs:t,backend:n}=e,{data:r,indices:a,segmentIds:s}=t;if(r.shape.length<1)throw new Error("Data should be at least 1 dimensional but received scalar");if(1!==a.shape.length)throw new Error(`Indices should be a vector but received shape\n              ${a.shape}`);if(1!==s.shape.length)throw new Error(`Segment ids should be a vector but received shape\n              ${s.shape}`);const o=n.readSync(r.dataId),i=n.readSync(a.dataId),l=n.readSync(s.dataId),[u,c]=sparseSegmentReductionImplCPU(o,r.shape,r.dtype,i,l,!0);return n.makeTensorInfo(c,r.dtype,u)}const sparseSegmentMeanConfig={kernelName:SparseSegmentMean,backendName:"webgl",kernelFunc:sparseSegmentMean};function sparseSegmentSum(e){const{inputs:t,backend:n}=e,{data:r,indices:a,segmentIds:s}=t;if(r.shape.length<1)throw new Error("Data should be at least 1 dimensional but received scalar");if(1!==a.shape.length)throw new Error(`Indices should be a vector but received shape\n             ${a.shape}`);if(1!==s.shape.length)throw new Error(`Segment ids should be a vector but received shape\n             ${s.shape}`);const o=n.readSync(r.dataId),i=n.readSync(a.dataId),l=n.readSync(s.dataId),[u,c]=sparseSegmentReductionImplCPU(o,r.shape,r.dtype,i,l);return n.makeTensorInfo(c,r.dtype,u)}const sparseSegmentSumConfig={kernelName:SparseSegmentSum,backendName:"webgl",kernelFunc:sparseSegmentSum};function sparseToDense(e){const{inputs:t,backend:n,attrs:r}=e,{sparseIndices:a,sparseValues:s,defaultValue:o}=t,{outputShape:i}=r,{sliceRank:l,numUpdates:u,strides:c,outputSize:p}=calculateShapes(s,a,i),d=new ScatterProgram(u,l,a.shape.length,s.shape.length,c,[p,1],!1),h=n.runWebGLProgram(d,[s,a,o],s.dtype),m=reshape({inputs:{x:h},backend:n,attrs:{shape:i}});return n.disposeIntermediateTensorInfo(h),m}const sparseToDenseConfig={kernelName:SparseToDense,backendName:"webgl",kernelFunc:sparseToDense};function splitV(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{numOrSizeSplits:s,axis:o}=r,i=parseAxisParam(o,a.shape)[0],l=prepareSplitSize(a,s,i),u=new Array(a.shape.length).fill(0),c=a.shape.slice();return l.map(e=>{const t=[...c];t[i]=e;const r=slice({inputs:{x:a},backend:n,attrs:{begin:u,size:t}});return u[i]+=e,r})}const splitVConfig={kernelName:SplitV,backendName:"webgl",kernelFunc:splitV},SQRT="return sqrt(x);",sqrt=unaryKernelFunc({opSnippet:SQRT}),sqrtConfig={kernelName:Sqrt,backendName:"webgl",kernelFunc:sqrt},SQUARE="return x * x;",square=unaryKernelFunc({opSnippet:SQUARE}),squareConfig={kernelName:Square,backendName:"webgl",kernelFunc:square},SQUARED_DIFFERENCE="return (a - b) * (a - b);",squaredDifference=binaryKernelFunc({opSnippet:SQUARED_DIFFERENCE,packedOpSnippet:SQUARED_DIFFERENCE}),squaredDifferenceConfig={kernelName:SquaredDifference,backendName:"webgl",kernelFunc:squaredDifference};function step({inputs:e,attrs:t,backend:n}){const{x:r}=e,a=new UnaryOpProgram(r.shape,CHECK_NAN_SNIPPET$2+`\n    return x > 0.0 ? 1.0 : float(${t.alpha});\n  `);return n.runWebGLProgram(a,[r],r.dtype)}const stepConfig={kernelName:Step,backendName:"webgl",kernelFunc:step};class StridedSliceProgram{constructor(e,t,n){this.variableNames=["x"],this.outputShape=n;const r=n.length,a=getCoordsDataType(n.length),s=getCoordsDataType(n.length);let o="";if(1===r)o="coords * strides + begin";else{let e=0;o=n.map((t,r)=>(e++,1===n.length?`coords * strides[${r}] + begin[${r}]`:`coords[${e-1}] * strides[${r}] + begin[${r}]`)).join(",")}this.userCode=`\n      ${a} begin = ${a}(${e});\n      ${a} strides = ${a}(${t});\n\n      void main() {\n        ${s} coords = getOutputCoords();\n        setOutput(getX(${o}));\n      }\n    `}}function stridedSlice(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{begin:s,end:o,strides:i,beginMask:l,endMask:u,ellipsisMask:c,newAxisMask:p,shrinkAxisMask:d}=r,{nonStrided:h,$begin:m,$strides:f,size:g,newShape:$,outShape:y}=sliceInfo(a.shape,s,o,i,l,u,c,p,d),b=reshape({inputs:{x:a},backend:n,attrs:{shape:$}});let x;if(h){const e=slice({inputs:{x:b},backend:n,attrs:{begin:m,size:g}});x=reshape({inputs:{x:e},backend:n,attrs:{shape:y}}),n.disposeIntermediateTensorInfo(e)}else if(y.some(e=>0===e))x=n.makeTensorInfo(y,a.dtype,[]);else if(n.shouldExecuteOnCPU([b])){const e=n.texData.get(b.dataId),t=buffer(b.shape,b.dtype,e.values),r=stridedSliceImplCPU(y,t,f,m);x=n.makeTensorInfo(y,b.dtype,r.values)}else{const e=new StridedSliceProgram(m,f,y);x=n.runWebGLProgram(e,[b],b.dtype)}const v=reshape({inputs:{x},backend:n,attrs:{shape:y}});return n.disposeIntermediateTensorInfo(b),n.disposeIntermediateTensorInfo(x),v}const stridedSliceConfig={kernelName:StridedSlice,backendName:"webgl",kernelFunc:stridedSlice};function stringNGrams(e){const{inputs:t,backend:n,attrs:r}=e,{separator:a,nGramWidths:s,leftPad:o,rightPad:i,padWidth:l,preserveShortSequences:u}=r,{data:c,dataSplits:p}=t,d=n.readSync(c.dataId),h=n.readSync(p.dataId),[m,f]=stringNGramsImplCPU(d,h,a,s,o,i,l,u);return[n.makeTensorInfo([m.length],"string",m),n.makeTensorInfo(p.shape,"int32",f)]}const stringNGramsConfig={kernelName:StringNGrams,backendName:"webgl",kernelFunc:stringNGrams};function stringSplit(e){const{inputs:t,backend:n,attrs:r}=e,{skipEmpty:a}=r,{input:s,delimiter:o}=t;if("string"!==s.dtype)throw new Error("Input must be of datatype string");if(1!==s.shape.length)throw new Error(`Input must be a vector, got shape: ${s.shape}`);if(0!==o.shape.length)throw new Error(`Delimiter must be a scalar, got shape: ${o.shape}`);const i=n.readSync(s.dataId),l=n.readSync(o.dataId)[0],[u,c,p]=stringSplitImplCPU(i,l,a),d=c.length;return[n.makeTensorInfo([d,2],"int32",u),n.makeTensorInfo([d],"string",c),n.makeTensorInfo([2],"int32",new Int32Array(p))]}const stringSplitConfig={kernelName:StringSplit,backendName:"webgl",kernelFunc:stringSplit};function stringToHashBucketFast(e){const{inputs:t,backend:n,attrs:r}=e,{numBuckets:a}=r,{input:s}=t;if("string"!==s.dtype)throw new Error("Input must be of datatype string");if(a<=0)throw new Error("Number of buckets must be at least 1");const o=n.readSync(s.dataId),i=stringToHashBucketFastImplCPU(o,a);return n.makeTensorInfo(s.shape,"int32",i)}const stringToHashBucketFastConfig={kernelName:StringToHashBucketFast,backendName:"webgl",kernelFunc:stringToHashBucketFast},TAN="return tan(x);",tan=unaryKernelFunc({opSnippet:TAN}),tanConfig={kernelName:Tan,backendName:"webgl",kernelFunc:tan},TANH="\n  float e2x = exp(-2.0 * abs(x));\n  return sign(x) * (1.0 - e2x) / (1.0 + e2x);\n",tanh=unaryKernelFunc({opSnippet:TANH}),tanhConfig={kernelName:Tanh$1,backendName:"webgl",kernelFunc:tanh};class TileProgram{constructor(e,t){this.variableNames=["A"];const n=new Array(e.length);for(let r=0;r<n.length;r++)n[r]=e[r]*t[r];this.outputShape=n,this.rank=n.length;const r=getCoordsDataType(this.rank),a=getSourceCoords(e);this.userCode=`\n      void main() {\n        ${r} resRC = getOutputCoords();\n        setOutput(getA(${a}));\n      }\n    `}}function getSourceCoords(e){const t=e.length;if(t>5)throw Error(`Tile for rank ${t} is not yet supported`);if(1===t)return`imod(resRC, ${e[0]})`;const n=["resRC.x","resRC.y","resRC.z","resRC.w","resRC.u"],r=[];for(let t=0;t<e.length;t++)r.push(`imod(${n[t]}, ${e[t]})`);return r.join()}function tile(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{reps:s}=r;if("string"===a.dtype||a.shape.length>5){const e=n.readSync(a.dataId),t="string"===a.dtype?e.map(e=>decodeString(e)):e,r=buffer(a.shape,a.dtype,t),o=tileImplCPU(r,s);return n.makeTensorInfo(o.shape,o.dtype,o.values)}const o=new TileProgram(a.shape,s);return n.runWebGLProgram(o,[a],a.dtype)}const tileConfig={kernelName:Tile,backendName:"webgl",kernelFunc:tile};class SwapProgram{constructor(e){this.variableNames=["x","indices"],this.customUniforms=[{name:"n",type:"int"},{name:"firstPass",type:"int"},{name:"negativeInf",type:"float"},{name:"dir",type:"int"},{name:"inc",type:"int"}],this.outputShape=e,this.userCode="\n       void main() {\n         ivec2 coords = getOutputCoords();\n         int batch = coords[0];\n         int elemIdx = coords[1];\n\n         // We compare elements pair-wise within a group of size 2 * inc.\n         // The comparing rule for each group alternates between ascending\n         // and descending. Within each group, we compare each pair at\n         // positions i and i+inc. To decide whether an element at position i\n         // is x0 or x1, we mod it by 2 * inc, if the result is smaller than\n         // inc, it is in the first half of the group, we denote it as x0,\n         // otherwise we denote it as x1.\n         // For example, as shown in the Bitonic top K paper referenced above,\n         // Figure5(a) shows that element[1] is in the\n         // second half of the group when group size is 2, but it is in the\n         // first half of the group when group size is 4.\n\n         bool isFirstInPair = imod(elemIdx, 2 * inc) < inc;\n         int i = isFirstInPair ? elemIdx : elemIdx - inc;\n\n         int i0 = firstPass == 1 ? i : int(getIndices(batch, i));\n         int i1 = firstPass == 1 ? i + inc : int(getIndices(batch, i + inc));\n         float x0 = i0 < n ? getX(batch, i0) : negativeInf;\n         float x1 = i1 < n ? getX(batch, i1) : negativeInf;\n\n         // Denotes which direction indices are in (ascending or descending).\n         bool reverse = imod(elemIdx, 2 * dir) >= dir;\n         bool isGreater = x0 > x1 || (x0 == x1 && i1 > i0);\n         if (reverse == isGreater) { // Elements in opposite order of direction\n           int iTemp = i0;\n           i0 = i1;\n           i1 = iTemp;\n         }\n         if (isFirstInPair) {\n            setOutput(float(i0));\n         } else {\n            setOutput(float(i1));\n         }\n       }\n     "}}class MergeProgram{constructor(e){this.variableNames=["x","indices"],this.customUniforms=[{name:"n",type:"int"},{name:"firstPass",type:"int"},{name:"k",type:"int"}],this.outputShape=e,this.userCode="\n    void main() {\n         // Takes max of indices (0, k), (1, k + 1), (2, k + 2) ...\n         ivec2 coords = getOutputCoords();\n         int batch = coords[0];\n         int elemIdx = coords[1];\n\n         // The output size is half of the previous size.\n         // If the previous sequence is | | | | _ _ _ _  | | | |  _ _ _ _ (k=4),\n         // we only need to output the indices at positions |, the indices at\n         // positions _ can be thrown away, see Figure5(b) After Phase 2\n         // (Merge phase) in the Bitonic Top K paper referenced above.\n         // For example, the paper shows we only need to output the orange bars.\n         // The output sequence should look like this | | | | | | | |.\n         // Because the sequence is halved, to map the output index back\n         // to the previous sequence to find the corresponding value,\n         // we need to double the index. When we double the index,\n         // we basically interpolate a position, so 2i looks like\n         // | _ | _ | _ | _ | _ | _ | _. We move the | to the first k position\n         // of each 2k positions by - elemIdx % k. E.g. for output at\n         // index 4,5,6,7, we want to get the corresponding element at\n         // original index 8,9,10,11, for output at index 8,9,10,11,\n         // we want to get the corresponding element at original index\n         // 16,17,18,19, so on and so forth.\n\n         int i = elemIdx < k ? elemIdx : (elemIdx * 2 - imod(elemIdx, k));\n         int i0 = firstPass == 1 ? i : int(getIndices(batch, i));\n         int i1 = firstPass == 1 ? i + k : int(getIndices(batch, i + k));\n\n         float x0 = getX(batch, i0);\n         float x1 = i1 < n ? getX(batch, i1) : x0;\n\n         setOutput(x0 >= x1 ? float(i0) : float(i1));\n       }\n     "}}function disposeIntermediateTensorInfoOrNull(e,t){null!==t&&e.disposeIntermediateTensorInfo(t)}function roundUpToPow2(e){let t=1;for(;t<e;)t*=2;return t}function topK(e){const{inputs:t,backend:n,attrs:r}=e,{x:a}=t,{k:s,sorted:o}=r,i=env().getNumber("TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD"),l=env().getNumber("TOPK_K_CPU_HANDOFF_THRESHOLD"),u=a.shape,c=u[u.length-1];if(n.shouldExecuteOnCPU([a])||c<i||s>l){const e=n.readSync(a.dataId),[t,r]=topKImplCPU(e,u,a.dtype,s,o);return[n.makeTensorInfo(t.shape,t.dtype,t.values),n.makeTensorInfo(r.shape,r.dtype,r.values)]}if(0===s)return u[u.length-1]=0,[n.makeTensorInfo(u,a.dtype,[]),n.makeTensorInfo(u,"int32",[])];if(1===c)return[a,fill({attrs:{shape:u,dtype:"int32",value:0},backend:n})];const p=n.texData.get(a.dataId),d=null!==p&&p.isPacked,h=d?n.unpackTensor(a):a,m=sizeFromShape(u)/c,f=reshape({inputs:{x:h},attrs:{shape:[m,c]},backend:n});d&&disposeIntermediateTensorInfoOrNull(n,h);const g=roundUpToPow2(s),$=roundUpToPow2(c);let y=null;const b=()=>null===y?[f,f]:[f,y],x=(e,t,r)=>{const a=b(),s=new SwapProgram(r),o=y;y=n.runWebGLProgram(s,a,"int32",[[c],[null===y?1:0],[Number.NEGATIVE_INFINITY],[e],[t]]),disposeIntermediateTensorInfoOrNull(n,o)};for(let e=1;e<g;e*=2){const t=2*e;for(let n=e;n>=1;n/=2)x(t,n,[m,$])}for(let e=$;e>g;e/=2){const t=b(),r=new MergeProgram([m,e/2]),a=y;y=n.runWebGLProgram(r,t,"int32",[[c],[null===y?1:0],[g]]),disposeIntermediateTensorInfoOrNull(n,a);const s=g/2,o=2*s;for(let e=s;e>=1;e/=2)x(o,e,y.shape)}let v=y;y=slice({inputs:{x:y},backend:n,attrs:{begin:0,size:[m,s]}}),disposeIntermediateTensorInfoOrNull(n,v);let I=gatherV2({inputs:{x:f,indices:y},backend:n,attrs:{axis:1,batchDims:1}});disposeIntermediateTensorInfoOrNull(n,f);const C=u.slice(0,-1);C.push(s),v=y,y=reshape({inputs:{x:y},attrs:{shape:C},backend:n}),disposeIntermediateTensorInfoOrNull(n,v);const S=I;return I=reshape({inputs:{x:I},attrs:{shape:C},backend:n}),disposeIntermediateTensorInfoOrNull(n,S),[I,y]}const topKConfig={kernelName:TopK,backendName:"webgl",kernelFunc:topK};class TransformProgram{constructor(e,t,n,r,a,s){this.variableNames=["Image","Transforms"],this.outputShape=s;const o="nearest"===n?1:2;let i;switch(r){case"constant":i=1;break;case"reflect":i=2;break;case"wrap":i=3;break;case"nearest":i=4;break;default:i=1}this.userCode=`\n            float mapCoord(float outCoord, float len) {\n              float inCoord = outCoord;\n              if(${i} == 2) {\n                if (inCoord < 0.0) {\n                  if (len <= 1.0) {\n                    inCoord = 0.0;\n                  } else {\n                    float sz2 = 2.0 * len;\n                    if (inCoord < sz2) {\n                      inCoord = sz2 * float(int(float(-inCoord / sz2))) +\n                      inCoord;\n                    }\n                    inCoord = inCoord < -len ? inCoord + sz2 : -inCoord - 1.0;\n                  }\n                } else if (inCoord > len - 1.0) {\n                  if (len <= 1.0) {\n                    inCoord = 0.0;\n                  } else {\n                    float sz2 = 2.0 * len;\n                    inCoord -= sz2 * float(int(float(inCoord / sz2)));\n                    if (inCoord >= len) {\n                      inCoord = sz2 - inCoord - 1.0;\n                    }\n                  }\n                }\n                return clamp(inCoord, 0.0, len - 1.0);\n              } else if (${i} == 3) {\n                if (inCoord < 0.0) {\n                  if (len <= 1.0) {\n                    inCoord = 0.0;\n                  } else {\n                    float sz = len - 1.0;\n                    inCoord += len * (float(int(float(-inCoord / sz))) + 1.0);\n                  }\n                } else if (inCoord > len - 1.0) {\n                  if (len <= 1.0) {\n                    inCoord = 0.0;\n                  } else {\n                    float sz = len - 1.0;\n                    inCoord -= len * float(int(float(inCoord / sz)));\n                  }\n                }\n                return clamp(inCoord, 0.0, len - 1.0);\n              } else if (${i} == 4) {\n                return clamp(outCoord, 0.0, len - 1.0);\n              } else {\n                return outCoord;\n              }\n            }\n\n            float readWithFillValue(int batch, int coordY, int coordX,\n              int channel) {\n              float outputValue;\n              if (0 <= coordY && coordY < ${e} && 0 <= coordX && coordX < ${t}) {\n                  outputValue = getImage(batch, coordY, coordX, channel);\n              } else {\n                outputValue = float(${a});\n              }\n              return outputValue;\n            }\n\n            void main() {\n              ivec4 coords = getOutputCoords();\n              float outputValue;\n              int batch = coords[0];\n              int x = coords[2];\n              int y = coords[1];\n              int channel = coords[3];\n              float xf = float(x);\n              float yf = float(y);\n              float a1 = getTransforms(batch, 0);\n              float a2 = getTransforms(batch, 1);\n              float a3 = getTransforms(batch, 2);\n              float b1 = getTransforms(batch, 3);\n              float b2 = getTransforms(batch, 4);\n              float b3 = getTransforms(batch, 5);\n              float c1 = getTransforms(batch, 6);\n              float c2 = getTransforms(batch, 7);\n              float projection = c1 * xf + c2 * yf + 1.0;\n              if (projection == 0.0) {\n                outputValue = float(${a});\n              } else {\n                float inX = (a1 * xf + a2 * yf + a3) / projection;\n                float inY = (b1 * xf + b2 * yf + b3) / projection;\n                float mapX = mapCoord(inX, float(${t}));\n                float mapY = mapCoord(inY, float(${e}));\n\n                if (${o} == 1) {\n                  int coordY = int(round(mapY));\n                  int coordX = int(round(mapX));\n                  outputValue = readWithFillValue(batch, coordY, coordX,\n                    channel);\n                } else {\n                  float yFloor = floor(mapY);\n                  float xFloor = floor(mapX);\n                  float yCeil = yFloor + 1.0;\n                  float xCeil = xFloor + 1.0;\n                  float valueYFloor = (xCeil - mapX) *\n                  readWithFillValue(batch, int(yFloor), int(xFloor), channel) +\n                  (mapX - xFloor) *\n                  readWithFillValue(batch, int(yFloor), int(xCeil), channel);\n                  float valueYCeil = (xCeil - mapX) *\n                  readWithFillValue(batch, int(yCeil), int(xFloor), channel) +\n                  (mapX - xFloor) *\n                  readWithFillValue(batch, int(yCeil), int(xCeil), channel);\n                  outputValue = (yCeil - mapY) * valueYFloor +\n                  (mapY - yFloor) * valueYCeil;\n                }\n              }\n              setOutput(outputValue);\n            }\n        `}}function transform(e){const{inputs:t,backend:n,attrs:r}=e,{image:a,transforms:s}=t,{interpolation:o,fillMode:i,fillValue:l,outputShape:u}=r,[c,p,d,h]=a.shape,[m,f]=null!=u?u:[p,d],g=new TransformProgram(p,d,o,i,l,[c,m,f,h]);return n.runWebGLProgram(g,[a,s],"float32")}const transformConfig={kernelName:Transform,backendName:"webgl",kernelFunc:transform};function unique(e){const{inputs:t,attrs:n,backend:r}=e,{axis:a}=n,{x:s}=t;assertNotComplex(s,"unique"),console.warn("WARNING: ","UI might be locked temporarily as data is being downloaded");const o=r.readSync(s.dataId),{outputValues:i,outputShape:l,indices:u}=uniqueImplCPU(o,a,s.shape,s.dtype);return[r.makeTensorInfo(l,s.dtype,i),r.makeTensorInfo([u.length],"int32",u)]}const uniqueConfig={kernelName:Unique,backendName:"webgl",kernelFunc:unique};function unpack(e){const{inputs:t,backend:n,attrs:r}=e,{value:a}=t;let{axis:s}=r;s<0&&(s+=a.shape.length);const o=a,i=o.shape.length,l=a.shape[s],u=new Array(i-1);let c=0;for(let e=0;e<i;e++)e!==s&&(u[c++]=o.shape[e]);const p=[],d=new Array(i).fill(0),h=o.shape.slice();h[s]=1;const m=new Array(l);for(let e=0;e<m.length;e++){d[s]=e;const t=slice({inputs:{x:o},backend:n,attrs:{begin:d,size:h}}),r=reshape({inputs:{x:t},backend:n,attrs:{shape:u}});m[e]=r,p.push(t)}return p.forEach(e=>n.disposeIntermediateTensorInfo(e)),m}const unpackConfig={kernelName:Unpack,backendName:"webgl",kernelFunc:unpack};class SegmentOpProgram{constructor(e,t){this.variableNames=["x","segmentIds"];const n=e.windowSize,r=e.batchSize,a=e.inSize,s=e.numSegments,o=s*Math.ceil(a/n);this.outputShape=[r,o];const i=4*Math.floor(n/4),l=n%4,u="\n        sumValue += dot(values, segFilter);\n    ";let c="";a%n>0&&(c=`\n        if (inIdx < 0 || inIdx >= ${a}) {\n          return initializationValue;\n        }\n      `);let p="";a%n>0&&(p=`\n        if (inIdx < 0 || inIdx >= ${a}) {\n          return -1.0;\n        }\n      `),this.userCode=`\n      const float initializationValue = 0.0;\n\n      float getValue(int batch, int inIdx) {\n        ${c}\n        return getX(batch, inIdx);\n      }\n\n      float getSegmentIdAtIndex(int inIdx) {\n        ${p}\n        return getSegmentIds(inIdx);\n      }\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n        int outIdx = coords[1];\n        int inOffset = int(floor(float(outIdx) / float(\n          ${s})) * float(${n}));\n        int currentSeg = int(mod(float(outIdx), float(${s})));\n\n        float sumValue = 0.0;\n\n        for (int i = 0; i < ${i}; i += 4) {\n          int inIdx = inOffset + i;\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            getValue(batch, inIdx + 3)\n          );\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 3)) == currentSeg ? 1 : 0\n          );\n\n          ${u}\n        }\n\n        int inIdx = inOffset + ${i};\n        if (${1===l}) {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            initializationValue,\n            initializationValue,\n            initializationValue\n          );\n\n          int inIdxSeg = int(getSegmentIdAtIndex(inIdx));\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            0,\n            0,\n            0\n          );\n\n          ${u}\n        } else if (${2===l}) {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            initializationValue,\n            initializationValue\n          );\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\n              0,\n              0\n          );\n\n          ${u}\n        } else if (${3===l}) {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            initializationValue\n          );\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,\n            0\n          );\n\n          ${u}\n        }\n        setOutput(sumValue);\n      }\n    `}}function unsortedSegmentSum(e){const{inputs:t,backend:n,attrs:r}=e,{x:a,segmentIds:s}=t,{numSegments:o}=r,i=a.shape.length,l=[];let u=0;const c=getAxesPermutation([u],i);let p=a;null!=c&&(p=transpose({inputs:{x:a},backend:n,attrs:{perm:c}}),l.push(p),u=getInnerMostAxes(1,i)[0]);const d=computeOutShape(p.shape,u,o),h=sizeFromShape([p.shape[u]]),m=reshape({inputs:{x:p},backend:n,attrs:{shape:[-1,h]}});l.push(m);const f=sumOutType(a.dtype),g=(e,t,r,a,s)=>{const o=e.shape[0],i=e.shape[1],u=segOpComputeOptimalWindowSize(i,s),c=new SegmentOpProgram({windowSize:u,inSize:i,batchSize:o,numSegments:s},t),p=n.compileAndRun(c,[e,r],a);if(l.push(p),p.shape[1]===s)return p;const d=range$1({backend:n,attrs:{start:0,stop:s,step:1,dtype:"float32"}}),h=tile({inputs:{x:d},backend:n,attrs:{reps:[i/u]}});return l.push(d),l.push(h),g(p,t,h,a,s)},$=reshape({inputs:{x:g(m,"unsortedSegmentSum",s,f,o)},backend:n,attrs:{shape:d}});let y=$;if(null!=c){l.push($);const e=getUndoAxesPermutation(c);y=transpose({inputs:{x:y},backend:n,attrs:{perm:e}})}return l.forEach(e=>n.disposeIntermediateTensorInfo(e)),y}const unsortedSegmentSumConfig={kernelName:UnsortedSegmentSum,backendName:"webgl",kernelFunc:unsortedSegmentSum},kernelConfigs=[LRNConfig,LRNGradConfig,_fusedMatMulConfig,absConfig,acosConfig,acoshConfig,addConfig,addNConfig,allConfig,anyConfig,argMaxConfig,argMinConfig,asinConfig,asinhConfig,atan2Config,atanConfig,atanhConfig,avgPool3DConfig,avgPoolConfig,avgPoolGrad3DConfig,avgPoolGradConfig,batchMatMulConfig,batchNormConfig,batchToSpaceNDConfig,bincountConfig,castConfig,ceilConfig,clipByValueConfig,complexAbsConfig,complexConfig,concatConfig,conv2DBackpropFilterConfig,conv2DBackpropInputConfig,conv2DConfig,conv3DBackpropFilterV2Config,conv3DBackpropInputConfig,conv3DConfig,cosConfig,coshConfig,cropAndResizeConfig,cumsumConfig,denseBincountConfig,depthToSpaceConfig,depthwiseConv2dNativeBackpropFilterConfig,depthwiseConv2dNativeBackpropInputConfig,depthwiseConv2dNativeConfig,diagConfig,dilation2DConfig,einsumConfig,eluConfig,eluGradConfig,equalConfig,erfConfig,expConfig,expandDimsConfig,expm1Config,fftConfig,fillConfig,flipLeftRightConfig,floorConfig,floorDivConfig,fromPixelsConfig,fusedConv2DConfig,fusedDepthwiseConv2DConfig,gatherNdConfig,gatherV2Config,greaterConfig,greaterEqualConfig,identityConfig,ifftConfig,imagConfig,isFiniteConfig,isInfConfig,isNaNConfig,leakyReluConfig,lessConfig,lessEqualConfig,linSpaceConfig,log1pConfig,logConfig,logicalAndConfig,logicalNotConfig,logicalOrConfig,maxConfig,maxPool3DConfig,maxPoolConfig,maxPoolGrad3DConfig,maxPoolGradConfig,maxPoolWithArgmaxConfig,maximumConfig,meanConfig,minConfig,minimumConfig,mirrorPadConfig,modConfig,multinomialConfig,multiplyConfig,negConfig,nonMaxSuppressionV3Config,nonMaxSuppressionV4Config,nonMaxSuppressionV5Config,notEqualConfig,oneHotConfig,onesLikeConfig,packConfig,padV2Config,powConfig,preluConfig,prodConfig,rangeConfig,realConfig,realDivConfig,reciprocalConfig,relu6Config,reluConfig,reshapeConfig,resizeBilinearConfig,resizeBilinearGradConfig,resizeNearestNeighborConfig,resizeNearestNeighborGradConfig,reverseConfig,rotateWithOffsetConfig,roundConfig,rsqrtConfig,scatterNdConfig,selectConfig,seluConfig,sigmoidConfig,signConfig,sinConfig,sinhConfig,sliceConfig,softmaxConfig,softplusConfig,spaceToBatchNDConfig,sparseFillEmptyRowsConfig,sparseReshapeConfig,sparseSegmentMeanConfig,sparseSegmentSumConfig,sparseToDenseConfig,splitVConfig,sqrtConfig,squareConfig,squaredDifferenceConfig,stepConfig,stridedSliceConfig,stringNGramsConfig,stringSplitConfig,stringToHashBucketFastConfig,subConfig,sumConfig,tanConfig,tanhConfig,tileConfig,topKConfig,transformConfig,transposeConfig,uniqueConfig,unpackConfig,unsortedSegmentSumConfig,zerosLikeConfig];for(const e of kernelConfigs)registerKernel(e);const version$1="3.8.0",version={"tfjs-core":version$7,"tfjs-backend-cpu":version$3,"tfjs-backend-webgl":version$2,"tfjs-data":version$4,"tfjs-layers":version$6,"tfjs-converter":version$5,tfjs:version$1};var dist={__proto__:null,data:index,version,AdadeltaOptimizer,AdagradOptimizer,AdamOptimizer,AdamaxOptimizer,MomentumOptimizer,Optimizer,RMSPropOptimizer,SGDOptimizer,Tensor,TensorBuffer,Variable,get Rank(){return Rank},sumOutType,upcastType,get Reduction(){return Reduction},customGrad,grad,grads,valueAndGrad,valueAndGrads,variableGrads,Environment,env,get ENV(){return ENV$2},nextFrame,KernelBackend,DataStorage,abs:abs$2,acos:acos$2,acosh:acosh$2,add:add$2,addN:addN$2,all:all$2,any:any$2,argMax:argMax$2,argMin:argMin$2,asin:asin$2,asinh:asinh$2,atan:atan$2,atan2:atan2$2,atanh:atanh$2,avgPool:avgPool$2,avgPool3d:avgPool3d$1,basicLSTMCell,batchToSpaceND:batchToSpaceND$2,batchNorm:batchNorm$2,batchNorm2d,batchNorm3d,batchNorm4d,bincount:bincount$2,broadcastTo,buffer,cast:cast$3,ceil:ceil$2,clipByValue:clipByValue$1,clone,complex:complex$2,concat:concat$2,concat1d,concat2d,concat3d,concat4d,conv1d:conv1d$1,conv2d:conv2d$3,conv2dTranspose:conv2dTranspose$1,conv3d:conv3d$1,conv3dTranspose:conv3dTranspose$1,cos:cos$2,cosh:cosh$2,cumsum:cumsum$2,denseBincount:denseBincount$2,depthToSpace:depthToSpace$2,depthwiseConv2d:depthwiseConv2d$3,diag:diag$2,dilation2d,div:div$1,divNoNan,dot:dot$2,einsum:einsum$2,elu:elu$4,equal:equal$2,erf:erf$2,exp:exp$2,expandDims:expandDims$3,expm1:expm1$2,eye,fill:fill$2,floor:floor$2,floorDiv:floorDiv$2,gather:gather$1,greater:greater$3,greaterEqual:greaterEqual$2,imag:imag$2,isFinite:isFinite$3,isInf:isInf$2,isNaN:isNaN$3,leakyRelu:leakyRelu$2,less:less$3,lessEqual:lessEqual$2,linspace,localResponseNormalization,log:log$3,log1p:log1p$2,logSigmoid,logSoftmax,logSumExp,logicalAnd:logicalAnd$2,logicalNot:logicalNot$2,logicalOr:logicalOr$2,logicalXor,matMul:matMul$1,max:max$3,maxPool:maxPool$2,maxPool3d:maxPool3d$1,maxPoolWithArgmax,maximum:maximum$3,mean:mean$1,meshgrid,min:min$3,minimum:minimum$3,mirrorPad:mirrorPad$1,mod:mod$2,moments,mul,multiRNNCell,multinomial:multinomial$2,neg:neg$2,notEqual:notEqual$2,oneHot:oneHot$2,ones:ones$1,onesLike:onesLike$2,outerProduct,pad,pad1d,pad2d,pad3d,pad4d,pool:pool$1,pow:pow$2,prelu:prelu$3,print,prod:prod$2,rand,randomGamma,randomNormal:randomNormal$2,randomUniform:randomUniform$1,range:range$4,real:real$2,reciprocal:reciprocal$2,relu:relu$3,relu6:relu6$2,reshape:reshape$3,reverse:reverse$2,reverse1d,reverse2d,reverse3d,reverse4d,round:round$2,rsqrt:rsqrt$2,scalar,selu:selu$2,separableConv2d:separableConv2d$1,setdiff1dAsync,sigmoid:sigmoid$2,sign:sign$2,sin:sin$2,sinh:sinh$2,slice:slice$2,slice1d,slice2d,slice3d,slice4d,softmax:softmax$3,softplus:softplus$2,spaceToBatchND:spaceToBatchND$2,fft:fft$2,ifft:ifft$2,irfft,rfft,split:split$2,sqrt:sqrt$2,square:square$2,squaredDifference:squaredDifference$2,squeeze,stack,step:step$2,stridedSlice:stridedSlice$2,sub:sub$2,sum:sum$2,tan:tan$2,tanh:tanh$2,tensor,tensor1d,tensor2d,tensor3d,tensor4d,tensor5d,tensor6d,tile:tile$3,topk,truncatedNormal:truncatedNormal$1,unique:unique$3,unsortedSegmentSum:unsortedSegmentSum$2,unstack,variable,where,whereAsync,zeros:zeros$2,zerosLike:zerosLike$2,op,OP_SCOPE_SUFFIX,booleanMaskAsync,transpose:transpose$2,norm,movingAverage,scatterND,sparseToDense:sparseToDense$2,gatherND,dropout:dropout$2,enclosingPowerOfTwo,cosineWindow,inTopKAsync,image:image$1,linalg,losses,spectral:spectral$1,fused:fused_ops,signal,sparse:sparse$1,string:string$1,train,enableProdMode,enableDebugMode,disableDeprecationWarnings,deprecationWarn,disposeVariables,engine,memory,profile,tidy,dispose,keep,time,setBackend,ready,getBackend,removeBackend,findBackend,findBackendFactory,registerBackend,backend,setPlatform,getKernel,getGradient,getKernelsForBackend,registerKernel,registerGradient,unregisterKernel,unregisterGradient,copyRegisteredKernels,Abs,Acos,Acosh,Add:Add$1,AddN,All,Any,ArgMax,ArgMin,Asin,Asinh,Atan,Atanh,Atan2,AvgPool,AvgPoolGrad,AvgPool3D,AvgPool3DGrad,BatchMatMul,BatchToSpaceND,Bincount,BroadcastTo,Cast,Ceil,ClipByValue,Complex,ComplexAbs,Concat,Conv2D:Conv2D$1,Conv2DBackpropFilter,Conv2DBackpropInput,Conv3D:Conv3D$1,Conv3DBackpropFilterV2,Conv3DBackpropInputV2,Cos,Cosh,Cumsum,CropAndResize,DenseBincount,DepthToSpace,DepthwiseConv2dNative,DepthwiseConv2dNativeBackpropFilter,DepthwiseConv2dNativeBackpropInput,Diag,Dilation2D,Dilation2DBackpropInput,Dilation2DBackpropFilter,RealDiv,Einsum,Elu:Elu$1,EluGrad,Erf,Equal,Exp,ExpandDims,Expm1,FFT,Fill,FlipLeftRight,Floor,FloorDiv,FusedBatchNorm,GatherV2,GatherNd,Greater,GreaterEqual,Identity:Identity$1,IFFT,Imag,IsFinite,IsInf,IsNan,LeakyRelu,Less,LessEqual,LinSpace,Log,Log1p,LogicalAnd,LogicalNot,LogicalOr,LogSoftmax:LogSoftmax$1,LRN,LRNGrad,Max,Maximum:Maximum$1,MaxPool,MaxPoolGrad,MaxPool3D,MaxPool3DGrad,MaxPoolWithArgmax,Mean,Min,Minimum:Minimum$1,MirrorPad,Mod,Multinomial,Multiply:Multiply$1,Neg,NotEqual,NonMaxSuppressionV3,NonMaxSuppressionV4,NonMaxSuppressionV5,OnesLike,OneHot,Pack,PadV2,Pool,Pow,Prelu,Prod,Range,Real,Reciprocal,Relu:Relu$1,Reshape:Reshape$1,ResizeNearestNeighbor,ResizeNearestNeighborGrad,ResizeBilinear,ResizeBilinearGrad,Relu6:Relu6$1,Reverse,Round,Rsqrt,ScatterNd,Select,Selu:Selu$1,Slice,Sin,Sinh,Sign,Sigmoid:Sigmoid$1,Softplus:Softplus$1,Sqrt,Sum,SpaceToBatchND,SplitV,Softmax:Softmax$2,SparseFillEmptyRows,SparseReshape,SparseSegmentMean,SparseSegmentSum,SparseToDense,SquaredDifference,Square,StridedSlice,StringNGrams,StringSplit,StringToHashBucketFast,Sub,Tan,Tanh:Tanh$1,Tile,TopK,Transform,Transpose,Unique,Unpack,UnsortedSegmentSum,ZerosLike,Step,FromPixels,RotateWithOffset,_FusedMatMul,FusedConv2D,FusedDepthwiseConv2D,version_core:version$7,browser,io,math,serialization,test_util,util,backend_util,tensor_util,slice_util,gather_util:gather_nd_util,scatter_util:scatter_nd_util,device_util,kernel_impls,CallbackList,CustomCallback,History,Callback,callbacks,EarlyStopping,InputSpec,SymbolicTensor,LayersModel,input,loadLayersModel,model,registerCallbackConstructor,sequential,RNN,Sequential,LayerVariable,version_layers:version$6,constraints:exports_constraints,initializers:exports_initializers,layers:exports_layers,metrics:exports_metrics,models:exports_models,regularizers:exports_regularizers,GraphModel,loadGraphModel,deregisterOp,registerOp,version_converter:version$5};const basetable=new Uint16Array(512),shifttable=new Uint8Array(512),mantissatable=new Uint32Array(2048),offsettable=new Uint16Array(64),exponenttable=new Uint32Array(64);let inited=!1;function init(){inited=!0;for(let e=0;e<256;++e){const t=e-127;t<-24?(basetable[0|e]=0,basetable[256|e]=32768,shifttable[0|e]=24,shifttable[256|e]=24):t<-14?(basetable[0|e]=1024>>-t-14,basetable[256|e]=1024>>-t-14|32768,shifttable[0|e]=-t-1,shifttable[256|e]=-t-1):t<=15?(basetable[0|e]=t+15<<10,basetable[256|e]=t+15<<10|32768,shifttable[0|e]=13,shifttable[256|e]=13):t<128?(basetable[0|e]=31744,basetable[256|e]=64512,shifttable[0|e]=24,shifttable[256|e]=24):(basetable[0|e]=31744,basetable[256|e]=64512,shifttable[0|e]=13,shifttable[256|e]=13)}for(let t=1;t<2048;++t)mantissatable[t]=t<1024?e(t):939524096+(t-1024<<13);exponenttable[32]=2147483648,exponenttable[31]=1199570944,exponenttable[63]=3347054592;for(let e=1;e<=30;++e)exponenttable[e]=e<<23;for(let e=33;e<=62;++e)exponenttable[e]=2147483648+(e-32<<23);for(let e=1;e<offsettable.length;++e)offsettable[e]=1024;function e(e){let t=e<<13,n=0;for(;!(8388608&t);)n-=8388608,t<<=1;return t&=-8388609,n+=947912704,(t|n)>>>0}offsettable[32]=0}function float32ToUInt32(e){const t=new Float32Array(1);return t[0]=e,new Uint32Array(t.buffer)[0]}function float16toUInt16(e){const t=float32ToUInt32(e);return inited||init(),basetable[t>>23&511]|(8388607&t)>>shifttable[t>>23&511]}function float16AsUintToFloat(e){inited||init();const t=mantissatable[offsettable[e>>10]+(1023&e)]+exponenttable[e>>10],n=new Uint32Array(1);return n[0]=t,new Float32Array(n.buffer)[0]}function assert(e,t="Assertion failed"){if(!e)throw new Error(t)}function userError(e){let t=new Error(e);throw t.isUserError=!0,t}function lookup(e,t){return e.hasOwnProperty(t)?e[t]:null}function oops(e="OOPS"){throw new Error(e)}function endsWith(e,t){return!(e.length<t.length||0!=t.length&&e.slice(-t.length)!=t)}function mapMap(e,t){let n={};return Object.keys(e).forEach(r=>n[r]=t(r,e[r])),n}function pushRange(e,t){for(let n=0;n<t.length;++n)e.push(t[n])}function range(e){let t=[];for(let n=0;n<e;++n)t.push(n);return t}let seed=218109047;function randomUint32(){let e=seed;return e^=e<<13,e^=e>>>17,e^=e<<5,e>>>=0,seed=e,e}function randomUFloat(){return randomUint32()/4294967296}function randomSFloat(){return 2*randomUFloat()-1}function flatClone(e){const t=e,n={};for(const e of Object.keys(t))n[e]=t[e];return n}function lf(e,...t){return e.replace(/{(\d+)}/g,(e,n)=>t[+n])}let badNameError=emitErr("opcode name doesn't match","<name>");class Instruction{constructor(e,t,n,r,a){this.opcode=n,this.mask=r,this.is32bit=a,this.canBeShared=!1,assert((n&r)==n),this.ei=e,this.code=t.replace(/\s+/g," "),this.friendlyFmt=t.replace(/\$\w+/g,e=>this.ei.encoders[e]?this.ei.encoders[e].pretty:e);let s=tokenize(t);this.name=s[0],this.args=s.slice(1)}emit(e){const t=e.words;if(t[0]!=this.name)return badNameError;let n=this.opcode,r=1,a=0,s=[],o=null,i=null,l=null;const u=this.ei.is32bit(this)&&!this.is32bit;for(let c=0;c<this.args.length;++c){let p=this.args[c],d=t[r++];if("$"==p[0]){let c=this.ei.encoders[p],h=null;if(c.isRegister){if(h=this.ei.registerNo(d,c),null==h)return emitErr("expecting register name",d);this.ei.isPush(this.opcode)?a++:this.ei.isPop(this.opcode)&&a--}else if(c.isImmediate){if(d=d.replace(/^#/,""),h=e.bin.parseOneInt(d),null==h)return emitErr("expecting number",d);this.ei.isAddSP(this.opcode)?a=-h/this.ei.wordSize():this.ei.isSubSP(this.opcode)&&(a=h/this.ei.wordSize())}else if(c.isRegList){if("{"!=d)return emitErr("expecting {",d);for(h=0;"}"!=t[r];){if(d=t[r++],!d)return emitErr("expecting }",t[r-2]);let e=this.ei.registerNo(d,c);if(null==e)return emitErr("expecting register name",d);if(h&1<<e)return emitErr("duplicate register name",d);h|=1<<e,this.ei.isPush(this.opcode)?a++:this.ei.isPop(this.opcode)&&a--,","==t[r]&&r++}d=t[r++]}else if(c.isLabel){if(d=d.replace(/^#/,""),/^[+-]?\d+$/.test(d))h=parseInt(d,10),o="rel"+h;else if(/^0x[0-9a-fA-F]+$/.test(d))h=parseInt(d,16),o="abs"+h;else{let t=0;if(d.indexOf("+")>0){const e=/(.*)\+(\d+)$/.exec(d);e&&(d=e[1],t=parseInt(e[2]))}if(o=d,h=this.ei.getAddressFromLabel(e.bin,this,d,c.isWordAligned),null==h){if(e.bin.finalEmit)return emitErr("unknown label",d);h=8}h+=t}if(u){i=h,l=d;continue}}else oops();if(null==h)return emitErr("didn't understand it",d);if(s.push(h),h=c.encode(h),null==h)return emitErr("argument out of range or mis-aligned",d);assert(0==(n&h)),n|=h}else if(p!=d)return emitErr("expecting "+p,d)}return t[r]?emitErr("trailing tokens",t[r]):u?this.ei.emit32(n,i,e.bin.normalizeExternalLabel(l)):this.is32bit?{opcode:n>>16&65535|32768,opcode2:n>>0&65535,stack:a,numArgs:s,labelName:e.bin.normalizeExternalLabel(o)}:{stack:a,opcode:n,numArgs:s,labelName:e.bin.normalizeExternalLabel(o)}}toString(){return this.friendlyFmt}}class Line{constructor(e,t){this.bin=e,this.text=t}getOpExt(){return this.instruction?this.instruction.code:""}getOp(){return this.instruction?this.instruction.name:""}update(e){this.bin.peepOps++,(e=e.replace(/^\s*/,""))||this.bin.peepDel++,e&&(e+="      "),this.text=(e="    "+e)+"; WAS: "+this.text.trim(),this.instruction=null,this.numArgs=null,this.words=tokenize(e)||[],0==this.words.length?this.type="empty":"@"==this.words[0][0]&&(this.type="directive")}}class File$1{constructor(e){this.baseOffset=0,this.checkStack=!0,this.inlineMode=!1,this.normalizeExternalLabel=e=>e,this.currLineNo=0,this.scope="",this.scopeId=0,this.errors=[],this.labels={},this.equs={},this.stackpointers={},this.stack=0,this.commPtr=0,this.peepOps=0,this.peepDel=0,this.peepCounts={},this.stats="",this.throwOnError=!1,this.disablePeepHole=!1,this.stackAtLabel={},this.currLine=new Line(this,"<start>"),this.currLine.lineNo=0,this.ei=e,this.ei.file=this}emitShort(e){assert(0<=e&&e<=65535),this.buf.push(e)}emitOpCode(e){this.emitShort(e)}location(){return 2*this.buf.length}pc(){return this.location()+this.baseOffset}parseOneInt(e){if(!e)return null;if(/^\d+$/.test(e))return parseInt(e,10);const t=e.indexOf("-");if(t>0)return this.parseOneInt(e.slice(0,t))-this.parseOneInt(e.slice(t+1));let n=1;if(e.indexOf("*")>=0){let t=null;for(;t=/^([^\*]*)\*(.*)$/.exec(e);){let r=this.parseOneInt(t[1]);if(null==r)return null;n*=r,e=t[2]}}if("-"==e[0]?(n*=-1,e=e.slice(1)):"+"==e[0]&&(e=e.slice(1)),/^\d+$/.test(e))return n*parseInt(e,10);if(endsWith(e,"|1"))return 1|this.parseOneInt(e.slice(0,e.length-2));if(endsWith(e,"-1"))return this.parseOneInt(e.slice(0,e.length-2))-1;if(endsWith(e,"+1"))return this.parseOneInt(e.slice(0,e.length-2))+1;let r=/(.*)>>(\d+)$/.exec(e);if(r){let e=this.parseOneInt(r[1]);return e&=~(-16777216&this.baseOffset),e>>parseInt(r[2])}let a=null;if("0"==e[0])if("x"==e[1]||"X"==e[1]){let t=/^0x([a-f0-9]+)$/i.exec(e);t&&(a=parseInt(t[1],16))}else if("b"==e[1]||"B"==e[1]){let t=/^0b([01]+)$/i.exec(e);t&&(a=parseInt(t[1],2))}if(e.indexOf("@")>=0){let t=/^(\w+)@(-?\d+)$/.exec(e);t&&(1!=n&&this.directiveError(lf("multiplication not supported with saved stacks")),this.stackpointers.hasOwnProperty(t[1])?a=this.ei.wordSize()*this.ei.computeStackOffset(t[1],this.stack-this.stackpointers[t[1]]+parseInt(t[2])):this.directiveError(lf("saved stack not found"))),t=/^(.*)@(hi|lo|fn)$/.exec(e),t&&this.looksLikeLabel(t[1])&&(a=this.lookupLabel(t[1],!0),null!=a&&("fn"==t[2]?a=this.ei.toFnPtr(a,this.baseOffset,t[1]):(a>>=1,0<=a&&a<=65535?"hi"==t[2]?a=a>>8&255:"lo"==t[2]?a&=255:oops():(this.directiveError(lf("@hi/lo out of range")),a=null))))}return null==a&&this.looksLikeLabel(e)&&(a=this.lookupLabel(e,!0),null!=a&&1==this.ei.postProcessRelAddress(this,1)&&(a+=this.baseOffset)),null==a||isNaN(a)?null:a*n}looksLikeLabel(e){return!/^(r\d|pc|sp|lr)$/i.test(e)&&/^[\.a-zA-Z_][\.:\w+]*$/.test(e)}scopedName(e){return"."==e[0]&&this.scope?this.scope+"$"+e:e}lookupLabel(e,t=!1){let n=null,r=this.scopedName(e);return this.labels.hasOwnProperty(r)?(n=this.labels[r],n=this.ei.postProcessRelAddress(this,n)):this.lookupExternalLabel&&(n=this.lookupExternalLabel(e),null!=n&&(n=this.ei.postProcessAbsAddress(this,n))),null==n&&this.equs.hasOwnProperty(r)&&(n=this.equs[r]),null==n&&t&&(this.finalEmit?this.directiveError(lf("unknown label: {0}",e)):n=11111),n}align(e){for(assert(2==e||4==e||8==e||16==e);this.location()%e!=0;)this.emitOpCode(0)}pushError(e,t=""){let n={scope:this.scope,message:lf("  -> Line {2} ('{1}'), error: {0}\n{3}",e,this.currLine.text,this.currLine.lineNo,t),lineNo:this.currLine.lineNo,line:this.currLine.text,coremsg:e,hints:t};if(this.errors.push(n),this.throwOnError)throw new Error(n.message)}directiveError(e){this.pushError(e)}emitString(e,t=!1){function n(e,t){return 255&(e.charCodeAt(t)||0)}let r,a=/^\s*([\w\.]+\s*:\s*)?.\w+\s+(".*")\s*$/.exec(e);if(a&&null!=(r=parseString(a[2])))if(this.align(2),t)for(let e=0;e<r.length;e++)this.emitShort(r.charCodeAt(e));else for(let e=0;e<r.length+1;e+=2)this.emitShort(n(r,e+1)<<8|n(r,e));else this.directiveError(lf("expecting string"))}parseNumber(e){let t=this.parseOneInt(e.shift());return null==t?null:t}parseNumbers(e){e=e.slice(1);let t=[];for(;;){let n=this.parseNumber(e);if(null==n){this.directiveError(lf("cannot parse number at '{0}'",e[0]));break}if(t.push(n),","!=e[0]){if(null==e[0])break;this.directiveError(lf("expecting number, got '{0}'",e[0]));break}if(e.shift(),null==e[0])break}return t}emitSpace(e){let t=this.parseNumbers(e);if(1==t.length&&t.push(0),2!=t.length)this.directiveError(lf("expecting one or two numbers"));else if(t[0]%2!=0)this.directiveError(lf("only even space supported"));else{let e=255&t[1];e|=e<<8;for(let n=0;n<t[0];n+=2)this.emitShort(e)}}emitBytes(e){let t=this.parseNumbers(e);t.length%2!=0&&(this.directiveError(".bytes needs an even number of arguments"),t.push(0));for(let e=0;e<t.length;e+=2){let n=t[e],r=t[e+1];0<=n&&r<=255&&0<=r&&n<=255?this.emitShort(255&n|(255&r)<<8):this.directiveError(lf("expecting uint8"))}}emitHex(e){e.slice(1).forEach(e=>{if(","!=e)if(e.length%4!=0)this.directiveError(".hex needs an even number of bytes");else if(/^[a-f0-9]+$/i.test(e))for(let t=0;t<e.length;t+=4){let n=parseInt(e.slice(t,t+4),16);n=(255&n)<<8|n>>8&255,this.emitShort(n)}else this.directiveError(".hex needs a hex number")})}emitFloats(e){e.slice(1).forEach(e=>{if(","==e)return;const t=parseFloat(e);isNaN(t)&&this.directiveError("invalid .float");const n=float32ToUInt32(t);this.emitShort(65535&n),this.emitShort(n>>16&65535)})}emitFloats16(e){e.slice(1).forEach(e=>{if(","==e)return;const t=parseFloat(e);isNaN(t)&&this.directiveError("invalid .float16");const n=float16toUInt16(t);this.emitShort(65535&n)})}handleDirective(e){let t,n=e.words,r=()=>{2!=n.length&&this.directiveError(lf("expecting one argument"))};switch(n[0]){case".ascii":case".asciz":case".string":this.emitString(e.text);break;case".utf16":this.emitString(e.text,!0);break;case".align":if(r(),t=this.parseOneInt(n[1]),null!=t){if(0==t)return;t<=4?this.align(1<<t):this.directiveError(lf("expecting 1, 2, 3 or 4 (for 2, 4, 8, or 16 byte alignment)"))}else this.directiveError(lf("expecting number"));break;case".balign":if(r(),t=this.parseOneInt(n[1]),null!=t){if(1==t)return;2==t||4==t||8==t||16==t?this.align(t):this.directiveError(lf("expecting 2, 4, 8, or 16"))}else this.directiveError(lf("expecting number"));break;case".p2align":r(),t=this.parseOneInt(n[1]),null!=t?this.align(1<<t):this.directiveError(lf("expecting number"));break;case".byte":this.emitBytes(n);break;case".hex":this.emitHex(n);break;case".float":this.emitFloats(n);break;case".float16":this.emitFloats16(n);break;case".hword":case".short":case".2bytes":this.parseNumbers(n).forEach(e=>{-32768<=e&&e<=65535?this.emitShort(65535&e):this.directiveError(lf("expecting int16"))});break;case".word":case".4bytes":case".long":this.parseNumbers(n).forEach(e=>{-2147483648<=e&&e<=4294967295?(this.emitShort(65535&e),this.emitShort(e>>16&65535)):this.directiveError(lf("expecting int32"))});break;case".skip":case".space":this.emitSpace(n);break;case".set":case".equ":/^\w+$/.test(n[1])||this.directiveError(lf("expecting name"));const a=this.parseNumbers(n.slice(","==n[2]||"="==n[2]?2:1));1!=a.length&&this.directiveError(lf("expecting one value")),void 0!==this.equs[n[1]]&&this.equs[n[1]]!=a[0]&&this.directiveError(lf("redefinition of {0}",n[1])),this.equs[n[1]]=a[0];break;case".startaddr":this.location()&&this.directiveError(lf(".startaddr can be only be specified at the beginning of the file")),r(),this.baseOffset=this.parseOneInt(n[1]);break;case"@stackmark":r(),this.stackpointers[n[1]]=this.stack;break;case"@stackempty":this.checkStack&&(null==this.stackpointers[n[1]]?this.directiveError(lf("no such saved stack")):this.stackpointers[n[1]]!=this.stack&&this.directiveError(lf("stack mismatch")));break;case"@scope":this.scope=n[1]||"",this.currLineNo=this.scope?0:this.realCurrLineNo;break;case".syntax":case"@nostackcheck":this.checkStack=!1;break;case"@dummystack":r(),this.stack+=this.parseOneInt(n[1]);break;case".section":case".global":this.stackpointers={},this.stack=0,this.scope="$S"+this.scopeId++;break;case".comm":{n=n.filter(e=>","!=e),n.shift();let e=this.parseOneInt(n[1]),t=0;if(t=n[2]?this.parseOneInt(n[2]):4,null==this.lookupLabel(n[0])){for(this.commPtr||(this.commPtr=this.lookupExternalLabel("_pxt_comm_base")||0,this.commPtr||this.directiveError(lf("PXT_COMM_BASE not defined")));this.commPtr&t-1;)this.commPtr++;this.labels[this.scopedName(n[0])]=this.commPtr-this.baseOffset,this.commPtr+=e}break}case".arch":case".thumb":case".file":case".text":case".cpu":case".fpu":case".eabi_attribute":case".code":case".thumb_func":case".type":case".fnstart":case".save":case".size":case".fnend":case".pad":case".globl":case".local":case"@":break;default:/^\.cfi_/.test(n[0])||this.directiveError(lf("unknown directive"))}}handleOneInstruction(e,t){let n=t.emit(e);return!n.error&&(this.stack+=n.stack,this.checkStack&&this.stack<0&&this.pushError(lf("stack underflow")),e.location=this.location(),e.opcode=n.opcode,e.stack=n.stack,this.emitOpCode(n.opcode),null!=n.opcode2&&this.emitOpCode(n.opcode2),null!=n.opcode3&&this.emitOpCode(n.opcode3),e.instruction=t,e.numArgs=n.numArgs,!0)}handleInstruction(e){if(e.instruction&&this.handleOneInstruction(e,e.instruction))return;const t=e=>this.ei.instructions.hasOwnProperty(e)?this.ei.instructions[e]:[];let n=t(e.words[0]);for(let t=0;t<n.length;++t)if(this.handleOneInstruction(e,n[t]))return;const r=this.ei.stripCondition(e.words[0]);if(r&&(n=t(r),n.length>0)){e.words[0]=r;for(let t=0;t<n.length;++t)if(this.handleOneInstruction(e,n[t]))return}let a=e.words[0].toLowerCase().replace(/s$/,"").replace(/[^a-z]/g,"");a=this.ei.stripCondition(a)||a;let s="",o=t(a).concat(t(a+"s"));o.length>0&&o.forEach(t=>{let n=t.emit(e);s+=lf("   Maybe: {0} ({1} at '{2}')\n",t.toString(),n.error,n.errorAt)}),this.pushError(lf("assembly error"),s)}buildLine(e,t){let n=e=>{let n=new Line(this,e);return n.scope=this.scope,n.lineNo=this.currLineNo,t.push(n),n},r=n(e),a=tokenize(r.text)||[];r.words=a;let s=a[0]||"";if(":"==s.charAt(s.length-1)){let t=/^([\.\w]+):$/.exec(a[0]);if(t){if(r.type="label",r.text=t[1]+":",r.words=[t[1]],!(a.length>1))return;a.shift(),r=n(e.replace(/^[^:]*:/,"")),r.words=a,s=a[0]||""}}let o=s.charAt(0);"."==o||"@"==o?(r.type="directive","@scope"==r.words[0]&&this.handleDirective(r)):r.type=0==r.words.length?"empty":"instruction"}prepLines(e){this.currLineNo=0,this.realCurrLineNo=0,this.lines=[],e.split(/\r?\n/).forEach(e=>{this.errors.length>10||(this.currLineNo++,this.realCurrLineNo++,this.buildLine(e,this.lines))})}iterLines(){this.stack=0,this.buf=[],this.scopeId=0,this.lines.forEach(e=>{if(!(this.errors.length>10)&&(this.currLine=e,0!=e.words.length))if("label"==e.type){let t=this.scopedName(e.words[0]);if(this.prevLabel=t,this.finalEmit){null!=this.equs[t]&&this.directiveError(lf(".equ redefined as label"));let e=this.labels[t];null==e&&oops(),0==this.errors.length&&e!=this.location()&&oops(`invalid location: ${this.location()} != ${e} at ${t}`),assert(this.errors.length>0||e==this.location()),this.reallyFinalEmit&&(this.stackAtLabel[t]=this.stack)}else this.labels.hasOwnProperty(t)?this.directiveError(lf("label redefinition")):this.inlineMode&&/^_/.test(t)?this.directiveError(lf("labels starting with '_' are reserved for the compiler")):this.labels[t]=this.location();e.location=this.location()}else"directive"==e.type?this.handleDirective(e):"instruction"==e.type?this.handleInstruction(e):"empty"==e.type||oops()})}getSource(e,t=1,n=0){let r=0,a=e=>{let t=this.labels[e]||r,n=t-r;return r=t,n},s=this.buf?this.location():0,o=a("_code_end"),i=a("_helpers_end"),l=a("_vtables_end"),u=a("_literals_end"),c=r,p=s+this.baseOffset&16777215;n&&p>n&&userError(lf("program too big by {0} bytes!",p-n));let d=lf("; total bytes: {0} ({1}% of {2}k flash with {3} free)",p,(100*p/(n=n||131072)).toFixed(1),(n/1024).toFixed(1),n-p),h=lf("; generated code sizes (bytes): {0} (incl. {1} user, {2} helpers, {3} vtables, {4} lits); src size {5}\n",c,o,i,l,u,s-c)+lf("; assembly: {0} lines; density: {1} bytes/stmt; ({2} stmts)\n",this.lines.length,Math.round(100*o/t)/100,t)+d+"\n"+this.stats+"\n\n",m=!1;return this.lines.forEach((t,n)=>{if("_stored_program"==t.words[0])return h+='_stored_program: .string "..."\n',void(m=!0);if(m)return void(m=!1);let r=t.text;if(e){if("@stackempty"==t.words[0]&&this.lines[n-1].text==t.text)return;if(r=r.replace(/; WAS: .*/,""),!r.trim())return}h+=r+"\n"}),h}peepHole(){let e=this.lines.filter(e=>"empty"!=e.type);for(let t=0;t<e.length;++t){let n=e[t];if(/^user/.test(n.scope))continue;let r=e[t+1];if(!r)continue;let a=e[t+2];"instruction"==n.type&&this.ei.peephole(n,r,a)}}clearLabels(){this.labels={},this.commPtr=0}peepPass(e){this.peepOps=0,this.peepDel=0,this.peepCounts={},this.peepHole(),this.throwOnError=!0,this.finalEmit=!1,this.clearLabels(),this.iterLines(),assert(!this.checkStack||0==this.stack),this.finalEmit=!0,this.reallyFinalEmit=e||0==this.peepOps,this.iterLines(),this.stats+=lf("; peep hole pass: {0} instructions removed and {1} updated\n",this.peepDel,this.peepOps-this.peepDel)}getLabels(){return this.userLabelsCache||(this.userLabelsCache=mapMap(this.labels,(e,t)=>t+this.baseOffset)),this.userLabelsCache}emit(e){if(assert(null==this.buf),this.prepLines(e),!(this.errors.length>0||(this.clearLabels(),this.iterLines(),this.checkStack&&0!=this.stack&&this.directiveError(lf("stack misaligned at the end of the file")),this.errors.length>0||(this.ei.expandLdlit(this),this.clearLabels(),this.iterLines(),this.finalEmit=!0,this.reallyFinalEmit=this.disablePeepHole,this.iterLines(),this.errors.length>0||this.disablePeepHole)))){let e=5;for(let t=0;t<e&&(console.debug(`Peephole OPT, pass ${t}`),this.peepPass(t==e),0!=this.peepOps);++t);}}}class AbstractProcessor{constructor(){this.file=null,this.encoders={},this.instructions={}}toFnPtr(e,t,n){return e}wordSize(){return-1}computeStackOffset(e,t){return t}is32bit(e){return!1}emit32(e,t,n){return null}postProcessRelAddress(e,t){return t}postProcessAbsAddress(e,t){return t}peephole(e,t,n){}registerNo(e,t){return null}getAddressFromLabel(e,t,n,r=!1){return null}isPop(e){return!1}isPush(e){return!1}isAddSP(e){return!1}isSubSP(e){return!1}testAssembler(){assert(!1)}expandLdlit(e){}addEnc(e,t,n){let r={name:e,pretty:t,encode:n,isRegister:/^\$[sr]\d/i.test(e),isImmediate:/^\$i\d/i.test(e),isRegList:/^\$[sr]l\d/i.test(e),isLabel:/^\$l[a-z]/i.test(e)};return this.encoders[e]=r,r}inrange(e,t,n){return Math.floor(t)!=t||t<0||t>e?null:n}inminmax(e,t,n,r){return Math.floor(n)!=n||n<e||n>t?null:r}inseq(e,t){let n=e.indexOf(t);return n<0?null:n}inrangeSigned(e,t,n){return Math.floor(t)!=t||t<-(e+1)||t>e?null:n&(e<<1|1)}addInst(e,t,n,r){let a=new Instruction(this,e,t,n,r);return this.instructions.hasOwnProperty(a.name)||(this.instructions[a.name]=[]),this.instructions[a.name].push(a),a}addInst32(e,t,n){const r=2147483648;return assert(!!(t&r)),assert(!!(n&r)),this.addInst(e,t&=~r,n&=~r,!0)}}function tokenize(e){let t=[],n="";e:for(let r=0;r<e.length;++r)switch(e[r]){case"[":case"]":case"!":case"{":case"}":case",":n&&(t.push(n),n=""),t.push(e[r]);break;case" ":case"\t":case"\r":case"\n":n&&(t.push(n),n="");break;case"/":if("/"==e[r+1])break e;break;case";":break e;default:n+=e[r]}return n&&(t.push(n),n=""),t[0]?t:null}function parseString(e){e=e.replace(/\\\\/g,"\\B").replace(/\\(['\?])/g,(e,t)=>t).replace(/\\[z0]/g,"\0").replace(/\\x([0-9a-f][0-9a-f])/gi,(e,t)=>"\\u00"+t).replace(/\\B/g,"\\\\");try{return JSON.parse(e)}catch(e){return null}}function emitErr(e,t){return{stack:null,opcode:null,error:e,errorAt:t}}function expectError(e,t){let n=new File$1(e);n.emit(t),0==n.errors.length&&oops("ASMTEST: expecting error for: "+t)}function tohex(e){return e<0||e>65535?("0x"+e.toString(16)).toLowerCase():("0x"+("000"+e.toString(16)).slice(-4)).toLowerCase()}function expect$1(e,t){let n=[],r=t.replace(/^([0-9a-fA-F]{4,8})\s/gm,(e,t)=>(n.push(parseInt(t.slice(0,4),16)),8==t.length&&n.push(parseInt(t.slice(4,8),16)),"")),a=new File$1(e);a.throwOnError=!0,a.disablePeepHole=!0,a.emit(r),a.errors.length>0&&(console.debug(a.errors[0].message),oops("ASMTEST: not expecting errors")),a.buf.length!=n.length&&oops("ASMTEST: wrong buf len");for(let e=0;e<n.length;++e)a.buf[e]!=n[e]&&oops("ASMTEST: wrong buf content at "+e+" , exp:"+tohex(n[e])+", got: "+tohex(a.buf[e]))}const asmDeps={softmax:["expf_asm"]},asmFns={expf_asm:"\n// based on https://stackoverflow.com/questions/29381117\nexpf_asm:\n\tvldr.32\ts15, .L10\n\tvcmpe.f32\ts0, s15\n\tvmrs\tAPSR_nzcv, FPSCR\n\tbmi\t.L5\n\tvldr.32\ts15, .L10+4\n\tvcmpe.f32\ts0, s15\n\tvmrs\tAPSR_nzcv, FPSCR\n\tbgt\t.L9\n\tvldr.32\ts15, .L10+8\n\tvldr.32\ts9, .L10+12\n\tvldr.32\ts6, .L10+16\n\tvldr.32\ts7, .L10+20\n\tvldr.32\ts10, .L10+24\n\tvldr.32\ts8, .L10+28\n\tvldr.32\ts11, .L10+32\n\tvldr.32\ts12, .L10+36\n\tvldr.32\ts13, .L10+40\n\tvmul.f32\ts15, s0, s15\n\tvmov.f32\ts14, #1.0\n\tvadd.f32\ts15, s15, s9\n\tvsub.f32\ts15, s15, s9\n\tvfma.f32\ts0, s15, s6\n\tvcvt.s32.f32\ts9, s15\n\tvfma.f32\ts0, s15, s7\n\tvmov.f32\ts15, s10\n\tvfma.f32\ts15, s8, s0\n\tvmov\tr3, s9\t// int\n\tvfma.f32\ts11, s15, s0\n\tvfma.f32\ts12, s11, s0\n\tvfma.f32\ts13, s12, s0\n\tvmov.f32\ts15, s13\n\tvmov.f32\ts13, s14\n\tvfma.f32\ts13, s15, s0\n\tvfma.f32\ts14, s13, s0\n\tvmov\tr2, s14\t// int\n\tadd\tr3, r2, r3, lsl #23\n\tvmov\ts0, r3\t// int\n\tbx\tlr\n.L9:\n\tvldr.32\ts15, .L10+44\n\tvmov.f32\ts14, #1.0\n\tvdiv.f32\ts0, s14, s15\n\tbx\tlr\n.L5:\n\tvldr.32\ts0, .L10+44\n\tbx\tlr\n.L11:\n\t.align\t2\n.L10:\n\t.word\t3265921024\n\t.word\t1118699520\n\t.word\t1069066811\n\t.word\t1262485504\n\t.word\t3207688704\n\t.word\t3049242254\n\t.word\t1007234926\n\t.word\t984915968\n\t.word\t1026207149\n\t.word\t1042983464\n\t.word\t1056964603\n\t.word\t0\n",softmax:"\nsoftmax:\n\tcmp\tr1, #1\n\tpush\t{r3, r4, r5, lr}\n\tvldr.32\ts5, [r0]\n\tbls\t.L13\n\tadds\tr3, r0, #4\n\tadd\tr2, r0, r1, lsl #2\n.L16:\n\tvldmia.32\tr3!, {s15}\n\tvcmp.f32\ts15, s5\n\tvmrs\tAPSR_nzcv, FPSCR\n\tit\tgt\n\tvmovgt.f32\ts5, s15\n\tcmp\tr2, r3\n\tbne\t.L16\n.L17:\n\tmovs\tr4, #0\n\tvmov\ts4, r4\n\tmov\tr5, r0\n.L19:\n\tvldr.32\ts0, [r5]\n\tvsub.f32\ts0, s0, s5\n\tbl\texpf_asm\n\tadds\tr4, #1\n\tcmp\tr1, r4\n\tvadd.f32\ts4, s4, s0\n\tvstmia.32\tr5!, {s0}\n\tbhi\t.L19\n\tmovs\tr3, #0\n.L20:\n\tvldr.32\ts14, [r0]\n\tvdiv.f32\ts15, s14, s4\n\tadds\tr3, #1\n\tcmp\tr1, r3\n\tvstmia.32\tr0!, {s15}\n\tbhi\t.L20\n\tpop\t{r3, r4, r5, pc}\n.L13:\n\tcmp\tr1, #0\n\tbne\t.L17\n\tpop\t{r3, r4, r5, pc}\n"},unrollLimit=10;var OpCode,Reg,F16Mode;function assert$1(e,t="assertion failed"){if(!e)throw new Error("ir: "+t)}function addParamBytes(e,t){assert$1(0==(e.weightPtr&t.length-1)),e.weightBuffer||(e.weightBuffer=new Uint8Array(128));const n=e.weightPtr+t.length;if(n+3>e.weightBuffer.length){const t=new Uint8Array(2*n);t.set(e.weightBuffer),e.weightBuffer=t}e.weightBuffer.set(t,e.weightPtr),e.weightPtr=n}function addFloat32(e,t){assert$1(null!=t&&!isNaN(t)),e.weightAsm+=`.float ${t}\n`;const n=float32ToUInt32(t);addParamBytes(e,[n>>0&255,n>>8&255,n>>16&255,n>>24&255])}function addFloat16(e,t){assert$1(null!=t&&!isNaN(t)),e.weightAsm+=`.float16 ${t}\n`;const n=float16toUInt16(t);addParamBytes(e,[n>>0&255,n>>8&255])}function alignWeights(e){for(;3&e.weightPtr;)addParamBytes(e,[0]);e.weightAsm+=".balign 4\n"}function addWeight(e,t){e.opts.float16weights?addFloat16(e,t):addFloat32(e,t)}function addBias(e,t){addFloat32(e,t)}function weightOffset(e){return assert$1(0==(3&e.weightPtr)),e.weightPtr>>2}function stringifyComment(e){return e?"// "+e.replace(/\n/g,"\n// "):""}function indent(e){return"  "+e.replace(/\n$/,"").replace(/\n/g,"\n  ")+"\n"}function numCycles(e){let t=0,n=null;const r=e=>e<4096?1:2;for(const a of e)switch(a.opcode){case OpCode.comment:case OpCode.label:break;case OpCode.repeat:t+=(numCycles(a.body)+4+(a.isDef?1:0))*a.num+1;break;case OpCode.loadWeightAddr:t+=2+r(4*a.num);break;case OpCode.loadDataAddr:t+=r(4*a.num+8);break;case OpCode.addPtr:null==a.src?t+=r(4*a.num):(1!=a.num&&(a.src>Reg.Zero?a.src==Reg.Zero+1||(a.src==Reg.Zero+2?t++:t+=2):t++),t+=2),t+=1==a.num?1:3;break;case OpCode.loadFConst:t+=0==a.num?2:1==a.num?1:4;break;case OpCode.load:case OpCode.store:t+=1+a.num;break;case OpCode.relu:t+=6;break;case OpCode.vmax:t+=4,a.src!=a.dst&&t++;break;case OpCode.vmul:case OpCode.vadd:t+=a.src===n||a.srcAlt===n?2:1,n=a.dst;break;case OpCode.vcvt:t+=1;break;case OpCode.fcall:t+="softmax"==a.fname?200+150*a.num:500+500*a.num;break;default:throw new Error("bad op "+a.opcode)}return t}function toThumb(e,t){var n;const r={},a=!!e.opts.testInput&&!!e.opts.includeTest;let s="";const o=e=>4*(e+2),i=["0x30470f62  // magic","0x46344c4d  // more magic; ML4F","_start_model-_header // header size","_end-_header // total size of compiled object","_weights-_header // offset of weights",a?"_testInput-_header":"0 // no tests",a?"_testOutput-_header":"0 // no tests",`${o(e.arenaSize)} // arena size`,`${o(0)}  // offset of input data`,"1 // input type - float32",`${o(e.outputOffset)}  // offset of output data`,"1 // output type - float32"];for(let e=0;e<4;++e)i.push("0 // padding");h(e.inputShape,"input"),h(e.outputShape,"output");let l="";for(;(null===(n=t[0])||void 0===n?void 0:n.opcode)==OpCode.comment;)l+=stringifyComment(t.shift().fname)+"\n";let u={},c=`${stringifyComment(e.stats)}\n    .cpu cortex-m4\n    .text\n    .arch armv7e-m\n    .syntax unified\n    .thumb\n    .thumb_func\n    .fpu fpv4-sp-d16\n// ABI: r0 -> points to magic, r1 -> points to RAM arena\n_header:\n`;for(const e of i)f(`.word ${e}`);let p=0;u[Reg.InputPtr]=1,u[Reg.OutputPtr]=2,u[Reg.KernelPtr]=3,u[Reg.DataDescPtr]=7,f("_start_model:"),f("push {r4,r5,r6,r7,r8,r9,r10,r11,r12,lr}"),f(`mov ${$(Reg.DataDescPtr)}, r1`),f("ldr r1, [r0, #4*4] // weight offset"),f("adds r1, r0 // weight addr"),f(`str r1, [${$(Reg.DataDescPtr)}, #0]`),f("movs r1, #0"),f(`str r1, [${$(Reg.DataDescPtr)}, #4]`),I(t),f("pop {r4,r5,r6,r7,r8,r9,r10,r11,r12,pc}");for(const e of Object.keys(r))for(const t of asmDeps[e]||[])r[t]=!0;for(const e of Object.keys(r))f(asmFns[e]);return f(".balign 4"),f(`_weights:\n${e.weightAsm}`),a&&(d("_testInput",e.opts.testInput),d("_testOutput",e.opts.testOutput)),f("_end:"),c;function d(e,t){f(`${e}:`);for(const e of t)f(`.float ${e}`)}function h(e,t){for(const n of e)null!=n&&i.push(`${n} // ${t} shape`);i.push(`0 // end of ${t} shape`)}function m(e,t){assert$1(!u[e]);const n={},r={};for(const e of Object.keys(u))n[e]=u[e],r[n[e]]=!0;let a=-1;for(let e=4;e<=12;++e)if(!r[e]){a=e;break}if(a<0&&g("can't alloc "+e),u[e]=a,t){const e=s;try{s+="    ",t()}finally{s=e,u=n}}}function f(e){y(e)&&g("wrong reg: "+e),c+=s+e+"\n"}function g(e){throw new Error("internal thumb error: "+e)}function $(e){if(null==e)return"<fake>";if(e<=Reg.S31)return"s"+(e-Reg.S0);if(e>=Reg.Zero)return"#"+(e-Reg.Zero);const t=u[e];return null==t?"<fake:"+regName(e)+">":"r"+t}function y(e){return e.indexOf("<fake")>=0}function b(e){return/^r[0-7]$/.test(e)}function x(e,t){t<=255&&b(e)?f(`movs ${e}, #${t}`):f(`movw ${e}, #${t}`)}function v(e,t,n){Math.abs(n)<4096?f(n<0?`subw ${e}, ${t}, #${-n}`:`addw ${e}, ${t}, #${n}`):(assert$1(t!=e),x(e,n),f(`adds ${e}, ${t}, ${e}`))}function I(e){for(const t of e)S(t)}function C(e){return"{"+range(e.num).map(t=>$(e.dst+t)).join(",")+"}"}function S(e){let t=$(e.dst);const n=$(e.src),a=$(e.srcAlt),s=e.increment?"!":"";switch(e.opcode){case OpCode.label:f(`${e.fname}:`);break;case OpCode.comment:f(stringifyComment(e.fname));break;case OpCode.repeat:assert$1(e.num>=1),m(e.dst,()=>{t=$(e.dst);const n=".l."+p++;x(t,e.isDef?0:e.num),f(`${n}:  // rep ${e.num}`),I(e.body),e.isDef?(f(`adds ${t}, #1`),f(`cmp ${t}, #${e.num}`),f(`blt ${n}`)):(b(t)?f(`subs ${t}, #1`):f(`subs ${t}, ${t}, #1`),f(`bne ${n}`))});break;case OpCode.loadWeightAddr:f(`ldr r0, [${$(Reg.DataDescPtr)}, #0]`),v(t,"r0",4*e.num);break;case OpCode.loadDataAddr:v(t,$(Reg.DataDescPtr),o(e.num));break;case OpCode.addPtr:if(y(t)&&e.isDef&&(m(e.dst),t=$(e.dst)),null==e.src)v(t,a,4*e.num);else{if(1!=e.num)if(x("r0",4*e.num),"#"==n[0]){const e=+n.slice(1);0==e?x("r0",0):1==e||(2==e?f("adds r0,r0"):(assert$1(t!=a),x(t,e),f(`muls r0, ${t}`)))}else f(`muls r0, ${n}`);else"#"==n[0]?x("r0",+n.slice(1)<<2):f(`lsls r0, ${n}, #2`);f(`adds ${t}, ${a}, r0`)}break;case OpCode.loadFConst:0==e.num?f(`vldr ${t}, [${$(Reg.DataDescPtr)}, #4]`):e.num==Number.NEGATIVE_INFINITY?(f("movw r0, #0xff80"),f("lsls r0, r0, #16"),f(`vmov ${t}, r0`)):f(`vmov ${t}, #${e.num}e+0`);break;case OpCode.load:assert$1(e.f16Mode!=F16Mode.On),f(`vldm ${n}${s}, ${C(e)}`);break;case OpCode.store:f(`vstm ${n}${s}, ${C(e)}`);break;case OpCode.relu:f(`ldr r0, [${t}, #0]`),f("cmp r0, #0"),f("it lt"),f("movwlt r0, #0"),f(`stm ${t}!, {r0}`);break;case OpCode.vmul:f(`vmul.f32 ${t}, ${n}, ${a}`);break;case OpCode.vadd:f(`vadd.f32 ${t}, ${n}, ${a}`);break;case OpCode.vcvt:f(`${e.fname} ${t}, ${n}`);break;case OpCode.vmax:assert$1(t!=a),n!=t&&f(`vmov ${t}, ${n}`),f(`vcmp.f32 ${t}, ${a}`),f("vmrs APSR_nzcv, FPSCR"),f("it mi"),f(`vmovmi.f32 ${t}, ${a}`);break;case OpCode.fcall:f(`mov r0, ${t}`),x("r1",e.num),f(`bl ${e.fname}`),r[e.fname]=!0;break;default:g("bad op "+e.opcode)}}}function toJS(e,t){let n="";if(t.opcode==OpCode.repeat){const r=regName(t.dst);n=`for (let ${r} = 0; ${r} < ${t.num}; ${r}++) {\n${indent(toJSs(e,t.body))}}\n`}else n=stringify1(t);return n.indexOf("???")>=0&&oops("invalid register in: "+n),n}function stringify(e){return e.map(stringify1).join("")}function stringify1(e){const t=null==e.dst?null:regName(e.dst),n=null==e.src?null:regName(e.src),r=null==e.srcAlt?null:regName(e.srcAlt);switch(e.opcode){case OpCode.label:return stringifyComment("label: "+e.fname)+"\n";case OpCode.comment:return isBreak(e)?"debugger\n":stringifyComment(e.fname)+"\n";case OpCode.repeat:return`for (let ${t} = 0; ${t} < ${e.num}; ${t}++) {\n${indent(stringify(e.body))}}\n`;case OpCode.loadWeightAddr:return`${t} = weightOff + ${e.num}\n`;case OpCode.loadDataAddr:return`${t} = dataOff + ${e.num}\n`;case OpCode.addPtr:return null==e.src?`${t} = ${r} + ${e.num}\n`:`${t} = ${r} + ${n}${1==e.num?"":" * "+e.num}\n`;case OpCode.loadFConst:return`${t} = ${e.num}\n`;case OpCode.load:{let t="",r=e.dst+0;if(e.increment)for(let a=0;a<e.num;++a)t+=`${regName(r++)} = ${e.fname||"mem"}[${n}++]\n`;else for(let a=0;a<e.num;++a)t+=`${regName(r++)} = mem[${n} + ${a}]\n`;return t}case OpCode.store:{let t="",r=e.dst+0;if(e.increment)for(let a=0;a<e.num;++a)t+=`mem[${n}++] = ${regName(r++)}\n`;else for(let a=0;a<e.num;++a)t+=`mem[${n} + ${a}] = ${regName(r++)}\n`;return t}case OpCode.relu:return`if (mem[${t}] < 0) mem[${t}] = 0; ${t}++\n`;case OpCode.vmul:return`${t} = f32(${n} * ${r})\n`;case OpCode.vadd:return`${t} = f32(${n} + ${r})\n`;case OpCode.vmax:return`${t} = Math.max(${n}, ${r})\n`;case OpCode.fcall:return`${e.fname}(${t}, ${e.num})\n`;case OpCode.vcvt:return`${t} = rt.${e.fname.replace(/\./g,"_")}(${n})\n`;default:throw new Error("bad op "+e.opcode)}}function regName(e){if(e<=Reg.S31)return"s"+(e-Reg.S0);if(e>=Reg.Zero)return""+(e-Reg.Zero);if(e>=Reg.Tmp0)return"tmp"+(e-Reg.Tmp0);if(e>=Reg.Index0)return"idx"+(e-Reg.Index0);switch(e){case Reg.InputPtr:return"input";case Reg.KernelPtr:return"kernel";case Reg.OutputPtr:return"output";default:return"???"+e}}function toJSs(e,t){return t.map(t=>toJS(e,t)).join("")}!function(e){e[e.comment=0]="comment",e[e.label=1]="label",e[e.repeat=2]="repeat",e[e.loadWeightAddr=3]="loadWeightAddr",e[e.loadDataAddr=4]="loadDataAddr",e[e.addPtr=5]="addPtr",e[e.loadFConst=6]="loadFConst",e[e.load=7]="load",e[e.store=8]="store",e[e.vmul=9]="vmul",e[e.vmax=10]="vmax",e[e.vadd=11]="vadd",e[e.vcvt=12]="vcvt",e[e.relu=13]="relu",e[e.fcall=14]="fcall"}(OpCode||(OpCode={})),function(e){e[e.S0=0]="S0",e[e.S1=1]="S1",e[e.S15=15]="S15",e[e.S31=32]="S31",e[e.InputPtr=200]="InputPtr",e[e.OutputPtr=201]="OutputPtr",e[e.KernelPtr=202]="KernelPtr",e[e.DataDescPtr=203]="DataDescPtr",e[e.Index0=300]="Index0",e[e.Tmp0=400]="Tmp0",e[e.Zero=500]="Zero",e[e.One=501]="One"}(Reg||(Reg={})),function(e){e[e.Off=0]="Off",e[e.On=1]="On",e[e.Even=2]="Even",e[e.Odd=3]="Odd"}(F16Mode||(F16Mode={}));let repIdx=0;function repeatIdx(e,t){const n=Reg.Index0+repIdx++;return{opcode:OpCode.repeat,dst:n,num:e,body:t(n),isDef:!0}}function repeat(e,t){const n=repeatIdx(e,t);return n.isDef=!1,n}function comment(e){return{opcode:OpCode.comment,fname:e}}function label(e){return{opcode:OpCode.label,fname:e}}function loadWeightAddr(e,t){return assert$1(t>=0),{opcode:OpCode.loadWeightAddr,dst:e,num:t}}function relaxWeights(){const e=addPtr(Reg.KernelPtr,null,0);return e.fname="relax",e}function loadDataAddr(e,t){return assert$1(t>=0),{opcode:OpCode.loadDataAddr,dst:e,num:t}}function addPtr(e,t,n=1,r){return r||(r=e),{opcode:OpCode.addPtr,dst:e,src:t,srcAlt:r,num:n}}function load0(e){return{opcode:OpCode.loadFConst,dst:e,num:0}}function loadMInf(e){return{opcode:OpCode.loadFConst,dst:e,num:Number.NEGATIVE_INFINITY}}function load(e,t,n,r){return{opcode:OpCode.load,dst:e,src:n,num:t,increment:r}}function load16(e,t,n){return{opcode:OpCode.load,dst:e,src:n,num:t,increment:!0,f16Mode:F16Mode.On}}function loadWeight(e,t,n){const r=Reg.KernelPtr;return e.opts.float16weights?load16(t,n,r):load(t,n,r,!0)}function store(e,t,n,r){return{opcode:OpCode.store,src:e,dst:t,num:n,increment:r}}function relu(e){return{opcode:OpCode.relu,dst:e,increment:!0}}function vmul(e,t,n){return{opcode:OpCode.vmul,dst:e,src:t,srcAlt:n}}function vmax(e,t,n){return n==e&&([t,n]=[n,t]),{opcode:OpCode.vmax,dst:e,src:t,srcAlt:n}}function vadd(e,t,n){return{opcode:OpCode.vadd,dst:e,src:t,srcAlt:n}}function vcvt(e,t,n){return{opcode:OpCode.vcvt,dst:t,src:n,fname:e}}function fcall(e,t,n){return{opcode:OpCode.fcall,fname:e,dst:t,num:n}}function flatten(...e){const t=[],n=e=>{e&&t.push(e)};for(const t of e)if(Array.isArray(t))for(const e of t)if(Array.isArray(e))for(const t of e)n(t);else n(e);else n(t);return t}function isRelax(e){return e.opcode==OpCode.addPtr&&"relax"==e.fname}function isBreak(e){return e.opcode==OpCode.comment&&"BREAK"==e.fname}function isOddF16(e){let t=0;for(const n of e)n.opcode==OpCode.load&&n.f16Mode&&(t+=n.num),isRelax(n)&&(t=t+1&-2);return!!(1&t)}function fixupAndMarkF16(e){return function e(t){const n=[];for(let r of t)if(r.opcode==OpCode.repeat)assert$1(!isOddF16(r.body)),r.body=e(r.body),n.push(r);else if(r.opcode==OpCode.load&&r.f16Mode){let e=0,t=!1;r.f16Mode==F16Mode.Odd?(e=1+(r.num>>1),n.push(addPtr(r.src,Reg.One,-1)),1&r.num||(t=!0)):r.f16Mode==F16Mode.Even?(e=r.num+1>>1,1&r.num&&(t=!0)):assert$1(!1);const a=load(r.dst,e,r.src,!0);a.fname="memU32",n.push(a);let s=r.dst+e-1;for(let e=r.num-1;e>=0;--e)n.push(vcvt(t?"vcvtb.f32.f16":"vcvtt.f32.f16",r.dst+e,s)),t&&s--,t=!t}else n.push(r);return n}(function e(t,n=!1){let r=n?1:0;const a=()=>!!(1&r),s=[];for(let n of t)if(n=cloneOp(n),n.opcode!=OpCode.repeat)s.push(n),n.opcode==OpCode.load&&n.f16Mode&&(assert$1(n.f16Mode==F16Mode.On),n.f16Mode=a()?F16Mode.Odd:F16Mode.Even,r+=n.num),isRelax(n)&&(r=r+1&-2);else{if(0==n.num)continue;const t=a(),o=n.body,i=e(o,t);if(n.body=i.ops,i.odd!=t)if(n.isDef&&(console.log(stringify([n])),assert$1(!1)),1==n.num)pushRange(s,i.ops),r++;else{const a=1&n.num;n.num>>=1;const l=e(o,i.odd);assert$1(l.odd==t),n.body=i.ops.concat(l.ops),s.push(n),a&&(pushRange(s,e(o,t).ops),r++)}else s.push(n)}return{ops:s,odd:!!(1&r)}}(e).ops)}function cloneOp(e){return{opcode:e.opcode,dst:e.dst,src:e.src,srcAlt:e.srcAlt,isDef:e.isDef,f16Mode:e.f16Mode,increment:e.increment,num:e.num,body:e.body,fname:e.fname}}function optimize(e,t={}){const n=e=>e&&null!=t[e]?t[e]:e,r=[];for(let a of e)switch(a=cloneOp(a),a.dst=n(a.dst),a.src=n(a.src),a.srcAlt=n(a.srcAlt),a.opcode){case OpCode.repeat:if(0==a.num);else if(1==a.num)t[a.dst]=Reg.Zero,pushRange(r,optimize(a.body,t));else{a.body=optimize(a.body,t);const e=!a.isDef&&2*a.body.length<unrollLimit;if(a.num*a.body.length<2*unrollLimit)for(let e=0;e<a.num;++e)t[a.dst]=Reg.Zero+e,pushRange(r,optimize(a.body,t));else if(e){const e=unrollLimit/a.body.length|0,t=a.body.slice();for(let n=1;n<e;++n)pushRange(a.body,t);const n=a.num/e|0;r.push(a);const s=a.num-n*e;a.num=n;for(let e=0;e<s;++e)pushRange(r,t)}else r.push(a)}break;case OpCode.addPtr:(a.dst!=a.srcAlt||0!=a.num&&a.src!=Reg.Zero)&&r.push(a);break;default:r.push(a)}return r}function reset(){repIdx=0}let inited$1=!1;const compilers={Conv2D:{compile:compileConv,computePaddedInputShape:paddingConv},Conv1D:{compile:compileConv,computePaddedInputShape:paddingConv},MaxPooling1D:{compile:compileMaxPooling,computePaddedInputShape:paddingPool,needsMInfPadding:!0},MaxPooling2D:{compile:compileMaxPooling,computePaddedInputShape:paddingPool,needsMInfPadding:!0},Dense:{compile:compileDense},Dropout:{},Flatten:{},InputLayer:{},Reshape:{}},numFPRegs=32,numTmpRegs=8;function unsupported(e){throw new Error("Unsupported operator or config: "+e)}function assert$2(e,t="assertion failed"){e||unsupported(t)}function getLayerInfo(e){let t=e.__ml4f_info;return t||(t={layer:e},e.__ml4f_info=t),t}function validateConfig(e){const t=e.layer.getConfig();e.model.opts.verbose&&console.log(e.inputShape,e.outputShape,t),4==e.inputShape.length?(4!=e.inputShape.length&&3!=e.inputShape.length&&unsupported("inputShape: "+e.inputShape.length),"channelsLast"!=t.dataFormat&&unsupported("dataFormat: "+t.dataFormat)):3!=e.inputShape.length&&unsupported("inputShape: "+e.inputShape.length),t.dtype&&"float32"!=t.dtype&&unsupported("dtype: "+t.dtype)}function addActivation(e,t){const n=t.layer.getConfig(),r=shapeElts(t.outputShape);"linear"!=n.activation&&(e.push(loadDataAddr(Reg.OutputPtr,t.outputOff)),"relu"==n.activation?e.push(repeat(r,()=>[relu(Reg.OutputPtr)])):"softmax"==n.activation?e.push(fcall("softmax",Reg.OutputPtr,r)):unsupported("activation: "+n.activation))}function paddingConv(e){const t=e.layer.getConfig(),n=e.inputShape.slice();for(let r=1;r<=t.kernelSize.length;++r){const a=t.strides[r-1],s=e.outputShape[r]*a+t.kernelSize[r-1]-a;assert$2(s>=n[r]),n[r]=s}return n}function paddingPool(e){const t=e.layer.getConfig(),n=e.inputShape.slice();for(let r=1;r<=t.poolSize.length;++r){const a=e.outputShape[r]*t.strides[r-1];a>n[r]&&(n[r]=a)}return n}function compileConv(e){const t=e.layer.getConfig(),n=numFPRegs>>1,r=numFPRegs>>1;validateConfig(e);const a=2==t.kernelSize.length,s=e.layer.weights[0].read().arraySync(),o=a?s:[s],i=e=>(e=e.slice(),a||e.unshift(1),e),[l,u]=i(t.kernelSize),[c,p]=i(t.strides),[d,h,m]=i(e.inputShape.slice(1)),[f,g,$]=i(e.outputShape.slice(1));assert$2(l<=d,"KH2"),assert$2(u<=h,"KW2"),assert$2(o.length==l,"KH"),assert$2(o[0].length==u,"KW"),assert$2(o[0][0].length==m,"CH"),assert$2(o[0][0][0].length==t.filters,"F"),assert$2($==t.filters,"FF");const y=e.model,b=weightOffset(y),x=t.useBias?e.layer.weights[1].read().arraySync():null;for(let e=0;e<t.filters;e++){x&&addBias(y,x[e]);for(let t=0;t<l;t++){for(let n=0;n<u;n++)for(let r=0;r<m;++r)addWeight(y,o[t][n][r][e]);alignWeights(y)}}const v=[loadWeightAddr(Reg.KernelPtr,b),repeatIdx(t.filters,a=>{const s=[],o=t=>{t.push(loadDataAddr(Reg.OutputPtr,e.outputOff)),t.push(addPtr(Reg.OutputPtr,a))};return o(s),s.push(t.useBias?load(Reg.S0,1,Reg.KernelPtr,!0):load0(Reg.S0)),s.push(repeat(g*f,()=>[store(Reg.OutputPtr,Reg.S0,1,!1),addPtr(Reg.OutputPtr,null,t.filters)])),s.push(repeatIdx(l,a=>{const s=[],i=u*m;let l=0;for(let u=0;u<i;u+=l){l=i-u,l>r&&(l=r),s.push(loadWeight(y,n,l)),s.push(loadDataAddr(Reg.InputPtr,e.inputOff+u)),s.push(addPtr(Reg.InputPtr,a,h*m)),o(s);const d=p*m,$=c*h*m;s.push(repeat(f,()=>[repeat(g,()=>flatten(load(Reg.S0,l,Reg.InputPtr,!0),addPtr(Reg.InputPtr,null,d-l),range(l+1).map(e=>[e<l?vmul(e,e,e+n):null,e>=2?vadd(Reg.S0,Reg.S0,e-1):null]),load(Reg.S1,1,Reg.OutputPtr,!1),vadd(Reg.S0,Reg.S0,Reg.S1),store(Reg.OutputPtr,Reg.S0,1,!1),addPtr(Reg.OutputPtr,null,t.filters))),addPtr(Reg.InputPtr,null,$-g*d)]))}return s.push(relaxWeights()),s})),s.push(relaxWeights()),s})];return addActivation(v,e),v}function compileMaxPooling(e){const t=e.layer.getConfig(),n=2==t.poolSize.length;validateConfig(e);const r=e=>(e=e.slice(),n||e.unshift(1),e),[a,s]=r(t.poolSize),[o,i]=r(t.strides),[l,u,c]=r(e.inputShape.slice(1)),[p,d,h]=r(e.outputShape.slice(1));assert$2(a<=l,"KH2"),assert$2(s<=u,"KW2"),assert$2(c==h,"CH"),a-1>numTmpRegs&&unsupported("too high MaxPool2D area");const m=u*c;return[repeatIdx(c,t=>{const n=[loadDataAddr(Reg.OutputPtr,e.outputOff),addPtr(Reg.OutputPtr,t),loadDataAddr(Reg.InputPtr,e.inputOff),addPtr(Reg.InputPtr,t)],r=range(a-1).map(e=>Reg.Tmp0+e);r.unshift(Reg.InputPtr);for(let e=1;e<a;++e){const t=addPtr(r[e],null,m*e,Reg.InputPtr);t.isDef=!0,n.push(t)}return n.push(repeat(p,()=>flatten(repeat(d,()=>{const e=[];for(let t=0;t<a;++t){for(let n=0;n<s;++n){const a=0==t&&0==n?Reg.S0:Reg.S1;e.push(load(a,1,r[t],!0),addPtr(r[t],null,c-1)),a!=Reg.S0&&e.push(vmax(Reg.S0,Reg.S0,a))}e.push(addPtr(r[t],null,(i-s)*c))}return e.push(store(Reg.OutputPtr,Reg.S0,1,!0),addPtr(Reg.OutputPtr,null,c-1)),e}),r.map(e=>addPtr(e,null,o*m-d*i*c))))),n})]}function compileDense(e){const t=e.layer.getConfig(),n=(numFPRegs>>1)-2,r=Reg.S1,a=r+n;2!=e.inputShape.length&&unsupported("inputShape: "+e.inputShape.length),t.dtype&&"float32"!=t.dtype&&unsupported("dtype: "+t.dtype);const s=e.layer.weights[0].read().arraySync(),o=e.inputShape[1];assert$2(s.length==o,"IH"),assert$2(s[0].length==t.units,"UN");const i=e.model,l=weightOffset(i),u=t.useBias?e.layer.weights[1].read().arraySync():null;for(let e=0;e<t.units;e++){u&&addBias(i,u[e]);for(let t=0;t<o;++t)addWeight(i,s[t][e]);alignWeights(i)}const c=[loadWeightAddr(Reg.KernelPtr,l),loadDataAddr(Reg.OutputPtr,e.outputOff),repeat(t.units,()=>{const s=[];s.push(t.useBias?load(Reg.S0,1,Reg.KernelPtr,!0):load0(Reg.S0)),s.push(loadDataAddr(Reg.InputPtr,e.inputOff));const l=e=>flatten(load(r,e,Reg.InputPtr,!0),loadWeight(i,a,e),range(e+1).map(t=>[t<e?vmul(r+t,r+t,a+t):null,t>=1?vadd(Reg.S0,Reg.S0,r+t-1):null])),u=o/n|0;u>0&&s.push(repeat(u,()=>l(n)));const c=o-u*n;return c>0&&pushRange(s,l(c)),s.push(store(Reg.OutputPtr,Reg.S0,1,!0)),s.push(relaxWeights()),s})];return addActivation(c,e),c}function noop(e){return[]}function shapeElts(e){let t=1;for(const n of e)null!=n&&(t*=n);return t}function fixupCompileInfo(e){void 0===e.testable&&(e.testable=!!e.compile),e.compile||(void 0===e.inPlace&&(e.inPlace=!0),e.compile=noop),e.computePaddedInputShape||(e.computePaddedInputShape=e=>e.inputShape.slice())}function isInPlace(e){var t;return!!(null===(t=compilers[e.getClassName()])||void 0===t?void 0:t.inPlace)}function needMInfPadding(e){var t;return!!(null===(t=compilers[e.getClassName()])||void 0===t?void 0:t.needsMInfPadding)}function shapeToString(e){return`[${e.filter(e=>null!=e).join(",")}]`}function assignLayerInfos(e,t){inited$1||(inited$1=!0,Object.values(compilers).forEach(fixupCompileInfo)),reset(),t.verbose&&e.summary();const n=e.layers[0].batchInputShape,r={weightPtr:0,weightBuffer:new Uint8Array(128),weightAsm:"",inputShape:n,outputShape:null,outputOffset:-1,arenaSize:-1,minArenaSize:-1,opts:t,stats:""};let a,s=[shapeElts(n),0],o=0,i=s[0];const l=e=>i=Math.max(e,i);for(const t of e.layers){const e=getLayerInfo(t);e.model=r,e.inputShape=a?a.outputShape:n,e.outputShape=t.computeOutputShape(e.inputShape);const i=compilers[t.getClassName()],u=i?i.computePaddedInputShape(e):e.inputShape.slice();e.inputOff=o,e.rawInputShape=e.inputShape.slice();const c=shapeElts(u);shapeElts(e.inputShape)!=c?(o=0==o?1:0,e.rawInputOff=e.inputOff,e.inputOff=o,e.inputShape=u,c>s[o]&&(s[o]=c),l(c+shapeElts(e.rawInputShape))):e.rawInputOff=null;const p=shapeElts(e.outputShape);isInPlace(t)?(l(shapeElts(e.inputShape)),l(shapeElts(e.outputShape))):(l(shapeElts(e.inputShape)+shapeElts(e.outputShape)),o=0==o?1:0),e.outputOff=o,p>s[o]&&(s[o]=p),a=e}r.outputShape=a.outputShape;const u=s[0];for(const t of e.layers){const e=getLayerInfo(t);e.inputOff&&(e.inputOff=u),e.outputOff&&(e.outputOff=u),e.rawInputOff&&(e.rawInputOff=u),e.stats={name:t.name}}const c=s[0]+s[1];return r.arenaSize=c,r.minArenaSize=i,c>1.2*i&&console.log("possible arena shrink with wiser allocation: "+(c/i).toFixed(3)+"x"),r}function compilePadding(e){const t=[comment("padding")];if(null==e.rawInputOff)return t;const n=e.rawInputShape.length>=4,r=e=>((e=e.slice()).shift(),n||e.unshift(1),e),[a,s,o]=r(e.rawInputShape),[i,l,u]=r(e.inputShape);assert$2(o==u);const c=l-s,p=c>>1,d=c-p,h=i-a,m=h>>1,f=h-m,g=numFPRegs>>1,$=numFPRegs-g,y=Reg.S0+g;t.push(needMInfPadding(e.layer)?loadMInf(Reg.S0):load0(Reg.S0));for(let e=1;e<g;++e)t.push(vadd(Reg.S0+e,Reg.S0,Reg.S0));t.push(loadDataAddr(Reg.InputPtr,e.rawInputOff)),t.push(loadDataAddr(Reg.OutputPtr,e.inputOff));const b=d+p,x=d+f*l;return t.push(...v(m*l+p)),t.push(repeat(a-1,()=>flatten(I(s),v(b)))),t.push(...I(s)),t.push(...v(x)),t;function v(e){const t=[],n=(e*=o)%g,r=(e-n)/g;return r&&t.push(repeat(r,()=>[store(Reg.OutputPtr,Reg.S0,g,!0)])),n&&t.push(store(Reg.OutputPtr,Reg.S0,n,!0)),t}function I(e){const t=[],n=(e*=o)%$,r=(e-n)/$;return r&&t.push(repeat(r,()=>[load(y,$,Reg.InputPtr,!0),store(Reg.OutputPtr,y,$,!0)])),n&&t.push(load(y,n,Reg.InputPtr,!0),store(Reg.OutputPtr,y,n,!0)),t}}function optimizeWithComment(e,t,n){e.float16weights&&(t=fixupAndMarkF16(t));const r=numCycles(t);e.optimize&&(t=optimize(t));const a=numCycles(t);n.unoptimizedCycles+=r,n.optimizedCycles+=a;const s=r?`${a} cycles (${(100*(r-a)/r).toFixed(1)}% opt)`:"(no computation)";return r&&t.unshift(comment(s)),{opcodes:t,optinfo:s}}function statsShape(e){return e.filter(e=>null!=e)}function compileModelCore(m,opts){const modelInfo=assignLayerInfos(m,opts);void 0===opts.optimize&&(opts.optimize=!0);const ops=[],layerStats=[],layer0=getLayerInfo(m.layers[0]),layerN=getLayerInfo(m.layers[m.layers.length-1]),totalStats={name:"TOTAL",inputShape:statsShape(layer0.rawInputShape||layer0.inputShape),outputShape:statsShape(layerN.outputShape),arenaBytes:0,codeBytes:0,weightBytes:0,unoptimizedCycles:0,optimizedCycles:0};for(const e of m.layers){const t=getLayerInfo(e);t.stats.unoptimizedCycles=0,t.stats.optimizedCycles=0,t.stats.arenaBytes=0,t.stats.inputShape=statsShape(t.rawInputShape||t.inputShape),t.stats.outputShape=statsShape(t.outputShape);const n=layerStats.length;if(layerStats.push(t.stats),ops.push([label("begin_"+n)]),null!=t.rawInputOff){const e=optimizeWithComment(opts,compilePadding(t),t.stats);ops.push(e.opcodes),t.stats.arenaBytes=shapeElts(t.rawInputShape)+shapeElts(t.inputShape)<<2,t.stats.hasPadding=!0}const r=compilers[e.getClassName()];if(r){const n=weightOffset(modelInfo),a=optimizeWithComment(opts,r.compile(t),t.stats);t.stats.weightBytes=weightOffset(modelInfo)-n<<2;const s=`data: ${shapeToString(t.inputShape)}@${t.inputOff} => ${shapeToString(t.outputShape)}@${t.outputOff}`,o=`Layer: ${e.getClassName()}; ${s}`;a.opcodes.unshift(comment(o)),opts.verbose&&console.log(o+" "+a.optinfo),ops.push(a.opcodes)}else unsupported("layer: "+e.getClassName());t.stats.unoptimizedCycles&&(t.stats.arenaBytes=Math.max(t.stats.arenaBytes,shapeElts(t.inputShape)+shapeElts(t.outputShape)<<2)),totalStats.unoptimizedCycles+=t.stats.unoptimizedCycles,ops.push([label("end_"+n)])}let flat=flatten(ops);const lastInfo=getLayerInfo(m.layers[m.layers.length-1]);modelInfo.outputOffset=lastInfo.outputOff;const cycles=numCycles(flat),cycleinfo=`total cycles: ${cycles} (${(cycles/84e3).toFixed(3)}ms at 84MHz)`;modelInfo.stats=cycleinfo,totalStats.optimizedCycles=cycles,opts.verbose&&console.log(modelInfo.stats),modelInfo.weightBuffer=modelInfo.weightBuffer.slice(0,modelInfo.weightPtr);const js=`\n${stringifyComment(modelInfo.stats)}\n((weights, mkRuntime) => {\n    "use strict";\n    const weightOff = ${modelInfo.arenaSize}\n    const dataOff = 0\n    const mem = new Float32Array(weightOff + ${weightOffset(modelInfo)})\n    mem.fill(1000.2342)\n    new Uint8Array(mem.buffer).set(weights, weightOff << 2)\n    const memU32 = new Uint32Array(mem.buffer)\n    const rt = mkRuntime(mem)\n    const { softmax, f32 } = rt\n    return (inputs => {\n        if (inputs.length != ${shapeElts(getLayerInfo(m.layers[0]).rawInputShape)})\n            throw new Error("invalid input size")\n        mem.set(inputs, dataOff)\n        let input, output, kernel\n        let ${range(numTmpRegs).map(e=>"tmp"+e).join(", ")}\n        let ${range(numFPRegs).map(e=>"s"+e).join(", ")}\n\n${toJSs(modelInfo,flat)}\n        \n        return mem.slice(${lastInfo.outputOff}, ${lastInfo.outputOff+shapeElts(lastInfo.outputShape)})\n    })\n})\n`,execute=eval(js)(modelInfo.weightBuffer,mkRuntime);let thumb="";if(opts.includeTest&&opts.testOutput&&opts.testOutputFromJS){const e=opts.testOutput;opts.testOutput=execute(opts.testInput),thumb=toThumb(modelInfo,flat),opts.testOutput=e}else thumb=toThumb(modelInfo,flat);const res={execute,js,thumb,machineCode:null,options:opts,memInfo:null,timeInfo:modelInfo.stats,stats:{total:totalStats,layers:layerStats}};return res}function mkRuntime(e){return{softmax:(t,n)=>{let r=e[t];for(let a=1;a<n;++a)r=Math.max(e[t+a],r);let a=0;for(let s=0;s<n;++s)a+=e[t+s]=Math.exp(e[t+s]-r);for(let r=0;r<n;++r)e[t+r]/=a},f32:e=>{const t=new Float32Array(1);return t[0]=e,t[0]},vcvtb_f32_f16:e=>float16AsUintToFloat(65535&e),vcvtt_f32_f16:e=>float16AsUintToFloat(e>>16&65535)}}const thumbRegs={r0:0,r1:1,r2:2,r3:3,r4:4,r5:5,r6:6,r7:7,r8:8,r9:9,r10:10,r11:11,r12:12,sp:13,r13:13,lr:14,r14:14,pc:15,r15:15},armConditions={eq:0,ne:1,cs:2,hs:2,cc:3,lo:3,mi:4,pl:5,vs:6,vc:7,hi:8,ls:9,ge:10,lt:11,gt:12,le:13,"":14,al:14};let fpRegs;class ThumbProcessor extends AbstractProcessor{constructor(){if(super(),this.runtimeIsARM=!1,!fpRegs){fpRegs={};for(let e=0;e<32;++e)fpRegs["s"+e]=e}const e=(e,t=!1)=>{for(const n of Object.keys(armConditions))(14!=armConditions[n]||t)&&e(n,armConditions[n])};this.addEnc("$r0","R0-7",e=>this.inrange(7,e,e)),this.addEnc("$r1","R0-7",e=>this.inrange(7,e,e<<3)),this.addEnc("$r2","R0-15",e=>this.inrange(15,e,7&e|(8&e)<<4)),this.addEnc("$r3","R0-15",e=>this.inrange(15,e,e<<3)),this.addEnc("$r4","R0-7",e=>this.inrange(7,e,e<<6)),this.addEnc("$r5","R0-7",e=>this.inrange(7,e,e<<8)),this.addEnc("$r01","R0-7",e=>this.inrange(7,e,e|e<<3)),this.addEnc("$i0","#0-255",e=>this.inrange(255,e,e)),this.addEnc("$i1","#0-1020",e=>this.inrange(255,e/4,e>>2)),this.addEnc("$i2","#0-510",e=>this.inrange(127,e/4,e>>2)),this.addEnc("$i3","#0-7",e=>this.inrange(7,e,e<<6)),this.addEnc("$i4","#0-31",e=>this.inrange(31,e,e<<6)),this.addEnc("$i5","#0-124",e=>this.inrange(31,e/4,e>>2<<6)),this.addEnc("$i6","#1-32",e=>0==e?null:32==e?0:this.inrange(31,e,e<<6)),this.addEnc("$i7","#0-62",e=>this.inrange(31,e/2,e>>1<<6)),this.addEnc("$i32","#0-2^32",e=>1),this.addEnc("$rl0","{R0-7,...}",e=>this.inrange(255,e,e)),this.addEnc("$rl1","{LR,R0-7,...}",e=>16384&e?this.inrange(255,-16385&e,256|255&e):this.inrange(255,e,e)),this.addEnc("$rl2","{PC,R0-7,...}",e=>32768&e?this.inrange(255,-32769&e,256|255&e):this.inrange(255,e,e)),this.addEnc("$la","LABEL",e=>this.inrange(255,e/4,e>>2)).isWordAligned=!0,this.addEnc("$lb","LABEL",e=>this.inrangeSigned(127,e/2,e>>1)),this.addEnc("$lb11","LABEL",e=>this.inrangeSigned(1023,e/2,e>>1)),this.addInst("adcs  $r0, $r1",16704,65472),this.addInst("add   $r2, $r3",17408,65280),this.addInst("add   $r5, pc, $i1",40960,63488),this.addInst("add   $r5, sp, $i1",43008,63488),this.addInst("add   sp, $i2",45056,65408).canBeShared=!0,this.addInst("adds  $r0, $r1, $i3",7168,65024),this.addInst("adds  $r0, $r1, $r4",6144,65024),this.addInst("adds  $r01, $r4",6144,65024),this.addInst("adds  $r5, $i0",12288,63488),this.addInst("adr   $r5, $la",40960,63488),this.addInst("ands  $r0, $r1",16384,65472),this.addInst("asrs  $r0, $r1",16640,65472),this.addInst("asrs  $r0, $r1, $i6",4096,63488),this.addInst("bics  $r0, $r1",17280,65472),this.addInst("bkpt  $i0",48640,65280),this.addInst("blx   $r3",18304,65415),this.addInst("bx    $r3",18176,65408),this.addInst("cmn   $r0, $r1",17088,65472),this.addInst("cmp   $r0, $r1",17024,65472),this.addInst("cmp   $r2, $r3",17664,65280),this.addInst("cmp   $r5, $i0",10240,63488),this.addInst("eors  $r0, $r1",16448,65472),this.addInst("ldmia $r5!, $rl0",51200,63488),this.addInst("ldmia $r5, $rl0",51200,63488),this.addInst("ldr   $r0, [$r1, $i5]",26624,63488),this.addInst("ldr   $r0, [$r1, $r4]",22528,65024),this.addInst("ldr   $r5, [pc, $i1]",18432,63488),this.addInst("ldr   $r5, $la",18432,63488),this.addInst("ldr   $r5, [sp, $i1]",38912,63488).canBeShared=!0,this.addInst("ldr   $r5, [sp]",38912,63488).canBeShared=!0,this.addInst("ldrb  $r0, [$r1, $i4]",30720,63488),this.addInst("ldrb  $r0, [$r1, $r4]",23552,65024),this.addInst("ldrh  $r0, [$r1, $i7]",34816,63488),this.addInst("ldrh  $r0, [$r1, $r4]",23040,65024),this.addInst("ldrsb $r0, [$r1, $r4]",22016,65024),this.addInst("ldrsh $r0, [$r1, $r4]",24064,65024),this.addInst("lsls  $r0, $r1",16512,65472),this.addInst("lsls  $r0, $r1, $i4",0,63488),this.addInst("lsrs  $r0, $r1",16576,65472),this.addInst("lsrs  $r0, $r1, $i6",2048,63488),this.addInst("mov   $r2, $r3",17920,65280),this.addInst("movs  $r0, $r1",0,65472),this.addInst("movs  $r5, $i0",8192,63488),this.addInst("muls  $r0, $r1",17216,65472),this.addInst("mvns  $r0, $r1",17344,65472),this.addInst("negs  $r0, $r1",16960,65472),this.addInst("nop",18112,65535),this.addInst("orrs  $r0, $r1",17152,65472),this.addInst("pop   $rl2",48128,65024),this.addInst("push  $rl1",46080,65024),this.addInst("rev   $r0, $r1",47616,65472),this.addInst("rev16 $r0, $r1",47680,65472),this.addInst("revsh $r0, $r1",47808,65472),this.addInst("rors  $r0, $r1",16832,65472),this.addInst("sbcs  $r0, $r1",16768,65472),this.addInst("sev",48960,65535),this.addInst("stm   $r5!, $rl0",49152,63488),this.addInst("stmia $r5!, $rl0",49152,63488),this.addInst("stmea $r5!, $rl0",49152,63488),this.addInst("str   $r0, [$r1, $i5]",24576,63488).canBeShared=!0,this.addInst("str   $r0, [$r1]",24576,63488).canBeShared=!0,this.addInst("str   $r0, [$r1, $r4]",20480,65024),this.addInst("str   $r5, [sp, $i1]",36864,63488).canBeShared=!0,this.addInst("str   $r5, [sp]",36864,63488).canBeShared=!0,this.addInst("strb  $r0, [$r1, $i4]",28672,63488),this.addInst("strb  $r0, [$r1, $r4]",21504,65024),this.addInst("strh  $r0, [$r1, $i7]",32768,63488),this.addInst("strh  $r0, [$r1, $r4]",20992,65024),this.addInst("sub   sp, $i2",45184,65408),this.addInst("subs  $r0, $r1, $i3",7680,65024),this.addInst("subs  $r0, $r1, $r4",6656,65024),this.addInst("subs  $r01, $r4",6656,65024),this.addInst("subs  $r5, $i0",14336,63488),this.addInst("svc   $i0",57088,65280),this.addInst("sxtb  $r0, $r1",45632,65472),this.addInst("sxth  $r0, $r1",45568,65472),this.addInst("tst   $r0, $r1",16896,65472),this.addInst("udf   $i0",56832,65280),this.addInst("uxtb  $r0, $r1",45760,65472),this.addInst("uxth  $r0, $r1",45696,65472),this.addInst("wfe",48928,65535),this.addInst("wfi",48944,65535),this.addInst("yield",48912,65535),this.addInst("cpsid i",46706,65535),this.addInst("cpsie i",46690,65535),e((e,t)=>this.addInst(`b${e} $lb`,53248|t<<8,65280)),this.addInst("b     $lb11",57344,63488),this.addInst("bal   $lb11",57344,63488),this.addInst("bl    $lb",61440,63488),this.addInst("bb    $lb",57344,63488),this.addInst("ldlit   $r5, $i32",18432,63488),this.addEnc("$RL0","{R0-15,...}",e=>this.inrange(65535,e,e)),this.addEnc("$R0","R0-15",e=>this.inrange(15,e,e<<8)),this.addEnc("$R1","R0-15",e=>this.inrange(15,e,e<<16)),this.addEnc("$R2","R0-15",e=>this.inrange(15,e,e<<12)),this.addEnc("$R3","R0-15",e=>this.inrange(15,e,e<<0)),this.addEnc("$I0","#0-4095",e=>this.inrange(4095,e,255&e|(1792&e)<<4|(2048&e)<<15)),this.addEnc("$I1","#0-4095",e=>this.inrange(4095,e,e)),this.addEnc("$I2","#0-65535",e=>this.inrange(65535,e,255&e|(1792&e)<<4|(2048&e)<<15|(61440&e)<<4)),this.addEnc("$I3","#0-31",e=>this.inrange(31,e,(3&e)<<6|e>>2<<12)),this.addEnc("$LB","LABEL",e=>{const t=e>>1&2047|(e>>12&63)<<16|(e>>18&1)<<13|(e>>19&1)<<11|(e>>20&1)<<26;return null==this.inrangeSigned(1048575,e/2,t)?null:t}),this.addEnc("$S0","S0-31",e=>this.inrange(31,e,e>>1<<0|(1&e)<<5)),this.addEnc("$S1","S0-31",e=>this.inrange(31,e,e>>1<<12|(1&e)<<22)),this.addEnc("$S2","S0-31",e=>this.inrange(31,e,e>>1<<16|(1&e)<<7)),this.addEnc("$SL0","{S0-S31}",e=>{if(!(e|=0))return null;let t=0;for(;t<32&&0==(e&1<<t);)t++;if(!(e>>>=t))return null;let n=0;for(;1&e;)e>>=1,n++;return e?null:(e=t)>>1<<12|(1&e)<<22|n}),this.addInst32("push  $RL0",3912040448,4294901760),this.addInst32("pop   $RL0",3904700416,4294901760),this.addInst32("addw  $R0, $R1, $I0",4060086272,4226842624),this.addInst32("subw  $R0, $R1, $I0",4070572032,4226842624),this.addInst32("ldr   $R2, [$R1, $I1]",4174381056,4293918720),this.addInst32("str   $R2, [$R1, $I1]",4173332480,4293918720),this.addInst32("movw  $R0, $I2",4064280576,4226842624),this.addInst32("add   $R0, $R1, $R3, lsl $I3",3942645760,4293951488),this.addInst32("subs  $R0, $R1, $i0",4054843392,4293951488),this.addInst32("sub   $R0, $R1, $i0",4053794816,4293951488),this.addInst32("adds  $R0, $R1, $i0",4044357632,4293951488),this.addInst32("add   $R0, $R1, $i0",4043309056,4293951488),e((e,t)=>this.addInst32(`b${e} $LB`,4026564608|t<<22,4223717376),!0),e((e,t)=>this.addInst(`it ${e}`,48904|t<<4,65535),!0),this.addInst32("vabs.f32     $S1, $S0",4004514496,4290711504),this.addInst32("vadd.f32     $S1, $S2, $S0",3996125696,4289728336),this.addInst32("vmul.f32     $S1, $S2, $S0",3995077120,4289728336),this.addInst32("vcmpe.f32    $S1, #0.0",4004842176,4290711536),this.addInst32("vcmpe.f32    $S1, $S0",4004776640,4290711504),this.addInst32("vcmp.f32     $S1, #0.0",4004842048,4290711536),this.addInst32("vcmp.f32     $S1, $S0",4004776512,4290711504),this.addInst32("vdiv.f32     $S1, $S2, $S0",4001368576,4289728336),this.addInst32("vfma.f32     $S1, $S2, $S0",4003465728,4289728336),this.addInst32("vfms.f32     $S1, $S2, $S0",4003465792,4289728336),this.addInst32("vfnma.f32    $S1, $S2, $S0",4002417216,4289728336),this.addInst32("vfnms.f32    $S1, $S2, $S0",4002417152,4289728336),this.addInst32("vmla.f32     $S1, $S2, $S0",3791654160,4289728272),this.addInst32("vmls.f32     $S1, $S2, $S0",3793751312,4289728272),this.addInst32("vneg.f32     $S1, $S0",4004579904,4290711504),this.addInst32("vsqrt.f32    $S1, $S0",4004580032,4290711504),this.addInst32("vsub.f32     $S1, $S2, $S0",3996125760,4289728336),this.addInst32("vstmdb       $R1!, $SL0",3978299904,4289728256),this.addInst32("vstmia       $R1!, $SL0",3969911296,4289728256),this.addInst32("vstmia       $R1, $SL0",3967814144,4289728256),this.addInst32("vstm         $R1!, $SL0",3969911296,4289728256),this.addInst32("vstm         $R1, $SL0",3967814144,4289728256),this.addInst32("vldmdb       $R1!, $SL0",3979348480,4289728256),this.addInst32("vldmia       $R1!, $SL0",3970959872,4289728256),this.addInst32("vldmia       $R1, $SL0",3968862720,4289728256),this.addInst32("vldm         $R1!, $SL0",3970959872,4289728256),this.addInst32("vldm         $R1, $SL0",3968862720,4289728256),this.addInst32("vldr         $S1, [$R1, $i1]",3985639936,4289728256),this.addInst32("vstr         $S1, [$R1, $i1]",3984591360,4289728256),this.addInst32("vldr         $S1, [$R1]",3985639936,4289728256),this.addInst32("vmrs         APSR_nzcv, fpscr",4008835600,4294967295),this.addInst32("vmrs         APSR_nzcv, FPSCR",4008835600,4294967295),this.addInst32("vmov.f32     $S1, $S0",4004514368,4290711504),this.addInst32("vmov         $S2, $R2",3992979984,4293922687),this.addInst32("vmov         $R2, $S2",3994028560,4293922687),this.addInst32("vldr         $S1, $la",3986622976,4290711296),this.addInst32("vmov.f32     $S1, #1.0",4004973056,4290711536),this.addInst32("vcvt.s32.f32 $S1, $S0",4005366464,4290711504),this.addInst32("vcvtb.f32.f16 $S1, $S0",4004645440,4290711504),this.addInst32("vcvtt.f32.f16 $S1, $S0",4004645568,4290711504),this.addInst32("vcvtb.f16.f32 $S1, $S0",4004710976,4290711504),this.addInst32("vcvtt.f16.f32 $S1, $S0",4004711104,4290711504)}stripCondition(e){if(e.length>=5){const t=e.indexOf(".");let n="",r=!1;if(t>0&&(n=e.slice(t),e=e.slice(0,t),".32"==n&&(r=!0,n="")),armConditions[e.slice(-2)])return e.slice(0,-2)+n;if(r)return e}return null}toFnPtr(e,t,n){return this.runtimeIsARM&&/::/.test(n)?e+t&-2:e+t|1}wordSize(){return 4}is32bit(e){return"bl"==e.name||"bb"==e.name||e.is32bit}postProcessAbsAddress(e,t){return(t^=1)-e.baseOffset}emit32(e,t,n){let r=!!(t%2);r&&(t=t+1&-4);let a=t>>1;if(assert(null!=a),(0|a)!=a||!(-2097152<a&&a<2097152))return emitErr("jump out of range",n);let s=2047&a,o=a>>11&1023;return{opcode:4026531840&a?62464|o:61440|o,opcode2:r?59392|s:63488|s,stack:0,numArgs:[t],labelName:n}}expandLdlit(e){let t,n=!1,r=[],a={},s=1;for(let o=0;o<e.lines.length;++o){let i=e.lines[o];if(r.push(i),"instruction"==i.type&&i.instruction&&"ldlit"==i.instruction.name){if(!t){let r=i.location+900,a=o+1;for(;a<e.lines.length&&!(e.lines[a].location>r);++a){let n=e.lines[a].getOp();("b"==n||"bb"==n||"pop"==n&&"pc"==e.lines[a].words[2])&&(t=e.lines[a])}if(t)n=!1;else for(n=!0;--a>o;)if("instruction"==e.lines[a].type){t=e.lines[a];break}}let r=i.words[1],l="#"+i.words[3],u=lookup(a,l);u||(u="_ldlit_"+ ++s,a[l]=u),i.update(`ldr ${r}, ${u}`)}if(i===t){t=null;let o=[],l="_jmpwords_"+ ++s;n&&o.push("bb "+l),o.push(".balign 4");for(let e of Object.keys(a))o.push(a[e]+": .word "+e.slice(1));n&&o.push(l+":");for(let t of o){e.buildLine(t,r);let n=r[r.length-1];n.scope=i.scope,n.lineNo=i.lineNo}a={}}}e.lines=r}getAddressFromLabel(e,t,n,r=!1){let a=e.lookupLabel(n);if(null==a)return null;let s=e.location()+4;return r&&(s&=4294967292),a-s}isPop(e){return 48128==e}isPush(e){return 46080==e}isAddSP(e){return 45056==e}isSubSP(e){return 45184==e}peephole(e,t,n){let r=this.encoders.$lb11,a=this.encoders.$lb;function s(e,t){return null!=e.encode(t.numArgs[0]+8)&&null!=e.encode(t.numArgs[0]-8)&&null!=e.encode(t.numArgs[0])}let o=e.getOp(),i=!1;"bne"!=o&&"beq"!=o||("b"==t.getOp()&&0==e.numArgs[0]&&(i=!0),"bb"==t.getOp()&&2==e.numArgs[0]&&(i=!0)),"bb"==o&&s(r,e)?e.update("b "+e.words[1]):"b"==o&&-2==e.numArgs[0]?e.update(""):"bne"==o&&i&&s(a,t)?(e.update("beq "+t.words[1]),t.update("")):"beq"==o&&i&&s(a,t)?(e.update("bne "+t.words[1]),t.update("")):"push"!=o||16384!=e.numArgs[0]||"push"!=t.getOp()||16384&t.numArgs[0]?"pop"==o&&"pop"==t.getOp()&&32768==t.numArgs[0]?(e.update(e.text.replace("}",", pc}")),t.update("")):"push"==o&&"pop"==t.getOp()&&e.numArgs[0]==t.numArgs[0]?(assert(e.numArgs[0]>0),e.update(""),t.update("")):"push"==o&&"pop"==t.getOp()&&4==e.words.length&&4==t.words.length?(assert("{"==e.words[1]),e.update("mov "+t.words[2]+", "+e.words[2]),t.update("")):n&&"movs $r5, $i0"==e.getOpExt()&&"mov $r0, $r1"==t.getOpExt()&&e.numArgs[0]==t.numArgs[1]&&clobbersReg(n,e.numArgs[0])?(e.update("movs r"+t.numArgs[0]+", #"+e.numArgs[1]),t.update("")):"pop"==o&&singleReg(e)>=0&&"push"==t.getOp()&&singleReg(e)==singleReg(t)?(e.update("ldr r"+singleReg(e)+", [sp, #0]"),t.update("")):"push"==o&&"ldr $r5, [sp, $i1]"==t.getOpExt()&&singleReg(e)==t.numArgs[0]&&0==t.numArgs[1]?t.update(""):n&&"push"==o&&singleReg(e)>=0&&preservesReg(t,singleReg(e))&&"pop"==n.getOp()&&singleReg(e)==singleReg(n)&&(e.update(""),n.update("")):(e.update(t.text.replace("{","{lr, ")),t.update(""))}registerNo(e,t){if(!e)return null;e=e.toLowerCase();let n=thumbRegs;"S"==t.name[1]&&(n=fpRegs);const r=n[e];return void 0===r?null:r}testAssembler(){expectError(this,"lsl r0, r0, #8"),expectError(this,"push {r17}"),expectError(this,"mov r0, r1 foo"),expectError(this,"movs r14, #100"),expectError(this,"push {r0"),expectError(this,"push lr,r0}"),expectError(this,"b #+11"),expectError(this,"b #+10240000"),expectError(this,"bne undefined_label"),expectError(this,".foobar"),expect$1(this,"0200      lsls    r0, r0, #8\nb500      push    {lr}\n2064      movs    r0, #100        ; 0x64\nb401      push    {r0}\nbc08      pop     {r3}\nb501      push    {r0, lr}\nbd20      pop {r5, pc}\nbc01      pop {r0}\n4770      bx      lr\n0000      .balign 4\ne6c0      .word   -72000\nfffe\n"),expect$1(this,"4291      cmp     r1, r2\nd100      bne     l6\ne000      b       l8\n1840  l6: adds    r0, r0, r1\n4718  l8: bx      r3\n"),expect$1(this,"          @stackmark base\nb403      push    {r0, r1}\n          @stackmark locals\n9801      ldr     r0, [sp, locals@1]\nb401      push    {r0}\n9802      ldr     r0, [sp, locals@1]\nbc01      pop     {r0}\n          @stackempty locals\n9901      ldr     r1, [sp, locals@1]\n9102      str     r1, [sp, base@0]\n          @stackempty locals\nb002      add     sp, #8\n          @stackempty base\n"),expect$1(this,"b090      sub sp, #4*16\nb010      add sp, #4*16\n"),expect$1(this,'6261      .string "abc"\n0063      \n'),expect$1(this,'6261      .string "abcde"\n6463      \n0065      \n'),expect$1(this,"3042      adds r0, 0x42\n1c0d      adds r5, r1, #0\nd100      bne #0\n2800      cmp r0, #0\n6b28      ldr r0, [r5, #48]\n0200      lsls r0, r0, #8\n2063      movs r0, 0x63\n4240      negs r0, r0\n46c0      nop\nb500      push {lr}\nb401      push {r0}\nb402      push {r1}\nb404      push {r2}\nb408      push {r3}\nb520      push {r5, lr}\nbd00      pop {pc}\nbc01      pop {r0}\nbc02      pop {r1}\nbc04      pop {r2}\nbc08      pop {r3}\nbd20      pop {r5, pc}\n9003      str r0, [sp, #4*3]\n")}}function preservesReg(e,t){return"movs $r5, $i0"==e.getOpExt()&&e.numArgs[0]!=t}function clobbersReg(e,t){return!!("pop"==e.getOp()&&e.numArgs[0]&1<<t)}function singleReg(e){assert("push"==e.getOp()||"pop"==e.getOp());let t=0,n=-1,r=e.numArgs[0];for(;r>0;)1&r&&(n=-1==n?t:-2),r>>=1,t++;return n>=0?n:-1}const epsF32=2e-5,epsF16=.0045;function mkProcessorFile(){const e=new File$1(new ThumbProcessor);return e.ei.testAssembler(),e.disablePeepHole=!0,e.lookupExternalLabel=e=>null,e.normalizeExternalLabel=e=>e,e.throwOnError=!0,e}function throwAssemblerErrors(e){if(e.errors.length>0)throw new Error(e.errors[0].message)}function assemble(e){const t=mkProcessorFile();t.emit(e),throwAssemblerErrors(t);const n=new Uint8Array(t.buf.length<<1);for(let e=0;e<t.buf.length;++e)n[e<<1]=255&t.buf[e],n[1+(e<<1)]=t.buf[e]>>8&255;return{binary:n,procFile:t}}function randomTensor(e,t=1){const n=shapeElts(e=e.map(e=>null==e?1:e));return dist.tidy(()=>dist.tensor(range(n).map(e=>t*randomSFloat())).reshape(e))}function isNear(e,t,n){const r=Math.abs(e-t);return r<n||r/(Math.abs(e)+Math.abs(t))<n}function optionsWithTestData(e,t){t=flatClone(t);let n=0,r=0;for(;;){const s=randomTensor(e.inputs[0].shape),o=e.predict(s).flatten().arraySync();let i=0,l=1;for(const e of o)i+=e,l*=e;if(!(Math.abs(i-1)<.1)){a();break}if(l>r&&(r=l,a()),n++>(t.includeTest?1e3:100)||r>.1){l||a();break}function a(){t.testInput=s.flatten().arraySync(),t.testOutput=o}}return t}function compileModel(e,t){const n=compileModelCore(e,t),r=assemble(n.thumb);n.machineCode=r.binary;let a=0;for(const e of n.stats.layers)e.codeBytes=r.procFile.lookupLabel("end_"+a)-r.procFile.lookupLabel("begin_"+a),a++;const s=getStatsFromBin(n.machineCode,n.stats.total);return n.memInfo=s.info,n}function validateCompilation(e){const t=e.options,n=t.testOutput,r=e.execute(t.testInput);e.options.verbose&&console.log("Test output",r);let a=0;for(let e=0;e<r.length&&(isNear(n[e],r[e],t.float16weights?epsF16:epsF32)||(console.log(`at ${e} ${n[e]}[exp] - ${r[e]} = ${n[e]-r[e]}`),a++,!(a>5)));++e);if(a)throw new Error("mismatch")}function compileAndTest(e,t){let n;try{return n=compileModel(e,t=optionsWithTestData(e,t)),validateCompilation(n),n}catch(r){throw t.info&&console.log(t.info),n&&t.verbose||(t.verbose=!0,n=compileModelCore(e,t)),console.log(n.js),console.log("Failing model: ",e.name),r}}function readU32(e,t){return(e[t]|e[t+1]<<8|e[t+2]<<16|e[t+3]<<24)>>>0}function readU32s(e){const t=[];for(let n=0;n<e.length;n+=4)t.push(readU32(e,n));return t}function getStatsFromBin(e,t){let[n,r,a,s,o,i,l,u]=readU32s(e.slice(0,64));if(809963362!=n)return null;const c=i||s,p=o-a,d=100*p/c,h=s-c;function m(e){return(e/1024).toFixed(2)+"k"}const f=`model: ${m(c)}; code: ${m(p)} (${d.toFixed(1)}%); arena: ${m(u)}; test ${m(h)}`;return t&&(t.arenaBytes=u,t.codeBytes=p,t.weightBytes=c-p),{info:f,modelSize:c,codeSize:p,testSize:h,totalSize:s,arenaSize:u}}var compileAndTest_1=compileAndTest,compileModel_1=compileModel;const _excluded=["worker"];function addLayer(e,t,n){let r;const a=e.inputs[0].fields.expand_button.value;switch(e.type){case"model_block_conv1d_layer":r=conv1d$2(t?{inputShape:t,kernelSize:[a.kernelSize],strides:a.strideSize,filters:a.numFilters,activation:a.activation,padding:"same"}:{kernelSize:[a.kernelSize],strides:a.strideSize,filters:a.numFilters,activation:a.activation,padding:"same"});break;case"model_block_maxpool1d_layer":r=maxPooling1d$1(t?{inputShape:t,poolSize:[a.poolSize],padding:"same"}:{poolSize:[a.poolSize],padding:"same"});break;case"model_block_avgpool1d_layer":break;case"model_block_conv2d_layer":r=conv2d$5(t?{inputShape:t,kernelSize:[a.kernelSize,a.kernelSize],strides:a.strideSize,filters:a.numFilters,activation:a.activation,padding:"same"}:{kernelSize:[a.kernelSize,a.kernelSize],strides:a.strideSize,filters:a.numFilters,activation:a.activation,padding:"same"});break;case"model_block_maxpool2d_layer":r=maxPooling2d$1(t?{inputShape:t,poolSize:[a.poolSize,a.poolSize],padding:"same"}:{poolSize:[a.poolSize,a.poolSize],padding:"same"});break;case"model_block_avgpool2d_layer":break;case"model_block_dropout_layer":r=dropout$3({rate:a.rate});break;case"model_block_flatten_layer":r=t?flatten$4({inputShape:t}):flatten$4();break;case"model_block_dense_layer":r=dense$1({units:n||a.numUnits,activation:n?"softmax":a.activation});break;default:console.error("Received an invalid layer type")}return r}function buildDefaultModel(e,t,n){e.add(conv2d$5({inputShape:t,kernelSize:[4,4],strides:1,filters:16,padding:"same",activation:"relu"})),e.add(maxPooling2d$1({poolSize:[2,2],padding:"same"})),e.add(dropout$3({rate:.1})),e.add(conv2d$5({kernelSize:[2,2],strides:1,filters:16,padding:"same",activation:"relu"})),e.add(maxPooling2d$1({poolSize:[2,2],padding:"same"})),e.add(dropout$3({rate:.1})),e.add(conv2d$5({kernelSize:[2,2],strides:1,filters:16,padding:"same",activation:"relu"})),e.add(dropout$3({rate:.1})),e.add(flatten$4()),e.add(dense$1({units:n,activation:"softmax"}))}function buildModelFromJSON(e,t){const n=sequential$1();let r;if("default"==t)e.inputShape.push(1),buildDefaultModel(n,e.inputShape,e.outputShape),r={loss:"categoricalCrossentropy",optimizer:"adam",metrics:["acc"],epochs:250};else{"2d"==e.convolutionType&&e.inputShape.push(1);const s=t.inputs.filter(e=>"LAYER_INPUTS"==e.name)[0].child;let o=addLayer(s,e.inputShape,null);var a;n.add(o),s&&(null==(a=s.children)||a.forEach((t,r)=>{o=addLayer(t,null,r==s.children.length-1?e.outputShape:null),n.add(o)}));const i=t.inputs[1].fields.expand_button.value;r={loss:i.lossFn,optimizer:i.optimizer,metrics:[i.metrics],epochs:i.numEpochs}}return{model:n,params:r}}const handlers={compile:async e=>{const{data:t}=e,{model:n,params:r}=buildModelFromJSON(t.model,t.modelBlockJSON);let a,s;await n.save({save:e=>{a=e;const t={modelArtifactsInfo:{dateSaved:new Date,modelTopologyType:"JSON"}};return Promise.resolve(t)}}),a.weightData=null;try{s=await compileModel_1(n,{verbose:!1,float16weights:!0,optimize:!0})}catch(t){return console.error("Error with getting model stats during compiling: ",t),_extends({},e,{data:void 0})}const o=[...s.stats.layers,s.stats.total];return _extends({},e,{data:{modelJSON:a,modelStats:o,trainingParams:r}})},train:async e=>{const{data:t}=e;if(t.xData[0].length!=t.model.inputShape[0]||t.xData[0][0].length!=t.model.inputShape[1])return console.error("Input data does not match expected shape of model."),_extends({},e,{data:void 0});const n=t.model.modelJSON,r=await loadLayersModel$1({load:()=>Promise.resolve(n)});let a=tensor3d$1(t.xData,[t.xData.length,t.model.inputShape[0],t.model.inputShape[1]]);n.modelTopology.config.layers[0].class_name.indexOf("2D")>-1&&(a=a.expandDims(3));const s=oneHot$5(tensor1d$1(t.yData,"int32"),t.model.labels.length),o=t.trainingParams;try{r.compile({loss:o.loss,optimizer:o.optimizer,metrics:o.metrics})}catch(t){return console.error("Error with model.compile during training: ",t),_extends({},e,{data:void 0})}let i,l=[];try{await r.fit(a,s,{epochs:o.epochs,validationSplit:t.xData.length>40?.1:0,callbacks:{onEpochEnd}}).then(e=>{l=e.history.acc})}catch(t){return console.error("Error with model.fit during training: ",t),_extends({},e,{data:void 0})}await r.save({save:e=>{i=e;const t={modelArtifactsInfo:{dateSaved:new Date,modelTopologyType:"JSON"}};return Promise.resolve(t)}});const u=i.weightData;let c;i.weightData=null;try{c=await compileAndTest_1(r,{verbose:!1,includeTest:!0,float16weights:!0,optimize:!0})}catch(e){console.error("Error compiling arm model during training: ",e)}return _extends({},e,{data:{modelWeights:u,trainingLogs:l,armModel:JSON.stringify(c)}})},predict:async e=>{const{data:t}=e,n=t.model.modelJSON;n.weightData=new Uint32Array(t.model.weights).buffer;const r=await loadLayersModel$1({load:()=>Promise.resolve(n)});let a,s=tensor$1(t.zData);n.modelTopology.config.layers[0].class_name.indexOf("2D")>-1&&(s=s.expandDims(3));try{a=await r.predict(s)}catch(t){return console.error("Error with model.predict during prediction: ",t),_extends({},e,{data:void 0})}const o=await a.argMax(1).dataSync(),i=await a.dataSync(),l=[],u=t.zData.length,c=t.model.labels.length;for(let e=0;e<u;e++){const n={};for(let r=0;r<c;r++)n[t.model.labels[e*c+r]]=i[e*c+r];l.push(n)}return _extends({},e,{data:{predictAll:l,predictTop:o}})}};async function dispatchAsyncMessages(e){try{const t=handlers[e.type];return await(null==t?void 0:t(e))}catch(e){return void console.error(e)}}async function handleMessage(e){const t=e.data,{worker:n}=t;if(_objectWithoutPropertiesLoose(t,_excluded),"tf"!==n)return;const r=await dispatchAsyncMessages(t);self.postMessage(r)}function onEpochEnd(e,t){self.postMessage({type:"progress",data:t})}self.addEventListener("message",handleMessage),console.debug("jacdac tf: worker registered");
//# sourceMappingURL=tf-worker.js.map

var __webpack_export_target__ = exports;
for(var i in __webpack_exports__) __webpack_export_target__[i] = __webpack_exports__[i];
if(__webpack_exports__.__esModule) Object.defineProperty(__webpack_export_target__, "__esModule", { value: true });
/******/ })()
;
//# sourceMappingURL=484.render-page.js.map