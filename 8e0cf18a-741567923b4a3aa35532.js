(self["webpackChunkjacdac_docs"] = self["webpackChunkjacdac_docs"] || []).push([[1954],{

/***/ 93192:
/***/ (function(__unused_webpack_module, __unused_webpack_exports, __webpack_require__) {

var _asyncToGenerator = __webpack_require__(48926);

__webpack_require__(65743);

__webpack_require__(25438);

function _mergeNamespaces(e, t) {
  return t.forEach(function (t) {
    t && "string" != typeof t && !Array.isArray(t) && Object.keys(t).forEach(function (n) {
      if ("default" !== n && !(n in e)) {
        var r = Object.getOwnPropertyDescriptor(t, n);
        Object.defineProperty(e, n, r.get ? r : {
          enumerable: !0,
          get: function get() {
            return t[n];
          }
        });
      }
    });
  }), e;
}

function _extends() {
  return _extends = Object.assign || function (e) {
    for (var t = 1; t < arguments.length; t++) {
      var n = arguments[t];

      for (var r in n) {
        Object.prototype.hasOwnProperty.call(n, r) && (e[r] = n[r]);
      }
    }

    return e;
  }, _extends.apply(this, arguments);
}

function _objectWithoutPropertiesLoose(e, t) {
  if (null == e) return {};
  var n,
      r,
      a = {},
      s = Object.keys(e);

  for (r = 0; r < s.length; r++) {
    t.indexOf(n = s[r]) >= 0 || (a[n] = e[n]);
  }

  return a;
}

var EPSILON_FLOAT32$3 = 1e-7,
    EPSILON_FLOAT16$3 = 1e-4;

class DataStorage$1 {
  constructor(e, t) {
    this.backend = e, this.dataMover = t, this.data = new WeakMap(), this.dataIdsCount = 0;
  }

  get(e) {
    return this.data.has(e) || this.dataMover.moveData(this.backend, e), this.data.get(e);
  }

  set(e, t) {
    this.dataIdsCount++, this.data.set(e, t);
  }

  has(e) {
    return this.data.has(e);
  }

  delete(e) {
    return this.dataIdsCount--, this.data.delete(e);
  }

  numDataIds() {
    return this.dataIdsCount;
  }

}

class KernelBackend$1 {
  refCount(e) {
    return notYetImplemented$1("refCount");
  }

  incRef(e) {
    return notYetImplemented$1("incRef");
  }

  timerAvailable() {
    return !0;
  }

  time(e) {
    return notYetImplemented$1("time");
  }

  read(e) {
    return notYetImplemented$1("read");
  }

  readSync(e) {
    return notYetImplemented$1("readSync");
  }

  numDataIds() {
    return notYetImplemented$1("numDataIds");
  }

  disposeData(e, t) {
    return notYetImplemented$1("disposeData");
  }

  write(e, t, n) {
    return notYetImplemented$1("write");
  }

  move(e, t, n, r, a) {
    return notYetImplemented$1("move");
  }

  memory() {
    return notYetImplemented$1("memory");
  }

  floatPrecision() {
    return notYetImplemented$1("floatPrecision");
  }

  epsilon() {
    return 32 === this.floatPrecision() ? EPSILON_FLOAT32$3 : EPSILON_FLOAT16$3;
  }

  dispose() {
    return notYetImplemented$1("dispose");
  }

}

function notYetImplemented$1(e) {
  throw new Error("'".concat(e, "' not yet implemented or not found in the registry. This kernel may not be supported by the tfjs backend you have chosen"));
}

function shuffle$1(e) {
  var t = e.length,
      n = 0;

  for (; t > 0;) {
    n = Math.random() * t | 0, t--, swap$1(e, t, n);
  }
}

function clamp$1(e, t, n) {
  return Math.max(e, Math.min(t, n));
}

function nearestLargerEven$1(e) {
  return e % 2 == 0 ? e : e + 1;
}

function swap$1(e, t, n) {
  var r = e[t];
  e[t] = e[n], e[n] = r;
}

function sum$7(e) {
  var t = 0;

  for (var n = 0; n < e.length; n++) {
    t += e[n];
  }

  return t;
}

function assert$6(e, t) {
  if (!e) throw new Error("string" == typeof t ? t : t());
}

function assertShapesMatch$1(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : "";
  assert$6(arraysEqual$1(e, t), () => n + " Shapes ".concat(e, " and ").concat(t, " must match"));
}

function assertNonNull$1(e) {
  assert$6(null != e, () => "The input to the tensor constructor must be a non-null value.");
}

function flatten$6(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : [];
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  if (null == t && (t = []), Array.isArray(e) || isTypedArray$1(e) && !n) for (var r = 0; r < e.length; ++r) {
    flatten$6(e[r], t, n);
  } else t.push(e);
  return t;
}

function sizeFromShape$1(e) {
  if (0 === e.length) return 1;
  var t = e[0];

  for (var n = 1; n < e.length; n++) {
    t *= e[n];
  }

  return t;
}

function arraysEqual$1(e, t) {
  if (e === t) return !0;
  if (null == e || null == t) return !1;
  if (e.length !== t.length) return !1;

  for (var n = 0; n < e.length; n++) {
    if (e[n] !== t[n]) return !1;
  }

  return !0;
}

function isInt$1(e) {
  return e % 1 == 0;
}

function sizeToSquarishShape$1(e) {
  var t = Math.ceil(Math.sqrt(e));
  return [t, Math.ceil(e / t)];
}

function rightPad$1(e, t) {
  return t <= e.length ? e : e + " ".repeat(t - e.length);
}

function repeatedTry$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : e => 0;
  var n = arguments.length > 2 ? arguments[2] : undefined;
  return new Promise((r, a) => {
    var s = 0;

    var o = () => {
      if (e()) return void r();
      s++;
      var i = t(s);
      null != n && s >= n ? a() : setTimeout(o, i);
    };

    o();
  });
}

function inferFromImplicitShape$1(e, t) {
  var n = 1,
      r = -1;

  for (var _t = 0; _t < e.length; ++_t) {
    if (e[_t] >= 0) n *= e[_t];else if (-1 === e[_t]) {
      if (-1 !== r) throw Error("Shapes can only have 1 implicit size. Found -1 at dim ".concat(r, " and dim ").concat(_t));
      r = _t;
    } else if (e[_t] < 0) throw Error("Shapes can not be < 0. Found ".concat(e[_t], " at dim ").concat(_t));
  }

  if (-1 === r) {
    if (t > 0 && t !== n) throw Error("Size(".concat(t, ") must match the product of shape ").concat(e));
    return e;
  }

  if (0 === n) throw Error("Cannot infer the missing size in [".concat(e, "] when there are 0 elements"));
  if (t % n != 0) throw Error("The implicit shape can't be a fractional number. Got ".concat(t, " / ").concat(n));
  var a = e.slice();
  return a[r] = t / n, a;
}

function parseAxisParam$1(e, t) {
  var n = t.length;
  return assert$6((e = null == e ? t.map((e, t) => t) : [].concat(e)).every(e => e >= -n && e < n), () => "All values in axis param must be in range [-".concat(n, ", ").concat(n, ") but got axis ").concat(e)), assert$6(e.every(e => isInt$1(e)), () => "All values in axis param must be integers but got axis ".concat(e)), e.map(e => e < 0 ? n + e : e);
}

function squeezeShape$1(e, t) {
  var n = [],
      r = [],
      a = null != t && Array.isArray(t) && 0 === t.length,
      s = null == t || a ? null : parseAxisParam$1(t, e).sort();
  var o = 0;

  for (var _t2 = 0; _t2 < e.length; ++_t2) {
    if (null != s) {
      if (s[o] === _t2 && 1 !== e[_t2]) throw new Error("Can't squeeze axis ".concat(_t2, " since its dim '").concat(e[_t2], "' is not 1"));
      (null == s[o] || s[o] > _t2) && 1 === e[_t2] && (n.push(e[_t2]), r.push(_t2)), s[o] <= _t2 && o++;
    }

    1 !== e[_t2] && (n.push(e[_t2]), r.push(_t2));
  }

  return {
    newShape: n,
    keptDims: r
  };
}

function getTypedArrayFromDType$1(e, t) {
  var n = null;
  if (null == e || "float32" === e) n = new Float32Array(t);else if ("int32" === e) n = new Int32Array(t);else {
    if ("bool" !== e) throw new Error("Unknown data type ".concat(e));
    n = new Uint8Array(t);
  }
  return n;
}

function getArrayFromDType$1(e, t) {
  var n = null;
  if (null == e || "float32" === e) n = new Float32Array(t);else if ("int32" === e) n = new Int32Array(t);else if ("bool" === e) n = new Uint8Array(t);else {
    if ("string" !== e) throw new Error("Unknown data type ".concat(e));
    n = new Array(t);
  }
  return n;
}

function checkConversionForErrors$1(e, t) {
  for (var n = 0; n < e.length; n++) {
    var r = e[n];
    if (isNaN(r) || !isFinite(r)) throw Error("A tensor of type ".concat(t, " being uploaded contains ").concat(r, "."));
  }
}

function isValidDtype$1(e) {
  return "bool" === e || "complex64" === e || "float32" === e || "int32" === e || "string" === e;
}

function hasEncodingLoss$1(e, t) {
  return !("complex64" === t || "float32" === t && "complex64" !== e || "int32" === t && "float32" !== e && "complex64" !== e || "bool" === t && "bool" === e);
}

function isTypedArray$1(e) {
  return e instanceof Float32Array || e instanceof Int32Array || e instanceof Uint8Array;
}

function bytesPerElement$1(e) {
  if ("float32" === e || "int32" === e) return 4;
  if ("complex64" === e) return 8;
  if ("bool" === e) return 1;
  throw new Error("Unknown dtype ".concat(e));
}

function bytesFromStringArray$1(e) {
  if (null == e) return 0;
  var t = 0;
  return e.forEach(e => t += e.length), t;
}

function isString$1(e) {
  return "string" == typeof e || e instanceof String;
}

function isBoolean$1(e) {
  return "boolean" == typeof e;
}

function isNumber$1(e) {
  return "number" == typeof e;
}

function inferDtype$1(e) {
  return Array.isArray(e) ? inferDtype$1(e[0]) : e instanceof Float32Array ? "float32" : e instanceof Int32Array || e instanceof Uint8Array ? "int32" : isNumber$1(e) ? "float32" : isString$1(e) ? "string" : isBoolean$1(e) ? "bool" : "float32";
}

function isFunction$1(e) {
  return !!(e && e.constructor && e.call && e.apply);
}

function nearestDivisor$1(e, t) {
  for (var n = t; n < e; ++n) {
    if (e % n == 0) return n;
  }

  return e;
}

function computeStrides$1(e) {
  var t = e.length;
  if (t < 2) return [];
  var n = new Array(t - 1);
  n[t - 2] = e[t - 1];

  for (var r = t - 3; r >= 0; --r) {
    n[r] = n[r + 1] * e[r + 1];
  }

  return n;
}

function createNestedArray$1(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
  var a = new Array();

  if (1 === t.length) {
    var s = t[0] * (r ? 2 : 1);

    for (var _t3 = 0; _t3 < s; _t3++) {
      a[_t3] = n[e + _t3];
    }
  } else {
    var _s = t[0],
        o = t.slice(1),
        i = o.reduce((e, t) => e * t) * (r ? 2 : 1);

    for (var _t4 = 0; _t4 < _s; _t4++) {
      a[_t4] = createNestedArray$1(e + _t4 * i, o, n, r);
    }
  }

  return a;
}

function toNestedArray$1(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  if (0 === e.length) return t[0];
  var r = e.reduce((e, t) => e * t) * (n ? 2 : 1);
  if (0 === r) return [];
  if (r !== t.length) throw new Error("[".concat(e, "] does not match the input size ").concat(t.length).concat(n ? " for a complex tensor" : "", "."));
  return createNestedArray$1(0, e, t, n);
}

function makeOnesTypedArray$1(e, t) {
  var n = makeZerosTypedArray$1(e, t);

  for (var _e = 0; _e < n.length; _e++) {
    n[_e] = 1;
  }

  return n;
}

function makeZerosTypedArray$1(e, t) {
  if (null == t || "float32" === t || "complex64" === t) return new Float32Array(e);
  if ("int32" === t) return new Int32Array(e);
  if ("bool" === t) return new Uint8Array(e);
  throw new Error("Unknown data type ".concat(t));
}

function makeZerosNestedTypedArray$1(e, t) {
  var n = e.reduce((e, t) => e * t, 1);
  if (null == t || "float32" === t) return toNestedArray$1(e, new Float32Array(n));
  if ("int32" === t) return toNestedArray$1(e, new Int32Array(n));
  if ("bool" === t) return toNestedArray$1(e, new Uint8Array(n));
  throw new Error("Unknown data type ".concat(t));
}

function assertNonNegativeIntegerDimensions$1(e) {
  e.forEach(t => {
    assert$6(Number.isInteger(t) && t >= 0, () => "Tensor must have a shape comprised of positive integers but got shape [".concat(e, "]."));
  });
}

function locToIndex$1(e, t, n) {
  if (0 === t) return 0;
  if (1 === t) return e[0];
  var r = e[e.length - 1];

  for (var _t5 = 0; _t5 < e.length - 1; ++_t5) {
    r += n[_t5] * e[_t5];
  }

  return r;
}

function indexToLoc$1(e, t, n) {
  if (0 === t) return [];
  if (1 === t) return [e];
  var r = new Array(t);

  for (var _t6 = 0; _t6 < r.length - 1; ++_t6) {
    r[_t6] = Math.floor(e / n[_t6]), e -= r[_t6] * n[_t6];
  }

  return r[r.length - 1] = e, r;
}

function isPromise$1(e) {
  return e && e.then && "function" == typeof e.then;
}

var TENSORFLOWJS_FLAGS_PREFIX$1 = "tfjsflags";

class Environment$1 {
  constructor(e) {
    this.global = e, this.flags = {}, this.flagRegistry = {}, this.urlFlags = {}, this.getQueryParams = getQueryParams$1, this.populateURLFlags();
  }

  setPlatform(e, t) {
    null != this.platform && console.warn("Platform ".concat(this.platformName, " has already been set. Overwriting the platform with ").concat(t, ".")), this.platformName = e, this.platform = t;
  }

  registerFlag(e, t, n) {
    if (this.flagRegistry[e] = {
      evaluationFn: t,
      setHook: n
    }, null != this.urlFlags[e]) {
      var _t7 = this.urlFlags[e];
      console.warn("Setting feature override from URL ".concat(e, ": ").concat(_t7, ".")), this.set(e, _t7);
    }
  }

  getAsync(e) {
    var _this = this;

    return _asyncToGenerator(function* () {
      return e in _this.flags || (_this.flags[e] = yield _this.evaluateFlag(e)), _this.flags[e];
    })();
  }

  get(e) {
    if (e in this.flags) return this.flags[e];
    var t = this.evaluateFlag(e);
    if (isPromise$1(t)) throw new Error("Flag ".concat(e, " cannot be synchronously evaluated. Please use getAsync() instead."));
    return this.flags[e] = t, this.flags[e];
  }

  getNumber(e) {
    return this.get(e);
  }

  getBool(e) {
    return this.get(e);
  }

  getFlags() {
    return this.flags;
  }

  get features() {
    return this.flags;
  }

  set(e, t) {
    if (null == this.flagRegistry[e]) throw new Error("Cannot set flag ".concat(e, " as it has not been registered."));
    this.flags[e] = t, null != this.flagRegistry[e].setHook && this.flagRegistry[e].setHook(t);
  }

  evaluateFlag(e) {
    if (null == this.flagRegistry[e]) throw new Error("Cannot evaluate flag '".concat(e, "': no evaluation function found."));
    return this.flagRegistry[e].evaluationFn();
  }

  setFlags(e) {
    this.flags = Object.assign({}, e);
  }

  reset() {
    this.flags = {}, this.urlFlags = {}, this.populateURLFlags();
  }

  populateURLFlags() {
    if (void 0 === this.global || void 0 === this.global.location || void 0 === this.global.location.search) return;
    var e = this.getQueryParams(this.global.location.search);
    TENSORFLOWJS_FLAGS_PREFIX$1 in e && e[TENSORFLOWJS_FLAGS_PREFIX$1].split(",").forEach(e => {
      var [t, n] = e.split(":");
      this.urlFlags[t] = parseValue$1(t, n);
    });
  }

}

function getQueryParams$1(e) {
  var t = {};
  return e.replace(/[?&]([^=?&]+)(?:=([^&]*))?/g, function (e) {
    for (var _len = arguments.length, n = new Array(_len > 1 ? _len - 1 : 0), _key = 1; _key < _len; _key++) {
      n[_key - 1] = arguments[_key];
    }

    return decodeParam$1(t, n[0], n[1]), n.join("=");
  }), t;
}

function decodeParam$1(e, t, n) {
  e[decodeURIComponent(t)] = decodeURIComponent(n || "");
}

function parseValue$1(e, t) {
  if ("true" === (t = t.toLowerCase()) || "false" === t) return "true" === t;
  if ("" + +t === t) return +t;
  throw new Error("Could not parse value flag value ".concat(t, " for flag ").concat(e, "."));
}

function env$1() {
  return ENV$5;
}

var ENV$5 = null,
    globalNameSpace$1;

function setEnvironmentGlobal$1(e) {
  ENV$5 = e;
}

function getGlobalNamespace$1() {
  if (null == globalNameSpace$1) {
    var e;
    if ("undefined" != typeof window) e = window;else if ("undefined" != typeof __webpack_require__.g) e = __webpack_require__.g;else if ("undefined" != typeof process) e = process;else {
      if ("undefined" == typeof self) throw new Error("Could not find a global object");
      e = self;
    }
    globalNameSpace$1 = e;
  }

  return globalNameSpace$1;
}

function getGlobalMap$1() {
  var e = getGlobalNamespace$1();
  return null == e._tfGlobals && (e._tfGlobals = new Map()), e._tfGlobals;
}

function getGlobal$1(e, t) {
  var n = getGlobalMap$1();
  if (n.has(e)) return n.get(e);
  {
    var r = t();
    return n.set(e, r), n.get(e);
  }
}

var Abs$1 = "Abs",
    Acos$1 = "Acos",
    Acosh$1 = "Acosh",
    Add$3 = "Add",
    AddN$1 = "AddN",
    All$1 = "All",
    Any$1 = "Any",
    ArgMax$1 = "ArgMax",
    ArgMin$1 = "ArgMin",
    Asin$1 = "Asin",
    Asinh$1 = "Asinh",
    Atan$1 = "Atan",
    Atanh$1 = "Atanh",
    Atan2$1 = "Atan2",
    AvgPool$1 = "AvgPool",
    AvgPoolGrad$1 = "AvgPoolGrad",
    AvgPool3D$1 = "AvgPool3D",
    AvgPool3DGrad$1 = "AvgPool3DGrad",
    BatchMatMul$1 = "BatchMatMul",
    BatchToSpaceND$1 = "BatchToSpaceND",
    Bincount$1 = "Bincount",
    BroadcastTo$1 = "BroadcastTo",
    Cast$1 = "Cast",
    Ceil$1 = "Ceil",
    ClipByValue$1 = "ClipByValue",
    Complex$1 = "Complex",
    ComplexAbs$1 = "ComplexAbs",
    Concat$1 = "Concat",
    Conv2D$3 = "Conv2D",
    Conv2DBackpropFilter$1 = "Conv2DBackpropFilter",
    Conv2DBackpropInput$1 = "Conv2DBackpropInput",
    Conv3D$3 = "Conv3D",
    Conv3DBackpropFilterV2$1 = "Conv3DBackpropFilterV2",
    Conv3DBackpropInputV2$1 = "Conv3DBackpropInputV2",
    Cos$1 = "Cos",
    Cosh$1 = "Cosh",
    Cumsum$1 = "Cumsum",
    CropAndResize$1 = "CropAndResize",
    DenseBincount$1 = "DenseBincount",
    DepthToSpace$1 = "DepthToSpace",
    DepthwiseConv2dNative$1 = "DepthwiseConv2dNative",
    DepthwiseConv2dNativeBackpropFilter$1 = "DepthwiseConv2dNativeBackpropFilter",
    DepthwiseConv2dNativeBackpropInput$1 = "DepthwiseConv2dNativeBackpropInput",
    Diag$1 = "Diag",
    Dilation2D$1 = "Dilation2D",
    Dilation2DBackpropInput$1 = "Dilation2DBackpropInput",
    Dilation2DBackpropFilter$1 = "Dilation2DBackpropFilter",
    RealDiv$1 = "RealDiv",
    Einsum$1 = "Einsum",
    Elu$3 = "Elu",
    EluGrad$1 = "EluGrad",
    Erf$1 = "Erf",
    Equal$1 = "Equal",
    Exp$1 = "Exp",
    ExpandDims$1 = "ExpandDims",
    Expm1$1 = "Expm1",
    FFT$1 = "FFT",
    Fill$1 = "Fill",
    FlipLeftRight$1 = "FlipLeftRight",
    Floor$1 = "Floor",
    FloorDiv$1 = "FloorDiv",
    FusedBatchNorm$1 = "FusedBatchNorm",
    GatherV2$1 = "GatherV2",
    GatherNd$1 = "GatherNd",
    Greater$1 = "Greater",
    GreaterEqual$1 = "GreaterEqual",
    Identity$3 = "Identity",
    IFFT$1 = "IFFT",
    Imag$1 = "Imag",
    IsFinite$1 = "IsFinite",
    IsInf$1 = "IsInf",
    IsNan$1 = "IsNan",
    LeakyRelu$1 = "LeakyRelu",
    Less$1 = "Less",
    LessEqual$1 = "LessEqual",
    LinSpace$1 = "LinSpace",
    Log$1 = "Log",
    Log1p$1 = "Log1p",
    LogicalAnd$1 = "LogicalAnd",
    LogicalNot$1 = "LogicalNot",
    LogicalOr$1 = "LogicalOr",
    LogSoftmax$3 = "LogSoftmax",
    LRN$1 = "LRN",
    LRNGrad$1 = "LRNGrad",
    Max$1 = "Max",
    Maximum$3 = "Maximum",
    MaxPool$1 = "MaxPool",
    MaxPoolGrad$1 = "MaxPoolGrad",
    MaxPool3D$1 = "MaxPool3D",
    MaxPool3DGrad$1 = "MaxPool3DGrad",
    MaxPoolWithArgmax$1 = "MaxPoolWithArgmax",
    Mean$1 = "Mean",
    Min$1 = "Min",
    Minimum$3 = "Minimum",
    MirrorPad$1 = "MirrorPad",
    Mod$1 = "Mod",
    Multinomial$1 = "Multinomial",
    Multiply$3 = "Multiply",
    Neg$1 = "Neg",
    NotEqual$1 = "NotEqual",
    NonMaxSuppressionV3$1 = "NonMaxSuppressionV3",
    NonMaxSuppressionV4$1 = "NonMaxSuppressionV4",
    NonMaxSuppressionV5$1 = "NonMaxSuppressionV5",
    OnesLike$1 = "OnesLike",
    OneHot$1 = "OneHot",
    Pack$1 = "Pack",
    PadV2$1 = "PadV2",
    Pow$1 = "Pow",
    Prelu$1 = "Prelu",
    Prod$1 = "Prod",
    Range$1 = "Range",
    Real$1 = "Real",
    Reciprocal$1 = "Reciprocal",
    Relu$3 = "Relu",
    Reshape$3 = "Reshape",
    ResizeNearestNeighbor$1 = "ResizeNearestNeighbor",
    ResizeNearestNeighborGrad$1 = "ResizeNearestNeighborGrad",
    ResizeBilinear$1 = "ResizeBilinear",
    ResizeBilinearGrad$1 = "ResizeBilinearGrad",
    Relu6$3 = "Relu6",
    Reverse$1 = "Reverse",
    Round$1 = "Round",
    Rsqrt$1 = "Rsqrt",
    ScatterNd$1 = "ScatterNd",
    Select$1 = "Select",
    Selu$3 = "Selu",
    Slice$1 = "Slice",
    Sin$1 = "Sin",
    Sinh$1 = "Sinh",
    Sign$1 = "Sign",
    Sigmoid$3 = "Sigmoid",
    Softplus$3 = "Softplus",
    Sqrt$1 = "Sqrt",
    Sum$1 = "Sum",
    SpaceToBatchND$1 = "SpaceToBatchND",
    SplitV$1 = "SplitV",
    Softmax$5 = "Softmax",
    SparseFillEmptyRows$1 = "SparseFillEmptyRows",
    SparseReshape$1 = "SparseReshape",
    SparseSegmentMean$1 = "SparseSegmentMean",
    SparseSegmentSum$1 = "SparseSegmentSum",
    SparseToDense$1 = "SparseToDense",
    SquaredDifference$1 = "SquaredDifference",
    Square$1 = "Square",
    StridedSlice$1 = "StridedSlice",
    StringNGrams$1 = "StringNGrams",
    StringSplit$1 = "StringSplit",
    StringToHashBucketFast$1 = "StringToHashBucketFast",
    Sub$1 = "Sub",
    Tan$1 = "Tan",
    Tanh$3 = "Tanh",
    Tile$1 = "Tile",
    TopK$1 = "TopK",
    Transform$1 = "Transform",
    Transpose$1 = "Transpose",
    Unique$1 = "Unique",
    Unpack$1 = "Unpack",
    UnsortedSegmentSum$1 = "UnsortedSegmentSum",
    ZerosLike$1 = "ZerosLike",
    Step$1 = "Step",
    FromPixels$1 = "FromPixels",
    RotateWithOffset$1 = "RotateWithOffset",
    _FusedMatMul$1 = "_FusedMatMul",
    FusedConv2D$1 = "FusedConv2D",
    FusedDepthwiseConv2D$1 = "FusedDepthwiseConv2D",
    kernelRegistry$1 = getGlobal$1("kernelRegistry", () => new Map()),
    gradRegistry$1 = getGlobal$1("gradRegistry", () => new Map());

function getKernel$1(e, t) {
  var n = makeKey$1(e, t);
  return kernelRegistry$1.get(n);
}

function getGradient$1(e) {
  return gradRegistry$1.get(e);
}

function getKernelsForBackend$1(e) {
  var t = kernelRegistry$1.entries(),
      n = [];

  for (;;) {
    var {
      done: r,
      value: a
    } = t.next();
    if (r) break;
    var [s, o] = a,
        [i] = s.split("_");
    i === e && n.push(o);
  }

  return n;
}

function registerKernel$1(e) {
  var {
    kernelName: t,
    backendName: n
  } = e,
      r = makeKey$1(t, n);
  kernelRegistry$1.has(r) && console.warn("The kernel '".concat(t, "' for backend '").concat(n, "' is already registered")), kernelRegistry$1.set(r, e);
}

function registerGradient$1(e) {
  var {
    kernelName: t
  } = e;
  gradRegistry$1.has(t) && env$1().getBool("DEBUG") && console.warn("Overriding the gradient for '".concat(t, "'")), gradRegistry$1.set(t, e);
}

function makeKey$1(e, t) {
  return "".concat(t, "_").concat(e);
}

var long$2 = Long$3,
    wasm$1 = null;

try {
  wasm$1 = new WebAssembly.Instance(new WebAssembly.Module(new Uint8Array([0, 97, 115, 109, 1, 0, 0, 0, 1, 13, 2, 96, 0, 1, 127, 96, 4, 127, 127, 127, 127, 1, 127, 3, 7, 6, 0, 1, 1, 1, 1, 1, 6, 6, 1, 127, 1, 65, 0, 11, 7, 50, 6, 3, 109, 117, 108, 0, 1, 5, 100, 105, 118, 95, 115, 0, 2, 5, 100, 105, 118, 95, 117, 0, 3, 5, 114, 101, 109, 95, 115, 0, 4, 5, 114, 101, 109, 95, 117, 0, 5, 8, 103, 101, 116, 95, 104, 105, 103, 104, 0, 0, 10, 191, 1, 6, 4, 0, 35, 0, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 126, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 127, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 128, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 129, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 130, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11])), {}).exports;
} catch (e) {}

function Long$3(e, t, n) {
  this.low = 0 | e, this.high = 0 | t, this.unsigned = !!n;
}

function isLong$1(e) {
  return !0 === (e && e.__isLong__);
}

Object.defineProperty(Long$3.prototype, "__isLong__", {
  value: !0
}), Long$3.isLong = isLong$1;
var INT_CACHE$1 = {},
    UINT_CACHE$1 = {};

function fromInt$1(e, t) {
  var n, r, a;
  return t ? (a = 0 <= (e >>>= 0) && e < 256) && (r = UINT_CACHE$1[e]) ? r : (n = fromBits$1(e, (0 | e) < 0 ? -1 : 0, !0), a && (UINT_CACHE$1[e] = n), n) : (a = -128 <= (e |= 0) && e < 128) && (r = INT_CACHE$1[e]) ? r : (n = fromBits$1(e, e < 0 ? -1 : 0, !1), a && (INT_CACHE$1[e] = n), n);
}

function fromNumber$1(e, t) {
  if (isNaN(e)) return t ? UZERO$1 : ZERO$1;

  if (t) {
    if (e < 0) return UZERO$1;
    if (e >= TWO_PWR_64_DBL$1) return MAX_UNSIGNED_VALUE$1;
  } else {
    if (e <= -TWO_PWR_63_DBL$1) return MIN_VALUE$1;
    if (e + 1 >= TWO_PWR_63_DBL$1) return MAX_VALUE$1;
  }

  return e < 0 ? fromNumber$1(-e, t).neg() : fromBits$1(e % TWO_PWR_32_DBL$1 | 0, e / TWO_PWR_32_DBL$1 | 0, t);
}

function fromBits$1(e, t, n) {
  return new Long$3(e, t, n);
}

Long$3.fromInt = fromInt$1, Long$3.fromNumber = fromNumber$1, Long$3.fromBits = fromBits$1;
var pow_dbl$1 = Math.pow;

function fromString$1(e, t, n) {
  if (0 === e.length) throw Error("empty string");
  if ("NaN" === e || "Infinity" === e || "+Infinity" === e || "-Infinity" === e) return ZERO$1;
  if ("number" == typeof t ? (n = t, t = !1) : t = !!t, (n = n || 10) < 2 || 36 < n) throw RangeError("radix");
  var r;
  if ((r = e.indexOf("-")) > 0) throw Error("interior hyphen");
  if (0 === r) return fromString$1(e.substring(1), t, n).neg();

  for (var a = fromNumber$1(pow_dbl$1(n, 8)), s = ZERO$1, o = 0; o < e.length; o += 8) {
    var i = Math.min(8, e.length - o),
        l = parseInt(e.substring(o, o + i), n);

    if (i < 8) {
      var u = fromNumber$1(pow_dbl$1(n, i));
      s = s.mul(u).add(fromNumber$1(l));
    } else s = (s = s.mul(a)).add(fromNumber$1(l));
  }

  return s.unsigned = t, s;
}

function fromValue$1(e, t) {
  return "number" == typeof e ? fromNumber$1(e, t) : "string" == typeof e ? fromString$1(e, t) : fromBits$1(e.low, e.high, "boolean" == typeof t ? t : e.unsigned);
}

Long$3.fromString = fromString$1, Long$3.fromValue = fromValue$1;
var TWO_PWR_16_DBL$1 = 65536,
    TWO_PWR_24_DBL$1 = 1 << 24,
    TWO_PWR_32_DBL$1 = TWO_PWR_16_DBL$1 * TWO_PWR_16_DBL$1,
    TWO_PWR_64_DBL$1 = TWO_PWR_32_DBL$1 * TWO_PWR_32_DBL$1,
    TWO_PWR_63_DBL$1 = TWO_PWR_64_DBL$1 / 2,
    TWO_PWR_24$1 = fromInt$1(TWO_PWR_24_DBL$1),
    ZERO$1 = fromInt$1(0);
Long$3.ZERO = ZERO$1;
var UZERO$1 = fromInt$1(0, !0);
Long$3.UZERO = UZERO$1;
var ONE$1 = fromInt$1(1);
Long$3.ONE = ONE$1;
var UONE$1 = fromInt$1(1, !0);
Long$3.UONE = UONE$1;
var NEG_ONE$1 = fromInt$1(-1);
Long$3.NEG_ONE = NEG_ONE$1;
var MAX_VALUE$1 = fromBits$1(-1, 2147483647, !1);
Long$3.MAX_VALUE = MAX_VALUE$1;
var MAX_UNSIGNED_VALUE$1 = fromBits$1(-1, -1, !0);
Long$3.MAX_UNSIGNED_VALUE = MAX_UNSIGNED_VALUE$1;
var MIN_VALUE$1 = fromBits$1(0, -2147483648, !1);
Long$3.MIN_VALUE = MIN_VALUE$1;
var LongPrototype$1 = Long$3.prototype;
LongPrototype$1.toInt = function () {
  return this.unsigned ? this.low >>> 0 : this.low;
}, LongPrototype$1.toNumber = function () {
  return this.unsigned ? (this.high >>> 0) * TWO_PWR_32_DBL$1 + (this.low >>> 0) : this.high * TWO_PWR_32_DBL$1 + (this.low >>> 0);
}, LongPrototype$1.toString = function (e) {
  if ((e = e || 10) < 2 || 36 < e) throw RangeError("radix");
  if (this.isZero()) return "0";

  if (this.isNegative()) {
    if (this.eq(MIN_VALUE$1)) {
      var t = fromNumber$1(e),
          n = this.div(t),
          r = n.mul(t).sub(this);
      return n.toString(e) + r.toInt().toString(e);
    }

    return "-" + this.neg().toString(e);
  }

  for (var a = fromNumber$1(pow_dbl$1(e, 6), this.unsigned), s = this, o = "";;) {
    var i = s.div(a),
        l = (s.sub(i.mul(a)).toInt() >>> 0).toString(e);
    if ((s = i).isZero()) return l + o;

    for (; l.length < 6;) {
      l = "0" + l;
    }

    o = "" + l + o;
  }
}, LongPrototype$1.getHighBits = function () {
  return this.high;
}, LongPrototype$1.getHighBitsUnsigned = function () {
  return this.high >>> 0;
}, LongPrototype$1.getLowBits = function () {
  return this.low;
}, LongPrototype$1.getLowBitsUnsigned = function () {
  return this.low >>> 0;
}, LongPrototype$1.getNumBitsAbs = function () {
  if (this.isNegative()) return this.eq(MIN_VALUE$1) ? 64 : this.neg().getNumBitsAbs();

  for (var e = 0 != this.high ? this.high : this.low, t = 31; t > 0 && 0 == (e & 1 << t); t--) {
    ;
  }

  return 0 != this.high ? t + 33 : t + 1;
}, LongPrototype$1.isZero = function () {
  return 0 === this.high && 0 === this.low;
}, LongPrototype$1.eqz = LongPrototype$1.isZero, LongPrototype$1.isNegative = function () {
  return !this.unsigned && this.high < 0;
}, LongPrototype$1.isPositive = function () {
  return this.unsigned || this.high >= 0;
}, LongPrototype$1.isOdd = function () {
  return 1 == (1 & this.low);
}, LongPrototype$1.isEven = function () {
  return 0 == (1 & this.low);
}, LongPrototype$1.equals = function (e) {
  return isLong$1(e) || (e = fromValue$1(e)), (this.unsigned === e.unsigned || this.high >>> 31 != 1 || e.high >>> 31 != 1) && this.high === e.high && this.low === e.low;
}, LongPrototype$1.eq = LongPrototype$1.equals, LongPrototype$1.notEquals = function (e) {
  return !this.eq(e);
}, LongPrototype$1.neq = LongPrototype$1.notEquals, LongPrototype$1.ne = LongPrototype$1.notEquals, LongPrototype$1.lessThan = function (e) {
  return this.comp(e) < 0;
}, LongPrototype$1.lt = LongPrototype$1.lessThan, LongPrototype$1.lessThanOrEqual = function (e) {
  return this.comp(e) <= 0;
}, LongPrototype$1.lte = LongPrototype$1.lessThanOrEqual, LongPrototype$1.le = LongPrototype$1.lessThanOrEqual, LongPrototype$1.greaterThan = function (e) {
  return this.comp(e) > 0;
}, LongPrototype$1.gt = LongPrototype$1.greaterThan, LongPrototype$1.greaterThanOrEqual = function (e) {
  return this.comp(e) >= 0;
}, LongPrototype$1.gte = LongPrototype$1.greaterThanOrEqual, LongPrototype$1.ge = LongPrototype$1.greaterThanOrEqual, LongPrototype$1.compare = function (e) {
  if (isLong$1(e) || (e = fromValue$1(e)), this.eq(e)) return 0;
  var t = this.isNegative(),
      n = e.isNegative();
  return t && !n ? -1 : !t && n ? 1 : this.unsigned ? e.high >>> 0 > this.high >>> 0 || e.high === this.high && e.low >>> 0 > this.low >>> 0 ? -1 : 1 : this.sub(e).isNegative() ? -1 : 1;
}, LongPrototype$1.comp = LongPrototype$1.compare, LongPrototype$1.negate = function () {
  return !this.unsigned && this.eq(MIN_VALUE$1) ? MIN_VALUE$1 : this.not().add(ONE$1);
}, LongPrototype$1.neg = LongPrototype$1.negate, LongPrototype$1.add = function (e) {
  isLong$1(e) || (e = fromValue$1(e));
  var t = 0,
      n = 0,
      r = 0,
      a = 0;
  return r += (a += (65535 & this.low) + (65535 & e.low)) >>> 16, n += (r += (this.low >>> 16) + (e.low >>> 16)) >>> 16, t += (n += (65535 & this.high) + (65535 & e.high)) >>> 16, t += (this.high >>> 16) + (e.high >>> 16), fromBits$1((r &= 65535) << 16 | (a &= 65535), (t &= 65535) << 16 | (n &= 65535), this.unsigned);
}, LongPrototype$1.subtract = function (e) {
  return isLong$1(e) || (e = fromValue$1(e)), this.add(e.neg());
}, LongPrototype$1.sub = LongPrototype$1.subtract, LongPrototype$1.multiply = function (e) {
  if (this.isZero()) return ZERO$1;
  if (isLong$1(e) || (e = fromValue$1(e)), wasm$1) return fromBits$1(wasm$1.mul(this.low, this.high, e.low, e.high), wasm$1.get_high(), this.unsigned);
  if (e.isZero()) return ZERO$1;
  if (this.eq(MIN_VALUE$1)) return e.isOdd() ? MIN_VALUE$1 : ZERO$1;
  if (e.eq(MIN_VALUE$1)) return this.isOdd() ? MIN_VALUE$1 : ZERO$1;
  if (this.isNegative()) return e.isNegative() ? this.neg().mul(e.neg()) : this.neg().mul(e).neg();
  if (e.isNegative()) return this.mul(e.neg()).neg();
  if (this.lt(TWO_PWR_24$1) && e.lt(TWO_PWR_24$1)) return fromNumber$1(this.toNumber() * e.toNumber(), this.unsigned);
  var t = 65535 & this.high,
      n = this.low >>> 16,
      r = 65535 & this.low,
      a = 65535 & e.high,
      s = e.low >>> 16,
      o = 65535 & e.low,
      i = 0,
      l = 0,
      u = 0,
      c = 0;
  return u += (c += r * o) >>> 16, l += (u += n * o) >>> 16, u &= 65535, l += (u += r * s) >>> 16, i += (l += t * o) >>> 16, l &= 65535, i += (l += n * s) >>> 16, l &= 65535, i += (l += r * a) >>> 16, i += (this.high >>> 16) * o + t * s + n * a + r * (e.high >>> 16), fromBits$1((u &= 65535) << 16 | (c &= 65535), (i &= 65535) << 16 | (l &= 65535), this.unsigned);
}, LongPrototype$1.mul = LongPrototype$1.multiply, LongPrototype$1.divide = function (e) {
  if (isLong$1(e) || (e = fromValue$1(e)), e.isZero()) throw Error("division by zero");
  var t, n, r;
  if (wasm$1) return this.unsigned || -2147483648 !== this.high || -1 !== e.low || -1 !== e.high ? fromBits$1((this.unsigned ? wasm$1.div_u : wasm$1.div_s)(this.low, this.high, e.low, e.high), wasm$1.get_high(), this.unsigned) : this;
  if (this.isZero()) return this.unsigned ? UZERO$1 : ZERO$1;

  if (this.unsigned) {
    if (e.unsigned || (e = e.toUnsigned()), e.gt(this)) return UZERO$1;
    if (e.gt(this.shru(1))) return UONE$1;
    r = UZERO$1;
  } else {
    if (this.eq(MIN_VALUE$1)) return e.eq(ONE$1) || e.eq(NEG_ONE$1) ? MIN_VALUE$1 : e.eq(MIN_VALUE$1) ? ONE$1 : (t = this.shr(1).div(e).shl(1)).eq(ZERO$1) ? e.isNegative() ? ONE$1 : NEG_ONE$1 : (n = this.sub(e.mul(t)), r = t.add(n.div(e)));
    if (e.eq(MIN_VALUE$1)) return this.unsigned ? UZERO$1 : ZERO$1;
    if (this.isNegative()) return e.isNegative() ? this.neg().div(e.neg()) : this.neg().div(e).neg();
    if (e.isNegative()) return this.div(e.neg()).neg();
    r = ZERO$1;
  }

  for (n = this; n.gte(e);) {
    t = Math.max(1, Math.floor(n.toNumber() / e.toNumber()));

    for (var a = Math.ceil(Math.log(t) / Math.LN2), s = a <= 48 ? 1 : pow_dbl$1(2, a - 48), o = fromNumber$1(t), i = o.mul(e); i.isNegative() || i.gt(n);) {
      i = (o = fromNumber$1(t -= s, this.unsigned)).mul(e);
    }

    o.isZero() && (o = ONE$1), r = r.add(o), n = n.sub(i);
  }

  return r;
}, LongPrototype$1.div = LongPrototype$1.divide, LongPrototype$1.modulo = function (e) {
  return isLong$1(e) || (e = fromValue$1(e)), wasm$1 ? fromBits$1((this.unsigned ? wasm$1.rem_u : wasm$1.rem_s)(this.low, this.high, e.low, e.high), wasm$1.get_high(), this.unsigned) : this.sub(this.div(e).mul(e));
}, LongPrototype$1.mod = LongPrototype$1.modulo, LongPrototype$1.rem = LongPrototype$1.modulo, LongPrototype$1.not = function () {
  return fromBits$1(~this.low, ~this.high, this.unsigned);
}, LongPrototype$1.and = function (e) {
  return isLong$1(e) || (e = fromValue$1(e)), fromBits$1(this.low & e.low, this.high & e.high, this.unsigned);
}, LongPrototype$1.or = function (e) {
  return isLong$1(e) || (e = fromValue$1(e)), fromBits$1(this.low | e.low, this.high | e.high, this.unsigned);
}, LongPrototype$1.xor = function (e) {
  return isLong$1(e) || (e = fromValue$1(e)), fromBits$1(this.low ^ e.low, this.high ^ e.high, this.unsigned);
}, LongPrototype$1.shiftLeft = function (e) {
  return isLong$1(e) && (e = e.toInt()), 0 == (e &= 63) ? this : e < 32 ? fromBits$1(this.low << e, this.high << e | this.low >>> 32 - e, this.unsigned) : fromBits$1(0, this.low << e - 32, this.unsigned);
}, LongPrototype$1.shl = LongPrototype$1.shiftLeft, LongPrototype$1.shiftRight = function (e) {
  return isLong$1(e) && (e = e.toInt()), 0 == (e &= 63) ? this : e < 32 ? fromBits$1(this.low >>> e | this.high << 32 - e, this.high >> e, this.unsigned) : fromBits$1(this.high >> e - 32, this.high >= 0 ? 0 : -1, this.unsigned);
}, LongPrototype$1.shr = LongPrototype$1.shiftRight, LongPrototype$1.shiftRightUnsigned = function (e) {
  if (isLong$1(e) && (e = e.toInt()), 0 == (e &= 63)) return this;
  var t = this.high;
  return e < 32 ? fromBits$1(this.low >>> e | t << 32 - e, t >>> e, this.unsigned) : fromBits$1(32 === e ? t : t >>> e - 32, 0, this.unsigned);
}, LongPrototype$1.shru = LongPrototype$1.shiftRightUnsigned, LongPrototype$1.shr_u = LongPrototype$1.shiftRightUnsigned, LongPrototype$1.toSigned = function () {
  return this.unsigned ? fromBits$1(this.low, this.high, !1) : this;
}, LongPrototype$1.toUnsigned = function () {
  return this.unsigned ? this : fromBits$1(this.low, this.high, !0);
}, LongPrototype$1.toBytes = function (e) {
  return e ? this.toBytesLE() : this.toBytesBE();
}, LongPrototype$1.toBytesLE = function () {
  var e = this.high,
      t = this.low;
  return [255 & t, t >>> 8 & 255, t >>> 16 & 255, t >>> 24, 255 & e, e >>> 8 & 255, e >>> 16 & 255, e >>> 24];
}, LongPrototype$1.toBytesBE = function () {
  var e = this.high,
      t = this.low;
  return [e >>> 24, e >>> 16 & 255, e >>> 8 & 255, 255 & e, t >>> 24, t >>> 16 & 255, t >>> 8 & 255, 255 & t];
}, Long$3.fromBytes = function (e, t, n) {
  return n ? Long$3.fromBytesLE(e, t) : Long$3.fromBytesBE(e, t);
}, Long$3.fromBytesLE = function (e, t) {
  return new Long$3(e[0] | e[1] << 8 | e[2] << 16 | e[3] << 24, e[4] | e[5] << 8 | e[6] << 16 | e[7] << 24, t);
}, Long$3.fromBytesBE = function (e, t) {
  return new Long$3(e[4] << 24 | e[5] << 16 | e[6] << 8 | e[7], e[0] << 24 | e[1] << 16 | e[2] << 8 | e[3], t);
};

var long$3 = long$2,
    LongExports$1 = /*#__PURE__*/_mergeNamespaces({
  __proto__: null,
  default: long$3
}, [long$2]);

var Long$2 = long$3 || LongExports$1;

function hexToLong$1(e) {
  return Long$2.fromString(e, !0, 16);
}

var k0$1 = hexToLong$1("c3a5c85c97cb3127"),
    k1$1 = hexToLong$1("b492b66fbe98f273"),
    k2$1 = hexToLong$1("9ae16a3b2f90404f");

function shiftMix$1(e) {
  return e.xor(e.shru(47));
}

function fetch$3(e, t, n) {
  var r = e.slice(t, t + n);
  return Long$2.fromBytes(Array.from(r), !0, !0);
}

function fetch64$1(e, t) {
  return fetch$3(e, t, 8);
}

function fetch32$1(e, t) {
  return fetch$3(e, t, 4);
}

function rotate64$1(e, t) {
  return 0 === t ? e : e.shru(t).or(e.shl(64 - t));
}

function hashLen16$1(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : hexToLong$1("9ddfea08eb382d69");
  var r = e.xor(t).mul(n);
  r = r.xor(r.shru(47));
  var a = t.xor(r).mul(n);
  return a = a.xor(a.shru(47)), a = a.mul(n), a;
}

function weakHashLen32WithSeeds$1(e, t, n, r, a, s) {
  a = a.add(e), s = rotate64$1(s.add(a).add(r), 21);
  var o = a;
  return a = (a = a.add(t)).add(n), s = s.add(rotate64$1(a, 44)), [a.add(r), s.add(o)];
}

function weakHashLen32WithSeedsStr$1(e, t, n, r) {
  return weakHashLen32WithSeeds$1(fetch64$1(e, t), fetch64$1(e, t + 8), fetch64$1(e, t + 16), fetch64$1(e, t + 24), n, r);
}

function hashLen0to16$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : e.length;

  if (t >= 8) {
    var n = k2$1.add(2 * t),
        r = fetch64$1(e, 0).add(k2$1),
        a = fetch64$1(e, t - 8);
    return hashLen16$1(rotate64$1(a, 37).mul(n).add(r), rotate64$1(r, 25).add(a).mul(n), n);
  }

  if (t >= 4) {
    var _n = k2$1.add(2 * t);

    return hashLen16$1(fetch32$1(e, 0).shl(3).add(t), fetch32$1(e, t - 4), _n);
  }

  if (t > 0) {
    var _n2 = t + (e[t - 1] << 2);

    return shiftMix$1(k2$1.mul(e[0] + (e[t >> 1] << 8)).xor(k0$1.mul(_n2))).mul(k2$1);
  }

  return k2$1;
}

function hashLen17to32$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : e.length;
  var n = k2$1.add(2 * t),
      r = fetch64$1(e, 0).mul(k1$1),
      a = fetch64$1(e, 8),
      s = fetch64$1(e, t - 8).mul(n),
      o = fetch64$1(e, t - 16).mul(k2$1);
  return hashLen16$1(rotate64$1(r.add(a), 43).add(rotate64$1(s, 30)).add(o), r.add(rotate64$1(a.add(k2$1), 18)).add(s), n);
}

function hashLen33to64$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : e.length;
  var n = k2$1.add(2 * t),
      r = fetch64$1(e, 0).mul(k2$1),
      a = fetch64$1(e, 8),
      s = fetch64$1(e, t - 8).mul(n),
      o = fetch64$1(e, t - 16).mul(k2$1),
      i = rotate64$1(r.add(a), 43).add(rotate64$1(s, 30)).add(o),
      l = hashLen16$1(i, r.add(rotate64$1(a.add(k2$1), 18)).add(s), n),
      u = fetch64$1(e, 16).mul(n),
      c = fetch64$1(e, 24),
      p = i.add(fetch64$1(e, t - 32)).mul(n),
      d = l.add(fetch64$1(e, t - 24)).mul(n);
  return hashLen16$1(rotate64$1(u.add(c), 43).add(rotate64$1(p, 30)).add(d), u.add(rotate64$1(c.add(r), 18)).add(p), n);
}

function fingerPrint64$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : e.length;
  var n = Long$2.fromNumber(81, !0);
  if (t <= 32) return t <= 16 ? hashLen0to16$1(e, t) : hashLen17to32$1(e, t);
  if (t <= 64) return hashLen33to64$1(e, t);
  var r = n,
      a = n.mul(k1$1).add(113),
      s = shiftMix$1(a.mul(k2$1).add(113)).mul(k2$1),
      o = [Long$2.UZERO, Long$2.UZERO],
      i = [Long$2.UZERO, Long$2.UZERO];
  r = r.mul(k2$1).add(fetch64$1(e, 0));
  var l = 0;
  var u = 64 * (t - 1 >> 6),
      c = u + (t - 1 & 63) - 63;

  do {
    r = rotate64$1(r.add(a).add(o[0]).add(fetch64$1(e, l + 8)), 37).mul(k1$1), a = rotate64$1(a.add(o[1]).add(fetch64$1(e, l + 48)), 42).mul(k1$1), r = r.xor(i[1]), a = a.add(o[0]).add(fetch64$1(e, l + 40)), s = rotate64$1(s.add(i[0]), 33).mul(k1$1), o = weakHashLen32WithSeedsStr$1(e, l, o[1].mul(k1$1), r.add(i[0])), i = weakHashLen32WithSeedsStr$1(e, l + 32, s.add(i[1]), a.add(fetch64$1(e, l + 16))), [s, r] = [r, s], l += 64;
  } while (l !== u);

  var p = k1$1.add(s.and(255).shl(1));
  return l = c, i[0] = i[0].add(t - 1 & 63), o[0] = o[0].add(i[0]), i[0] = i[0].add(o[0]), r = rotate64$1(r.add(a).add(o[0]).add(fetch64$1(e, l + 8)), 37).mul(p), a = rotate64$1(a.add(o[1]).add(fetch64$1(e, l + 48)), 42).mul(p), r = r.xor(i[1].mul(9)), a = a.add(o[0].mul(9).add(fetch64$1(e, l + 40))), s = rotate64$1(s.add(i[0]), 33).mul(p), o = weakHashLen32WithSeedsStr$1(e, l, o[1].mul(p), r.add(i[0])), i = weakHashLen32WithSeedsStr$1(e, l + 32, s.add(i[1]), a.add(fetch64$1(e, l + 16))), [s, r] = [r, s], hashLen16$1(hashLen16$1(o[0], i[0], p).add(shiftMix$1(a).mul(k0$1)).add(s), hashLen16$1(o[1], i[1], p).add(r), p);
}

function createScalarValue$1(e, t) {
  return "string" === t ? encodeString$1(e) : toTypedArray$1([e], t);
}

function noConversionNeeded$1(e, t) {
  return e instanceof Float32Array && "float32" === t || e instanceof Int32Array && "int32" === t || e instanceof Uint8Array && "bool" === t;
}

function toTypedArray$1(e, t) {
  if ("string" === t) throw new Error("Cannot convert a string[] to a TypedArray");
  if (Array.isArray(e) && (e = flatten$6(e)), env$1().getBool("DEBUG") && checkConversionForErrors$1(e, t), noConversionNeeded$1(e, t)) return e;
  if (null == t || "float32" === t || "complex64" === t) return new Float32Array(e);
  if ("int32" === t) return new Int32Array(e);

  if ("bool" === t) {
    var _t8 = new Uint8Array(e.length);

    for (var n = 0; n < _t8.length; ++n) {
      0 !== Math.round(e[n]) && (_t8[n] = 1);
    }

    return _t8;
  }

  throw new Error("Unknown data type ".concat(t));
}

function now$1() {
  return env$1().platform.now();
}

function encodeString$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : "utf-8";
  return t = t || "utf-8", env$1().platform.encode(e, t);
}

function decodeString$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : "utf-8";
  return t = t || "utf-8", env$1().platform.decode(e, t);
}

class Profiler$1 {
  constructor(e, t) {
    this.backendTimer = e, this.logger = t, null == t && (this.logger = new Logger$1());
  }

  profileKernel(e, t, n) {
    var r;

    var a = () => {
      r = n();
    };

    var s;
    var o = now$1();
    if (this.backendTimer.timerAvailable()) s = this.backendTimer.time(a);else {
      a();

      for (var _e2 of r) {
        _e2.dataSync();
      }

      s = Promise.resolve({
        kernelMs: now$1() - o
      });
    }

    if (env$1().getBool("CHECK_COMPUTATION_FOR_ERRORS")) {
      var _loop = function _loop(_t9) {
        var n = r[_t9];
        n.data().then(t => {
          checkComputationForErrors$1(t, n.dtype, e);
        });
      };

      for (var _t9 = 0; _t9 < r.length; _t9++) {
        _loop(_t9);
      }
    }

    return {
      kernelName: e,
      outputs: r,
      inputs: t,
      timeMs: s.then(e => e.kernelMs),
      extraInfo: s.then(e => null != e.getExtraProfileInfo ? e.getExtraProfileInfo() : "")
    };
  }

  logKernelProfile(e) {
    var {
      kernelName: t,
      outputs: n,
      timeMs: r,
      inputs: a,
      extraInfo: s
    } = e;
    n.forEach(e => {
      Promise.all([e.data(), r, s]).then(n => {
        this.logger.logKernelProfile(t, e, n[0], n[1], a, n[2]);
      });
    });
  }

}

function checkComputationForErrors$1(e, t, n) {
  if ("float32" !== t) return !1;

  for (var _t10 = 0; _t10 < e.length; _t10++) {
    var r = e[_t10];
    if (isNaN(r) || !isFinite(r)) return console.warn("Found ".concat(r, " in the result of '").concat(n, "'")), !0;
  }

  return !1;
}

class Logger$1 {
  logKernelProfile(e, t, n, r, a, s) {
    var o = "number" == typeof r ? rightPad$1("".concat(r, "ms"), 9) : r.error,
        i = rightPad$1(e, 25),
        l = t.rank,
        u = t.size,
        c = rightPad$1(t.shape.toString(), 14);
    var p = "";

    for (var _e3 in a) {
      var _n3 = a[_e3];

      if (null != _n3) {
        var _r = _n3.shape || t.shape,
            _a = _r.length;

        p += "".concat(_e3, ": ").concat(_a, "D ").concat(_a > 0 ? _r : "", " ");
      }
    }

    console.log("%c".concat(i, "\t%c").concat(o, "\t%c").concat(l, "D ").concat(c, "\t%c").concat(u, "\t%c").concat(p, "\t%c").concat(s), "font-weight:bold", "color:red", "color:blue", "color: orange", "color: green", "color: steelblue");
  }

}

function getFilteredNodesXToY$1(e, t, n) {
  var r = {},
      a = {};

  for (var _e4 = 0; _e4 < t.length; _e4++) {
    r[t[_e4].id] = !0;
  }

  for (var _n4 = 0; _n4 < e.length; _n4++) {
    var _s2 = e[_n4],
        _o = _s2.inputs;

    for (var _e5 in _o) {
      var _n5 = _o[_e5];

      var _i = !1;

      for (var _e6 = 0; _e6 < t.length; _e6++) {
        if (r[_n5.id]) {
          _s2.outputs.forEach(e => r[e.id] = !0), _i = !0, a[_s2.id] = !0;
          break;
        }
      }

      if (_i) break;
    }
  }

  var s = {};
  s[n.id] = !0;
  var o = {};

  for (var _t11 = e.length - 1; _t11 >= 0; _t11--) {
    var _n6 = e[_t11],
        _r2 = _n6.inputs;

    for (var _e7 = 0; _e7 < _n6.outputs.length; _e7++) {
      if (s[_n6.outputs[_e7].id]) {
        for (var _e8 in _r2) {
          s[_r2[_e8].id] = !0, o[_n6.id] = !0;
        }

        break;
      }
    }
  }

  var i = [];

  for (var _t12 = 0; _t12 < e.length; _t12++) {
    var _n7 = e[_t12];

    if (a[_n7.id] && o[_n7.id]) {
      var _e9 = {};

      for (var _t14 in _n7.inputs) {
        var _a2 = _n7.inputs[_t14];
        r[_a2.id] && (_e9[_t14] = _a2);
      }

      var _t13 = Object.assign({}, _n7);

      _t13.inputs = _e9, _t13.outputs = _n7.outputs, i.push(_t13);
    }
  }

  return i;
}

function backpropagateGradients$1(e, t, n, r) {
  var _loop2 = function _loop2(a) {
    var s = t[a],
        o = [];
    if (s.outputs.forEach(t => {
      var n = e[t.id];
      o.push(null != n ? n : null);
    }), null == s.gradient) throw new Error("Cannot compute gradient: gradient function not found for ".concat(s.kernelName, "."));
    var i = s.gradient(o);

    var _loop3 = function _loop3(_t15) {
      if (!(_t15 in i)) throw new Error("Cannot backprop through input ".concat(_t15, ". Available gradients found: ").concat(Object.keys(i), "."));
      var a = n(() => i[_t15]());
      if ("float32" !== a.dtype) throw new Error("Error in gradient for op ".concat(s.kernelName, ". The gradient of input ").concat(_t15, " must have 'float32' dtype, but has '").concat(a.dtype, "'"));
      var o = s.inputs[_t15];
      if (!arraysEqual$1(a.shape, o.shape)) throw new Error("Error in gradient for op ".concat(s.kernelName, ". The gradient of input '").concat(_t15, "' has shape '").concat(a.shape, "', which does not match the shape of the input '").concat(o.shape, "'"));
      if (null == e[o.id]) e[o.id] = a;else {
        var _t16 = e[o.id];
        e[o.id] = r(_t16, a), _t16.dispose();
      }
    };

    for (var _t15 in s.inputs) {
      _loop3(_t15);
    }
  };

  for (var a = t.length - 1; a >= 0; a--) {
    _loop2(a);
  }
}

var FORMAT_LIMIT_NUM_VALS$1 = 20,
    FORMAT_NUM_FIRST_LAST_VALS$1 = 3,
    FORMAT_NUM_SIG_DIGITS$1 = 7;

function tensorToString$1(e, t, n, r) {
  var a = computeStrides$1(t),
      s = computeMaxSizePerColumn$1(e, t, n, a),
      o = t.length,
      i = subTensorToString$1(e, t, n, a, s),
      l = ["Tensor"];
  return r && (l.push("  dtype: ".concat(n)), l.push("  rank: ".concat(o)), l.push("  shape: [".concat(t, "]")), l.push("  values:")), l.push(i.map(e => "    " + e).join("\n")), l.join("\n");
}

function computeMaxSizePerColumn$1(e, t, n, r) {
  var a = sizeFromShape$1(t),
      s = r[r.length - 1],
      o = new Array(s).fill(0),
      i = t.length,
      l = "complex64" === n ? createComplexTuples$1(e) : e;
  if (i > 1) for (var _e10 = 0; _e10 < a / s; _e10++) {
    var _t17 = _e10 * s;

    for (var _e11 = 0; _e11 < s; _e11++) {
      o[_e11] = Math.max(o[_e11], valToString$1(l[_t17 + _e11], 0, n).length);
    }
  }
  return o;
}

function valToString$1(e, t, n) {
  var r;
  return r = Array.isArray(e) ? "".concat(parseFloat(e[0].toFixed(FORMAT_NUM_SIG_DIGITS$1)), " + ").concat(parseFloat(e[1].toFixed(FORMAT_NUM_SIG_DIGITS$1)), "j") : isString$1(e) ? "'".concat(e, "'") : "bool" === n ? boolNumToString$1(e) : parseFloat(e.toFixed(FORMAT_NUM_SIG_DIGITS$1)).toString(), rightPad$1(r, t);
}

function boolNumToString$1(e) {
  return 0 === e ? "false" : "true";
}

function subTensorToString$1(e, t, n, r, a) {
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : !0;
  var o = "complex64" === n ? 2 : 1,
      i = t[0],
      l = t.length;
  if (0 === l) return "complex64" === n ? [valToString$1(createComplexTuples$1(e)[0], 0, n)] : "bool" === n ? [boolNumToString$1(e[0])] : [e[0].toString()];

  if (1 === l) {
    if (i > FORMAT_LIMIT_NUM_VALS$1) {
      var _t18 = Array.from(e.slice(0, FORMAT_NUM_FIRST_LAST_VALS$1 * o)),
          _r3 = Array.from(e.slice((i - FORMAT_NUM_FIRST_LAST_VALS$1) * o, i * o));

      return "complex64" === n && (_t18 = createComplexTuples$1(_t18), _r3 = createComplexTuples$1(_r3)), ["[" + _t18.map((e, t) => valToString$1(e, a[t], n)).join(", ") + ", ..., " + _r3.map((e, t) => valToString$1(e, a[i - FORMAT_NUM_FIRST_LAST_VALS$1 + t], n)).join(", ") + "]"];
    }

    return ["[" + ("complex64" === n ? createComplexTuples$1(e) : Array.from(e)).map((e, t) => valToString$1(e, a[t], n)).join(", ") + "]"];
  }

  var u = t.slice(1),
      c = r.slice(1),
      p = r[0] * o,
      d = [];

  if (i > FORMAT_LIMIT_NUM_VALS$1) {
    for (var _t19 = 0; _t19 < FORMAT_NUM_FIRST_LAST_VALS$1; _t19++) {
      var _r4 = _t19 * p;

      d.push(...subTensorToString$1(e.slice(_r4, _r4 + p), u, n, c, a, !1));
    }

    d.push("...");

    for (var _t20 = i - FORMAT_NUM_FIRST_LAST_VALS$1; _t20 < i; _t20++) {
      var _r5 = _t20 * p;

      d.push(...subTensorToString$1(e.slice(_r5, _r5 + p), u, n, c, a, _t20 === i - 1));
    }
  } else for (var _t21 = 0; _t21 < i; _t21++) {
    var _r6 = _t21 * p;

    d.push(...subTensorToString$1(e.slice(_r6, _r6 + p), u, n, c, a, _t21 === i - 1));
  }

  var h = 2 === l ? "," : "";
  d[0] = "[" + d[0] + h;

  for (var _e12 = 1; _e12 < d.length - 1; _e12++) {
    d[_e12] = " " + d[_e12] + h;
  }

  var m = ",\n";

  for (var _e13 = 2; _e13 < l; _e13++) {
    m += "\n";
  }

  return d[d.length - 1] = " " + d[d.length - 1] + "]" + (s ? "" : m), d;
}

function createComplexTuples$1(e) {
  var t = [];

  for (var n = 0; n < e.length; n += 2) {
    t.push([e[n], e[n + 1]]);
  }

  return t;
}

class TensorBuffer$1 {
  constructor(e, t, n) {
    if (this.dtype = t, this.shape = e.slice(), this.size = sizeFromShape$1(e), null != n) {
      var _e14 = n.length;
      assert$6(_e14 === this.size, () => "Length of values '".concat(_e14, "' does not match the size inferred by the shape '").concat(this.size, "'."));
    }

    if ("complex64" === t) throw new Error("complex64 dtype TensorBuffers are not supported. Please create a TensorBuffer for the real and imaginary parts separately and call tf.complex(real, imag).");
    this.values = n || getArrayFromDType$1(t, this.size), this.strides = computeStrides$1(e);
  }

  set(e) {
    for (var _len2 = arguments.length, t = new Array(_len2 > 1 ? _len2 - 1 : 0), _key2 = 1; _key2 < _len2; _key2++) {
      t[_key2 - 1] = arguments[_key2];
    }

    0 === t.length && (t = [0]), assert$6(t.length === this.rank, () => "The number of provided coordinates (".concat(t.length, ") must match the rank (").concat(this.rank, ")"));
    var n = this.locToIndex(t);
    this.values[n] = e;
  }

  get() {
    for (var _len3 = arguments.length, e = new Array(_len3), _key3 = 0; _key3 < _len3; _key3++) {
      e[_key3] = arguments[_key3];
    }

    0 === e.length && (e = [0]);
    var t = 0;

    for (var _n8 of e) {
      if (_n8 < 0 || _n8 >= this.shape[t]) throw new Error("Requested out of range element at ".concat(e, ".   Buffer shape=").concat(this.shape));
      t++;
    }

    var n = e[e.length - 1];

    for (var _t22 = 0; _t22 < e.length - 1; ++_t22) {
      n += this.strides[_t22] * e[_t22];
    }

    return this.values[n];
  }

  locToIndex(e) {
    if (0 === this.rank) return 0;
    if (1 === this.rank) return e[0];
    var t = e[e.length - 1];

    for (var n = 0; n < e.length - 1; ++n) {
      t += this.strides[n] * e[n];
    }

    return t;
  }

  indexToLoc(e) {
    if (0 === this.rank) return [];
    if (1 === this.rank) return [e];
    var t = new Array(this.shape.length);

    for (var n = 0; n < t.length - 1; ++n) {
      t[n] = Math.floor(e / this.strides[n]), e -= t[n] * this.strides[n];
    }

    return t[t.length - 1] = e, t;
  }

  get rank() {
    return this.shape.length;
  }

  toTensor() {
    return trackerFn$1().makeTensor(this.values, this.shape, this.dtype);
  }

}

var trackerFn$1 = null,
    opHandler$3 = null;

function setTensorTracker$1(e) {
  trackerFn$1 = e;
}

function setOpHandler$1(e) {
  opHandler$3 = e;
}

class Tensor$1 {
  constructor(e, t, n, r) {
    this.kept = !1, this.isDisposedInternal = !1, this.shape = e.slice(), this.dtype = t || "float32", this.size = sizeFromShape$1(e), this.strides = computeStrides$1(e), this.dataId = n, this.id = r, this.rankType = this.rank < 5 ? this.rank.toString() : "higher";
  }

  get rank() {
    return this.shape.length;
  }

  buffer() {
    var _this2 = this;

    return _asyncToGenerator(function* () {
      var e = yield _this2.data();
      return opHandler$3.buffer(_this2.shape, _this2.dtype, e);
    })();
  }

  bufferSync() {
    return opHandler$3.buffer(this.shape, this.dtype, this.dataSync());
  }

  array() {
    var _this3 = this;

    return _asyncToGenerator(function* () {
      var e = yield _this3.data();
      return toNestedArray$1(_this3.shape, e, "complex64" === _this3.dtype);
    })();
  }

  arraySync() {
    return toNestedArray$1(this.shape, this.dataSync(), "complex64" === this.dtype);
  }

  data() {
    var _this4 = this;

    return _asyncToGenerator(function* () {
      _this4.throwIfDisposed();

      var e = trackerFn$1().read(_this4.dataId);

      if ("string" === _this4.dtype) {
        var t = yield e;

        try {
          return t.map(e => decodeString$1(e));
        } catch (e) {
          throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().");
        }
      }

      return e;
    })();
  }

  dataSync() {
    this.throwIfDisposed();
    var e = trackerFn$1().readSync(this.dataId);
    if ("string" === this.dtype) try {
      return e.map(e => decodeString$1(e));
    } catch (e) {
      throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().");
    }
    return e;
  }

  bytes() {
    var _this5 = this;

    return _asyncToGenerator(function* () {
      _this5.throwIfDisposed();

      var e = yield trackerFn$1().read(_this5.dataId);
      return "string" === _this5.dtype ? e : new Uint8Array(e.buffer);
    })();
  }

  dispose() {
    this.isDisposed || (trackerFn$1().disposeTensor(this), this.isDisposedInternal = !0);
  }

  get isDisposed() {
    return this.isDisposedInternal;
  }

  throwIfDisposed() {
    if (this.isDisposed) throw new Error("Tensor is disposed.");
  }

  print() {
    var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : !1;
    return opHandler$3.print(this, e);
  }

  clone() {
    return this.throwIfDisposed(), opHandler$3.clone(this);
  }

  toString() {
    var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : !1;
    return tensorToString$1(this.dataSync(), this.shape, this.dtype, e);
  }

  cast(e) {
    return this.throwIfDisposed(), opHandler$3.cast(this, e);
  }

  variable() {
    var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : !0;
    var t = arguments.length > 1 ? arguments[1] : undefined;
    var n = arguments.length > 2 ? arguments[2] : undefined;
    return this.throwIfDisposed(), trackerFn$1().makeVariable(this, e, t, n);
  }

}

function getGlobalTensorClass$1() {
  return getGlobal$1("Tensor", () => Tensor$1);
}

Object.defineProperty(Tensor$1, Symbol.hasInstance, {
  value: e => !!e && null != e.data && null != e.dataSync && null != e.throwIfDisposed
}), getGlobalTensorClass$1();

class Variable$1 extends Tensor$1 {
  constructor(e, t, n, r) {
    super(e.shape, e.dtype, e.dataId, r), this.trainable = t, this.name = n;
  }

  assign(e) {
    if (e.dtype !== this.dtype) throw new Error("dtype of the new value (".concat(e.dtype, ") and previous value (").concat(this.dtype, ") must match"));
    if (!arraysEqual$1(e.shape, this.shape)) throw new Error("shape of the new value (".concat(e.shape, ") and previous value (").concat(this.shape, ") must match"));
    trackerFn$1().disposeTensor(this), this.dataId = e.dataId, trackerFn$1().incRef(this, null);
  }

  dispose() {
    trackerFn$1().disposeVariable(this), this.isDisposedInternal = !0;
  }

}

var Rank$1, UpcastInt32AndMap$1, UpcastBoolAndMap$1, UpcastFloat32AndMap$1, UpcastComplex64AndMap$1;
Object.defineProperty(Variable$1, Symbol.hasInstance, {
  value: e => e instanceof Tensor$1 && null != e.assign && e.assign instanceof Function
}), function (e) {
  e.R0 = "R0", e.R1 = "R1", e.R2 = "R2", e.R3 = "R3", e.R4 = "R4", e.R5 = "R5", e.R6 = "R6";
}(Rank$1 || (Rank$1 = {})), function (e) {
  e.float32 = "float32", e.int32 = "int32", e.bool = "int32", e.complex64 = "complex64";
}(UpcastInt32AndMap$1 || (UpcastInt32AndMap$1 = {})), function (e) {
  e.float32 = "float32", e.int32 = "int32", e.bool = "bool", e.complex64 = "complex64";
}(UpcastBoolAndMap$1 || (UpcastBoolAndMap$1 = {})), function (e) {
  e.float32 = "float32", e.int32 = "float32", e.bool = "float32", e.complex64 = "complex64";
}(UpcastFloat32AndMap$1 || (UpcastFloat32AndMap$1 = {})), function (e) {
  e.float32 = "complex64", e.int32 = "complex64", e.bool = "complex64", e.complex64 = "complex64";
}(UpcastComplex64AndMap$1 || (UpcastComplex64AndMap$1 = {}));
var upcastTypeMap$1 = {
  float32: UpcastFloat32AndMap$1,
  int32: UpcastInt32AndMap$1,
  bool: UpcastBoolAndMap$1,
  complex64: UpcastComplex64AndMap$1
};

function upcastType$1(e, t) {
  if ("string" === e || "string" === t) {
    if ("string" === e && "string" === t) return "string";
    throw new Error("Can not upcast ".concat(e, " with ").concat(t));
  }

  return upcastTypeMap$1[e][t];
}

function sumOutType$1(e) {
  return upcastType$1(e, "int32");
}

function makeTypesMatch$1(e, t) {
  if (e.dtype === t.dtype) return [e, t];
  var n = upcastType$1(e.dtype, t.dtype);
  return [e.cast(n), t.cast(n)];
}

function getTensorsInContainer$1(e) {
  var t = [];
  return walkTensorContainer$1(e, t, new Set()), t;
}

function walkTensorContainer$1(e, t, n) {
  if (null == e) return;
  if (e instanceof Tensor$1) return void t.push(e);
  if (!isIterable$2(e)) return;
  var r = e;

  for (var _e15 in r) {
    var a = r[_e15];
    n.has(a) || (n.add(a), walkTensorContainer$1(a, t, n));
  }
}

function isIterable$2(e) {
  return Array.isArray(e) || "object" == typeof e;
}

function isRegisteredKernelInvocation$1(e) {
  return null != e.kernelName;
}

class EngineState$1 {
  constructor() {
    this.registeredVariables = {}, this.nextTapeNodeId = 0, this.numBytes = 0, this.numTensors = 0, this.numStringTensors = 0, this.numDataBuffers = 0, this.gradientDepth = 0, this.kernelDepth = 0, this.scopeStack = [], this.numDataMovesStack = [], this.nextScopeId = 0, this.tensorInfo = new WeakMap(), this.profiling = !1, this.activeProfile = {
      newBytes: 0,
      newTensors: 0,
      peakBytes: 0,
      kernels: [],
      result: null,

      get kernelNames() {
        return Array.from(new Set(this.kernels.map(e => e.name)));
      }

    };
  }

  dispose() {
    for (var e in this.registeredVariables) {
      this.registeredVariables[e].dispose();
    }
  }

}

class Engine$1 {
  constructor(e) {
    this.ENV = e, this.registry = {}, this.registryFactory = {}, this.pendingBackendInitId = 0, this.state = new EngineState$1();
  }

  ready() {
    var _this6 = this;

    return _asyncToGenerator(function* () {
      if (null != _this6.pendingBackendInit) return _this6.pendingBackendInit.then(() => {});
      if (null != _this6.backendInstance) return;

      var e = _this6.getSortedBackends();

      for (var t = 0; t < e.length; t++) {
        var n = e[t];
        if (yield _this6.initializeBackend(n).success) return void (yield _this6.setBackend(n));
      }

      throw new Error("Could not initialize any backends, all backend initializations failed.");
    })();
  }

  get backend() {
    if (null != this.pendingBackendInit) throw new Error("Backend '".concat(this.backendName, "' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods"));

    if (null == this.backendInstance) {
      var {
        name: e,
        asyncInit: t
      } = this.initializeBackendsAndReturnBest();
      if (t) throw new Error("The highest priority backend '".concat(e, "' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods"));
      this.setBackend(e);
    }

    return this.backendInstance;
  }

  backendNames() {
    return Object.keys(this.registryFactory);
  }

  findBackend(e) {
    if (!(e in this.registry)) {
      if (!(e in this.registryFactory)) return null;
      {
        var {
          asyncInit: t
        } = this.initializeBackend(e);
        if (t) return null;
      }
    }

    return this.registry[e];
  }

  findBackendFactory(e) {
    return e in this.registryFactory ? this.registryFactory[e].factory : null;
  }

  registerBackend(e, t) {
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 1;
    return e in this.registryFactory ? (console.warn("".concat(e, " backend was already registered. Reusing existing backend factory.")), !1) : (this.registryFactory[e] = {
      factory: t,
      priority: n
    }, !0);
  }

  setBackend(e) {
    var _this7 = this;

    return _asyncToGenerator(function* () {
      if (null == _this7.registryFactory[e]) throw new Error("Backend name '".concat(e, "' not found in registry"));

      if (_this7.backendName = e, null == _this7.registry[e]) {
        _this7.backendInstance = null;

        var {
          success: t,
          asyncInit: n
        } = _this7.initializeBackend(e);

        if (!(n ? yield t : t)) return !1;
      }

      return _this7.backendInstance = _this7.registry[e], _this7.setupRegisteredKernels(), _this7.profiler = new Profiler$1(_this7.backendInstance), !0;
    })();
  }

  setupRegisteredKernels() {
    getKernelsForBackend$1(this.backendName).forEach(e => {
      null != e.setupFunc && e.setupFunc(this.backendInstance);
    });
  }

  disposeRegisteredKernels(e) {
    getKernelsForBackend$1(e).forEach(t => {
      null != t.disposeFunc && t.disposeFunc(this.registry[e]);
    });
  }

  initializeBackend(e) {
    var t = this.registryFactory[e];
    if (null == t) throw new Error("Cannot initialize backend ".concat(e, ", no registration found."));

    try {
      var n = t.factory();
      if (!n || n instanceof KernelBackend$1 || "function" != typeof n.then) return this.registry[e] = n, {
        success: !0,
        asyncInit: !1
      };
      {
        var _t23 = ++this.pendingBackendInitId,
            r = n.then(n => !(_t23 < this.pendingBackendInitId || (this.registry[e] = n, this.pendingBackendInit = null, 0))).catch(n => (_t23 < this.pendingBackendInitId || (this.pendingBackendInit = null, console.warn("Initialization of backend ".concat(e, " failed")), console.warn(n.stack || n.message)), !1));

        return this.pendingBackendInit = r, {
          success: r,
          asyncInit: !0
        };
      }
    } catch (t) {
      return console.warn("Initialization of backend ".concat(e, " failed")), console.warn(t.stack || t.message), {
        success: !1,
        asyncInit: !1
      };
    }
  }

  removeBackend(e) {
    if (!(e in this.registryFactory)) throw new Error("".concat(e, " backend not found in registry"));
    this.backendName === e && null != this.pendingBackendInit && this.pendingBackendInitId++, e in this.registry && (this.disposeRegisteredKernels(e), this.registry[e].dispose(), delete this.registry[e]), delete this.registryFactory[e], this.backendName === e && (this.pendingBackendInit = null, this.backendName = null, this.backendInstance = null);
  }

  getSortedBackends() {
    if (0 === Object.keys(this.registryFactory).length) throw new Error("No backend found in registry.");
    return Object.keys(this.registryFactory).sort((e, t) => this.registryFactory[t].priority - this.registryFactory[e].priority);
  }

  initializeBackendsAndReturnBest() {
    var e = this.getSortedBackends();

    for (var t = 0; t < e.length; t++) {
      var n = e[t],
          {
        success: r,
        asyncInit: a
      } = this.initializeBackend(n);
      if (a || r) return {
        name: n,
        asyncInit: a
      };
    }

    throw new Error("Could not initialize any backends, all backend initializations failed.");
  }

  moveData(e, t) {
    var n = this.state.tensorInfo.get(t),
        r = n.backend,
        a = this.readSync(t),
        s = r.refCount(t);
    r.disposeData(t, !0), n.backend = e, e.move(t, a, n.shape, n.dtype, s), this.shouldCheckForMemLeaks() && this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1]++;
  }

  tidy(e, t) {
    var n,
        r = null;

    if (null == t) {
      if ("function" != typeof e) throw new Error("Please provide a function to tidy()");
      t = e;
    } else {
      if ("string" != typeof e && !(e instanceof String)) throw new Error("When calling with two arguments, the first argument to tidy() must be a string");
      if ("function" != typeof t) throw new Error("When calling with two arguments, the 2nd argument to tidy() must be a function");
      r = e;
    }

    return this.scopedRun(() => this.startScope(r), () => this.endScope(n), () => (n = t(), n instanceof Promise && console.error("Cannot return a Promise inside of tidy."), n));
  }

  scopedRun(e, t, n) {
    e();

    try {
      var _e16 = n();

      return t(), _e16;
    } catch (e) {
      throw t(), e;
    }
  }

  nextTensorId() {
    return Engine$1.nextTensorId++;
  }

  nextVariableId() {
    return Engine$1.nextVariableId++;
  }

  clone(e) {
    var t = ENGINE$1.runKernel(Identity$3, {
      x: e
    });
    return this.addTapeNode(this.state.activeScope.name, {
      x: e
    }, [t], e => ({
      x: () => ENGINE$1.runKernel(Cast$1, {
        x: e
      }, {
        dtype: "float32"
      })
    }), [], {}), t;
  }

  runKernel(e, t, n) {
    if (null == getKernel$1(e, this.backendName)) throw new Error("Kernel '".concat(e, "' not registered for backend '").concat(this.backendName, "'"));
    return this.runKernelFunc({
      kernelName: e,
      inputs: t,
      attrs: n
    });
  }

  shouldCheckForMemLeaks() {
    return this.ENV.getBool("IS_TEST");
  }

  checkKernelForMemLeak(e, t, n) {
    var r = this.backend.numDataIds();
    var a = 0;
    n.forEach(e => {
      a += "complex64" === e.dtype ? 3 : 1;
    });
    var s = r - t - a - this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1];
    if (s > 0) throw new Error("Backend '".concat(this.backendName, "' has an internal memory leak (").concat(s, " data ids) after running '").concat(e, "'"));
  }

  runKernelFunc(e) {
    var t,
        n = [];
    var r = this.isTapeOn(),
        a = this.state.numBytes,
        s = this.state.numTensors;
    var o, i;
    this.shouldCheckForMemLeaks() && this.state.numDataMovesStack.push(0);
    var l = isRegisteredKernelInvocation$1(e) ? e.kernelName : null != this.state.activeScope ? this.state.activeScope.name : "";

    if (isRegisteredKernelInvocation$1(e)) {
      var {
        kernelName: _t24,
        inputs: _a3,
        attrs: _s3
      } = e,
          _l = getKernel$1(_t24, this.backendName);

      assert$6(null != _l, () => "Cannot find registered kernel '".concat(_t24, "' for backend '").concat(this.backendName, "'")), o = () => {
        var e = this.backend.numDataIds();
        i = _l.kernelFunc({
          inputs: _a3,
          attrs: _s3,
          backend: this.backend
        });
        var o = Array.isArray(i) ? i : [i];
        this.shouldCheckForMemLeaks() && this.checkKernelForMemLeak(_t24, e, o);
        var u = o.map(e => {
          if (null != e.rank) return e;
          var {
            dataId: t,
            shape: n,
            dtype: r
          } = e;
          return this.makeTensorFromDataId(t, n, r);
        });

        if (r) {
          var _e17 = this.getTensorsForGradient(_t24, _a3, u);

          n = this.saveTensorsForBackwardMode(_e17);
        }

        return u;
      };
    } else {
      var {
        forwardFunc: _t25
      } = e,
          _a4 = e => {
        r && (n = e.map(e => this.keep(this.clone(e))));
      };

      o = () => {
        var e = this.backend.numDataIds();
        i = this.tidy(() => _t25(this.backend, _a4));
        var n = Array.isArray(i) ? i : [i];
        return this.shouldCheckForMemLeaks() && this.checkKernelForMemLeak(l, e, n), n;
      };
    }

    var {
      inputs: u,
      attrs: c
    } = e,
        p = isRegisteredKernelInvocation$1(e) ? null : e.backwardsFunc;
    var d;
    return this.scopedRun(() => this.state.kernelDepth++, () => this.state.kernelDepth--, () => {
      this.ENV.getBool("DEBUG") || this.state.profiling ? (d = this.profiler.profileKernel(l, u, () => o()), this.ENV.getBool("DEBUG") && this.profiler.logKernelProfile(d), t = d.outputs) : t = o();
    }), r && this.addTapeNode(l, u, t, p, n, c), this.state.profiling && this.state.activeProfile.kernels.push({
      name: l,
      bytesAdded: this.state.numBytes - a,
      totalBytesSnapshot: this.state.numBytes,
      tensorsAdded: this.state.numTensors - s,
      totalTensorsSnapshot: this.state.numTensors,
      inputShapes: Object.keys(u).map(e => null != u[e] ? u[e].shape : null),
      outputShapes: t.map(e => e.shape),
      kernelTimeMs: d.timeMs,
      extraInfo: d.extraInfo
    }), Array.isArray(i) ? t : t[0];
  }

  saveTensorsForBackwardMode(e) {
    var t = e.map(e => this.keep(this.clone(e)));
    return t;
  }

  getTensorsForGradient(e, t, n) {
    var r = getGradient$1(e);

    if (null != r) {
      var _e18 = r.inputsToSave || [],
          a = r.outputsToSave || [];

      var s;
      r.saveAllInputs ? (assert$6(Array.isArray(t), () => "saveAllInputs is true, expected inputs to be an array."), s = Object.keys(t).map(e => t[e])) : s = _e18.map(e => t[e]);
      var o = n.filter((e, t) => a[t]);
      return s.concat(o);
    }

    return [];
  }

  makeTensor(e, t, n, r) {
    if (null == e) throw new Error("Values passed to engine.makeTensor() are null");
    r = r || this.backend;
    var a = e;
    "string" === (n = n || "float32") && isString$1(e[0]) && (a = e.map(e => encodeString$1(e)));
    var s = r.write(a, t, n),
        o = new Tensor$1(t, n, s, this.nextTensorId());

    if (this.trackTensor(o, r), "string" === n) {
      var _e19 = this.state.tensorInfo.get(s),
          _t26 = bytesFromStringArray$1(a);

      this.state.numBytes += _t26 - _e19.bytes, _e19.bytes = _t26;
    }

    return o;
  }

  makeTensorFromDataId(e, t, n, r) {
    var a = new Tensor$1(t, n = n || "float32", e, this.nextTensorId());
    return this.trackTensor(a, r), a;
  }

  makeVariable(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !0;
    var n = arguments.length > 2 ? arguments[2] : undefined;
    var r = arguments.length > 3 ? arguments[3] : undefined;
    n = n || this.nextVariableId().toString(), null != r && r !== e.dtype && (e = e.cast(r));
    var a = new Variable$1(e, t, n, this.nextTensorId());
    if (null != this.state.registeredVariables[a.name]) throw new Error("Variable with name ".concat(a.name, " was already registered"));
    return this.state.registeredVariables[a.name] = a, this.incRef(a, this.backend), a;
  }

  trackTensor(e, t) {
    this.state.numTensors++, "string" === e.dtype && this.state.numStringTensors++;
    var n = 0;
    "complex64" !== e.dtype && "string" !== e.dtype && (n = e.size * bytesPerElement$1(e.dtype)), this.state.numBytes += n, this.state.tensorInfo.has(e.dataId) || (this.state.numDataBuffers++, this.state.tensorInfo.set(e.dataId, {
      backend: t || this.backend,
      dtype: e.dtype,
      shape: e.shape,
      bytes: n
    })), e instanceof Variable$1 || this.track(e);
  }

  incRef(e, t) {
    this.trackTensor(e, t), this.backend.incRef(e.dataId);
  }

  removeDataId(e, t) {
    this.state.tensorInfo.has(e) && this.state.tensorInfo.get(e).backend === t && (this.state.tensorInfo.delete(e), this.state.numDataBuffers--);
  }

  disposeTensor(e) {
    if (!this.state.tensorInfo.has(e.dataId)) return;
    var t = this.state.tensorInfo.get(e.dataId);

    if (this.state.numTensors--, "string" === e.dtype && (this.state.numStringTensors--, this.state.numBytes -= t.bytes), "complex64" !== e.dtype && "string" !== e.dtype) {
      var _t27 = e.size * bytesPerElement$1(e.dtype);

      this.state.numBytes -= _t27;
    }

    t.backend.disposeData(e.dataId) && this.removeDataId(e.dataId, t.backend);
  }

  disposeVariables() {
    for (var e in this.state.registeredVariables) {
      this.disposeVariable(this.state.registeredVariables[e]);
    }
  }

  disposeVariable(e) {
    this.disposeTensor(e), null != this.state.registeredVariables[e.name] && delete this.state.registeredVariables[e.name];
  }

  memory() {
    var e = this.backend.memory();
    return e.numTensors = this.state.numTensors, e.numDataBuffers = this.state.numDataBuffers, e.numBytes = this.state.numBytes, this.state.numStringTensors > 0 && (e.unreliable = !0, null == e.reasons && (e.reasons = []), e.reasons.push("Memory usage by string tensors is approximate (2 bytes per character)")), e;
  }

  profile(e) {
    var _this8 = this;

    return _asyncToGenerator(function* () {
      _this8.state.profiling = !0;
      var t = _this8.state.numBytes,
          n = _this8.state.numTensors;
      _this8.state.activeProfile.kernels = [], _this8.state.activeProfile.result = yield e(), _this8.state.profiling = !1, _this8.state.activeProfile.peakBytes = Math.max(..._this8.state.activeProfile.kernels.map(e => e.totalBytesSnapshot)), _this8.state.activeProfile.newBytes = _this8.state.numBytes - t, _this8.state.activeProfile.newTensors = _this8.state.numTensors - n;

      for (var _e20 of _this8.state.activeProfile.kernels) {
        _e20.kernelTimeMs = yield _e20.kernelTimeMs, _e20.extraInfo = yield _e20.extraInfo;
      }

      return _this8.state.activeProfile;
    })();
  }

  isTapeOn() {
    return this.state.gradientDepth > 0 && 0 === this.state.kernelDepth;
  }

  addTapeNode(e, t, n, r, a, s) {
    var o = {
      id: this.state.nextTapeNodeId++,
      kernelName: e,
      inputs: t,
      outputs: n,
      saved: a
    },
        i = getGradient$1(e);
    null != i && (r = i.gradFunc), null != r && (o.gradient = e => (e = e.map((e, t) => {
      if (null == e) {
        var _e21 = n[t],
            _r7 = makeZerosTypedArray$1(_e21.size, _e21.dtype);

        return this.makeTensor(_r7, _e21.shape, _e21.dtype);
      }

      return e;
    }), r(e.length > 1 ? e : e[0], a, s))), this.state.activeTape.push(o);
  }

  keep(e) {
    return e.kept = !0, e;
  }

  startTape() {
    0 === this.state.gradientDepth && (this.state.activeTape = []), this.state.gradientDepth++;
  }

  endTape() {
    this.state.gradientDepth--;
  }

  startScope(e) {
    var t = {
      track: [],
      name: "unnamed scope",
      id: this.state.nextScopeId++
    };
    e && (t.name = e), this.state.scopeStack.push(t), this.state.activeScope = t;
  }

  endScope(e) {
    var t = getTensorsInContainer$1(e),
        n = new Set(t.map(e => e.id));

    for (var _e22 = 0; _e22 < this.state.activeScope.track.length; _e22++) {
      var _t28 = this.state.activeScope.track[_e22];
      _t28.kept || n.has(_t28.id) || _t28.dispose();
    }

    var r = this.state.scopeStack.pop();
    this.state.activeScope = 0 === this.state.scopeStack.length ? null : this.state.scopeStack[this.state.scopeStack.length - 1], t.forEach(e => {
      e.kept || e.scopeId !== r.id || this.track(e);
    });
  }

  gradients(e, t, n) {
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
    if (assert$6(t.length > 0, () => "gradients() received an empty list of xs."), null != n && "float32" !== n.dtype) throw new Error("dy must have 'float32' dtype, but has '".concat(n.dtype, "'"));
    var a = this.scopedRun(() => this.startTape(), () => this.endTape(), () => this.tidy("forward", e));
    assert$6(a instanceof Tensor$1, () => "The result y returned by f() must be a tensor.");
    var s = getFilteredNodesXToY$1(this.state.activeTape, t, a);
    if (!r && 0 === s.length && t.length > 0) throw new Error("Cannot compute gradient of y=f(x) with respect to x. Make sure that the f you passed encloses all operations that lead from x to y.");
    return this.tidy("backward", () => {
      var e = {};
      e[a.id] = null == n ? ones$4(a.shape) : n, backpropagateGradients$1(e, s, e => this.tidy(e), add$6);
      var r = t.map(t => e[t.id]);
      return 0 === this.state.gradientDepth && (this.state.activeTape.forEach(e => {
        for (var _t29 of e.saved) {
          _t29.dispose();
        }
      }), this.state.activeTape = null), {
        value: a,
        grads: r
      };
    });
  }

  customGrad(e) {
    var _this9 = this;

    return assert$6(isFunction$1(e), () => "The f passed in customGrad(f) must be a function."), function () {
      for (var _len4 = arguments.length, t = new Array(_len4), _key4 = 0; _key4 < _len4; _key4++) {
        t[_key4] = arguments[_key4];
      }

      var n;
      assert$6(t.every(e => e instanceof Tensor$1), () => "The args passed in customGrad(f)(x1, x2,...) must all be tensors");
      var r = {};
      return t.forEach((e, t) => {
        r[t] = e;
      }), _this9.runKernelFunc({
        forwardFunc: (r, a) => (n = e(...t, a), assert$6(n.value instanceof Tensor$1, () => "The function f passed in customGrad(f) must return an object where `obj.value` is a tensor"), assert$6(isFunction$1(n.gradFunc), () => "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function."), n.value),
        backwardsFunc: (e, r) => {
          var a = n.gradFunc(e, r),
              s = Array.isArray(a) ? a : [a];
          assert$6(s.length === t.length, () => "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns the same number of tensors as inputs passed to f(...)."), assert$6(s.every(e => e instanceof Tensor$1), () => "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns a list of only tensors.");
          var o = {};
          return s.forEach((e, t) => {
            o[t] = () => e;
          }), o;
        },
        inputs: r
      });
    };
  }

  readSync(e) {
    return this.state.tensorInfo.get(e).backend.readSync(e);
  }

  read(e) {
    return this.state.tensorInfo.get(e).backend.read(e);
  }

  time(e) {
    var _this10 = this;

    return _asyncToGenerator(function* () {
      var t = now$1(),
          n = yield _this10.backend.time(e);
      return n.wallMs = now$1() - t, n;
    })();
  }

  track(e) {
    return null != this.state.activeScope && (e.scopeId = this.state.activeScope.id, this.state.activeScope.track.push(e)), e;
  }

  get registeredVariables() {
    return this.state.registeredVariables;
  }

  reset() {
    this.pendingBackendInitId++, this.state.dispose(), this.ENV.reset(), this.state = new EngineState$1();

    for (var e in this.registry) {
      this.disposeRegisteredKernels(e), this.registry[e].dispose(), delete this.registry[e];
    }

    this.backendName = null, this.backendInstance = null, this.pendingBackendInit = null;
  }

}

function ones$4(e) {
  var t = makeOnesTypedArray$1(sizeFromShape$1(e), "float32");
  return ENGINE$1.makeTensor(t, e, "float32");
}

function getOrMakeEngine$1() {
  var e = getGlobalNamespace$1();

  if (null == e._tfengine) {
    var t = new Environment$1(e);
    e._tfengine = new Engine$1(t);
  }

  return setEnvironmentGlobal$1(e._tfengine.ENV), setTensorTracker$1(() => e._tfengine), e._tfengine;
}

Engine$1.nextTensorId = 0, Engine$1.nextVariableId = 0;
var ENGINE$1 = getOrMakeEngine$1();

function add$6(e, t) {
  return ENGINE$1.runKernel(Add$3, {
    a: e,
    b: t
  });
}

function _isNavigatorDefined$1() {
  return "undefined" != typeof navigator && null != navigator;
}

function isMobile$1(e) {
  if (e || _isNavigatorDefined$1()) {
    if (e || (e = navigator), "ReactNative" === e.product) return !0;
    var t = e.userAgent || e.vendor || window.opera;
    return /(android|bb\d+|meego).+mobile|avantgo|bada\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\.(browser|link)|vodafone|wap|windows ce|xda|xiino/i.test(t) || /1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\-(n|u)|c55\/|capi|ccwa|cdm\-|cell|chtm|cldc|cmd\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\-s|devi|dica|dmob|do(c|p)o|ds(12|\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\-|_)|g1 u|g560|gene|gf\-5|g\-mo|go(\.w|od)|gr(ad|un)|haie|hcit|hd\-(m|p|t)|hei\-|hi(pt|ta)|hp( i|ip)|hs\-c|ht(c(\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\-(20|go|ma)|i230|iac( |\-|\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\/)|klon|kpt |kwc\-|kyo(c|k)|le(no|xi)|lg( g|\/(k|l|u)|50|54|\-[a-w])|libw|lynx|m1\-w|m3ga|m50\/|ma(te|ui|xo)|mc(01|21|ca)|m\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\-2|po(ck|rt|se)|prox|psio|pt\-g|qa\-a|qc(07|12|21|32|60|\-[2-7]|i\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\-|oo|p\-)|sdk\/|se(c(\-|0|1)|47|mc|nd|ri)|sgh\-|shar|sie(\-|m)|sk\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\-|v\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\-|tdg\-|tel(i|m)|tim\-|t\-mo|to(pl|sh)|ts(70|m\-|m3|m5)|tx\-9|up(\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\-|your|zeto|zte\-/i.test(t.substr(0, 4));
  }

  return !1;
}

function isBrowser$1() {
  return "undefined" != typeof window && null != window.document || "undefined" != typeof WorkerGlobalScope;
}

var ENV$4 = env$1();

function inferShape$1(e, t) {
  var n = e;
  if (isTypedArray$1(e)) return "string" === t ? [] : [e.length];
  if (!Array.isArray(e)) return [];
  var r = [];

  for (; Array.isArray(n) || isTypedArray$1(n) && "string" !== t;) {
    r.push(n.length), n = n[0];
  }

  return Array.isArray(e) && env$1().getBool("TENSORLIKE_CHECK_SHAPE_CONSISTENCY") && deepAssertShapeConsistency$1(e, r, []), r;
}

function deepAssertShapeConsistency$1(e, t, n) {
  if (n = n || [], !Array.isArray(e) && !isTypedArray$1(e)) return void assert$6(0 === t.length, () => "Element arr[".concat(n.join("]["), "] is a primitive, but should be an array/TypedArray of ").concat(t[0], " elements"));
  assert$6(t.length > 0, () => "Element arr[".concat(n.join("]["), "] should be a primitive, but is an array of ").concat(e.length, " elements")), assert$6(e.length === t[0], () => "Element arr[".concat(n.join("]["), "] should have ").concat(t[0], " elements, but has ").concat(e.length, " elements"));
  var r = t.slice(1);

  for (var _t30 = 0; _t30 < e.length; ++_t30) {
    deepAssertShapeConsistency$1(e[_t30], r, n.concat(_t30));
  }
}

function assertDtype$1(e, t, n, r) {
  if ("string_or_numeric" !== e) {
    if (null == e) throw new Error("Expected dtype cannot be null.");
    if ("numeric" !== e && e !== t || "numeric" === e && "string" === t) throw new Error("Argument '".concat(n, "' passed to '").concat(r, "' must be ").concat(e, " tensor, but got ").concat(t, " tensor"));
  }
}

function convertToTensor$1(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : "numeric";
  if (e instanceof Tensor$1) return assertDtype$1(r, e.dtype, t, n), e;
  var a = inferDtype$1(e);
  if ("string" !== a && ["bool", "int32", "float32"].indexOf(r) >= 0 && (a = r), assertDtype$1(r, a, t, n), null == e || !isTypedArray$1(e) && !Array.isArray(e) && "number" != typeof e && "boolean" != typeof e && "string" != typeof e) throw new Error("Argument '".concat(t, "' passed to '").concat(n, "' must be a Tensor or TensorLike, but got '").concat(null == e ? "null" : e.constructor.name, "'"));
  var s = inferShape$1(e, a);
  isTypedArray$1(e) || Array.isArray(e) || (e = [e]);
  var o = "string" !== a ? toTypedArray$1(e, a) : flatten$6(e, [], !0);
  return ENGINE$1.makeTensor(o, s, a);
}

function convertToTensorArray$1(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : "numeric";
  if (!Array.isArray(e)) throw new Error("Argument ".concat(t, " passed to ").concat(n, " must be a `Tensor[]` or `TensorLike[]`"));
  return e.map((e, a) => convertToTensor$1(e, "".concat(t, "[").concat(a, "]"), n, r));
}

ENV$4.registerFlag("DEBUG", () => !1, e => {
  e && console.warn("Debugging mode is ON. The output of every math call will be downloaded to CPU and checked for NaNs. This significantly impacts performance.");
}), ENV$4.registerFlag("IS_BROWSER", () => isBrowser$1()), ENV$4.registerFlag("IS_NODE", () => "undefined" != typeof process && void 0 !== process.versions && void 0 !== process.versions.node), ENV$4.registerFlag("IS_CHROME", () => "undefined" != typeof navigator && null != navigator && null != navigator.userAgent && /Chrome/.test(navigator.userAgent) && /Google Inc/.test(navigator.vendor)), ENV$4.registerFlag("PROD", () => !1), ENV$4.registerFlag("TENSORLIKE_CHECK_SHAPE_CONSISTENCY", () => ENV$4.getBool("DEBUG")), ENV$4.registerFlag("DEPRECATION_WARNINGS_ENABLED", () => !0), ENV$4.registerFlag("IS_TEST", () => !1), ENV$4.registerFlag("CHECK_COMPUTATION_FOR_ERRORS", () => !0), ENV$4.registerFlag("WRAP_TO_IMAGEBITMAP", () => !1);
var OP_SCOPE_SUFFIX$1 = "__op";

function op$1(e) {
  var t = Object.keys(e);
  if (1 !== t.length) throw new Error("Please provide an object with a single key (operation name) mapping to a function. Got an object with ".concat(t.length, " keys."));
  var n = t[0];
  var r = e[n];
  n.endsWith("_") && (n = n.substring(0, n.length - 1)), n += OP_SCOPE_SUFFIX$1;

  var a = function a() {
    ENGINE$1.startScope(n);

    try {
      var _t31 = r(...arguments);

      return isPromise$1(_t31) && console.error("Cannot return a Promise inside of tidy."), ENGINE$1.endScope(_t31), _t31;
    } catch (e) {
      throw ENGINE$1.endScope(null), e;
    }
  };

  return Object.defineProperty(a, "name", {
    value: n,
    configurable: !0
  }), a;
}

function complex_$1(e, t) {
  var n = convertToTensor$1(e, "real", "complex"),
      r = convertToTensor$1(t, "imag", "complex");
  return assertShapesMatch$1(n.shape, r.shape, "real and imag shapes, ".concat(n.shape, " and ").concat(r.shape, ", must match in call to tf.complex().")), ENGINE$1.runKernel(Complex$1, {
    real: n,
    imag: r
  });
}

var complex$5 = op$1({
  complex_: complex_$1
});

function makeTensor$1(e, t, n, r) {
  if (null == r && (r = inferDtype$1(e)), "complex64" === r) throw new Error("Cannot construct a complex64 tensor directly. Please use tf.complex(real, imag).");
  if (!isTypedArray$1(e) && !Array.isArray(e) && "number" != typeof e && "boolean" != typeof e && "string" != typeof e) throw new Error("values passed to tensor(values) must be a number/boolean/string or an array of numbers/booleans/strings, or a TypedArray");

  if (null != t) {
    assertNonNegativeIntegerDimensions$1(t);

    var _e23 = sizeFromShape$1(t),
        _r8 = sizeFromShape$1(n);

    assert$6(_e23 === _r8, () => "Based on the provided shape, [".concat(t, "], the tensor should have ").concat(_e23, " values but has ").concat(_r8));

    for (var _e24 = 0; _e24 < n.length; ++_e24) {
      var _r9 = n[_e24],
          a = _e24 !== n.length - 1 || _r9 !== sizeFromShape$1(t.slice(_e24));

      assert$6(n[_e24] === t[_e24] || !a, () => "Error creating a new Tensor. Inferred shape (".concat(n, ") does not match the provided shape (").concat(t, "). "));
    }
  }

  return isTypedArray$1(e) || Array.isArray(e) || (e = [e]), t = t || n, e = "string" !== r ? toTypedArray$1(e, r) : flatten$6(e, [], !0), ENGINE$1.makeTensor(e, t, r);
}

function tensor$1(e, t, n) {
  return makeTensor$1(e, t, inferShape$1(e, n), n);
}

var DTYPE_VALUE_SIZE_MAP$1 = {
  float32: 4,
  float16: 2,
  int32: 4,
  uint16: 2,
  uint8: 1,
  bool: 1,
  complex64: 8
},
    NUM_BYTES_STRING_LENGTH$1 = 4;

function encodeWeights$1(_x, _x2) {
  return _encodeWeights$.apply(this, arguments);
}

function _encodeWeights$() {
  _encodeWeights$ = _asyncToGenerator(function* (e, t) {
    var n = [],
        r = [],
        a = Array.isArray(e) ? e.map(e => e.name) : Object.keys(e);

    var _loop60 = function _loop60(s) {
      var o = a[s],
          i = Array.isArray(e) ? e[s].tensor : e[o];
      if ("float32" !== i.dtype && "int32" !== i.dtype && "bool" !== i.dtype && "string" !== i.dtype && "complex64" !== i.dtype) throw new Error("Unsupported dtype in weight '".concat(o, "': ").concat(i.dtype));
      var l = {
        name: o,
        shape: i.shape,
        dtype: i.dtype
      };

      if ("string" === i.dtype) {
        var _e1137 = new Promise( /*#__PURE__*/function () {
          var _ref75 = _asyncToGenerator(function* (e) {
            var t = yield i.bytes(),
                n = t.reduce((e, t) => e + t.length, 0) + NUM_BYTES_STRING_LENGTH$1 * t.length,
                r = new Uint8Array(n);
            var a = 0;

            for (var _e1138 = 0; _e1138 < t.length; _e1138++) {
              var _n450 = t[_e1138],
                  _s223 = new Uint8Array(new Uint32Array([_n450.length]).buffer);

              r.set(_s223, a), a += NUM_BYTES_STRING_LENGTH$1, r.set(_n450, a), a += _n450.length;
            }

            e(r);
          });

          return function (_x145) {
            return _ref75.apply(this, arguments);
          };
        }());

        r.push(_e1137);
      } else r.push(i.data());

      null != t && (l.group = t), n.push(l);
    };

    for (var s = 0; s < a.length; ++s) {
      _loop60(s);
    }

    return {
      data: concatenateTypedArrays$1(yield Promise.all(r)),
      specs: n
    };
  });
  return _encodeWeights$.apply(this, arguments);
}

function decodeWeights$1(e, t) {
  var n = {};
  var r,
      a = 0;

  for (var s of t) {
    var _t32 = s.name,
        o = s.dtype,
        i = s.shape,
        l = sizeFromShape$1(i);
    var u = void 0;

    if ("quantization" in s) {
      var _n9 = s.quantization;

      if ("uint8" === _n9.dtype || "uint16" === _n9.dtype) {
        if (!("min" in _n9) || !("scale" in _n9)) throw new Error("Weight ".concat(s.name, " with quantization ").concat(_n9.dtype, " doesn't have corresponding metadata min and scale."));
      } else {
        if ("float16" !== _n9.dtype) throw new Error("Weight ".concat(s.name, " has unknown quantization dtype ").concat(_n9.dtype, ". Supported quantization dtypes are: 'uint8', 'uint16', and 'float16'."));
        if ("float32" !== o) throw new Error("Weight ".concat(s.name, " is quantized with ").concat(_n9.dtype, " which only supports weights of type float32 not ").concat(o, "."));
      }

      var _i2 = DTYPE_VALUE_SIZE_MAP$1[_n9.dtype],
          c = e.slice(a, a + l * _i2),
          _p = "uint8" === _n9.dtype ? new Uint8Array(c) : new Uint16Array(c);

      if ("float32" === o) {
        if ("uint8" === _n9.dtype || "uint16" === _n9.dtype) {
          u = new Float32Array(_p.length);

          for (var _e25 = 0; _e25 < _p.length; _e25++) {
            u[_e25] = _p[_e25] * _n9.scale + _n9.min;
          }
        } else {
          if ("float16" !== _n9.dtype) throw new Error("Unsupported quantization type ".concat(_n9.dtype, " for weight type float32."));
          void 0 === r && (r = getFloat16Decoder$1()), u = r(_p);
        }
      } else {
        if ("int32" !== o) throw new Error("Unsupported dtype in weight '".concat(_t32, "': ").concat(o));
        if ("uint8" !== _n9.dtype && "uint16" !== _n9.dtype) throw new Error("Unsupported quantization type ".concat(_n9.dtype, " for weight type int32."));
        u = new Int32Array(_p.length);

        for (var _e26 = 0; _e26 < _p.length; _e26++) {
          u[_e26] = Math.round(_p[_e26] * _n9.scale + _n9.min);
        }
      }
      a += l * _i2;
    } else if ("string" === o) {
      var _t33 = sizeFromShape$1(s.shape);

      u = [];

      for (var _n10 = 0; _n10 < _t33; _n10++) {
        var _t34 = new Uint32Array(e.slice(a, a + NUM_BYTES_STRING_LENGTH$1))[0];
        a += NUM_BYTES_STRING_LENGTH$1;

        var _n11 = new Uint8Array(e.slice(a, a + _t34));

        u.push(_n11), a += _t34;
      }
    } else {
      var _r10 = DTYPE_VALUE_SIZE_MAP$1[o],
          _s4 = e.slice(a, a + l * _r10);

      if ("float32" === o) u = new Float32Array(_s4);else if ("int32" === o) u = new Int32Array(_s4);else if ("bool" === o) u = new Uint8Array(_s4);else {
        if ("complex64" !== o) throw new Error("Unsupported dtype in weight '".concat(_t32, "': ").concat(o));
        {
          u = new Float32Array(_s4);

          var _e27 = new Float32Array(u.length / 2),
              _r11 = new Float32Array(u.length / 2);

          for (var _t35 = 0; _t35 < _e27.length; _t35++) {
            _e27[_t35] = u[2 * _t35], _r11[_t35] = u[2 * _t35 + 1];
          }

          var _a5 = tensor$1(_e27, i, "float32"),
              _o2 = tensor$1(_r11, i, "float32");

          n[_t32] = complex$5(_a5, _o2), _a5.dispose(), _o2.dispose();
        }
      }
      a += l * _r10;
    }

    "complex64" !== o && (n[_t32] = tensor$1(u, i, o));
  }

  return n;
}

function concatenateTypedArrays$1(e) {
  if (null === e) throw new Error("Invalid input value: ".concat(JSON.stringify(e)));
  var t = 0;
  var n = [];
  e.forEach(e => {
    if (t += e.byteLength, n.push(e.byteLength === e.buffer.byteLength ? e : new e.constructor(e)), !(e instanceof Float32Array || e instanceof Int32Array || e instanceof Uint8Array)) throw new Error("Unsupported TypedArray subtype: ".concat(e.constructor.name));
  });
  var r = new Uint8Array(t);
  var a = 0;
  return n.forEach(e => {
    r.set(new Uint8Array(e.buffer), a), a += e.byteLength;
  }), r.buffer;
}

var useNodeBuffer$1 = "undefined" != typeof Buffer && ("undefined" == typeof Blob || "undefined" == typeof atob || "undefined" == typeof btoa);

function stringByteLength$1(e) {
  return useNodeBuffer$1 ? Buffer.byteLength(e) : new Blob([e]).size;
}

function arrayBufferToBase64String$1(e) {
  if (useNodeBuffer$1) return Buffer.from(e).toString("base64");
  var t = new Uint8Array(e);
  var n = "";

  for (var _e28 = 0, r = t.length; _e28 < r; _e28++) {
    n += String.fromCharCode(t[_e28]);
  }

  return btoa(n);
}

function base64StringToArrayBuffer$1(e) {
  if (useNodeBuffer$1) {
    var _t36 = Buffer.from(e, "base64");

    return _t36.buffer.slice(_t36.byteOffset, _t36.byteOffset + _t36.byteLength);
  }

  var t = atob(e),
      n = new Uint8Array(t.length);

  for (var _e29 = 0; _e29 < t.length; ++_e29) {
    n.set([t.charCodeAt(_e29)], _e29);
  }

  return n.buffer;
}

function concatenateArrayBuffers$1(e) {
  if (1 === e.length) return e[0];
  var t = 0;
  e.forEach(e => {
    t += e.byteLength;
  });
  var n = new Uint8Array(t);
  var r = 0;
  return e.forEach(e => {
    n.set(new Uint8Array(e), r), r += e.byteLength;
  }), n.buffer;
}

function getModelJSONForModelArtifacts$1(e, t) {
  var n = {
    modelTopology: e.modelTopology,
    format: e.format,
    generatedBy: e.generatedBy,
    convertedBy: e.convertedBy,
    weightsManifest: t
  };
  return null != e.signature && (n.signature = e.signature), null != e.userDefinedMetadata && (n.userDefinedMetadata = e.userDefinedMetadata), null != e.modelInitializer && (n.modelInitializer = e.modelInitializer), null != e.trainingConfig && (n.trainingConfig = e.trainingConfig), n;
}

function getModelArtifactsForJSON$1(_x3, _x4) {
  return _getModelArtifactsForJSON$.apply(this, arguments);
}

function _getModelArtifactsForJSON$() {
  _getModelArtifactsForJSON$ = _asyncToGenerator(function* (e, t) {
    var n = {
      modelTopology: e.modelTopology,
      format: e.format,
      generatedBy: e.generatedBy,
      convertedBy: e.convertedBy
    };

    if (null != e.trainingConfig && (n.trainingConfig = e.trainingConfig), null != e.weightsManifest) {
      var [r, a] = yield t(e.weightsManifest);
      n.weightSpecs = r, n.weightData = a;
    }

    return null != e.signature && (n.signature = e.signature), null != e.userDefinedMetadata && (n.userDefinedMetadata = e.userDefinedMetadata), null != e.modelInitializer && (n.modelInitializer = e.modelInitializer), n;
  });
  return _getModelArtifactsForJSON$.apply(this, arguments);
}

function getModelArtifactsInfoForJSON$1(e) {
  if (e.modelTopology instanceof ArrayBuffer) throw new Error("Expected JSON model topology, received ArrayBuffer.");
  return {
    dateSaved: new Date(),
    modelTopologyType: "JSON",
    modelTopologyBytes: null == e.modelTopology ? 0 : stringByteLength$1(JSON.stringify(e.modelTopology)),
    weightSpecsBytes: null == e.weightSpecs ? 0 : stringByteLength$1(JSON.stringify(e.weightSpecs)),
    weightDataBytes: null == e.weightData ? 0 : e.weightData.byteLength
  };
}

function computeFloat16MantisaTable$1() {
  var e = e => {
    var t = e << 13,
        n = 0;

    for (; 0 == (8388608 & t);) {
      n -= 8388608, t <<= 1;
    }

    return t &= -8388609, n += 947912704, t | n;
  },
      t = new Uint32Array(2048);

  t[0] = 0;

  for (var n = 1; n < 1024; n++) {
    t[n] = e(n);
  }

  for (var _e30 = 1024; _e30 < 2048; _e30++) {
    t[_e30] = 939524096 + (_e30 - 1024 << 13);
  }

  return t;
}

function computeFloat16ExponentTable$1() {
  var e = new Uint32Array(64);
  e[0] = 0, e[31] = 1199570944, e[32] = 2147483648, e[63] = 3347054592;

  for (var t = 1; t < 31; t++) {
    e[t] = t << 23;
  }

  for (var _t37 = 33; _t37 < 63; _t37++) {
    e[_t37] = 2147483648 + (_t37 - 32 << 23);
  }

  return e;
}

function computeFloat16OffsetTable$1() {
  var e = new Uint32Array(64);

  for (var t = 0; t < 64; t++) {
    e[t] = 1024;
  }

  return e[0] = e[32] = 0, e;
}

function getFloat16Decoder$1() {
  var e = computeFloat16MantisaTable$1(),
      t = computeFloat16ExponentTable$1(),
      n = computeFloat16OffsetTable$1();
  return r => {
    var a = new ArrayBuffer(4 * r.length),
        s = new Uint32Array(a);

    for (var _a6 = 0; _a6 < r.length; _a6++) {
      var o = r[_a6];
      s[_a6] = e[n[o >> 10] + (1023 & o)] + t[o >> 10];
    }

    return new Float32Array(a);
  };
}

class IORouterRegistry$1 {
  constructor() {
    this.saveRouters = [], this.loadRouters = [];
  }

  static getInstance() {
    return null == IORouterRegistry$1.instance && (IORouterRegistry$1.instance = new IORouterRegistry$1()), IORouterRegistry$1.instance;
  }

  static registerSaveRouter(e) {
    IORouterRegistry$1.getInstance().saveRouters.push(e);
  }

  static registerLoadRouter(e) {
    IORouterRegistry$1.getInstance().loadRouters.push(e);
  }

  static getSaveHandlers(e) {
    return IORouterRegistry$1.getHandlers(e, "save");
  }

  static getLoadHandlers(e, t) {
    return IORouterRegistry$1.getHandlers(e, "load", t);
  }

  static getHandlers(e, t, n) {
    var r = [];
    return ("load" === t ? IORouterRegistry$1.getInstance().loadRouters : IORouterRegistry$1.getInstance().saveRouters).forEach(t => {
      var a = t(e, n);
      null !== a && r.push(a);
    }), r;
  }

}

var getSaveHandlers$1 = e => IORouterRegistry$1.getSaveHandlers(e),
    getLoadHandlers$1 = (e, t) => IORouterRegistry$1.getLoadHandlers(e, t),
    DATABASE_NAME$1 = "tensorflowjs",
    DATABASE_VERSION$1 = 1,
    MODEL_STORE_NAME$1 = "models_store",
    INFO_STORE_NAME$1 = "model_info_store";

function getIndexedDBFactory$1() {
  if (!env$1().getBool("IS_BROWSER")) throw new Error("Failed to obtain IndexedDB factory because the current environmentis not a web browser.");
  var e = "undefined" == typeof window ? self : window,
      t = e.indexedDB || e.mozIndexedDB || e.webkitIndexedDB || e.msIndexedDB || e.shimIndexedDB;
  if (null == t) throw new Error("The current browser does not appear to support IndexedDB.");
  return t;
}

function setUpDatabase$1(e) {
  var t = e.result;
  t.createObjectStore(MODEL_STORE_NAME$1, {
    keyPath: "modelPath"
  }), t.createObjectStore(INFO_STORE_NAME$1, {
    keyPath: "modelPath"
  });
}

class BrowserIndexedDB$1 {
  constructor(e) {
    if (this.indexedDB = getIndexedDBFactory$1(), null == e || !e) throw new Error("For IndexedDB, modelPath must not be null, undefined or empty.");
    this.modelPath = e;
  }

  save(e) {
    var _this11 = this;

    return _asyncToGenerator(function* () {
      if (e.modelTopology instanceof ArrayBuffer) throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");
      return _this11.databaseAction(_this11.modelPath, e);
    })();
  }

  load() {
    var _this12 = this;

    return _asyncToGenerator(function* () {
      return _this12.databaseAction(_this12.modelPath);
    })();
  }

  databaseAction(e, t) {
    return new Promise((e, n) => {
      var r = this.indexedDB.open(DATABASE_NAME$1, DATABASE_VERSION$1);
      r.onupgradeneeded = () => setUpDatabase$1(r), r.onsuccess = () => {
        var a = r.result;

        if (null == t) {
          var _t38 = a.transaction(MODEL_STORE_NAME$1, "readonly"),
              _r12 = _t38.objectStore(MODEL_STORE_NAME$1).get(this.modelPath);

          _r12.onsuccess = () => {
            if (null == _r12.result) return a.close(), n(new Error("Cannot find model with path '".concat(this.modelPath, "' in IndexedDB.")));
            e(_r12.result.modelArtifacts);
          }, _r12.onerror = e => (a.close(), n(_r12.error)), _t38.oncomplete = () => a.close();
        } else {
          var _r13 = getModelArtifactsInfoForJSON$1(t),
              s = a.transaction(INFO_STORE_NAME$1, "readwrite");

          var o = s.objectStore(INFO_STORE_NAME$1);
          var i = o.put({
            modelPath: this.modelPath,
            modelArtifactsInfo: _r13
          });
          var l;
          i.onsuccess = () => {
            l = a.transaction(MODEL_STORE_NAME$1, "readwrite");
            var i = l.objectStore(MODEL_STORE_NAME$1).put({
              modelPath: this.modelPath,
              modelArtifacts: t,
              modelArtifactsInfo: _r13
            });
            i.onsuccess = () => e({
              modelArtifactsInfo: _r13
            }), i.onerror = e => {
              o = s.objectStore(INFO_STORE_NAME$1);
              var t = o.delete(this.modelPath);
              t.onsuccess = () => (a.close(), n(i.error)), t.onerror = e => (a.close(), n(i.error));
            };
          }, i.onerror = e => (a.close(), n(i.error)), s.oncomplete = () => {
            null == l ? a.close() : l.oncomplete = () => a.close();
          };
        }
      }, r.onerror = e => n(r.error);
    });
  }

}

BrowserIndexedDB$1.URL_SCHEME = "indexeddb://";

var indexedDBRouter$1 = e => env$1().getBool("IS_BROWSER") && !Array.isArray(e) && e.startsWith(BrowserIndexedDB$1.URL_SCHEME) ? browserIndexedDB$1(e.slice(BrowserIndexedDB$1.URL_SCHEME.length)) : null;

function browserIndexedDB$1(e) {
  return new BrowserIndexedDB$1(e);
}

function maybeStripScheme$3(e) {
  return e.startsWith(BrowserIndexedDB$1.URL_SCHEME) ? e.slice(BrowserIndexedDB$1.URL_SCHEME.length) : e;
}

IORouterRegistry$1.registerSaveRouter(indexedDBRouter$1), IORouterRegistry$1.registerLoadRouter(indexedDBRouter$1);

class BrowserIndexedDBManager$1 {
  constructor() {
    this.indexedDB = getIndexedDBFactory$1();
  }

  listModels() {
    var _this13 = this;

    return _asyncToGenerator(function* () {
      return new Promise((e, t) => {
        var n = _this13.indexedDB.open(DATABASE_NAME$1, DATABASE_VERSION$1);

        n.onupgradeneeded = () => setUpDatabase$1(n), n.onsuccess = () => {
          var r = n.result,
              a = r.transaction(INFO_STORE_NAME$1, "readonly"),
              s = a.objectStore(INFO_STORE_NAME$1).getAll();
          s.onsuccess = () => {
            var t = {};

            for (var _e31 of s.result) {
              t[_e31.modelPath] = _e31.modelArtifactsInfo;
            }

            e(t);
          }, s.onerror = e => (r.close(), t(s.error)), a.oncomplete = () => r.close();
        }, n.onerror = e => t(n.error);
      });
    })();
  }

  removeModel(e) {
    var _this14 = this;

    return _asyncToGenerator(function* () {
      return e = maybeStripScheme$3(e), new Promise((t, n) => {
        var r = _this14.indexedDB.open(DATABASE_NAME$1, DATABASE_VERSION$1);

        r.onupgradeneeded = () => setUpDatabase$1(r), r.onsuccess = () => {
          var a = r.result,
              s = a.transaction(INFO_STORE_NAME$1, "readwrite"),
              o = s.objectStore(INFO_STORE_NAME$1),
              i = o.get(e);
          var l;
          i.onsuccess = () => {
            if (null == i.result) return a.close(), n(new Error("Cannot find model with path '".concat(e, "' in IndexedDB.")));
            {
              var _r14 = o.delete(e),
                  _s5 = () => {
                l = a.transaction(MODEL_STORE_NAME$1, "readwrite");
                var r = l.objectStore(MODEL_STORE_NAME$1).delete(e);
                r.onsuccess = () => t(i.result.modelArtifactsInfo), r.onerror = e => n(i.error);
              };

              _r14.onsuccess = _s5, _r14.onerror = e => (_s5(), a.close(), n(i.error));
            }
          }, i.onerror = e => (a.close(), n(i.error)), s.oncomplete = () => {
            null == l ? a.close() : l.oncomplete = () => a.close();
          };
        }, r.onerror = e => n(r.error);
      });
    })();
  }

}

var PATH_SEPARATOR$1 = "/",
    PATH_PREFIX$1 = "tensorflowjs_models",
    INFO_SUFFIX$1 = "info",
    MODEL_TOPOLOGY_SUFFIX$1 = "model_topology",
    WEIGHT_SPECS_SUFFIX$1 = "weight_specs",
    WEIGHT_DATA_SUFFIX$1 = "weight_data",
    MODEL_METADATA_SUFFIX$1 = "model_metadata";

function getModelKeys$1(e) {
  return {
    info: [PATH_PREFIX$1, e, INFO_SUFFIX$1].join(PATH_SEPARATOR$1),
    topology: [PATH_PREFIX$1, e, MODEL_TOPOLOGY_SUFFIX$1].join(PATH_SEPARATOR$1),
    weightSpecs: [PATH_PREFIX$1, e, WEIGHT_SPECS_SUFFIX$1].join(PATH_SEPARATOR$1),
    weightData: [PATH_PREFIX$1, e, WEIGHT_DATA_SUFFIX$1].join(PATH_SEPARATOR$1),
    modelMetadata: [PATH_PREFIX$1, e, MODEL_METADATA_SUFFIX$1].join(PATH_SEPARATOR$1)
  };
}

function removeItems$1(e) {
  for (var t of Object.values(e)) {
    window.localStorage.removeItem(t);
  }
}

function getModelPathFromKey$1(e) {
  var t = e.split(PATH_SEPARATOR$1);
  if (t.length < 3) throw new Error("Invalid key format: ".concat(e));
  return t.slice(1, t.length - 1).join(PATH_SEPARATOR$1);
}

function maybeStripScheme$2(e) {
  return e.startsWith(BrowserLocalStorage$1.URL_SCHEME) ? e.slice(BrowserLocalStorage$1.URL_SCHEME.length) : e;
}

class BrowserLocalStorage$1 {
  constructor(e) {
    if (!env$1().getBool("IS_BROWSER") || "undefined" == typeof window || void 0 === window.localStorage) throw new Error("The current environment does not support local storage.");
    if (this.LS = window.localStorage, null == e || !e) throw new Error("For local storage, modelPath must not be null, undefined or empty.");
    this.modelPath = e, this.keys = getModelKeys$1(this.modelPath);
  }

  save(e) {
    var _this15 = this;

    return _asyncToGenerator(function* () {
      if (e.modelTopology instanceof ArrayBuffer) throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");
      {
        var t = JSON.stringify(e.modelTopology),
            n = JSON.stringify(e.weightSpecs),
            r = getModelArtifactsInfoForJSON$1(e);

        try {
          return _this15.LS.setItem(_this15.keys.info, JSON.stringify(r)), _this15.LS.setItem(_this15.keys.topology, t), _this15.LS.setItem(_this15.keys.weightSpecs, n), _this15.LS.setItem(_this15.keys.weightData, arrayBufferToBase64String$1(e.weightData)), _this15.LS.setItem(_this15.keys.modelMetadata, JSON.stringify({
            format: e.format,
            generatedBy: e.generatedBy,
            convertedBy: e.convertedBy,
            signature: null != e.signature ? e.signature : void 0,
            userDefinedMetadata: null != e.userDefinedMetadata ? e.userDefinedMetadata : void 0,
            modelInitializer: null != e.modelInitializer ? e.modelInitializer : void 0,
            trainingConfig: null != e.trainingConfig ? e.trainingConfig : void 0
          })), {
            modelArtifactsInfo: r
          };
        } catch (e) {
          throw removeItems$1(_this15.keys), new Error("Failed to save model '".concat(_this15.modelPath, "' to local storage: size quota being exceeded is a possible cause of this failure: modelTopologyBytes=").concat(r.modelTopologyBytes, ", weightSpecsBytes=").concat(r.weightSpecsBytes, ", weightDataBytes=").concat(r.weightDataBytes, "."));
        }
      }
    })();
  }

  load() {
    var _this16 = this;

    return _asyncToGenerator(function* () {
      var e = JSON.parse(_this16.LS.getItem(_this16.keys.info));
      if (null == e) throw new Error("In local storage, there is no model with name '".concat(_this16.modelPath, "'"));
      if ("JSON" !== e.modelTopologyType) throw new Error("BrowserLocalStorage does not support loading non-JSON model topology yet.");
      var t = {},
          n = JSON.parse(_this16.LS.getItem(_this16.keys.topology));
      if (null == n) throw new Error("In local storage, the topology of model '".concat(_this16.modelPath, "' is missing."));
      t.modelTopology = n;
      var r = JSON.parse(_this16.LS.getItem(_this16.keys.weightSpecs));
      if (null == r) throw new Error("In local storage, the weight specs of model '".concat(_this16.modelPath, "' are missing."));
      t.weightSpecs = r;

      var a = _this16.LS.getItem(_this16.keys.modelMetadata);

      if (null != a) {
        var _e32 = JSON.parse(a);

        t.format = _e32.format, t.generatedBy = _e32.generatedBy, t.convertedBy = _e32.convertedBy, null != _e32.signature && (t.signature = _e32.signature), null != _e32.userDefinedMetadata && (t.userDefinedMetadata = _e32.userDefinedMetadata), null != _e32.modelInitializer && (t.modelInitializer = _e32.modelInitializer), null != _e32.trainingConfig && (t.trainingConfig = _e32.trainingConfig);
      }

      var s = _this16.LS.getItem(_this16.keys.weightData);

      if (null == s) throw new Error("In local storage, the binary weight values of model '".concat(_this16.modelPath, "' are missing."));
      return t.weightData = base64StringToArrayBuffer$1(s), t;
    })();
  }

}

BrowserLocalStorage$1.URL_SCHEME = "localstorage://";

var localStorageRouter$1 = e => env$1().getBool("IS_BROWSER") && !Array.isArray(e) && e.startsWith(BrowserLocalStorage$1.URL_SCHEME) ? browserLocalStorage$1(e.slice(BrowserLocalStorage$1.URL_SCHEME.length)) : null;

function browserLocalStorage$1(e) {
  return new BrowserLocalStorage$1(e);
}

IORouterRegistry$1.registerSaveRouter(localStorageRouter$1), IORouterRegistry$1.registerLoadRouter(localStorageRouter$1);

class BrowserLocalStorageManager$1 {
  constructor() {
    assert$6(env$1().getBool("IS_BROWSER"), () => "Current environment is not a web browser"), assert$6("undefined" == typeof window || void 0 !== window.localStorage, () => "Current browser does not appear to support localStorage"), this.LS = window.localStorage;
  }

  listModels() {
    var _this17 = this;

    return _asyncToGenerator(function* () {
      var e = {},
          t = PATH_PREFIX$1 + PATH_SEPARATOR$1,
          n = PATH_SEPARATOR$1 + INFO_SUFFIX$1;

      for (var r = 0; r < _this17.LS.length; ++r) {
        var a = _this17.LS.key(r);

        a.startsWith(t) && a.endsWith(n) && (e[getModelPathFromKey$1(a)] = JSON.parse(_this17.LS.getItem(a)));
      }

      return e;
    })();
  }

  removeModel(e) {
    var _this18 = this;

    return _asyncToGenerator(function* () {
      var t = getModelKeys$1(e = maybeStripScheme$2(e));
      if (null == _this18.LS.getItem(t.info)) throw new Error("Cannot find model at path '".concat(e, "'"));
      var n = JSON.parse(_this18.LS.getItem(t.info));
      return removeItems$1(t), n;
    })();
  }

}

var URL_SCHEME_SUFFIX$1 = "://";

class ModelStoreManagerRegistry$1 {
  constructor() {
    this.managers = {};
  }

  static getInstance() {
    return null == ModelStoreManagerRegistry$1.instance && (ModelStoreManagerRegistry$1.instance = new ModelStoreManagerRegistry$1()), ModelStoreManagerRegistry$1.instance;
  }

  static registerManager(e, t) {
    assert$6(null != e, () => "scheme must not be undefined or null."), e.endsWith(URL_SCHEME_SUFFIX$1) && (e = e.slice(0, e.indexOf(URL_SCHEME_SUFFIX$1))), assert$6(e.length > 0, () => "scheme must not be an empty string.");
    var n = ModelStoreManagerRegistry$1.getInstance();
    assert$6(null == n.managers[e], () => "A model store manager is already registered for scheme '".concat(e, "'.")), n.managers[e] = t;
  }

  static getManager(e) {
    var t = this.getInstance().managers[e];
    if (null == t) throw new Error("Cannot find model manager for scheme '".concat(e, "'"));
    return t;
  }

  static getSchemes() {
    return Object.keys(this.getInstance().managers);
  }

}

class PlatformBrowser$1 {
  fetch(e, t) {
    return fetch(e, t);
  }

  now() {
    return performance.now();
  }

  encode(e, t) {
    if ("utf-8" !== t && "utf8" !== t) throw new Error("Browser's encoder only supports utf-8, but got ".concat(t));
    return null == this.textEncoder && (this.textEncoder = new TextEncoder()), this.textEncoder.encode(e);
  }

  decode(e, t) {
    return new TextDecoder(t).decode(e);
  }

}

if (env$1().get("IS_BROWSER")) {
  env$1().setPlatform("browser", new PlatformBrowser$1());

  try {
    ModelStoreManagerRegistry$1.registerManager(BrowserLocalStorage$1.URL_SCHEME, new BrowserLocalStorageManager$1());
  } catch (e) {}

  try {
    ModelStoreManagerRegistry$1.registerManager(BrowserIndexedDB$1.URL_SCHEME, new BrowserIndexedDBManager$1());
  } catch (e) {}
}

var getNodeFetch$1 = {
  importFetch: () => __webpack_require__(76474)
};
var systemFetch$1;

class PlatformNode$1 {
  constructor() {
    this.util = __webpack_require__(15895), this.textEncoder = new this.util.TextEncoder();
  }

  fetch(e, t) {
    return null != env$1().global.fetch ? env$1().global.fetch(e, t) : (null == systemFetch$1 && (systemFetch$1 = getNodeFetch$1.importFetch()), systemFetch$1(e, t));
  }

  now() {
    var e = process.hrtime();
    return 1e3 * e[0] + e[1] / 1e6;
  }

  encode(e, t) {
    if ("utf-8" !== t && "utf8" !== t) throw new Error("Node built-in encoder only supports utf-8, but got ".concat(t));
    return this.textEncoder.encode(e);
  }

  decode(e, t) {
    return 0 === e.length ? "" : new this.util.TextDecoder(t).decode(e);
  }

}

function buffer$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : "float32";
  var n = arguments.length > 2 ? arguments[2] : undefined;
  return t = t || "float32", assertNonNegativeIntegerDimensions$1(e), new TensorBuffer$1(e, t, n);
}

function cast_$1(e, t) {
  var n = convertToTensor$1(e, "x", "cast");
  if (!isValidDtype$1(t)) throw new Error("Failed to cast to unknown dtype ".concat(t));
  if ("string" === t && "string" !== n.dtype || "string" !== t && "string" === n.dtype) throw new Error("Only strings can be casted to strings");
  return ENGINE$1.runKernel(Cast$1, {
    x: n
  }, {
    dtype: t
  });
}

env$1().get("IS_NODE") && env$1().setPlatform("node", new PlatformNode$1());
var cast$7 = op$1({
  cast_: cast_$1
});

function clone_$1(e) {
  var t = convertToTensor$1(e, "x", "clone", "string_or_numeric");
  return ENGINE$1.runKernel(Identity$3, {
    x: t
  });
}

var clone$1 = op$1({
  clone_: clone_$1
});

function print$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;
  console.log(e.toString(t));
}

getOrMakeEngine$1();
var opHandler$2 = {
  buffer: buffer$1,
  cast: cast$7,
  clone: clone$1,
  print: print$1
};
setOpHandler$1(opHandler$2);
var DEFAULT_FILE_NAME_PREFIX$1 = "model",
    DEFAULT_JSON_EXTENSION_NAME$1 = ".json",
    DEFAULT_WEIGHT_DATA_EXTENSION_NAME$1 = ".weights.bin";

function defer$1(e) {
  return new Promise(e => setTimeout(e)).then(e);
}

class BrowserDownloads$1 {
  constructor(e) {
    if (!env$1().getBool("IS_BROWSER")) throw new Error("browserDownloads() cannot proceed because the current environment is not a browser.");
    e.startsWith(BrowserDownloads$1.URL_SCHEME) && (e = e.slice(BrowserDownloads$1.URL_SCHEME.length)), null != e && 0 !== e.length || (e = DEFAULT_FILE_NAME_PREFIX$1), this.modelJsonFileName = e + DEFAULT_JSON_EXTENSION_NAME$1, this.weightDataFileName = e + DEFAULT_WEIGHT_DATA_EXTENSION_NAME$1;
  }

  save(e) {
    var _this19 = this;

    return _asyncToGenerator(function* () {
      if ("undefined" == typeof document) throw new Error("Browser downloads are not supported in this environment since `document` is not present");
      var t = window.URL.createObjectURL(new Blob([e.weightData], {
        type: "application/octet-stream"
      }));
      if (e.modelTopology instanceof ArrayBuffer) throw new Error("BrowserDownloads.save() does not support saving model topology in binary formats yet.");
      {
        var n = getModelJSONForModelArtifacts$1(e, [{
          paths: ["./" + _this19.weightDataFileName],
          weights: e.weightSpecs
        }]),
            r = window.URL.createObjectURL(new Blob([JSON.stringify(n)], {
          type: "application/json"
        })),
            a = null == _this19.modelJsonAnchor ? document.createElement("a") : _this19.modelJsonAnchor;

        if (a.download = _this19.modelJsonFileName, a.href = r, yield defer$1(() => a.dispatchEvent(new MouseEvent("click"))), null != e.weightData) {
          var _e33 = null == _this19.weightDataAnchor ? document.createElement("a") : _this19.weightDataAnchor;

          _e33.download = _this19.weightDataFileName, _e33.href = t, yield defer$1(() => _e33.dispatchEvent(new MouseEvent("click")));
        }

        return {
          modelArtifactsInfo: getModelArtifactsInfoForJSON$1(e)
        };
      }
    })();
  }

}

BrowserDownloads$1.URL_SCHEME = "downloads://";

var browserDownloadsRouter$1 = e => env$1().getBool("IS_BROWSER") && !Array.isArray(e) && e.startsWith(BrowserDownloads$1.URL_SCHEME) ? browserDownloads$1(e.slice(BrowserDownloads$1.URL_SCHEME.length)) : null;

function browserDownloads$1() {
  var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : "model";
  return new BrowserDownloads$1(e);
}

function monitorPromisesProgress$1(e, t, n, r) {
  !function (e) {
    assert$6(null != e && Array.isArray(e) && e.length > 0, () => "promises must be a none empty array");
  }(e), function (e, t) {
    assert$6(e >= 0 && e <= 1, () => "Progress fraction must be in range [0, 1], but got startFraction ".concat(e)), assert$6(t >= 0 && t <= 1, () => "Progress fraction must be in range [0, 1], but got endFraction ".concat(t)), assert$6(t >= e, () => "startFraction must be no more than endFraction, but got startFraction ".concat(e, " and endFraction ").concat(t));
  }(n = null == n ? 0 : n, r = null == r ? 1 : r);
  var a = 0;
  return Promise.all(e.map(s => (s.then(s => {
    var o = n + ++a / e.length * (r - n);
    return t(o), s;
  }), s)));
}

function loadWeightsAsArrayBuffer$1(_x5, _x6) {
  return _loadWeightsAsArrayBuffer$.apply(this, arguments);
}

function _loadWeightsAsArrayBuffer$() {
  _loadWeightsAsArrayBuffer$ = _asyncToGenerator(function* (e, t) {
    null == t && (t = {});
    var n = null == t.fetchFunc ? env$1().platform.fetch : t.fetchFunc,
        r = e.map(e => n(e, t.requestInit, {
      isBinary: !0
    })),
        a = (null == t.onProgress ? yield Promise.all(r) : yield monitorPromisesProgress$1(r, t.onProgress, 0, .5)).map(e => e.arrayBuffer());
    return null == t.onProgress ? yield Promise.all(a) : yield monitorPromisesProgress$1(a, t.onProgress, .5, 1);
  });
  return _loadWeightsAsArrayBuffer$.apply(this, arguments);
}

IORouterRegistry$1.registerSaveRouter(browserDownloadsRouter$1);
var OCTET_STREAM_MIME_TYPE$1 = "application/octet-stream",
    JSON_TYPE$1 = "application/json";

class HTTPRequest$1 {
  constructor(e, t) {
    if (this.DEFAULT_METHOD = "POST", null == t && (t = {}), this.weightPathPrefix = t.weightPathPrefix, this.onProgress = t.onProgress, this.weightUrlConverter = t.weightUrlConverter, null != t.fetchFunc ? (assert$6("function" == typeof t.fetchFunc, () => "Must pass a function that matches the signature of `fetch` (see https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API)"), this.fetch = t.fetchFunc) : this.fetch = env$1().platform.fetch, assert$6(null != e && e.length > 0, () => "URL path for http must not be null, undefined or empty."), Array.isArray(e) && assert$6(2 === e.length, () => "URL paths for http must have a length of 2, (actual length is ".concat(e.length, ").")), this.path = e, null != t.requestInit && null != t.requestInit.body) throw new Error("requestInit is expected to have no pre-existing body, but has one.");
    this.requestInit = t.requestInit || {};
  }

  save(e) {
    var _this20 = this;

    return _asyncToGenerator(function* () {
      if (e.modelTopology instanceof ArrayBuffer) throw new Error("BrowserHTTPRequest.save() does not support saving model topology in binary formats yet.");
      var t = Object.assign({
        method: _this20.DEFAULT_METHOD
      }, _this20.requestInit);
      t.body = new FormData();
      var n = getModelJSONForModelArtifacts$1(e, [{
        paths: ["./model.weights.bin"],
        weights: e.weightSpecs
      }]);
      t.body.append("model.json", new Blob([JSON.stringify(n)], {
        type: JSON_TYPE$1
      }), "model.json"), null != e.weightData && t.body.append("model.weights.bin", new Blob([e.weightData], {
        type: OCTET_STREAM_MIME_TYPE$1
      }), "model.weights.bin");
      var r = yield _this20.fetch(_this20.path, t);
      if (r.ok) return {
        modelArtifactsInfo: getModelArtifactsInfoForJSON$1(e),
        responses: [r]
      };
      throw new Error("BrowserHTTPRequest.save() failed due to HTTP response status ".concat(r.status, "."));
    })();
  }

  load() {
    var _this21 = this;

    return _asyncToGenerator(function* () {
      var e = yield _this21.fetch(_this21.path, _this21.requestInit);
      if (!e.ok) throw new Error("Request to ".concat(_this21.path, " failed with status code ").concat(e.status, ". Please verify this URL points to the model JSON of the model to load."));
      var t;

      try {
        t = yield e.json();
      } catch (e) {
        var _t39 = "Failed to parse model JSON of response from ".concat(_this21.path, ".");

        throw _this21.path.endsWith(".pb") ? _t39 += " Your path contains a .pb file extension. Support for .pb models have been removed in TensorFlow.js 1.0 in favor of .json models. You can re-convert your Python TensorFlow model using the TensorFlow.js 1.0 conversion scripts or you can convert your.pb models with the 'pb2json'NPM script in the tensorflow/tfjs-converter repository." : _t39 += " Please make sure the server is serving valid JSON for this request.", new Error(_t39);
      }

      if (null == t.modelTopology && null == t.weightsManifest) throw new Error("The JSON from HTTP path ".concat(_this21.path, " contains neither model topology or manifest for weights."));
      return getModelArtifactsForJSON$1(t, e => _this21.loadWeights(e));
    })();
  }

  loadWeights(e) {
    var _this22 = this;

    return _asyncToGenerator(function* () {
      var t = Array.isArray(_this22.path) ? _this22.path[1] : _this22.path,
          [n, r] = parseUrl$1(t),
          a = _this22.weightPathPrefix || n,
          s = [];

      for (var _t40 of e) {
        s.push(..._t40.weights);
      }

      var o = [],
          i = [];

      for (var _t41 of e) {
        for (var _e34 of _t41.paths) {
          null != _this22.weightUrlConverter ? i.push(_this22.weightUrlConverter(_e34)) : o.push(a + _e34 + r);
        }
      }

      return _this22.weightUrlConverter && o.push(...(yield Promise.all(i))), [s, concatenateArrayBuffers$1(yield loadWeightsAsArrayBuffer$1(o, {
        requestInit: _this22.requestInit,
        fetchFunc: _this22.fetch,
        onProgress: _this22.onProgress
      }))];
    })();
  }

}

function parseUrl$1(e) {
  var t = e.lastIndexOf("/"),
      n = e.lastIndexOf("?");
  return [e.substring(0, t) + "/", n > t ? e.substring(n) : ""];
}

function isHTTPScheme$1(e) {
  return null != e.match(HTTPRequest$1.URL_SCHEME_REGEX);
}

HTTPRequest$1.URL_SCHEME_REGEX = /^https?:\/\//;

var httpRouter$1 = (e, t) => {
  if ("undefined" == typeof fetch && (null == t || null == t.fetchFunc)) return null;
  {
    var n = !0;
    if (n = Array.isArray(e) ? e.every(e => isHTTPScheme$1(e)) : isHTTPScheme$1(e), n) return http$1(e, t);
  }
  return null;
};

function http$1(e, t) {
  return new HTTPRequest$1(e, t);
}

function browserHTTPRequest$1(e, t) {
  return http$1(e, t);
}

function matMul_$1(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
  var a = convertToTensor$1(e, "a", "matMul"),
      s = convertToTensor$1(t, "b", "matMul");
  return [a, s] = makeTypesMatch$1(a, s), ENGINE$1.runKernel(BatchMatMul$1, {
    a,
    b: s
  }, {
    transposeA: n,
    transposeB: r
  });
}

IORouterRegistry$1.registerSaveRouter(httpRouter$1), IORouterRegistry$1.registerLoadRouter(httpRouter$1);
var matMul$3 = op$1({
  matMul_: matMul_$1
});

function oneHot_$1(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 1;
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 0;
  if (t < 2) throw new Error("Error in oneHot: depth must be >=2, but it is ".concat(t));
  var a = convertToTensor$1(e, "indices", "oneHot", "int32");
  return ENGINE$1.runKernel(OneHot$1, {
    indices: a
  }, {
    depth: t,
    onValue: n,
    offValue: r
  });
}

var oneHot$5 = op$1({
  oneHot_: oneHot_$1
});

function transpose_$1(e, t) {
  var n = convertToTensor$1(e, "x", "transpose");
  return null == t && (t = n.shape.map((e, t) => t).reverse()), assert$6(n.rank === t.length, () => "Error in transpose: rank of input ".concat(n.rank, " must match length of perm ").concat(t, ".")), t.forEach(e => {
    assert$6(e >= 0 && e < n.rank, () => "All entries in 'perm' must be between 0 and " + (n.rank - 1) + " but got ".concat(t));
  }), n.rank <= 1 ? n.clone() : ENGINE$1.runKernel(Transpose$1, {
    x: n
  }, {
    perm: t
  });
}

var transpose$5 = op$1({
  transpose_: transpose_$1
});

function tensor3d$1(e, t, n) {
  if (assertNonNull$1(e), null != t && 3 !== t.length) throw new Error("tensor3d() requires shape to have three numbers");
  var r = inferShape$1(e, n);
  if (3 !== r.length && 1 !== r.length) throw new Error("tensor3d() requires values to be number[][][] or flat/TypedArray");
  if (1 === r.length && null == t) throw new Error("tensor3d() requires shape to be provided when `values` are a flat array");
  return makeTensor$1(e, t, r, n);
}

function prepareAndValidate$1(e, t) {
  var n = e.shape.length,
      r = t.shape.length;
  if (n < 1) throw new Error("tf.gatherND() expects the input to be rank 1 or higher, but the rank was ".concat(n, "."));
  if (r < 1) throw new Error("tf.gatherND() expects the indices to be rank 1 or higher, but the rank was ".concat(r, "."));
  if ("int32" !== t.dtype) throw new Error("tf.gatherND() expects the indices to be int32 type, but the dtype was ".concat(t.dtype, "."));
  if (t.shape[r - 1] > n) throw new Error("index innermost dimension length must be <= tensor rank; saw: ".concat(t.shape[r - 1], " vs. ").concat(n));
  if (0 === sizeFromShape$1(e.shape)) throw new Error("Requested more than 0 entries, but input is empty. Input shape: ".concat(e.shape, "."));
  var a = t.shape,
      s = a[a.length - 1];
  var o = 1;

  for (var _e35 = 0; _e35 < a.length - 1; ++_e35) {
    o *= a[_e35];
  }

  var i = e.shape,
      l = a.slice();
  l.pop();
  var u = 1;

  for (var _e36 = s; _e36 < n; ++_e36) {
    u *= i[_e36], l.push(i[_e36]);
  }

  var c = [...computeStrides$1(e.shape).map(e => e / u), 1].slice(0, s);
  return [l, o, u, c];
}

function validateUpdateShape$1(e, t, n) {
  var r = t.rank > 1 ? t.shape[t.rank - 1] : 1,
      a = t.rank > 1 ? t.rank - 1 : 1,
      s = "Must have updates.shape = indices.shape[:batchDim] + shape[sliceDim:], got updates.shape: ".concat(n.shape, ", indices.shape: ").concat(t.shape, ", shape: ").concat(e, ", sliceDim: ").concat(r, ", and batchDim: ").concat(a, ".");
  if (n.rank < a) throw new Error(s + " update.rank < ".concat(a, ". "));
  if (e.length < r + (n.rank - a)) throw new Error(s + " Output shape length < ".concat(r + (n.rank - a)));
  if (n.rank !== a + e.length - r) throw new Error(s + " update.rank != " + (a + e.length - r));

  for (var _e37 = 0; _e37 < a; ++_e37) {
    if (n.shape[_e37] !== t.shape[_e37]) throw new Error(s + " updates.shape[".concat(_e37, "] (").concat(n.shape[_e37], ") != indices.shape[").concat(_e37, "] (").concat(t.shape[_e37], ")."));
  }

  for (var _t42 = 0; _t42 < n.rank - a; ++_t42) {
    if (n.shape[_t42 + a] !== e[_t42 + r]) throw new Error(s + " updates.shape[".concat(_t42 + a, "] (").concat(n.shape[_t42 + a], ") != shape[").concat(_t42 + a, "] (").concat(e[_t42 + a], ")"));
  }
}

function validateInput$2(e, t, n) {
  if (t.rank < 1) throw new Error("tf.scatterND() expects the indices to be rank 1 or higher, but the rank was ".concat(t.rank, "."));
  if (e.rank < 1) throw new Error("tf.scatterND() expects the updates to be rank 1 or higher, but the rank was ".concat(e.rank, "."));
  if ("int32" !== t.dtype) throw new Error("The dtype of 'indices' should be int32, but got dtype: ".concat(t.dtype));
  if (n.length < 1) throw new Error("Output rank must be greater or equal to 1, but got shape: ".concat(n));

  if (0 === n.length) {
    if (0 === t.size) throw new Error("Indices specified for empty output. indices shape: ".concat(t.shape));
    if (0 === e.size) throw new Error("Updates specified for empty output. updates shape: ".concat(e.shape));
  }

  validateUpdateShape$1(n, t, e);
}

function calculateShapes$1(e, t, n) {
  var r = t.shape.length,
      a = r > 1 ? t.shape[r - 1] : 1,
      s = n.length;
  var o = 1;

  for (var _e38 = a; _e38 < s; ++_e38) {
    o *= n[_e38];
  }

  var i = a < 1 ? 1 : a;
  return {
    sliceRank: a,
    numUpdates: sizeFromShape$1(t.shape) / i,
    sliceSize: o,
    strides: [...computeStrides$1(n.slice(0, a)), 1],
    outputSize: sizeFromShape$1(n)
  };
}

function assertParamsValid$1(e, t, n) {
  var r = e.shape.length;
  assert$6(r === t.length, () => "Error in slice".concat(r, "D: Length of begin ").concat(t, " must match the rank of the array (").concat(r, ").")), assert$6(r === n.length, () => "Error in slice".concat(r, "D: Length of size ").concat(n, " must match the rank of the array (").concat(r, ")."));

  var _loop4 = function _loop4(a) {
    assert$6(t[a] + n[a] <= e.shape[a], () => "Error in slice".concat(r, "D: begin[").concat(a, "] + size[").concat(a, "] (").concat(t[a] + n[a], ") would overflow input.shape[").concat(a, "] (").concat(e.shape[a], ")"));
  };

  for (var a = 0; a < r; ++a) {
    _loop4(a);
  }
}

function maskToAxes$1(e) {
  var t = [];
  var n = 0;

  for (; e > 0;) {
    1 & e && t.push(n), e /= 2, n++;
  }

  return t;
}

function computeOutShape$5(e, t, n) {
  var r = [];

  for (var a = 0; a < e.length; a++) {
    r[a] = Math.ceil((t[a] - e[a]) / n[a]);
  }

  return r;
}

function stridesWithElidedDims$1(e, t, n, r) {
  var a = [...e];

  for (var _e39 = a.length; _e39 < r.length; _e39++) {
    a.push(1);
  }

  for (var _e40 = 0; _e40 < n; _e40++) {
    0 === _e40 ? a[t] = 1 : (a.splice(t, 0, 1), a.pop());
  }

  return a;
}

function unnormalizeAxis$1(e, t, n) {
  return n <= e ? n : n - (t - 1);
}

function getElidedAxes$1(e, t) {
  var n = [];

  for (var r = 0; r < e; r++) {
    n.push(t + r);
  }

  return n;
}

function getNormalizedAxes$1(e, t, n, r, a, s, o, i, l) {
  var u = e.length;
  var c = new Array(u),
      p = new Array(u),
      d = new Array(u);

  if (t.length && n > 0) {
    var _l2 = t[0],
        _u = n + 1;

    c = startIndicesWithElidedDims$1(o, _l2, _u, r, e), p = stopIndicesWithElidedDims$1(i, _l2, _u, a, e), d = stridesWithElidedDims$1(s, _l2, _u, e);
  } else for (var _t43 = 0; _t43 < u; _t43++) {
    c[_t43] = startForAxis$1(o, r, s, e, _t43, l), p[_t43] = stopForAxis$1(i, a, s, e, _t43, l), d[_t43] = stridesForAxis$1(s, _t43, l);
  }

  return {
    begin: c,
    end: p,
    strides: d
  };
}

function startIndicesWithElidedDims$1(e, t, n, r, a) {
  var s = [...a],
      o = getElidedAxes$1(n, t);

  for (var _a7 = 0; _a7 < s.length; _a7++) {
    if (o.indexOf(_a7) > -1) s[_a7] = 0;else {
      var _o3 = unnormalizeAxis$1(t, n, _a7);

      var i = r[_o3];
      e & 1 << _o3 && (i = 0), s[_a7] = i;
    }
  }

  return s;
}

function stopIndicesWithElidedDims$1(e, t, n, r, a) {
  var s = [...a],
      o = getElidedAxes$1(n, t);

  for (var _a8 = 0; _a8 < s.length; _a8++) {
    if (o.indexOf(_a8) > -1) s[_a8] = Number.MAX_SAFE_INTEGER;else {
      var _o4 = unnormalizeAxis$1(t, n, _a8);

      var i = r[_o4];
      e & 1 << _o4 && (i = Number.MAX_SAFE_INTEGER), s[_a8] = i;
    }
  }

  for (var _e41 = 0; _e41 < s.length; _e41++) {
    var _t44 = a[_e41];
    s[_e41] < 0 && (s[_e41] += _t44), s[_e41] = clamp$1(0, s[_e41], a[_e41]);
  }

  return s;
}

function stridesForAxis$1(e, t, n) {
  var r = e[t];
  return (n & 1 << t || null == r) && (r = 1), r;
}

function startForAxis$1(e, t, n, r, a, s) {
  var o = t[a];
  (e & 1 << a || s & 1 << a || null == o) && (o = (n[a] || 1) > 0 ? Number.MIN_SAFE_INTEGER : Number.MAX_SAFE_INTEGER);
  var i = r[a];
  return o < 0 && (o += i), o = clamp$1(0, o, i - 1), o;
}

function stopForAxis$1(e, t, n, r, a, s) {
  var o = t[a];
  var i = n[a] || 1;
  (e & 1 << a || s & 1 << a || null == o) && (o = i > 0 ? Number.MAX_SAFE_INTEGER : Number.MIN_SAFE_INTEGER);
  var l = r[a];
  return o < 0 && (o += l), o = i > 0 ? clamp$1(0, o, l) : clamp$1(-1, o, l - 1), o;
}

function isSliceContinous$1(e, t, n) {
  var r = n.length;

  for (var _e42 = 0; _e42 < n.length; _e42++) {
    if (n[_e42] > 1) {
      r = _e42;
      break;
    }
  }

  for (var a = r + 1; a < n.length; a++) {
    if (t[a] > 0 || n[a] !== e[a]) return !1;
  }

  return !0;
}

function computeFlatOffset$1(e, t) {
  var n = e.length > 0 ? e[e.length - 1] : 1;

  for (var r = 0; r < e.length - 1; r++) {
    n += e[r] * t[r];
  }

  return n;
}

function parseSliceParams$1(e, t, n) {
  var r;
  var a = e.shape.length;
  var s;
  return r = "number" == typeof t ? [t, ...new Array(a - 1).fill(0)] : t.length < a ? t.concat(new Array(a - t.length).fill(0)) : t.slice(), r.forEach(e => {
    assert$6(-1 !== e, () => "slice() does not support negative begin indexing.");
  }), s = null == n ? new Array(a).fill(-1) : "number" == typeof n ? [n, ...new Array(a - 1).fill(-1)] : n.length < a ? n.concat(new Array(a - n.length).fill(-1)) : n, s = s.map((t, n) => t >= 0 ? t : (assert$6(-1 === t, () => "Negative size values should be exactly -1 but got ".concat(t, " for the slice() size at index ").concat(n, ".")), e.shape[n] - r[n])), [r, s];
}

function sliceInfo$1(e, t, n, r, a, s, o, i, l) {
  var u = t.slice(),
      c = n.slice(),
      p = r;
  null == r && (p = new Array(u.length));
  var d = maskToAxes$1(o);
  if (d.length > 1) throw new Error("Multiple ellipses in slice is not allowed.");
  if (0 !== o && 0 !== i) throw new Error("Using both ellipsisMask and newAxisMask is not yet supported.");
  if (0 !== o && 0 !== l) throw new Error("Using both ellipsisMask and shrinkAxisMask is not yet supported.");
  var h = e.length - u.length,
      m = maskToAxes$1(i),
      f = e.slice();
  m.forEach(e => {
    u[e] = 0, c[e] = 1, f.splice(e, 0, 1);
  });
  var {
    begin: g,
    end: $,
    strides: y
  } = getNormalizedAxes$1(f, d, h, u, c, p, a, s, o);
  u = g, c = $, p = y;
  var b = maskToAxes$1(l);
  b.forEach(e => {
    c[e] = u[e] + 1, p[e] = 1;
  });
  var x = computeOutShape$5(u, c, p),
      v = x.filter((e, t) => -1 === b.indexOf(t));
  return {
    nonStrided: p.every(e => 1 === e),
    $begin: u,
    $end: c,
    $strides: p,
    size: x,
    newShape: f,
    outShape: v
  };
}

var slice_util$1 = {
  __proto__: null,
  assertParamsValid: assertParamsValid$1,
  maskToAxes: maskToAxes$1,
  computeOutShape: computeOutShape$5,
  stridesWithElidedDims: stridesWithElidedDims$1,
  getNormalizedAxes: getNormalizedAxes$1,
  startIndicesWithElidedDims: startIndicesWithElidedDims$1,
  stopIndicesWithElidedDims: stopIndicesWithElidedDims$1,
  stridesForAxis: stridesForAxis$1,
  startForAxis: startForAxis$1,
  stopForAxis: stopForAxis$1,
  isSliceContinous: isSliceContinous$1,
  computeFlatOffset: computeFlatOffset$1,
  parseSliceParams: parseSliceParams$1,
  sliceInfo: sliceInfo$1
};

class Serializable$1 {
  getClassName() {
    return this.constructor.className;
  }

  static fromConfig(e, t) {
    return new e(t);
  }

}

class SerializationMap$1 {
  constructor() {
    this.classNameMap = {};
  }

  static getMap() {
    return null == SerializationMap$1.instance && (SerializationMap$1.instance = new SerializationMap$1()), SerializationMap$1.instance;
  }

  static register(e) {
    SerializationMap$1.getMap().classNameMap[e.className] = [e, e.fromConfig];
  }

}

function registerClass$1(e) {
  assert$6(null != e.className, () => "Class being registered does not have the static className property defined."), assert$6("string" == typeof e.className, () => "className is required to be a string, but got type " + typeof e.className), assert$6(e.className.length > 0, () => "Class being registered has an empty-string as its className, which is disallowed."), SerializationMap$1.register(e);
}

var version$e = "3.8.0";

function engine$1() {
  return ENGINE$1;
}

function memory$1() {
  return ENGINE$1.memory();
}

function tidy$1(e, t) {
  return ENGINE$1.tidy(e, t);
}

function dispose$1(e) {
  getTensorsInContainer$1(e).forEach(e => e.dispose());
}

function keep$1(e) {
  return ENGINE$1.keep(e);
}

function registerBackend$1(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 1;
  return ENGINE$1.registerBackend(e, t, n);
}

function backend$1() {
  return ENGINE$1.backend;
}

function add_$1(e, t) {
  var n = convertToTensor$1(e, "a", "add"),
      r = convertToTensor$1(t, "b", "add");
  return [n, r] = makeTypesMatch$1(n, r), ENGINE$1.runKernel(Add$3, {
    a: n,
    b: r
  });
}

var add$5 = op$1({
  add_: add_$1
});

function floorDiv_$1(e, t) {
  var n = convertToTensor$1(e, "a", "floorDiv"),
      r = convertToTensor$1(t, "b", "floorDiv");
  return [n, r] = makeTypesMatch$1(n, r), ENGINE$1.runKernel(FloorDiv$1, {
    a: n,
    b: r
  });
}

var floorDiv$5 = op$1({
  floorDiv_: floorDiv_$1
});

function div_$1(e, t) {
  var n = convertToTensor$1(e, "a", "div"),
      r = convertToTensor$1(t, "b", "div");
  return [n, r] = makeTypesMatch$1(n, r), "int32" === n.dtype && "int32" === r.dtype ? floorDiv$5(n, r) : ENGINE$1.runKernel(RealDiv$1, {
    a: n,
    b: r
  }, {});
}

var div$3 = op$1({
  div_: div_$1
});

function mul_$1(e, t) {
  var n = convertToTensor$1(e, "a", "mul"),
      r = convertToTensor$1(t, "b", "mul");
  return [n, r] = makeTypesMatch$1(n, r), ENGINE$1.runKernel(Multiply$3, {
    a: n,
    b: r
  });
}

var mul$1 = op$1({
  mul_: mul_$1
});

function abs_$1(e) {
  var t = convertToTensor$1(e, "x", "abs");
  return ENGINE$1.runKernel("complex64" === t.dtype ? ComplexAbs$1 : Abs$1, {
    x: t
  });
}

var abs$5 = op$1({
  abs_: abs_$1
});

function acos_$1(e) {
  var t = convertToTensor$1(e, "x", "acos");
  return ENGINE$1.runKernel(Acos$1, {
    x: t
  });
}

var acos$5 = op$1({
  acos_: acos_$1
});

function acosh_$1(e) {
  var t = convertToTensor$1(e, "x", "acosh");
  return ENGINE$1.runKernel(Acosh$1, {
    x: t
  });
}

var acosh$5 = op$1({
  acosh_: acosh_$1
});

function all_$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  var r = convertToTensor$1(e, "x", "all", "bool");
  return ENGINE$1.runKernel(All$1, {
    x: r
  }, {
    axis: t,
    keepDims: n
  });
}

var all$5 = op$1({
  all_: all_$1
});

function any_$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  var r = convertToTensor$1(e, "x", "any", "bool");
  return ENGINE$1.runKernel(Any$1, {
    x: r
  }, {
    axis: t,
    keepDims: n
  });
}

var any$5 = op$1({
  any_: any_$1
});

function argMax_$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;
  var n = convertToTensor$1(e, "x", "argMax");
  return ENGINE$1.runKernel(ArgMax$1, {
    x: n
  }, {
    axis: t
  });
}

var argMax$5 = op$1({
  argMax_: argMax_$1
});

function argMin_$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;
  var n = convertToTensor$1(e, "x", "argMin");
  return ENGINE$1.runKernel(ArgMin$1, {
    x: n
  }, {
    axis: t
  });
}

var argMin$5 = op$1({
  argMin_: argMin_$1
});

function asin_$1(e) {
  var t = convertToTensor$1(e, "x", "asin");
  return ENGINE$1.runKernel(Asin$1, {
    x: t
  });
}

var asin$5 = op$1({
  asin_: asin_$1
});

function asinh_$1(e) {
  var t = convertToTensor$1(e, "x", "asinh");
  return ENGINE$1.runKernel(Asinh$1, {
    x: t
  });
}

var asinh$5 = op$1({
  asinh_: asinh_$1
});

function atan_$1(e) {
  var t = convertToTensor$1(e, "x", "atan");
  return ENGINE$1.runKernel(Atan$1, {
    x: t
  });
}

var atan$5 = op$1({
  atan_: atan_$1
});

function atan2_$1(e, t) {
  var n = convertToTensor$1(e, "a", "atan2"),
      r = convertToTensor$1(t, "b", "atan2");
  return [n, r] = makeTypesMatch$1(n, r), ENGINE$1.runKernel(Atan2$1, {
    a: n,
    b: r
  });
}

var atan2$5 = op$1({
  atan2_: atan2_$1
});

function atanh_$1(e) {
  var t = convertToTensor$1(e, "x", "atanh");
  return ENGINE$1.runKernel(Atanh$1, {
    x: t
  });
}

var atanh$5 = op$1({
  atanh_: atanh_$1
});

function computeDilation2DInfo$1(e, t, n, r) {
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : "NHWC";
  var s = arguments.length > 5 ? arguments[5] : undefined;
  return computeConv2DInfo$1(e, [...t, e[3]], n, s, r, null, null, convertConv2DDataFormat$1(a));
}

function computePool2DInfo$1(e, t, n, r, a, s) {
  var o = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : "channelsLast";
  var [i, l] = parseTupleParam$1(t);
  var u;
  if ("channelsLast" === o) u = [i, l, e[3], e[3]];else {
    if ("channelsFirst" !== o) throw new Error("Unknown dataFormat ".concat(o));
    u = [i, l, e[1], e[1]];
  }
  return computeConv2DInfo$1(e, u, n, r, a, s, !1, o);
}

function computePool3DInfo$1(e, t, n, r, a, s) {
  var o = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : "NDHWC";
  var [i, l, u] = parse3TupleParam$1(t);
  var c, p;
  if ("NDHWC" === o) p = "channelsLast", c = [i, l, u, e[4], e[4]];else {
    if ("NCDHW" !== o) throw new Error("Unknown dataFormat ".concat(o));
    p = "channelsFirst", c = [i, l, u, e[1], e[1]];
  }
  return computeConv3DInfo$1(e, c, n, r, a, !1, p, s);
}

function computeConv2DInfo$1(e, t, n, r, a, s) {
  var o = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : !1;
  var i = arguments.length > 7 && arguments[7] !== undefined ? arguments[7] : "channelsLast";
  var [l, u, c, p] = [-1, -1, -1, -1];
  if ("channelsLast" === i) [l, u, c, p] = e;else {
    if ("channelsFirst" !== i) throw new Error("Unknown dataFormat ".concat(i));
    [l, p, u, c] = e;
  }
  var [d, h,, m] = t,
      [f, g] = parseTupleParam$1(n),
      [$, y] = parseTupleParam$1(r),
      b = getEffectiveFilterSize$1(d, $),
      x = getEffectiveFilterSize$1(h, y),
      {
    padInfo: v,
    outHeight: I,
    outWidth: C
  } = getPadAndOutInfo$1(a, u, c, f, g, b, x, s, i),
      S = o ? m * p : m;
  var k;
  return "channelsFirst" === i ? k = [l, S, I, C] : "channelsLast" === i && (k = [l, I, C, S]), {
    batchSize: l,
    dataFormat: i,
    inHeight: u,
    inWidth: c,
    inChannels: p,
    outHeight: I,
    outWidth: C,
    outChannels: S,
    padInfo: v,
    strideHeight: f,
    strideWidth: g,
    filterHeight: d,
    filterWidth: h,
    effectiveFilterHeight: b,
    effectiveFilterWidth: x,
    dilationHeight: $,
    dilationWidth: y,
    inShape: e,
    outShape: k,
    filterShape: t
  };
}

function computeConv3DInfo$1(e, t, n, r, a) {
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : !1;
  var o = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : "channelsLast";
  var i = arguments.length > 7 ? arguments[7] : undefined;
  var [l, u, c, p, d] = [-1, -1, -1, -1, -1];
  if ("channelsLast" === o) [l, u, c, p, d] = e;else {
    if ("channelsFirst" !== o) throw new Error("Unknown dataFormat ".concat(o));
    [l, d, u, c, p] = e;
  }
  var [h, m, f,, g] = t,
      [$, y, b] = parse3TupleParam$1(n),
      [x, v, I] = parse3TupleParam$1(r),
      C = getEffectiveFilterSize$1(h, x),
      S = getEffectiveFilterSize$1(m, v),
      k = getEffectiveFilterSize$1(f, I),
      {
    padInfo: T,
    outDepth: N,
    outHeight: w,
    outWidth: E
  } = get3DPadAndOutInfo$1(a, u, c, p, $, y, b, C, S, k, i),
      A = s ? g * d : g;
  var D;
  return "channelsFirst" === o ? D = [l, A, N, w, E] : "channelsLast" === o && (D = [l, N, w, E, A]), {
    batchSize: l,
    dataFormat: o,
    inDepth: u,
    inHeight: c,
    inWidth: p,
    inChannels: d,
    outDepth: N,
    outHeight: w,
    outWidth: E,
    outChannels: A,
    padInfo: T,
    strideDepth: $,
    strideHeight: y,
    strideWidth: b,
    filterDepth: h,
    filterHeight: m,
    filterWidth: f,
    effectiveFilterDepth: C,
    effectiveFilterHeight: S,
    effectiveFilterWidth: k,
    dilationDepth: x,
    dilationHeight: v,
    dilationWidth: I,
    inShape: e,
    outShape: D,
    filterShape: t
  };
}

function computeOutputShape2D$1(e, t, n, r, a) {
  null == r && (r = computeDefaultPad$1(e, t, n));
  var s = e[1];
  return [round$7((e[0] - t + 2 * r) / n + 1, a), round$7((s - t + 2 * r) / n + 1, a)];
}

function computeOutputShape4D$1(e, t, n, r, a, s) {
  null == a && (a = computeDefaultPad$1(e, t, r));
  var o = e[1],
      i = e[2];
  return [round$7((e[0] - t + 2 * a) / r + 1, s), round$7((o - t + 2 * a) / r + 1, s), round$7((i - t + 2 * a) / r + 1, s), n];
}

function computeDefaultPad$1(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 1;
  var a = getEffectiveFilterSize$1(t, r);
  return Math.floor((e[0] * (n - 1) - n + a) / 2);
}

function parseTupleParam$1(e) {
  return "number" == typeof e ? [e, e, e] : 2 === e.length ? [e[0], e[1], 1] : e;
}

function parse3TupleParam$1(e) {
  return "number" == typeof e ? [e, e, e] : e;
}

function getEffectiveFilterSize$1(e, t) {
  return t <= 1 ? e : e + (e - 1) * (t - 1);
}

function getPadAndOutInfo$1(e, t, n, r, a, s, o, i, l) {
  var u, c, p;

  if ("number" == typeof e) {
    u = {
      top: e,
      bottom: e,
      left: e,
      right: e,
      type: 0 === e ? "VALID" : "NUMBER"
    };

    var _a9 = computeOutputShape2D$1([t, n], s, r, e, i);

    c = _a9[0], p = _a9[1];
  } else if ("same" === e) {
    c = Math.ceil(t / r), p = Math.ceil(n / a);

    var _e43 = Math.max(0, (c - 1) * r + s - t),
        _i3 = Math.max(0, (p - 1) * a + o - n),
        _l3 = Math.floor(_e43 / 2),
        d = _e43 - _l3,
        h = Math.floor(_i3 / 2);

    u = {
      top: _l3,
      bottom: d,
      left: h,
      right: _i3 - h,
      type: "SAME"
    };
  } else if ("valid" === e) u = {
    top: 0,
    bottom: 0,
    left: 0,
    right: 0,
    type: "VALID"
  }, c = Math.ceil((t - s + 1) / r), p = Math.ceil((n - o + 1) / a);else {
    if ("object" != typeof e) throw Error("Unknown padding parameter: ".concat(e));
    {
      var _d = "channelsLast" === l ? e[1][0] : e[2][0],
          _h = "channelsLast" === l ? e[1][1] : e[2][1],
          m = "channelsLast" === l ? e[2][0] : e[3][0],
          f = "channelsLast" === l ? e[2][1] : e[3][1];

      u = {
        top: _d,
        bottom: _h,
        left: m,
        right: f,
        type: 0 === _d && 0 === _h && 0 === m && 0 === f ? "VALID" : "EXPLICIT"
      }, c = round$7((t - s + _d + _h) / r + 1, i), p = round$7((n - o + m + f) / a + 1, i);
    }
  }

  return {
    padInfo: u,
    outHeight: c,
    outWidth: p
  };
}

function get3DPadAndOutInfo$1(e, t, n, r, a, s, o, i, l, u, c) {
  var p, d, h, m;

  if ("number" == typeof e) {
    p = {
      top: e,
      bottom: e,
      left: e,
      right: e,
      front: e,
      back: e,
      type: 0 === e ? "VALID" : "NUMBER"
    };

    var _s6 = computeOutputShape4D$1([t, n, r, 1], i, 1, a, e, c);

    d = _s6[0], h = _s6[1], m = _s6[2];
  } else if ("same" === e) {
    d = Math.ceil(t / a), h = Math.ceil(n / s), m = Math.ceil(r / o);

    var _e44 = (d - 1) * a + i - t,
        _c = (h - 1) * s + l - n,
        f = (m - 1) * o + u - r,
        g = Math.floor(_e44 / 2),
        $ = _e44 - g,
        y = Math.floor(_c / 2),
        b = _c - y,
        x = Math.floor(f / 2);

    p = {
      top: y,
      bottom: b,
      left: x,
      right: f - x,
      front: g,
      back: $,
      type: "SAME"
    };
  } else {
    if ("valid" !== e) throw Error("Unknown padding parameter: ".concat(e));
    p = {
      top: 0,
      bottom: 0,
      left: 0,
      right: 0,
      front: 0,
      back: 0,
      type: "VALID"
    }, d = Math.ceil((t - i + 1) / a), h = Math.ceil((n - l + 1) / s), m = Math.ceil((r - u + 1) / o);
  }

  return {
    padInfo: p,
    outDepth: d,
    outHeight: h,
    outWidth: m
  };
}

function round$7(e, t) {
  if (!t) return Math.trunc(e);

  switch (t) {
    case "round":
      return Math.round(e);

    case "ceil":
      return Math.ceil(e);

    case "floor":
      return Math.floor(e);

    default:
      throw new Error("Unknown roundingMode ".concat(t));
  }
}

function tupleValuesAreOne$1(e) {
  var [t, n, r] = parseTupleParam$1(e);
  return 1 === t && 1 === n && 1 === r;
}

function eitherStridesOrDilationsAreOne$1(e, t) {
  return tupleValuesAreOne$1(e) || tupleValuesAreOne$1(t);
}

function convertConv2DDataFormat$1(e) {
  if ("NHWC" === e) return "channelsLast";
  if ("NCHW" === e) return "channelsFirst";
  throw new Error("Unknown dataFormat ".concat(e));
}

function reshape_$1(e, t) {
  var n = convertToTensor$1(e, "x", "reshape", "string_or_numeric");
  return ENGINE$1.runKernel(Reshape$3, {
    x: n
  }, {
    shape: t
  });
}

var reshape$6 = op$1({
  reshape_: reshape_$1
});

function avgPool_$1(e, t, n, r, a) {
  var s = convertToTensor$1(e, "x", "avgPool", "float32");
  assert$6(eitherStridesOrDilationsAreOne$1(n, 1), () => "Error in avgPool: Either strides or dilations must be 1. Got strides ".concat(n, " and dilations '1'"));
  var o = s,
      i = !1;
  3 === s.rank && (i = !0, o = reshape$6(s, [1, s.shape[0], s.shape[1], s.shape[2]])), assert$6(4 === o.rank, () => "Error in avgPool: x must be rank 4 but got rank ".concat(o.rank, ".")), null != a && assert$6(isInt$1(r), () => "Error in avgPool: pad must be an integer when using, dimRoundingMode ".concat(a, " but got pad ").concat(r, "."));
  var l = ENGINE$1.runKernel(AvgPool$1, {
    x: o
  }, {
    filterSize: t,
    strides: n,
    pad: r,
    dimRoundingMode: a
  });
  return l = cast$7(l, s.dtype), i ? reshape$6(l, [l.shape[1], l.shape[2], l.shape[3]]) : l;
}

var avgPool$5 = op$1({
  avgPool_: avgPool_$1
});

function avgPool3d_$1(e, t, n, r, a) {
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : "NDHWC";
  var o = convertToTensor$1(e, "x", "avgPool3d", "float32");
  var i = o,
      l = !1;
  4 === o.rank && (l = !0, i = reshape$6(o, [1, o.shape[0], o.shape[1], o.shape[2], o.shape[3]])), assert$6(5 === i.rank, () => "Error in avgPool3d: x must be rank 5 but got rank ".concat(i.rank, ".")), assert$6("NDHWC" === s, () => "Error in avgPool3d: Only NDHWC is currently supported, but got dataFormat of ".concat(s)), null != a && assert$6(isInt$1(r), () => "Error in avgPool3d: pad must be an integer when using, dimRoundingMode ".concat(a, " but got pad ").concat(r, "."));
  var u = ENGINE$1.runKernel(AvgPool3D$1, {
    x: i
  }, {
    filterSize: t,
    strides: n,
    pad: r,
    dimRoundingMode: a,
    dataFormat: s
  });
  return u = cast$7(u, i.dtype), l ? reshape$6(u, [u.shape[1], u.shape[2], u.shape[3], u.shape[4]]) : u;
}

var avgPool3d$2 = op$1({
  avgPool3d_: avgPool3d_$1
});

function concat_$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;
  assert$6(e.length >= 1, () => "Pass at least one tensor to concat");
  var n = convertToTensorArray$1(e, "tensors", "concat", "string_or_numeric");
  return "complex64" === n[0].dtype && n.forEach(e => {
    if ("complex64" !== e.dtype) throw new Error("Cannot concatenate complex64 tensors with a tensor\n          with dtype ".concat(e.dtype, ". "));
  }), 1 === n.length ? clone$1(n[0]) : ENGINE$1.runKernel(Concat$1, n, {
    axis: t
  });
}

var concat$5 = op$1({
  concat_: concat_$1
});

function sigmoid_$1(e) {
  var t = convertToTensor$1(e, "x", "sigmoid");
  return ENGINE$1.runKernel(Sigmoid$3, {
    x: t
  });
}

var sigmoid$5 = op$1({
  sigmoid_: sigmoid_$1
});

function slice_$1(e, t, n) {
  var r = convertToTensor$1(e, "x", "slice", "string_or_numeric");
  if (0 === r.rank) throw new Error("Slicing scalar is not possible");
  return ENGINE$1.runKernel(Slice$1, {
    x: r
  }, {
    begin: t,
    size: n
  });
}

var slice$5 = op$1({
  slice_: slice_$1
});

function tanh_$1(e) {
  var t = convertToTensor$1(e, "x", "tanh");
  return ENGINE$1.runKernel(Tanh$3, {
    x: t
  });
}

var tanh$6 = op$1({
  tanh_: tanh_$1
});

function batchToSpaceND_$1(e, t, n) {
  var r = convertToTensor$1(e, "x", "batchToSpaceND"),
      a = t.reduce((e, t) => e * t);
  return assert$6(r.rank >= 1 + t.length, () => "input rank is ".concat(r.rank, " but should be > than blockShape.length ").concat(t.length)), assert$6(n.length === t.length, () => "crops.length is ".concat(n.length, " but should be equal to blockShape.length  ").concat(t.length)), assert$6(r.shape[0] % a == 0, () => "input tensor batch is ".concat(r.shape[0], " but is not divisible by the product of the elements of blockShape ").concat(t.join(" * "), " === ").concat(a)), ENGINE$1.runKernel(BatchToSpaceND$1, {
    x: r
  }, {
    blockShape: t,
    crops: n
  });
}

var batchToSpaceND$5 = op$1({
  batchToSpaceND_: batchToSpaceND_$1
});

function xAs4D$1(e) {
  var t;
  return t = 0 === e.rank || 1 === e.rank ? reshape$6(e, [1, 1, 1, e.size]) : 2 === e.rank ? reshape$6(e, [1, 1, e.shape[0], e.shape[1]]) : 3 === e.rank ? reshape$6(e, [1, e.shape[0], e.shape[1], e.shape[2]]) : e, t;
}

function batchNorm_$1(e, t, n, r, a, s) {
  null == s && (s = .001);
  var o = convertToTensor$1(e, "x", "batchNorm"),
      i = convertToTensor$1(t, "mean", "batchNorm"),
      l = convertToTensor$1(n, "variance", "batchNorm");
  var u, c;
  null != a && (u = convertToTensor$1(a, "scale", "batchNorm")), null != r && (c = convertToTensor$1(r, "offset", "batchNorm")), assert$6(i.rank === l.rank, () => "Batch normalization gradient requires mean and variance to have equal ranks."), assert$6(null == c || i.rank === c.rank, () => "Batch normalization gradient requires mean and offset to have equal ranks."), assert$6(null == u || i.rank === u.rank, () => "Batch normalization gradient requires mean and scale to have equal ranks.");
  var p = xAs4D$1(o),
      d = ENGINE$1.runKernel(FusedBatchNorm$1, {
    x: p,
    scale: u,
    offset: c,
    mean: i,
    variance: l
  }, {
    varianceEpsilon: s
  });
  return reshape$6(d, o.shape);
}

var batchNorm$5 = op$1({
  batchNorm_: batchNorm_$1
});

function batchNorm2d_$1(e, t, n, r, a, s) {
  var o = convertToTensor$1(e, "x", "batchNorm"),
      i = convertToTensor$1(t, "mean", "batchNorm"),
      l = convertToTensor$1(n, "variance", "batchNorm");
  var u, c;
  return null != a && (u = convertToTensor$1(a, "scale", "batchNorm")), null != r && (c = convertToTensor$1(r, "offset", "batchNorm")), assert$6(2 === o.rank, () => "Error in batchNorm2D: x must be rank 2 but got rank ".concat(o.rank, ".")), assert$6(2 === i.rank || 1 === i.rank, () => "Error in batchNorm2D: mean must be rank 2 or rank 1 but got rank ".concat(i.rank, ".")), assert$6(2 === l.rank || 1 === l.rank, () => "Error in batchNorm2D: variance must be rank 2 or rank 1 but got rank ".concat(l.rank, ".")), null != u && assert$6(2 === u.rank || 1 === u.rank, () => "Error in batchNorm2D: scale must be rank 2 or rank 1 but got rank ".concat(u.rank, ".")), null != c && assert$6(2 === c.rank || 1 === c.rank, () => "Error in batchNorm2D: offset must be rank 2 or rank 1 but got rank ".concat(c.rank, ".")), batchNorm$5(o, i, l, c, u, s);
}

var batchNorm2d$1 = op$1({
  batchNorm2d_: batchNorm2d_$1
});

function batchNorm3d_$1(e, t, n, r, a, s) {
  var o = convertToTensor$1(e, "x", "batchNorm"),
      i = convertToTensor$1(t, "mean", "batchNorm"),
      l = convertToTensor$1(n, "variance", "batchNorm");
  var u, c;
  return null != a && (u = convertToTensor$1(a, "scale", "batchNorm")), null != r && (c = convertToTensor$1(r, "offset", "batchNorm")), assert$6(3 === o.rank, () => "Error in batchNorm3D: x must be rank 3 but got rank ".concat(o.rank, ".")), assert$6(3 === i.rank || 1 === i.rank, () => "Error in batchNorm3D: mean must be rank 3 or rank 1 but got rank ".concat(i.rank, ".")), assert$6(3 === l.rank || 1 === l.rank, () => "Error in batchNorm3D: variance must be rank 3 or rank 1 but got rank ".concat(l.rank, ".")), null != u && assert$6(3 === u.rank || 1 === u.rank, () => "Error in batchNorm3D: scale must be rank 3 or rank 1 but got rank ".concat(u.rank, ".")), null != c && assert$6(3 === c.rank || 1 === c.rank, () => "Error in batchNorm3D: offset must be rank 3 or rank 1 but got rank ".concat(c.rank, ".")), batchNorm$5(o, i, l, c, u, s);
}

var batchNorm3d$1 = op$1({
  batchNorm3d_: batchNorm3d_$1
});

function batchNorm4d_$1(e, t, n, r, a, s) {
  var o = convertToTensor$1(e, "x", "batchNorm"),
      i = convertToTensor$1(t, "mean", "batchNorm"),
      l = convertToTensor$1(n, "variance", "batchNorm");
  var u, c;
  return null != a && (u = convertToTensor$1(a, "scale", "batchNorm")), null != r && (c = convertToTensor$1(r, "offset", "batchNorm")), assert$6(4 === o.rank, () => "Error in batchNorm4D: x must be rank 4 but got rank ".concat(o.rank, ".")), assert$6(4 === i.rank || 1 === i.rank, () => "Error in batchNorm4D: mean must be rank 4 or rank 1 but got rank ".concat(i.rank, ".")), assert$6(4 === l.rank || 1 === l.rank, () => "Error in batchNorm4D: variance must be rank 4 or rank 1 but got rank ".concat(l.rank, ".")), null != u && assert$6(4 === u.rank || 1 === u.rank, () => "Error in batchNorm4D: scale must be rank 4 or rank 1 but got rank ".concat(u.rank, ".")), null != c && assert$6(4 === c.rank || 1 === c.rank, () => "Error in batchNorm4D: offset must be rank 4 or rank 1 but got rank ".concat(c.rank, ".")), batchNorm$5(o, i, l, c, u, s);
}

var batchNorm4d$1 = op$1({
  batchNorm4d_: batchNorm4d_$1
});

function bincount_$1(e, t, n) {
  var r = convertToTensor$1(e, "x", "bincount"),
      a = convertToTensor$1(t, "weights", "bincount");
  return assert$6("int32" === r.dtype, () => "Error in bincount: input dtype must be int32, but got ".concat(r.dtype)), assert$6(n >= 0, () => "size must be non-negative, but got ".concat(n, ".")), assert$6(a.size === r.size || 0 === a.size, () => "Error in bincount: weights must have the same size as input or0-length, but got input shape: ".concat(r.shape, ", weights shape: ").concat(a.shape, ".")), ENGINE$1.runKernel(Bincount$1, {
    x: r,
    weights: a
  }, {
    size: n
  });
}

var bincount$5 = op$1({
  bincount_: bincount_$1
});

function broadcastTo_$1(e, t) {
  var n = convertToTensor$1(e, "broadcastTo", "x");
  var r = n.shape;
  if (t.some(e => !(e > 0) || e % 1 != 0)) throw new Error("broadcastTo(): Invalid broadcast shape [".concat(t, "]."));
  if (t.length < n.rank) throw new Error("broadcastTo(): shape.length=".concat(t.length, " < input.rank=").concat(n.rank, "."));

  if (t.length > n.rank) {
    var _e45 = n.shape.slice();

    for (; _e45.length < t.length;) {
      _e45.unshift(1);
    }

    n = reshape$6(n, _e45);
  }

  var a = n.shape,
      s = Array.from(t);

  for (var _e46 = t.length - 1; _e46 >= 0; _e46--) {
    if (a[_e46] === t[_e46]) s[_e46] = 1;else if (1 !== n.shape[_e46]) throw new Error("broadcastTo(): [".concat(r, "] cannot be broadcast to [").concat(t, "]."));
  }

  return 0 === s.map((e, t) => e > 1 ? t : -1).filter(e => e >= 0).length ? clone$1(n) : ENGINE$1.runKernel(Tile$1, {
    x: n
  }, {
    reps: s
  });
}

var broadcastTo$1 = op$1({
  broadcastTo_: broadcastTo_$1
});

function ceil_$1(e) {
  var t = convertToTensor$1(e, "x", "ceil");
  return ENGINE$1.runKernel(Ceil$1, {
    x: t
  });
}

var ceil$5 = op$1({
  ceil_: ceil_$1
});

function clipByValue_$1(e, t, n) {
  var r = convertToTensor$1(e, "x", "clipByValue");
  return assert$6(t <= n, () => "Error in clip: min (".concat(t, ") must be less than or equal to max (").concat(n, ").")), ENGINE$1.runKernel(ClipByValue$1, {
    x: r
  }, {
    clipValueMin: t,
    clipValueMax: n
  });
}

var clipByValue$3 = op$1({
  clipByValue_: clipByValue_$1
});

function concat1d_$1(e) {
  return concat$5(e, 0);
}

var concat1d$1 = op$1({
  concat1d_: concat1d_$1
});

function concat2d_$1(e, t) {
  return concat$5(e, t);
}

var concat2d$1 = op$1({
  concat2d_: concat2d_$1
});

function concat3d_$1(e, t) {
  return concat$5(e, t);
}

var concat3d$1 = op$1({
  concat3d_: concat3d_$1
});

function concat4d_$1(e, t) {
  return concat$5(e, t);
}

var concat4d$1 = op$1({
  concat4d_: concat4d_$1
});

function conv2d_$1(e, t, n, r) {
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : "NHWC";
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : [1, 1];
  var o = arguments.length > 6 ? arguments[6] : undefined;
  var i = convertToTensor$1(e, "x", "conv2d"),
      l = convertToTensor$1(t, "filter", "conv2d");
  var u = i,
      c = !1;
  3 === i.rank && (c = !0, u = reshape$6(i, [1, i.shape[0], i.shape[1], i.shape[2]])), assert$6(4 === u.rank, () => "Error in conv2d: input must be rank 4, but got rank ".concat(u.rank, ".")), assert$6(4 === l.rank, () => "Error in conv2d: filter must be rank 4, but got rank ".concat(l.rank, ".")), null != o && assert$6(isInt$1(r), () => "Error in conv2d: pad must be an integer when using, dimRoundingMode ".concat(o, " but got pad ").concat(r, "."));
  var p = "NHWC" === a ? u.shape[3] : u.shape[1];
  assert$6(p === l.shape[2], () => "Error in conv2d: depth of input (".concat(p, ") must match input depth for filter ").concat(l.shape[2], ".")), assert$6(eitherStridesOrDilationsAreOne$1(n, s), () => "Error in conv2D: Either strides or dilations must be 1. Got strides ".concat(n, " and dilations '").concat(s, "'"));
  var d = ENGINE$1.runKernel(Conv2D$3, {
    x: u,
    filter: l
  }, {
    strides: n,
    pad: r,
    dataFormat: a,
    dilations: s,
    dimRoundingMode: o
  });
  return c ? reshape$6(d, [d.shape[1], d.shape[2], d.shape[3]]) : d;
}

var conv2d$7 = op$1({
  conv2d_: conv2d_$1
});

function conv1d_$1(e, t, n, r) {
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : "NWC";
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : 1;
  var o = arguments.length > 6 ? arguments[6] : undefined;
  var i = convertToTensor$1(e, "x", "conv1d"),
      l = convertToTensor$1(t, "filter", "conv1d");
  var u = i,
      c = !1;
  2 === i.rank && (c = !0, u = reshape$6(i, [1, i.shape[0], i.shape[1]])), assert$6(3 === u.rank, () => "Error in conv1d: input must be rank 3, but got rank ".concat(u.rank, ".")), assert$6(3 === l.rank, () => "Error in conv1d: filter must be rank 3, but got rank ".concat(l.rank, ".")), null != o && assert$6(isInt$1(r), () => "Error in conv1d: pad must be an integer when using, dimRoundingMode ".concat(o, " but got pad ").concat(r, ".")), assert$6(u.shape[2] === l.shape[1], () => "Error in conv1d: depth of input (".concat(u.shape[2], ") must match input depth for filter ").concat(l.shape[1], ".")), assert$6(eitherStridesOrDilationsAreOne$1(n, s), () => "Error in conv1D: Either stride or dilation must be 1. Got stride ".concat(n, " and dilation '").concat(s, "'")), assert$6("NWC" === a, () => "Error in conv1d: got dataFormat of ".concat(a, " but only NWC is currently supported."));
  var p = reshape$6(l, [1, l.shape[0], l.shape[1], l.shape[2]]),
      d = reshape$6(u, [u.shape[0], 1, u.shape[1], u.shape[2]]),
      h = conv2d$7(d, p, [1, n], r, "NHWC", [1, s], o);
  return reshape$6(h, c ? [h.shape[2], h.shape[3]] : [h.shape[0], h.shape[2], h.shape[3]]);
}

var conv1d$3 = op$1({
  conv1d_: conv1d_$1
});

function conv2DBackpropInput_$1(e, t, n, r, a) {
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : "NHWC";
  var o = arguments.length > 6 ? arguments[6] : undefined;
  assert$6(e.length === t.rank, () => "Length of inShape (".concat(e.length, ") and rank of dy (").concat(t.rank, ") must match"));
  var i = e,
      l = t,
      u = !1;
  3 === t.rank && (u = !0, l = reshape$6(t, [1, t.shape[0], t.shape[1], t.shape[2]]), i = [1, e[0], e[1], e[2]]), assert$6(4 === i.length, () => "Error in conv2dDerInput: inShape must be length 4, but got length ".concat(i.length, ".")), assert$6(4 === l.rank, () => "Error in conv2dDerInput: dy must be rank 4, but got rank ".concat(l.rank)), assert$6(4 === n.rank, () => "Error in conv2dDerInput: filter must be rank 4, but got rank ".concat(n.rank));
  var c = "NHWC" === s ? i[3] : i[1],
      p = "NHWC" === s ? l.shape[3] : l.shape[1];
  assert$6(c === n.shape[2], () => "Error in conv2dDerInput: depth of input (".concat(c, ") must match input depth for filter ").concat(n.shape[2], ".")), assert$6(p === n.shape[3], () => "Error in conv2dDerInput: depth of output (".concat(p, ") must match output depth for filter ").concat(n.shape[3], ".")), null != o && assert$6(isInt$1(a), () => "Error in conv2dDerInput: pad must be an integer when using, dimRoundingMode ".concat(o, " but got pad ").concat(a, "."));
  var d = ENGINE$1.runKernel(Conv2DBackpropInput$1, {
    dy: l,
    filter: n
  }, {
    strides: r,
    pad: a,
    dataFormat: s,
    dimRoundingMode: o,
    inputShape: i
  });
  return u ? reshape$6(d, [d.shape[1], d.shape[2], d.shape[3]]) : d;
}

var conv2DBackpropInput$5 = op$1({
  conv2DBackpropInput_: conv2DBackpropInput_$1
});

function conv2dTranspose_$1(e, t, n, r, a, s) {
  var o = convertToTensor$1(e, "x", "conv2dTranspose"),
      i = convertToTensor$1(t, "filter", "conv2dTranspose");
  return conv2DBackpropInput$5(n, o, i, r, a, "NHWC", s);
}

var conv2dTranspose$2 = op$1({
  conv2dTranspose_: conv2dTranspose_$1
});

function conv3d_$1(e, t, n, r) {
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : "NDHWC";
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : [1, 1, 1];
  var o = convertToTensor$1(e, "x", "conv3d"),
      i = convertToTensor$1(t, "filter", "conv3d");
  var l = o,
      u = !1;
  4 === o.rank && (u = !0, l = reshape$6(o, [1, o.shape[0], o.shape[1], o.shape[2], o.shape[3]])), assert$6(5 === l.rank, () => "Error in conv3d: input must be rank 5, but got rank ".concat(l.rank, ".")), assert$6(5 === i.rank, () => "Error in conv3d: filter must be rank 5, but got rank ".concat(i.rank, ".")), assert$6(l.shape[4] === i.shape[3], () => "Error in conv3d: depth of input (".concat(l.shape[4], ") must match input depth for filter ").concat(i.shape[3], ".")), assert$6(eitherStridesOrDilationsAreOne$1(n, s), () => "Error in conv3D: Either strides or dilations must be 1. Got strides ".concat(n, " and dilations '").concat(s, "'")), assert$6("NDHWC" === a, () => "Error in conv3d: got dataFormat of ".concat(a, " but only NDHWC is currently supported."));
  var c = ENGINE$1.runKernel(Conv3D$3, {
    x: l,
    filter: i
  }, {
    strides: n,
    pad: r,
    dataFormat: a,
    dilations: s
  });
  return u ? reshape$6(c, [c.shape[1], c.shape[2], c.shape[3], c.shape[4]]) : c;
}

var conv3d$2 = op$1({
  conv3d_: conv3d_$1
});

function conv3DBackpropInput_$1(e, t, n, r, a) {
  assert$6(e.length === t.rank, () => "Length of inShape (".concat(e.length, ") and rank of dy (").concat(t.rank, ") must match"));
  var s = e,
      o = t,
      i = !1;
  4 === t.rank && (i = !0, o = reshape$6(t, [1, t.shape[0], t.shape[1], t.shape[2], t.shape[3]]), s = [1, e[0], e[1], e[2], e[3]]);
  var l = s[4],
      u = o.shape[4];
  assert$6(5 === s.length, () => "Error in conv3dDerInput: inShape must be length 5, but got length ".concat(s.length, ".")), assert$6(5 === o.rank, () => "Error in conv3dDerInput: dy must be rank 5, but got rank ".concat(o.rank)), assert$6(5 === n.rank, () => "Error in conv3dDerInput: filter must be rank 5, but got rank ".concat(n.rank)), assert$6(l === n.shape[3], () => "Error in conv3dDerInput: depth of input (".concat(l, ") must match input depth for filter ").concat(n.shape[3], ".")), assert$6(u === n.shape[4], () => "Error in conv3dDerInput: depth of output (".concat(u, ") must match output depth for filter ").concat(n.shape[4], "."));
  var c = ENGINE$1.runKernel(Conv3DBackpropInputV2$1, {
    dy: o,
    filter: n
  }, {
    pad: a,
    strides: r,
    inputShape: s
  });
  return i ? reshape$6(c, [c.shape[1], c.shape[2], c.shape[3], c.shape[4]]) : c;
}

var conv3DBackpropInput$3 = op$1({
  conv3DBackpropInput_: conv3DBackpropInput_$1
});

function conv3dTranspose_$1(e, t, n, r, a) {
  var s = convertToTensor$1(e, "x", "conv3dTranspose"),
      o = convertToTensor$1(t, "filter", "conv3dTranspose");
  return conv3DBackpropInput$3(n, s, o, r, a);
}

var conv3dTranspose$2 = op$1({
  conv3dTranspose_: conv3dTranspose_$1
});

function cos_$1(e) {
  var t = convertToTensor$1(e, "x", "cos");
  return ENGINE$1.runKernel(Cos$1, {
    x: t
  });
}

var cos$5 = op$1({
  cos_: cos_$1
});

function cosh_$1(e) {
  var t = convertToTensor$1(e, "x", "cosh");
  return ENGINE$1.runKernel(Cosh$1, {
    x: t
  });
}

var cosh$5 = op$1({
  cosh_: cosh_$1
});

function cumsum_$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
  var a = convertToTensor$1(e, "x", "cumsum");
  return ENGINE$1.runKernel(Cumsum$1, {
    x: a
  }, {
    axis: t,
    exclusive: n,
    reverse: r
  });
}

var cumsum$5 = op$1({
  cumsum_: cumsum_$1
});

function depthToSpace_$1(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : "NHWC";
  var r = convertToTensor$1(e, "x", "depthToSpace"),
      a = "NHWC" === n ? r.shape[1] : r.shape[2],
      s = "NHWC" === n ? r.shape[2] : r.shape[3],
      o = "NHWC" === n ? r.shape[3] : r.shape[1];
  return assert$6(a * t >= 0, () => "Negative dimension size caused by overflow when multiplying\n    ".concat(a, " and ").concat(t, "  for depthToSpace with input shape\n    ").concat(r.shape)), assert$6(s * t >= 0, () => "Negative dimension size caused by overflow when multiplying\n    ".concat(s, " and ").concat(t, " for depthToSpace with input shape\n        ").concat(r.shape)), assert$6(o % (t * t) == 0, () => "Dimension size must be evenly divisible by ".concat(t * t, " but is ").concat(o, " for depthToSpace with input shape ").concat(r.shape)), ENGINE$1.runKernel(DepthToSpace$1, {
    x: r
  }, {
    blockSize: t,
    dataFormat: n
  });
}

var depthToSpace$5 = op$1({
  depthToSpace_: depthToSpace_$1
});

function depthwiseConv2d_$1(e, t, n, r) {
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : "NHWC";
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : [1, 1];
  var o = arguments.length > 6 ? arguments[6] : undefined;
  var i = convertToTensor$1(e, "x", "depthwiseConv2d"),
      l = convertToTensor$1(t, "filter", "depthwiseConv2d");
  var u = i,
      c = !1;
  3 === i.rank && (c = !0, u = reshape$6(i, [1, i.shape[0], i.shape[1], i.shape[2]])), assert$6(4 === u.rank, () => "Error in depthwiseConv2d: input must be rank 4, but got rank ".concat(u.rank, ".")), assert$6(4 === l.rank, () => "Error in depthwiseConv2d: filter must be rank 4, but got rank ".concat(l.rank, ".")), assert$6(u.shape[3] === l.shape[2], () => "Error in depthwiseConv2d: number of input channels (".concat(u.shape[3], ") must match the inChannels dimension in filter ").concat(l.shape[2], ".")), null != o && assert$6(isInt$1(r), () => "Error in depthwiseConv2d: pad must be an integer when using, dimRoundingMode ".concat(o, " but got pad ").concat(r, "."));
  var p = ENGINE$1.runKernel(DepthwiseConv2dNative$1, {
    x: u,
    filter: l
  }, {
    strides: n,
    pad: r,
    dataFormat: a,
    dilations: s,
    dimRoundingMode: o
  });
  return c ? reshape$6(p, [p.shape[1], p.shape[2], p.shape[3]]) : p;
}

var depthwiseConv2d$5 = op$1({
  depthwiseConv2d_: depthwiseConv2d_$1
});

function dilation2d_$1(e, t, n, r) {
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : [1, 1];
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : "NHWC";
  var o = convertToTensor$1(e, "x", "dilation2d"),
      i = convertToTensor$1(t, "filter", "dilation2d");
  assert$6(3 === o.rank || 4 === o.rank, () => "Error in dilation2d: input must be rank 3 or 4, but got rank ".concat(o.rank, ".")), assert$6(3 === i.rank, () => "Error in dilation2d: filter must be rank 3, but got rank ".concat(i.rank, ".")), assert$6("NHWC" === s, () => "Error in dilation2d: Only NHWC is currently supported, but got dataFormat of ".concat(s));
  var l = o,
      u = !1;
  3 === o.rank && (l = reshape$6(o, [1, o.shape[0], o.shape[1], o.shape[2]]), u = !0);
  var c = ENGINE$1.runKernel(Dilation2D$1, {
    x: l,
    filter: i
  }, {
    strides: n,
    pad: r,
    dilations: a
  });
  return u ? reshape$6(c, [c.shape[1], c.shape[2], c.shape[3]]) : c;
}

var dilation2d$1 = op$1({
  dilation2d_: dilation2d_$1
});

function getBroadcastDims$3(e, t) {
  var n = e.length,
      r = [];

  for (var a = 0; a < n; a++) {
    var s = n - 1 - a,
        o = e[s] || 1;
    (t[t.length - 1 - a] || 1) > 1 && 1 === o && r.unshift(s);
  }

  return r;
}

function getReductionAxes$1(e, t) {
  var n = [];

  for (var r = 0; r < t.length; r++) {
    var a = e[e.length - r - 1],
        s = t.length - r - 1,
        o = t[s];
    (null == a || 1 === a && o > 1) && n.unshift(s);
  }

  return n;
}

function assertAndGetBroadcastShape$1(e, t) {
  var n = [],
      r = Math.max(e.length, t.length);

  for (var a = 0; a < r; a++) {
    var _r15 = e[e.length - a - 1];
    null == _r15 && (_r15 = 1);
    var s = t[t.length - a - 1];
    if (null == s && (s = 1), 1 === _r15) n.unshift(s);else if (1 === s) n.unshift(_r15);else {
      if (_r15 !== s) throw Error("Operands could not be broadcast together with shapes ".concat(e, " and ").concat(t, "."));
      n.unshift(_r15);
    }
  }

  return n;
}

function equal_$1(e, t) {
  var n = convertToTensor$1(e, "a", "equal", "string_or_numeric"),
      r = convertToTensor$1(t, "b", "equal", "string_or_numeric");
  return [n, r] = makeTypesMatch$1(n, r), assertAndGetBroadcastShape$1(n.shape, r.shape), ENGINE$1.runKernel(Equal$1, {
    a: n,
    b: r
  });
}

var equal$5 = op$1({
  equal_: equal_$1
});

function where_$1(e, t, n) {
  var r = convertToTensor$1(t, "a", "where"),
      a = convertToTensor$1(n, "b", "where"),
      s = convertToTensor$1(e, "condition", "where", "bool"),
      o = assertAndGetBroadcastShape$1(assertAndGetBroadcastShape$1(s.shape, r.shape), a.shape),
      i = broadcastTo$1(s, o),
      l = broadcastTo$1(r, o),
      u = broadcastTo$1(a, o);
  return ENGINE$1.runKernel(Select$1, {
    condition: i,
    t: l,
    e: u
  });
}

var where$1 = op$1({
  where_: where_$1
});

function zerosLike_$1(e) {
  var t = convertToTensor$1(e, "x", "zerosLike");
  return ENGINE$1.runKernel(ZerosLike$1, {
    x: t
  });
}

var zerosLike$5 = op$1({
  zerosLike_: zerosLike_$1
});

function divNoNan_$1(e, t) {
  var n = convertToTensor$1(e, "a", "div"),
      r = convertToTensor$1(t, "b", "div");
  [n, r] = makeTypesMatch$1(n, r);
  var a = div$3(n, r),
      s = zerosLike$5(a),
      o = equal$5(r, s);
  return where$1(o, s, a);
}

var divNoNan$1 = op$1({
  divNoNan_: divNoNan_$1
});

function dot_$1(e, t) {
  var n = convertToTensor$1(e, "t1", "dot"),
      r = convertToTensor$1(t, "t2", "dot");
  assert$6(!(1 !== n.rank && 2 !== n.rank || 1 !== r.rank && 2 !== r.rank), () => "Error in dot: inputs must all be rank 1 or 2, but got ranks ".concat(n.rank, " and ").concat(r.rank, "."));
  var a = 1 === n.rank ? n.size : n.shape[1],
      s = 1 === r.rank ? r.size : r.shape[0];

  if (assert$6(a === s, () => "Error in dot: inner dimensions of inputs must match, but got ".concat(a, " and ").concat(s, ".")), 1 === n.rank && 1 === r.rank) {
    var _e47 = reshape$6(n, [1, -1]),
        _t45 = reshape$6(r, [-1, 1]),
        _a10 = matMul$3(_e47, _t45);

    return reshape$6(_a10, []);
  }

  if (1 === n.rank && 2 === r.rank) {
    var _e48 = reshape$6(n, [1, -1]),
        _t46 = reshape$6(r, [r.shape[0], r.shape[1]]),
        _a11 = matMul$3(_e48, _t46);

    return reshape$6(_a11, [_a11.size]);
  }

  if (2 === n.rank && 1 === r.rank) {
    var _e49 = reshape$6(r, [-1, 1]),
        _t47 = matMul$3(n, _e49);

    return reshape$6(_t47, [_t47.size]);
  }

  {
    var _e50 = reshape$6(r, [r.shape[0], r.shape[1]]);

    return matMul$3(n, _e50);
  }
}

var dot$4 = op$1({
  dot_: dot_$1
});

function elu_$1(e) {
  var t = convertToTensor$1(e, "x", "elu");
  return ENGINE$1.runKernel(Elu$3, {
    x: t
  });
}

var elu$8 = op$1({
  elu_: elu_$1
});

function erf_$1(e) {
  var t = convertToTensor$1(e, "x", "erf");
  return assert$6("int32" === t.dtype || "float32" === t.dtype, () => "Input dtype must be `int32` or `float32`."), "int32" === t.dtype && (t = cast$7(t, "float32")), ENGINE$1.runKernel(Erf$1, {
    x: t
  });
}

var erf$5 = op$1({
  erf_: erf_$1
});

function exp_$1(e) {
  var t = convertToTensor$1(e, "x", "exp");
  return ENGINE$1.runKernel(Exp$1, {
    x: t
  });
}

var exp$5 = op$1({
  exp_: exp_$1
});

function expandDims_$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;
  var n = convertToTensor$1(e, "x", "expandDims", "string_or_numeric");
  return assert$6(t <= n.rank, () => "Axis must be <= rank of the tensor"), ENGINE$1.runKernel(ExpandDims$1, {
    input: n
  }, {
    dim: t
  });
}

var expandDims$7 = op$1({
  expandDims_: expandDims_$1
});

function expm1_$1(e) {
  var t = convertToTensor$1(e, "x", "expm1");
  return ENGINE$1.runKernel(Expm1$1, {
    x: t
  });
}

var expm1$5 = op$1({
  expm1_: expm1_$1
});

function tile_$1(e, t) {
  var n = convertToTensor$1(e, "x", "tile", "string_or_numeric");
  return assert$6(n.rank === t.length, () => "Error in transpose: rank of input ".concat(n.rank, " must match length of reps ").concat(t, ".")), ENGINE$1.runKernel(Tile$1, {
    x: n
  }, {
    reps: t
  });
}

var tile$7 = op$1({
  tile_: tile_$1
});

function eye_$1(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : "float32";
  null == t && (t = e);
  var a = buffer$1([e, t], r),
      s = e <= t ? e : t;

  for (var _e51 = 0; _e51 < s; ++_e51) {
    a.set(1, _e51, _e51);
  }

  var o = reshape$6(a.toTensor(), [e, t]);
  if (null == n) return o;
  if (1 === n.length) return tile$7(expandDims$7(o, 0), [n[0], 1, 1]);
  if (2 === n.length) return tile$7(expandDims$7(expandDims$7(o, 0), 0), [n[0], n[1], 1, 1]);
  if (3 === n.length) return tile$7(expandDims$7(expandDims$7(expandDims$7(o, 0), 0), 0), [n[0], n[1], n[2], 1, 1]);
  throw new Error("eye() currently supports only 1D and 2D batchShapes, but received ".concat(n.length, "D."));
}

var eye$1 = op$1({
  eye_: eye_$1
});

function fill$5(e, t, n) {
  return ENGINE$1.runKernel(Fill$1, {}, {
    shape: e,
    value: t,
    dtype: n
  });
}

function floor_$1(e) {
  var t = convertToTensor$1(e, "x", "floor");
  return ENGINE$1.runKernel(Floor$1, {
    x: t
  });
}

var floor$5 = op$1({
  floor_: floor_$1
});

function gather_$1(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 0;
  var a = convertToTensor$1(e, "x", "gather"),
      s = convertToTensor$1(t, "indices", "gather", "int32");
  return ENGINE$1.runKernel(GatherV2$1, {
    x: a,
    indices: s
  }, {
    axis: n,
    batchDims: r
  });
}

var gather$3 = op$1({
  gather_: gather_$1
});

function greater_$1(e, t) {
  var n = convertToTensor$1(e, "a", "greater", "string_or_numeric"),
      r = convertToTensor$1(t, "b", "greater", "string_or_numeric");
  return [n, r] = makeTypesMatch$1(n, r), assertAndGetBroadcastShape$1(n.shape, r.shape), ENGINE$1.runKernel(Greater$1, {
    a: n,
    b: r
  });
}

var greater$6 = op$1({
  greater_: greater_$1
});

function greaterEqual_$1(e, t) {
  var n = convertToTensor$1(e, "a", "greaterEqual", "string_or_numeric"),
      r = convertToTensor$1(t, "b", "greaterEqual", "string_or_numeric");
  return [n, r] = makeTypesMatch$1(n, r), assertAndGetBroadcastShape$1(n.shape, r.shape), ENGINE$1.runKernel(GreaterEqual$1, {
    a: n,
    b: r
  });
}

var greaterEqual$5 = op$1({
  greaterEqual_: greaterEqual_$1
});

function imag_$1(e) {
  var t = convertToTensor$1(e, "input", "imag");
  return ENGINE$1.runKernel(Imag$1, {
    input: t
  });
}

var imag$5 = op$1({
  imag_: imag_$1
});

function isFinite_$1(e) {
  var t = convertToTensor$1(e, "x", "isFinite");
  return ENGINE$1.runKernel(IsFinite$1, {
    x: t
  });
}

var isFinite$6 = op$1({
  isFinite_: isFinite_$1
});

function isInf_$1(e) {
  var t = convertToTensor$1(e, "x", "isInf");
  return ENGINE$1.runKernel(IsInf$1, {
    x: t
  });
}

var isInf$5 = op$1({
  isInf_: isInf_$1
});

function isNaN_$1(e) {
  var t = convertToTensor$1(e, "x", "isNaN");
  return ENGINE$1.runKernel(IsNan$1, {
    x: t
  });
}

var isNaN$6 = op$1({
  isNaN_: isNaN_$1
});

function leakyRelu_$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : .2;
  var n = convertToTensor$1(e, "x", "leakyRelu");
  return ENGINE$1.runKernel(LeakyRelu$1, {
    x: n
  }, {
    alpha: t
  });
}

var leakyRelu$5 = op$1({
  leakyRelu_: leakyRelu_$1
});

function less_$1(e, t) {
  var n = convertToTensor$1(e, "a", "less", "string_or_numeric"),
      r = convertToTensor$1(t, "b", "less", "string_or_numeric");
  return [n, r] = makeTypesMatch$1(n, r), assertAndGetBroadcastShape$1(n.shape, r.shape), ENGINE$1.runKernel(Less$1, {
    a: n,
    b: r
  });
}

var less$6 = op$1({
  less_: less_$1
});

function lessEqual_$1(e, t) {
  var n = convertToTensor$1(e, "a", "lessEqual", "string_or_numeric"),
      r = convertToTensor$1(t, "b", "lessEqual", "string_or_numeric");
  return [n, r] = makeTypesMatch$1(n, r), assertAndGetBroadcastShape$1(n.shape, r.shape), ENGINE$1.runKernel(LessEqual$1, {
    a: n,
    b: r
  });
}

var lessEqual$5 = op$1({
  lessEqual_: lessEqual_$1
});

function localResponseNormalization_$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 5;
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 1;
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 1;
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : .5;
  var s = convertToTensor$1(e, "x", "localResponseNormalization");
  assert$6(4 === s.rank || 3 === s.rank, () => "Error in localResponseNormalization: x must be rank 3 or 4 but got\n               rank ".concat(s.rank, ".")), assert$6(isInt$1(t), () => "Error in localResponseNormalization: depthRadius must be an integer but got depthRadius ".concat(t, "."));
  var o = s,
      i = !1;
  3 === s.rank && (i = !0, o = reshape$6(s, [1, s.shape[0], s.shape[1], s.shape[2]]));
  var l = ENGINE$1.runKernel(LRN$1, {
    x: o
  }, {
    depthRadius: t,
    bias: n,
    alpha: r,
    beta: a
  });
  return i ? reshape$6(l, [l.shape[1], l.shape[2], l.shape[3]]) : l;
}

var localResponseNormalization$1 = op$1({
  localResponseNormalization_: localResponseNormalization_$1
});

function log_$1(e) {
  var t = convertToTensor$1(e, "x", "log");
  return ENGINE$1.runKernel(Log$1, {
    x: t
  });
}

var log$7 = op$1({
  log_: log_$1
});

function log1p_$1(e) {
  var t = convertToTensor$1(e, "x", "log1p");
  return ENGINE$1.runKernel(Log1p$1, {
    x: t
  });
}

var log1p$5 = op$1({
  log1p_: log1p_$1
});

function variableGrads$1(e, t) {
  assert$6(isFunction$1(e), () => "The f passed in variableGrads(f) must be a function"), assert$6(null == t || Array.isArray(t) && t.every(e => e instanceof Variable$1), () => "The varList passed in variableGrads(f, varList) must be an array of variables");
  var n = null != t;

  if (!n) {
    t = [];

    for (var _e52 in ENGINE$1.registeredVariables) {
      t.push(ENGINE$1.registeredVariables[_e52]);
    }
  }

  var r = n ? t.filter(e => !e.trainable) : null,
      a = t.length;
  t = t.filter(e => e.trainable), assert$6(t.length > 0, () => "variableGrads() expects at least one of the input variables to be trainable, but none of the ".concat(a, " variables is trainable."));
  var {
    value: s,
    grads: o
  } = ENGINE$1.gradients(e, t, null, !0);
  assert$6(o.some(e => null != e), () => "Cannot find a connection between any variable and the result of the loss function y=f(x). Please make sure the operations that use variables are inside the function f passed to minimize()."), assert$6(0 === s.rank, () => "The f passed in variableGrads(f) must return a scalar, but it returned a rank-".concat(s.rank, " tensor"));
  var i = {};
  return t.forEach((e, t) => {
    null != o[t] && (i[e.name] = o[t]);
  }), null != r && r.forEach(e => i[e.name] = null), {
    value: s,
    grads: i
  };
}

function customGrad$1(e) {
  return ENGINE$1.customGrad(e);
}

function neg_$1(e) {
  var t = convertToTensor$1(e, "x", "neg");
  return ENGINE$1.runKernel(Neg$1, {
    x: t
  });
}

var neg$5 = op$1({
  neg_: neg_$1
});

function softplus_$1(e) {
  var t = convertToTensor$1(e, "x", "softplus");
  return ENGINE$1.runKernel(Softplus$3, {
    x: t
  });
}

var softplus$5 = op$1({
  softplus_: softplus_$1
});

function logSigmoid_$1(e) {
  var t = convertToTensor$1(e, "x", "logSigmoid"),
      n = customGrad$1(e => ({
    value: neg$5(softplus$5(neg$5(e))),
    gradFunc: t => mul$1(t, sigmoid$5(neg$5(e)))
  }));
  return n(t);
}

var logSigmoid$1 = op$1({
  logSigmoid_: logSigmoid_$1
});

function max_$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  var r = convertToTensor$1(e, "x", "max");
  return ENGINE$1.runKernel(Max$1, {
    x: r
  }, {
    reductionIndices: t,
    keepDims: n
  });
}

var max$7 = op$1({
  max_: max_$1
});

function sub_$1(e, t) {
  var n = convertToTensor$1(e, "a", "sub"),
      r = convertToTensor$1(t, "b", "sub");
  return [n, r] = makeTypesMatch$1(n, r), ENGINE$1.runKernel(Sub$1, {
    a: n,
    b: r
  });
}

var sub$5 = op$1({
  sub_: sub_$1
});

function sum_$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  var r = convertToTensor$1(e, "x", "sum");
  return "bool" === r.dtype && (r = cast$7(r, "int32")), ENGINE$1.runKernel(Sum$1, {
    x: r
  }, {
    axis: t,
    keepDims: n
  });
}

var sum$6 = op$1({
  sum_: sum_$1
});

function logSoftmax_$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : -1;
  var n = convertToTensor$1(e, "logits", "logSoftmax");
  if (-1 === t && (t = n.rank - 1), t !== n.rank - 1) throw Error("Log Softmax along a non-last dimension is not yet supported. Logits was rank ".concat(n.rank, " and axis was ").concat(t));
  var r = customGrad$1((e, n) => {
    var r = max$7(e, t, !0),
        a = sub$5(e, r),
        s = sub$5(cast$7(a, "float32"), log$7(sum$6(exp$5(a), t, !0)));
    return n([s]), {
      value: s,
      gradFunc: (e, n) => {
        var [r] = n,
            a = exp$5(r);
        return sub$5(e, mul$1(sum$6(e, t, !0), a));
      }
    };
  });
  return r(n);
}

var logSoftmax$1 = op$1({
  logSoftmax_: logSoftmax_$1
});

function axesAreInnerMostDims$1(e, t) {
  for (var n = 0; n < e.length; ++n) {
    if (e[e.length - n - 1] !== t - 1 - n) return !1;
  }

  return !0;
}

function combineLocations$1(e, t, n) {
  var r = e.length + t.length,
      a = [];
  var s = 0,
      o = 0;

  for (var i = 0; i < r; i++) {
    -1 === n.indexOf(i) ? a.push(e[s++]) : a.push(t[o++]);
  }

  return a;
}

function computeOutAndReduceShapes$1(e, t) {
  var n = [],
      r = e.length;

  for (var a = 0; a < r; a++) {
    -1 === t.indexOf(a) && n.push(e[a]);
  }

  return [n, t.map(t => e[t])];
}

function expandShapeToKeepDim$1(e, t) {
  return combineLocations$1(e, t.map(e => 1), t);
}

function assertAxesAreInnerMostDims$1(e, t, n) {
  assert$6(axesAreInnerMostDims$1(t, n), () => "".concat(e, " supports only inner-most axes for now. Got axes ").concat(t, " and rank-").concat(n, " input."));
}

function getAxesPermutation$1(e, t) {
  if (axesAreInnerMostDims$1(e, t)) return null;
  var n = [];

  for (var r = 0; r < t; ++r) {
    -1 === e.indexOf(r) && n.push(r);
  }

  return e.forEach(e => n.push(e)), n;
}

function getUndoAxesPermutation$1(e) {
  return e.map((e, t) => [t, e]).sort((e, t) => e[1] - t[1]).map(e => e[0]);
}

function getInnerMostAxes$1(e, t) {
  var n = [];

  for (var r = t - e; r < t; ++r) {
    n.push(r);
  }

  return n;
}

function logSumExp_$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  var r = convertToTensor$1(e, "x", "logSumExp"),
      a = parseAxisParam$1(t, r.shape),
      s = max$7(r, a, !0),
      o = sub$5(r, s),
      i = exp$5(o),
      l = sum$6(i, a),
      u = log$7(l),
      c = add$5(reshape$6(s, u.shape), u);

  if (n) {
    var _e53 = expandShapeToKeepDim$1(c.shape, a);

    return reshape$6(c, _e53);
  }

  return c;
}

var logSumExp$1 = op$1({
  logSumExp_: logSumExp_$1
});

function logicalAnd_$1(e, t) {
  var n = convertToTensor$1(e, "a", "logicalAnd", "bool"),
      r = convertToTensor$1(t, "b", "logicalAnd", "bool");
  return assertAndGetBroadcastShape$1(n.shape, r.shape), ENGINE$1.runKernel(LogicalAnd$1, {
    a: n,
    b: r
  });
}

var logicalAnd$5 = op$1({
  logicalAnd_: logicalAnd_$1
});

function logicalNot_$1(e) {
  var t = convertToTensor$1(e, "x", "logicalNot", "bool");
  return ENGINE$1.runKernel(LogicalNot$1, {
    x: t
  });
}

var logicalNot$5 = op$1({
  logicalNot_: logicalNot_$1
});

function logicalOr_$1(e, t) {
  var n = convertToTensor$1(e, "a", "logicalOr", "bool"),
      r = convertToTensor$1(t, "b", "logicalOr", "bool");
  return assertAndGetBroadcastShape$1(n.shape, r.shape), ENGINE$1.runKernel(LogicalOr$1, {
    a: n,
    b: r
  });
}

var logicalOr$5 = op$1({
  logicalOr_: logicalOr_$1
});

function logicalXor_$1(e, t) {
  var n = convertToTensor$1(e, "a", "logicalXor", "bool"),
      r = convertToTensor$1(t, "b", "logicalXor", "bool");
  return assertAndGetBroadcastShape$1(n.shape, r.shape), logicalAnd$5(logicalOr$5(e, t), logicalNot$5(logicalAnd$5(e, t)));
}

var logicalXor$1 = op$1({
  logicalXor_: logicalXor_$1
});

function maxPool_$1(e, t, n, r, a) {
  var s = convertToTensor$1(e, "x", "maxPool");
  var o = s,
      i = !1;
  3 === s.rank && (i = !0, o = reshape$6(s, [1, s.shape[0], s.shape[1], s.shape[2]])), assert$6(4 === o.rank, () => "Error in maxPool: input must be rank 4 but got rank ".concat(o.rank, ".")), assert$6(eitherStridesOrDilationsAreOne$1(n, 1), () => "Error in maxPool: Either strides or dilations must be 1. Got strides ".concat(n, " and dilations '1'")), null != a && assert$6(isInt$1(r), () => "Error in maxPool: pad must be an integer when using, dimRoundingMode ".concat(a, " but got pad ").concat(r, "."));
  var l = ENGINE$1.runKernel(MaxPool$1, {
    x: o
  }, {
    filterSize: t,
    strides: n,
    pad: r,
    dimRoundingMode: a
  });
  return i ? reshape$6(l, [l.shape[1], l.shape[2], l.shape[3]]) : l;
}

var maxPool$5 = op$1({
  maxPool_: maxPool_$1
});

function maxPool3d_$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : [1, 1, 1];
  var n = arguments.length > 2 ? arguments[2] : undefined;
  var r = arguments.length > 3 ? arguments[3] : undefined;
  var a = arguments.length > 4 ? arguments[4] : undefined;
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : "NDHWC";
  var o = convertToTensor$1(e, "x", "maxPool3d");
  var i = o,
      l = !1;
  4 === o.rank && (l = !0, i = reshape$6(o, [1, o.shape[0], o.shape[1], o.shape[2], o.shape[3]])), assert$6(5 === i.rank, () => "Error in maxPool3d: x must be rank 5 but got rank ".concat(i.rank, ".")), assert$6("NDHWC" === s, () => "Error in maxPool3d: Only NDHWC is currently supported, but got dataFormat of ".concat(s)), null != a && assert$6(isInt$1(r), () => "Error in maxPool3d: pad must be an integer when using, dimRoundingMode ".concat(a, " but got pad ").concat(r, "."));
  var u = ENGINE$1.runKernel(MaxPool3D$1, {
    x: i
  }, {
    filterSize: t,
    strides: n,
    pad: r,
    dimRoundingMode: a,
    dataFormat: s
  });
  return l ? reshape$6(u, [u.shape[1], u.shape[2], u.shape[3], u.shape[4]]) : u;
}

var maxPool3d$3 = op$1({
  maxPool3d_: maxPool3d_$1
});

function maximum_$1(e, t) {
  var n = convertToTensor$1(e, "a", "maximum"),
      r = convertToTensor$1(t, "b", "maximum");
  return [n, r] = makeTypesMatch$1(n, r), "bool" === n.dtype && (n = cast$7(n, "int32"), r = cast$7(r, "int32")), assertAndGetBroadcastShape$1(n.shape, r.shape), ENGINE$1.runKernel(Maximum$3, {
    a: n,
    b: r
  });
}

var maximum$6 = op$1({
  maximum_: maximum_$1
});

function mean_$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  var r = convertToTensor$1(e, "x", "mean");
  return ENGINE$1.runKernel(Mean$1, {
    x: r
  }, {
    axis: t,
    keepDims: n
  });
}

var mean$3 = op$1({
  mean_: mean_$1
});

function zeros$4(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : "float32";

  if ("complex64" === t) {
    var _t48 = zeros$4(e, "float32"),
        _n12 = zeros$4(e, "float32");

    return complex$5(_t48, _n12);
  }

  var n = makeZerosTypedArray$1(sizeFromShape$1(e), t);
  return ENGINE$1.makeTensor(n, e, t);
}

function ones$3(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : "float32";

  if ("complex64" === t) {
    var _t49 = ones$3(e, "float32"),
        _n13 = zeros$4(e, "float32");

    return complex$5(_t49, _n13);
  }

  var n = makeOnesTypedArray$1(sizeFromShape$1(e), t);
  return ENGINE$1.makeTensor(n, e, t);
}

function min_$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  var r = convertToTensor$1(e, "x", "min");
  return ENGINE$1.runKernel(Min$1, {
    x: r
  }, {
    axis: t,
    keepDims: n
  });
}

var min$7 = op$1({
  min_: min_$1
});

function minimum_$1(e, t) {
  var n = convertToTensor$1(e, "a", "minimum"),
      r = convertToTensor$1(t, "b", "minimum");
  return [n, r] = makeTypesMatch$1(n, r), "bool" === n.dtype && (n = cast$7(n, "int32"), r = cast$7(r, "int32")), assertAndGetBroadcastShape$1(n.shape, r.shape), ENGINE$1.runKernel(Minimum$3, {
    a: n,
    b: r
  });
}

var minimum$6 = op$1({
  minimum_: minimum_$1
});

function mirrorPad_$1(e, t, n) {
  assert$6("reflect" === n || "symmetric" === n, () => "Invalid mode. Mode must be either reflect or symmetric. Got ".concat(n, "."));
  var r = convertToTensor$1(e, "x", "mirrorPad");
  if (0 === r.rank) throw new Error("mirrorPad(scalar) is not defined. Pass non-scalar to mirrorPad");
  assert$6(t.length === r.rank, () => "Padding doesn't match input. Must be ".concat(r.rank, ". Got ").concat(t.length, "."));
  var a = "reflect" === n ? 1 : 0;

  var _loop5 = function _loop5(_e54) {
    assert$6(2 === t[_e54].length, () => "Invalid number of paddings. Must be length of 2 each."), assert$6(t[_e54][0] >= 0 && t[_e54][0] <= r.shape[_e54] - a && t[_e54][1] >= 0 && t[_e54][1] <= r.shape[_e54] - a, () => "Padding in dimension ".concat(_e54, " cannot be greater than or equal to ").concat(r.shape[_e54] - a, " or less than 0 for input of shape ").concat(r.shape));
  };

  for (var _e54 = 0; _e54 < r.rank; _e54++) {
    _loop5(_e54);
  }

  return ENGINE$1.runKernel(MirrorPad$1, {
    x: r
  }, {
    paddings: t,
    mode: n
  });
}

var mirrorPad$3 = op$1({
  mirrorPad_: mirrorPad_$1
});

function mod_$1(e, t) {
  var n = convertToTensor$1(e, "a", "mod"),
      r = convertToTensor$1(t, "b", "mod");
  return [n, r] = makeTypesMatch$1(n, r), ENGINE$1.runKernel(Mod$1, {
    a: n,
    b: r
  });
}

var mod$5 = op$1({
  mod_: mod_$1
});

function square_$1(e) {
  var t = convertToTensor$1(e, "x", "square");
  return ENGINE$1.runKernel("Square", {
    x: t
  }, {});
}

var square$5 = op$1({
  square_: square_$1
});

function moments_$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  var r = parseAxisParam$1(t, (e = convertToTensor$1(e, "x", "moments")).shape),
      a = mean$3(e, r, n);
  var s = a.shape;
  n || (s = expandShapeToKeepDim$1(a.shape, r));
  var o = square$5(sub$5(cast$7(e, "float32"), reshape$6(a, s)));
  return {
    mean: a,
    variance: mean$3(o, r, n)
  };
}

var moments$1 = op$1({
  moments_: moments_$1
});

function notEqual_$1(e, t) {
  var n = convertToTensor$1(e, "a", "notEqual", "string_or_numeric"),
      r = convertToTensor$1(t, "b", "notEqual", "string_or_numeric");
  return [n, r] = makeTypesMatch$1(n, r), assertAndGetBroadcastShape$1(n.shape, r.shape), ENGINE$1.runKernel(NotEqual$1, {
    a: n,
    b: r
  });
}

var notEqual$5 = op$1({
  notEqual_: notEqual_$1
});

function onesLike_$1(e) {
  var t = convertToTensor$1(e, "x", "onesLike");
  return ENGINE$1.runKernel(OnesLike$1, {
    x: t
  });
}

var onesLike$5 = op$1({
  onesLike_: onesLike_$1
});

function pad_$1(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;
  var r = convertToTensor$1(e, "x", "pad");
  if (0 === r.rank) throw new Error("pad(scalar) is not defined. Pass non-scalar to pad");
  return ENGINE$1.runKernel(PadV2$1, {
    x: r
  }, {
    paddings: t,
    constantValue: n
  });
}

var pad$1 = op$1({
  pad_: pad_$1
});

function spaceToBatchND_$1(e, t, n) {
  var r = convertToTensor$1(e, "x", "spaceToBatchND");
  return assert$6(r.rank >= 1 + t.length, () => "input rank ".concat(r.rank, " should be > than [blockShape] ").concat(t.length)), assert$6(n.length === t.length, () => "paddings.shape[0] ".concat(n.length, " must be equal to [blockShape] ").concat(t.length)), assert$6(r.shape.reduce((e, r, a) => a > 0 && a <= t.length ? e && (r + n[a - 1][0] + n[a - 1][1]) % t[a - 1] == 0 : e, !0), () => "input spatial dimensions ".concat(r.shape.slice(1), " with paddings ").concat(n.toString(), " must be divisible by blockShapes ").concat(t.toString())), ENGINE$1.runKernel(SpaceToBatchND$1, {
    x: r
  }, {
    blockShape: t,
    paddings: n
  });
}

var spaceToBatchND$5 = op$1({
  spaceToBatchND_: spaceToBatchND_$1
});

function pool_$1(e, t, n, r, a, s) {
  null == a && (a = [1, 1]), null == s && (s = 1), 0 === r && (r = "valid");
  var o = convertToTensor$1(e, "x", "maxPool");
  var i = o,
      l = !1;
  3 === o.rank && (l = !0, i = reshape$6(o, [1, o.shape[0], o.shape[1], o.shape[2]])), assert$6(eitherStridesOrDilationsAreOne$1(s, a), () => "Error in pool: Either strides or dilations must be 1. Got strides ".concat(s, " and dilations '").concat(a, "'"));
  var u = computePool2DInfo$1(i.shape, t, s, a, r),
      c = [u.dilationHeight, u.dilationWidth];
  var p;
  p = "same" === r ? withSpaceToBatchBasePaddings$1([u.filterHeight, u.filterWidth], c) : [[0, 0], [0, 0]];
  var d = 1 === c[0] && 1 === c[1],
      [h, m] = requiredSpaceToBatchPaddings$1([u.inHeight, u.inWidth], c, p),
      f = d ? r : "valid",
      g = d ? i : spaceToBatchND$5(i, c, h),
      $ = ("avg" === n ? () => avgPool$5(g, t, s, f) : () => maxPool$5(g, t, s, f))(),
      y = d ? $ : batchToSpaceND$5($, c, m);
  return l ? reshape$6(y, [y.shape[1], y.shape[2], y.shape[3]]) : y;
}

function requiredSpaceToBatchPaddings$1(e, t, n) {
  var r = n.map(e => e[0]),
      a = n.map(e => e[1]),
      s = e.concat(r, a),
      o = t.map((e, t) => (e - s[t] % e) % e),
      i = a.map((e, t) => e + o[t]);
  return [t.map((e, t) => [r[t], i[t]]), t.map((e, t) => [0, o[t]])];
}

function withSpaceToBatchBasePaddings$1(e, t) {
  var n = e.map((e, n) => e + (e - 1) * (t[n] - 1)).map(e => e - 1),
      r = n.map(e => Math.floor(e / 2)),
      a = n.map((e, t) => e - r[t]);
  return n.map((e, t) => [r[t], a[t]]);
}

var pool$3 = op$1({
  pool_: pool_$1
});

function pow_$1(e, t) {
  var n = convertToTensor$1(e, "base", "pow"),
      r = convertToTensor$1(t, "exp", "pow");
  return [n, r] = makeTypesMatch$1(n, r), ENGINE$1.runKernel(Pow$1, {
    a: n,
    b: r
  });
}

var pow$5 = op$1({
  pow_: pow_$1
});

function prelu_$1(e, t) {
  var n = convertToTensor$1(e, "x", "prelu"),
      r = convertToTensor$1(t, "alpha", "prelu");
  return ENGINE$1.runKernel(Prelu$1, {
    x: n,
    alpha: r
  });
}

var prelu$6 = op$1({
  prelu_: prelu_$1
});

function prod_$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  var r = convertToTensor$1(e, "x", "prod");
  return "bool" === r.dtype && (r = cast$7(r, "int32")), ENGINE$1.runKernel(Prod$1, {
    x: r
  }, {
    axis: t,
    keepDims: n
  });
}

var prod$5 = op$1({
  prod_: prod_$1
});
var commonjsGlobal = "undefined" != typeof globalThis ? globalThis : "undefined" != typeof window ? window : "undefined" != typeof __webpack_require__.g ? __webpack_require__.g : "undefined" != typeof self ? self : {};

function createCommonjsModule(e) {
  var t = {
    exports: {}
  };
  return e(t, t.exports), t.exports;
}

var alea$1 = createCommonjsModule(function (e) {
  !function (e, t, n) {
    function r(e) {
      var t,
          n = this,
          r = (t = 4022871197, function (e) {
        e = e.toString();

        for (var n = 0; n < e.length; n++) {
          var r = .02519603282416938 * (t += e.charCodeAt(n));
          r -= t = r >>> 0, t = (r *= t) >>> 0, t += 4294967296 * (r -= t);
        }

        return 2.3283064365386963e-10 * (t >>> 0);
      });
      n.next = function () {
        var e = 2091639 * n.s0 + 2.3283064365386963e-10 * n.c;
        return n.s0 = n.s1, n.s1 = n.s2, n.s2 = e - (n.c = 0 | e);
      }, n.c = 1, n.s0 = r(" "), n.s1 = r(" "), n.s2 = r(" "), n.s0 -= r(e), n.s0 < 0 && (n.s0 += 1), n.s1 -= r(e), n.s1 < 0 && (n.s1 += 1), n.s2 -= r(e), n.s2 < 0 && (n.s2 += 1), r = null;
    }

    function a(e, t) {
      return t.c = e.c, t.s0 = e.s0, t.s1 = e.s1, t.s2 = e.s2, t;
    }

    function s(e, t) {
      var n = new r(e),
          s = t && t.state,
          o = n.next;
      return o.int32 = function () {
        return 4294967296 * n.next() | 0;
      }, o.double = function () {
        return o() + 11102230246251565e-32 * (2097152 * o() | 0);
      }, o.quick = o, s && ("object" == typeof s && a(s, n), o.state = function () {
        return a(n, {});
      }), o;
    }

    t && t.exports ? t.exports = s : this.alea = s;
  }(0, e);
}),
    xor128$1 = createCommonjsModule(function (e) {
  !function (e, t, n) {
    function r(e) {
      var t = this,
          n = "";
      t.x = 0, t.y = 0, t.z = 0, t.w = 0, t.next = function () {
        var e = t.x ^ t.x << 11;
        return t.x = t.y, t.y = t.z, t.z = t.w, t.w ^= t.w >>> 19 ^ e ^ e >>> 8;
      }, e === (0 | e) ? t.x = e : n += e;

      for (var r = 0; r < n.length + 64; r++) {
        t.x ^= 0 | n.charCodeAt(r), t.next();
      }
    }

    function a(e, t) {
      return t.x = e.x, t.y = e.y, t.z = e.z, t.w = e.w, t;
    }

    function s(e, t) {
      var n = new r(e),
          s = t && t.state,
          o = function o() {
        return (n.next() >>> 0) / 4294967296;
      };

      return o.double = function () {
        do {
          var e = ((n.next() >>> 11) + (n.next() >>> 0) / 4294967296) / (1 << 21);
        } while (0 === e);

        return e;
      }, o.int32 = n.next, o.quick = o, s && ("object" == typeof s && a(s, n), o.state = function () {
        return a(n, {});
      }), o;
    }

    t && t.exports ? t.exports = s : this.xor128 = s;
  }(0, e);
}),
    xorwow$1 = createCommonjsModule(function (e) {
  !function (e, t, n) {
    function r(e) {
      var t = this,
          n = "";
      t.next = function () {
        var e = t.x ^ t.x >>> 2;
        return t.x = t.y, t.y = t.z, t.z = t.w, t.w = t.v, (t.d = t.d + 362437 | 0) + (t.v = t.v ^ t.v << 4 ^ e ^ e << 1) | 0;
      }, t.x = 0, t.y = 0, t.z = 0, t.w = 0, t.v = 0, e === (0 | e) ? t.x = e : n += e;

      for (var r = 0; r < n.length + 64; r++) {
        t.x ^= 0 | n.charCodeAt(r), r == n.length && (t.d = t.x << 10 ^ t.x >>> 4), t.next();
      }
    }

    function a(e, t) {
      return t.x = e.x, t.y = e.y, t.z = e.z, t.w = e.w, t.v = e.v, t.d = e.d, t;
    }

    function s(e, t) {
      var n = new r(e),
          s = t && t.state,
          o = function o() {
        return (n.next() >>> 0) / 4294967296;
      };

      return o.double = function () {
        do {
          var e = ((n.next() >>> 11) + (n.next() >>> 0) / 4294967296) / (1 << 21);
        } while (0 === e);

        return e;
      }, o.int32 = n.next, o.quick = o, s && ("object" == typeof s && a(s, n), o.state = function () {
        return a(n, {});
      }), o;
    }

    t && t.exports ? t.exports = s : this.xorwow = s;
  }(0, e);
}),
    xorshift7$1 = createCommonjsModule(function (e) {
  !function (e, t, n) {
    function r(e) {
      var t = this;
      t.next = function () {
        var e,
            n,
            r = t.x,
            a = t.i;
        return e = r[a], n = (e ^= e >>> 7) ^ e << 24, n ^= (e = r[a + 1 & 7]) ^ e >>> 10, n ^= (e = r[a + 3 & 7]) ^ e >>> 3, n ^= (e = r[a + 4 & 7]) ^ e << 7, e = r[a + 7 & 7], r[a] = n ^= (e ^= e << 13) ^ e << 9, t.i = a + 1 & 7, n;
      }, function (e, t) {
        var n,
            r = [];
        if (t === (0 | t)) r[0] = t;else for (t = "" + t, n = 0; n < t.length; ++n) {
          r[7 & n] = r[7 & n] << 15 ^ t.charCodeAt(n) + r[n + 1 & 7] << 13;
        }

        for (; r.length < 8;) {
          r.push(0);
        }

        for (n = 0; n < 8 && 0 === r[n]; ++n) {
          ;
        }

        for (8 == n && (r[7] = -1), e.x = r, e.i = 0, n = 256; n > 0; --n) {
          e.next();
        }
      }(t, e);
    }

    function a(e, t) {
      return t.x = e.x.slice(), t.i = e.i, t;
    }

    function s(e, t) {
      null == e && (e = +new Date());

      var n = new r(e),
          s = t && t.state,
          o = function o() {
        return (n.next() >>> 0) / 4294967296;
      };

      return o.double = function () {
        do {
          var e = ((n.next() >>> 11) + (n.next() >>> 0) / 4294967296) / (1 << 21);
        } while (0 === e);

        return e;
      }, o.int32 = n.next, o.quick = o, s && (s.x && a(s, n), o.state = function () {
        return a(n, {});
      }), o;
    }

    t && t.exports ? t.exports = s : this.xorshift7 = s;
  }(0, e);
}),
    xor4096$1 = createCommonjsModule(function (e) {
  !function (e, t, n) {
    function r(e) {
      var t = this;
      t.next = function () {
        var e,
            n,
            r = t.w,
            a = t.X,
            s = t.i;
        return t.w = r = r + 1640531527 | 0, n = a[s + 34 & 127], e = a[s = s + 1 & 127], n ^= n << 13, e ^= e << 17, n = a[s] = (n ^= n >>> 15) ^ (e ^= e >>> 12), t.i = s, n + (r ^ r >>> 16) | 0;
      }, function (e, t) {
        var n,
            r,
            a,
            s,
            o,
            i = [],
            l = 128;

        for (t === (0 | t) ? (r = t, t = null) : (t += "\0", r = 0, l = Math.max(l, t.length)), a = 0, s = -32; s < l; ++s) {
          t && (r ^= t.charCodeAt((s + 32) % t.length)), 0 === s && (o = r), r ^= r << 10, r ^= r >>> 15, r ^= r << 4, r ^= r >>> 13, s >= 0 && (a = 0 == (n = i[127 & s] ^= r + (o = o + 1640531527 | 0)) ? a + 1 : 0);
        }

        for (a >= 128 && (i[127 & (t && t.length || 0)] = -1), a = 127, s = 512; s > 0; --s) {
          r = i[a + 34 & 127], n = i[a = a + 1 & 127], r ^= r << 13, n ^= n << 17, i[a] = (r ^= r >>> 15) ^ (n ^= n >>> 12);
        }

        e.w = o, e.X = i, e.i = a;
      }(t, e);
    }

    function a(e, t) {
      return t.i = e.i, t.w = e.w, t.X = e.X.slice(), t;
    }

    function s(e, t) {
      null == e && (e = +new Date());

      var n = new r(e),
          s = t && t.state,
          o = function o() {
        return (n.next() >>> 0) / 4294967296;
      };

      return o.double = function () {
        do {
          var e = ((n.next() >>> 11) + (n.next() >>> 0) / 4294967296) / (1 << 21);
        } while (0 === e);

        return e;
      }, o.int32 = n.next, o.quick = o, s && (s.X && a(s, n), o.state = function () {
        return a(n, {});
      }), o;
    }

    t && t.exports ? t.exports = s : this.xor4096 = s;
  }(0, e);
}),
    tychei$1 = createCommonjsModule(function (e) {
  !function (e, t, n) {
    function r(e) {
      var t = this,
          n = "";
      t.next = function () {
        var e = t.b,
            n = t.c,
            r = t.d,
            a = t.a;
        return e = e << 25 ^ e >>> 7 ^ n, n = n - r | 0, r = r << 24 ^ r >>> 8 ^ a, a = a - e | 0, t.b = e = e << 20 ^ e >>> 12 ^ n, t.c = n = n - r | 0, t.d = r << 16 ^ n >>> 16 ^ a, t.a = a - e | 0;
      }, t.a = 0, t.b = 0, t.c = -1640531527, t.d = 1367130551, e === Math.floor(e) ? (t.a = e / 4294967296 | 0, t.b = 0 | e) : n += e;

      for (var r = 0; r < n.length + 20; r++) {
        t.b ^= 0 | n.charCodeAt(r), t.next();
      }
    }

    function a(e, t) {
      return t.a = e.a, t.b = e.b, t.c = e.c, t.d = e.d, t;
    }

    function s(e, t) {
      var n = new r(e),
          s = t && t.state,
          o = function o() {
        return (n.next() >>> 0) / 4294967296;
      };

      return o.double = function () {
        do {
          var e = ((n.next() >>> 11) + (n.next() >>> 0) / 4294967296) / (1 << 21);
        } while (0 === e);

        return e;
      }, o.int32 = n.next, o.quick = o, s && ("object" == typeof s && a(s, n), o.state = function () {
        return a(n, {});
      }), o;
    }

    t && t.exports ? t.exports = s : this.tychei = s;
  }(0, e);
}),
    _nodeResolve_empty = {},
    _nodeResolve_empty$1 = {
  __proto__: null,
  default: _nodeResolve_empty
},
    seedrandom$3 = createCommonjsModule(function (e) {
  !function (t, n) {
    var r,
        a = this,
        s = 256,
        o = n.pow(s, 6),
        i = n.pow(2, 52),
        l = 2 * i,
        u = 255;

    function c(e, u, c) {
      var g = [],
          $ = m(h((u = 1 == u ? {
        entropy: !0
      } : u || {}).entropy ? [e, f(t)] : null == e ? function () {
        try {
          var e;
          return r && (e = r.randomBytes) ? e = e(s) : (e = new Uint8Array(s), (a.crypto || a.msCrypto).getRandomValues(e)), f(e);
        } catch (e) {
          var n = a.navigator,
              o = n && n.plugins;
          return [+new Date(), a, o, a.screen, f(t)];
        }
      }() : e, 3), g),
          y = new p(g),
          b = function b() {
        for (var e = y.g(6), t = o, n = 0; e < i;) {
          e = (e + n) * s, t *= s, n = y.g(1);
        }

        for (; e >= l;) {
          e /= 2, t /= 2, n >>>= 1;
        }

        return (e + n) / t;
      };

      return b.int32 = function () {
        return 0 | y.g(4);
      }, b.quick = function () {
        return y.g(4) / 4294967296;
      }, b.double = b, m(f(y.S), t), (u.pass || c || function (e, t, r, a) {
        return a && (a.S && d(a, y), e.state = function () {
          return d(y, {});
        }), r ? (n.random = e, t) : e;
      })(b, $, "global" in u ? u.global : this == n, u.state);
    }

    function p(e) {
      var t,
          n = e.length,
          r = this,
          a = 0,
          o = r.i = r.j = 0,
          i = r.S = [];

      for (n || (e = [n++]); a < s;) {
        i[a] = a++;
      }

      for (a = 0; a < s; a++) {
        i[a] = i[o = u & o + e[a % n] + (t = i[a])], i[o] = t;
      }

      (r.g = function (e) {
        for (var t, n = 0, a = r.i, o = r.j, i = r.S; e--;) {
          t = i[a = u & a + 1], n = n * s + i[u & (i[a] = i[o = u & o + t]) + (i[o] = t)];
        }

        return r.i = a, r.j = o, n;
      })(s);
    }

    function d(e, t) {
      return t.i = e.i, t.j = e.j, t.S = e.S.slice(), t;
    }

    function h(e, t) {
      var n,
          r = [],
          a = typeof e;
      if (t && "object" == a) for (n in e) {
        try {
          r.push(h(e[n], t - 1));
        } catch (e) {}
      }
      return r.length ? r : "string" == a ? e : e + "\0";
    }

    function m(e, t) {
      for (var n, r = e + "", a = 0; a < r.length;) {
        t[u & a] = u & (n ^= 19 * t[u & a]) + r.charCodeAt(a++);
      }

      return f(t);
    }

    function f(e) {
      return String.fromCharCode.apply(0, e);
    }

    if (n.seedrandom = c, m(n.random(), t), e.exports) {
      e.exports = c;

      try {
        r = _nodeResolve_empty$1;
      } catch (e) {}
    }
  }([], Math);
});
seedrandom$3.alea = alea$1, seedrandom$3.xor128 = xor128$1, seedrandom$3.xorwow = xorwow$1, seedrandom$3.xorshift7 = xorshift7$1, seedrandom$3.xor4096 = xor4096$1, seedrandom$3.tychei = tychei$1;
var seedrandom$2 = seedrandom$3;

class MPRandGauss$1 {
  constructor(e, t, n, r, a) {
    this.mean = e, this.stdDev = t, this.dtype = n, this.nextVal = NaN, this.truncated = r, this.truncated && (this.upper = this.mean + 2 * this.stdDev, this.lower = this.mean - 2 * this.stdDev);
    var s = a || Math.random();
    this.random = seedrandom$2.alea(s.toString());
  }

  nextValue() {
    if (!isNaN(this.nextVal)) {
      var _e55 = this.nextVal;
      return this.nextVal = NaN, _e55;
    }

    var e,
        t,
        n = !1;

    for (; !n;) {
      var r = void 0,
          a = void 0,
          s = void 0;

      do {
        r = 2 * this.random() - 1, a = 2 * this.random() - 1, s = r * r + a * a;
      } while (s >= 1 || 0 === s);

      var o = Math.sqrt(-2 * Math.log(s) / s);
      e = this.mean + this.stdDev * r * o, t = this.mean + this.stdDev * a * o, this.truncated && !this.isValidTruncated(e) || (n = !0);
    }

    return this.truncated && !this.isValidTruncated(t) || (this.nextVal = this.convertValue(t)), this.convertValue(e);
  }

  convertValue(e) {
    return null == this.dtype || "float32" === this.dtype ? e : Math.round(e);
  }

  isValidTruncated(e) {
    return e <= this.upper && e >= this.lower;
  }

}

class UniformRandom$1 {
  constructor() {
    var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 0;
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 1;
    var n = arguments.length > 2 ? arguments[2] : undefined;
    var r = arguments.length > 3 ? arguments[3] : undefined;
    if (this.canReturnFloat = () => null == this.dtype || "float32" === this.dtype, this.min = e, this.range = t - e, this.dtype = n, null == r && (r = Math.random()), "number" == typeof r && (r = r.toString()), !this.canReturnFloat() && this.range <= 1) throw new Error("The difference between ".concat(e, " - ").concat(t, " <= 1 and dtype is not float"));
    this.random = seedrandom$2.alea(r);
  }

  convertValue(e) {
    return this.canReturnFloat() ? e : Math.round(e);
  }

  nextValue() {
    return this.convertValue(this.min + this.range * this.random());
  }

}

function randomNormal_$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 1;
  var r = arguments.length > 3 ? arguments[3] : undefined;
  var a = arguments.length > 4 ? arguments[4] : undefined;
  if (null != r && "bool" === r) throw new Error("Unsupported data type ".concat(r));
  var s = new MPRandGauss$1(t, n, r, !1, a),
      o = buffer$1(e, r);

  for (var _e56 = 0; _e56 < o.values.length; _e56++) {
    o.values[_e56] = s.nextValue();
  }

  return o.toTensor();
}

var randomNormal$4 = op$1({
  randomNormal_: randomNormal_$1
});

function randomUniform_$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 1;
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : "float32";
  var a = arguments.length > 4 ? arguments[4] : undefined;
  var s = buffer$1(e, r),
      o = new UniformRandom$1(t, n, null, a);

  for (var _e57 = 0; _e57 < s.values.length; _e57++) {
    s.values[_e57] = o.nextValue();
  }

  return s.toTensor();
}

var randomUniform$2 = op$1({
  randomUniform_: randomUniform_$1
});

function range$8(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 1;
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : "float32";
  if (0 === n) throw new Error("Cannot have a step of zero");
  return ENGINE$1.runKernel(Range$1, {}, {
    start: e,
    stop: t,
    step: n,
    dtype: r
  });
}

function real_$1(e) {
  var t = convertToTensor$1(e, "input", "real");
  return ENGINE$1.runKernel(Real$1, {
    input: t
  });
}

var real$5 = op$1({
  real_: real_$1
});

function reciprocal_$1(e) {
  var t = convertToTensor$1(e, "x", "reciprocal");
  return ENGINE$1.runKernel(Reciprocal$1, {
    x: t
  });
}

var reciprocal$5 = op$1({
  reciprocal_: reciprocal_$1
});

function relu_$1(e) {
  var t = convertToTensor$1(e, "x", "relu");
  return ENGINE$1.runKernel(Relu$3, {
    x: t
  });
}

var relu$6 = op$1({
  relu_: relu_$1
});

function relu6_$1(e) {
  var t = convertToTensor$1(e, "x", "relu6");
  return ENGINE$1.runKernel(Relu6$3, {
    x: t
  });
}

var relu6$5 = op$1({
  relu6_: relu6_$1
});

function reverse_$1(e, t) {
  var n = convertToTensor$1(e, "x", "reverse");
  return ENGINE$1.runKernel(Reverse$1, {
    x: n
  }, {
    dims: t
  });
}

var reverse$5 = op$1({
  reverse_: reverse_$1
});

function round_$1(e) {
  var t = convertToTensor$1(e, "x", "round");
  return ENGINE$1.runKernel(Round$1, {
    x: t
  });
}

var round$6 = op$1({
  round_: round_$1
});

function rsqrt_$1(e) {
  var t = convertToTensor$1(e, "x", "rsqrt");
  return ENGINE$1.runKernel(Rsqrt$1, {
    x: t
  });
}

var rsqrt$5 = op$1({
  rsqrt_: rsqrt_$1
});

function scalar$1(e, t) {
  if ((isTypedArray$1(e) && "string" !== t || Array.isArray(e)) && "complex64" !== t) throw new Error("Error creating a new Scalar: value must be a primitive (number|boolean|string)");
  if ("string" === t && isTypedArray$1(e) && !(e instanceof Uint8Array)) throw new Error("When making a scalar from encoded string, the value must be `Uint8Array`.");
  return makeTensor$1(e, [], [], t);
}

function selu_$1(e) {
  var t = convertToTensor$1(e, "x", "selu");
  return ENGINE$1.runKernel(Selu$3, {
    x: t
  });
}

var selu$5 = op$1({
  selu_: selu_$1
});

function separableConv2d_$1(e, t, n, r, a) {
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : [1, 1];
  var o = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : "NHWC";
  var i = convertToTensor$1(e, "x", "separableConv2d"),
      l = convertToTensor$1(t, "depthwiseFilter", "separableConv2d"),
      u = convertToTensor$1(n, "pointwiseFilter", "separableConv2d");
  var c = i,
      p = !1;
  if (3 === i.rank && (p = !0, c = reshape$6(i, [1, i.shape[0], i.shape[1], i.shape[2]])), "NCHW" === o) throw new Error("separableConv2d currently does not support dataFormat NCHW; only NHWC is supported");
  assert$6(4 === c.rank, () => "Error in separableConv2d: input must be rank 4, but got rank ".concat(c.rank, ".")), assert$6(4 === l.rank, () => "Error in separableConv2d: depthwise filter must be rank 4, but got rank ".concat(l.rank, ".")), assert$6(4 === u.rank, () => "Error in separableConv2d: pointwise filter must be rank 4, but got rank ".concat(l.rank, ".")), assert$6(1 === u.shape[0], () => "Error in separableConv2d: the first dimension of pointwise filter  must be 1, but got ".concat(u.shape[0], ".")), assert$6(1 === u.shape[1], () => "Error in separableConv2d: the second dimension of pointwise filter must be 1, but got ".concat(u.shape[1], "."));
  var d = l.shape[2],
      h = l.shape[3];
  assert$6(u.shape[2] === d * h, () => "Error in separableConv2d: the third dimension of pointwise filter must be ".concat(d * h, ", but got ").concat(u.shape[2], "."));
  var m = depthwiseConv2d$5(c, l, r, a, o, s),
      f = conv2d$7(m, u, 1, "valid", o);
  return p ? reshape$6(f, [f.shape[1], f.shape[2], f.shape[3]]) : f;
}

var separableConv2d$2 = op$1({
  separableConv2d_: separableConv2d_$1
});

function sign_$1(e) {
  var t = convertToTensor$1(e, "x", "sign");
  return ENGINE$1.runKernel(Sign$1, {
    x: t
  });
}

var sign$5 = op$1({
  sign_: sign_$1
});

function sin_$1(e) {
  var t = convertToTensor$1(e, "x", "sin");
  return ENGINE$1.runKernel(Sin$1, {
    x: t
  });
}

var sin$5 = op$1({
  sin_: sin_$1
});

function sinh_$1(e) {
  var t = convertToTensor$1(e, "x", "sinh");
  return ENGINE$1.runKernel(Sinh$1, {
    x: t
  });
}

var sinh$5 = op$1({
  sinh_: sinh_$1
});

function slice1d_$1(e, t, n) {
  var r = convertToTensor$1(e, "x", "slice1d");
  return assert$6(1 === r.rank, () => "slice1d expects a rank-1 tensor, but got a rank-".concat(r.rank, " tensor")), slice$5(r, [t], [n]);
}

var slice1d$1 = op$1({
  slice1d_: slice1d_$1
});

function slice2d_$1(e, t, n) {
  var r = convertToTensor$1(e, "x", "slice2d");
  return assert$6(2 === r.rank, () => "slice2d expects a rank-2 tensor, but got a rank-".concat(r.rank, " tensor")), slice$5(r, t, n);
}

var slice2d$1 = op$1({
  slice2d_: slice2d_$1
});

function slice3d_$1(e, t, n) {
  var r = convertToTensor$1(e, "x", "slice3d");
  return assert$6(3 === r.rank, () => "slice3d expects a rank-3 tensor, but got a rank-".concat(r.rank, " tensor")), slice$5(r, t, n);
}

var slice3d$1 = op$1({
  slice3d_: slice3d_$1
});

function slice4d_$1(e, t, n) {
  var r = convertToTensor$1(e, "x", "slice4d");
  return assert$6(4 === r.rank, () => "slice4d expects a rank-4 tensor, but got a rank-".concat(r.rank, " tensor")), slice$5(r, t, n);
}

var slice4d$1 = op$1({
  slice4d_: slice4d_$1
});

function softmax_$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : -1;
  var n = convertToTensor$1(e, "logits", "softmax", "float32");
  if (-1 === t && (t = n.rank - 1), t !== n.rank - 1) throw Error("Softmax along a non-last dimension is not yet supported. Logits was rank ".concat(n.rank, " and dim was ").concat(t));
  return ENGINE$1.runKernel(Softmax$5, {
    logits: n
  }, {
    dim: t
  });
}

var softmax$6 = op$1({
  softmax_: softmax_$1
});

function fft_$1(e) {
  return assert$6("complex64" === e.dtype, () => "The dtype for tf.spectral.fft() must be complex64 but got ".concat(e.dtype, ".")), ENGINE$1.runKernel(FFT$1, {
    input: e
  });
}

var fft$5 = op$1({
  fft_: fft_$1
});

function ifft_$1(e) {
  return assert$6("complex64" === e.dtype, () => "The dtype for tf.spectral.ifft() must be complex64 but got ".concat(e.dtype, ".")), ENGINE$1.runKernel(IFFT$1, {
    input: e
  });
}

var ifft$5 = op$1({
  ifft_: ifft_$1
});

function irfft_$1(e) {
  var t = e.shape[e.shape.length - 1],
      n = e.size / t;
  var r;

  if (t <= 2) {
    var a = reshape$6(e, [n, t]);
    r = ifft$5(a);
  } else {
    var _a12 = [n, 2 * (t - 1)],
        s = reshape$6(real$5(e), [n, t]),
        o = reshape$6(imag$5(e), [n, t]),
        i = reverse$5(slice$5(s, [0, 1], [n, t - 2]), 1),
        l = mul$1(reverse$5(slice$5(o, [0, 1], [n, t - 2]), 1), scalar$1(-1)),
        u = concat$5([s, i], 1),
        c = concat$5([o, l], 1),
        _p2 = reshape$6(complex$5(u, c), [_a12[0], _a12[1]]);

    r = ifft$5(_p2);
  }

  if (r = real$5(r), 3 === e.rank && 0 !== e.shape[0]) {
    var _t50 = r,
        _n14 = e.shape[0];
    r = reshape$6(r, [_n14, r.shape[0] / _n14, r.shape[1]]), _t50.dispose();
  }

  return r;
}

var irfft$1 = op$1({
  irfft_: irfft_$1
});

function split_$1(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;
  var r = convertToTensor$1(e, "x", "split");
  return ENGINE$1.runKernel(SplitV$1, {
    x: r
  }, {
    numOrSizeSplits: t,
    axis: n
  });
}

var split$4 = op$1({
  split_: split_$1
});

function rfft_$1(e, t) {
  assert$6("float32" === e.dtype, () => "The dtype for rfft() must be real value but got ".concat(e.dtype));
  var n = e.shape[e.shape.length - 1];
  var r = e.size / n;
  var a;

  if (null != t && t < n) {
    var _r16 = e.shape.map(e => 0),
        _s7 = e.shape.map(e => e);

    _s7[e.shape.length - 1] = t, a = slice$5(e, _r16, _s7), n = t;
  } else if (null != t && t > n) {
    var _r17 = e.shape.map(e => e);

    _r17[e.shape.length - 1] = t - n, a = concat$5([e, zeros$4(_r17)], e.shape.length - 1), n = t;
  } else a = e;

  var s = zerosLike$5(a),
      o = reshape$6(complex$5(a, s), [r, n]),
      i = fft$5(o),
      l = Math.floor(n / 2) + 1,
      u = real$5(i),
      c = imag$5(i),
      p = split$4(u, [l, n - l], u.shape.length - 1),
      d = split$4(c, [l, n - l], c.shape.length - 1),
      h = a.shape.slice();
  return h[a.shape.length - 1] = l, reshape$6(complex$5(p[0], d[0]), h);
}

var rfft$1 = op$1({
  rfft_: rfft_$1
});

function sqrt_$1(e) {
  var t = convertToTensor$1(e, "x", "sqrt");
  return ENGINE$1.runKernel(Sqrt$1, {
    x: t
  });
}

var sqrt$5 = op$1({
  sqrt_: sqrt_$1
});

function squaredDifference_$1(e, t) {
  var n = convertToTensor$1(e, "a", "squaredDifference"),
      r = convertToTensor$1(t, "b", "squaredDifference");
  return [n, r] = makeTypesMatch$1(n, r), assertAndGetBroadcastShape$1(n.shape, r.shape), ENGINE$1.runKernel(SquaredDifference$1, {
    a: n,
    b: r
  }, {});
}

var squaredDifference$5 = op$1({
  squaredDifference_: squaredDifference_$1
});

function squeeze_$1(e, t) {
  var n = convertToTensor$1(e, "x", "squeeze");
  return reshape$6(n, squeezeShape$1(n.shape, t).newShape);
}

var squeeze$1 = op$1({
  squeeze_: squeeze_$1
});

function stack_$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;
  var n = convertToTensorArray$1(e, "tensors", "stack", "string_or_numeric");
  return assert$6(n.length >= 1, () => "Pass at least one tensor to tf.stack"), n.length > 0 && assert$6(t <= n[0].rank, () => "Axis must be <= rank of the tensor"), ENGINE$1.runKernel(Pack$1, n, {
    axis: t
  });
}

var stack$1 = op$1({
  stack_: stack_$1
});

function step_$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;
  var n = convertToTensor$1(e, "x", "step");
  return ENGINE$1.runKernel(Step$1, {
    x: n
  }, {
    alpha: t
  });
}

var step$5 = op$1({
  step_: step_$1
});

function stridedSlice_$1(e, t, n, r) {
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : 0;
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : 0;
  var o = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : 0;
  var i = arguments.length > 7 && arguments[7] !== undefined ? arguments[7] : 0;
  var l = arguments.length > 8 && arguments[8] !== undefined ? arguments[8] : 0;
  var u = convertToTensor$1(e, "x", "stridedSlice", "string_or_numeric");
  return ENGINE$1.runKernel(StridedSlice$1, {
    x: u
  }, {
    begin: t,
    end: n,
    strides: r,
    beginMask: a,
    endMask: s,
    ellipsisMask: o,
    newAxisMask: i,
    shrinkAxisMask: l
  });
}

var stridedSlice$5 = op$1({
  stridedSlice_: stridedSlice_$1
});

function tan_$1(e) {
  var t = convertToTensor$1(e, "x", "tan");
  return ENGINE$1.runKernel(Tan$1, {
    x: t
  });
}

var tan$5 = op$1({
  tan_: tan_$1
});

function tensor1d$1(e, t) {
  assertNonNull$1(e);
  var n = inferShape$1(e, t);
  if (1 !== n.length) throw new Error("tensor1d() requires values to be a flat/TypedArray");
  return makeTensor$1(e, null, n, t);
}

function tensor2d$1(e, t, n) {
  if (assertNonNull$1(e), null != t && 2 !== t.length) throw new Error("tensor2d() requires shape to have two numbers");
  var r = inferShape$1(e, n);
  if (2 !== r.length && 1 !== r.length) throw new Error("tensor2d() requires values to be number[][] or flat/TypedArray");
  if (1 === r.length && null == t) throw new Error("tensor2d() requires shape to be provided when `values` are a flat/TypedArray");
  return makeTensor$1(e, t, r, n);
}

function topk_$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 1;
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !0;
  var r = convertToTensor$1(e, "x", "topk");
  if (0 === r.rank) throw new Error("topk() expects the input to be of rank 1 or higher");
  var a = r.shape[r.shape.length - 1];
  if (t < 0) throw new Error("'k' passed to topk() must be >= 0 but got ".concat(t));
  if (t > a) throw new Error("'k' passed to topk() must be <= the last dimension (".concat(a, ") but got ").concat(t));
  var s = {
    x: r
  },
      o = {
    k: t,
    sorted: n
  },
      [i, l] = ENGINE$1.runKernel(TopK$1, s, o);
  return {
    values: i,
    indices: l
  };
}

var topk$1 = op$1({
  topk_: topk_$1
});

function truncatedNormal_$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 1;
  var r = arguments.length > 3 ? arguments[3] : undefined;
  var a = arguments.length > 4 ? arguments[4] : undefined;
  if (null != r && "bool" === r) throw new Error("Unsupported data type $ { dtype }");
  var s = new MPRandGauss$1(t, n, r, !0, a),
      o = buffer$1(e, r);

  for (var _e58 = 0; _e58 < o.values.length; _e58++) {
    o.values[_e58] = s.nextValue();
  }

  return o.toTensor();
}

var truncatedNormal$2 = op$1({
  truncatedNormal_: truncatedNormal_$1
});

function unique_$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;
  var n = convertToTensor$1(e, "x", "unique", "string_or_numeric");
  assert$6(n.rank > 0, () => "The input tensor must be at least 1D");
  var r = {
    x: n
  },
      a = {
    axis: t
  },
      [s, o] = ENGINE$1.runKernel(Unique$1, r, a);
  return {
    values: s,
    indices: o
  };
}

var unique$7 = op$1({
  unique_: unique_$1
});

function unsortedSegmentSum_$1(e, t, n) {
  var r = convertToTensor$1(e, "x", "unsortedSegmentSum"),
      a = convertToTensor$1(t, "segmentIds", "unsortedSegmentSum", "int32");
  return assert$6(isInt$1(n), () => "numSegments must be of dtype int"), ENGINE$1.runKernel(UnsortedSegmentSum$1, {
    x: r,
    segmentIds: a
  }, {
    numSegments: n
  });
}

var unsortedSegmentSum$5 = op$1({
  unsortedSegmentSum_: unsortedSegmentSum_$1
});

function unstack_$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;
  var n = convertToTensor$1(e, "x", "unstack", "string_or_numeric");
  return assert$6(t >= -n.shape.length && t < n.shape.length, () => "Axis = ".concat(t, " is not in [-").concat(n.shape.length, ", ").concat(n.shape.length, ")")), ENGINE$1.runKernel(Unpack$1, {
    value: n
  }, {
    axis: t
  });
}

var unstack$1 = op$1({
  unstack_: unstack_$1
});

function variable$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !0;
  var n = arguments.length > 2 ? arguments[2] : undefined;
  var r = arguments.length > 3 ? arguments[3] : undefined;
  return ENGINE$1.makeVariable(e, t, n, r);
}

function whereImpl$5(e, t) {
  var n = [];

  for (var _e59 = 0; _e59 < t.length; _e59++) {
    t[_e59] && n.push(_e59);
  }

  var r = buffer$1(e, "int32"),
      a = buffer$1([n.length, e.length], "int32");

  for (var _t51 = 0; _t51 < n.length; _t51++) {
    var s = r.indexToLoc(n[_t51]);
    a.values.set(s, _t51 * e.length);
  }

  return a.toTensor();
}

function norm_$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : "euclidean";
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
  var a = normImpl$1(e = convertToTensor$1(e, "x", "norm"), t, n);
  var s = a.shape;

  if (r) {
    var _t52 = parseAxisParam$1(n, e.shape);

    s = expandShapeToKeepDim$1(a.shape, _t52);
  }

  return reshape$6(a, s);
}

function normImpl$1(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;
  if (0 === e.rank) return abs$5(e);
  if (1 !== e.rank && null === n) return normImpl$1(reshape$6(e, [-1]), t, n);

  if (1 === e.rank || "number" == typeof n || Array.isArray(n) && 1 === n.length) {
    if (1 === t) return sum$6(abs$5(e), n);
    if (Infinity === t) return max$7(abs$5(e), n);
    if (-Infinity === t) return min$7(abs$5(e), n);
    if ("euclidean" === t || 2 === t) return sqrt$5(sum$6(pow$5(abs$5(e), scalar$1(2, "int32")), n));
    throw new Error("Error in norm: invalid ord value: ".concat(t));
  }

  if (Array.isArray(n) && 2 === n.length) {
    if (1 === t) return max$7(sum$6(abs$5(e), n[0]), n[1] - 1);
    if (Infinity === t) return max$7(sum$6(abs$5(e), n[1]), n[0]);
    if (-Infinity === t) return min$7(sum$6(abs$5(e), n[1]), n[0]);
    if ("fro" === t || "euclidean" === t) return sqrt$5(sum$6(square$5(e), n));
    throw new Error("Error in norm: invalid ord value: ".concat(t));
  }

  throw new Error("Error in norm: invalid axis: ".concat(n));
}

var norm$1 = op$1({
  norm_: norm_$1
});

function getNoiseShape$1(e, t) {
  if (null == t) return e.shape.slice();
  if (arraysEqual$1(e.shape, t)) return t;

  if (e.shape.length === t.length) {
    var n = [];

    for (var r = 0; r < e.shape.length; r++) {
      n.push(null == t[r] && null != e.shape[r] ? e.shape[r] : t[r]);
    }

    return n;
  }

  return t;
}

function dropout_$1(e, t, n, r) {
  var a = convertToTensor$1(e, "x", "dropout");
  if (assert$6("float32" === a.dtype, () => "x has to be a floating point tensor since it's going to be scaled, but got a ".concat(a.dtype, " tensor instead.")), assert$6(t >= 0 && t < 1, () => "rate must be a float in the range [0, 1), but got ".concat(t, ".")), 0 === t) return e instanceof Tensor$1 ? a.clone() : a;
  var s = getNoiseShape$1(a, n),
      o = 1 - t,
      i = div$3(floor$5(add$5(randomUniform$2(s, 0, 1, "float32", r), o)), o);
  return mul$1(a, i);
}

var dropout$5 = op$1({
  dropout_: dropout_$1
});

function enclosingPowerOfTwo$1(e) {
  return Math.floor(Math.pow(2, Math.ceil(Math.log(e) / Math.log(2))));
}

function cosineWindow$1(e, t, n) {
  var r = 1 - e % 2,
      a = new Float32Array(e);

  for (var s = 0; s < e; ++s) {
    var o = 2 * Math.PI * s / (e + r - 1);
    a[s] = t - n * Math.cos(o);
  }

  return tensor1d$1(a, "float32");
}

function conv2DBackpropFilter_$1(e, t, n, r, a) {
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : "NHWC";
  var o = arguments.length > 6 ? arguments[6] : undefined;
  var i = e;
  3 === e.rank && (i = reshape$6(e, [1, e.shape[0], e.shape[1], e.shape[2]]));
  var l = t;
  3 === l.rank && (l = reshape$6(t, [1, t.shape[0], t.shape[1], t.shape[2]])), assert$6(4 === i.rank, () => "Error in conv2dDerFilter: input must be rank 4, but got shape ".concat(i.shape, ".")), assert$6(4 === l.rank, () => "Error in conv2dDerFilter: dy must be rank 4, but got shape ".concat(l.shape, ".")), assert$6(4 === n.length, () => "Error in conv2dDerFilter: filterShape must be length 4, but got ".concat(n, "."));
  var u = "NHWC" === s ? i.shape[3] : i.shape[1],
      c = "NHWC" === s ? l.shape[3] : l.shape[1];
  return assert$6(u === n[2], () => "Error in conv2dDerFilter: depth of input ".concat(u, ") must match input depth in filter (").concat(n[2], ".")), assert$6(c === n[3], () => "Error in conv2dDerFilter: depth of dy (".concat(c, ") must match output depth for filter (").concat(n[3], ").")), null != o && assert$6(isInt$1(a), () => "Error in conv2dDerFilter: pad must be an integer when using, dimRoundingMode ".concat(o, " but got pad ").concat(a, ".")), ENGINE$1.runKernel(Conv2DBackpropFilter$1, {
    x: i,
    dy: l
  }, {
    strides: r,
    pad: a,
    dataFormat: s,
    dimRoundingMode: o,
    filterShape: n
  });
}

var conv2DBackpropFilter$5 = op$1({
  conv2DBackpropFilter_: conv2DBackpropFilter_$1
});

function getFusedDyActivation$1(e, t, n) {
  if (null == n || "linear" === n) return e;
  if ("relu" === n) return mul$1(e, step$5(t));
  throw new Error("Cannot compute gradient for fused activation ".concat(n, "."));
}

function getFusedBiasGradient$1(e, t) {
  var n = t;
  var r = getReductionAxes$1(e.shape, t.shape);
  return r.length > 0 && (n = sum$6(n, r)), reshape$6(n, e.shape);
}

function applyActivation$3(e, t, n, r) {
  if ("linear" === t) return e;
  if ("relu" === t) return relu$6(e);
  if ("elu" === t) return elu$8(e);
  if ("relu6" === t) return relu6$5(e);
  if ("prelu" === t) return prelu$6(e, n);
  if ("leakyrelu" === t) return leakyRelu$5(e, r);
  if ("sigmoid" === t) return sigmoid$5(e);
  throw new Error("Unknown fused activation ".concat(t, "."));
}

var shouldFuse$1 = (e, t) => !(e > 0) || "linear" === t;

function fusedConv2d_$1(_ref) {
  var {
    x: e,
    filter: t,
    strides: n,
    pad: r,
    dataFormat: a = "NHWC",
    dilations: s = [1, 1],
    dimRoundingMode: o,
    bias: i,
    activation: l = "linear",
    preluActivationWeights: u,
    leakyreluAlpha: c
  } = _ref;

  if (!1 === shouldFuse$1(ENGINE$1.state.gradientDepth, l = l || "linear")) {
    var _p3 = conv2d$7(e, t, n, r, a, s, o);

    return null != i && (_p3 = add$5(_p3, i)), applyActivation$3(_p3, l, u, c);
  }

  var p = convertToTensor$1(e, "x", "conv2d"),
      d = convertToTensor$1(t, "filter", "conv2d");
  var h = p,
      m = !1;
  3 === p.rank && (m = !0, h = reshape$6(p, [1, p.shape[0], p.shape[1], p.shape[2]])), assert$6(4 === h.rank, () => "Error in fused conv2d: input must be rank 4, but got rank ".concat(h.rank, ".")), assert$6(4 === d.rank, () => "Error in fused conv2d: filter must be rank 4, but got rank ".concat(d.rank, ".")), null != o && assert$6(isInt$1(r), () => "Error in fused conv2d: pad must be an integer when using, dimRoundingMode ".concat(o, " but got pad ").concat(r, ".")), assert$6(h.shape[3] === d.shape[2], () => "Error in conv2d: depth of input (".concat(h.shape[3], ") must match input depth for filter ").concat(d.shape[2], ".")), assert$6(eitherStridesOrDilationsAreOne$1(n, s), () => "Error in conv2D: Either strides or dilations must be 1. Got strides ".concat(n, " and dilations '").concat(s, "'")), assert$6("NHWC" === a, () => "Error in conv2d: got dataFormat of ".concat(a, " but only NHWC is currently supported."));
  var f = computeConv2DInfo$1(h.shape, d.shape, n, s, r, o);
  var g, $;
  null != i && (g = convertToTensor$1(i, "bias", "fused conv2d"), [g] = makeTypesMatch$1(g, p), assertAndGetBroadcastShape$1(f.outShape, g.shape)), null != u && ($ = convertToTensor$1(u, "prelu weights", "fused conv2d"));

  var y = (e, t) => {
    var [a, o, i, u] = t,
        c = getFusedDyActivation$1(e, i, l);
    assert$6(tupleValuesAreOne$1(s), () => "Error in gradient of fused conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '".concat(s, "'"));
    var p = [conv2DBackpropInput$5(o.shape, c, a, n, r), conv2DBackpropFilter$5(o, c, a.shape, n, r)];

    if (null != u) {
      var _e60 = getFusedBiasGradient$1(u, c);

      p.push(_e60);
    }

    return p;
  },
      b = {
    x: h,
    filter: d,
    bias: g,
    preluActivationWeights: $
  },
      x = {
    strides: n,
    pad: r,
    dataFormat: a,
    dilations: s,
    dimRoundingMode: o,
    activation: l,
    leakyreluAlpha: c
  };

  if (null == i) {
    var _e61 = customGrad$1((e, t, n) => {
      var r = ENGINE$1.runKernel(FusedConv2D$1, b, x);
      return n([t, e, r]), m && (r = reshape$6(r, [r.shape[1], r.shape[2], r.shape[3]])), {
        value: r,
        gradFunc: y
      };
    });

    return _e61(h, d);
  }

  {
    var _e62 = customGrad$1((e, t, n, r) => {
      var a = ENGINE$1.runKernel(FusedConv2D$1, b, x);
      return r([t, e, a, n]), m && (a = reshape$6(a, [a.shape[1], a.shape[2], a.shape[3]])), {
        value: a,
        gradFunc: y
      };
    });

    return _e62(h, d, g);
  }
}

var conv2d$6 = op$1({
  fusedConv2d_: fusedConv2d_$1
});

function depthwiseConv2dNativeBackpropFilter_$1(e, t, n, r, a) {
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : [1, 1];
  var o = arguments.length > 6 ? arguments[6] : undefined;
  var i = e;
  3 === e.rank && (i = reshape$6(e, [1, e.shape[0], e.shape[1], e.shape[2]]));
  var l = t;
  return 3 === l.rank && (l = reshape$6(t, [1, t.shape[0], t.shape[1], t.shape[2]])), ENGINE$1.runKernel(DepthwiseConv2dNativeBackpropFilter$1, {
    x: i,
    dy: l
  }, {
    strides: r,
    pad: a,
    dimRoundingMode: o,
    dilations: s,
    filterShape: n
  });
}

var depthwiseConv2dNativeBackpropFilter$5 = op$1({
  depthwiseConv2dNativeBackpropFilter_: depthwiseConv2dNativeBackpropFilter_$1
});

function depthwiseConv2dNativeBackpropInput_$1(e, t, n, r, a) {
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : [1, 1];
  var o = arguments.length > 6 ? arguments[6] : undefined;
  var i = t,
      l = !1;
  3 === t.rank && (l = !0, i = reshape$6(t, [1, t.shape[0], t.shape[1], t.shape[2]]));
  var u = ENGINE$1.runKernel(DepthwiseConv2dNativeBackpropInput$1, {
    dy: i,
    filter: n
  }, {
    strides: r,
    pad: a,
    dimRoundingMode: o,
    dilations: s,
    inputShape: e
  });
  return l ? reshape$6(u, [u.shape[1], u.shape[2], u.shape[3]]) : u;
}

var depthwiseConv2dNativeBackpropInput$5 = op$1({
  depthwiseConv2dNativeBackpropInput_: depthwiseConv2dNativeBackpropInput_$1
});

function fusedMatMul_$1(_ref2) {
  var {
    a: e,
    b: t,
    transposeA: n = !1,
    transposeB: r = !1,
    bias: a,
    activation: s = "linear",
    preluActivationWeights: o,
    leakyreluAlpha: i
  } = _ref2;

  if (!1 === shouldFuse$1(ENGINE$1.state.gradientDepth, s)) {
    var _l4 = matMul$3(e, t, n, r);

    return null != a && (_l4 = add$5(_l4, a)), applyActivation$3(_l4, s, o, i);
  }

  var l = convertToTensor$1(e, "a", "fused matMul"),
      u = convertToTensor$1(t, "b", "fused matMul");
  [l, u] = makeTypesMatch$1(l, u);
  var c = n ? l.shape[l.rank - 2] : l.shape[l.rank - 1],
      p = r ? u.shape[u.rank - 1] : u.shape[u.rank - 2],
      d = n ? l.shape[l.rank - 1] : l.shape[l.rank - 2],
      h = r ? u.shape[u.rank - 2] : u.shape[u.rank - 1],
      m = l.shape.slice(0, -2),
      f = u.shape.slice(0, -2),
      g = sizeFromShape$1(m),
      $ = sizeFromShape$1(f);
  assert$6(l.rank >= 2 && u.rank >= 2 && l.rank === u.rank, () => "Error in fused matMul: inputs must have the same rank of at least 2, got ranks ".concat(l.rank, " and ").concat(u.rank, ".")), assert$6(arraysEqual$1(m, f), () => "Error in fused matMul: outer dimensions (".concat(m, ") and (").concat(f, ") of Tensors with shapes ").concat(l.shape, " and ").concat(u.shape, " must match.")), assert$6(c === p, () => "Error in fused matMul: inner shapes (".concat(c, ") and (").concat(p, ") of Tensors with shapes ").concat(l.shape, " and ").concat(u.shape, " and transposeA=").concat(n, " and transposeB=").concat(r, " must match."));
  var y = l.shape.slice(0, -2).concat([d, h]),
      b = reshape$6(l, n ? [g, c, d] : [g, d, c]),
      x = reshape$6(u, r ? [$, h, p] : [$, p, h]);
  var v, I;
  null != a && (v = convertToTensor$1(a, "bias", "fused matMul"), [v] = makeTypesMatch$1(v, l), assertAndGetBroadcastShape$1(y, v.shape)), null != o && (I = convertToTensor$1(o, "prelu weights", "fused matMul"));

  var C = (e, t) => {
    var [o, i, l, u] = t,
        c = getFusedDyActivation$1(reshape$6(e, l.shape), l, s);
    var p, d;
    return n || r ? !n && r ? (p = matMul$3(c, i, !1, !1), d = matMul$3(c, o, !0, !1)) : n && !r ? (p = matMul$3(i, c, !1, !0), d = matMul$3(o, c, !1, !1)) : (p = matMul$3(i, c, !0, !0), d = matMul$3(c, o, !0, !0)) : (p = matMul$3(c, i, !1, !0), d = matMul$3(o, c, !0, !1)), null != a ? [p, d, getFusedBiasGradient$1(u, c)] : [p, d];
  },
      S = {
    a: b,
    b: x,
    bias: v,
    preluActivationWeights: I
  },
      k = {
    transposeA: n,
    transposeB: r,
    activation: s,
    leakyreluAlpha: i
  };

  if (null == a) {
    var _e63 = customGrad$1((e, t, n) => {
      var r = ENGINE$1.runKernel(_FusedMatMul$1, S, k);
      return n([e, t, r]), {
        value: reshape$6(r, y),
        gradFunc: C
      };
    });

    return _e63(b, x);
  }

  {
    var _e64 = customGrad$1((e, t, n, r) => {
      var a = ENGINE$1.runKernel(_FusedMatMul$1, S, k);
      return r([e, t, a, n]), {
        value: reshape$6(a, y),
        gradFunc: C
      };
    });

    return _e64(b, x, v);
  }
}

var matMul$2 = op$1({
  fusedMatMul_: fusedMatMul_$1
});

function hammingWindow_$1(e) {
  return cosineWindow$1(e, .54, .46);
}

var hammingWindow$1 = op$1({
  hammingWindow_: hammingWindow_$1
});

function hannWindow_$1(e) {
  return cosineWindow$1(e, .5, .5);
}

var hannWindow$1 = op$1({
  hannWindow_: hannWindow_$1
});

function frame_$1(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : 0;
  var s = 0;
  var o = [];

  for (; s + t <= e.size;) {
    o.push(slice$5(e, s, t)), s += n;
  }

  if (r) for (; s < e.size;) {
    var _r18 = s + t - e.size,
        i = concat$5([slice$5(e, s, t - _r18), fill$5([_r18], a)]);

    o.push(i), s += n;
  }
  return 0 === o.length ? tensor2d$1([], [0, t]) : reshape$6(concat$5(o), [o.length, t]);
}

var frame$1 = op$1({
  frame_: frame_$1
});

function stft_$1(e, t, n, r) {
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : hannWindow$1;
  null == r && (r = enclosingPowerOfTwo$1(t));
  var s = frame$1(e, t, n),
      o = mul$1(s, a(t));
  return rfft$1(o, r);
}

var stft$1 = op$1({
  stft_: stft_$1
});

function cropAndResize_$1(e, t, n, r) {
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : "bilinear";
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : 0;
  var o = convertToTensor$1(e, "image", "cropAndResize"),
      i = convertToTensor$1(t, "boxes", "cropAndResize", "float32"),
      l = convertToTensor$1(n, "boxInd", "cropAndResize", "int32"),
      u = i.shape[0];
  return assert$6(4 === o.rank, () => "Error in cropAndResize: image must be rank 4,but got rank ".concat(o.rank, ".")), assert$6(2 === i.rank && 4 === i.shape[1], () => "Error in cropAndResize: boxes must be have size [".concat(u, ",4] but had shape ").concat(i.shape, ".")), assert$6(1 === l.rank && l.shape[0] === u, () => "Error in cropAndResize: boxInd must be have size [".concat(u, "] but had shape ").concat(i.shape, ".")), assert$6(2 === r.length, () => "Error in cropAndResize: cropSize must be of length 2, but got length ".concat(r.length, ".")), assert$6(r[0] >= 1 && r[1] >= 1, () => "cropSize must be atleast [1,1], but was ".concat(r)), assert$6("bilinear" === a || "nearest" === a, () => "method must be bilinear or nearest, but was ".concat(a)), ENGINE$1.runKernel(CropAndResize$1, {
    image: o,
    boxes: i,
    boxInd: l
  }, {
    method: a,
    extrapolationValue: s,
    cropSize: r
  });
}

var cropAndResize$5 = op$1({
  cropAndResize_: cropAndResize_$1
});

function flipLeftRight_$1(e) {
  var t = convertToTensor$1(e, "image", "flipLeftRight", "float32");
  return assert$6(4 === t.rank, () => "Error in flipLeftRight: image must be rank 4,but got rank ".concat(t.rank, ".")), ENGINE$1.runKernel(FlipLeftRight$1, {
    image: t
  }, {});
}

var flipLeftRight$1 = op$1({
  flipLeftRight_: flipLeftRight_$1
});

function rotateWithOffset_$1(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : .5;
  var a = convertToTensor$1(e, "image", "rotateWithOffset", "float32");
  return assert$6(4 === a.rank, () => "Error in rotateWithOffset: image must be rank 4,but got rank ".concat(a.rank, ".")), ENGINE$1.runKernel(RotateWithOffset$1, {
    image: a
  }, {
    radians: t,
    fillValue: n,
    center: r
  });
}

var rotateWithOffset$1 = op$1({
  rotateWithOffset_: rotateWithOffset_$1
});

function nonMaxSuppSanityCheck$1(e, t, n, r, a, s) {
  null == r && (r = .5), null == a && (a = Number.NEGATIVE_INFINITY), null == s && (s = 0);
  var o = e.shape[0];
  return n = Math.min(n, o), assert$6(0 <= r && r <= 1, () => "iouThreshold must be in [0, 1], but was '".concat(r, "'")), assert$6(2 === e.rank, () => "boxes must be a 2D tensor, but was of rank '".concat(e.rank, "'")), assert$6(4 === e.shape[1], () => "boxes must have 4 columns, but 2nd dimension was ".concat(e.shape[1])), assert$6(1 === t.rank, () => "scores must be a 1D tensor"), assert$6(t.shape[0] === o, () => "scores has incompatible shape with boxes. Expected ".concat(o, ", but was ").concat(t.shape[0])), assert$6(0 <= s && s <= 1, () => "softNmsSigma must be in [0, 1], but was '".concat(s, "'")), {
    maxOutputSize: n,
    iouThreshold: r,
    scoreThreshold: a,
    softNmsSigma: s
  };
}

function nonMaxSuppression_$1(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : .5;
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : Number.NEGATIVE_INFINITY;
  var s = convertToTensor$1(e, "boxes", "nonMaxSuppression"),
      o = convertToTensor$1(t, "scores", "nonMaxSuppression"),
      i = nonMaxSuppSanityCheck$1(s, o, n, r, a);
  return ENGINE$1.runKernel(NonMaxSuppressionV3$1, {
    boxes: s,
    scores: o
  }, {
    maxOutputSize: n = i.maxOutputSize,
    iouThreshold: r = i.iouThreshold,
    scoreThreshold: a = i.scoreThreshold
  });
}

var nonMaxSuppression$1 = op$1({
  nonMaxSuppression_: nonMaxSuppression_$1
});

function binaryInsert$1(e, t, n) {
  var r = binarySearch$1(e, t, n);
  e.splice(r < 0 ? -(r + 1) : r, 0, t);
}

function binarySearch$1(e, t, n) {
  return binarySearch_$1(e, t, n || defaultComparator$1);
}

function defaultComparator$1(e, t) {
  return e > t ? 1 : e < t ? -1 : 0;
}

function binarySearch_$1(e, t, n) {
  var r = 0,
      a = e.length,
      s = 0,
      o = !1;

  for (; r < a;) {
    s = r + (a - r >>> 1);
    var i = n(t, e[s]);
    i > 0 ? r = s + 1 : (a = s, o = !i);
  }

  return o ? r : -r - 1;
}

function nonMaxSuppressionV3Impl$5(e, t, n, r, a) {
  return nonMaxSuppressionImpl_$1(e, t, n, r, a, 0);
}

function nonMaxSuppressionV4Impl$5(e, t, n, r, a, s) {
  return nonMaxSuppressionImpl_$1(e, t, n, r, a, 0, !1, s, !0);
}

function nonMaxSuppressionV5Impl$5(e, t, n, r, a, s) {
  return nonMaxSuppressionImpl_$1(e, t, n, r, a, s, !0);
}

function nonMaxSuppressionImpl_$1(e, t, n, r, a, s) {
  var o = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : !1;
  var i = arguments.length > 7 && arguments[7] !== undefined ? arguments[7] : !1;
  var l = arguments.length > 8 && arguments[8] !== undefined ? arguments[8] : !1;
  var u = [];

  for (var _e65 = 0; _e65 < t.length; _e65++) {
    t[_e65] > a && u.push({
      score: t[_e65],
      boxIndex: _e65,
      suppressBeginIndex: 0
    });
  }

  u.sort(ascendingComparator$1);
  var c = s > 0 ? -.5 / s : 0,
      p = [],
      d = [];

  for (; p.length < n && u.length > 0;) {
    var _t53 = u.pop(),
        {
      score: _n15,
      boxIndex: _s8,
      suppressBeginIndex: _o5
    } = _t53;

    if (_n15 < a) break;

    var _i4 = !1;

    for (var _n16 = p.length - 1; _n16 >= _o5; --_n16) {
      var _o6 = intersectionOverUnion$1(e, _s8, p[_n16]);

      if (_o6 >= r) {
        _i4 = !0;
        break;
      }

      if (_t53.score = _t53.score * suppressWeight$1(r, c, _o6), _t53.score <= a) break;
    }

    _t53.suppressBeginIndex = p.length, _i4 || (_t53.score === _n15 ? (p.push(_s8), d.push(_t53.score)) : _t53.score > a && binaryInsert$1(u, _t53, ascendingComparator$1));
  }

  var h = p.length,
      m = n - h;
  i && m > 0 && (p.push(...new Array(m).fill(0)), d.push(...new Array(m).fill(0)));
  var f = {
    selectedIndices: p
  };
  return o && (f.selectedScores = d), l && (f.validOutputs = h), f;
}

function intersectionOverUnion$1(e, t, n) {
  var r = e.subarray(4 * t, 4 * t + 4),
      a = e.subarray(4 * n, 4 * n + 4),
      s = Math.min(r[0], r[2]),
      o = Math.min(r[1], r[3]),
      i = Math.max(r[0], r[2]),
      l = Math.max(r[1], r[3]),
      u = Math.min(a[0], a[2]),
      c = Math.min(a[1], a[3]),
      p = Math.max(a[0], a[2]),
      d = Math.max(a[1], a[3]),
      h = (i - s) * (l - o),
      m = (p - u) * (d - c);
  if (h <= 0 || m <= 0) return 0;
  var f = Math.max(s, u),
      g = Math.max(o, c),
      $ = Math.min(i, p),
      y = Math.min(l, d),
      b = Math.max($ - f, 0) * Math.max(y - g, 0);
  return b / (h + m - b);
}

function suppressWeight$1(e, t, n) {
  var r = Math.exp(t * n * n);
  return n <= e ? r : 0;
}

function ascendingComparator$1(e, t) {
  return e.score - t.score || e.score === t.score && t.boxIndex - e.boxIndex;
}

function nonMaxSuppressionAsync_$1(_x7, _x8, _x9) {
  return _nonMaxSuppressionAsync_$.apply(this, arguments);
}

function _nonMaxSuppressionAsync_$() {
  _nonMaxSuppressionAsync_$ = _asyncToGenerator(function* (e, t, n) {
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : .5;
    var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : Number.NEGATIVE_INFINITY;
    var s = convertToTensor$1(e, "boxes", "nonMaxSuppressionAsync"),
        o = convertToTensor$1(t, "scores", "nonMaxSuppressionAsync"),
        i = nonMaxSuppSanityCheck$1(s, o, n, r, a);
    n = i.maxOutputSize, r = i.iouThreshold, a = i.scoreThreshold;
    var l = yield Promise.all([s.data(), o.data()]),
        u = l[0],
        c = l[1],
        {
      selectedIndices: p
    } = nonMaxSuppressionV3Impl$5(u, c, n, r, a);
    return s !== e && s.dispose(), o !== t && o.dispose(), tensor1d$1(p, "int32");
  });
  return _nonMaxSuppressionAsync_$.apply(this, arguments);
}

var nonMaxSuppressionAsync$1 = nonMaxSuppressionAsync_$1;

function nonMaxSuppressionWithScore_$1(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : .5;
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : Number.NEGATIVE_INFINITY;
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : 0;
  var o = convertToTensor$1(e, "boxes", "nonMaxSuppression"),
      i = convertToTensor$1(t, "scores", "nonMaxSuppression"),
      l = nonMaxSuppSanityCheck$1(o, i, n, r, a, s),
      u = ENGINE$1.runKernel(NonMaxSuppressionV5$1, {
    boxes: o,
    scores: i
  }, {
    maxOutputSize: n = l.maxOutputSize,
    iouThreshold: r = l.iouThreshold,
    scoreThreshold: a = l.scoreThreshold,
    softNmsSigma: s = l.softNmsSigma
  });
  return {
    selectedIndices: u[0],
    selectedScores: u[1]
  };
}

var nonMaxSuppressionWithScore$1 = op$1({
  nonMaxSuppressionWithScore_: nonMaxSuppressionWithScore_$1
});

function nonMaxSuppressionWithScoreAsync_$1(_x10, _x11, _x12) {
  return _nonMaxSuppressionWithScoreAsync_$.apply(this, arguments);
}

function _nonMaxSuppressionWithScoreAsync_$() {
  _nonMaxSuppressionWithScoreAsync_$ = _asyncToGenerator(function* (e, t, n) {
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : .5;
    var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : Number.NEGATIVE_INFINITY;
    var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : 0;
    var o = convertToTensor$1(e, "boxes", "nonMaxSuppressionAsync"),
        i = convertToTensor$1(t, "scores", "nonMaxSuppressionAsync"),
        l = nonMaxSuppSanityCheck$1(o, i, n, r, a, s);
    n = l.maxOutputSize, r = l.iouThreshold, a = l.scoreThreshold, s = l.softNmsSigma;
    var u = yield Promise.all([o.data(), i.data()]),
        c = u[0],
        p = u[1],
        {
      selectedIndices: d,
      selectedScores: h
    } = nonMaxSuppressionV5Impl$5(c, p, n, r, a, s);
    return o !== e && o.dispose(), i !== t && i.dispose(), {
      selectedIndices: tensor1d$1(d, "int32"),
      selectedScores: tensor1d$1(h)
    };
  });
  return _nonMaxSuppressionWithScoreAsync_$.apply(this, arguments);
}

var nonMaxSuppressionWithScoreAsync$1 = nonMaxSuppressionWithScoreAsync_$1;

function nonMaxSuppressionPadded_$1(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : .5;
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : Number.NEGATIVE_INFINITY;
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : !1;
  var o = convertToTensor$1(e, "boxes", "nonMaxSuppression"),
      i = convertToTensor$1(t, "scores", "nonMaxSuppression"),
      l = nonMaxSuppSanityCheck$1(o, i, n, r, a, null),
      u = ENGINE$1.runKernel(NonMaxSuppressionV4$1, {
    boxes: o,
    scores: i
  }, {
    maxOutputSize: l.maxOutputSize,
    iouThreshold: l.iouThreshold,
    scoreThreshold: l.scoreThreshold,
    padToMaxOutputSize: s
  });
  return {
    selectedIndices: u[0],
    validOutputs: u[1]
  };
}

var nonMaxSuppressionPadded$1 = op$1({
  nonMaxSuppressionPadded_: nonMaxSuppressionPadded_$1
});

function nonMaxSuppressionPaddedAsync_$1(_x13, _x14, _x15) {
  return _nonMaxSuppressionPaddedAsync_$.apply(this, arguments);
}

function _nonMaxSuppressionPaddedAsync_$() {
  _nonMaxSuppressionPaddedAsync_$ = _asyncToGenerator(function* (e, t, n) {
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : .5;
    var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : Number.NEGATIVE_INFINITY;
    var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : !1;
    var o = convertToTensor$1(e, "boxes", "nonMaxSuppressionAsync"),
        i = convertToTensor$1(t, "scores", "nonMaxSuppressionAsync"),
        l = nonMaxSuppSanityCheck$1(o, i, n, r, a, null),
        u = l.maxOutputSize,
        c = l.iouThreshold,
        p = l.scoreThreshold,
        [d, h] = yield Promise.all([o.data(), i.data()]),
        {
      selectedIndices: m,
      validOutputs: f
    } = nonMaxSuppressionV4Impl$5(d, h, u, c, p, s);
    return o !== e && o.dispose(), i !== t && i.dispose(), {
      selectedIndices: tensor1d$1(m, "int32"),
      validOutputs: scalar$1(f, "int32")
    };
  });
  return _nonMaxSuppressionPaddedAsync_$.apply(this, arguments);
}

var nonMaxSuppressionPaddedAsync$1 = nonMaxSuppressionPaddedAsync_$1;

function resizeBilinear_$1(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
  var a = convertToTensor$1(e, "images", "resizeBilinear");
  assert$6(3 === a.rank || 4 === a.rank, () => "Error in resizeBilinear: x must be rank 3 or 4, but got rank ".concat(a.rank, ".")), assert$6(2 === t.length, () => "Error in resizeBilinear: new shape must 2D, but got shape ".concat(t, ".")), assert$6(!1 === r || !1 === n, () => "Error in resizeBilinear: If halfPixelCenters is true, alignCorners must be false.");
  var s = a,
      o = !1;
  3 === a.rank && (o = !0, s = reshape$6(a, [1, a.shape[0], a.shape[1], a.shape[2]]));
  var i = ENGINE$1.runKernel(ResizeBilinear$1, {
    images: s
  }, {
    alignCorners: n,
    halfPixelCenters: r,
    size: t
  });
  return o ? reshape$6(i, [i.shape[1], i.shape[2], i.shape[3]]) : i;
}

var resizeBilinear$5 = op$1({
  resizeBilinear_: resizeBilinear_$1
});

function resizeNearestNeighbor_$1(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
  var a = convertToTensor$1(e, "images", "resizeNearestNeighbor");
  assert$6(3 === a.rank || 4 === a.rank, () => "Error in resizeNearestNeighbor: x must be rank 3 or 4, but got rank ".concat(a.rank, ".")), assert$6(2 === t.length, () => "Error in resizeNearestNeighbor: new shape must 2D, but got shape ".concat(t, ".")), assert$6("float32" === a.dtype || "int32" === a.dtype, () => "`images` must have `int32` or `float32` as dtype"), assert$6(!1 === r || !1 === n, () => "Error in resizeNearestNeighbor: If halfPixelCenters is true, alignCorners must be false.");
  var s = a,
      o = !1;
  3 === a.rank && (o = !0, s = reshape$6(a, [1, a.shape[0], a.shape[1], a.shape[2]]));
  var i = ENGINE$1.runKernel(ResizeNearestNeighbor$1, {
    images: s
  }, {
    alignCorners: n,
    halfPixelCenters: r,
    size: t
  });
  return o ? reshape$6(i, [i.shape[1], i.shape[2], i.shape[3]]) : i;
}

var resizeNearestNeighbor$5 = op$1({
  resizeNearestNeighbor_: resizeNearestNeighbor_$1
});

function threshold_$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : "binary";
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : .5;
  var a = convertToTensor$1(e, "image", "threshold"),
      s = a.shape[0] * a.shape[1];
  var o,
      i,
      l,
      u,
      c = mul$1(tensor1d$1([r]), 255);

  if (assert$6(3 === a.rank, () => "Error in threshold: image must be rank 3,but got rank ".concat(a.rank, ".")), assert$6(3 === a.shape[2] || 1 === a.shape[2], () => "Error in threshold: image color channel must be equal to 3 or 1but got ".concat(a.shape[2], ".")), assert$6("int32" === a.dtype || "float32" === a.dtype, () => "Error in dtype: image dtype must be int32 or float32,but got dtype ".concat(a.dtype, ".")), assert$6("otsu" === t || "binary" === t, () => "Method must be binary or otsu, but was ".concat(t)), 3 === a.shape[2]) {
    [o, i, l] = split$4(a, [1, 1, 1], -1);

    var _e66 = mul$1(o, .2989),
        _t54 = mul$1(i, .587),
        _n17 = mul$1(l, .114);

    u = add$5(add$5(_e66, _t54), _n17);
  } else u = e;

  "otsu" === t && (c = otsu$1(bincount$5(cast$7(round$6(u), "int32"), tensor$1([]), 256), s));
  var p = n ? lessEqual$5(u, c) : greater$6(u, c);
  return cast$7(mul$1(p, 255), "int32");
}

function otsu$1(e, t) {
  var n,
      r,
      a,
      s,
      o,
      i,
      l = tensor1d$1([-1]),
      u = tensor1d$1([0]),
      c = tensor1d$1([0]);

  for (var _p4 = 0; _p4 < e.size - 1; _p4++) {
    n = slice$5(e, 0, _p4 + 1), r = slice$5(e, _p4 + 1), o = div$3(sum$6(n), t), i = div$3(sum$6(r), t);
    var d = sum$6(mul$1(n, range$8(0, n.size)));
    a = div$3(d, sum$6(n));
    var h = fill$5(r.shape, n.size),
        m = add$5(range$8(0, r.size), h),
        f = mul$1(r, m);
    s = div$3(sum$6(f), sum$6(r));
    var g = sub$5(a, s),
        $ = sub$5(a, s),
        y = mul$1(o, i);
    c = mul$1(mul$1(y, g), $);
    var b = greater$6(c, u);
    u = where$1(b, c, u), l = where$1(b, tensor1d$1([_p4]), l);
  }

  return l;
}

var threshold$3 = op$1({
  threshold_: threshold_$1
});

function transform_$1(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : "nearest";
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : "constant";
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : 0;
  var s = arguments.length > 5 ? arguments[5] : undefined;
  var o = convertToTensor$1(e, "image", "transform", "float32"),
      i = convertToTensor$1(t, "transforms", "transform", "float32");
  return assert$6(4 === o.rank, () => "Error in transform: image must be rank 4,but got rank ".concat(o.rank, ".")), assert$6(2 === i.rank && (i.shape[0] === o.shape[0] || 1 === i.shape[0]) && 8 === i.shape[1], () => "Error in transform: Input transform should be batch x 8 or 1 x 8"), assert$6(null == s || 2 === s.length, () => "Error in transform: outputShape must be [height, width] or null, but got ".concat(s, ".")), ENGINE$1.runKernel(Transform$1, {
    image: o,
    transforms: i
  }, {
    interpolation: n,
    fillMode: r,
    fillValue: a,
    outputShape: s
  });
}

var transform$5 = op$1({
  transform_: transform_$1
});

function bandPart_$1(e, t, n) {
  assert$6(t % 1 == 0, () => "bandPart(): numLower must be an integer, got ".concat(t, ".")), assert$6(n % 1 == 0, () => "bandPart(): numUpper must be an integer, got ".concat(n, "."));
  var r = convertToTensor$1(e, "a", "bandPart");
  assert$6(r.rank >= 2, () => "bandPart(): Rank must be at least 2, got ".concat(r.rank, "."));
  var a = r.shape,
      [s, o] = r.shape.slice(-2);
  if (!(t <= s)) throw new Error("bandPart(): numLower (".concat(t, ") must not be greater than the number of rows (").concat(s, ")."));
  if (!(n <= o)) throw new Error("bandPart(): numUpper (".concat(n, ") must not be greater than the number of columns (").concat(o, ")."));
  t < 0 && (t = s), n < 0 && (n = o);
  var i = reshape$6(range$8(0, s, 1, "int32"), [-1, 1]),
      l = range$8(0, o, 1, "int32"),
      u = sub$5(i, l),
      c = logicalAnd$5(lessEqual$5(u, scalar$1(+t, "int32")), greaterEqual$5(u, scalar$1(-n, "int32"))),
      p = zeros$4([s, o], r.dtype);
  return reshape$6(stack$1(unstack$1(reshape$6(r, [-1, s, o])).map(e => where$1(c, e, p))), a);
}

var bandPart$1 = op$1({
  bandPart_: bandPart_$1
});

function gramSchmidt_$1(e) {
  var t;

  if (Array.isArray(e)) {
    (function () {
      t = !1, assert$6(null != e && e.length > 0, () => "Gram-Schmidt process: input must not be null, undefined, or empty");
      var n = e[0].shape[0];

      var _loop6 = function _loop6(_t55) {
        assert$6(e[_t55].shape[0] === n, () => "Gram-Schmidt: Non-unique lengths found in the input vectors: (".concat(e[_t55].shape[0], " vs. ").concat(n, ")"));
      };

      for (var _t55 = 1; _t55 < e.length; ++_t55) {
        _loop6(_t55);
      }
    })();
  } else t = !0, e = split$4(e, e.shape[0], 0).map(e => squeeze$1(e, [0]));

  assert$6(e.length <= e[0].shape[0], () => "Gram-Schmidt: Number of vectors (".concat(e.length, ") exceeds number of dimensions (").concat(e[0].shape[0], ")."));
  var n = [],
      r = e;

  var _loop7 = function _loop7(_t56) {
    n.push(ENGINE$1.tidy(() => {
      var e = r[_t56];
      if (_t56 > 0) for (var _r19 = 0; _r19 < _t56; ++_r19) {
        var _t57 = mul$1(sum$6(mul$1(n[_r19], e)), n[_r19]);

        e = sub$5(e, _t57);
      }
      return div$3(e, norm$1(e, "euclidean"));
    }));
  };

  for (var _t56 = 0; _t56 < e.length; ++_t56) {
    _loop7(_t56);
  }

  return t ? stack$1(n, 0) : n;
}

var gramSchmidt$1 = op$1({
  gramSchmidt_: gramSchmidt_$1
});

function qr_$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;
  if (assert$6(e.rank >= 2, () => "qr() requires input tensor to have a rank >= 2, but got rank ".concat(e.rank)), 2 === e.rank) return qr2d$1(e, t);
  {
    var n = e.shape.slice(0, e.shape.length - 2).reduce((e, t) => e * t),
        r = unstack$1(reshape$6(e, [n, e.shape[e.shape.length - 2], e.shape[e.shape.length - 1]]), 0),
        a = [],
        s = [];
    return r.forEach(e => {
      var [n, r] = qr2d$1(e, t);
      a.push(n), s.push(r);
    }), [reshape$6(stack$1(a, 0), e.shape), reshape$6(stack$1(s, 0), e.shape)];
  }
}

function qr2d$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;
  return ENGINE$1.tidy(() => {
    assert$6(2 === e.shape.length, () => "qr2d() requires a 2D Tensor, but got a ".concat(e.shape.length, "D Tensor."));
    var n = e.shape[0],
        r = e.shape[1];
    var a = eye$1(n),
        s = clone$1(e);
    var o = tensor2d$1([[1]], [1, 1]);
    var i = clone$1(o);
    var l = n >= r ? r : n;

    var _loop8 = function _loop8(_e67) {
      var t = s,
          l = i,
          u = a;
      [i, s, a] = ENGINE$1.tidy(() => {
        var t = slice$5(s, [_e67, _e67], [n - _e67, 1]),
            l = norm$1(t),
            u = slice$5(s, [_e67, _e67], [1, 1]),
            c = where$1(greater$6(u, 0), tensor2d$1([[-1]]), tensor2d$1([[1]])),
            p = sub$5(u, mul$1(c, l)),
            d = div$3(t, p);
        i = 1 === d.shape[0] ? clone$1(o) : concat$5([o, slice$5(d, [1, 0], [d.shape[0] - 1, d.shape[1]])], 0);
        var h = neg$5(div$3(matMul$3(c, p), l)),
            m = slice$5(s, [_e67, 0], [n - _e67, r]),
            f = mul$1(h, i),
            g = transpose$5(i);
        if (0 === _e67) s = sub$5(m, matMul$3(f, matMul$3(g, m)));else {
          var _t58 = sub$5(m, matMul$3(f, matMul$3(g, m)));

          s = concat$5([slice$5(s, [0, 0], [_e67, r]), _t58], 0);
        }
        var $ = transpose$5(f),
            y = slice$5(a, [0, _e67], [n, a.shape[1] - _e67]);
        if (0 === _e67) a = sub$5(y, matMul$3(matMul$3(y, i), $));else {
          var _t59 = sub$5(y, matMul$3(matMul$3(y, i), $));

          a = concat$5([slice$5(a, [0, 0], [n, _e67]), _t59], 1);
        }
        return [i, s, a];
      }), dispose$1([t, l, u]);
    };

    for (var _e67 = 0; _e67 < l; ++_e67) {
      _loop8(_e67);
    }

    return !t && n > r && (a = slice$5(a, [0, 0], [n, r]), s = slice$5(s, [0, 0], [r, r])), [a, s];
  });
}

var qr$1 = op$1({
  qr_: qr_$1
});
var Reduction$1;

function computeWeightedLoss_$1(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : Reduction$1.SUM_BY_NONZERO_WEIGHTS;
  var r = convertToTensor$1(e, "losses", "computeWeightedLoss");
  var a = null;
  null != t && (a = convertToTensor$1(t, "weights", "computeWeightedLoss"));
  var s = null == a ? r : mul$1(r, a);
  if (n === Reduction$1.NONE) return s;
  if (n === Reduction$1.SUM) return sum$6(s);

  if (n === Reduction$1.MEAN) {
    if (null == a) return mean$3(s);
    {
      var _e68 = r.size / a.size,
          _t60 = div$3(sum$6(s), sum$6(a));

      return _e68 > 1 ? div$3(_t60, scalar$1(_e68)) : _t60;
    }
  }

  if (n === Reduction$1.SUM_BY_NONZERO_WEIGHTS) {
    if (null == a) return div$3(sum$6(s), scalar$1(r.size));
    {
      var _e69 = mul$1(a, ones$3(r.shape)),
          _t61 = cast$7(sum$6(notEqual$5(_e69, scalar$1(0))), "float32");

      return div$3(sum$6(s), _t61);
    }
  }

  throw Error("Unknown reduction: ".concat(n));
}

!function (e) {
  e[e.NONE = 0] = "NONE", e[e.MEAN = 1] = "MEAN", e[e.SUM = 2] = "SUM", e[e.SUM_BY_NONZERO_WEIGHTS = 3] = "SUM_BY_NONZERO_WEIGHTS";
}(Reduction$1 || (Reduction$1 = {}));
var computeWeightedLoss$3 = op$1({
  computeWeightedLoss_: computeWeightedLoss_$1
});

function absoluteDifference_$1(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : Reduction$1.SUM_BY_NONZERO_WEIGHTS;
  var a = convertToTensor$1(e, "labels", "absoluteDifference"),
      s = convertToTensor$1(t, "predictions", "absoluteDifference");
  var o = null;
  null != n && (o = convertToTensor$1(n, "weights", "absoluteDifference")), assertShapesMatch$1(a.shape, s.shape, "Error in absoluteDifference: ");
  var i = abs$5(sub$5(a, s));
  return computeWeightedLoss$3(i, o, r);
}

var absoluteDifference$1 = op$1({
  absoluteDifference_: absoluteDifference_$1
});

function cosineDistance_$1(e, t, n, r) {
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : Reduction$1.SUM_BY_NONZERO_WEIGHTS;
  var s = convertToTensor$1(e, "labels", "cosineDistance"),
      o = convertToTensor$1(t, "predictions", "cosineDistance");
  var i = null;
  null != r && (i = convertToTensor$1(r, "weights", "cosineDistance")), assertShapesMatch$1(s.shape, o.shape, "Error in cosineDistance: ");
  var l = scalar$1(1),
      u = sub$5(l, sum$6(mul$1(s, o), n, !0));
  return computeWeightedLoss$3(u, i, a);
}

var cosineDistance$1 = op$1({
  cosineDistance_: cosineDistance_$1
});

function hingeLoss_$1(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : Reduction$1.SUM_BY_NONZERO_WEIGHTS;
  var a = convertToTensor$1(e, "labels", "hingeLoss");
  var s = convertToTensor$1(t, "predictions", "hingeLoss");
  var o = null;
  null != n && (o = convertToTensor$1(n, "weights", "hingeLoss")), assertShapesMatch$1(a.shape, s.shape, "Error in hingeLoss: ");
  var i = scalar$1(1);
  a = sub$5(mul$1(scalar$1(2), a), i);
  var l = relu$6(sub$5(i, mul$1(a, s)));
  return computeWeightedLoss$3(l, o, r);
}

var hingeLoss$1 = op$1({
  hingeLoss_: hingeLoss_$1
});

function huberLoss_$1(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 1;
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : Reduction$1.SUM_BY_NONZERO_WEIGHTS;
  var s = convertToTensor$1(e, "labels", "huberLoss"),
      o = convertToTensor$1(t, "predictions", "huberLoss");
  var i = null;
  null != n && (i = convertToTensor$1(n, "weights", "huberLoss")), assertShapesMatch$1(s.shape, o.shape, "Error in huberLoss: ");
  var l = scalar$1(r),
      u = abs$5(sub$5(o, s)),
      c = minimum$6(u, l),
      p = sub$5(u, c),
      d = add$5(mul$1(scalar$1(.5), square$5(c)), mul$1(l, p));
  return computeWeightedLoss$3(d, i, a);
}

var huberLoss$1 = op$1({
  huberLoss_: huberLoss_$1
});

function logLoss_$1(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 1e-7;
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : Reduction$1.SUM_BY_NONZERO_WEIGHTS;
  var s = convertToTensor$1(e, "labels", "logLoss"),
      o = convertToTensor$1(t, "predictions", "logLoss");
  var i = null;
  null != n && (i = convertToTensor$1(n, "weights", "logLoss")), assertShapesMatch$1(s.shape, o.shape, "Error in logLoss: ");
  var l = scalar$1(1),
      u = scalar$1(r),
      c = neg$5(mul$1(s, log$7(add$5(o, u)))),
      p = mul$1(sub$5(l, s), log$7(add$5(sub$5(l, o), u))),
      d = sub$5(c, p);
  return computeWeightedLoss$3(d, i, a);
}

var logLoss$1 = op$1({
  logLoss_: logLoss_$1
});

function meanSquaredError_$1(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : Reduction$1.SUM_BY_NONZERO_WEIGHTS;
  var a = convertToTensor$1(e, "labels", "meanSquaredError"),
      s = convertToTensor$1(t, "predictions", "meanSquaredError");
  var o = null;
  null != n && (o = convertToTensor$1(n, "weights", "meanSquaredError")), assertShapesMatch$1(a.shape, s.shape, "Error in meanSquaredError: ");
  var i = squaredDifference$5(a, s);
  return computeWeightedLoss$3(i, o, r);
}

var meanSquaredError$4 = op$1({
  meanSquaredError_: meanSquaredError_$1
});

function sigmoidCrossEntropyWithLogits_$1(e, t) {
  var n = convertToTensor$1(e, "labels", "sigmoidCrossEntropyWithLogits"),
      r = convertToTensor$1(t, "logits", "sigmoidCrossEntropyWithLogits");
  assertShapesMatch$1(n.shape, r.shape, "Error in sigmoidCrossEntropyWithLogits: ");
  var a = relu$6(r),
      s = mul$1(r, n),
      o = log1p$5(exp$5(neg$5(abs$5(r))));
  return add$5(sub$5(a, s), o);
}

function sigmoidCrossEntropy_$1(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 0;
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : Reduction$1.SUM_BY_NONZERO_WEIGHTS;
  var s = convertToTensor$1(e, "multiClassLabels", "sigmoidCrossEntropy");
  var o = convertToTensor$1(t, "logits", "sigmoidCrossEntropy");
  var i = null;

  if (null != n && (i = convertToTensor$1(n, "weights", "sigmoidCrossEntropy")), assertShapesMatch$1(s.shape, o.shape, "Error in sigmoidCrossEntropy: "), r > 0) {
    var _e70 = scalar$1(r),
        _t62 = scalar$1(1),
        _n18 = scalar$1(.5);

    s = add$5(mul$1(s, sub$5(_t62, _e70)), mul$1(_n18, _e70));
  }

  var l = sigmoidCrossEntropyWithLogits_$1(s, o);
  return computeWeightedLoss$3(l, i, a);
}

var sigmoidCrossEntropy$1 = op$1({
  sigmoidCrossEntropy_: sigmoidCrossEntropy_$1
});

function softmaxCrossEntropyWithLogits_$1(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : -1;
  if (-1 === n && (n = t.rank - 1), n !== t.rank - 1) throw Error("Softmax cross entropy along a non-last dimension is not yet supported. Labels / logits was rank ".concat(t.rank, " and dim was ").concat(n));
  var r = customGrad$1((e, t, r) => {
    var a = logSumExp$1(t, [n], !0),
        s = sub$5(cast$7(t, "float32"), a);
    r([e, s]);
    var o = neg$5(mul$1(s, e));
    return {
      value: sum$6(o, [n]),
      gradFunc: (e, t) => {
        var [r, a] = t,
            s = expandShapeToKeepDim$1(e.shape, [n]);
        return [mul$1(reshape$6(e, s), sub$5(cast$7(r, "float32"), exp$5(a))), mul$1(reshape$6(e, s), sub$5(exp$5(a), cast$7(r, "float32")))];
      }
    };
  });
  return r(e, t);
}

function softmaxCrossEntropy_$1(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 0;
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : Reduction$1.SUM_BY_NONZERO_WEIGHTS;
  var s = convertToTensor$1(e, "onehotLabels", "softmaxCrossEntropy");
  var o = convertToTensor$1(t, "logits", "softmaxCrossEntropy");
  var i = null;

  if (null != n && (i = convertToTensor$1(n, "weights", "softmaxCrossEntropy")), assertShapesMatch$1(s.shape, o.shape, "Error in softmaxCrossEntropy: "), r > 0) {
    var _e71 = scalar$1(r),
        _t63 = scalar$1(1),
        _n19 = scalar$1(s.shape[1]);

    s = add$5(mul$1(s, sub$5(_t63, _e71)), div$3(_e71, _n19));
  }

  var l = softmaxCrossEntropyWithLogits_$1(s, o);
  return computeWeightedLoss$3(l, i, a);
}

var softmaxCrossEntropy$1 = op$1({
  softmaxCrossEntropy_: softmaxCrossEntropy_$1
});

function sparseFillEmptyRows_$1(e, t, n, r) {
  var a = convertToTensor$1(e, "indices", "sparseFillEmptyRows"),
      s = convertToTensor$1(t, "values", "sparseFillEmptyRows"),
      o = convertToTensor$1(n, "denseShape", "sparseFillEmptyRows"),
      i = convertToTensor$1(r, "defaultValue", "sparseFillEmptyRows", s.dtype);
  if (2 !== a.rank) throw new Error("Indices should be Tensor2D but received shape\n        ".concat(a.shape));
  if (1 !== s.rank) throw new Error("Values should be Tensor1D but received shape ".concat(s.shape));
  if (1 !== o.rank) throw new Error("Dense shape should be Tensor1D but received shape ".concat(o.shape));
  if (0 !== i.rank) throw new Error("Default value should be a scalar but received shape ".concat(i.shape));
  var l = ENGINE$1.runKernel(SparseFillEmptyRows$1, {
    indices: a,
    values: s,
    denseShape: o,
    defaultValue: i
  });
  return {
    outputIndices: l[0],
    outputValues: l[1],
    emptyRowIndicator: l[2],
    reverseIndexMap: l[3]
  };
}

var sparseFillEmptyRows$5 = op$1({
  sparseFillEmptyRows_: sparseFillEmptyRows_$1
});

function sparseReshape_$1(e, t, n) {
  var r = convertToTensor$1(e, "inputIndices", "sparseReshape"),
      a = convertToTensor$1(t, "inputShape", "sparseReshape"),
      s = convertToTensor$1(n, "newShape", "sparseReshape");
  if (2 !== r.rank) throw new Error("Input indices should be Tensor2D but received shape\n        ".concat(r.shape));
  if (1 !== a.rank) throw new Error("Input shape should be Tensor1D but received shape ".concat(a.shape));
  if (1 !== s.rank) throw new Error("New shape should be Tensor1D but received shape ".concat(s.shape));
  var o = ENGINE$1.runKernel(SparseReshape$1, {
    inputIndices: r,
    inputShape: a,
    newShape: s
  });
  return {
    outputIndices: o[0],
    outputShape: o[1]
  };
}

var sparseReshape$5 = op$1({
  sparseReshape_: sparseReshape_$1
});

function sparseSegmentMean_$1(e, t, n) {
  var r = convertToTensor$1(e, "data", "sparseSegmentMean"),
      a = convertToTensor$1(t, "indices", "sparseSegmentMean"),
      s = convertToTensor$1(n, "segmentIds", "sparseSegmentMean");
  if (r.rank < 1) throw new Error("Data should be at least 1 dimensional but received scalar");
  if (1 !== a.rank) throw new Error("Indices should be Tensor1D but received shape\n          ".concat(a.shape));
  if (1 !== s.rank) throw new Error("Segment ids should be Tensor1D but received shape\n          ".concat(s.shape));
  return ENGINE$1.runKernel(SparseSegmentMean$1, {
    data: r,
    indices: a,
    segmentIds: s
  });
}

var sparseSegmentMean$5 = op$1({
  sparseSegmentMean_: sparseSegmentMean_$1
});

function sparseSegmentSum_$1(e, t, n) {
  var r = convertToTensor$1(e, "data", "sparseSegmentSum"),
      a = convertToTensor$1(t, "indices", "sparseSegmentSum"),
      s = convertToTensor$1(n, "segmentIds", "sparseSegmentSum");
  if (r.rank < 1) throw new Error("Data should be at least 1 dimensional but received scalar");
  if (1 !== a.rank) throw new Error("Indices should be Tensor1D but received shape\n         ".concat(a.shape));
  if (1 !== s.rank) throw new Error("Segment ids should be Tensor1D but received shape\n         ".concat(s.shape));
  return ENGINE$1.runKernel(SparseSegmentSum$1, {
    data: r,
    indices: a,
    segmentIds: s
  });
}

var sparseSegmentSum$5 = op$1({
  sparseSegmentSum_: sparseSegmentSum_$1
});

function stringNGrams_$1(e, t, n, r, a, s, o, i) {
  var l = convertToTensor$1(e, "data", "stringNGrams", "string");
  if ("string" !== l.dtype) throw new Error("Data must be of datatype string");
  if (1 !== l.shape.length) throw new Error("Data must be a vector, saw: ".concat(l.shape));
  var u = convertToTensor$1(t, "dataSplits", "stringNGrams");
  if ("int32" !== u.dtype) throw new Error("Data splits must be of datatype int32");
  var c = ENGINE$1.runKernel(StringNGrams$1, {
    data: l,
    dataSplits: u
  }, {
    separator: n,
    nGramWidths: r,
    leftPad: a,
    rightPad: s,
    padWidth: o,
    preserveShortSequences: i
  });
  return {
    nGrams: c[0],
    nGramsSplits: c[1]
  };
}

var stringNGrams$5 = op$1({
  stringNGrams_: stringNGrams_$1
});

function stringSplit_$1(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !0;
  var r = convertToTensor$1(e, "input", "stringSplit", "string"),
      a = convertToTensor$1(t, "delimiter", "stringSplit", "string");
  if (1 !== r.rank) throw new Error("Input should be Tensor1D but received shape ".concat(r.shape));
  if (0 !== a.rank) throw new Error("Delimiter should be a scalar but received shape ".concat(a.shape));
  var s = ENGINE$1.runKernel(StringSplit$1, {
    input: r,
    delimiter: a
  }, {
    skipEmpty: n
  });
  return {
    indices: s[0],
    values: s[1],
    shape: s[2]
  };
}

var stringSplit$5 = op$1({
  stringSplit_: stringSplit_$1
});

function stringToHashBucketFast_$1(e, t) {
  var n = convertToTensor$1(e, "input", "stringToHashBucketFast", "string"),
      r = {
    numBuckets: t
  };
  if (t <= 0) throw new Error("Number of buckets must be at least 1");
  return ENGINE$1.runKernel(StringToHashBucketFast$1, {
    input: n
  }, r);
}

var stringToHashBucketFast$5 = op$1({
  stringToHashBucketFast_: stringToHashBucketFast_$1
}),
    image$2 = {
  flipLeftRight: flipLeftRight$1,
  resizeNearestNeighbor: resizeNearestNeighbor$5,
  resizeBilinear: resizeBilinear$5,
  rotateWithOffset: rotateWithOffset$1,
  cropAndResize: cropAndResize$5,
  nonMaxSuppression: nonMaxSuppression$1,
  nonMaxSuppressionAsync: nonMaxSuppressionAsync$1,
  nonMaxSuppressionWithScore: nonMaxSuppressionWithScore$1,
  nonMaxSuppressionWithScoreAsync: nonMaxSuppressionWithScoreAsync$1,
  nonMaxSuppressionPadded: nonMaxSuppressionPadded$1,
  nonMaxSuppressionPaddedAsync: nonMaxSuppressionPaddedAsync$1,
  threshold: threshold$3,
  transform: transform$5
},
    linalg$1 = {
  bandPart: bandPart$1,
  gramSchmidt: gramSchmidt$1,
  qr: qr$1
};

class Optimizer$1 extends Serializable$1 {
  minimize(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;
    var n = arguments.length > 2 ? arguments[2] : undefined;
    var {
      value: r,
      grads: a
    } = this.computeGradients(e, n);

    if (null != n) {
      var _e72 = n.map(e => ({
        name: e.name,
        tensor: a[e.name]
      }));

      this.applyGradients(_e72);
    } else this.applyGradients(a);

    return dispose$1(a), t ? r : (r.dispose(), null);
  }

  get iterations() {
    return null == this.iterations_ && (this.iterations_ = 0), this.iterations_;
  }

  incrementIterations() {
    this.iterations_ = this.iterations + 1;
  }

  computeGradients(e, t) {
    return variableGrads$1(e, t);
  }

  dispose() {
    null != this.iterations_ && dispose$1(this.iterations_);
  }

  saveIterations() {
    var _this23 = this;

    return _asyncToGenerator(function* () {
      return null == _this23.iterations_ && (_this23.iterations_ = 0), {
        name: "iter",
        tensor: scalar$1(_this23.iterations_, "int32")
      };
    })();
  }

  getWeights() {
    return _asyncToGenerator(function* () {
      throw new Error("getWeights() is not implemented for this optimizer yet.");
    })();
  }

  setWeights(e) {
    var _this24 = this;

    return _asyncToGenerator(function* () {
      throw new Error("setWeights() is not implemented for this optimizer class ".concat(_this24.getClassName()));
    })();
  }

  extractIterations(e) {
    var _this25 = this;

    return _asyncToGenerator(function* () {
      return _this25.iterations_ = (yield e[0].tensor.data())[0], e.slice(1);
    })();
  }

}

Object.defineProperty(Optimizer$1, Symbol.hasInstance, {
  value: e => null != e.minimize && null != e.computeGradients && null != e.applyGradients
});

class AdadeltaOptimizer$1 extends Optimizer$1 {
  constructor(e, t) {
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;
    super(), this.learningRate = e, this.rho = t, this.epsilon = n, this.accumulatedGrads = [], this.accumulatedUpdates = [], null == n && (this.epsilon = ENGINE$1.backend.epsilon());
  }

  applyGradients(e) {
    (Array.isArray(e) ? e.map(e => e.name) : Object.keys(e)).forEach((t, n) => {
      var r = ENGINE$1.registeredVariables[t];
      null == this.accumulatedGrads[n] && (this.accumulatedGrads[n] = {
        originalName: "".concat(t, "/accum_grad"),
        variable: tidy$1(() => zerosLike$5(r).variable(!1))
      }), null == this.accumulatedUpdates[n] && (this.accumulatedUpdates[n] = {
        originalName: "".concat(t, "/accum_var"),
        variable: tidy$1(() => zerosLike$5(r).variable(!1))
      });
      var a = Array.isArray(e) ? e[n].tensor : e[t];
      if (null == a) return;
      var s = this.accumulatedGrads[n].variable,
          o = this.accumulatedUpdates[n].variable;
      tidy$1(() => {
        var e = add$5(mul$1(s, this.rho), mul$1(square$5(a), 1 - this.rho)),
            t = mul$1(div$3(sqrt$5(add$5(o, this.epsilon)), sqrt$5(add$5(s, this.epsilon))), a),
            n = add$5(mul$1(o, this.rho), mul$1(square$5(t), 1 - this.rho));
        s.assign(e), o.assign(n);
        var i = add$5(mul$1(t, -this.learningRate), r);
        r.assign(i);
      });
    }), this.incrementIterations();
  }

  dispose() {
    null != this.accumulatedUpdates && (dispose$1(this.accumulatedGrads.map(e => e.variable)), dispose$1(this.accumulatedUpdates.map(e => e.variable)));
  }

  getWeights() {
    var _this26 = this;

    return _asyncToGenerator(function* () {
      var e = [..._this26.accumulatedGrads, ..._this26.accumulatedUpdates];
      return [yield _this26.saveIterations()].concat(e.map(e => ({
        name: e.originalName,
        tensor: e.variable
      })));
    })();
  }

  setWeights(e) {
    var _this27 = this;

    return _asyncToGenerator(function* () {
      var t = (e = yield _this27.extractIterations(e)).length / 2;
      _this27.accumulatedGrads = e.slice(0, t).map(e => ({
        originalName: e.name,
        variable: e.tensor.variable(!1)
      })), _this27.accumulatedUpdates = e.slice(t, 2 * t).map(e => ({
        originalName: e.name,
        variable: e.tensor.variable(!1)
      }));
    })();
  }

  getConfig() {
    return {
      learningRate: this.learningRate,
      rho: this.rho,
      epsilon: this.epsilon
    };
  }

  static fromConfig(e, t) {
    return new e(t.learningRate, t.rho, t.epsilon);
  }

}

AdadeltaOptimizer$1.className = "Adadelta", registerClass$1(AdadeltaOptimizer$1);

class AdagradOptimizer$1 extends Optimizer$1 {
  constructor(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : .1;
    super(), this.learningRate = e, this.initialAccumulatorValue = t, this.accumulatedGrads = [];
  }

  applyGradients(e) {
    (Array.isArray(e) ? e.map(e => e.name) : Object.keys(e)).forEach((t, n) => {
      var r = ENGINE$1.registeredVariables[t];

      if (null == this.accumulatedGrads[n]) {
        var _e73 = !1;

        this.accumulatedGrads[n] = {
          originalName: "".concat(t, "/accumulator"),
          variable: tidy$1(() => fill$5(r.shape, this.initialAccumulatorValue).variable(_e73))
        };
      }

      var a = Array.isArray(e) ? e[n].tensor : e[t];
      if (null == a) return;
      var s = this.accumulatedGrads[n].variable;
      tidy$1(() => {
        var e = add$5(s, square$5(a));
        s.assign(e);
        var t = add$5(mul$1(div$3(a, sqrt$5(add$5(e, ENGINE$1.backend.epsilon()))), -this.learningRate), r);
        r.assign(t);
      });
    }), this.incrementIterations();
  }

  dispose() {
    null != this.accumulatedGrads && dispose$1(this.accumulatedGrads.map(e => e.variable));
  }

  getWeights() {
    var _this28 = this;

    return _asyncToGenerator(function* () {
      return [yield _this28.saveIterations()].concat(_this28.accumulatedGrads.map(e => ({
        name: e.originalName,
        tensor: e.variable
      })));
    })();
  }

  setWeights(e) {
    var _this29 = this;

    return _asyncToGenerator(function* () {
      e = yield _this29.extractIterations(e), _this29.accumulatedGrads = e.map(e => ({
        originalName: e.name,
        variable: e.tensor.variable(!1)
      }));
    })();
  }

  getConfig() {
    return {
      learningRate: this.learningRate,
      initialAccumulatorValue: this.initialAccumulatorValue
    };
  }

  static fromConfig(e, t) {
    return new e(t.learningRate, t.initialAccumulatorValue);
  }

}

AdagradOptimizer$1.className = "Adagrad", registerClass$1(AdagradOptimizer$1);

class AdamOptimizer$1 extends Optimizer$1 {
  constructor(e, t, n) {
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : null;
    super(), this.learningRate = e, this.beta1 = t, this.beta2 = n, this.epsilon = r, this.accumulatedFirstMoment = [], this.accumulatedSecondMoment = [], tidy$1(() => {
      this.accBeta1 = scalar$1(t).variable(), this.accBeta2 = scalar$1(n).variable();
    }), null == r && (this.epsilon = ENGINE$1.backend.epsilon());
  }

  applyGradients(e) {
    var t = Array.isArray(e) ? e.map(e => e.name) : Object.keys(e);
    tidy$1(() => {
      var n = sub$5(1, this.accBeta1),
          r = sub$5(1, this.accBeta2);
      t.forEach((t, a) => {
        var s = ENGINE$1.registeredVariables[t];
        null == this.accumulatedFirstMoment[a] && (this.accumulatedFirstMoment[a] = {
          originalName: "".concat(t, "/m"),
          variable: tidy$1(() => zerosLike$5(s).variable(!1))
        }), null == this.accumulatedSecondMoment[a] && (this.accumulatedSecondMoment[a] = {
          originalName: "".concat(t, "/v"),
          variable: tidy$1(() => zerosLike$5(s).variable(!1))
        });
        var o = Array.isArray(e) ? e[a].tensor : e[t];
        if (null == o) return;
        var i = this.accumulatedFirstMoment[a].variable,
            l = this.accumulatedSecondMoment[a].variable,
            u = add$5(mul$1(i, this.beta1), mul$1(o, 1 - this.beta1)),
            c = add$5(mul$1(l, this.beta2), mul$1(square$5(o), 1 - this.beta2)),
            p = div$3(u, n),
            d = div$3(c, r);
        i.assign(u), l.assign(c);
        var h = add$5(mul$1(div$3(p, add$5(sqrt$5(d), this.epsilon)), -this.learningRate), s);
        s.assign(h);
      }), this.accBeta1.assign(mul$1(this.accBeta1, this.beta1)), this.accBeta2.assign(mul$1(this.accBeta2, this.beta2));
    }), this.incrementIterations();
  }

  dispose() {
    this.accBeta1.dispose(), this.accBeta2.dispose(), null != this.accumulatedFirstMoment && dispose$1(this.accumulatedFirstMoment.map(e => e.variable)), null != this.accumulatedSecondMoment && dispose$1(this.accumulatedSecondMoment.map(e => e.variable));
  }

  getWeights() {
    var _this30 = this;

    return _asyncToGenerator(function* () {
      var e = [..._this30.accumulatedFirstMoment, ..._this30.accumulatedSecondMoment];
      return [yield _this30.saveIterations()].concat(e.map(e => ({
        name: e.originalName,
        tensor: e.variable
      })));
    })();
  }

  setWeights(e) {
    var _this31 = this;

    return _asyncToGenerator(function* () {
      e = yield _this31.extractIterations(e), tidy$1(() => {
        _this31.accBeta1.assign(pow$5(_this31.beta1, _this31.iterations_ + 1)), _this31.accBeta2.assign(pow$5(_this31.beta2, _this31.iterations_ + 1));
      });
      var t = e.length / 2;
      _this31.accumulatedFirstMoment = e.slice(0, t).map(e => ({
        originalName: e.name,
        variable: e.tensor.variable(!1)
      })), _this31.accumulatedSecondMoment = e.slice(t, 2 * t).map(e => ({
        originalName: e.name,
        variable: e.tensor.variable(!1)
      }));
    })();
  }

  getConfig() {
    return {
      learningRate: this.learningRate,
      beta1: this.beta1,
      beta2: this.beta2,
      epsilon: this.epsilon
    };
  }

  static fromConfig(e, t) {
    return new e(t.learningRate, t.beta1, t.beta2, t.epsilon);
  }

}

AdamOptimizer$1.className = "Adam", registerClass$1(AdamOptimizer$1);

class AdamaxOptimizer$1 extends Optimizer$1 {
  constructor(e, t, n) {
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : null;
    var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : 0;
    super(), this.learningRate = e, this.beta1 = t, this.beta2 = n, this.epsilon = r, this.decay = a, this.accumulatedFirstMoment = [], this.accumulatedWeightedInfNorm = [], tidy$1(() => {
      this.iteration = scalar$1(0).variable(), this.accBeta1 = scalar$1(t).variable();
    }), null == r && (this.epsilon = ENGINE$1.backend.epsilon());
  }

  applyGradients(e) {
    var t = Array.isArray(e) ? e.map(e => e.name) : Object.keys(e);
    tidy$1(() => {
      var n = sub$5(1, this.accBeta1),
          r = div$3(-this.learningRate, add$5(mul$1(this.iteration, this.decay), 1));
      t.forEach((t, a) => {
        var s = ENGINE$1.registeredVariables[t];
        null == this.accumulatedFirstMoment[a] && (this.accumulatedFirstMoment[a] = {
          originalName: "".concat(t, "/m"),
          variable: zerosLike$5(s).variable(!1)
        }), null == this.accumulatedWeightedInfNorm[a] && (this.accumulatedWeightedInfNorm[a] = {
          originalName: "".concat(t, "/v"),
          variable: zerosLike$5(s).variable(!1)
        });
        var o = Array.isArray(e) ? e[a].tensor : e[t];
        if (null == o) return;
        var i = this.accumulatedFirstMoment[a].variable,
            l = this.accumulatedWeightedInfNorm[a].variable,
            u = add$5(mul$1(i, this.beta1), mul$1(o, 1 - this.beta1)),
            c = mul$1(l, this.beta2),
            p = abs$5(o),
            d = maximum$6(c, p);
        i.assign(u), l.assign(d);
        var h = add$5(mul$1(div$3(r, n), div$3(u, add$5(d, this.epsilon))), s);
        s.assign(h);
      }), this.iteration.assign(add$5(this.iteration, 1)), this.accBeta1.assign(mul$1(this.accBeta1, this.beta1));
    }), this.incrementIterations();
  }

  dispose() {
    this.accBeta1.dispose(), this.iteration.dispose(), null != this.accumulatedFirstMoment && dispose$1(this.accumulatedFirstMoment.map(e => e.variable)), null != this.accumulatedWeightedInfNorm && dispose$1(this.accumulatedWeightedInfNorm.map(e => e.variable));
  }

  getWeights() {
    return _asyncToGenerator(function* () {
      throw new Error("getWeights() is not implemented for Adamax yet.");
    })();
  }

  setWeights(e) {
    return _asyncToGenerator(function* () {
      throw new Error("setWeights() is not implemented for Adamax yet.");
    })();
  }

  getConfig() {
    return {
      learningRate: this.learningRate,
      beta1: this.beta1,
      beta2: this.beta2,
      epsilon: this.epsilon,
      decay: this.decay
    };
  }

  static fromConfig(e, t) {
    return new e(t.learningRate, t.beta1, t.beta2, t.epsilon, t.decay);
  }

}

AdamaxOptimizer$1.className = "Adamax", registerClass$1(AdamaxOptimizer$1);

class SGDOptimizer$1 extends Optimizer$1 {
  constructor(e) {
    super(), this.learningRate = e, this.setLearningRate(e);
  }

  applyGradients(e) {
    (Array.isArray(e) ? e.map(e => e.name) : Object.keys(e)).forEach((t, n) => {
      var r = Array.isArray(e) ? e[n].tensor : e[t];
      if (null == r) return;
      var a = ENGINE$1.registeredVariables[t];
      tidy$1(() => {
        var e = add$5(mul$1(this.c, r), a);
        a.assign(e);
      });
    }), this.incrementIterations();
  }

  setLearningRate(e) {
    this.learningRate = e, null != this.c && this.c.dispose(), this.c = keep$1(scalar$1(-e));
  }

  dispose() {
    this.c.dispose();
  }

  getWeights() {
    var _this32 = this;

    return _asyncToGenerator(function* () {
      return [yield _this32.saveIterations()];
    })();
  }

  setWeights(e) {
    var _this33 = this;

    return _asyncToGenerator(function* () {
      if (0 !== (e = yield _this33.extractIterations(e)).length) throw new Error("SGD optimizer does not have settable weights.");
    })();
  }

  getConfig() {
    return {
      learningRate: this.learningRate
    };
  }

  static fromConfig(e, t) {
    return new e(t.learningRate);
  }

}

SGDOptimizer$1.className = "SGD", registerClass$1(SGDOptimizer$1);

class MomentumOptimizer$1 extends SGDOptimizer$1 {
  constructor(e, t) {
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
    super(e), this.learningRate = e, this.momentum = t, this.useNesterov = n, this.accumulations = [], this.m = scalar$1(this.momentum);
  }

  applyGradients(e) {
    (Array.isArray(e) ? e.map(e => e.name) : Object.keys(e)).forEach((t, n) => {
      var r = ENGINE$1.registeredVariables[t];

      if (null == this.accumulations[n]) {
        var _e74 = !1;

        this.accumulations[n] = {
          originalName: "".concat(t, "/momentum"),
          variable: tidy$1(() => zerosLike$5(r).variable(_e74))
        };
      }

      var a = this.accumulations[n].variable,
          s = Array.isArray(e) ? e[n].tensor : e[t];
      null != s && tidy$1(() => {
        var e;
        var t = add$5(mul$1(this.m, a), s);
        e = add$5(mul$1(this.c, this.useNesterov ? add$5(s, mul$1(t, this.m)) : t), r), a.assign(t), r.assign(e);
      });
    }), this.incrementIterations();
  }

  dispose() {
    this.m.dispose(), null != this.accumulations && dispose$1(this.accumulations.map(e => e.variable));
  }

  setMomentum(e) {
    this.momentum = e;
  }

  getWeights() {
    var _this34 = this;

    return _asyncToGenerator(function* () {
      return [yield _this34.saveIterations()].concat(_this34.accumulations.map(e => ({
        name: e.originalName,
        tensor: e.variable
      })));
    })();
  }

  setWeights(e) {
    var _this35 = this;

    return _asyncToGenerator(function* () {
      e = yield _this35.extractIterations(e), _this35.accumulations = e.map(e => ({
        originalName: e.name,
        variable: e.tensor.variable(!1)
      }));
    })();
  }

  getConfig() {
    return {
      learningRate: this.learningRate,
      momentum: this.momentum,
      useNesterov: this.useNesterov
    };
  }

  static fromConfig(e, t) {
    return new e(t.learningRate, t.momentum, t.useNesterov);
  }

}

MomentumOptimizer$1.className = "Momentum", registerClass$1(MomentumOptimizer$1);

class RMSPropOptimizer$1 extends Optimizer$1 {
  constructor(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : .9;
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : null;
    var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;
    if (super(), this.learningRate = e, this.decay = t, this.momentum = n, this.epsilon = r, this.accumulatedMeanSquares = [], this.accumulatedMoments = [], this.accumulatedMeanGrads = [], this.centered = a, null == r && (this.epsilon = ENGINE$1.backend.epsilon()), null == e) throw new Error("learningRate for RMSPropOptimizer must be defined.");
  }

  applyGradients(e) {
    (Array.isArray(e) ? e.map(e => e.name) : Object.keys(e)).forEach((t, n) => {
      var r = ENGINE$1.registeredVariables[t],
          a = !1;
      null == this.accumulatedMeanSquares[n] && (this.accumulatedMeanSquares[n] = {
        originalName: "".concat(t, "/rms"),
        variable: tidy$1(() => zerosLike$5(r).variable(a))
      }), null == this.accumulatedMoments[n] && (this.accumulatedMoments[n] = {
        originalName: "".concat(t, "/momentum"),
        variable: tidy$1(() => zerosLike$5(r).variable(a))
      }), null == this.accumulatedMeanGrads[n] && this.centered && (this.accumulatedMeanGrads[n] = {
        originalName: "".concat(t, "/mg"),
        variable: tidy$1(() => zerosLike$5(r).variable(a))
      });
      var s = Array.isArray(e) ? e[n].tensor : e[t];
      if (null == s) return;
      var o = this.accumulatedMeanSquares[n].variable,
          i = this.accumulatedMoments[n].variable;
      tidy$1(() => {
        var e = add$5(mul$1(o, this.decay), mul$1(square$5(s), 1 - this.decay));

        if (this.centered) {
          var _t64 = this.accumulatedMeanGrads[n].variable,
              _a13 = add$5(mul$1(_t64, this.decay), mul$1(s, 1 - this.decay)),
              l = div$3(mul$1(s, this.learningRate), sqrt$5(sub$5(e, add$5(square$5(_a13), this.epsilon)))),
              u = add$5(mul$1(i, this.momentum), l);

          o.assign(e), _t64.assign(_a13), i.assign(u);
          var c = sub$5(r, u);
          r.assign(c);
        } else {
          var _e75 = add$5(mul$1(o, this.decay), mul$1(square$5(s), 1 - this.decay)),
              _t65 = add$5(mul$1(i, this.momentum), div$3(mul$1(s, this.learningRate), sqrt$5(add$5(_e75, this.epsilon))));

          o.assign(_e75), i.assign(_t65);

          var _n20 = sub$5(r, _t65);

          r.assign(_n20);
        }
      });
    }), this.incrementIterations();
  }

  dispose() {
    null != this.accumulatedMeanSquares && dispose$1(this.accumulatedMeanSquares.map(e => e.variable)), null != this.accumulatedMeanGrads && this.centered && dispose$1(this.accumulatedMeanGrads.map(e => e.variable)), null != this.accumulatedMoments && dispose$1(this.accumulatedMoments.map(e => e.variable));
  }

  getWeights() {
    var _this36 = this;

    return _asyncToGenerator(function* () {
      var e = [..._this36.accumulatedMeanSquares, ..._this36.accumulatedMoments];
      return _this36.centered && e.push(..._this36.accumulatedMeanGrads), [yield _this36.saveIterations()].concat(e.map(e => ({
        name: e.originalName,
        tensor: e.variable
      })));
    })();
  }

  setWeights(e) {
    var _this37 = this;

    return _asyncToGenerator(function* () {
      e = yield _this37.extractIterations(e);
      var t = _this37.centered ? e.length / 3 : e.length / 2,
          n = !1;
      _this37.accumulatedMeanSquares = e.slice(0, t).map(e => ({
        originalName: e.name,
        variable: e.tensor.variable(n)
      })), _this37.accumulatedMoments = e.slice(t, 2 * t).map(e => ({
        originalName: e.name,
        variable: e.tensor.variable(n)
      })), _this37.centered && (_this37.accumulatedMeanGrads = e.slice(2 * t, 3 * t).map(e => ({
        originalName: e.name,
        variable: e.tensor.variable(n)
      })));
    })();
  }

  getConfig() {
    return {
      learningRate: this.learningRate,
      decay: this.decay,
      momentum: this.momentum,
      epsilon: this.epsilon,
      centered: this.centered
    };
  }

  static fromConfig(e, t) {
    return new e(t.learningRate, t.decay, t.momentum, t.epsilon, t.centered);
  }

}

RMSPropOptimizer$1.className = "RMSProp", registerClass$1(RMSPropOptimizer$1);

class OptimizerConstructors$1 {
  static sgd(e) {
    return new SGDOptimizer$1(e);
  }

  static momentum(e, t) {
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
    return new MomentumOptimizer$1(e, t, n);
  }

  static rmsprop(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : .9;
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : null;
    var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;
    return new RMSPropOptimizer$1(e, t, n, r, a);
  }

  static adam() {
    var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : .001;
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : .9;
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : .999;
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : null;
    return new AdamOptimizer$1(e, t, n, r);
  }

  static adadelta() {
    var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : .001;
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : .95;
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;
    return new AdadeltaOptimizer$1(e, t, n);
  }

  static adamax() {
    var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : .002;
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : .9;
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : .999;
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : null;
    var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : 0;
    return new AdamaxOptimizer$1(e, t, n, r, a);
  }

  static adagrad(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : .1;
    return new AdagradOptimizer$1(e, t);
  }

}

var train$1 = {
  sgd: OptimizerConstructors$1.sgd,
  momentum: OptimizerConstructors$1.momentum,
  adadelta: OptimizerConstructors$1.adadelta,
  adagrad: OptimizerConstructors$1.adagrad,
  rmsprop: OptimizerConstructors$1.rmsprop,
  adamax: OptimizerConstructors$1.adamax,
  adam: OptimizerConstructors$1.adam
},
    delayCallback$1 = "undefined" != typeof requestAnimationFrame ? requestAnimationFrame : "undefined" != typeof setImmediate ? setImmediate : e => e();

function nextFrame$1() {
  return new Promise(e => delayCallback$1(() => e()));
}

function assertParamsConsistent$1(e, t) {
  var n = e[0].length;
  e.forEach((e, t) => {
    assert$6(e.length === n, () => "Error in concat".concat(n, "D: rank of tensors[").concat(t, "] must be the same as the rank of the rest (").concat(n, ")"));
  }), assert$6(t >= 0 && t < n, () => "Error in concat".concat(n, "D: axis must be between 0 and ").concat(n - 1, "."));
  var r = e[0];
  e.forEach((e, a) => {
    for (var s = 0; s < n; s++) {
      assert$6(s === t || e[s] === r[s], () => "Error in concat".concat(n, "D: Shape of tensors[").concat(a, "] (").concat(e, ") does not match the shape of the rest (").concat(r, ") along the non-concatenated axis ").concat(a, "."));
    }
  });
}

function computeOutShape$4(e, t) {
  var n = e[0].slice();

  for (var r = 1; r < e.length; r++) {
    n[t] += e[r][t];
  }

  return n;
}

var PARALLELIZE_THRESHOLD$1 = 30;

function computeOptimalWindowSize$1(e) {
  return e <= PARALLELIZE_THRESHOLD$1 ? e : nearestDivisor$1(e, Math.floor(Math.sqrt(e)));
}

function getImageCenter$1(e, t, n) {
  return [n * ("number" == typeof e ? e : e[0]), t * ("number" == typeof e ? e : e[1])];
}

function getReshaped$1(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !0;
  var a = [];
  if (r) a = a.concat(t.slice(0)), a.push(e[0] / n), a = a.concat(e.slice(1));else {
    a = a.concat(e[0]);
    var _n21 = t.length;

    for (var _r20 = 0; _r20 < _n21; ++_r20) {
      a = a.concat([e[_r20 + 1] / t[_r20], t[_r20]]);
    }

    a = a.concat(e.slice(_n21 + 1));
  }
  return a;
}

function getPermuted$1(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !0;
  var r = [];

  if (n) {
    r.push(t);

    for (var _n22 = t + 1; _n22 < e; ++_n22) {
      _n22 <= 2 * t ? (r.push(_n22), r.push(_n22 - (t + 1))) : r.push(_n22);
    }
  } else {
    var _n23 = [],
        a = [];

    for (var _r21 = 1; _r21 < e; ++_r21) {
      _r21 >= 2 * t + 1 || _r21 % 2 == 1 ? a.push(_r21) : _n23.push(_r21);
    }

    r.push(..._n23), r.push(0), r.push(...a);
  }

  return r;
}

function getReshapedPermuted$1(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !0;
  var a = [];
  a.push(r ? e[0] / n : e[0] * n);

  for (var _n24 = 1; _n24 < e.length; ++_n24) {
    a.push(_n24 <= t.length ? r ? t[_n24 - 1] * e[_n24] : e[_n24] / t[_n24 - 1] : e[_n24]);
  }

  return a;
}

function getSliceBeginCoords$1(e, t) {
  var n = [0];

  for (var r = 0; r < t; ++r) {
    n.push(e[r][0]);
  }

  return n;
}

function getSliceSize$1(e, t, n) {
  var r = e.slice(0, 1);

  for (var a = 0; a < n; ++a) {
    r.push(e[a + 1] - t[a][0] - t[a][1]);
  }

  return r;
}

var SELU_SCALEALPHA$1 = 1.7580993408473768,
    SELU_SCALE$1 = 1.0507009873554805,
    ERF_P$1 = .3275911,
    ERF_A1$1 = .254829592,
    ERF_A2$1 = -.284496736,
    ERF_A3$1 = 1.421413741,
    ERF_A4$1 = -1.453152027,
    ERF_A5$1 = 1.061405429;

function warn$1() {
  env$1().getBool("IS_TEST") || console.warn(...arguments);
}

function log$6() {
  env$1().getBool("IS_TEST") || console.log(...arguments);
}

function mergeRealAndImagArrays$1(e, t) {
  if (e.length !== t.length) throw new Error("Cannot merge real and imag arrays of different lengths. real:".concat(e.length, ", imag: ").concat(t.length, "."));
  var n = new Float32Array(2 * e.length);

  for (var r = 0; r < n.length; r += 2) {
    n[r] = e[r / 2], n[r + 1] = t[r / 2];
  }

  return n;
}

function splitRealAndImagArrays$1(e) {
  var t = new Float32Array(e.length / 2),
      n = new Float32Array(e.length / 2);

  for (var r = 0; r < e.length; r += 2) {
    t[r / 2] = e[r], n[r / 2] = e[r + 1];
  }

  return {
    real: t,
    imag: n
  };
}

function complexWithEvenIndex$1(e) {
  var t = Math.ceil(e.length / 4),
      n = new Float32Array(t),
      r = new Float32Array(t);

  for (var _t66 = 0; _t66 < e.length; _t66 += 4) {
    n[Math.floor(_t66 / 4)] = e[_t66], r[Math.floor(_t66 / 4)] = e[_t66 + 1];
  }

  return {
    real: n,
    imag: r
  };
}

function complexWithOddIndex$1(e) {
  var t = Math.floor(e.length / 4),
      n = new Float32Array(t),
      r = new Float32Array(t);

  for (var _t67 = 2; _t67 < e.length; _t67 += 4) {
    n[Math.floor(_t67 / 4)] = e[_t67], r[Math.floor(_t67 / 4)] = e[_t67 + 1];
  }

  return {
    real: n,
    imag: r
  };
}

function getComplexWithIndex$1(e, t) {
  return {
    real: e[2 * t],
    imag: e[2 * t + 1]
  };
}

function assignToTypedArray$1(e, t, n, r) {
  e[2 * r] = t, e[2 * r + 1] = n;
}

function exponents$1(e, t) {
  var n = new Float32Array(e / 2),
      r = new Float32Array(e / 2);

  for (var a = 0; a < Math.ceil(e / 2); a++) {
    var s = (t ? 2 : -2) * Math.PI * (a / e);
    n[a] = Math.cos(s), r[a] = Math.sin(s);
  }

  return {
    real: n,
    imag: r
  };
}

function exponent$1(e, t, n) {
  var r = (n ? 2 : -2) * Math.PI * (e / t);
  return {
    real: Math.cos(r),
    imag: Math.sin(r)
  };
}

var ARROW$1 = "->",
    ARROW_REGEX$1 = /->/g,
    COMMA$1 = ",",
    ELLIPSIS$1 = "...";

function decodeEinsumEquation$1(e, t) {
  var n = ((e = e.replace(/\s/g, "")).length - e.replace(ARROW_REGEX$1, "").length) / ARROW$1.length;
  if (n < 1) throw new Error("Equations without an arrow are not supported.");
  if (n > 1) throw new Error("Equation must contain exactly one arrow (\"".concat(ARROW$1, "\")."));
  var [r, a] = e.split(ARROW$1);
  assert$6(-1 === r.indexOf(ELLIPSIS$1), () => "The ellipsis notation (\"".concat(ELLIPSIS$1, "\") is not supported yet."));
  var s = r.split(COMMA$1),
      o = s.length;
  if (t !== o) throw new Error("Expected ".concat(o, " input tensors, received ").concat(t));
  if (o > 2) throw new Error("Support for more than 2 input tensors is not implemented yet.");
  var i = [];

  var _loop9 = function _loop9(_e76) {
    var t = a[_e76];
    if (!s.some(e => -1 !== e.indexOf(t))) throw new Error("Output subscripts contain the label ".concat(t, " not present in the input subscripts."));
    -1 === i.indexOf(t) && i.push(t);
  };

  for (var _e76 = 0; _e76 < a.length; ++_e76) {
    _loop9(_e76);
  }

  for (var _e77 = 0; _e77 < r.length; ++_e77) {
    var _t68 = r[_e77];
    -1 === i.indexOf(_t68) && _t68 !== COMMA$1 && i.push(_t68);
  }

  var l = new Array(s.length);

  for (var _e78 = 0; _e78 < o; ++_e78) {
    if (new Set(s[_e78].split("")).size !== s[_e78].length) throw new Error("Found duplicate axes in input component ".concat(s[_e78], ". Support for duplicate axes in input is not implemented yet."));
    l[_e78] = [];

    for (var _t69 = 0; _t69 < s[_e78].length; ++_t69) {
      l[_e78].push(i.indexOf(s[_e78][_t69]));
    }
  }

  var u = i.length,
      c = [];

  for (var _e79 = a.length; _e79 < u; ++_e79) {
    c.push(_e79);
  }

  return {
    allDims: i,
    summedDims: c,
    idDims: l
  };
}

function getEinsumPermutation$1(e, t) {
  var n = new Array(e);
  n.fill(-1);

  for (var _e80 = 0; _e80 < t.length; ++_e80) {
    n[t[_e80]] = _e80;
  }

  var r = [];

  for (var _t70 = 0; _t70 < e; ++_t70) {
    -1 === n[_t70] && r.push(_t70);
  }

  return n = n.filter(e => -1 !== e), {
    permutationIndices: n,
    expandDims: r
  };
}

function checkEinsumDimSizes$1(e, t, n) {
  var r = new Array(e);

  var _loop10 = function _loop10(_e81) {
    var a = n[_e81].shape;

    var _loop11 = function _loop11(_n25) {
      void 0 === r[t[_e81][_n25]] ? r[t[_e81][_n25]] = a[_n25] : assert$6(r[t[_e81][_n25]] === a[_n25], () => "Expected dimension ".concat(r[t[_e81][_n25]], " at axis ").concat(_n25, " of input shaped ").concat(JSON.stringify(a), ", but got dimension ").concat(a[_n25]));
    };

    for (var _n25 = 0; _n25 < t[_e81].length; ++_n25) {
      _loop11(_n25);
    }
  };

  for (var _e81 = 0; _e81 < n.length; ++_e81) {
    _loop10(_e81);
  }
}

function getEinsumComputePath$1(e, t) {
  var n = e,
      r = [];
  var a = 0;
  0 === e.length && n.push(-1), a = e.length + 1;

  for (var _e82 = 0; _e82 < a; ++_e82) {
    r.push([]);
  }

  var s = [];

  for (var _e83 = 0; _e83 < n.length; ++_e83) {
    var _a14 = findTermsWithDim$1(t, n[_e83]);

    for (var _t71 of _a14) {
      -1 === s.indexOf(_t71) && (r[_e83].push(_t71), s.push(_t71));
    }
  }

  return {
    path: n,
    steps: r
  };
}

function isIdentityPermutation$1(e) {
  return e.every((e, t) => e === t);
}

function findTermsWithDim$1(e, t) {
  var n = [];

  for (var r = 0; r < e.length; ++r) {
    0 !== e[r].length && -1 === e[r].indexOf(t) && -1 !== t || n.push(r);
  }

  return n;
}

function prepareSplitSize$1(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;
  var r = [];
  if ("number" == typeof t) assert$6(e.shape[n] % t == 0, () => "Number of splits must evenly divide the axis."), r = new Array(t).fill(e.shape[n] / t);else {
    var a = t.reduce((e, t) => (-1 === t && (e += 1), e), 0);
    assert$6(a <= 1, () => "There should be only one negative value in split array.");
    var s = t.indexOf(-1);

    if (-1 !== s) {
      var _r22 = t.reduce((e, t) => t > 0 ? e + t : e);

      t[s] = e.shape[n] - _r22;
    }

    assert$6(e.shape[n] === t.reduce((e, t) => e + t), () => "The sum of sizes must match the size of the axis dimension."), r = t;
  }
  return r;
}

function segOpComputeOptimalWindowSize$1(e, t) {
  var n,
      r = !1;

  for (e <= PARALLELIZE_THRESHOLD$1 ? (n = e, r = !0) : n = nearestDivisor$1(e, Math.floor(Math.sqrt(e))); !r;) {
    n > t || n === e ? r = !0 : n = nearestDivisor$1(e, n + 1);
  }

  return n;
}

function computeOutShape$3(e, t, n) {
  var r = [],
      a = e.length;

  for (var s = 0; s < a; s++) {
    r.push(s !== t ? e[s] : n);
  }

  return r;
}

function collectGatherOpShapeInfo$1(e, t, n, r) {
  var a = t.shape.length,
      s = e.shape.length;
  if (0 !== r && (r < -a || r > a)) throw new Error("Expect batchDims in the range of [-".concat(a, ", ").concat(a, "], but got ").concat(r));
  if (r < 0 && (r += a), r > s) throw new Error("batchDims (".concat(r, ") must be less than rank(x) (\n    ").concat(s, ")."));
  if (n < r) throw new Error("batchDims (".concat(r, ") must be less than or equal to axis (").concat(n, ")."));

  for (var _n26 = 0; _n26 < r; ++_n26) {
    if (e.shape[_n26] !== t.shape[_n26]) throw new Error("x.shape[".concat(_n26, "]: ").concat(e.shape[_n26], " should be equal to indices.shape[").concat(_n26, "]: ").concat(t.shape[_n26], "."));
  }

  var o = e.shape[n],
      i = [];
  var l = 1,
      u = 1,
      c = 1;

  for (var _t72 = 0; _t72 < r; ++_t72) {
    i.push(e.shape[_t72]), l *= e.shape[_t72];
  }

  for (var _t73 = r; _t73 < n; _t73++) {
    i.push(e.shape[_t73]), u *= e.shape[_t73];
  }

  for (var _e84 = r; _e84 < a; _e84++) {
    i.push(t.shape[_e84]);
  }

  for (var _t74 = n + 1; _t74 < s; _t74++) {
    i.push(e.shape[_t74]), c *= e.shape[_t74];
  }

  return {
    batchSize: l,
    sliceSize: c,
    outerSize: u,
    dimSize: o,
    outputShape: i
  };
}

var segment_util$1 = {
  __proto__: null,
  segOpComputeOptimalWindowSize: segOpComputeOptimalWindowSize$1,
  computeOutShape: computeOutShape$3,
  collectGatherOpShapeInfo: collectGatherOpShapeInfo$1
};

function fromUint8ToStringArray$1(e) {
  try {
    return e.map(e => decodeString$1(e));
  } catch (e) {
    throw new Error("Failed to decode encoded string bytes into utf-8, error: ".concat(e));
  }
}

function fromStringArrayToUint8$1(e) {
  return e.map(e => encodeString$1(e));
}

var backend_util$1 = {
  __proto__: null,
  slice_util: slice_util$1,
  segment_util: segment_util$1,
  fromUint8ToStringArray: fromUint8ToStringArray$1,
  fromStringArrayToUint8: fromStringArrayToUint8$1,
  upcastType: upcastType$1,
  axesAreInnerMostDims: axesAreInnerMostDims$1,
  combineLocations: combineLocations$1,
  computeOutAndReduceShapes: computeOutAndReduceShapes$1,
  expandShapeToKeepDim: expandShapeToKeepDim$1,
  assertAxesAreInnerMostDims: assertAxesAreInnerMostDims$1,
  getAxesPermutation: getAxesPermutation$1,
  getUndoAxesPermutation: getUndoAxesPermutation$1,
  getInnerMostAxes: getInnerMostAxes$1,
  getBroadcastDims: getBroadcastDims$3,
  getReductionAxes: getReductionAxes$1,
  assertAndGetBroadcastShape: assertAndGetBroadcastShape$1,
  assertParamsConsistent: assertParamsConsistent$1,
  computeOutShape: computeOutShape$4,
  computeDilation2DInfo: computeDilation2DInfo$1,
  computePool2DInfo: computePool2DInfo$1,
  computePool3DInfo: computePool3DInfo$1,
  computeConv2DInfo: computeConv2DInfo$1,
  computeConv3DInfo: computeConv3DInfo$1,
  computeDefaultPad: computeDefaultPad$1,
  tupleValuesAreOne: tupleValuesAreOne$1,
  eitherStridesOrDilationsAreOne: eitherStridesOrDilationsAreOne$1,
  convertConv2DDataFormat: convertConv2DDataFormat$1,
  getFusedDyActivation: getFusedDyActivation$1,
  getFusedBiasGradient: getFusedBiasGradient$1,
  applyActivation: applyActivation$3,
  shouldFuse: shouldFuse$1,
  PARALLELIZE_THRESHOLD: PARALLELIZE_THRESHOLD$1,
  computeOptimalWindowSize: computeOptimalWindowSize$1,
  getImageCenter: getImageCenter$1,
  getReshaped: getReshaped$1,
  getPermuted: getPermuted$1,
  getReshapedPermuted: getReshapedPermuted$1,
  getSliceBeginCoords: getSliceBeginCoords$1,
  getSliceSize: getSliceSize$1,
  prepareAndValidate: prepareAndValidate$1,
  validateUpdateShape: validateUpdateShape$1,
  validateInput: validateInput$2,
  calculateShapes: calculateShapes$1,
  SELU_SCALEALPHA: SELU_SCALEALPHA$1,
  SELU_SCALE: SELU_SCALE$1,
  ERF_P: ERF_P$1,
  ERF_A1: ERF_A1$1,
  ERF_A2: ERF_A2$1,
  ERF_A3: ERF_A3$1,
  ERF_A4: ERF_A4$1,
  ERF_A5: ERF_A5$1,
  warn: warn$1,
  log: log$6,
  mergeRealAndImagArrays: mergeRealAndImagArrays$1,
  splitRealAndImagArrays: splitRealAndImagArrays$1,
  complexWithEvenIndex: complexWithEvenIndex$1,
  complexWithOddIndex: complexWithOddIndex$1,
  getComplexWithIndex: getComplexWithIndex$1,
  assignToTypedArray: assignToTypedArray$1,
  exponents: exponents$1,
  exponent: exponent$1,
  decodeEinsumEquation: decodeEinsumEquation$1,
  getEinsumPermutation: getEinsumPermutation$1,
  checkEinsumDimSizes: checkEinsumDimSizes$1,
  getEinsumComputePath: getEinsumComputePath$1,
  isIdentityPermutation: isIdentityPermutation$1,
  prepareSplitSize: prepareSplitSize$1
};
var absGradConfig$1 = {
  kernelName: Abs$1,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => mul$1(e, step$5(cast$7(n, "float32"), -1))
    };
  }
},
    acosGradConfig$1 = {
  kernelName: Acos$1,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => {
        var t = square$5(cast$7(n, "float32")),
            r = sqrt$5(sub$5(scalar$1(1), t));
        return neg$5(div$3(e, r));
      }
    };
  }
},
    acoshGradConfig$1 = {
  kernelName: Acosh$1,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => {
        var t = sqrt$5(sub$5(square$5(cast$7(n, "float32")), 1));
        return div$3(e, t);
      }
    };
  }
},
    addGradConfig$1 = {
  kernelName: Add$3,
  inputsToSave: ["a", "b"],
  gradFunc: (e, t) => {
    var [n, r] = t,
        _a15 = assertAndGetBroadcastShape$1(n.shape, r.shape);

    return {
      a: () => {
        var t = e;
        var r = getReductionAxes$1(n.shape, _a15);
        return r.length > 0 && (t = sum$6(t, r)), reshape$6(t, n.shape);
      },
      b: () => {
        var t = e;
        var n = getReductionAxes$1(r.shape, _a15);
        return n.length > 0 && (t = sum$6(t, n)), reshape$6(t, r.shape);
      }
    };
  }
},
    addNGradConfig$1 = {
  kernelName: AddN$1,
  saveAllInputs: !0,
  gradFunc: (e, t) => {
    var n = {};
    return t.forEach((t, r) => {
      n[r] = () => e.clone();
    }), n;
  }
},
    argMaxGradConfig$1 = {
  kernelName: ArgMax$1,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => zerosLike$5(n)
    };
  }
},
    argMinGradConfig$1 = {
  kernelName: ArgMin$1,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => zerosLike$5(n)
    };
  }
},
    asinGradConfig$1 = {
  kernelName: Asin$1,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => div$3(e, sqrt$5(sub$5(scalar$1(1), square$5(cast$7(n, "float32")))))
    };
  }
},
    asinhGradConfig$1 = {
  kernelName: Asinh$1,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => {
        var t = sqrt$5(add$5(scalar$1(1), square$5(cast$7(n, "float32"))));
        return div$3(e, t);
      }
    };
  }
},
    atan2GradConfig$1 = {
  kernelName: Atan2$1,
  inputsToSave: ["a", "b"],
  gradFunc: (e, t) => {
    var [n, r] = t,
        _a16 = assertAndGetBroadcastShape$1(n.shape, r.shape);

    return {
      a: () => {
        var t = add$5(square$5(n), square$5(r));
        var s = mul$1(e, div$3(r, t));
        var o = getReductionAxes$1(n.shape, _a16);
        return o.length > 0 && (s = sum$6(s, o)), reshape$6(s, n.shape);
      },
      b: () => {
        var t = add$5(square$5(n), square$5(r));
        var s = neg$5(mul$1(e, div$3(n, t)));
        var o = getReductionAxes$1(r.shape, _a16);
        return o.length > 0 && (s = sum$6(s, o)), reshape$6(s, r.shape);
      }
    };
  }
},
    atanGradConfig$1 = {
  kernelName: Atan$1,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => div$3(e, add$5(square$5(cast$7(n, "float32")), 1))
    };
  }
},
    atanhGradConfig$1 = {
  kernelName: Atanh$1,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => div$3(e, sub$5(scalar$1(1), square$5(cast$7(n, "float32"))))
    };
  }
};

function avgPool3dGrad_$1(e, t, n, r, a, s) {
  var o = convertToTensor$1(e, "dy", "avgPool3dGrad"),
      i = convertToTensor$1(t, "input", "avgPool3dGrad");
  var l = o,
      u = i,
      c = !1;
  4 === i.rank && (c = !0, l = reshape$6(o, [1, o.shape[0], o.shape[1], o.shape[2], o.shape[3]]), u = reshape$6(i, [1, i.shape[0], i.shape[1], i.shape[2], i.shape[3]])), assert$6(5 === l.rank, () => "Error in avgPool3dGrad: dy must be rank 5 but got rank ".concat(l.rank, ".")), assert$6(5 === u.rank, () => "Error in avgPool3dGrad: input must be rank 5 but got rank ".concat(u.rank, ".")), null != s && assert$6(isInt$1(a), () => "Error in avgPool3dGrad: pad must be an integer when using, dimRoundingMode ".concat(s, " but got pad ").concat(a, "."));
  var p = ENGINE$1.runKernel(AvgPool3DGrad$1, {
    dy: l,
    input: u
  }, {
    filterSize: n,
    strides: r,
    pad: a,
    dimRoundingMode: s
  });
  return c ? reshape$6(p, [p.shape[1], p.shape[2], p.shape[3], p.shape[4]]) : p;
}

var avgPool3dGrad$1 = op$1({
  avgPool3dGrad_: avgPool3dGrad_$1
}),
    avgPool3DGradConfig$3 = {
  kernelName: AvgPool3D$1,
  inputsToSave: ["x"],
  gradFunc: (e, t, n) => {
    var [r] = t,
        {
      filterSize: a,
      strides: s,
      pad: o,
      dimRoundingMode: i
    } = n;
    return {
      x: () => avgPool3dGrad$1(e, r, a, s, o, i)
    };
  }
};

function avgPoolGrad_$1(e, t, n, r, a) {
  var s = convertToTensor$1(e, "dy", "avgPoolGrad"),
      o = convertToTensor$1(t, "input", "avgPoolGrad");
  assert$6(o.rank === s.rank, () => "Rank of input (".concat(o.rank, ") does not match rank of dy (").concat(s.rank, ")"));
  var i = o,
      l = s,
      u = !1;
  3 === o.rank && (u = !0, i = reshape$6(o, [1, o.shape[0], o.shape[1], o.shape[2]]), l = reshape$6(s, [1, s.shape[0], s.shape[1], s.shape[2]])), assert$6(4 === l.rank, () => "Error in avgPoolGrad: dy must be rank 4 but got rank ".concat(l.rank, ".")), assert$6(4 === i.rank, () => "Error in avgPoolGrad: input must be rank 4 but got rank ".concat(i.rank, "."));
  var c = ENGINE$1.runKernel(AvgPoolGrad$1, {
    dy: l,
    input: i
  }, {
    filterSize: n,
    strides: r,
    pad: a
  });
  return u ? reshape$6(c, [c.shape[1], c.shape[2], c.shape[3]]) : c;
}

var avgPoolGrad$5 = op$1({
  avgPoolGrad_: avgPoolGrad_$1
}),
    avgPoolGradConfig$5 = {
  kernelName: AvgPool$1,
  inputsToSave: ["x"],
  gradFunc: (e, t, n) => {
    var [r] = t,
        {
      filterSize: a,
      strides: s,
      pad: o
    } = n;
    return {
      x: () => avgPoolGrad$5(e, r, a, s, o)
    };
  }
},
    batchMatMulGradConfig$1 = {
  kernelName: BatchMatMul$1,
  inputsToSave: ["a", "b"],
  gradFunc: (e, t, n) => {
    var [r, _a17] = t,
        {
      transposeA: s,
      transposeB: o
    } = n;
    return s || o ? !s && o ? {
      a: () => matMul$3(e, _a17, !1, !1),
      b: () => matMul$3(e, r, !0, !1)
    } : s && !o ? {
      a: () => matMul$3(_a17, e, !1, !0),
      b: () => matMul$3(r, e, !1, !1)
    } : {
      a: () => matMul$3(_a17, e, !0, !0),
      b: () => matMul$3(e, r, !0, !0)
    } : {
      a: () => matMul$3(e, _a17, !1, !0),
      b: () => matMul$3(r, e, !0, !1)
    };
  }
},
    batchToSpaceNDGradConfig$1 = {
  kernelName: BatchToSpaceND$1,
  gradFunc: (e, t, n) => {
    var {
      blockShape: r,
      crops: a
    } = n;
    return {
      x: () => spaceToBatchND$5(e, r, a)
    };
  }
},
    broadcastToGradConfig$1 = {
  kernelName: BroadcastTo$1,
  gradFunc: (e, t, n) => {
    var r = n.inputShape,
        a = n.shape,
        s = Array.from(a);

    for (var _e85 = r.length - 1; _e85 >= 0; _e85--) {
      if (r[_e85] === a[_e85]) s[_e85] = 1;else if (1 !== r[_e85]) throw new Error("broadcastTo(): [".concat(r, "] cannot be broadcast to [").concat(a, "]."));
    }

    var o = [];

    for (var _e86 = 0; _e86 < s.length; _e86++) {
      s[_e86] > 1 && o.push(_e86);
    }

    return {
      x: () => sum$6(e, o, !0)
    };
  }
},
    castGradConfig$1 = {
  kernelName: Cast$1,
  gradFunc: e => ({
    x: () => e.clone()
  })
},
    ceilGradConfig$1 = {
  kernelName: Ceil$1,
  gradFunc: e => ({
    x: () => zerosLike$5(e)
  })
},
    clipByValueGradConfig$1 = {
  kernelName: ClipByValue$1,
  inputsToSave: ["x"],
  gradFunc: (e, t, n) => {
    var [r] = t,
        {
      clipValueMin: a,
      clipValueMax: s
    } = n;
    return {
      x: () => where$1(logicalAnd$5(greaterEqual$5(r, a), lessEqual$5(r, s)), e, zerosLike$5(e))
    };
  }
},
    complexAbsGradConfig$1 = {
  kernelName: ComplexAbs$1,
  inputsToSave: ["x"],
  gradFunc: absGradConfig$1.gradFunc
},
    concatGradConfig$1 = {
  kernelName: Concat$1,
  saveAllInputs: !0,
  gradFunc: (e, t, n) => {
    var r = t.map(e => e.shape),
        {
      axis: a
    } = n,
        s = parseAxisParam$1(a, t[0].shape)[0],
        o = r.map(e => e[s]);
    return split$4(e, o, s).map(e => () => e);
  }
},
    conv2DGradConfig$1 = {
  kernelName: Conv2D$3,
  inputsToSave: ["x", "filter"],
  gradFunc: (e, t, n) => {
    var [r, a] = t,
        {
      dilations: s,
      strides: o,
      pad: i,
      dataFormat: l
    } = n;
    return assert$6(tupleValuesAreOne$1(s), () => "Error in gradient of conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '".concat(s, "'")), {
      x: () => conv2DBackpropInput$5(r.shape, e, a, o, i, l),
      filter: () => conv2DBackpropFilter$5(r, e, a.shape, o, i, l)
    };
  }
},
    conv2DBackpropInputGradConfig$1 = {
  kernelName: Conv2DBackpropInput$1,
  inputsToSave: ["dy", "filter"],
  gradFunc: (e, t, n) => {
    var [r, a] = t,
        {
      strides: s,
      pad: o,
      dataFormat: i,
      dimRoundingMode: l
    } = n;
    return {
      dy: () => conv2d$7(e, a, s, o, i, 1, l),
      filter: () => conv2DBackpropFilter$5(e, r, a.shape, s, o, i, l)
    };
  }
};

function conv3DBackpropFilter_$1(e, t, n, r, a) {
  var s = e;
  4 === e.rank && (s = reshape$6(e, [1, e.shape[0], e.shape[1], e.shape[2], e.shape[3]]));
  var o = t;
  return 4 === o.rank && (o = reshape$6(t, [1, t.shape[0], t.shape[1], t.shape[2], t.shape[3]])), assert$6(5 === s.rank, () => "Error in conv3dDerFilter: input must be rank 5, but got shape ".concat(s.shape, ".")), assert$6(5 === o.rank, () => "Error in conv3dDerFilter: dy must be rank 5, but got shape ".concat(o.shape, ".")), assert$6(5 === n.length, () => "Error in conv3dDerFilter: filterShape must be length 5, but got ".concat(n, ".")), assert$6(s.shape[4] === n[3], () => "Error in conv3dDerFilter: depth of input ".concat(s.shape[4], ") must match input depth in filter (").concat(n[3], ".")), assert$6(o.shape[4] === n[4], () => "Error in conv3dDerFilter: depth of dy (".concat(o.shape[4], ") must match output depth for filter (").concat(n[4], ").")), ENGINE$1.runKernel(Conv3DBackpropFilterV2$1, {
    x: s,
    dy: o
  }, {
    strides: r,
    pad: a,
    filterShape: n
  });
}

var conv3DBackpropFilter$1 = op$1({
  conv3DBackpropFilter_: conv3DBackpropFilter_$1
}),
    conv3DGradConfig$1 = {
  kernelName: Conv3D$3,
  inputsToSave: ["x", "filter"],
  gradFunc: (e, t, n) => {
    var {
      dilations: r,
      strides: a,
      pad: s
    } = n;
    assert$6(tupleValuesAreOne$1(r), () => "Error in gradient of conv3D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '".concat(r, "'"));
    var [o, i] = t;
    return {
      x: () => conv3DBackpropInput$3(o.shape, e, i, a, s),
      filter: () => conv3DBackpropFilter$1(o, e, i.shape, a, s)
    };
  }
},
    cosGradConfig$1 = {
  kernelName: Cos$1,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => mul$1(neg$5(sin$5(cast$7(n, "float32"))), e)
    };
  }
},
    coshGradConfig$1 = {
  kernelName: Cosh$1,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => mul$1(sinh$5(cast$7(n, "float32")), e)
    };
  }
},
    cumsumGradConfig$1 = {
  kernelName: Cumsum$1,
  inputsToSave: ["x"],
  gradFunc: (e, t, n) => {
    var [r] = t,
        {
      axis: a,
      exclusive: s,
      reverse: o
    } = n;
    return {
      x: () => {
        var t = getAxesPermutation$1([a], r.rank);
        var n = cumsum$5(e, a, s, !o);
        return null != t && (n = transpose$5(n, t)), n;
      }
    };
  }
},
    depthwiseConv2dNativeGradConfig$1 = {
  kernelName: DepthwiseConv2dNative$1,
  inputsToSave: ["x", "filter"],
  gradFunc: (e, t, n) => {
    var {
      dilations: r,
      strides: a,
      pad: s,
      dimRoundingMode: o
    } = n,
        i = null == r ? [1, 1] : r;
    assert$6(tupleValuesAreOne$1(i), () => "Error in gradient of depthwiseConv2dNative: dilation rates greater than 1 are not yet supported. Got dilations '".concat(i, "'"));
    var [l, u] = t;
    return assert$6(4 === l.rank, () => "Error in gradient of depthwiseConv2dNative: input must be rank 4, but got rank ".concat(l.rank, ".")), assert$6(4 === u.rank, () => "Error in gradient of depthwiseConv2dNative: filter must be rank 4, but got rank ".concat(u.rank, ".")), assert$6(l.shape[3] === u.shape[2], () => "Error in gradient of depthwiseConv2d: number of input channels (".concat(l.shape[3], ") must match the inChannels dimension in filter ").concat(u.shape[2], ".")), assert$6(eitherStridesOrDilationsAreOne$1(a, i), () => "Error in gradient of depthwiseConv2d: Either strides or dilations must be  1. Got strides ".concat(a, " and dilations '").concat(i, "'.")), null != o && assert$6(isInt$1(s), () => "Error in depthwiseConv2d: pad must be an integer when using, dimRoundingMode ".concat(o, " but got pad ").concat(s, ".")), {
      x: () => depthwiseConv2dNativeBackpropInput$5(l.shape, e, u, a, s, r, o),
      filter: () => depthwiseConv2dNativeBackpropFilter$5(l, e, u.shape, a, s, r, o)
    };
  }
},
    dilation2dGradConfig$1 = {
  kernelName: Dilation2D$1,
  inputsToSave: ["x", "filter"],
  gradFunc: (e, t, n) => {
    var [r, a] = t,
        s = {
      x: r,
      filter: a,
      dy: e
    },
        o = {
      x: r,
      filter: a,
      dy: e
    };
    return {
      x: () => ENGINE$1.runKernel(Dilation2DBackpropInput$1, s, n),
      filter: () => ENGINE$1.runKernel(Dilation2DBackpropFilter$1, o, n)
    };
  }
},
    eluGradConfig$5 = {
  kernelName: Elu$3,
  outputsToSave: [!0],
  gradFunc: (e, t) => {
    var [n] = t,
        r = {
      dy: e,
      y: n
    };
    return {
      x: () => ENGINE$1.runKernel(EluGrad$1, r)
    };
  }
},
    erfGradConfig$1 = {
  kernelName: Erf$1,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t,
        r = mul$1(exp$5(neg$5(square$5(n))), 2 / Math.sqrt(Math.PI));
    return {
      x: () => mul$1(e, r)
    };
  }
},
    expGradConfig$1 = {
  kernelName: Exp$1,
  outputsToSave: [!0],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => mul$1(e, n)
    };
  }
},
    expandDimsGradConfig$1 = {
  kernelName: ExpandDims$1,
  inputsToSave: ["input"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      input: () => reshape$6(e, n.shape)
    };
  }
},
    expm1GradConfig$1 = {
  kernelName: Expm1$1,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => mul$1(e, exp$5(n))
    };
  }
},
    floorGradConfig$1 = {
  kernelName: Floor$1,
  gradFunc: e => ({
    x: () => zerosLike$5(e)
  })
},
    floorDivGradConfig$1 = {
  kernelName: FloorDiv$1,
  inputsToSave: ["a", "b"],
  gradFunc: (e, t) => {
    var [n, r] = t,
        _a18 = assertAndGetBroadcastShape$1(n.shape, r.shape);

    return {
      a: () => {
        var t = div$3(e, cast$7(r, "float32")),
            s = getReductionAxes$1(n.shape, _a18);
        return s.length > 0 ? reshape$6(sum$6(t, s), n.shape) : t;
      },
      b: () => {
        var t = mul$1(e, cast$7(n, "float32"));
        var s = getReductionAxes$1(r.shape, _a18);
        s.length > 0 && (t = reshape$6(sum$6(t, s), r.shape));
        var o = square$5(r);
        return neg$5(div$3(t, cast$7(o, "float32")));
      }
    };
  }
},
    fusedBatchNormGradConfig$1 = {
  kernelName: FusedBatchNorm$1,
  inputsToSave: ["x", "mean", "variance", "scale"],
  gradFunc: (e, t, n) => {
    var {
      varianceEpsilon: r
    } = n,
        [a, s, o, i] = t,
        l = null == i ? scalar$1(1) : i,
        u = getReductionAxes$1(s.shape, a.shape),
        c = [];

    if (1 === s.rank) {
      for (var _e87 = 0; _e87 < a.shape.length - 1; ++_e87) {
        c.push(a.shape[_e87]);
      }

      c.push(1);
    }

    var p = sub$5(a, s),
        d = mul$1(e, l),
        h = rsqrt$5(add$5(o, scalar$1(r))),
        m = mul$1(mul$1(mul$1(h, h), h), scalar$1(-.5));
    return {
      x: () => reshape$6(mul$1(mul$1(e, 1 === s.rank ? tile$7(reshape$6(h, [1, 1, 1, s.shape[0]]), c) : h), l), a.shape),
      mean: () => {
        var e = mul$1(mul$1(h, scalar$1(-1)), d);
        return 1 === s.rank && (e = sum$6(e, u)), reshape$6(e, s.shape);
      },
      variance: () => {
        var e = mul$1(mul$1(m, p), d);
        return 1 === s.rank && (e = sum$6(e, u)), reshape$6(e, s.shape);
      },
      scale: () => {
        var t = mul$1(p, h);
        var n = mul$1(e, t);
        return 1 === s.rank && (n = sum$6(n, u)), reshape$6(n, s.shape);
      },
      offset: () => {
        var t = e;
        return 1 === s.rank && (t = sum$6(t, u)), reshape$6(t, s.shape);
      }
    };
  }
},
    gatherGradConfig$1 = {
  kernelName: GatherV2$1,
  inputsToSave: ["x", "indices"],
  gradFunc: (e, t, n) => {
    var [r, a] = t,
        {
      axis: s
    } = n,
        o = parseAxisParam$1(s, r.shape)[0];
    return {
      x: () => {
        var t = r.shape,
            n = a.size,
            i = t.slice(0, o),
            l = i.length,
            u = t.slice(s, t.length).slice(1),
            c = u.length,
            p = arrayRange$1(0, l),
            d = arrayRange$1(l + 1, l + 1 + c),
            h = arrayConcat$1([i, [n], u]),
            m = reshape$6(e, h),
            f = reshape$6(a, [n]),
            g = arrayConcat$1([[l], p, d]),
            $ = transpose$5(m, g);
        var y = unsortedSegmentSum$5($, f, r.shape[o]);
        var b = getUndoAxesPermutation$1(g);
        return y = transpose$5(y, b), y;
      },
      indices: () => a
    };
  }
};

function arrayRange$1(e, t) {
  var n = [];

  for (var r = e; r < t; ++r) {
    n.push(r);
  }

  return n;
}

function arrayConcat$1(e) {
  var t = [];

  for (var n = 0; n < e.length; ++n) {
    for (var r = 0; r < e[n].length; ++r) {
      t.push(e[n][r]);
    }
  }

  return t;
}

var greaterEqualGradConfig$1 = {
  kernelName: GreaterEqual$1,
  inputsToSave: ["a", "b"],
  gradFunc: (e, t) => {
    var [n, r] = t;
    return {
      a: () => zerosLike$5(n),
      b: () => zerosLike$5(r)
    };
  }
},
    identityGradConfig$1 = {
  kernelName: Identity$3,
  gradFunc: e => ({
    x: () => cast$7(e, "float32")
  })
},
    isFiniteGradConfig$1 = {
  kernelName: IsFinite$1,
  gradFunc: e => ({
    x: () => zerosLike$5(e)
  })
},
    isInfGradConfig$1 = {
  kernelName: IsInf$1,
  gradFunc: e => ({
    x: () => zerosLike$5(e)
  })
},
    isNanGradConfig$1 = {
  kernelName: IsNan$1,
  gradFunc: e => ({
    x: () => zerosLike$5(e)
  })
},
    leakyReluGradConfig$1 = {
  kernelName: LeakyRelu$1,
  inputsToSave: ["x"],
  gradFunc: (e, t, n) => {
    var [r] = t,
        {
      alpha: a
    } = n,
        s = greater$6(r, 0);
    return {
      x: () => where$1(s, e, mul$1(e, a))
    };
  }
},
    log1pGradConfig$1 = {
  kernelName: Log1p$1,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => div$3(e, add$5(n, 1))
    };
  }
},
    logGradConfig$1 = {
  kernelName: Log$1,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => div$3(e, cast$7(n, "float32"))
    };
  }
},
    logSoftmaxGradConfig$1 = {
  kernelName: LogSoftmax$3,
  inputsToSave: [],
  outputsToSave: [!0],
  gradFunc: (e, t, n) => {
    var [r] = t,
        {
      axis: a
    } = n;
    return {
      logits: () => {
        var t = exp$5(r);
        return sub$5(e, mul$1(sum$6(e, a, !0), t));
      }
    };
  }
};

function localResponseNormalizationBackprop_$1(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 5;
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : 1;
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : 1;
  var o = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : .5;
  return ENGINE$1.runKernel(LRNGrad$1, {
    x: e,
    y: t,
    dy: n
  }, {
    depthRadius: r,
    bias: a,
    alpha: s,
    beta: o
  });
}

var localResponseNormalizationBackprop$1 = op$1({
  localResponseNormalizationBackprop_: localResponseNormalizationBackprop_$1
}),
    lrnGradConfig$1 = {
  kernelName: LRN$1,
  inputsToSave: ["x"],
  outputsToSave: [!0],
  gradFunc: (e, t, n) => {
    var [r, a] = t,
        {
      depthRadius: s,
      bias: o,
      alpha: i,
      beta: l
    } = n;
    return {
      x: () => localResponseNormalizationBackprop$1(r, a, e, s, o, i, l)
    };
  }
};

function gradForMinAndMax$1(e, t, n, r) {
  return t.rank < n.rank && (t = reshape$6(t, expandShapeToKeepDim$1(t.shape, r))), e.rank < n.rank && (e = reshape$6(e, expandShapeToKeepDim$1(e.shape, r))), {
    x: () => mul$1(e, cast$7(equal$5(n, t), e.dtype))
  };
}

var maxGradConfig$1 = {
  kernelName: Max$1,
  inputsToSave: ["x"],
  outputsToSave: [!0],
  gradFunc: (e, t, n) => {
    var r = n,
        {
      reductionIndices: a
    } = r,
        s = t[0],
        o = gradForMinAndMax$1(e, t[1], s, parseAxisParam$1(a, s.shape));
    return {
      x: () => o.x()
    };
  }
},
    maximumGradConfig$1 = {
  kernelName: Maximum$3,
  inputsToSave: ["a", "b"],
  gradFunc: (e, t) => {
    var [n, r] = t;
    return {
      a: () => mul$1(e, cast$7(greaterEqual$5(n, r), "float32")),
      b: () => mul$1(e, cast$7(less$6(n, r), "float32"))
    };
  }
};

function maxPool3dGrad_$1(e, t, n, r, a, s, o) {
  var i = convertToTensor$1(e, "dy", "maxPool3dGrad"),
      l = convertToTensor$1(t, "input", "maxPool3dGrad"),
      u = convertToTensor$1(n, "output", "maxPool3dGrad");
  var c = i,
      p = l,
      d = u,
      h = !1;
  4 === l.rank && (h = !0, c = reshape$6(i, [1, i.shape[0], i.shape[1], i.shape[2], i.shape[3]]), p = reshape$6(l, [1, l.shape[0], l.shape[1], l.shape[2], l.shape[3]]), d = reshape$6(u, [1, u.shape[0], u.shape[1], u.shape[2], u.shape[3]])), assert$6(5 === c.rank, () => "Error in maxPool3dGrad: dy must be rank 5 but got rank ".concat(c.rank, ".")), assert$6(5 === p.rank, () => "Error in maxPool3dGrad: input must be rank 5 but got rank ".concat(p.rank, ".")), assert$6(5 === d.rank, () => "Error in maxPool3dGrad: output must be rank 5 but got rank ".concat(d.rank, ".")), null != o && assert$6(isInt$1(s), () => "Error in maxPool3dGrad: pad must be an integer when using, dimRoundingMode ".concat(o, " but got pad ").concat(s, "."));
  var m = ENGINE$1.runKernel(MaxPool3DGrad$1, {
    dy: c,
    input: p,
    output: d
  }, {
    filterSize: r,
    strides: a,
    pad: s,
    dimRoundingMode: o
  });
  return h ? reshape$6(m, [m.shape[1], m.shape[2], m.shape[3], m.shape[4]]) : m;
}

var maxPool3dGrad$1 = op$1({
  maxPool3dGrad_: maxPool3dGrad_$1
}),
    maxPool3DGradConfig$3 = {
  kernelName: MaxPool3D$1,
  inputsToSave: ["x"],
  outputsToSave: [!0],
  gradFunc: (e, t, n) => {
    var [r, a] = t,
        {
      filterSize: s,
      strides: o,
      pad: i,
      dimRoundingMode: l
    } = n;
    return {
      x: () => maxPool3dGrad$1(e, r, a, s, o, i, l)
    };
  }
};

function maxPoolGrad_$1(e, t, n, r, a, s, o) {
  var i = convertToTensor$1(e, "dy", "maxPoolGrad"),
      l = convertToTensor$1(t, "input", "maxPoolGrad"),
      u = convertToTensor$1(n, "output", "maxPoolGrad");
  return assert$6(l.rank === i.rank, () => "Rank of input (".concat(l.rank, ") does not match rank of dy (").concat(i.rank, ")")), assert$6(4 === i.rank, () => "Error in maxPoolGrad: dy must be rank 4 but got rank ".concat(i.rank, ".")), assert$6(4 === l.rank, () => "Error in maxPoolGrad: input must be rank 4 but got rank ".concat(l.rank, ".")), null != o && assert$6(isInt$1(s), () => "Error in maxPoolGrad: pad must be an integer when using, dimRoundingMode ".concat(o, " but got pad ").concat(s, ".")), ENGINE$1.runKernel(MaxPoolGrad$1, {
    dy: i,
    input: l,
    output: u
  }, {
    filterSize: r,
    strides: a,
    pad: s,
    dimRoundingMode: o
  });
}

var maxPoolGrad$5 = op$1({
  maxPoolGrad_: maxPoolGrad_$1
}),
    maxPoolGradConfig$5 = {
  kernelName: MaxPool$1,
  inputsToSave: ["x"],
  outputsToSave: [!0],
  gradFunc: (e, t, n) => {
    var [r, a] = t,
        {
      filterSize: s,
      strides: o,
      pad: i
    } = n;
    return {
      x: () => maxPoolGrad$5(e, r, a, s, o, i)
    };
  }
},
    meanGradConfig$1 = {
  kernelName: Mean$1,
  inputsToSave: ["x"],
  gradFunc: (e, t, n) => {
    var [r] = t,
        {
      axis: a
    } = n,
        s = parseAxisParam$1(a, r.shape),
        o = sizeFromShape$1(computeOutAndReduceShapes$1(r.shape, s)[1]);
    return {
      x: () => {
        var t = r.shape.slice();
        s.forEach(e => {
          t[e] = 1;
        });
        var n = reshape$6(e, t);
        return div$3(mul$1(n, ones$3(r.shape, "float32")), o);
      }
    };
  }
},
    minGradConfig$1 = {
  kernelName: Min$1,
  inputsToSave: ["x"],
  outputsToSave: [!0],
  gradFunc: (e, t, n) => {
    var r = n,
        {
      axis: a
    } = r,
        [s, o] = t,
        i = gradForMinAndMax$1(e, o, s, parseAxisParam$1(a, s.shape));
    return {
      x: () => i.x()
    };
  }
},
    minimumGradConfig$1 = {
  kernelName: Minimum$3,
  inputsToSave: ["a", "b"],
  gradFunc: (e, t) => {
    var [n, r] = t;
    return {
      a: () => mul$1(e, cast$7(lessEqual$5(n, r), "float32")),
      b: () => mul$1(e, cast$7(greater$6(n, r), "float32"))
    };
  }
},
    mirrorPadGradConfig$1 = {
  kernelName: MirrorPad$1,
  inputsToSave: ["x"],
  gradFunc: (e, t, n) => {
    var r = t[0],
        {
      paddings: a
    } = n,
        s = a.map(e => e[0]);
    return {
      x: () => slice$5(e, s, r.shape)
    };
  }
},
    modGradConfig$1 = {
  kernelName: Mod$1,
  inputsToSave: ["a", "b"],
  gradFunc: (e, t) => {
    var [n, r] = t,
        _a19 = assertAndGetBroadcastShape$1(n.shape, r.shape);

    return {
      a: () => {
        var t = getReductionAxes$1(n.shape, _a19);
        return t.length > 0 ? reshape$6(sum$6(e, t), n.shape) : e;
      },
      b: () => {
        var t = mul$1(e, neg$5(floor$5(div$3(n, r)))),
            s = getReductionAxes$1(r.shape, _a19);
        return s.length > 0 ? reshape$6(sum$6(t, s), r.shape) : t;
      }
    };
  }
},
    multiplyGradConfig$1 = {
  kernelName: Multiply$3,
  inputsToSave: ["a", "b"],
  gradFunc: (e, t) => {
    var [n, r] = t,
        _a20 = assertAndGetBroadcastShape$1(n.shape, r.shape);

    return {
      a: () => {
        var t = mul$1(e, cast$7(r, "float32")),
            s = getReductionAxes$1(n.shape, _a20);
        return s.length > 0 ? reshape$6(sum$6(t, s), n.shape) : t;
      },
      b: () => {
        var t = mul$1(e, cast$7(n, "float32")),
            s = getReductionAxes$1(r.shape, _a20);
        return s.length > 0 ? reshape$6(sum$6(t, s), r.shape) : t;
      }
    };
  }
},
    negGradConfig$1 = {
  kernelName: Neg$1,
  gradFunc: e => ({
    x: () => neg$5(e)
  })
},
    oneHotGradConfig$1 = {
  kernelName: OneHot$1,
  inputsToSave: ["indices"],
  gradFunc: (e, t) => {
    var n = t[0];
    return {
      indices: () => zeros$4(n.shape, "float32")
    };
  }
},
    onesLikeGradConfig$1 = {
  kernelName: OnesLike$1,
  gradFunc: e => ({
    x: () => zerosLike$5(e)
  })
},
    packGradConfig$1 = {
  kernelName: Pack$1,
  saveAllInputs: !0,
  gradFunc: (e, t, n) => {
    var {
      axis: r
    } = n;
    return unstack$1(e, r).map(e => () => e);
  }
},
    padV2GradConfig$1 = {
  kernelName: PadV2$1,
  inputsToSave: ["x"],
  gradFunc: (e, t, n) => {
    var r = t[0],
        {
      paddings: a
    } = n,
        s = a.map(e => e[0]);
    return {
      x: () => slice$5(e, s, r.shape)
    };
  }
},
    powGradConfig$1 = {
  kernelName: Pow$1,
  inputsToSave: ["a", "b"],
  outputsToSave: [!0],
  gradFunc: (e, t) => {
    var [n, r, a] = t,
        s = n,
        o = r,
        i = assertAndGetBroadcastShape$1(s.shape, o.shape);
    return {
      a: () => {
        var t = cast$7(o, "float32");
        var n = mul$1(e, mul$1(t, pow$5(s, sub$5(t, scalar$1(1)))));
        var r = getReductionAxes$1(s.shape, i);
        return r.length > 0 && (n = sum$6(n, r)), reshape$6(n, s.shape);
      },
      b: () => {
        var t = greater$6(s, 0),
            n = where$1(t, log$7(s), zerosLike$5(s));
        var r = mul$1(e, mul$1(a, n));
        var l = getReductionAxes$1(o.shape, i);
        return l.length > 0 && (r = sum$6(r, l)), reshape$6(r, o.shape);
      }
    };
  }
},
    preluGradConfig$1 = {
  kernelName: Prelu$1,
  inputsToSave: ["x", "alpha"],
  gradFunc: (e, t) => {
    var [n, r] = t,
        a = greater$6(n, 0);
    return {
      x: () => where$1(a, e, mul$1(e, r)),
      alpha: () => {
        var t = where$1(a, zerosLike$5(e), mul$1(e, n));
        var s = getReductionAxes$1(r.shape, e.shape);
        return s.length > 0 && (t = sum$6(t, s)), reshape$6(t, r.shape);
      }
    };
  }
},
    divGradConfig$1 = {
  kernelName: RealDiv$1,
  inputsToSave: ["a", "b"],
  gradFunc: (e, t) => {
    var [n, r] = t,
        _a21 = assertAndGetBroadcastShape$1(n.shape, r.shape);

    return {
      a: () => {
        var t = div$3(e, cast$7(r, "float32")),
            s = getReductionAxes$1(n.shape, _a21);
        return s.length > 0 ? reshape$6(sum$6(t, s), n.shape) : t;
      },
      b: () => {
        var t = mul$1(e, cast$7(n, "float32"));
        var s = getReductionAxes$1(r.shape, _a21);
        s.length > 0 && (t = reshape$6(sum$6(t, s), r.shape));
        var o = square$5(r);
        return neg$5(div$3(t, cast$7(o, "float32")));
      }
    };
  }
},
    reciprocalGradConfig$1 = {
  kernelName: Reciprocal$1,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => div$3(e, neg$5(square$5(n)))
    };
  }
},
    relu6GradConfig$1 = {
  kernelName: Relu6$3,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t,
        r = mul$1(lessEqual$5(n, 6), step$5(n));
    return {
      x: () => mul$1(e, cast$7(r, "float32"))
    };
  }
},
    reluGradConfig$1 = {
  kernelName: Relu$3,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => mul$1(e, cast$7(step$5(n), "float32"))
    };
  }
},
    reshapeGradConfig$1 = {
  kernelName: Reshape$3,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => reshape$6(e, n.shape)
    };
  }
},
    resizeBilinearGradConfig$5 = {
  kernelName: ResizeBilinear$1,
  inputsToSave: ["images"],
  gradFunc: (e, t, n) => {
    var [r] = t,
        a = {
      dy: e,
      images: r
    };
    return {
      images: () => ENGINE$1.runKernel(ResizeBilinearGrad$1, a, n)
    };
  }
},
    resizeNearestNeighborGradConfig$5 = {
  kernelName: ResizeNearestNeighbor$1,
  inputsToSave: ["images"],
  gradFunc: (e, t, n) => {
    var [r] = t,
        a = {
      dy: e,
      images: r
    };
    return {
      images: () => ENGINE$1.runKernel(ResizeNearestNeighborGrad$1, a, n)
    };
  }
},
    reverseGradConfig$1 = {
  kernelName: Reverse$1,
  gradFunc: (e, t, n) => {
    var {
      dims: r
    } = n,
        a = parseAxisParam$1(r, e.shape);
    return {
      x: () => reverse$5(e, a)
    };
  }
},
    roundGradConfig$1 = {
  kernelName: Round$1,
  gradFunc: e => ({
    x: () => zerosLike$5(e)
  })
},
    rsqrtGradConfig$1 = {
  kernelName: Rsqrt$1,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => neg$5(div$3(e, mul$1(pow$5(n, 1.5), 2)))
    };
  }
},
    selectGradConfig$1 = {
  kernelName: Select$1,
  inputsToSave: ["condition"],
  gradFunc: (_e88, t) => {
    var [n] = t;
    return {
      condition: () => cast$7(zerosLike$5(n), "float32"),
      t: () => mul$1(_e88, cast$7(n, _e88.dtype)),
      e: () => mul$1(_e88, cast$7(logicalNot$5(n), _e88.dtype))
    };
  }
},
    seluGradConfig$1 = {
  kernelName: Selu$3,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => {
        var t = greater$6(n, scalar$1(0)),
            r = scalar$1(SELU_SCALEALPHA$1),
            a = scalar$1(SELU_SCALE$1),
            s = mul$1(e, a),
            o = mul$1(mul$1(e, r), exp$5(cast$7(n, "float32")));
        return where$1(t, s, o);
      }
    };
  }
},
    sigmoidGradConfig$1 = {
  kernelName: Sigmoid$3,
  outputsToSave: [!0],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => mul$1(e, mul$1(n, sub$5(scalar$1(1), n)))
    };
  }
},
    signGradConfig$1 = {
  kernelName: Sign$1,
  gradFunc: e => ({
    x: () => zerosLike$5(e)
  })
},
    sinGradConfig$1 = {
  kernelName: Sin$1,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => mul$1(cos$5(cast$7(n, "float32")), e)
    };
  }
},
    sinhGradConfig$1 = {
  kernelName: Sinh$1,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => mul$1(cosh$5(cast$7(n, "float32")), e)
    };
  }
},
    sliceGradConfig$1 = {
  kernelName: Slice$1,
  inputsToSave: ["x"],
  gradFunc: (e, t, n) => {
    var [r] = t,
        {
      begin: a,
      size: s
    } = n,
        o = r.shape,
        [i, l] = parseSliceParams$1(r, a, s),
        u = [];

    for (var _t75 = 0; _t75 < e.rank; _t75++) {
      u.push([i[_t75], o[_t75] - i[_t75] - l[_t75]]);
    }

    return {
      x: () => pad$1(e, u)
    };
  }
},
    softmaxGradConfig$1 = {
  kernelName: Softmax$5,
  outputsToSave: [!0],
  gradFunc: (e, t, n) => {
    var [r] = t,
        {
      dim: a
    } = n,
        s = mul$1(e, r);
    return {
      logits: () => sub$5(s, mul$1(sum$6(s, [a], !0), r))
    };
  }
},
    softplusGradConfig$1 = {
  kernelName: Softplus$3,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => mul$1(e, sigmoid$5(n))
    };
  }
},
    spaceToBatchNDGradConfig$1 = {
  kernelName: SpaceToBatchND$1,
  gradFunc: (e, t, n) => {
    var {
      blockShape: r,
      paddings: a
    } = n;
    return {
      x: () => batchToSpaceND$5(e, r, a)
    };
  }
},
    splitVGradConfig$1 = {
  kernelName: SplitV$1,
  gradFunc: (e, t, n) => {
    var {
      axis: r
    } = n;
    return {
      x: () => concat$5(e, r)
    };
  }
},
    sqrtGradConfig$1 = {
  kernelName: Sqrt$1,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => div$3(e, mul$1(sqrt$5(cast$7(n, "float32")), 2))
    };
  }
},
    squareGradConfig$1 = {
  kernelName: Square$1,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => mul$1(e, mul$1(cast$7(n, "float32"), 2))
    };
  }
},
    squaredDifferenceGradConfig$1 = {
  kernelName: SquaredDifference$1,
  inputsToSave: ["a", "b"],
  gradFunc: (e, t) => {
    var [n, r] = t,
        _a22 = scalar$1(2);

    return {
      a: () => mul$1(e, mul$1(_a22, sub$5(n, r))),
      b: () => mul$1(e, mul$1(_a22, sub$5(r, n)))
    };
  }
},
    stepGradConfig$1 = {
  kernelName: Step$1,
  gradFunc: e => ({
    x: () => zerosLike$5(e)
  })
},
    subGradConfig$1 = {
  kernelName: Sub$1,
  inputsToSave: ["a", "b"],
  gradFunc: (e, t) => {
    var [n, r] = t,
        _a23 = assertAndGetBroadcastShape$1(n.shape, r.shape);

    return {
      a: () => {
        var t = e;
        var r = getReductionAxes$1(n.shape, _a23);
        return r.length > 0 && (t = sum$6(t, r)), reshape$6(t, n.shape);
      },
      b: () => {
        var t = e;
        var n = getReductionAxes$1(r.shape, _a23);
        return n.length > 0 && (t = sum$6(t, n)), reshape$6(neg$5(t), r.shape);
      }
    };
  }
},
    sumGradConfig$1 = {
  kernelName: Sum$1,
  inputsToSave: ["x"],
  gradFunc: (e, t, n) => {
    var [r] = t,
        a = r.shape.slice(),
        {
      axis: s
    } = n;
    parseAxisParam$1(s, r.shape).forEach(e => {
      a[e] = 1;
    });
    var o = reshape$6(e, a),
        i = mul$1(o, ones$3(r.shape, "float32"));
    return {
      x: () => i
    };
  }
},
    tanGradConfig$1 = {
  kernelName: Tan$1,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => div$3(e, square$5(cos$5(n)))
    };
  }
},
    tanhGradConfig$1 = {
  kernelName: Tanh$3,
  outputsToSave: [!0],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => mul$1(sub$5(scalar$1(1), square$5(n)), e)
    };
  }
},
    tileGradConfig$1 = {
  kernelName: Tile$1,
  inputsToSave: ["x"],
  gradFunc: (e, t, n) => {
    var [r] = t,
        {
      reps: a
    } = n;
    return {
      x: () => {
        var t = zerosLike$5(r);
        if (1 === r.rank) for (var _n27 = 0; _n27 < a[0]; ++_n27) {
          t = add$5(t, slice$5(e, [_n27 * r.shape[0]], [r.shape[0]]));
        } else if (2 === r.rank) for (var _n28 = 0; _n28 < a[0]; ++_n28) {
          for (var s = 0; s < a[1]; ++s) {
            t = add$5(t, slice$5(e, [_n28 * r.shape[0], s * r.shape[1]], [r.shape[0], r.shape[1]]));
          }
        } else if (3 === r.rank) for (var _n29 = 0; _n29 < a[0]; ++_n29) {
          for (var _s9 = 0; _s9 < a[1]; ++_s9) {
            for (var o = 0; o < a[2]; ++o) {
              t = add$5(t, slice$5(e, [_n29 * r.shape[0], _s9 * r.shape[1], o * r.shape[2]], [r.shape[0], r.shape[1], r.shape[2]]));
            }
          }
        } else {
          if (4 !== r.rank) throw new Error("Gradient for tile operation is not implemented for rank-".concat(r.rank, " tensors yet."));

          for (var _n30 = 0; _n30 < a[0]; ++_n30) {
            for (var _s10 = 0; _s10 < a[1]; ++_s10) {
              for (var _o7 = 0; _o7 < a[2]; ++_o7) {
                for (var i = 0; i < a[3]; ++i) {
                  t = add$5(t, slice$5(e, [_n30 * r.shape[0], _s10 * r.shape[1], _o7 * r.shape[2], i * r.shape[3]], [r.shape[0], r.shape[1], r.shape[2], r.shape[3]]));
                }
              }
            }
          }
        }
        return t;
      }
    };
  }
},
    transposeGradConfig$1 = {
  kernelName: Transpose$1,
  gradFunc: (e, t, n) => {
    var r = n,
        {
      perm: a
    } = r,
        s = getUndoAxesPermutation$1(a);
    return {
      x: () => transpose$5(e, s)
    };
  }
},
    unpackGradConfig$1 = {
  kernelName: Unpack$1,
  gradFunc: (e, t, n) => {
    var r = n,
        {
      axis: a
    } = r;
    return {
      value: () => stack$1(e, a)
    };
  }
},
    unsortedSegmentSumGradConfig$1 = {
  kernelName: UnsortedSegmentSum$1,
  inputsToSave: ["segmentIds"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => gatherDropNegatives$1(e, n)
    };
  }
};

function gatherDropNegatives$1(e, t) {
  var n = maximum$6(t, zerosLike$5(t)),
      r = gather$3(e, n);
  var a = greaterEqual$5(t, scalar$1(0, "int32"));
  var s = r.rank - a.rank;

  for (var _e89 = 0; _e89 < s; ++_e89) {
    a = expandDims$7(a, _e89 + 1);
  }

  a = logicalAnd$5(a, ones$3(r.shape, "bool"));
  var o = zerosLike$5(r);
  return where$1(a, r, o);
}

var zerosLikeGradConfig$1 = {
  kernelName: ZerosLike$1,
  gradFunc: e => ({
    x: () => zerosLike$5(e)
  })
},
    gradConfigs$1 = [absGradConfig$1, acosGradConfig$1, acoshGradConfig$1, addGradConfig$1, addNGradConfig$1, argMaxGradConfig$1, argMinGradConfig$1, asinGradConfig$1, asinhGradConfig$1, atan2GradConfig$1, atanGradConfig$1, atanhGradConfig$1, avgPool3DGradConfig$3, avgPoolGradConfig$5, batchMatMulGradConfig$1, batchToSpaceNDGradConfig$1, broadcastToGradConfig$1, castGradConfig$1, ceilGradConfig$1, clipByValueGradConfig$1, complexAbsGradConfig$1, concatGradConfig$1, conv2DBackpropInputGradConfig$1, conv2DGradConfig$1, conv3DGradConfig$1, cosGradConfig$1, coshGradConfig$1, cumsumGradConfig$1, depthwiseConv2dNativeGradConfig$1, dilation2dGradConfig$1, divGradConfig$1, eluGradConfig$5, erfGradConfig$1, expGradConfig$1, expandDimsGradConfig$1, expm1GradConfig$1, floorDivGradConfig$1, floorGradConfig$1, fusedBatchNormGradConfig$1, gatherGradConfig$1, greaterEqualGradConfig$1, identityGradConfig$1, isFiniteGradConfig$1, isInfGradConfig$1, isNanGradConfig$1, leakyReluGradConfig$1, log1pGradConfig$1, logGradConfig$1, logSoftmaxGradConfig$1, lrnGradConfig$1, maxGradConfig$1, maxGradConfig$1, maximumGradConfig$1, maxPool3DGradConfig$3, maxPoolGradConfig$5, meanGradConfig$1, minGradConfig$1, minimumGradConfig$1, mirrorPadGradConfig$1, modGradConfig$1, multiplyGradConfig$1, negGradConfig$1, oneHotGradConfig$1, onesLikeGradConfig$1, packGradConfig$1, padV2GradConfig$1, padV2GradConfig$1, powGradConfig$1, preluGradConfig$1, reciprocalGradConfig$1, relu6GradConfig$1, reluGradConfig$1, reshapeGradConfig$1, resizeBilinearGradConfig$5, resizeNearestNeighborGradConfig$5, reverseGradConfig$1, roundGradConfig$1, rsqrtGradConfig$1, selectGradConfig$1, seluGradConfig$1, sigmoidGradConfig$1, signGradConfig$1, sinGradConfig$1, sinhGradConfig$1, sliceGradConfig$1, softmaxGradConfig$1, softplusGradConfig$1, spaceToBatchNDGradConfig$1, spaceToBatchNDGradConfig$1, splitVGradConfig$1, splitVGradConfig$1, sqrtGradConfig$1, squaredDifferenceGradConfig$1, squareGradConfig$1, stepGradConfig$1, subGradConfig$1, sumGradConfig$1, tanGradConfig$1, tanhGradConfig$1, tileGradConfig$1, transposeGradConfig$1, unpackGradConfig$1, unsortedSegmentSumGradConfig$1, zerosLikeGradConfig$1];

for (var e of gradConfigs$1) {
  registerGradient$1(e);
}

var _epsilon$1;

function epsilon$3() {
  return null == _epsilon$1 && (_epsilon$1 = backend$1().epsilon()), _epsilon$1;
}

function imageDataFormat$1() {
  return "channelsLast";
}

getGlobalTensorClass$1().prototype.abs = function () {
  return this.throwIfDisposed(), abs$5(this);
}, getGlobalTensorClass$1().prototype.acos = function () {
  return this.throwIfDisposed(), acos$5(this);
}, getGlobalTensorClass$1().prototype.acosh = function () {
  return this.throwIfDisposed(), acosh$5(this);
}, getGlobalTensorClass$1().prototype.add = function (e) {
  return this.throwIfDisposed(), add$5(this, e);
}, getGlobalTensorClass$1().prototype.all = function (e, t) {
  return this.throwIfDisposed(), all$5(this, e, t);
}, getGlobalTensorClass$1().prototype.any = function (e, t) {
  return this.throwIfDisposed(), any$5(this, e, t);
}, getGlobalTensorClass$1().prototype.argMax = function (e) {
  return this.throwIfDisposed(), argMax$5(this, e);
}, getGlobalTensorClass$1().prototype.argMin = function (e) {
  return this.throwIfDisposed(), argMin$5(this, e);
}, getGlobalTensorClass$1().prototype.asScalar = function () {
  return this.throwIfDisposed(), assert$6(1 === this.size, () => "The array must have only 1 element."), reshape$6(this, []);
}, getGlobalTensorClass$1().prototype.asType = function (e) {
  return this.throwIfDisposed(), cast$7(this, e);
}, getGlobalTensorClass$1().prototype.as1D = function () {
  return this.throwIfDisposed(), reshape$6(this, [this.size]);
}, getGlobalTensorClass$1().prototype.as2D = function (e, t) {
  return this.throwIfDisposed(), reshape$6(this, [e, t]);
}, getGlobalTensorClass$1().prototype.as3D = function (e, t, n) {
  return this.throwIfDisposed(), reshape$6(this, [e, t, n]);
}, getGlobalTensorClass$1().prototype.as4D = function (e, t, n, r) {
  return this.throwIfDisposed(), reshape$6(this, [e, t, n, r]);
}, getGlobalTensorClass$1().prototype.as5D = function (e, t, n, r, a) {
  return this.throwIfDisposed(), reshape$6(this, [e, t, n, r, a]);
}, getGlobalTensorClass$1().prototype.asin = function () {
  return this.throwIfDisposed(), asin$5(this);
}, getGlobalTensorClass$1().prototype.asinh = function () {
  return this.throwIfDisposed(), asinh$5(this);
}, getGlobalTensorClass$1().prototype.atan = function () {
  return this.throwIfDisposed(), atan$5(this);
}, getGlobalTensorClass$1().prototype.atan2 = function (e) {
  return this.throwIfDisposed(), atan2$5(this, e);
}, getGlobalTensorClass$1().prototype.atanh = function () {
  return this.throwIfDisposed(), atanh$5(this);
}, getGlobalTensorClass$1().prototype.avgPool = function (e, t, n, r) {
  return this.throwIfDisposed(), avgPool$5(this, e, t, n, r);
}, getGlobalTensorClass$1().prototype.batchToSpaceND = function (e, t) {
  return this.throwIfDisposed(), batchToSpaceND$5(this, e, t);
}, getGlobalTensorClass$1().prototype.batchNorm = function (e, t, n, r, a) {
  return this.throwIfDisposed(), batchNorm$5(this, e, t, n, r, a);
}, getGlobalTensorClass$1().prototype.broadcastTo = function (e) {
  return this.throwIfDisposed(), broadcastTo$1(this, e);
}, getGlobalTensorClass$1().prototype.cast = function (e) {
  return this.throwIfDisposed(), cast$7(this, e);
}, getGlobalTensorClass$1().prototype.ceil = function () {
  return this.throwIfDisposed(), ceil$5(this);
}, getGlobalTensorClass$1().prototype.clipByValue = function (e, t) {
  return this.throwIfDisposed(), clipByValue$3(this, e, t);
}, getGlobalTensorClass$1().prototype.concat = function (e, t) {
  return this.throwIfDisposed(), e instanceof Tensor$1 && (e = [e]), concat$5([this, ...e], t);
}, getGlobalTensorClass$1().prototype.conv1d = function (e, t, n, r, a, s) {
  return this.throwIfDisposed(), conv1d$3(this, e, t, n, r, a, s);
}, getGlobalTensorClass$1().prototype.conv2dTranspose = function (e, t, n, r, a) {
  return this.throwIfDisposed(), conv2dTranspose$2(this, e, t, n, r, a);
}, getGlobalTensorClass$1().prototype.conv2d = function (e, t, n, r, a, s) {
  return this.throwIfDisposed(), conv2d$7(this, e, t, n, r, a, s);
}, getGlobalTensorClass$1().prototype.cos = function () {
  return this.throwIfDisposed(), cos$5(this);
}, getGlobalTensorClass$1().prototype.cosh = function () {
  return this.throwIfDisposed(), cosh$5(this);
}, getGlobalTensorClass$1().prototype.cumsum = function (e, t, n) {
  return this.throwIfDisposed(), cumsum$5(this, e, t, n);
}, getGlobalTensorClass$1().prototype.depthToSpace = function (e, t) {
  return this.throwIfDisposed(), depthToSpace$5(this, e, t);
}, getGlobalTensorClass$1().prototype.depthwiseConv2d = function (e, t, n, r, a, s) {
  return this.throwIfDisposed(), depthwiseConv2d$5(this, e, t, n, r, a, s);
}, getGlobalTensorClass$1().prototype.dilation2d = function (e, t, n, r, a) {
  return this.throwIfDisposed(), dilation2d$1(this, e, t, n, r, a);
}, getGlobalTensorClass$1().prototype.divNoNan = function (e) {
  return this.throwIfDisposed(), divNoNan$1(this, e);
}, getGlobalTensorClass$1().prototype.div = function (e) {
  return this.throwIfDisposed(), div$3(this, e);
}, getGlobalTensorClass$1().prototype.dot = function (e) {
  return this.throwIfDisposed(), dot$4(this, e);
}, getGlobalTensorClass$1().prototype.elu = function () {
  return this.throwIfDisposed(), elu$8(this);
}, getGlobalTensorClass$1().prototype.equal = function (e) {
  return this.throwIfDisposed(), equal$5(this, e);
}, getGlobalTensorClass$1().prototype.erf = function () {
  return this.throwIfDisposed(), erf$5(this);
}, getGlobalTensorClass$1().prototype.exp = function () {
  return this.throwIfDisposed(), exp$5(this);
}, getGlobalTensorClass$1().prototype.expandDims = function (e) {
  return this.throwIfDisposed(), expandDims$7(this, e);
}, getGlobalTensorClass$1().prototype.expm1 = function () {
  return this.throwIfDisposed(), expm1$5(this);
}, getGlobalTensorClass$1().prototype.fft = function () {
  return this.throwIfDisposed(), fft$5(this);
}, getGlobalTensorClass$1().prototype.flatten = function () {
  return this.throwIfDisposed(), reshape$6(this, [this.size]);
}, getGlobalTensorClass$1().prototype.floor = function () {
  return this.throwIfDisposed(), floor$5(this);
}, getGlobalTensorClass$1().prototype.floorDiv = function (e) {
  return this.throwIfDisposed(), floorDiv$5(this, e);
}, getGlobalTensorClass$1().prototype.gather = function (e, t) {
  return this.throwIfDisposed(), gather$3(this, e, t);
}, getGlobalTensorClass$1().prototype.greaterEqual = function (e) {
  return this.throwIfDisposed(), greaterEqual$5(this, e);
}, getGlobalTensorClass$1().prototype.greater = function (e) {
  return this.throwIfDisposed(), greater$6(this, e);
}, getGlobalTensorClass$1().prototype.ifft = function () {
  return this.throwIfDisposed(), ifft$5(this);
}, getGlobalTensorClass$1().prototype.irfft = function () {
  return this.throwIfDisposed(), irfft$1(this);
}, getGlobalTensorClass$1().prototype.isFinite = function () {
  return this.throwIfDisposed(), isFinite$6(this);
}, getGlobalTensorClass$1().prototype.isInf = function () {
  return this.throwIfDisposed(), isInf$5(this);
}, getGlobalTensorClass$1().prototype.isNaN = function () {
  return this.throwIfDisposed(), isNaN$6(this);
}, getGlobalTensorClass$1().prototype.leakyRelu = function (e) {
  return this.throwIfDisposed(), leakyRelu$5(this, e);
}, getGlobalTensorClass$1().prototype.lessEqual = function (e) {
  return this.throwIfDisposed(), lessEqual$5(this, e);
}, getGlobalTensorClass$1().prototype.less = function (e) {
  return this.throwIfDisposed(), less$6(this, e);
}, getGlobalTensorClass$1().prototype.localResponseNormalization = function (e, t, n, r) {
  return this.throwIfDisposed(), localResponseNormalization$1(this, e, t, n, r);
}, getGlobalTensorClass$1().prototype.logSigmoid = function () {
  return this.throwIfDisposed(), logSigmoid$1(this);
}, getGlobalTensorClass$1().prototype.logSoftmax = function (e) {
  return this.throwIfDisposed(), logSoftmax$1(this, e);
}, getGlobalTensorClass$1().prototype.logSumExp = function (e, t) {
  return this.throwIfDisposed(), logSumExp$1(this, e, t);
}, getGlobalTensorClass$1().prototype.log = function () {
  return this.throwIfDisposed(), log$7(this);
}, getGlobalTensorClass$1().prototype.log1p = function () {
  return this.throwIfDisposed(), log1p$5(this);
}, getGlobalTensorClass$1().prototype.logicalAnd = function (e) {
  return this.throwIfDisposed(), logicalAnd$5(this, e);
}, getGlobalTensorClass$1().prototype.logicalNot = function () {
  return this.throwIfDisposed(), logicalNot$5(this);
}, getGlobalTensorClass$1().prototype.logicalOr = function (e) {
  return this.throwIfDisposed(), logicalOr$5(this, e);
}, getGlobalTensorClass$1().prototype.logicalXor = function (e) {
  return this.throwIfDisposed(), logicalXor$1(this, e);
}, getGlobalTensorClass$1().prototype.matMul = function (e, t, n) {
  return this.throwIfDisposed(), matMul$3(this, e, t, n);
}, getGlobalTensorClass$1().prototype.maxPool = function (e, t, n, r) {
  return this.throwIfDisposed(), maxPool$5(this, e, t, n, r);
}, getGlobalTensorClass$1().prototype.max = function (e, t) {
  return this.throwIfDisposed(), max$7(this, e, t);
}, getGlobalTensorClass$1().prototype.maximum = function (e) {
  return this.throwIfDisposed(), maximum$6(this, e);
}, getGlobalTensorClass$1().prototype.mean = function (e, t) {
  return this.throwIfDisposed(), mean$3(this, e, t);
}, getGlobalTensorClass$1().prototype.min = function (e, t) {
  return this.throwIfDisposed(), min$7(this, e, t);
}, getGlobalTensorClass$1().prototype.minimum = function (e) {
  return this.throwIfDisposed(), minimum$6(this, e);
}, getGlobalTensorClass$1().prototype.mirrorPad = function (e, t) {
  return this.throwIfDisposed(), mirrorPad$3(this, e, t);
}, getGlobalTensorClass$1().prototype.mod = function (e) {
  return this.throwIfDisposed(), mod$5(this, e);
}, getGlobalTensorClass$1().prototype.mul = function (e) {
  return this.throwIfDisposed(), mul$1(this, e);
}, getGlobalTensorClass$1().prototype.neg = function () {
  return this.throwIfDisposed(), neg$5(this);
}, getGlobalTensorClass$1().prototype.norm = function (e, t, n) {
  return this.throwIfDisposed(), norm$1(this, e, t, n);
}, getGlobalTensorClass$1().prototype.notEqual = function (e) {
  return this.throwIfDisposed(), notEqual$5(this, e);
}, getGlobalTensorClass$1().prototype.oneHot = function (e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 1;
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;
  return this.throwIfDisposed(), oneHot$5(this, e, t, n);
}, getGlobalTensorClass$1().prototype.onesLike = function () {
  return this.throwIfDisposed(), onesLike$5(this);
}, getGlobalTensorClass$1().prototype.pad = function (e, t) {
  return this.throwIfDisposed(), pad$1(this, e, t);
}, getGlobalTensorClass$1().prototype.pool = function (e, t, n, r, a) {
  return this.throwIfDisposed(), pool$3(this, e, t, n, r, a);
}, getGlobalTensorClass$1().prototype.pow = function (e) {
  return this.throwIfDisposed(), pow$5(this, e);
}, getGlobalTensorClass$1().prototype.prelu = function (e) {
  return this.throwIfDisposed(), prelu$6(this, e);
}, getGlobalTensorClass$1().prototype.prod = function (e, t) {
  return this.throwIfDisposed(), prod$5(this, e, t);
}, getGlobalTensorClass$1().prototype.reciprocal = function () {
  return this.throwIfDisposed(), reciprocal$5(this);
}, getGlobalTensorClass$1().prototype.relu = function () {
  return this.throwIfDisposed(), relu$6(this);
}, getGlobalTensorClass$1().prototype.relu6 = function () {
  return this.throwIfDisposed(), relu6$5(this);
}, getGlobalTensorClass$1().prototype.reshapeAs = function (e) {
  return this.throwIfDisposed(), reshape$6(this, e.shape);
}, getGlobalTensorClass$1().prototype.reshape = function (e) {
  return this.throwIfDisposed(), reshape$6(this, e);
}, getGlobalTensorClass$1().prototype.resizeBilinear = function (e, t, n) {
  return this.throwIfDisposed(), resizeBilinear$5(this, e, t, n);
}, getGlobalTensorClass$1().prototype.resizeNearestNeighbor = function (e, t, n) {
  return this.throwIfDisposed(), resizeNearestNeighbor$5(this, e, t, n);
}, getGlobalTensorClass$1().prototype.reverse = function (e) {
  return this.throwIfDisposed(), reverse$5(this, e);
}, getGlobalTensorClass$1().prototype.rfft = function () {
  return this.throwIfDisposed(), rfft$1(this);
}, getGlobalTensorClass$1().prototype.round = function () {
  return this.throwIfDisposed(), round$6(this);
}, getGlobalTensorClass$1().prototype.rsqrt = function () {
  return this.throwIfDisposed(), rsqrt$5(this);
}, getGlobalTensorClass$1().prototype.selu = function () {
  return this.throwIfDisposed(), selu$5(this);
}, getGlobalTensorClass$1().prototype.separableConv2d = function (e, t, n, r, a, s) {
  return this.throwIfDisposed(), separableConv2d$2(this, e, t, n, r, a, s);
}, getGlobalTensorClass$1().prototype.sigmoid = function () {
  return this.throwIfDisposed(), sigmoid$5(this);
}, getGlobalTensorClass$1().prototype.sign = function () {
  return this.throwIfDisposed(), sign$5(this);
}, getGlobalTensorClass$1().prototype.sin = function () {
  return this.throwIfDisposed(), sin$5(this);
}, getGlobalTensorClass$1().prototype.sinh = function () {
  return this.throwIfDisposed(), sinh$5(this);
}, getGlobalTensorClass$1().prototype.slice = function (e, t) {
  return this.throwIfDisposed(), slice$5(this, e, t);
}, getGlobalTensorClass$1().prototype.softmax = function (e) {
  return this.throwIfDisposed(), softmax$6(this, e);
}, getGlobalTensorClass$1().prototype.softplus = function () {
  return this.throwIfDisposed(), softplus$5(this);
}, getGlobalTensorClass$1().prototype.spaceToBatchND = function (e, t) {
  return this.throwIfDisposed(), spaceToBatchND$5(this, e, t);
}, getGlobalTensorClass$1().prototype.split = function (e, t) {
  return this.throwIfDisposed(), split$4(this, e, t);
}, getGlobalTensorClass$1().prototype.sqrt = function () {
  return this.throwIfDisposed(), sqrt$5(this);
}, getGlobalTensorClass$1().prototype.square = function () {
  return this.throwIfDisposed(), square$5(this);
}, getGlobalTensorClass$1().prototype.squaredDifference = function (e) {
  return this.throwIfDisposed(), squaredDifference$5(this, e);
}, getGlobalTensorClass$1().prototype.squeeze = function (e) {
  return this.throwIfDisposed(), squeeze$1(this, e);
}, getGlobalTensorClass$1().prototype.stack = function (e, t) {
  this.throwIfDisposed();
  var n = e instanceof Tensor$1 ? [this, e] : [this, ...e];
  return stack$1(n, t);
}, getGlobalTensorClass$1().prototype.step = function (e) {
  return this.throwIfDisposed(), step$5(this, e);
}, getGlobalTensorClass$1().prototype.stridedSlice = function (e, t, n, r, a, s, o, i) {
  return this.throwIfDisposed(), stridedSlice$5(this, e, t, n, r, a, s, o, i);
}, getGlobalTensorClass$1().prototype.sub = function (e) {
  return this.throwIfDisposed(), sub$5(this, e);
}, getGlobalTensorClass$1().prototype.sum = function (e, t) {
  return this.throwIfDisposed(), sum$6(this, e, t);
}, getGlobalTensorClass$1().prototype.tan = function () {
  return this.throwIfDisposed(), tan$5(this);
}, getGlobalTensorClass$1().prototype.tanh = function () {
  return this.throwIfDisposed(), tanh$6(this);
}, getGlobalTensorClass$1().prototype.tile = function (e) {
  return this.throwIfDisposed(), tile$7(this, e);
}, getGlobalTensorClass$1().prototype.toBool = function () {
  return this.throwIfDisposed(), cast$7(this, "bool");
}, getGlobalTensorClass$1().prototype.toFloat = function () {
  return this.throwIfDisposed(), cast$7(this, "float32");
}, getGlobalTensorClass$1().prototype.toInt = function () {
  return this.throwIfDisposed(), cast$7(this, "int32");
}, getGlobalTensorClass$1().prototype.topk = function (e, t) {
  return this.throwIfDisposed(), topk$1(this, e, t);
}, getGlobalTensorClass$1().prototype.transpose = function (e) {
  return this.throwIfDisposed(), transpose$5(this, e);
}, getGlobalTensorClass$1().prototype.unique = function (e) {
  return this.throwIfDisposed(), unique$7(this, e);
}, getGlobalTensorClass$1().prototype.unsortedSegmentSum = function (e, t) {
  return this.throwIfDisposed(), unsortedSegmentSum$5(this, e, t);
}, getGlobalTensorClass$1().prototype.unstack = function (e) {
  return this.throwIfDisposed(), unstack$1(this, e);
}, getGlobalTensorClass$1().prototype.where = function (e, t) {
  return this.throwIfDisposed(), where$1(e, this, t);
}, getGlobalTensorClass$1().prototype.zerosLike = function () {
  return this.throwIfDisposed(), zerosLike$5(this);
};

class AttributeError$1 extends Error {
  constructor(e) {
    super(e), Object.setPrototypeOf(this, AttributeError$1.prototype);
  }

}

class RuntimeError$1 extends Error {
  constructor(e) {
    super(e), Object.setPrototypeOf(this, RuntimeError$1.prototype);
  }

}

class ValueError$1 extends Error {
  constructor(e) {
    super(e), Object.setPrototypeOf(this, ValueError$1.prototype);
  }

}

class NotImplementedError$1 extends Error {
  constructor(e) {
    super(e), Object.setPrototypeOf(this, NotImplementedError$1.prototype);
  }

}

class AssertionError$1 extends Error {
  constructor(e) {
    super(e), Object.setPrototypeOf(this, AssertionError$1.prototype);
  }

}

function pyListRepeat$1(e, t) {
  if (Array.isArray(e)) {
    var n = [];

    for (var r = 0; r < t; r++) {
      n = n.concat(e);
    }

    return n;
  }

  {
    var _n31 = new Array(t);

    return _n31.fill(e), _n31;
  }
}

function assert$5(e, t) {
  if (!e) throw new AssertionError$1(t);
}

function count$1(e, t) {
  var n = 0;

  for (var r of e) {
    r === t && n++;
  }

  return n;
}

function singletonOrArray$1(e) {
  return 1 === e.length ? e[0] : e;
}

function toList$1(e) {
  return Array.isArray(e) ? e : [e];
}

function toSnakeCase$1(e) {
  var t = e.replace(/(.)([A-Z][a-z0-9]+)/g, "$1_$2").replace(/([a-z])([A-Z])/g, "$1_$2").toLowerCase();
  return "_" !== t[0] ? t : "private" + t;
}

function toCamelCase$1(e) {
  return e.length <= 1 || -1 === e.indexOf("_") ? e : e.replace(/[_]+(\w|$)/g, (e, t) => t.toUpperCase());
}

var _GLOBAL_CUSTOM_OBJECTS$1 = {};

function serializeKerasObject$1(e) {
  if (null == e) return null;
  var t = {};
  return t.className = e.getClassName(), t.config = e.getConfig(), t;
}

function convertNDArrayScalarsInConfig$1(e) {
  if (null != e && "object" == typeof e) if (Array.isArray(e)) e.forEach(e => convertNDArrayScalarsInConfig$1(e));else {
    var t = Object.keys(e);

    for (var n of t) {
      var _t76 = e[n];
      null != _t76 && "object" == typeof _t76 && (Array.isArray(_t76) || "ndarray" !== _t76.type || "number" != typeof _t76.value ? convertNDArrayScalarsInConfig$1(_t76) : e[n] = _t76.value);
    }
  }
}

function deserializeKerasObject$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : "object";
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;

  if ("string" == typeof e) {
    var _a24 = e;
    var s;
    if (_a24 in n) s = n[_a24];else if (_a24 in _GLOBAL_CUSTOM_OBJECTS$1) s = _GLOBAL_CUSTOM_OBJECTS$1[_a24];else if (s = t[_a24], null == s) throw new ValueError$1("Unknown ".concat(r, ": ").concat(e, ". This may be due to one of the following reasons:\n1. The ").concat(r, " is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.\n2. The custom ").concat(r, " is defined in JavaScript, but is not registered properly with tf.serialization.registerClass()."));
    return s;
  }

  {
    var _s11 = e;
    if (null == _s11.className || null == _s11.config) throw new ValueError$1("".concat(r, ": Improper config format: ").concat(JSON.stringify(_s11), ".\n'className' and 'config' must set."));
    var o = _s11.className;
    var i, l;
    if (o in n ? [i, l] = n[o] : o in _GLOBAL_CUSTOM_OBJECTS$1 ? [i, l] = _GLOBAL_CUSTOM_OBJECTS$1.className : o in t && ([i, l] = t[o]), null == i) throw new ValueError$1("Unknown ".concat(r, ": ").concat(o, ". This may be due to one of the following reasons:\n1. The ").concat(r, " is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.\n2. The custom ").concat(r, " is defined in JavaScript, but is not registered properly with tf.serialization.registerClass()."));

    if (null != l) {
      var _e90 = {};

      for (var _t78 of Object.keys(_GLOBAL_CUSTOM_OBJECTS$1)) {
        _e90[_t78] = _GLOBAL_CUSTOM_OBJECTS$1[_t78];
      }

      for (var _t79 of Object.keys(n)) {
        _e90[_t79] = n[_t79];
      }

      _s11.config.customObjects = _e90;

      var _t77 = Object.assign({}, _GLOBAL_CUSTOM_OBJECTS$1);

      for (var _e91 of Object.keys(n)) {
        _GLOBAL_CUSTOM_OBJECTS$1[_e91] = n[_e91];
      }

      convertNDArrayScalarsInConfig$1(_s11.config);

      var _r23 = l(i, _s11.config, n, a);

      return _GLOBAL_CUSTOM_OBJECTS$1 = Object.assign({}, _t77), _r23;
    }

    {
      var _e92 = Object.assign({}, _GLOBAL_CUSTOM_OBJECTS$1);

      for (var _e93 of Object.keys(n)) {
        _GLOBAL_CUSTOM_OBJECTS$1[_e93] = n[_e93];
      }

      var _t80 = new i(_s11.config);

      return _GLOBAL_CUSTOM_OBJECTS$1 = Object.assign({}, _e92), _t80;
    }
  }
}

function numberCompare$1(e, t) {
  return e < t ? -1 : e > t ? 1 : 0;
}

function reverseNumberCompare$1(e, t) {
  return -1 * numberCompare$1(e, t);
}

function unique$6(e) {
  if (null == e) return e;
  var t = [];

  for (var n of e) {
    -1 === t.indexOf(n) && t.push(n);
  }

  return t;
}

function isObjectEmpty$1(e) {
  if (null == e) throw new ValueError$1("Invalid value in obj: ".concat(JSON.stringify(e)));

  for (var t in e) {
    if (e.hasOwnProperty(t)) return !1;
  }

  return !0;
}

function checkStringTypeUnionValue$1(e, t, n) {
  if (null != n && e.indexOf(n) < 0) throw new ValueError$1("".concat(n, " is not a valid ").concat(t, ".  Valid values are ").concat(e, " or null/undefined."));
}

function checkArrayTypeAndLength$1(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : Infinity;
  return assert$5(n >= 0), assert$5(r >= n), Array.isArray(e) && e.length >= n && e.length <= r && e.every(e => typeof e === t);
}

function assertPositiveInteger$1(e, t) {
  Array.isArray(e) ? (assert$6(e.length > 0, () => "".concat(t, " is unexpectedly an empty array.")), e.forEach((e, n) => assertPositiveInteger$1(e, "element ".concat(n + 1, " of ").concat(t)))) : assert$6(Number.isInteger(e) && e > 0, () => "Expected ".concat(t, " to be a positive integer, but got ").concat(formatAsFriendlyString$1(e), "."));
}

function formatAsFriendlyString$1(e) {
  return null === e ? "null" : Array.isArray(e) ? "[" + e.map(e => formatAsFriendlyString$1(e)).join(",") + "]" : "string" == typeof e ? "\"".concat(e, "\"") : "".concat(e);
}

function debounce$1(e, t) {
  var n,
      r = now$1();
  return function () {
    var s = now$1();
    return s - r < t || (r = s, n = e(...arguments)), n;
  };
}

function mapActivationToFusedKernel$1(e) {
  return "relu" === e ? "relu" : "linear" === e ? "linear" : "elu" === e ? "elu" : null;
}

function calcL2Norms$1(e, t) {
  return tidy$1(() => sqrt$5(sum$6(mul$1(e, e), t, !0)));
}

class Constraint$1 extends Serializable$1 {
  getConfig() {
    return {};
  }

}

class MaxNorm$1 extends Constraint$1 {
  constructor(e) {
    super(), this.defaultMaxValue = 2, this.defaultAxis = 0, this.maxValue = null != e.maxValue ? e.maxValue : this.defaultMaxValue, this.axis = null != e.axis ? e.axis : this.defaultAxis;
  }

  apply(e) {
    return tidy$1(() => {
      var t = calcL2Norms$1(e, this.axis),
          n = clipByValue$3(t, 0, this.maxValue);
      return mul$1(e, div$3(n, add$5(epsilon$3(), t)));
    });
  }

  getConfig() {
    return {
      maxValue: this.maxValue,
      axis: this.axis
    };
  }

}

MaxNorm$1.className = "MaxNorm", registerClass$1(MaxNorm$1);

class UnitNorm$1 extends Constraint$1 {
  constructor(e) {
    super(), this.defaultAxis = 0, this.axis = null != e.axis ? e.axis : this.defaultAxis;
  }

  apply(e) {
    return tidy$1(() => div$3(e, add$5(epsilon$3(), calcL2Norms$1(e, this.axis))));
  }

  getConfig() {
    return {
      axis: this.axis
    };
  }

}

UnitNorm$1.className = "UnitNorm", registerClass$1(UnitNorm$1);

class NonNeg$1 extends Constraint$1 {
  apply(e) {
    return relu$6(e);
  }

}

NonNeg$1.className = "NonNeg", registerClass$1(NonNeg$1);

class MinMaxNorm$1 extends Constraint$1 {
  constructor(e) {
    super(), this.defaultMinValue = 0, this.defaultMaxValue = 1, this.defaultRate = 1, this.defaultAxis = 0, this.minValue = null != e.minValue ? e.minValue : this.defaultMinValue, this.maxValue = null != e.maxValue ? e.maxValue : this.defaultMaxValue, this.rate = null != e.rate ? e.rate : this.defaultRate, this.axis = null != e.axis ? e.axis : this.defaultAxis;
  }

  apply(e) {
    return tidy$1(() => {
      var t = calcL2Norms$1(e, this.axis),
          n = add$5(mul$1(this.rate, clipByValue$3(t, this.minValue, this.maxValue)), mul$1(1 - this.rate, t));
      return mul$1(e, div$3(n, add$5(epsilon$3(), t)));
    });
  }

  getConfig() {
    return {
      minValue: this.minValue,
      maxValue: this.maxValue,
      rate: this.rate,
      axis: this.axis
    };
  }

}

MinMaxNorm$1.className = "MinMaxNorm", registerClass$1(MinMaxNorm$1);
var CONSTRAINT_IDENTIFIER_REGISTRY_SYMBOL_MAP$1 = {
  maxNorm: "MaxNorm",
  minMaxNorm: "MinMaxNorm",
  nonNeg: "NonNeg",
  unitNorm: "UnitNorm"
};

function serializeConstraint$1(e) {
  return serializeKerasObject$1(e);
}

function deserializeConstraint$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};
  return deserializeKerasObject$1(e, SerializationMap$1.getMap().classNameMap, t, "constraint");
}

function getConstraint$1(e) {
  return null == e ? null : "string" == typeof e ? deserializeConstraint$1({
    className: e in CONSTRAINT_IDENTIFIER_REGISTRY_SYMBOL_MAP$1 ? CONSTRAINT_IDENTIFIER_REGISTRY_SYMBOL_MAP$1[e] : e,
    config: {}
  }) : e instanceof Constraint$1 ? e : deserializeConstraint$1(e);
}

var VALID_DATA_FORMAT_VALUES$1 = ["channelsFirst", "channelsLast"],
    VALID_INTERPOLATION_FORMAT_VALUES$1 = ["nearest", "bilinear"],
    VALID_PADDING_MODE_VALUES$1 = ["valid", "same", "causal"],
    VALID_POOL_MODE_VALUES$1 = ["max", "avg"],
    VALID_BIDIRECTIONAL_MERGE_MODES$1 = ["sum", "mul", "concat", "ave"],
    nameMap$1 = new Map();

function checkDataFormat$1(e) {
  checkStringTypeUnionValue$1(VALID_DATA_FORMAT_VALUES$1, "DataFormat", e);
}

function checkInterpolationFormat$1(e) {
  checkStringTypeUnionValue$1(VALID_INTERPOLATION_FORMAT_VALUES$1, "InterpolationFormat", e);
}

function checkPaddingMode$1(e) {
  checkStringTypeUnionValue$1(VALID_PADDING_MODE_VALUES$1, "PaddingMode", e);
}

function checkPoolMode$1(e) {
  checkStringTypeUnionValue$1(VALID_POOL_MODE_VALUES$1, "PoolMode", e);
}

var _nameScopeStack$1 = [],
    _nameScopeDivider$1 = "/";

function nameScope$1(e, t) {
  _nameScopeStack$1.push(e);

  try {
    var _e94 = t();

    return _nameScopeStack$1.pop(), _e94;
  } catch (e) {
    throw _nameScopeStack$1.pop(), e;
  }
}

function currentNameScopePrefix$1() {
  return 0 === _nameScopeStack$1.length ? "" : _nameScopeStack$1.join(_nameScopeDivider$1) + _nameScopeDivider$1;
}

function getScopedTensorName$1(e) {
  if (!isValidTensorName$1(e)) throw new Error("Not a valid tensor name: '" + e + "'");
  return currentNameScopePrefix$1() + e;
}

function getUniqueTensorName$1(e) {
  if (!isValidTensorName$1(e)) throw new Error("Not a valid tensor name: '" + e + "'");
  nameMap$1.has(e) || nameMap$1.set(e, 0);
  var t = nameMap$1.get(e);

  if (nameMap$1.set(e, nameMap$1.get(e) + 1), t > 0) {
    var n = "".concat(e, "_").concat(t);
    return nameMap$1.set(n, 1), n;
  }

  return e;
}

var tensorNameRegex$1 = new RegExp(/^[A-Za-z0-9][-A-Za-z0-9\._\/]*$/);

function isValidTensorName$1(e) {
  return !!e.match(tensorNameRegex$1);
}

function isInteger$1(e) {
  return e === parseInt(e.toString(), 10);
}

function arrayProd$1(e, t, n) {
  null == t && (t = 0), null == n && (n = e.length);
  var r = 1;

  for (var a = t; a < n; ++a) {
    r *= e[a];
  }

  return r;
}

function min$6(e) {
  if (0 === e.length) return Number.NaN;
  var t = Number.POSITIVE_INFINITY;

  for (var n = 0; n < e.length; n++) {
    var r = e[n];
    r < t && (t = r);
  }

  return t;
}

function max$6(e) {
  if (0 === e.length) return Number.NaN;
  var t = Number.NEGATIVE_INFINITY;

  for (var n = 0; n < e.length; n++) {
    var r = e[n];
    r > t && (t = r);
  }

  return t;
}

function range$7(e, t) {
  if (t < e) throw new ValueError$1("end (".concat(t, ") < begin (").concat(e, ") is forbidden."));
  var n = [];

  for (var r = e; r < t; ++r) {
    n.push(r);
  }

  return n;
}

function cast$6(e, t) {
  return cast$7(e, t);
}

function expandDims$6(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : -1;
  var n = e.shape.slice();
  return t < 0 && (t = n.length + t + 1), n.splice(t, 0, 1), reshape$6(e, n);
}

function repeat$2(e, t) {
  return tidy$1(() => {
    if (2 !== e.shape.length) throw new ValueError$1("repeat() expects a rank-2 tensor, but received a rank-".concat(e.shape.length, " tensor."));
    return tile$6(expandDims$6(e, 1), [1, t, 1]);
  });
}

function flatten$5(e) {
  var t = [arrayProd$1(e.shape)];
  return reshape$6(e, t);
}

function batchFlatten$1(e) {
  if (e.rank <= 1) throw new ValueError$1("batchFlatten requires a minimum rank of 2. Got rank: ".concat(e.rank, "."));
  var t = [e.shape[0], arrayProd$1(e.shape, 1)];
  return reshape$6(e, t);
}

function sliceAlongFirstAxis$1(e, t, n) {
  return tidy$1(() => {
    switch (e.rank) {
      case 1:
        return slice1d$1(e, t, n);

      case 2:
        return slice2d$1(e, [t, 0], [n, e.shape[1]]);

      case 3:
        return slice3d$1(e, [t, 0, 0], [n, e.shape[1], e.shape[2]]);

      case 4:
        return slice4d$1(e, [t, 0, 0, 0], [n, e.shape[1], e.shape[2], e.shape[3]]);

      case 5:
        return slice$5(e, [t, 0, 0, 0, 0], [n, e.shape[1], e.shape[2], e.shape[3], e.shape[4]]);

      case 6:
        return slice$5(e, [t, 0, 0, 0, 0, 0], [n, e.shape[1], e.shape[2], e.shape[3], e.shape[4], e.shape[5]]);

      default:
        throw new ValueError$1("sliceAlongFirstAxis() received an unsupported tensor rank: ".concat(e.rank));
    }
  });
}

function sliceAlongLastAxis$1(e, t, n) {
  return tidy$1(() => {
    switch (e.rank) {
      case 1:
        return slice1d$1(e, t, n);

      case 2:
        return slice2d$1(e, [0, t], [e.shape[0], n]);

      case 3:
        return slice3d$1(e, [0, 0, t], [e.shape[0], e.shape[1], n]);

      case 4:
        return slice4d$1(e, [0, 0, 0, t], [e.shape[0], e.shape[1], e.shape[2], n]);

      default:
        throw new ValueError$1("sliceAlongLastAxis() received an unsupported tensor rank: ".concat(e.rank));
    }
  });
}

function sliceAlongAxis$1(e, t, n, r) {
  return tidy$1(() => {
    switch (e.rank) {
      case 1:
        return slice1d$1(e, t, n);

      case 2:
        switch (r) {
          case 1:
            return sliceAlongFirstAxis$1(e, t, n);

          case 2:
            return sliceAlongLastAxis$1(e, t, n);

          default:
            throw new ValueError$1("The axis is not within the rank of the tensor ".concat(r));
        }

      case 3:
        switch (r) {
          case 1:
            return sliceAlongFirstAxis$1(e, t, n);

          case 2:
            return slice3d$1(e, [0, t, 0], [e.shape[0], n, e.shape[2]]);

          case 3:
            return sliceAlongLastAxis$1(e, t, n);

          default:
            throw new ValueError$1("The axis is not within the rank of the tensor ".concat(r));
        }

      case 4:
        switch (r) {
          case 1:
            return sliceAlongFirstAxis$1(e, t, n);

          case 2:
            return slice4d$1(e, [0, t, 0, 0], [e.shape[0], n, e.shape[2], e.shape[3]]);

          case 3:
            return slice4d$1(e, [0, 0, t, 0], [e.shape[0], e.shape[1], n, e.shape[3]]);

          case 4:
            return sliceAlongLastAxis$1(e, t, n);

          default:
            throw new ValueError$1("The axis is not within the rank of the tensor ".concat(r));
        }

      default:
        throw new ValueError$1("sliceAlongLastAxis() received an unsupported tensor rank: ".concat(e.rank));
    }
  });
}

function concatenate$2(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : -1;
  var n;
  return t < 0 && (n = e[0].rank, t = 0 !== n ? n : 0), t === e[0].rank && (t = -1), concat$5(e, t);
}

function concatAlongFirstAxis$1(e, t) {
  switch (e.rank) {
    case 1:
      return concat1d$1([e, t]);

    case 2:
      return concat2d$1([e, t], 0);

    case 3:
      return concat3d$1([e, t], 0);

    case 4:
      return concat4d$1([e, t], 0);

    default:
      throw new ValueError$1("concatAlongFirstAxis() received an unsupported tensor rank: ".concat(e.rank));
  }
}

function tile$6(e, t) {
  if (Array.isArray(t) || (t = [t]), e.rank !== t.length) throw new ValueError$1("The length of input n (".concat(t.length, ") does not match the number of dimensions in input x (").concat(e.rank, ")"));
  return tile$7(e, t);
}

function randomNormal$3(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 1;
  var r = arguments.length > 3 ? arguments[3] : undefined;
  var a = arguments.length > 4 ? arguments[4] : undefined;
  return randomNormal$4(e, t, n, r, a);
}

function dot$3(e, t, n, r) {
  if (e.rank < 2 || t.rank < 2) throw new NotImplementedError$1("dot requires both inputs to be rank >= 2 but got x shape = ".concat(e.shape, " and y shape = ").concat(t.shape));
  if (t.rank >= 3 && e.shape.slice(-1)[0] !== t.shape.slice(-2)[0]) throw new NotImplementedError$1("If rank y >= 3, then the second last dim of y must equal the last dim of x but got x shape = ".concat(e.shape, " and  y shape = ").concat(t.shape));
  if (2 === e.rank && 2 === t.rank) return matMul$2({
    a: e,
    b: t,
    transposeA: !1,
    transposeB: !1,
    bias: r ? reshapeBias$1(e.rank, r, imageDataFormat$1()) : null,
    activation: n
  });
  {
    var a = e.shape.slice(),
        s = a.pop();
    e = reshape$6(e, [-1, s]);
    var o = t.shape.slice(),
        i = o.pop(),
        l = o.pop(),
        u = [...o, i],
        c = Array.from({
      length: t.rank
    }, (e, n) => 0 === n ? t.rank - 2 : n <= t.rank - 2 ? n - 1 : n);
    t = reshape$6(transpose$5(t, c), [l, -1]);
    var _p5 = [...a, ...u];
    return reshape$6(matMul$2({
      a: e,
      b: t,
      transposeA: !1,
      transposeB: !1,
      bias: r ? reshapeBias$1(e.rank, r, imageDataFormat$1()) : null,
      activation: n
    }), _p5);
  }
}

function gather$2(e, t, n) {
  return tidy$1(() => (t = Array.isArray(t) ? tensor1d$1(t, "int32") : cast$7(t, "int32"), gather$3(e, t, n)));
}

function square$4(e) {
  return mul$1(e, e);
}

function reshapeBias$1(e, t, n) {
  var r = t.shape;
  if (1 !== t.rank && t.rank !== e) throw new ValueError$1("Unexpected bias dimensions: ".concat(t.rank, "; expected it to be 1 or ").concat(e));

  if (5 === e) {
    if ("channelsFirst" === n) return reshape$6(t, 1 === r.length ? [1, r[0], 1, 1, 1] : [1, r[3], r[0], r[1], r[2]]);
    if ("channelsLast" === n) return reshape$6(t, 1 === r.length ? [1, 1, 1, 1, r[0]] : [1].concat(r));
  } else if (4 === e) {
    if ("channelsFirst" === n) return reshape$6(t, 1 === r.length ? [1, r[0], 1, 1] : [1, r[2], r[0], r[1]]);
    if ("channelsLast" === n) return reshape$6(t, 1 === r.length ? [1, 1, 1, r[0]] : [1].concat(r));
  } else if (3 === e) {
    if ("channelsFirst" === n) return reshape$6(t, 1 === r.length ? [1, r[0], 1] : [1, r[1], r[0]]);
    if ("channelsLast" === n) return reshape$6(t, 1 === r.length ? [1, 1, r[0]] : [1].concat(r));
  } else if (e < 3) return t;

  throw new ValueError$1("Unsupported input rank by biasAdd: ".concat(t.rank));
}

function biasAdd$1(e, t, n) {
  return tidy$1(() => (null == n && (n = imageDataFormat$1()), checkDataFormat$1(n), add$5(e, reshapeBias$1(e.rank, t, n))));
}

function elu$7(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 1;
  if (1 !== t) throw new NotImplementedError$1("Support for alpha values other than 1 (".concat(t, ") is not implemented yet."));
  return elu$8(e);
}

function softsign$1(e) {
  return tidy$1(() => div$3(e, add$5(abs$5(e), 1)));
}

function dropout$4(e, t, n, r) {
  return tidy$1(() => dropout$5(e, t, n, r));
}

function hardSigmoid$1(e) {
  return tidy$1(() => {
    var t = add$5(.5, mul$1(.2, e));
    return clipByValue$3(t, 0, 1);
  });
}

function inTrainPhase$1(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  return n ? e() : t();
}

var VALID_FAN_MODE_VALUES$1 = ["fanIn", "fanOut", "fanAvg"],
    VALID_DISTRIBUTION_VALUES$1 = ["normal", "uniform", "truncatedNormal"];

function checkFanMode$1(e) {
  checkStringTypeUnionValue$1(VALID_FAN_MODE_VALUES$1, "FanMode", e);
}

function checkDistribution$1(e) {
  checkStringTypeUnionValue$1(VALID_DISTRIBUTION_VALUES$1, "Distribution", e);
}

class Initializer$1 extends Serializable$1 {
  fromConfigUsesCustomObjects() {
    return !1;
  }

  getConfig() {
    return {};
  }

}

class Zeros$1 extends Initializer$1 {
  apply(e, t) {
    return zeros$4(e, t);
  }

}

Zeros$1.className = "Zeros", registerClass$1(Zeros$1);

class Ones$1 extends Initializer$1 {
  apply(e, t) {
    return ones$3(e, t);
  }

}

Ones$1.className = "Ones", registerClass$1(Ones$1);

class Constant$1 extends Initializer$1 {
  constructor(e) {
    if (super(), "object" != typeof e) throw new ValueError$1("Expected argument of type ConstantConfig but got ".concat(e));
    if (void 0 === e.value) throw new ValueError$1("config must have value set but got ".concat(e));
    this.value = e.value;
  }

  apply(e, t) {
    return tidy$1(() => mul$1(scalar$1(this.value), ones$3(e, t)));
  }

  getConfig() {
    return {
      value: this.value
    };
  }

}

Constant$1.className = "Constant", registerClass$1(Constant$1);

class RandomUniform$1 extends Initializer$1 {
  constructor(e) {
    super(), this.DEFAULT_MINVAL = -.05, this.DEFAULT_MAXVAL = .05, this.minval = e.minval || this.DEFAULT_MINVAL, this.maxval = e.maxval || this.DEFAULT_MAXVAL, this.seed = e.seed;
  }

  apply(e, t) {
    return randomUniform$2(e, this.minval, this.maxval, t);
  }

  getConfig() {
    return {
      minval: this.minval,
      maxval: this.maxval,
      seed: this.seed
    };
  }

}

RandomUniform$1.className = "RandomUniform", registerClass$1(RandomUniform$1);

class RandomNormal$1 extends Initializer$1 {
  constructor(e) {
    super(), this.DEFAULT_MEAN = 0, this.DEFAULT_STDDEV = .05, this.mean = e.mean || this.DEFAULT_MEAN, this.stddev = e.stddev || this.DEFAULT_STDDEV, this.seed = e.seed;
  }

  apply(e, t) {
    if ("float32" !== (t = t || "float32") && "int32" !== t) throw new NotImplementedError$1("randomNormal does not support dType ".concat(t, "."));
    return randomNormal$3(e, this.mean, this.stddev, t, this.seed);
  }

  getConfig() {
    return {
      mean: this.mean,
      stddev: this.stddev,
      seed: this.seed
    };
  }

}

RandomNormal$1.className = "RandomNormal", registerClass$1(RandomNormal$1);

class TruncatedNormal$1 extends Initializer$1 {
  constructor(e) {
    super(), this.DEFAULT_MEAN = 0, this.DEFAULT_STDDEV = .05, this.mean = e.mean || this.DEFAULT_MEAN, this.stddev = e.stddev || this.DEFAULT_STDDEV, this.seed = e.seed;
  }

  apply(e, t) {
    if ("float32" !== (t = t || "float32") && "int32" !== t) throw new NotImplementedError$1("truncatedNormal does not support dType ".concat(t, "."));
    return truncatedNormal$2(e, this.mean, this.stddev, t, this.seed);
  }

  getConfig() {
    return {
      mean: this.mean,
      stddev: this.stddev,
      seed: this.seed
    };
  }

}

TruncatedNormal$1.className = "TruncatedNormal", registerClass$1(TruncatedNormal$1);

class Identity$2 extends Initializer$1 {
  constructor(e) {
    super(), this.gain = null != e.gain ? e.gain : 1;
  }

  apply(e, t) {
    return tidy$1(() => {
      if (2 !== e.length || e[0] !== e[1]) throw new ValueError$1("Identity matrix initializer can only be used for 2D square matrices.");
      return mul$1(this.gain, eye$1(e[0]));
    });
  }

  getConfig() {
    return {
      gain: this.gain
    };
  }

}

function computeFans$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : "channelsLast";
  var n, r;
  if (checkDataFormat$1(t), 2 === e.length) n = e[0], r = e[1];else if (-1 !== [3, 4, 5].indexOf(e.length)) {
    if ("channelsFirst" === t) {
      var _t81 = arrayProd$1(e, 2);

      n = e[1] * _t81, r = e[0] * _t81;
    } else if ("channelsLast" === t) {
      var _t82 = arrayProd$1(e, 0, e.length - 2);

      n = e[e.length - 2] * _t82, r = e[e.length - 1] * _t82;
    }
  } else {
    var _t83 = arrayProd$1(e);

    n = Math.sqrt(_t83), r = Math.sqrt(_t83);
  }
  return [n, r];
}

Identity$2.className = "Identity", registerClass$1(Identity$2);

class VarianceScaling$1 extends Initializer$1 {
  constructor(e) {
    if (super(), e.scale < 0) throw new ValueError$1("scale must be a positive float. Got: ".concat(e.scale));
    this.scale = null == e.scale ? 1 : e.scale, this.mode = null == e.mode ? "fanIn" : e.mode, checkFanMode$1(this.mode), this.distribution = null == e.distribution ? "normal" : e.distribution, checkDistribution$1(this.distribution), this.seed = e.seed;
  }

  apply(e, t) {
    var n = computeFans$1(e),
        r = n[0],
        a = n[1];
    var s = this.scale;

    if (s /= "fanIn" === this.mode ? Math.max(1, r) : "fanOut" === this.mode ? Math.max(1, a) : Math.max(1, (r + a) / 2), "normal" === this.distribution) {
      var _n32 = Math.sqrt(s);

      if ("float32" !== (t = t || "float32") && "int32" !== t) throw new NotImplementedError$1("".concat(this.getClassName(), " does not support dType ").concat(t, "."));
      return truncatedNormal$2(e, 0, _n32, t, this.seed);
    }

    {
      var _n33 = Math.sqrt(3 * s);

      return randomUniform$2(e, -_n33, _n33, t);
    }
  }

  getConfig() {
    return {
      scale: this.scale,
      mode: this.mode,
      distribution: this.distribution,
      seed: this.seed
    };
  }

}

VarianceScaling$1.className = "VarianceScaling", registerClass$1(VarianceScaling$1);

class GlorotUniform$1 extends VarianceScaling$1 {
  constructor(e) {
    super({
      scale: 1,
      mode: "fanAvg",
      distribution: "uniform",
      seed: null == e ? null : e.seed
    });
  }

  getClassName() {
    return VarianceScaling$1.className;
  }

}

GlorotUniform$1.className = "GlorotUniform", registerClass$1(GlorotUniform$1);

class GlorotNormal$1 extends VarianceScaling$1 {
  constructor(e) {
    super({
      scale: 1,
      mode: "fanAvg",
      distribution: "normal",
      seed: null == e ? null : e.seed
    });
  }

  getClassName() {
    return VarianceScaling$1.className;
  }

}

GlorotNormal$1.className = "GlorotNormal", registerClass$1(GlorotNormal$1);

class HeNormal$1 extends VarianceScaling$1 {
  constructor(e) {
    super({
      scale: 2,
      mode: "fanIn",
      distribution: "normal",
      seed: null == e ? null : e.seed
    });
  }

  getClassName() {
    return VarianceScaling$1.className;
  }

}

HeNormal$1.className = "HeNormal", registerClass$1(HeNormal$1);

class HeUniform$1 extends VarianceScaling$1 {
  constructor(e) {
    super({
      scale: 2,
      mode: "fanIn",
      distribution: "uniform",
      seed: null == e ? null : e.seed
    });
  }

  getClassName() {
    return VarianceScaling$1.className;
  }

}

HeUniform$1.className = "HeUniform", registerClass$1(HeUniform$1);

class LeCunNormal$1 extends VarianceScaling$1 {
  constructor(e) {
    super({
      scale: 1,
      mode: "fanIn",
      distribution: "normal",
      seed: null == e ? null : e.seed
    });
  }

  getClassName() {
    return VarianceScaling$1.className;
  }

}

LeCunNormal$1.className = "LeCunNormal", registerClass$1(LeCunNormal$1);

class LeCunUniform$1 extends VarianceScaling$1 {
  constructor(e) {
    super({
      scale: 1,
      mode: "fanIn",
      distribution: "uniform",
      seed: null == e ? null : e.seed
    });
  }

  getClassName() {
    return VarianceScaling$1.className;
  }

}

LeCunUniform$1.className = "LeCunNormal", registerClass$1(LeCunUniform$1);

class Orthogonal$1 extends Initializer$1 {
  constructor(e) {
    if (super(), this.DEFAULT_GAIN = 1, this.gain = null == e.gain ? this.DEFAULT_GAIN : e.gain, this.seed = e.seed, null != this.seed) throw new NotImplementedError$1("Random seed is not implemented for Orthogonal Initializer yet.");
  }

  apply(e, t) {
    return tidy$1(() => {
      if (e.length < 2) throw new NotImplementedError$1("Shape must be at least 2D.");
      e[0] * e[1] > 2e3 && console.warn("Orthogonal initializer is being called on a matrix with more than 2000 (".concat(e[0] * e[1], ") elements: Slowness may result."));
      var t = randomNormal$3(e[0] > e[1] ? [e[1], e[0]] : e, 0, 1, "float32");
      var n = linalg$1.gramSchmidt(t);
      return e[0] > e[1] && (n = transpose$5(n)), mul$1(this.gain, n);
    });
  }

  getConfig() {
    return {
      gain: this.gain,
      seed: this.seed
    };
  }

}

Orthogonal$1.className = "Orthogonal", registerClass$1(Orthogonal$1);
var INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP$1 = {
  constant: "Constant",
  glorotNormal: "GlorotNormal",
  glorotUniform: "GlorotUniform",
  heNormal: "HeNormal",
  heUniform: "HeUniform",
  identity: "Identity",
  leCunNormal: "LeCunNormal",
  leCunUniform: "LeCunUniform",
  ones: "Ones",
  orthogonal: "Orthogonal",
  randomNormal: "RandomNormal",
  randomUniform: "RandomUniform",
  truncatedNormal: "TruncatedNormal",
  varianceScaling: "VarianceScaling",
  zeros: "Zeros"
};

function deserializeInitializer$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};
  return deserializeKerasObject$1(e, SerializationMap$1.getMap().classNameMap, t, "initializer");
}

function serializeInitializer$1(e) {
  return serializeKerasObject$1(e);
}

function getInitializer$1(e) {
  if ("string" == typeof e) {
    var t = e in INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP$1 ? INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP$1[e] : e;
    if ("GlorotNormal" === t) return new GlorotNormal$1();
    if ("GlorotUniform" === t) return new GlorotUniform$1();
    if ("HeNormal" === t) return new HeNormal$1();
    if ("HeUniform" === t) return new HeUniform$1();
    if ("LeCunNormal" === t) return new LeCunNormal$1();
    if ("LeCunUniform" === t) return new LeCunUniform$1();
    {
      var _e95 = {};
      return _e95.className = t, _e95.config = {}, deserializeInitializer$1(_e95);
    }
  }

  return e instanceof Initializer$1 ? e : deserializeInitializer$1(e);
}

var _nextUniqueTensorId$1 = 0;

function getNextUniqueTensorId$1() {
  return _nextUniqueTensorId$1++;
}

var _uidPrefixes$1 = {};

function getUid$1() {
  var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : "";
  return e in _uidPrefixes$1 || (_uidPrefixes$1[e] = 0), _uidPrefixes$1[e] += 1, e + _uidPrefixes$1[e].toString();
}

function isArrayOfShapes$1(e) {
  return Array.isArray(e) && Array.isArray(e[0]);
}

function normalizeShapeList$1(e) {
  return 0 === e.length ? [] : Array.isArray(e[0]) ? e : [e];
}

function getExactlyOneTensor$1(e) {
  var t;

  if (Array.isArray(e)) {
    if (1 !== e.length) throw new ValueError$1("Expected Tensor length to be 1; got ".concat(e.length));
    t = e[0];
  } else t = e;

  return t;
}

function getExactlyOneShape$1(e) {
  if (Array.isArray(e) && Array.isArray(e[0])) {
    if (1 === e.length) return (e = e)[0];
    throw new ValueError$1("Expected exactly 1 Shape; got ".concat(e.length));
  }

  return e;
}

function countParamsInWeights$1(e) {
  var t = 0;

  for (var n of e) {
    t += 0 === n.shape.length ? 1 : n.shape.reduce((e, t) => e * t);
  }

  return t;
}

var DEFAULT_VARIABLE_NAME_PREFIX$1 = "Variable";

class LayerVariable$1 {
  constructor(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : "float32";
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : DEFAULT_VARIABLE_NAME_PREFIX$1;
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !0;
    var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : null;
    this.dtype = null == t ? "float32" : t, this.shape = e.shape, this.id = getNextUniqueTensorId$1(), this.originalName = getScopedTensorName$1(n = null == n ? DEFAULT_VARIABLE_NAME_PREFIX$1 : n), this.name = getUniqueTensorName$1(this.originalName), this.trainable_ = r, this.constraint = a, this.val = variable$1(e, this.trainable_, this.name, this.dtype);
  }

  read() {
    return this.assertNotDisposed(), this.val;
  }

  write(e) {
    return this.assertNotDisposed(), checkShapesMatch$1(this.val, e), this.val.id !== e.id && (this.val.assign(e), null != this.constraint && this.val.assign(this.constraint.apply(this.val))), this;
  }

  dispose() {
    this.assertNotDisposed(), this.val.dispose();
  }

  assertNotDisposed() {
    if (this.val.isDisposed) throw new Error("LayersVariable ".concat(this.name, " is already disposed."));
  }

  get trainable() {
    return this.trainable_;
  }

  set trainable(e) {
    this.trainable_ = e, this.val.trainable = e;
  }

}

function checkShapesMatch$1(e, t) {
  if (e.shape.toString() !== t.shape.toString()) throw new Error("Shape mismatch: " + JSON.stringify(e.shape) + " vs. " + JSON.stringify(t.shape));
}

function batchGetValue$1(e) {
  return e.map(e => e.read());
}

function batchSetValue$1(e) {
  e.forEach(e => {
    e[0].write(e[1]);
  });
}

class InputSpec$1 {
  constructor(e) {
    this.dtype = e.dtype, this.shape = e.shape, this.ndim = null != e.shape ? e.shape.length : e.ndim, this.maxNDim = e.maxNDim, this.minNDim = e.minNDim, this.axes = e.axes || {};
  }

}

class SymbolicTensor$1 {
  constructor(e, t, n, r, a, s, o) {
    this.dtype = e, this.shape = t, this.sourceLayer = n, this.inputs = r, this.callArgs = a, this.outputTensorIndex = o, this.id = getNextUniqueTensorId$1(), null != s && (this.originalName = getScopedTensorName$1(s), this.name = getUniqueTensorName$1(this.originalName)), this.rank = t.length;
  }

}

var _nextNodeID$1 = 0;

class Node$1 {
  constructor(e, t) {
    this.callArgs = t, this.id = _nextNodeID$1++, this.outboundLayer = e.outboundLayer, this.inboundLayers = e.inboundLayers, this.nodeIndices = e.nodeIndices, this.tensorIndices = e.tensorIndices, this.inputTensors = e.inputTensors, this.outputTensors = e.outputTensors, this.inputMasks = e.inputMasks, this.outputMasks = e.outputMasks, this.inputShapes = e.inputShapes, this.outputShapes = e.outputShapes;

    for (var _t84 of e.inboundLayers) {
      null != _t84 && _t84.outboundNodes.push(this);
    }

    e.outboundLayer.inboundNodes.push(this);
  }

  getConfig() {
    var e = [];

    for (var t of this.inboundLayers) {
      e.push(null != t ? t.name : null);
    }

    return {
      outboundLayer: this.outboundLayer ? this.outboundLayer.name : null,
      inboundLayers: e,
      nodeIndices: this.nodeIndices,
      tensorIndices: this.tensorIndices
    };
  }

}

var _nextLayerID$1 = 0;

class Layer$1 extends Serializable$1 {
  constructor() {
    var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};
    super(), this._callHook = null, this._addedWeightNames = [], this._stateful = !1, this.id = _nextLayerID$1++, this.activityRegularizer = null, this.inputSpec = null, this.supportsMasking = !1, this._trainableWeights = [], this._nonTrainableWeights = [], this._losses = [], this._updates = [], this._built = !1, this.inboundNodes = [], this.outboundNodes = [];
    var t = e.name;

    if (!t) {
      var _e96 = this.getClassName();

      t = toSnakeCase$1(_e96) + "_" + getUid$1(_e96);
    }

    if (this.name = t, this.trainable_ = null == e.trainable || e.trainable, null != e.inputShape || null != e.batchInputShape) {
      var _t85;

      if (null != e.batchInputShape) _t85 = e.batchInputShape;else if (null != e.inputShape) {
        var _n34 = null;
        null != e.batchSize && (_n34 = e.batchSize), _t85 = [_n34].concat(e.inputShape);
      }
      this.batchInputShape = _t85;
      var n = e.dtype;
      null == n && (n = e.inputDType), null == n && (n = "float32"), this.dtype = n;
    }

    this.initialWeights = null != e.weights ? e.weights : null, this._refCount = null, this.fastWeightInitDuringBuild = !1;
  }

  static nodeKey(e, t) {
    return e.name + "_ib-" + t.toString();
  }

  getNodeAtIndex(e, t) {
    if (0 === this.inboundNodes.length) throw new RuntimeError$1("The layer has never been called and thus has no defined ".concat(t, "."));
    if (this.inboundNodes.length <= e) throw new ValueError$1("Asked to get ".concat(t, " at node ").concat(e, ", but the layer has only ").concat(this.inboundNodes.length, " inbound nodes."));
    return this.inboundNodes[e];
  }

  getInputAt(e) {
    return singletonOrArray$1(this.getNodeAtIndex(e, "input").inputTensors);
  }

  getOutputAt(e) {
    return singletonOrArray$1(this.getNodeAtIndex(e, "output").outputTensors);
  }

  get input() {
    if (this.inboundNodes.length > 1) throw new AttributeError$1("Layer ".concat(this.name, " has multiple inbound nodes, hence the notion of \"layer input\" is ill-defined. Use `getInputAt(nodeIndex)` instead."));
    if (0 === this.inboundNodes.length) throw new AttributeError$1("Layer ".concat(this.name, " is not connected, no input to return."));
    return singletonOrArray$1(this.getNodeAtIndex(0, "input").inputTensors);
  }

  get output() {
    if (0 === this.inboundNodes.length) throw new AttributeError$1("Layer ".concat(this.name, " has no inbound nodes."));
    if (this.inboundNodes.length > 1) throw new AttributeError$1("Layer ".concat(this.name, " has multiple inbound nodes, hence the notion of \"layer output\" is ill-defined. Use `getOutputAt(nodeIndex)` instead."));
    return singletonOrArray$1(this.getNodeAtIndex(0, "output").outputTensors);
  }

  get losses() {
    return this._losses;
  }

  calculateLosses() {
    return this.losses.map(e => e());
  }

  get updates() {
    return this._updates;
  }

  get built() {
    return this._built;
  }

  set built(e) {
    this._built = e;
  }

  get trainable() {
    return this.trainable_;
  }

  set trainable(e) {
    this._trainableWeights.forEach(t => t.trainable = e), this.trainable_ = e;
  }

  get trainableWeights() {
    return this.trainable_ ? this._trainableWeights.filter(e => e.trainable) : [];
  }

  set trainableWeights(e) {
    this._trainableWeights = e;
  }

  get nonTrainableWeights() {
    return this.trainable ? this._trainableWeights.filter(e => !e.trainable).concat(this._nonTrainableWeights) : this._trainableWeights.concat(this._nonTrainableWeights);
  }

  set nonTrainableWeights(e) {
    this._nonTrainableWeights = e;
  }

  get weights() {
    return this.trainableWeights.concat(this.nonTrainableWeights);
  }

  get stateful() {
    return this._stateful;
  }

  resetStates() {
    if (!this.stateful) throw new Error("Cannot call the resetStates() method of a non-stateful Layer object.");
  }

  assertInputCompatibility(e) {
    if (e = toList$1(e), null == this.inputSpec || 0 === this.inputSpec.length) return;
    var t = toList$1(this.inputSpec);
    if (e.length !== t.length) throw new ValueError$1("Layer ".concat(this.name, " expects ").concat(t.length, " inputs, but it received ").concat(e.length, " input tensors. Input received: ").concat(e));

    for (var n = 0; n < e.length; n++) {
      var r = e[n],
          a = t[n];
      if (null == a) continue;
      var s = r.rank;
      if (null != a.ndim && s !== a.ndim) throw new ValueError$1("Input ".concat(n, " is incompatible with layer ").concat(this.name, ": expected ndim=").concat(a.ndim, ", found ndim=").concat(s));
      if (null != a.maxNDim && s > a.maxNDim) throw new ValueError$1("Input ".concat(n, " is incompatible with layer ").concat(this.name, ": expected max_ndim=").concat(a.maxNDim, ", found ndim=").concat(s));
      if (null != a.minNDim && s < a.minNDim) throw new ValueError$1("Input ".concat(n, " is incompatible with layer ").concat(this.name, ": expected min_ndim=").concat(a.minNDim, ", found ndim=").concat(s, "."));
      if (null != a.dtype && r.dtype !== a.dtype) throw new ValueError$1("Input ".concat(n, " is incompatible with layer ").concat(this.name, " : expected dtype=").concat(a.dtype, ", found dtype=").concat(r.dtype, "."));

      if (a.axes) {
        var _e97 = r.shape;

        for (var _t86 in a.axes) {
          var _r24 = Number(_t86),
              _s12 = a.axes[_t86],
              o = _r24 >= 0 ? _e97[_r24] : _e97[_e97.length + _r24];

          if (null != _s12 && -1 === [_s12, null].indexOf(o)) throw new ValueError$1("Input ".concat(n, " is incompatible with layer ").concat(this.name, ": expected axis ").concat(_r24, " of input shape to have value ").concat(_s12, " but got shape ").concat(_e97, "."));
        }
      }

      if (null != a.shape) for (var _e98 = 0; _e98 < a.shape.length; ++_e98) {
        var _t87 = a.shape[_e98],
            _s13 = r.shape[_e98];
        if (null != _t87 && null != _s13 && _t87 !== _s13) throw new ValueError$1("Input ".concat(n, " is incompatible with layer ").concat(this.name, ": expected shape=").concat(a.shape, ", found shape=").concat(r.shape, "."));
      }
    }
  }

  call(e, t) {
    return e;
  }

  invokeCallHook(e, t) {
    null != this._callHook && this._callHook(e, t);
  }

  setCallHook(e) {
    this._callHook = e;
  }

  clearCallHook() {
    this._callHook = null;
  }

  apply(e, t) {
    t = t || {}, this.assertNotDisposed();
    var n = toList$1(e);
    var r = !0;

    for (var _e99 of n) {
      if (!(_e99 instanceof SymbolicTensor$1)) {
        r = !1;
        break;
      }
    }

    var a = !0;

    for (var _e100 of n) {
      if (_e100 instanceof SymbolicTensor$1) {
        a = !1;
        break;
      }
    }

    if (r === a) throw new ValueError$1("Arguments to apply() must be all SymbolicTensors or all Tensors");
    return nameScope$1(this.name, () => {
      if (!this.built) {
        this.assertInputCompatibility(e);
        var _t88 = [];

        for (var _n35 of toList$1(e)) {
          _t88.push(_n35.shape);
        }

        this.build(singletonOrArray$1(_t88)), this.built = !0, this.initialWeights && this.setWeights(this.initialWeights), null === this._refCount && a && (this._refCount = 1);
      }

      if (this.assertInputCompatibility(e), a) {
        var _r25 = this.call(e, t);

        var _a25 = toList$1(_r25),
            s = [];

        for (var _e101 of _a25) {
          -1 !== n.indexOf(_e101) && (_e101 = _e101.clone()), s.push(_e101);
        }

        if (_r25 = singletonOrArray$1(s), null != this.activityRegularizer) throw new NotImplementedError$1("Layer invocation in the presence of activity regularizer(s) is not supported yet.");
        return _r25;
      }

      {
        var _n36 = collectInputShape$1(e),
            _r26 = this.computeOutputShape(_n36);

        var _a26;

        var _s14 = guessOutputDType$1(e);

        if (this.warnOnIncompatibleInputShape(Array.isArray(e) ? _n36[0] : _n36), _a26 = null != _r26 && _r26.length > 0 && Array.isArray(_r26[0]) ? _r26.map((n, r) => new SymbolicTensor$1(_s14, n, this, toList$1(e), t, this.name, r)) : new SymbolicTensor$1(_s14, _r26, this, toList$1(e), t, this.name), this.addInboundNode(e, _a26, null, null, _n36, _r26, t), this._refCount++, null != this.activityRegularizer) throw new NotImplementedError$1("Layer invocation in the presence of activity regularizer(s) is not supported yet.");
        return _a26;
      }
    });
  }

  warnOnIncompatibleInputShape(e) {
    if (null != this.batchInputShape) if (e.length !== this.batchInputShape.length) console.warn("The rank of the input tensor provided (shape: ".concat(JSON.stringify(e), ") does not match that of the batchInputShape (").concat(JSON.stringify(this.batchInputShape), ") of the layer ").concat(this.name));else {
      var t = !1;
      this.batchInputShape.forEach((n, r) => {
        null != n && null != e[r] && e[r] !== n && (t = !0);
      }), t && console.warn("The shape of the input tensor (".concat(JSON.stringify(e), ") does not match the expectation of layer ").concat(this.name, ": ").concat(JSON.stringify(this.batchInputShape)));
    }
  }

  get outputShape() {
    if (null == this.inboundNodes || 0 === this.inboundNodes.length) throw new AttributeError$1("The layer ".concat(this.name, " has never been called and thus has no defined output shape."));
    var e = [];

    for (var t of this.inboundNodes) {
      var n = JSON.stringify(t.outputShapes);
      -1 === e.indexOf(n) && e.push(n);
    }

    if (1 === e.length) {
      var _e102 = this.inboundNodes[0].outputShapes;
      return Array.isArray(_e102) && Array.isArray(_e102[0]) && 1 === _e102.length ? _e102[0] : _e102;
    }

    throw new AttributeError$1("The layer ".concat(this.name, " has multiple inbound nodes with different output shapes. Hence the notion of \"output shape\" is ill-defined for the layer."));
  }

  countParams() {
    if (!this.built) throw new RuntimeError$1("You tried to call countParams() on ".concat(this.name, ", but the layer is not built yet. Build it first by calling build(batchInputShape)."));
    return countParamsInWeights$1(this.weights);
  }

  build(e) {
    this.built = !0;
  }

  getWeights() {
    var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : !1;
    return batchGetValue$1(e ? this.trainableWeights : this.weights);
  }

  setWeights(e) {
    tidy$1(() => {
      var t = this.weights;
      if (t.length !== e.length) throw new ValueError$1("You called setWeights(weights) on layer \"".concat(this.name, "\" with a weight list of length ").concat(e.length, ", but the layer was expecting ").concat(t.length, " weights. Provided weights: ").concat(e, "..."));
      if (0 === t.length) return;
      var n = [],
          r = batchGetValue$1(t);

      for (var a = 0; a < r.length; ++a) {
        var s = r[a],
            o = t[a],
            i = e[a];
        if (!arraysEqual$1(s.shape, i.shape)) throw new ValueError$1("Layer weight shape ".concat(s.shape, " not compatible with provided weight shape ").concat(i.shape));
        n.push([o, i]);
      }

      batchSetValue$1(n);
    });
  }

  addWeight(e, t, n, r, a, s, o) {
    if (-1 !== this._addedWeightNames.indexOf(e)) throw new ValueError$1("Duplicate weight name ".concat(e, " for layer ").concat(this.name));
    this._addedWeightNames.push(e), null == n && (n = "float32"), this.fastWeightInitDuringBuild && (r = getInitializer$1("zeros"));
    var i = r.apply(t, n),
        l = new LayerVariable$1(i, n, e, s, o);
    return i.dispose(), null != a && this.addLoss(() => a.apply(l.read())), null == s && (s = !0), s ? this._trainableWeights.push(l) : this._nonTrainableWeights.push(l), l;
  }

  setFastWeightInitDuringBuild(e) {
    this.fastWeightInitDuringBuild = e;
  }

  addLoss(e) {
    null == e || Array.isArray(e) && 0 === e.length || (e = toList$1(e), null != this._losses && this.losses.push(...e));
  }

  computeOutputShape(e) {
    return e;
  }

  computeMask(e, t) {
    if (!this.supportsMasking) {
      if (null != t) {
        if (!Array.isArray(t)) throw new TypeError("Layer ".concat(this.name, " does not support masking, but was passed an inputMask."));
        t.forEach(e => {
          if (null != e) throw new TypeError("Layer ".concat(this.name, " does not support masking, but was passed an inputMask."));
        });
      }

      return null;
    }

    return t;
  }

  addInboundNode(e, t, n, r, a, s) {
    var o = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : null;
    var i = toList$1(e);
    t = toList$1(t), n = toList$1(n), r = toList$1(r), a = normalizeShapeList$1(a), s = normalizeShapeList$1(s);
    var l = [],
        u = [],
        c = [];

    for (var _e103 of i) {
      l.push(_e103.sourceLayer), u.push(_e103.nodeIndex), c.push(_e103.tensorIndex);
    }

    new Node$1({
      outboundLayer: this,
      inboundLayers: l,
      nodeIndices: u,
      tensorIndices: c,
      inputTensors: i,
      outputTensors: t,
      inputMasks: n,
      outputMasks: r,
      inputShapes: a,
      outputShapes: s
    }, o);

    for (var _e104 = 0; _e104 < t.length; _e104++) {
      t[_e104].sourceLayer = this, t[_e104].nodeIndex = this.inboundNodes.length - 1, t[_e104].tensorIndex = _e104;
    }
  }

  getConfig() {
    var e = {
      name: this.name,
      trainable: this.trainable
    };
    return null != this.batchInputShape && (e.batchInputShape = this.batchInputShape), null != this.dtype && (e.dtype = this.dtype), e;
  }

  disposeWeights() {
    return this.weights.forEach(e => e.dispose()), this.weights.length;
  }

  assertNotDisposed() {
    if (0 === this._refCount) throw new Error("Layer '".concat(this.name, "' is already disposed."));
  }

  dispose() {
    if (!this.built) throw new Error("Cannot dispose Layer ".concat(this.name, " because it has not been built yet."));
    if (null === this._refCount) throw new Error("Cannot dispose Layer ".concat(this.name, " because it has not been used yet."));
    this.assertNotDisposed();
    var e = 0;
    return 0 == --this._refCount && (e = this.disposeWeights()), {
      refCountAfterDispose: this._refCount,
      numDisposedVariables: e
    };
  }

}

function collectInputShape$1(e) {
  e = toList$1(e);
  var t = [];

  for (var n of e) {
    t.push(n.shape);
  }

  return singletonOrArray$1(t);
}

function guessOutputDType$1(e) {
  return "float32";
}

function getSourceInputs$1(e, t, n) {
  if ((null == t || null != n && n > 0) && (t = e.sourceLayer, n = e.nodeIndex), 0 === t.inboundNodes.length) return [e];
  {
    var _e105 = t.inboundNodes[n];
    if (0 === _e105.inboundLayers.length) return _e105.inputTensors;
    {
      var _t89 = [];

      for (var _n37 = 0; _n37 < _e105.inboundLayers.length; _n37++) {
        var r = getSourceInputs$1(_e105.inputTensors[_n37], _e105.inboundLayers[_n37], _e105.nodeIndices[_n37]);

        for (var _e106 of r) {
          -1 === _t89.indexOf(_e106) && _t89.push(_e106);
        }
      }

      return _t89;
    }
  }
}

class InputLayer$1 extends Layer$1 {
  constructor(e) {
    if (super({
      dtype: e.dtype,
      name: null != e.name ? e.name : getUid$1("input").toString()
    }), null == e.batchSize && (e.batchSize = null), null == e.sparse && (e.sparse = !1), this.trainable = !1, this.built = !0, this.sparse = e.sparse, null != e.inputShape && null != e.batchInputShape) throw new ValueError$1("Only provide the inputShape OR batchInputShape argument to inputLayer, not both at the same time.");
    var t = e.batchInputShape;

    if (null == t) {
      if (null == e.inputShape) throw new ValueError$1("An InputLayer should be passed either a `batchInputShape` or an `inputShape`.");
      t = [e.batchSize].concat(e.inputShape);
    } else if (null != e.batchSize) throw new ValueError$1("Cannot specify batchSize if batchInputShape is specified when creating an InputLayer.");

    var n = e.dtype || "float32";
    this.batchInputShape = t, this.dtype = n, this.inputSpec = [{
      shape: t
    }];
    var r = new SymbolicTensor$1(this.dtype, this.batchInputShape, this, [], {}, this.name);
    r.nodeIndex = 0, r.tensorIndex = 0, new Node$1({
      outboundLayer: this,
      inboundLayers: [],
      nodeIndices: [],
      tensorIndices: [],
      inputTensors: [r],
      outputTensors: [r],
      inputMasks: [null],
      outputMasks: [null],
      inputShapes: [t],
      outputShapes: [t]
    });
  }

  apply(e, t) {
    throw new ValueError$1("Cannot pass any input to an InputLayer's apply() method. InputLayer name: ".concat(this.name));
  }

  dispose() {
    return {
      refCountAfterDispose: this._refCount,
      numDisposedVariables: 0
    };
  }

  getConfig() {
    return {
      batchInputShape: this.batchInputShape,
      dtype: this.dtype,
      sparse: this.sparse,
      name: this.name
    };
  }

}

function Input$1(e) {
  if (null == e.batchShape && null == e.shape) throw new Error("Please provide to Input either a `shape` or a `batchShape` argument. Note that `shape` does not include the batch dimension.");
  if (null != e.batchShape && null != e.shape) throw new ValueError$1("Please provide either a `shape` or `batchShape` argument to Input, but not both.");
  var t = e.batchShape;
  null != e.shape && null == t && (t = [null].concat(e.shape));
  var n = e.dtype;
  return null == n && (n = "float32"), new InputLayer$1({
    batchInputShape: t,
    name: e.name,
    dtype: n,
    sparse: e.sparse
  }).inboundNodes[0].outputTensors[0];
}

function resolveScalarsInLogs$1(_x16) {
  return _resolveScalarsInLogs$.apply(this, arguments);
}

function _resolveScalarsInLogs$() {
  _resolveScalarsInLogs$ = _asyncToGenerator(function* (e) {
    if (null == e) return;
    var t = [],
        n = [],
        r = [];

    for (var a in e) {
      var s = e[a];

      if ("number" != typeof s) {
        var _e1139 = s;
        t.push(_e1139.data()), n.push(a), r.push(_e1139);
      }
    }

    if (t.length > 0) {
      var _a316 = yield Promise.all(t);

      for (var _t761 = 0; _t761 < _a316.length; ++_t761) {
        e[n[_t761]] = _a316[_t761][0];
      }

      dispose$1(r);
    }
  });
  return _resolveScalarsInLogs$.apply(this, arguments);
}

function disposeTensorsInLogs$1(e) {
  if (null != e) for (var t in e) {
    var n = e[t];
    "number" != typeof n && n.dispose();
  }
}

var ModelLoggingVerbosity$1;
InputLayer$1.className = "InputLayer", registerClass$1(InputLayer$1), function (e) {
  e[e.SILENT = 0] = "SILENT", e[e.VERBOSE = 1] = "VERBOSE";
}(ModelLoggingVerbosity$1 || (ModelLoggingVerbosity$1 = {}));
var DEFAULT_YIELD_EVERY_MS$1 = 125;

class BaseCallback$1 {
  constructor() {
    this.validationData = null;
  }

  setParams(e) {
    this.params = e;
  }

  onEpochBegin(e, t) {
    return _asyncToGenerator(function* () {})();
  }

  onEpochEnd(e, t) {
    return _asyncToGenerator(function* () {})();
  }

  onBatchBegin(e, t) {
    return _asyncToGenerator(function* () {})();
  }

  onBatchEnd(e, t) {
    return _asyncToGenerator(function* () {})();
  }

  onTrainBegin(e) {
    return _asyncToGenerator(function* () {})();
  }

  onTrainEnd(e) {
    return _asyncToGenerator(function* () {})();
  }

  setModel(e) {}

}

class CallbackList$1 {
  constructor(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 10;
    null == e && (e = []), this.callbacks = e, this.queueLength = t;
  }

  append(e) {
    this.callbacks.push(e);
  }

  setParams(e) {
    for (var t of this.callbacks) {
      t.setParams(e);
    }
  }

  setModel(e) {
    for (var t of this.callbacks) {
      t.setModel(e);
    }
  }

  onEpochBegin(e, t) {
    var _this38 = this;

    return _asyncToGenerator(function* () {
      null == t && (t = {});

      for (var n of _this38.callbacks) {
        yield n.onEpochBegin(e, t);
      }
    })();
  }

  onEpochEnd(e, t) {
    var _this39 = this;

    return _asyncToGenerator(function* () {
      null == t && (t = {});

      for (var n of _this39.callbacks) {
        yield n.onEpochEnd(e, t);
      }
    })();
  }

  onBatchBegin(e, t) {
    var _this40 = this;

    return _asyncToGenerator(function* () {
      null == t && (t = {});

      for (var n of _this40.callbacks) {
        yield n.onBatchBegin(e, t);
      }
    })();
  }

  onBatchEnd(e, t) {
    var _this41 = this;

    return _asyncToGenerator(function* () {
      null == t && (t = {});

      for (var n of _this41.callbacks) {
        yield n.onBatchEnd(e, t);
      }
    })();
  }

  onTrainBegin(e) {
    var _this42 = this;

    return _asyncToGenerator(function* () {
      null == e && (e = {});

      for (var t of _this42.callbacks) {
        yield t.onTrainBegin(e);
      }
    })();
  }

  onTrainEnd(e) {
    var _this43 = this;

    return _asyncToGenerator(function* () {
      null == e && (e = {});

      for (var t of _this43.callbacks) {
        yield t.onTrainEnd(e);
      }
    })();
  }

}

class BaseLogger$1 extends BaseCallback$1 {
  constructor() {
    super();
  }

  onEpochBegin(e) {
    var _this44 = this;

    return _asyncToGenerator(function* () {
      _this44.seen = 0, _this44.totals = {};
    })();
  }

  onBatchEnd(e, t) {
    var _this45 = this;

    return _asyncToGenerator(function* () {
      null == t && (t = {});
      var n = null == t.size ? 0 : t.size;
      _this45.seen += n;

      var _loop12 = function _loop12(_e107) {
        var r = t[_e107];
        if ("number" == typeof r) _this45.totals.hasOwnProperty(_e107) || (_this45.totals[_e107] = 0), _this45.totals[_e107] = _this45.totals[_e107] + r * n;else {
          var _t90;

          _e107 in _this45.totals ? _t90 = _this45.totals[_e107] : _this45.totals[_e107] = 0;
          var a = tidy$1(() => add$5(_this45.totals[_e107], mul$1(r, n)));
          _this45.totals[_e107] = a, null != _t90 && _t90.dispose();
        }
      };

      for (var _e107 in t) {
        _loop12(_e107);
      }
    })();
  }

  onEpochEnd(e, t) {
    var _this46 = this;

    return _asyncToGenerator(function* () {
      if (null != t) {
        var _loop13 = function _loop13(_e108) {
          null != _this46.totals[_e108] && ("number" == typeof _this46.totals[_e108] ? t[_e108] = _this46.totals[_e108] / _this46.seen : tidy$1(() => {
            var n = mul$1(div$3(1, _this46.seen), _this46.totals[_e108]);
            t[_e108] = n, _this46.totals[_e108].dispose(), keep$1(t[_e108]);
          }));
        };

        for (var _e108 of _this46.params.metrics) {
          _loop13(_e108);
        }
      }
    })();
  }

}

class History$1 extends BaseCallback$1 {
  onTrainBegin(e) {
    var _this47 = this;

    return _asyncToGenerator(function* () {
      _this47.epoch = [], _this47.history = {};
    })();
  }

  onEpochEnd(e, t) {
    var _this48 = this;

    return _asyncToGenerator(function* () {
      null == t && (t = {}), _this48.epoch.push(e);

      for (var _e109 in t) {
        null == _this48.history[_e109] && (_this48.history[_e109] = []), _this48.history[_e109].push(t[_e109]);
      }
    })();
  }

  syncData() {
    var _this49 = this;

    return _asyncToGenerator(function* () {
      var e = [],
          t = [],
          n = [];

      for (var _r27 in _this49.history) {
        var a = _this49.history[_r27];

        for (var s = 0; s < a.length; ++s) {
          "number" != typeof a[s] && (e.push(a[s].data()), t.push(_r27), n.push(s));
        }
      }

      var r = yield Promise.all(e);

      for (var _e110 = 0; _e110 < r.length; ++_e110) {
        _this49.history[t[_e110]][n[_e110]].dispose(), _this49.history[t[_e110]][n[_e110]] = r[_e110][0];
      }
    })();
  }

}

class CustomCallback$1 extends BaseCallback$1 {
  constructor(e, t) {
    if (super(), this.currentEpoch = 0, this.yieldEvery = t || "auto", "auto" === this.yieldEvery && (this.yieldEvery = DEFAULT_YIELD_EVERY_MS$1), "never" === this.yieldEvery && null != e.onYield) throw new Error("yieldEvery is `never` but you provided an `onYield` callback. Either change `yieldEvery` or remove the callback");
    isNumber$1(this.yieldEvery) && (this.maybeWait = debounce$1(this.maybeWait.bind(this), this.yieldEvery)), this.trainBegin = e.onTrainBegin, this.trainEnd = e.onTrainEnd, this.epochBegin = e.onEpochBegin, this.epochEnd = e.onEpochEnd, this.batchBegin = e.onBatchBegin, this.batchEnd = e.onBatchEnd, this.yield = e.onYield;
  }

  maybeWait(e, t, n) {
    var _this50 = this;

    return _asyncToGenerator(function* () {
      var r = [];
      null != _this50.yield && (yield resolveScalarsInLogs$1(n), r.push(_this50.yield(e, t, n))), r.push(nextFrame$1()), yield Promise.all(r);
    })();
  }

  onEpochBegin(e, t) {
    var _this51 = this;

    return _asyncToGenerator(function* () {
      _this51.currentEpoch = e, null != _this51.epochBegin && (yield resolveScalarsInLogs$1(t), yield _this51.epochBegin(e, t));
    })();
  }

  onEpochEnd(e, t) {
    var _this52 = this;

    return _asyncToGenerator(function* () {
      var n = [];
      null != _this52.epochEnd && (yield resolveScalarsInLogs$1(t), n.push(_this52.epochEnd(e, t))), "epoch" === _this52.yieldEvery && n.push(nextFrame$1()), yield Promise.all(n);
    })();
  }

  onBatchBegin(e, t) {
    var _this53 = this;

    return _asyncToGenerator(function* () {
      null != _this53.batchBegin && (yield resolveScalarsInLogs$1(t), yield _this53.batchBegin(e, t));
    })();
  }

  onBatchEnd(e, t) {
    var _this54 = this;

    return _asyncToGenerator(function* () {
      var n = [];
      null != _this54.batchEnd && (yield resolveScalarsInLogs$1(t), n.push(_this54.batchEnd(e, t))), "batch" === _this54.yieldEvery ? n.push(nextFrame$1()) : isNumber$1(_this54.yieldEvery) && n.push(_this54.maybeWait(_this54.currentEpoch, e, t)), yield Promise.all(n);
    })();
  }

  onTrainBegin(e) {
    var _this55 = this;

    return _asyncToGenerator(function* () {
      null != _this55.trainBegin && (yield resolveScalarsInLogs$1(e), yield _this55.trainBegin(e));
    })();
  }

  onTrainEnd(e) {
    var _this56 = this;

    return _asyncToGenerator(function* () {
      null != _this56.trainEnd && (yield resolveScalarsInLogs$1(e), yield _this56.trainEnd(e));
    })();
  }

}

function standardizeCallbacks$1(e, t) {
  return null == e && (e = {}), e instanceof BaseCallback$1 ? [e] : Array.isArray(e) && e[0] instanceof BaseCallback$1 ? e : toList$1(e).map(e => new CustomCallback$1(e, t));
}

class CallbackConstructorRegistry$1 {
  constructor() {}

  static registerCallbackConstructor(e, t) {
    assert$6(e >= 0 && Number.isInteger(e), () => "Verbosity level is expected to be an integer >= 0, but got ".concat(e)), CallbackConstructorRegistry$1.checkForDuplicate(t), null == CallbackConstructorRegistry$1.constructors[e] && (CallbackConstructorRegistry$1.constructors[e] = []), CallbackConstructorRegistry$1.constructors[e].push(t);
  }

  static checkForDuplicate(e) {
    for (var t in CallbackConstructorRegistry$1.constructors) {
      CallbackConstructorRegistry$1.constructors[+t].forEach(t => {
        if (t === e) throw new ValueError$1("Duplicate callback constructor.");
      });
    }
  }

  static clear() {
    CallbackConstructorRegistry$1.constructors = {};
  }

  static createCallbacks(e) {
    var t = [];

    for (var n in CallbackConstructorRegistry$1.constructors) {
      var r = +n;
      e >= r && t.push(...CallbackConstructorRegistry$1.constructors[r]);
    }

    return t.map(e => new e());
  }

}

function configureCallbacks$1(e, t, n, r, a, s, o, i, l) {
  var u = new History$1(),
      c = [new BaseLogger$1(), ...CallbackConstructorRegistry$1.createCallbacks(t)];
  null != e && c.push(...e), c.push(u);
  var p = new CallbackList$1(c);
  return p.setParams({
    epochs: n,
    initialEpoch: r,
    samples: a,
    steps: s,
    batchSize: o,
    verbose: t,
    doValidation: i,
    metrics: l
  }), {
    callbackList: p,
    history: u
  };
}

function deserialize$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  return deserializeKerasObject$1(e, SerializationMap$1.getMap().classNameMap, t, "layer", n);
}

function l2Normalize$1(e, t) {
  return tidy$1(() => {
    "float32" !== e.dtype && (e = cast$7(e, "float32"));
    var n = sum$6(square$4(e), t, !0),
        r = fill$5(n.shape, epsilon$3()),
        a = sqrt$5(maximum$6(n, r));
    return div$3(e, a);
  });
}

function meanSquaredError$3(e, t) {
  return tidy$1(() => mean$3(square$4(sub$5(t, e)), -1));
}

function meanAbsoluteError$2(e, t) {
  return tidy$1(() => mean$3(abs$5(sub$5(t, e)), -1));
}

function meanAbsolutePercentageError$2(e, t) {
  return tidy$1(() => {
    var n = sub$5(e, t),
        r = clipByValue$3(abs$5(e), epsilon$3(), Number.MAX_VALUE),
        a = abs$5(div$3(n, r));
    return mul$1(100, mean$3(a, -1));
  });
}

function meanSquaredLogarithmicError$1(e, t) {
  return tidy$1(() => {
    var n = clipByValue$3(t, epsilon$3(), Number.MAX_VALUE),
        r = log$7(add$5(1, n)),
        a = clipByValue$3(e, epsilon$3(), Number.MAX_VALUE),
        s = log$7(add$5(1, a));
    return mean$3(square$4(sub$5(r, s)), -1);
  });
}

function squaredHinge$1(e, t) {
  return tidy$1(() => {
    var n = maximum$6(0, sub$5(1, mul$1(e, t)));
    return mean$3(square$4(n), -1);
  });
}

function hinge$1(e, t) {
  return tidy$1(() => {
    var n = maximum$6(0, sub$5(1, mul$1(e, t)));
    return mean$3(n, -1);
  });
}

function categoricalHinge$1(e, t) {
  return tidy$1(() => {
    var n = sum$6(mul$1(e, t), -1),
        r = max$7(mul$1(sub$5(1, e), t), -1);
    return maximum$6(0, add$5(1, sub$5(r, n)));
  });
}

function logcosh$1(e, t) {
  return tidy$1(() => {
    var n = Math.log(2),
        r = sub$5(t, e),
        a = sub$5(add$5(r, softplus$5(mul$1(-2, r))), n);
    return mean$3(a, -1);
  });
}

function categoricalCrossentropy$4(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  return tidy$1(() => {
    if (n) t = softmax$6(t);else {
      var _e111 = sum$6(t, t.shape.length - 1, !0);

      t = div$3(t, _e111);
    }
    return t = clipByValue$3(t, epsilon$3(), 1 - epsilon$3()), neg$5(sum$6(mul$1(cast$7(e, "float32"), log$7(t)), t.shape.length - 1));
  });
}

function sparseCategoricalCrossentropy$3(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  return tidy$1(() => {
    var r = cast$7(floor$5(flatten$5(e)), "int32"),
        a = (t = clipByValue$3(t, epsilon$3(), 1 - epsilon$3())).shape;
    return categoricalCrossentropy$4(reshape$6(oneHot$5(r, a[a.length - 1]), a), t, n);
  });
}

function sigmoidCrossEntropyWithLogits$1(e, t) {
  if (!arraysEqual$1(e.shape, t.shape)) throw new ValueError$1("logits and labels must have the same shape, but got shapes ".concat(JSON.stringify(e.shape), " and ").concat(JSON.stringify(t.shape)));
  return tidy$1(() => {
    var n = relu$6(t),
        r = neg$5(abs$5(t));
    return add$5(sub$5(n, mul$1(t, e)), log1p$5(exp$5(r)));
  });
}

function binaryCrossentropy$4(e, t) {
  return tidy$1(() => {
    var n;
    return n = clipByValue$3(t, epsilon$3(), 1 - epsilon$3()), n = log$7(div$3(n, sub$5(1, n))), mean$3(sigmoidCrossEntropyWithLogits$1(e, n), -1);
  });
}

function kullbackLeiblerDivergence$1(e, t) {
  return tidy$1(() => {
    var n = clipByValue$3(e, epsilon$3(), 1),
        r = clipByValue$3(t, epsilon$3(), 1);
    return sum$6(mul$1(e, log$7(div$3(n, r))), -1);
  });
}

function poisson$1(e, t) {
  return tidy$1(() => {
    var n = log$7(add$5(epsilon$3(), t));
    return mean$3(sub$5(t, mul$1(e, n)), -1);
  });
}

function cosineProximity$2(e, t) {
  return tidy$1(() => {
    var n = l2Normalize$1(e, -1),
        r = l2Normalize$1(t, -1),
        a = mul$1(n, r);
    return neg$5(sum$6(a, -1));
  });
}

CallbackConstructorRegistry$1.constructors = {};
var lossesMap$1 = {
  meanSquaredError: meanSquaredError$3,
  meanAbsoluteError: meanAbsoluteError$2,
  meanAbsolutePercentageError: meanAbsolutePercentageError$2,
  meanSquaredLogarithmicError: meanSquaredLogarithmicError$1,
  squaredHinge: squaredHinge$1,
  hinge: hinge$1,
  categoricalHinge: categoricalHinge$1,
  logcosh: logcosh$1,
  categoricalCrossentropy: categoricalCrossentropy$4,
  sparseCategoricalCrossentropy: sparseCategoricalCrossentropy$3,
  binaryCrossentropy: binaryCrossentropy$4,
  kullbackLeiblerDivergence: kullbackLeiblerDivergence$1,
  poisson: poisson$1,
  cosineProximity: cosineProximity$2
};

function get$3(e) {
  if ("string" == typeof e) {
    if (e in lossesMap$1) return lossesMap$1[e];
    var t = "Unknown loss ".concat(e);
    throw e.toLowerCase().includes("softmaxcrossentropy") && (t = "Unknown loss ".concat(e, ". Use \"categoricalCrossentropy\" as the string name for tf.losses.softmaxCrossEntropy")), new ValueError$1(t);
  }

  return e;
}

function binaryAccuracy$2(e, t) {
  return tidy$1(() => {
    var n = mul$1(.5, onesLike$5(t)),
        r = cast$6(greater$6(t, n), e.dtype);
    return mean$3(equal$5(e, r), -1);
  });
}

function categoricalAccuracy$2(e, t) {
  return tidy$1(() => cast$6(equal$5(argMax$5(e, -1), argMax$5(t, -1)), "float32"));
}

function truePositives$1(e, t) {
  return tidy$1(() => cast$7(sum$6(logicalAnd$5(equal$5(e, 1), equal$5(t, 1))), "float32"));
}

function falsePositives$1(e, t) {
  return tidy$1(() => cast$7(sum$6(logicalAnd$5(equal$5(e, 0), equal$5(t, 1))), "float32"));
}

function precision$2(e, t) {
  return tidy$1(() => {
    var n = truePositives$1(e, t),
        r = falsePositives$1(e, t),
        a = add$5(n, r);
    return cast$7(where$1(greater$6(a, 0), div$3(n, a), 0), "float32");
  });
}

function binaryCrossentropy$3(e, t) {
  return binaryCrossentropy$4(e, t);
}

function sparseCategoricalAccuracy$2(e, t) {
  return e.rank === t.rank && (e = squeeze$1(e, [e.rank - 1])), (t = argMax$5(t, -1)).dtype !== e.dtype && (t = cast$7(t, e.dtype)), cast$7(equal$5(e, t), "float32");
}

var mse$2 = meanSquaredError$3,
    MSE$2 = meanSquaredError$3,
    mae$1 = meanAbsoluteError$2,
    MAE$1 = meanAbsoluteError$2,
    mape$2 = meanAbsolutePercentageError$2,
    MAPE$2 = meanAbsolutePercentageError$2,
    categoricalCrossentropy$3 = categoricalCrossentropy$4,
    cosine$1 = cosineProximity$2,
    sparseCategoricalCrossentropy$2 = sparseCategoricalCrossentropy$3,
    metricsMap$1 = {
  binaryAccuracy: binaryAccuracy$2,
  categoricalAccuracy: categoricalAccuracy$2,
  precision: precision$2,
  categoricalCrossentropy: categoricalCrossentropy$3,
  sparseCategoricalCrossentropy: sparseCategoricalCrossentropy$2,
  mse: mse$2,
  MSE: MSE$2,
  mae: mae$1,
  MAE: MAE$1,
  mape: mape$2,
  MAPE: MAPE$2,
  cosine: cosine$1
};

function get$2(e) {
  if ("string" == typeof e && e in metricsMap$1) return metricsMap$1[e];
  if ("string" != typeof e && null != e) return e;
  throw new ValueError$1("Unknown metric ".concat(e));
}

function getLossOrMetricName$1(e) {
  if (assert$5(null !== e, "Unknown LossOrMetricFn ".concat(e)), "string" == typeof e) return e;
  {
    var t;

    for (var n of Object.keys(lossesMap$1)) {
      if (lossesMap$1[n] === e) {
        t = n;
        break;
      }
    }

    if (void 0 !== t) return t;

    for (var _n38 of Object.keys(metricsMap$1)) {
      if (metricsMap$1[_n38] === e) {
        t = _n38;
        break;
      }
    }

    return void 0 !== t ? t : e.name;
  }
}

function getOptimizer$1(e) {
  var t = {
    Adagrad: () => train$1.adagrad(.01),
    Adadelta: () => train$1.adadelta(1, .95, epsilon$3()),
    Adam: () => train$1.adam(.001, .9, .999, epsilon$3()),
    Adamax: () => train$1.adamax(.002, .9, .999, epsilon$3(), 0),
    RMSProp: () => train$1.rmsprop(.001, .9, 0, epsilon$3()),
    SGD: () => train$1.sgd(.01)
  };
  if (t.adagrad = t.Adagrad, t.adadelta = t.Adadelta, t.adam = t.Adam, t.adamax = t.Adamax, t.rmsprop = t.RMSProp, t.sgd = t.SGD, e in t) return t[e]();
  throw new ValueError$1("Unknown Optimizer ".concat(e));
}

var MAX_USER_DEFINED_METADATA_SERIALIZED_LENGTH$1 = 1048576;

function checkUserDefinedMetadata$1(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  if (null == e || "object" != typeof e || Object.getPrototypeOf(e) !== Object.prototype || !plainObjectCheck$1(e)) throw new Error("User-defined metadata is expected to be a JSON object, but is not.");

  if (n) {
    var _n39 = JSON.stringify(e);

    _n39.length > MAX_USER_DEFINED_METADATA_SERIALIZED_LENGTH$1 && console.warn("User-defined metadata of model \"".concat(t, "\" is too large in size (length=").concat(_n39.length, " when serialized). It is not recommended to store such large objects in user-defined metadata. Please make sure its serialized length is <= ").concat(MAX_USER_DEFINED_METADATA_SERIALIZED_LENGTH$1, "."));
  }
}

function plainObjectCheck$1(e) {
  if (null === e) return !0;

  if ("object" == typeof e) {
    if (Object.getPrototypeOf(e) === Object.prototype) {
      var t = Object.keys(e);

      for (var n of t) {
        if ("string" != typeof n) return !1;
        if (!plainObjectCheck$1(e[n])) return !1;
      }

      return !0;
    }

    if (Array.isArray(e)) {
      for (var _t91 of e) {
        if (!plainObjectCheck$1(_t91)) return !1;
      }

      return !0;
    }

    return !1;
  }

  {
    var _t92 = typeof e;

    return "string" === _t92 || "number" === _t92 || "boolean" === _t92;
  }
}

function printSummary$1(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : console.log;
  var a = isModelSequentialLike$1(e),
      s = ["Layer (type)", "Output shape", "Param #"];
  var o;

  if (a ? (t = t || 65, n = n || [.45, .85, 1]) : (t = t || 98, n = n || [.33, .55, .67, 1]), n[n.length - 1] <= 1 && (n = n.map(e => Math.floor(t * e))), !a) {
    s.push("Receives inputs"), o = [];

    for (var _t93 in e.nodesByDepth) {
      o.push(...e.nodesByDepth[_t93]);
    }
  }

  r("_".repeat(t)), printRow$1(s, n, r), r("=".repeat(t));
  var i = e.layers;

  for (var _e112 = 0; _e112 < i.length; ++_e112) {
    a ? printLayerSummary$1(i[_e112], n, r) : printLayerSummaryWithConnections$1(i[_e112], n, o, r), r((_e112 === i.length - 1 ? "=" : "_").repeat(t));
  }

  e.checkTrainableWeightsConsistency();
  var l = countTrainableParams$1(e),
      u = countParamsInWeights$1(e.nonTrainableWeights);
  r("Total params: ".concat(l + u)), r("Trainable params: ".concat(l)), r("Non-trainable params: ".concat(u)), r("_".repeat(t));
}

function countTrainableParams$1(e) {
  var t;
  return t = countParamsInWeights$1(null != e.collectedTrainableWeights ? e.collectedTrainableWeights : e.trainableWeights), t;
}

function isModelSequentialLike$1(e) {
  var t = !0;
  var n = [],
      r = [];

  for (var _t94 in e.nodesByDepth) {
    n.push(e.nodesByDepth[_t94]);
  }

  for (var _e113 of n) {
    if (_e113.length > 1 || 1 === _e113.length && _e113[0].inboundLayers.length > 1) {
      t = !1;
      break;
    }

    r.push(..._e113);
  }

  if (t) for (var _n40 of e.layers) {
    var _e114 = !1;

    for (var a of _n40.inboundNodes) {
      if (-1 !== r.indexOf(a)) {
        if (_e114) {
          t = !1;
          break;
        }

        _e114 = !0;
      }
    }

    if (!t) break;
  }
  return t;
}

function printRow$1(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : console.log;
  var r = "";

  for (var _n41 = 0; _n41 < e.length; ++_n41) {
    _n41 > 0 && (r = r.slice(0, r.length - 1) + " "), r += e[_n41], r = r.slice(0, t[_n41]), r += " ".repeat(t[_n41] - r.length);
  }

  n(r);
}

function printLayerSummary$1(e, t, n) {
  var r;

  try {
    r = JSON.stringify(e.outputShape);
  } catch (e) {
    r = "multiple";
  }

  printRow$1(["".concat(e.name, " (").concat(e.getClassName(), ")"), r, e.countParams().toString()], t, n);
}

function printLayerSummaryWithConnections$1(e, t, n, r) {
  var a;

  try {
    a = JSON.stringify(e.outputShape);
  } catch (e) {
    a = "multiple";
  }

  var s = [];

  for (var _t95 of e.inboundNodes) {
    if (!(null != n && n.length > 0 && -1 === n.indexOf(_t95))) for (var _e115 = 0; _e115 < _t95.inboundLayers.length; ++_e115) {
      s.push("".concat(_t95.inboundLayers[_e115].name, "[").concat(_t95.nodeIndices[_e115], "][").concat(_t95.tensorIndices[_e115], "]"));
    }
  }

  var o = e.name,
      i = e.getClassName(),
      l = 0 === s.length ? "" : s[0];
  printRow$1(["".concat(o, " (").concat(i, ")"), a, e.countParams().toString(), l], t, r);

  for (var _e116 = 1; _e116 < s.length; ++_e116) {
    printRow$1(["", "", "", s[_e116]], t, r);
  }
}

function isArrayItemInputOrOutputName$1(e, t, n) {
  return ("inboundNodes" === e || "outputLayers" === e || "inputLayers" === e) && 0 === t && "string" == typeof n;
}

function convertPythonicToTs$1(e, t) {
  if (null === e) return null;
  if ("string" == typeof e) return toCamelCase$1(e);
  if ("number" == typeof e || "boolean" == typeof e) return e;

  if (e instanceof Array) {
    var n = [],
        r = e.length;

    for (var a = 0; a < r; ++a) {
      var _r28 = e[a];
      isArrayItemInputOrOutputName$1(t, a, _r28) ? n.push(_r28) : n.push(convertPythonicToTs$1(_r28, t));
    }

    return n;
  }

  {
    var _t96 = {};

    for (var _n42 of Object.keys(e)) {
      var _r29 = e[_n42];
      if ("name" === _n42 && "string" == typeof _r29) _t96[_n42] = _r29;else {
        var _e117 = toCamelCase$1(_n42);

        _t96[_e117] = convertPythonicToTs$1(_r29, _e117);
      }
    }

    return _t96;
  }
}

function convertTsToPythonic$1(e, t) {
  if (null == e) return null;
  if ("string" == typeof e) return toSnakeCase$1(e);
  if ("number" == typeof e || "boolean" == typeof e) return e;

  if (e instanceof Array) {
    var n = [],
        r = e.length;

    for (var a = 0; a < r; ++a) {
      var _r30 = e[a];
      isArrayItemInputOrOutputName$1(t, a, _r30) ? n.push(_r30) : n.push(convertTsToPythonic$1(_r30, t));
    }

    return n;
  }

  {
    var _t97 = {};

    for (var _n43 of Object.keys(e)) {
      var _r31 = e[_n43];
      _t97[toSnakeCase$1(_n43)] = "name" !== _n43 && "className" !== _n43 || "string" != typeof _r31 ? convertTsToPythonic$1(_r31, _n43) : _r31;
    }

    return _t97;
  }
}

var version$d = "3.8.0";

function assertFeedCompatibility$1(e, t) {
  if (null == e.dtype || e.dtype === t.dtype) return t;

  try {
    return cast$7(t, e.dtype);
  } catch (n) {
    throw new ValueError$1("The dtype of the feed (".concat(t.dtype, ") can not be cast to the dtype of the key '").concat(e.name, "' (").concat(e.dtype, ")."));
  }
}

class FeedDict$1 {
  constructor(e) {
    if (this.id2Value = {}, this.id2Mask = {}, this.name2Id = {}, e instanceof FeedDict$1) for (var t in e.id2Value) {
      this.id2Value[t] = e.id2Value[t], t in e.id2Mask && (this.id2Mask[t] = e.id2Mask[t]);
    } else {
      if (null == e) return;

      for (var _t98 of e) {
        this.add(_t98.key, _t98.value);
      }
    }
  }

  add(e, t, n) {
    if (null != this.id2Value[e.id]) throw new ValueError$1("Duplicate key: name=".concat(e.name, ", id=").concat(e.id));
    return this.id2Value[e.id] = assertFeedCompatibility$1(e, t), this.name2Id[e.name] = e.id, null != n && (this.id2Mask[e.id] = n), this;
  }

  addFeed(e) {
    this.add(e.key, e.value);
  }

  hasKey(e) {
    return null != this.id2Value[e.id];
  }

  names() {
    return Object.keys(this.name2Id);
  }

  getValue(e) {
    if (e instanceof SymbolicTensor$1) {
      if (null == this.id2Value[e.id]) throw new ValueError$1("Nonexistent key: ".concat(e.name));
      return this.id2Value[e.id];
    }

    {
      var t = this.name2Id[e];
      if (null == t) throw new ValueError$1("Feed dict has no SymbolicTensor name: ".concat(e));
      return this.id2Value[t];
    }
  }

  getMask(e) {
    if (e instanceof SymbolicTensor$1) {
      if (null == this.id2Value[e.id]) throw new ValueError$1("Nonexistent key: ".concat(e.name));
      return this.id2Mask[e.id];
    }

    {
      var t = this.name2Id[e];
      if (null == t) throw new ValueError$1("Feed dict has no SymbolicTensor name: ".concat(e));
      return this.id2Mask[t];
    }
  }

  disposeMasks() {
    null != this.id2Mask && dispose$1(this.id2Mask);
  }

}

var cachedSorted$1 = {},
    cachedRecipientCounts$1 = {};

function execute$1(e, t, n, r) {
  var a = null != n && n.training,
      s = Array.isArray(e),
      o = s ? e : [e],
      i = o.map(e => e.name),
      l = [],
      u = t.names();

  for (var _e118 of i) {
    -1 !== u.indexOf(_e118) ? l.push(t.getValue(_e118)) : l.push(null);
  }

  null != r && (r.maxNumTensors = -Infinity, r.minNumTensors = Infinity);
  var c = i.join(",") + "|" + t.names().join(",");
  var p, d;

  if (null == cachedSorted$1[c]) {
    var _e119 = getTopologicalSortAndRecipientCounts$1(o, t);

    p = _e119.sorted, d = _e119.recipientCounts, cachedSorted$1[c] = p, cachedRecipientCounts$1[c] = d;
  }

  p = cachedSorted$1[c], d = {}, a || Object.assign(d, cachedRecipientCounts$1[c]);
  var h = new FeedDict$1(t);

  for (var _e120 = 0; _e120 < p.length; ++_e120) {
    if (null != r) {
      var _e121 = memory$1().numTensors;
      _e121 > r.maxNumTensors && (r.maxNumTensors = _e121), _e121 < r.minNumTensors && (r.minNumTensors = _e121);
    }

    var _s15 = p[_e120],
        _o8 = _s15.sourceLayer;
    if (_o8 instanceof InputLayer$1) continue;
    var _u2 = [],
        _c2 = [],
        m = [];
    var f = !1;

    for (var _e122 of _s15.inputs) {
      var _n44 = h.getValue(_e122),
          _r32 = h.getMask(_e122);

      _u2.push(_n44), _c2.push(_r32), null != _r32 && (f = !0), a || (d[_e122.name]--, 0 !== d[_e122.name] || t.hasKey(_e122) || -1 !== i.indexOf(_e122.name) || _n44.isDisposed || !0 === _e122.sourceLayer.stateful || m.push(_n44));
    }

    f && ((n = n || {}).mask = _c2[0]);
    var g = toList$1(_o8.apply(_u2, n));
    var $ = null;
    _o8.supportsMasking && ($ = _o8.computeMask(_u2, _c2));
    var y = getNodeOutputs$1(_s15),
        b = Array.isArray(y) ? y : [y];

    for (var _e123 = 0; _e123 < b.length; ++_e123) {
      h.hasKey(b[_e123]) || h.add(b[_e123], g[_e123], Array.isArray($) ? $[0] : $);

      var _t99 = i.indexOf(b[_e123].name);

      -1 !== _t99 && (l[_t99] = g[_e123]);
    }

    a || dispose$1(m);
  }

  return h.disposeMasks(), s ? l : l[0];
}

function getTopologicalSortAndRecipientCounts$1(e, t) {
  assert$6(null != e && e.length > 0, () => "Expected at least one fetch, got none");
  var n = [],
      r = {};

  if (1 === e.length) {
    var a = getTopologicalSortAndRecipientCountsForOneFetch$1(e[0], t);
    n = a.sorted, r = a.recipientMap;
  } else {
    var _a27 = new Set();

    for (var s of e) {
      var {
        sorted: _e124,
        recipientMap: o
      } = getTopologicalSortAndRecipientCountsForOneFetch$1(s, t);

      for (var _t100 of _e124) {
        _a27.has(_t100.name) || (n.push(_t100), _a27.add(_t100.name));
      }

      var _loop14 = function _loop14(_e125) {
        null == r[_e125] && (r[_e125] = new Set()), o[_e125].forEach(t => r[_e125].add(t));
      };

      for (var _e125 in o) {
        _loop14(_e125);
      }
    }
  }

  return {
    sorted: n,
    recipientCounts: recipientMap2Counts$1(r)
  };
}

function recipientMap2Counts$1(e) {
  var t = {};

  for (var n in e) {
    t[n] = e[n].size;
  }

  return t;
}

function getTopologicalSortAndRecipientCountsForOneFetch$1(e, t) {
  var n = new Set(),
      r = [],
      a = {};

  for (var _e126 of t.names()) {
    n.add(_e126);
  }

  var s = [],
      o = [];

  for (s.push(e); s.length > 0;) {
    var _e127 = s[s.length - 1];

    if (n.has(_e127.name)) {
      s.pop();
      continue;
    }

    var _t101 = o[o.length - 1] === s.length - 1;

    if (0 === _e127.inputs.length || _t101) s.pop(), r.push(_e127), n.add(_e127.name), _t101 && o.pop();else {
      o.push(s.length - 1);

      for (var _t102 of _e127.inputs) {
        null == a[_t102.name] && (a[_t102.name] = new Set()), a[_t102.name].add(_e127.name), n.has(_t102.name) || s.push(_t102);
      }
    }
  }

  return {
    sorted: r,
    recipientMap: a
  };
}

function getNodeOutputs$1(e) {
  var t;
  if (1 === e.sourceLayer.inboundNodes.length) t = e.sourceLayer.output;else {
    var n = null;

    for (var _t103 = 0; _t103 < e.sourceLayer.inboundNodes.length; ++_t103) {
      for (var r of e.sourceLayer.inboundNodes[_t103].outputTensors) {
        if (r.id === e.id) {
          n = _t103;
          break;
        }
      }
    }

    t = e.sourceLayer.getOutputAt(n);
  }
  return t;
}

class Container$1 extends Layer$1 {
  constructor(e) {
    if (super({}), this.containerNodes = new Set(), this.name = e.name, null == this.name) {
      var _e128 = this.getClassName().toLowerCase();

      this.name = getUid$1(_e128);
    }

    if (this.supportsMasking = !1, this.trainable_ = !0, this.inputs = Array.isArray(e.inputs) ? e.inputs.slice() : [e.inputs], this.outputs = Array.isArray(e.outputs) ? e.outputs.slice() : [e.outputs], unique$6(this.inputs).length !== this.inputs.length) throw new ValueError$1("The list of inputs passed to the model is redundant. All inputs should only appear once. Found: ".concat(this.inputs.map(e => e.name)));
    unique$6(this.outputs).length !== this.outputs.length && console.warn("The list of outputs passed to the model is redundant. All outputs should only appear once. Found: ".concat(this.outputs.map(e => e.name))), this.inputLayers = [], this.inputLayersNodeIndices = [], this.inputLayersTensorIndices = [], this.outputLayers = [], this.outputLayersNodeIndices = [], this.outputLayersTensorIndices = [], this.layers = [], this.internalContainerRefs = [];

    for (var _e129 of this.outputs) {
      var _t104 = _e129.nodeIndex,
          _n45 = _e129.tensorIndex;
      this.outputLayers.push(_e129.sourceLayer), this.outputLayersNodeIndices.push(_t104), this.outputLayersTensorIndices.push(_n45);
    }

    for (var _e130 of this.inputs) {
      var _t105 = _e130.sourceLayer,
          _n46 = _e130.nodeIndex,
          _r33 = _e130.tensorIndex;
      assert$5(0 === _n46, "input layer has >1 nodes"), assert$5(0 === _r33, "input layer has >1 tensors"), this.inputLayers.push(_t105), this.inputLayersNodeIndices.push(_n46), this.inputLayersTensorIndices.push(_r33);
    }

    this.inputNames = [], this.outputNames = [], this.feedInputShapes = [], this.feedInputNames = [], this.feedOutputNames = [];

    for (var _t106 = 0; _t106 < this.inputLayers.length; _t106++) {
      var _n47 = this.inputLayers[_t106];
      if (!(_n47 instanceof InputLayer$1)) throw new TypeError("Input layers to a LayersModel must be InputLayer objects. Received inputs: ".concat(e.inputs, ". Input ").concat(_t106, " (0-based) originates from layer type ").concat(_n47.getClassName(), "."));
      this.inputNames.push(_n47.name), this.feedInputShapes.push(_n47.batchInputShape), this.feedInputNames.push(_n47.name);
    }

    for (var _e131 of this.outputLayers) {
      this.outputNames.push(_e131.name);
    }

    this.internalInputShapes = this.inputs.map(e => e.shape), this.internalOutputShapes = this.outputs.map(e => e.shape);

    var t = {},
        n = {},
        r = {},
        a = {},
        s = {},
        o = [],
        i = (e, t, n, r, a, l) => {
      null != r && null != a && null != l || (r = e.sourceLayer, a = e.nodeIndex, l = e.tensorIndex);
      var u = r.inboundNodes[a];
      if (-1 !== n.indexOf(u)) throw new RuntimeError$1("The tensor ".concat(e.name, " at layer \"").concat(r.name, "\" is part of a cycle."));
      if (-1 !== t.indexOf(u)) return;
      this.containerNodes.add(Container$1.nodeKey(r, a)), r.id in s || (s[r.id] = Object.keys(s).length), -1 === n.indexOf(u) && n.push(u);
      var c = u.inboundLayers.length;

      for (var _e132 = 0; _e132 < c; _e132++) {
        i(u.inputTensors[_e132], t, n, u.inboundLayers[_e132], u.nodeIndices[_e132], u.tensorIndices[_e132]);
      }

      for (t.push(u); n.indexOf(u) >= 0;) {
        n.splice(n.indexOf(u), 1);
      }

      o.push(u);
    },
        l = [],
        u = [];

    for (var _e133 of this.outputs) {
      i(_e133, l, u);
    }

    var c = o.slice().reverse();

    for (var _e134 of c) {
      n[_e134.id] = _e134, _e134.id in t || (t[_e134.id] = 0);
      var _s16 = t[_e134.id];
      _s16 = Math.max(_s16, null == r[_e134.outboundLayer.id] ? 0 : r[_e134.outboundLayer.id]), r[_e134.outboundLayer.id] = _s16, a[_e134.outboundLayer.id] = _e134.outboundLayer, t[_e134.id] = _s16;

      for (var _r34 = 0; _r34 < _e134.inboundLayers.length; _r34++) {
        var _a28 = _e134.inboundLayers[_r34].inboundNodes[_e134.nodeIndices[_r34]];
        t[_a28.id] = Math.max(_s16 + 1, null == t[_a28.id] ? 0 : t[_a28.id]), n[_a28.id] = _a28;
      }
    }

    var p = {};

    for (var _e135 in t) {
      var _r35 = t[_e135];
      _r35 in p || (p[_r35] = []), p[_r35].push(n[_e135]);
    }

    var d = {};

    for (var _e136 in r) {
      var _t107 = r[_e136];
      _t107 in d || (d[_t107] = []), d[_t107].push(a[_e136]);
    }

    var h = Object.keys(d).map(e => parseInt(e, 10)).sort(reverseNumberCompare$1);
    this.layers = [];

    for (var _e137 of h) {
      var _t108 = d[_e137];

      _t108.sort((e, t) => {
        var n = s[e.id],
            r = s[t.id];
        return n < r ? -1 : n > r ? 1 : 0;
      });

      for (var _e138 of _t108) {
        _e138 instanceof Container$1 && this.internalContainerRefs.push(_e138), this.layers.push(_e138);
      }
    }

    this.layersByDepth = d, h = Object.keys(p).map(e => parseInt(e, 10)).sort(reverseNumberCompare$1);
    var m = this.inputs.slice(),
        f = [];

    for (var _e139 of h) {
      for (var _t109 of p[_e139]) {
        var _e140 = _t109.outboundLayer;

        if (null != _e140) {
          for (var _n48 of _t109.inputTensors) {
            if (-1 === m.indexOf(_n48)) throw new RuntimeError$1("Graph disconnected: cannot obtain value for tensor ".concat(_n48, " at layer \"").concat(_e140.name, "\". The following previous layers were accessed without issue: ").concat(f));
          }

          for (var _e141 of _t109.outputTensors) {
            m.push(_e141);
          }

          f.push(_e140.name);
        }
      }
    }

    this.nodesByDepth = p;
    var g = this.layers.map(e => e.name);

    var _loop15 = function _loop15(_e142) {
      var t = g.filter(t => t === _e142).length;
      if (1 !== t) throw new RuntimeError$1("The name \"".concat(_e142, "\" is used ").concat(t, " times in the model. All layer names should be unique. Layer names: ") + JSON.stringify(g));
    };

    for (var _e142 of g) {
      _loop15(_e142);
    }

    this.outboundNodes = [], this.inboundNodes = [], new Node$1({
      outboundLayer: this,
      inboundLayers: [],
      nodeIndices: [],
      tensorIndices: [],
      inputTensors: this.inputs,
      outputTensors: this.outputs,
      inputMasks: this.inputs.map(e => null),
      outputMasks: this.outputs.map(e => null),
      inputShapes: this.inputs.map(e => e.shape),
      outputShapes: this.outputs.map(e => e.shape)
    }), this.built = !0, this._refCount = 1;
  }

  assertNotDisposed() {
    if (0 === this._refCount) throw new Error("Container '".concat(this.name, "' is already disposed."));
  }

  dispose() {
    this.assertNotDisposed();
    var e = {
      refCountAfterDispose: null,
      numDisposedVariables: 0
    };

    if (0 == --this._refCount) {
      for (var t of this.layers) {
        e.numDisposedVariables += t.dispose().numDisposedVariables;
      }

      for (var _t110 of this.internalContainerRefs) {
        e.numDisposedVariables += _t110.dispose().numDisposedVariables;
      }
    }

    return e.refCountAfterDispose = this._refCount, e;
  }

  get trainable() {
    return this.trainable_;
  }

  set trainable(e) {
    this.layers.forEach(t => {
      t._trainableWeights.forEach(t => t.trainable = e);
    }), this.trainable_ = e;
  }

  get trainableWeights() {
    if (this._trainableWeights.length > 0) throw new ValueError$1("Container instance unexpectedly contains _trainableWeights.The trainable weights of a Container are a union of the trainable weights of its consituent Layers. Its own _trainableWeights must remain an empty Array.");
    if (!this.trainable) return [];
    var e = [];

    for (var t of this.layers) {
      e = e.concat(t.trainableWeights);
    }

    return e;
  }

  get nonTrainableWeights() {
    var e = [];

    for (var t of this.layers) {
      e.push(...t.nonTrainableWeights);
    }

    if (!this.trainable) {
      var _t111 = [];

      for (var _e143 of this.layers) {
        _t111.push(..._e143.trainableWeights);
      }

      return _t111.concat(e);
    }

    return e;
  }

  get weights() {
    return this.trainableWeights.concat(this.nonTrainableWeights);
  }

  loadWeights(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !0;
    var n = {};
    var r = 0;

    for (var _e144 of this.layers) {
      for (var _t112 of _e144.weights) {
        if (null != n[_t112.originalName]) throw new ValueError$1("Duplicate weight name: ".concat(_t112.originalName));
        n[_t112.originalName] = _t112, r++;
      }
    }

    var a = [];

    for (var _r36 in e) {
      var s = _r36;

      if (null == n[_r36]) {
        var _e145 = _r36.split("/");

        s = _e145.slice(0, -2).concat([_e145[_e145.length - 1]]).join("/");
      }

      if (null != n[s]) a.push([n[s], e[_r36]]);else if (t) throw new ValueError$1("Provided weight data has no target variable: ".concat(_r36));
      delete n[s];
    }

    if (t) {
      var _e146 = [];

      for (var _t113 in n) {
        _e146.push(_t113);
      }

      if (_e146.length > 0) throw new ValueError$1("".concat(_e146.length, " of ").concat(r, " weights are not set: ").concat(_e146));
    }

    batchSetValue$1(a);
  }

  updatedConfig() {
    var e = this.getConfig(),
        t = {};
    return t.className = this.getClassName(), t.config = e, t.kerasVersion = "tfjs-layers ".concat(version$d), t.backend = "TensorFlow.js", t;
  }

  toJSON(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !0;
    var n = convertTsToPythonic$1(this.updatedConfig());
    return t ? JSON.stringify(n) : n;
  }

  call(e, t) {
    return tidy$1(() => {
      e = toList$1(e);
      var n = new FeedDict$1();

      for (var _t114 = 0; _t114 < this.inputs.length; ++_t114) {
        n.add(this.inputs[_t114], e[_t114]);
      }

      return execute$1(this.outputs, n, t);
    });
  }

  computeMask(e, t) {
    return tidy$1(() => {
      var n;
      return e = toList$1(e), n = null == t ? pyListRepeat$1(null, e.length) : toList$1(t), this.runInternalGraph(e, n)[1];
    });
  }

  computeOutputShape(e) {
    var t = normalizeShapeList$1(e);
    if (t.length !== this.inputLayers.length) throw new ValueError$1("Invalid inputShape argument ".concat(e, ": model has ").concat(this.inputLayers.length, " tensor inputs."));
    var n = {};

    for (var _e147 = 0; _e147 < t.length; _e147++) {
      n[this.inputLayers[_e147].name + "_0_0"] = t[_e147];
    }

    var r = Object.keys(this.nodesByDepth).map(e => parseInt(e, 10)).sort(reverseNumberCompare$1);
    if (r.length > 1) for (var _e148 of r) {
      var _t115 = this.nodesByDepth[_e148];

      for (var _e149 of _t115) {
        var _t116 = _e149.outboundLayer;
        if (-1 !== this.inputLayers.map(e => e.id).indexOf(_t116.id)) continue;
        var _r37 = [];

        for (var _t117 = 0; _t117 < _e149.inboundLayers.length; _t117++) {
          _r37.push(n["".concat(_e149.inboundLayers[_t117].name, "_").concat(_e149.nodeIndices[_t117], "_").concat(_e149.tensorIndices[_t117])]);
        }

        var _a29 = normalizeShapeList$1(_t116.computeOutputShape(singletonOrArray$1(_r37))),
            _s17 = _t116.inboundNodes.indexOf(_e149);

        for (var _e150 = 0; _e150 < _a29.length; _e150++) {
          n["".concat(_t116.name, "_").concat(_s17, "_").concat(_e150)] = _a29[_e150];
        }
      }
    }
    var a = [],
        s = [];

    for (var _e151 = 0; _e151 < this.outputLayers.length; _e151++) {
      s.push("".concat(this.outputLayers[_e151].name, "_").concat(this.outputLayersNodeIndices[_e151], "_").concat(this.outputLayersTensorIndices[_e151]));
    }

    for (var _e152 = 0; _e152 < s.length; _e152++) {
      var _t118 = s[_e152];
      assert$5(_t118 in n), a.push(n[_t118]);
    }

    return singletonOrArray$1(a);
  }

  runInternalGraph(e, t) {
    null == t && (t = pyListRepeat$1(null, e.length));
    var n = {};

    for (var _r38 = 0; _r38 < this.inputs.length; ++_r38) {
      n[this.inputs[_r38].id] = [e[_r38], t[_r38]];
    }

    var r = Object.keys(this.nodesByDepth).map(e => parseInt(e, 10)).sort(reverseNumberCompare$1);

    for (var _e153 of r) {
      var _t119 = this.nodesByDepth[_e153];

      for (var _e154 of _t119) {
        var _t120 = _e154.outboundLayer,
            _r39 = _e154.inputTensors,
            _a30 = _e154.outputTensors,
            _s18 = new Array();

        for (var _e155 of _r39) {
          _e155.id in n && _s18.push(n[_e155.id]);
        }

        if (_s18.length === _r39.length) {
          var _r40 = void 0,
              _o9 = void 0,
              i = void 0,
              l = void 0,
              u = {};

          if (null != _e154.callArgs && (u = _e154.callArgs), 1 === _s18.length) {
            var [_e156, _n49] = _s18[0];
            null == u.mask && (u.mask = _n49), i = toList$1(_t120.call(_e156, u)), l = toList$1(_t120.computeMask(_e156, _n49)), _r40 = [_e156], _o9 = [_n49];
          } else _r40 = _s18.map(e => e[0]), _o9 = _s18.map(e => e[1]), null == u.mask && (u.mask = _o9), i = toList$1(_t120.call(_r40, u)), l = toList$1(_t120.computeMask(_r40, _o9));

          if (_t120.activityRegularizer) throw new NotImplementedError$1("LayersModel invocation with concrete Tensor value(s) in the presence of activity regularizer(s) is not supported yet.");

          for (var _e157 = 0; _e157 < _a30.length; ++_e157) {
            n[_a30[_e157].id] = [i[_e157], l[_e157]];
          }
        }
      }
    }

    var a = [],
        s = [],
        o = [];

    for (var _e158 of this.outputs) {
      assert$5(_e158.id in n, "Could not compute output ".concat(_e158.name, " : ").concat(_e158.id));
      var [_t121, _r41] = n[_e158.id];
      o.push(_t121.shape), a.push(_t121), s.push(_r41);
    }

    return [a, s, o];
  }

  buildNodeConversionMap(e) {
    var t = {};
    var n;

    for (var _e159 of this.layers) {
      n = _e159 instanceof Container$1 ? 1 : 0;

      for (var r = 0; r < _e159.inboundNodes.length; r++) {
        var a = Container$1.nodeKey(_e159, r);
        this.containerNodes.has(a) && (t[a] = n, n += 1);
      }
    }

    return t;
  }

  getLayer(e, t) {
    if (null != t) {
      if (this.layers.length <= t) throw new ValueError$1("Was asked to retrieve layer at index ".concat(t, ", but model only has ").concat(this.layers.length, " layer(s)."));
      return this.layers[t];
    }

    if (null == e) throw new ValueError$1("Provide either a layer name or layer index");

    for (var _t122 of this.layers) {
      if (_t122.name === e) return _t122;
    }

    throw new ValueError$1("No such layer: ".concat(e));
  }

  calculateLosses() {
    return tidy$1(() => {
      var e = [];

      for (var t of this.layers) {
        for (var n = 0; n < t.inboundNodes.length; ++n) {
          var r = Container$1.nodeKey(t, n);
          this.containerNodes.has(r) && e.push(...t.calculateLosses());
        }
      }

      return e;
    });
  }

  getConfig() {
    var e = {
      name: this.name
    },
        t = this.buildNodeConversionMap(this.layers),
        n = [];

    for (var _e160 of this.layers) {
      var _r42 = _e160.getClassName(),
          _a31 = _e160.getConfig(),
          s = [];

      for (var _n50 = 0; _n50 < _e160.inboundNodes.length; _n50++) {
        var _r43 = _e160.inboundNodes[_n50],
            _a32 = Container$1.nodeKey(_e160, _n50);

        var _o10 = {};

        if (this.containerNodes.has(_a32)) {
          if (_r43.callArgs) try {
            JSON.stringify(_r43.callArgs), _o10 = _r43.callArgs;
          } catch (t) {
            console.warn("Layer ".concat(_e160.name, " was passed non-serializable keyword arguments: ").concat(_r43.callArgs, ". They will not be included in the serialized model (and thus will be missing at deserialization time).")), _o10 = {};
          }

          if (_r43.inboundLayers.length > 0) {
            var _e161 = [];

            for (var _n51 = 0; _n51 < _r43.inboundLayers.length; _n51++) {
              var _a33 = _r43.inboundLayers[_n51],
                  _s19 = _r43.tensorIndices[_n51];
              var i = t[Container$1.nodeKey(_a33, _r43.nodeIndices[_n51])];
              null == i && (i = 0), _e161.push([_a33.name, i, _s19, _o10]);
            }

            s.push(_e161);
          }
        }
      }

      var o = {};
      o.name = _e160.name, o.className = _r42, o.config = _a31, o.inboundNodes = s, n.push(o);
    }

    e.layers = n;
    var r = [];

    for (var _e162 = 0; _e162 < this.inputLayers.length; _e162++) {
      var _n52 = this.inputLayers[_e162],
          _a34 = Container$1.nodeKey(_n52, this.inputLayersNodeIndices[_e162]);

      if (!this.containerNodes.has(_a34)) continue;
      var _s20 = t[_a34];
      null == _s20 && (_s20 = 0), r.push([_n52.name, _s20, this.inputLayersTensorIndices[_e162]]);
    }

    e.inputLayers = r;
    var a = [];

    for (var _e163 = 0; _e163 < this.outputLayers.length; _e163++) {
      var _n53 = this.outputLayers[_e163],
          _r44 = Container$1.nodeKey(_n53, this.outputLayersNodeIndices[_e163]);

      if (!this.containerNodes.has(_r44)) continue;
      var _s21 = t[_r44];
      null == _s21 && (_s21 = 0), a.push([_n53.name, _s21, this.outputLayersTensorIndices[_e163]]);
    }

    return e.outputLayers = a, e;
  }

  static fromConfig(e, t) {
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
    var a = {},
        s = {};

    function o(e, t) {
      e.name in s ? s[e.name].push(t) : s[e.name] = [t];
    }

    function i(e, t) {
      var n = [];
      var r;

      for (var _s22 of t) {
        var _i5 = _s22[0],
            _l5 = _s22[1],
            _u3 = _s22[2];
        if (r = null == _s22[3] ? {} : _s22[3], !(_i5 in a)) return void o(e, t);
        var _c3 = a[_i5];
        if (_c3.inboundNodes.length <= _l5) return void o(e, t);
        n.push(_c3.inboundNodes[_l5].outputTensors[_u3]);
      }

      n.length > 0 && e.apply(singletonOrArray$1(n), r);
    }

    function l(e) {
      var n = e.name,
          s = deserialize$1(e, null != t.customObjects ? t.customObjects : {});
      s.setFastWeightInitDuringBuild(r), a[n] = s, e.inboundNodes.forEach(e => {
        if (!(e instanceof Array)) throw new ValueError$1("Corrupted configuration, expected array for nodeData: ".concat(e));
        o(s, e);
      });
    }

    var u = t.name,
        c = t.layers;

    for (var _e164 of c) {
      l(_e164);
    }

    for (; !isObjectEmpty$1(s);) {
      for (var _e165 of c) {
        var _t123 = a[_e165.name];

        if (_t123.name in s) {
          var _e166 = s[_t123.name];
          delete s[_t123.name];

          for (var _n54 of _e166) {
            i(_t123, _n54);
          }
        }
      }
    }

    var p = [],
        d = [],
        h = t.inputLayers;

    for (var _e167 of h) {
      var _t124 = _e167[0],
          _n55 = _e167[1],
          _r45 = _e167[2];
      assert$5(_t124 in a), p.push(a[_t124].inboundNodes[_n55].outputTensors[_r45]);
    }

    var m = t.outputLayers;

    for (var _e168 of m) {
      var _t125 = _e168[0],
          _n56 = _e168[1],
          _r46 = _e168[2];
      assert$5(_t125 in a), d.push(a[_t125].inboundNodes[_n56].outputTensors[_r46]);
    }

    return new e({
      inputs: p,
      outputs: d,
      name: u
    });
  }

  get stateful() {
    if (this._stateful) throw new ValueError$1("Container instance unexpectedly has _stateful = true. The statefulness of a Container is determined by the Layers it contains. Its _stateful property must remain the default false.");

    for (var _e169 of this.layers) {
      if (_e169.stateful) return !0;
    }

    return !1;
  }

  resetStates() {
    tidy$1(() => {
      this.layers.forEach(e => {
        e.stateful && e.resetStates();
      });
    });
  }

}

function standardizeSampleOrClassWeights$1(e, t, n) {
  var r = t.length;
  if (null == e || Array.isArray(e) && 0 === e.length) return t.map(e => null);
  if (1 === r) return Array.isArray(e) && 1 === e.length ? e : "object" == typeof e && t[0] in e ? [e[t[0]]] : [e];

  if (Array.isArray(e)) {
    if (e.length !== r) throw new Error("Provided ".concat(n, " is an array of ").concat(e.length, " element(s), but the model has ").concat(r, " outputs. Make sure a set of weights is provided for each model output."));
    return e;
  }

  if ("object" == typeof e && Object.keys(e).length > 0 && "object" == typeof e[Object.keys(e)[0]]) {
    var _n57 = [];
    return t.forEach(t => {
      _n57.push(t in e ? e[t] : null);
    }), _n57;
  }

  throw new Error("The model has multiple (".concat(r, ") outputs, so ").concat(n, " must be either an array with ").concat(r, " elements or an object with ").concat(t, " keys. Provided ").concat(n, " not understood: ").concat(JSON.stringify(e)));
}

function standardizeClassWeights$1(e, t) {
  return standardizeSampleOrClassWeights$1(e, t, "classWeight");
}

function standardizeWeights$1(_x17, _x18, _x19, _x20) {
  return _standardizeWeights$.apply(this, arguments);
}

function _standardizeWeights$() {
  _standardizeWeights$ = _asyncToGenerator(function* (e, t, n, r) {
    if (null != t || null != r) throw new Error("Support sampleWeight is not implemented yet");

    if (null != n) {
      var _t762 = tidy$1(() => {
        if (1 === e.shape.length) return clone$1(e);

        if (2 === e.shape.length) {
          if (e.shape[1] > 1) return argMax$5(e, 1);
          if (1 === e.shape[1]) return reshape$6(e, [e.shape[0]]);
          throw new Error("Encountered unexpected last-dimension size (".concat(e.shape[1], ") during handling of class weights. The size is expected to be >= 1."));
        }

        throw new Error("Unexpected rank of target (y) tensor (".concat(e.rank, ") during handling of class weights. The rank is expected to be 1 or 2."));
      }),
          _r445 = Array.from(yield _t762.data());

      dispose$1(_t762);
      var a = [];
      return _r445.forEach(e => {
        if (null == n[e]) throw new Error("classWeight must contain all classes in the training data. The class ".concat(e, " exists in the data but not in classWeight"));
        a.push(n[e]);
      }), tensor1d$1(a, "float32");
    }

    return null;
  });
  return _standardizeWeights$.apply(this, arguments);
}

function computeWeightedLoss$2(e, t) {
  return mul$1(e, t);
}

var DEFAULT_VALIDATION_BATCH_SIZE$1 = 32;

function standardizeDataIteratorOutput$1(e, t) {
  var n, r;
  n = t.xs, r = t.ys, assert$6(null != n && null != r, () => "A Dataset iterator for fitDataset() is expected to generate objects of the form `{xs: xVal, ys: yVal}`, where the two values may be `tf.Tensor`, an array of Tensors, or a map of string to Tensor.  The provided Dataset instead generates ".concat(t));
  var a = flattenTensorOrArrayOrMap$1("input", e.inputNames, n),
      s = flattenTensorOrArrayOrMap$1("output", e.outputNames, r),
      o = a[0].shape[0];
  assert$6(a.length === e.inputs.length, () => "LayersModel has ".concat(e.inputs.length, " inputs, but the dataset provides ").concat(a.length, " inputs.  (Expected input keys: ").concat(JSON.stringify(e.inputNames), ")")), assert$6(s.length === e.outputs.length, () => "LayersModel has ".concat(e.outputs.length, " outputs, but the dataset provides ").concat(s.length, " outputs.  (Expected output keys: ").concat(JSON.stringify(e.outputNames), ")"));

  var _loop16 = function _loop16(_t126) {
    assert$6(a[_t126].shape[0] === o, () => "Batch size mismatch: input ".concat(e.inputNames[_t126], " has ").concat(a[_t126].shape[0], "; expected  ").concat(o, " based on input ").concat(e.inputNames[0], "."));
  };

  for (var _t126 = 0; _t126 < a.length; _t126++) {
    _loop16(_t126);
  }

  var _loop17 = function _loop17(_t127) {
    assert$6(s[_t127].shape[0] === o, () => "Batch size mismatch: output ".concat(e.outputNames[_t127], " has ").concat(s[_t127].shape[0], "; expected  ").concat(o, " based on input ").concat(e.inputNames[0], "."));
  };

  for (var _t127 = 0; _t127 < s.length; _t127++) {
    _loop17(_t127);
  }

  return {
    xs: a,
    ys: s
  };
}

function flattenTensorOrArrayOrMap$1(e, t, n) {
  if (n instanceof Tensor$1) return [n];
  if (Array.isArray(n)) return assert$6(n.length === t.length, () => "Received an array of ".concat(n.length, " Tensors, but expected ").concat(t.length, " to match the ").concat(e, " keys ").concat(t, ".")), n;
  {
    var r = [];

    for (var a of t) {
      if (null == n[a]) throw new ValueError$1("The feature data generated by the dataset lacks the required ".concat(e, " key '").concat(a, "'."));
      r.push(n[a]);
    }

    return r;
  }
}

function standardizeTensorValidationData$1(e) {
  if (3 === e.length) throw new NotImplementedError$1("Validation with sample weights is not implemented yet.");
  return {
    xs: e[0],
    ys: e[1]
  };
}

function fitDataset$1(_x21, _x22, _x23) {
  return _fitDataset$.apply(this, arguments);
}

function _fitDataset$() {
  _fitDataset$ = _asyncToGenerator(function* (e, t, n) {
    var r = null != n.batchesPerEpoch;
    if (assert$6(null != e.optimizer, () => "You must compile a model before training/testing. Use LayersModel.compile(modelCompileConfig)."), assert$6(null != n, () => "For fitDataset(), the 2nd argument (config) is required, but it is not provided in this call."), assert$6(null != n.epochs && n.epochs > 0 && Number.isInteger(n.epochs), () => "For fitDataset(), config.epochs is expected to be a positive integer, but got ".concat(n.epochs)), assert$6(!r || n.batchesPerEpoch > 0 && Number.isInteger(n.batchesPerEpoch), () => "For fitDataset(), config.batchesPerEpoch is expected to be a positive integer if specified, but got ".concat(n.batchesPerEpoch)), assert$6(null == n.validationSplit, () => "`validationSplit` is not supported by `fitDataset()`. Use validationData instead."), e.isTraining) throw new Error("Cannot start training because another fit() call is ongoing.");
    e.isTraining = !0;

    try {
      var a = null != n.validationData;
      var s, o;
      if (a) if (isDatasetObject$1(n.validationData)) assert$6(null == n.validationBatches || n.validationBatches > 0 && Number.isInteger(n.validationBatches), () => "For fitDataset() with dataset-based validation, config.validationBatches is expected not to be provided, or to be a positive integer, but got ".concat(n.validationBatches));else {
        var _e1140 = standardizeTensorValidationData$1(n.validationData);

        s = _e1140.xs, o = _e1140.ys;
      }
      var i = e.makeTrainFunction(),
          l = e.getDedupedMetricsNames();
      var u;
      u = a ? l.slice().concat(l.map(e => "val_" + e)) : l.slice();

      var c = standardizeCallbacks$1(n.callbacks, n.yieldEvery),
          _p40 = null == n.verbose ? 1 : n.verbose,
          {
        callbackList: d,
        history: h
      } = configureCallbacks$1(c, _p40, n.epochs, null, null, getStepsPerEpoch$1(t, n), null, a, u);

      d.setModel(e), e.history = h, yield d.onTrainBegin(), e.stopTraining_ = !1;
      var m = null == n.initialEpoch ? 0 : n.initialEpoch,
          f = yield t.iterator();

      for (; m < n.epochs;) {
        var _u64 = {};
        yield d.onEpochBegin(m);
        var _c42 = 0,
            _p41 = 0;

        for (r || (f = yield t.iterator()); !r || _c42 < n.batchesPerEpoch;) {
          var _t763 = yield f.next();

          if (r && _t763.done) {
            console.warn("You provided `batchesPerEpoch` as ".concat(n.batchesPerEpoch, ", but your dataset iterator ran out of data after ").concat(_c42, " batches; interrupting training. Make sure that your dataset can generate at least `batchesPerEpoch * epochs` batches (in this case, ") + n.batchesPerEpoch * n.epochs + " batches). You may need to use the repeat() function when building your dataset.");
            break;
          }

          if (null != _t763.value) {
            var {
              xs: _r446,
              ys: _a317
            } = standardizeDataIteratorOutput$1(e, _t763.value),
                _s224 = {};
            _s224.batch = _p41, _s224.size = _r446[0].shape[0], yield d.onBatchBegin(_p41, _s224);
            var _o159 = [];

            if (null != n.classWeight) {
              var _t764 = standardizeClassWeights$1(n.classWeight, e.outputNames);

              for (var _e1141 = 0; _e1141 < _t764.length; ++_e1141) {
                _o159.push(yield standardizeWeights$1(_a317[_e1141], null, _t764[_e1141]));
              }
            }

            var _u65 = _r446.concat(_a317).concat(_o159),
                _h25 = i(_u65);

            dispose$1(_u65);

            for (var _e1142 = 0; _e1142 < l.length; ++_e1142) {
              var _t765 = _h25[_e1142];
              _s224[l[_e1142]] = _t765, keep$1(_t765);
            }

            yield d.onBatchEnd(_p41, _s224), disposeTensorsInLogs$1(_s224), _p41++, _c42++;
          }

          if (r ? _c42 >= n.batchesPerEpoch : _t763.done) {
            if (a) {
              var _t766 = void 0;

              _t766 = isDatasetObject$1(n.validationData) ? toList$1(yield e.evaluateDataset(n.validationData, {
                batches: n.validationBatches
              })) : toList$1(e.evaluate(s, o, {
                batchSize: null == n.validationBatchSize ? DEFAULT_VALIDATION_BATCH_SIZE$1 : n.validationBatchSize,
                verbose: 0
              }));

              for (var _n451 = 0; _n451 < e.metricsNames.length; ++_n451) {
                _u64["val_".concat(e.metricsNames[_n451])] = _t766[_n451];
              }
            }

            break;
          }

          if (e.stopTraining_) break;
        }

        if (yield d.onEpochEnd(m, _u64), m++, e.stopTraining_) break;
      }

      return yield d.onTrainEnd(), yield e.history.syncData(), e.history;
    } finally {
      e.isTraining = !1;
    }
  });
  return _fitDataset$.apply(this, arguments);
}

function getStepsPerEpoch$1(e, t) {
  var n = null;
  return null != t.batchesPerEpoch ? n = t.batchesPerEpoch : Number.isFinite(e.size) && (n = e.size), n;
}

function isDatasetObject$1(e) {
  return "function" == typeof e.iterator;
}

function isLazyIteratorObject$1(e) {
  return "function" == typeof e.next;
}

function evaluateDataset$1(_x24, _x25, _x26) {
  return _evaluateDataset$.apply(this, arguments);
}

function _evaluateDataset$() {
  _evaluateDataset$ = _asyncToGenerator(function* (e, t, n) {
    var r = null != (n = n || {}).batches,
        a = e.testFunction;
    var s = [];
    if (n.verbose > 0) throw new NotImplementedError$1("Verbose mode is not implemented yet.");
    assert$6(!r || n.batches > 0 && Number.isInteger(n.batches), () => "Test loop expects `batches` to be a positive integer, but received ".concat(JSON.stringify(n.batches)));
    var o = isLazyIteratorObject$1(t) ? t : yield t.iterator();
    var i = 0,
        l = 0;

    var _loop61 = function* _loop61() {
      var t = yield o.next();

      if (s = tidy$1(() => {
        if (t.value) {
          (function () {
            var {
              xs: n,
              ys: r
            } = standardizeDataIteratorOutput$1(e, t.value),
                o = n.concat(r),
                u = tidy$1(() => a(o));
            if (dispose$1(o), 0 === l) for (var _e1144 = 0; _e1144 < u.length; ++_e1144) {
              s.push(scalar$1(0));
            }
            var c = o[0].shape[0];

            var _loop62 = function _loop62(_e1145) {
              var t = u[_e1145],
                  n = s[_e1145];
              s[_e1145] = tidy$1(() => add$5(s[_e1145], mul$1(c, t))), l > 0 && dispose$1(n);
            };

            for (var _e1145 = 0; _e1145 < u.length; ++_e1145) {
              _loop62(_e1145);
            }

            dispose$1(u), i += c, ++l;
          })();
        }

        return s;
      }), t.done) {
        r && console.warn("Your dataset iterator ran out of data during evaluateDataset(). Interrupting evalution. Make sure that your dataset can generate at least `batches` batches (in this case, ".concat(n.batches, " batches). You may need to use the repeat() function when building your dataset."));
        return "break";
      }
    };

    for (; !r || l < n.batches;) {
      var _ret5 = yield* _loop61();

      if (_ret5 === "break") break;
    }

    for (var _e1143 = 0; _e1143 < s.length; ++_e1143) {
      var _t767 = s[_e1143];
      s[_e1143] = div$3(s[_e1143], i), dispose$1(_t767);
    }

    return singletonOrArray$1(s);
  });
  return _evaluateDataset$.apply(this, arguments);
}

function checkBatchSize$1(e) {
  assert$6(e > 0 && Number.isInteger(e), () => "batchSize is required to be a positive integer, but got ".concat(e));
}

function sliceArrays$1(e, t, n) {
  return null == e ? [null] : Array.isArray(e) ? e.map(e => sliceAlongFirstAxis$1(e, t, n - t)) : sliceAlongFirstAxis$1(e, t, n - t);
}

function sliceArraysByIndices$1(e, t) {
  return tidy$1(() => null == e ? null : Array.isArray(e) ? e.map(e => sliceArraysByIndices$1(e, t)) : gather$2(e, "int32" === t.dtype ? t : cast$7(t, "int32")));
}

function makeBatches$1(e, t) {
  var n = [];
  var r = 0,
      a = null;

  for (; r < e;) {
    a = r + t, a >= e && (a = e), n.push([r, a]), r = a;
  }

  return n;
}

function fitLoop$1(_x27, _x28, _x29, _x30, _x31, _x32, _x33, _x34, _x35, _x36, _x37, _x38, _x39, _x40, _x41) {
  return _fitLoop$.apply(this, arguments);
}

function _fitLoop$() {
  _fitLoop$ = _asyncToGenerator(function* (e, t, n, r, a, s, o, i, l, u, c, p, d, h, m) {
    null == a && (a = 32), null == s && (s = 1), null == c && (c = !0), null == d && (d = 0);
    var f = !1;
    if (null != l && null != u && (f = !0), null != m && (f = !0, null == h)) throw new ValueError$1("Can only use `validationSteps` when doing step-wise training, i.e., `stepsPerEpoch` must be set.");
    var g = e.checkNumSamples(n, a, h, "steps_per_epoch");
    var $;
    null != g && ($ = range$7(0, g)), null == o && (o = 1);
    var {
      callbackList: y,
      history: b
    } = configureCallbacks$1(i, o, s, d, g, h, a, f, p);
    y.setModel(e), e.history = b, yield y.onTrainBegin(), e.stopTraining_ = !1;

    var _loop63 = function* _loop63(_o160) {
      yield y.onEpochBegin(_o160);
      var s = {};
      if (null != h) throw new NotImplementedError$1("stepsPerEpoch mode is not implemented yet.");
      {
        yield* function* () {
          if ("batch" === c) throw new NotImplementedError$1("batch shuffling is not implemneted yet");
          c && shuffle$1($);
          var o = tensor1d$1($),
              i = makeBatches$1(g, a);

          var _loop64 = function* _loop64(_c43) {
            var p = {};
            if (yield y.onBatchBegin(_c43, p), tidy$1(() => {
              var d = i[_c43][0],
                  h = i[_c43][1],
                  m = sliceAlongFirstAxis$1(o, d, h - d);
              p.batch = _c43, p.size = h - d;
              var g = sliceArraysByIndices$1(n, m),
                  $ = t(g);

              for (var _e1146 = 0; _e1146 < r.length; ++_e1146) {
                var _t768 = $[_e1146];
                p[r[_e1146]] = _t768, keep$1(_t768);
              }

              if (_c43 === i.length - 1 && f) {
                var _t769 = e.testLoop(l, u, a);

                for (var _e1147 = 0; _e1147 < r.length; ++_e1147) {
                  var _n452 = r[_e1147],
                      _a318 = _t769[_e1147];
                  keep$1(_a318), s["val_" + _n452] = _a318;
                }
              }
            }), yield y.onBatchEnd(_c43, p), disposeTensorsInLogs$1(p), e.stopTraining_) return "break";
          };

          for (var _c43 = 0; _c43 < i.length; ++_c43) {
            var _ret7 = yield* _loop64(_c43);

            if (_ret7 === "break") break;
          }

          o.dispose();
        }();
      }
      if (yield y.onEpochEnd(_o160, s), e.stopTraining_) return "break";
    };

    for (var _o160 = d; _o160 < s; ++_o160) {
      var _ret6 = yield* _loop63(_o160);

      if (_ret6 === "break") break;
    }

    return yield y.onTrainEnd(), yield e.history.syncData(), e.history;
  });
  return _fitLoop$.apply(this, arguments);
}

function fitTensors$1(_x42, _x43, _x44) {
  return _fitTensors$.apply(this, arguments);
}

function _fitTensors$() {
  _fitTensors$ = _asyncToGenerator(function* (e, t, n) {
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : {};
    if (e.isTraining) throw new Error("Cannot start training because another fit() call is ongoing.");
    var a, s, o, i, l, u, c;
    e.isTraining = !0;

    try {
      var _p42 = null == r.batchSize ? 32 : r.batchSize;

      checkBatchSize$1(_p42);
      var d = !1,
          h = yield e.standardizeUserData(t, n, r.sampleWeight, r.classWeight, d, _p42);
      a = h[0], s = h[1], c = h[2];
      var m,
          f = !1;

      if (null != r.validationData && r.validationData.length > 0) {
        if (f = !0, 2 !== r.validationData.length) throw 3 === r.validationData.length ? new NotImplementedError$1("validationData including sample weights is not supported yet.") : new ValueError$1("When passing validation data, it must contain 2 (valX, valY) or 3 (valX, valY, valSampleWeight) items; ".concat(r.validationData, " is invalid."));
        o = r.validationData[0], i = r.validationData[1];

        var _t770 = !0,
            _n453 = yield e.standardizeUserData(o, i, null, null, _t770, _p42);

        l = _n453[0], u = _n453[1], m = l.concat(u);
      } else if (null != r.validationSplit && r.validationSplit > 0 && r.validationSplit < 1) {
        f = !0;

        var _e1148 = Math.floor(a[0].shape[0] * (1 - r.validationSplit)),
            _t771 = a[0].shape[0];

        l = sliceArrays$1(a, _e1148, _t771), a = sliceArrays$1(a, 0, _e1148), u = sliceArrays$1(s, _e1148, _t771), s = sliceArrays$1(s, 0, _e1148), m = l.concat(u);
      } else null != r.validationSteps && (f = !0);

      var g = a.concat(s).concat(c);
      e.checkTrainableWeightsConsistency();
      var $ = e.makeTrainFunction(),
          y = e.getDedupedMetricsNames();
      var b, x;
      f ? (e.makeTestFunction(), b = e.testFunction, x = y.slice().concat(y.map(e => "val_" + e))) : (b = null, m = [], x = y.slice());
      var v = standardizeCallbacks$1(r.callbacks, r.yieldEvery);
      return yield fitLoop$1(e, $, g, y, _p42, r.epochs, r.verbose, v, b, m, r.shuffle, x, r.initialEpoch, null, null);
    } finally {
      e.isTraining = !1, disposeNewTensors$1(a, t), disposeNewTensors$1(s, n), disposeNewTensors$1(l, o), disposeNewTensors$1(u, i), null != c && dispose$1(c);
    }
  });
  return _fitTensors$.apply(this, arguments);
}

function ensureTensorsRank2OrHigher$1(e) {
  var t = [];
  e instanceof Tensor$1 && (e = [e]);

  for (var n = 0; n < e.length; ++n) {
    var r = e[n];
    if (1 === r.rank) t.push(expandDims$6(r, 1));else {
      if (0 === r.rank) throw new Error("Expected tensor to be at least 1D, but received a 0D tensor (scalar).");
      t.push(r);
    }
  }

  return t;
}

function disposeNewTensors$1(e, t) {
  if (null == e) return;
  var n = [];
  if (t instanceof Tensor$1) n.push(t.id);else if (Array.isArray(t)) t.forEach(e => n.push(e.id));else if (null != t) for (var _e170 in t) {
    n.push(t[_e170].id);
  }
  var r = [];
  if (e instanceof Tensor$1) -1 === n.indexOf(e.id) && r.push(e);else if (Array.isArray(e)) e.forEach(e => {
    -1 === n.indexOf(e.id) && r.push(e);
  });else if (null != e) for (var _t128 in e) {
    var a = e[_t128];
    -1 === n.indexOf(a.id) && r.push(a);
  }
  r.forEach(e => {
    e.isDisposed || e.dispose();
  });
}

function isDataTensor$1(e) {
  return e instanceof Tensor$1;
}

function isDataArray$1(e) {
  return Array.isArray(e);
}

function isDataDict$1(e) {
  return !isDataTensor$1(e) && !isDataArray$1(e);
}

function standardizeInputData$1(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !0;
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : "";

  if (null == t || 0 === t.length) {
    if (null != e) {
      var _t129 = !1;

      if (isDataArray$1(e) && e.length > 0) _t129 = !0;else if (isDataDict$1(e)) {
        for (var _n58 in e) {
          if (e.hasOwnProperty(_n58)) {
            _t129 = !0;
            break;
          }
        }
      } else _t129 = !0;
      if (_t129) throw new ValueError$1("Error when checking model ".concat(a, " expected no data, but got ").concat(e));
    }

    return [];
  }

  if (null == e) return t.map(e => null);
  var s;

  if (isDataDict$1(e)) {
    e = e, s = [];

    for (var _n59 of t) {
      if (null == e[_n59]) throw new ValueError$1("No data provided for \"".concat(_n59, "\". Need data for each key in: ").concat(t));
      s.push(e[_n59]);
    }
  } else if (isDataArray$1(e)) {
    if ((e = e).length !== t.length) throw new ValueError$1("Error when checking model ".concat(a, ": the Array of Tensors that you are passing to your model is not the size the model expected. Expected to see ").concat(t.length, " Tensor(s), but instead got the following list of Tensor(s): ").concat(e));
    s = e;
  } else {
    if (e = e, t.length > 1) throw new ValueError$1("The model ".concat(a, " expects ").concat(t.length, " Tensor(s), but only received one Tensor. Found: Tensor with shape ").concat(e.shape));
    s = [e];
  }

  if (s = ensureTensorsRank2OrHigher$1(s), null != n) for (var _e171 = 0; _e171 < t.length; ++_e171) {
    if (null == n[_e171]) continue;
    var o = s[_e171];
    if (o.shape.length !== n[_e171].length) throw new ValueError$1("Error when checking ".concat(a, ": expected ").concat(t[_e171], " to have ").concat(n[_e171].length, " dimension(s). but got array with shape ").concat(o.shape));

    for (var _s23 = 0; _s23 < n[_e171].length; ++_s23) {
      if (0 === _s23 && !r) continue;
      var i = o.shape[_s23],
          l = n[_e171][_s23];
      if (null != l && l >= 0 && i !== l) throw new ValueError$1("Error when checking ".concat(a, ": expected ").concat(t[_e171], " to have shape [").concat(n[_e171], "], but got array with shape [").concat(o.shape, "]."));
    }
  }
  return s;
}

function checkArrayLengths$1(e, t, n) {
  var r = unique$6(e.map(e => e.shape[0]));
  r.sort();
  var a = unique$6(t.map(e => e.shape[0]));
  if (a.sort(), r.length > 1) throw new ValueError$1("All input Tensors (x) should have the same number of samples. Got array shapes: ".concat(JSON.stringify(e.map(e => e.shape))));
  if (a.length > 1) throw new ValueError$1("All target Tensors (y) should have the same number of samples. Got array shapes: ".concat(JSON.stringify(t.map(e => e.shape))));
  if (r.length > 0 && a.length > 0 && !arraysEqual$1(r, a)) throw new ValueError$1("Input Tensors should have the same number of samples as target Tensors. Found ".concat(r[0], " input sample(s) and ").concat(a[0], " target sample(s)."));
}

function checkLossAndTargetCompatibility$1(e, t, n) {
  var r = [meanSquaredError$3, binaryCrossentropy$4, categoricalCrossentropy$4];

  for (var a = 0; a < e.length; ++a) {
    var s = e[a],
        o = t[a],
        i = n[a];

    if (null != o) {
      if (o === categoricalCrossentropy$4 && 1 === s.shape[s.shape.length - 1]) throw new ValueError$1("You are passing a target array of shape ".concat(s.shape, " while using a loss 'categorical_crossentropy'. 'categorical_crossentropy'expects targets to be binary matrices (1s and 0s) of shape [samples, classes]."));

      if (-1 !== r.indexOf(o)) {
        var _e172 = s.shape.slice(1),
            _t130 = i.slice(1);

        for (var _n60 = 0; _n60 < _e172.length; ++_n60) {
          var _r47 = _e172[_n60],
              _a35 = _t130[_n60];
          if (null != _a35 && _r47 !== _a35) throw new ValueError$1("A target Tensor with shape ".concat(s.shape, " was passed for an output of shape ").concat(i, ", while using a loss function that expects targets to have the same shape as the output."));
        }
      }
    }
  }
}

function checkInputData$1(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !0;
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : "";
  var s;

  if (Array.isArray(e)) {
    if (e.length !== t.length) throw new ValueError$1("Error when checking model ".concat(a, ": the Array of Tensors that you are passing to your model is not the size the the model expected. Expected to see ").concat(t.length, " Tensor(s), but instead got ").concat(e.length, " Tensors(s)."));
    s = e;
  } else {
    if (t.length > 1) throw new ValueError$1("The model expects ".concat(t.length, " ").concat(a, " Tensors, but only received one Tensor. Found: array with shape ").concat(JSON.stringify(e.shape), "."));
    s = [e];
  }

  if (null != n) for (var _e173 = 0; _e173 < t.length; ++_e173) {
    if (null == n[_e173]) continue;
    var o = s[_e173];
    if (o.shape.length !== n[_e173].length) throw new ValueError$1("Error when checking ".concat(a, ": expected ").concat(t[_e173], " to have ").concat(n[_e173].length, " dimension(s), but got array with shape ").concat(JSON.stringify(o.shape)));

    for (var _s24 = 0; _s24 < n[_e173].length; ++_s24) {
      if (0 === _s24 && !r) continue;
      var i = o.shape[_s24],
          l = n[_e173][_s24];
      if (null != l && l !== i) throw new ValueError$1("Error when checking ".concat(a, ": expected ").concat(t[_e173], " to have shape ").concat(JSON.stringify(n[_e173]), " but got array with shape ").concat(JSON.stringify(o.shape), "."));
    }
  }
}

function collectMetrics$1(e, t) {
  if (null == e || Array.isArray(e) && 0 === e.length) return t.map(e => []);
  var n;
  if ("string" == typeof e || "function" == typeof e) n = [e];else {
    if (!Array.isArray(e) && "object" != typeof e) throw new TypeError("Type of metrics argument not understood. Expected an string,function, Array, or Object, found: ".concat(e));
    n = e;
  }
  if (Array.isArray(n)) return t.map(e => n);
  {
    var _e174 = [];

    for (var r of t) {
      var _t131 = n.hasOwnProperty(r) ? n[r] : [];

      Array.isArray(_t131) || (_t131 = [_t131]), _e174.push(_t131);
    }

    return _e174;
  }
}

var LAYERS_MODEL_FORMAT_NAME$1 = "layers-model";

class LayersModel$1 extends Container$1 {
  constructor(e) {
    super(e), this.isTraining = !1;
  }

  summary(e, t) {
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : console.log;
    if (!this.built) throw new ValueError$1("This model has never been called, thus its weights have not been created yet. So no summary can be displayed. Build the model first (e.g., by calling it on some test data).");
    printSummary$1(this, e, t, n);
  }

  compile(e) {
    var _this57 = this;

    if (null == e.loss && (e.loss = []), this.loss = e.loss, "string" == typeof e.optimizer) this.optimizer_ = getOptimizer$1(e.optimizer), this.isOptimizerOwned = !0;else {
      if (!(e.optimizer instanceof Optimizer$1)) throw new ValueError$1("User-defined optimizer must be an instance of tf.Optimizer.");
      this.optimizer_ = e.optimizer, this.isOptimizerOwned = !1;
    }
    var t = [];
    if (Array.isArray(e.loss) || "string" == typeof e.loss || "function" == typeof e.loss) {
      if (Array.isArray(e.loss)) {
        if (e.loss.length !== this.outputs.length) throw new ValueError$1("When passing an Array as loss, it should have one entry per model output. The model has ".concat(this.outputs.length, " output(s), but you passed loss=").concat(e.loss, "."));
        t = e.loss.map(e => get$3(e));
      } else {
        var _n61 = get$3(e.loss);

        this.outputs.forEach(e => {
          t.push(_n61);
        });
      }
    } else {
      e.loss = e.loss;

      for (var _t132 in e.loss) {
        if (-1 === this.outputNames.indexOf(_t132)) throw new ValueError$1("Unknown entry in loss dictionary: \"".concat(_t132, "\". Only expected the following keys: ").concat(this.outputNames));
      }

      for (var _n62 of this.outputNames) {
        null == e.loss[_n62] && console.warn("Output \"".concat(_n62, "\" is missing from loss dictionary. We assume this was done on purpose, and we will not be expecting data to be passed to ").concat(_n62, " during training")), t.push(get$3(e.loss[_n62]));
      }
    }
    this.lossFunctions = t, this.feedOutputNames = [], this.feedOutputShapes = [], this.feedLossFns = [];

    for (var _e175 = 0; _e175 < this.outputs.length; ++_e175) {
      var _t133 = this.internalOutputShapes[_e175];
      this.feedOutputNames.push(this.outputNames[_e175]), this.feedOutputShapes.push(_t133), this.feedLossFns.push(this.lossFunctions[_e175]);
    }

    var n = [];
    this.metrics = e.metrics, this.metricsNames = ["loss"], this.metricsTensors = [], nameScope$1("loss", () => {
      for (var _e176 = 0; _e176 < this.outputs.length; ++_e176) {
        if (-1 !== n.indexOf(_e176)) continue;
        var _t134 = this.lossFunctions[_e176];
        this.outputs.length > 1 && (this.metricsTensors.push([_t134, _e176]), this.metricsNames.push(this.outputNames[_e176] + "_loss"));
      }
    });

    var r = collectMetrics$1(e.metrics, this.outputNames),
        a = (e, t, n) => {
      this.outputNames.length > 1 && (t = this.outputNames[e] + "_" + t), this.metricsNames.push(t), this.metricsTensors.push([n, e]);
    };

    nameScope$1("metric", () => {
      var _loop18 = function _loop18(_e177) {
        -1 === n.indexOf(_e177) && (t => {
          var n, r, s;

          for (var o of t) {
            if ("string" == typeof o && -1 !== ["accuracy", "acc", "crossentropy", "ce"].indexOf(o)) {
              var _t136 = _this57.internalOutputShapes[_e177];

              var _a36 = void 0;

              1 === _t136[_t136.length - 1] || _this57.lossFunctions[_e177] === binaryCrossentropy$4 ? -1 !== ["accuracy", "acc"].indexOf(o) ? r = binaryAccuracy$2 : -1 !== ["crossentropy", "ce"].indexOf(o) && (r = binaryCrossentropy$3) : _this57.lossFunctions[_e177] === sparseCategoricalCrossentropy$3 ? -1 !== ["accuracy", "acc"].indexOf(o) ? r = sparseCategoricalAccuracy$2 : -1 !== ["crossentropy", "ce"].indexOf(o) && (r = sparseCategoricalCrossentropy$2) : -1 !== ["accuracy", "acc"].indexOf(o) ? r = categoricalAccuracy$2 : -1 !== ["crossentropy", "ce"].indexOf(o) && (r = categoricalCrossentropy$3), -1 !== ["accuracy", "acc"].indexOf(o) ? _a36 = "acc" : -1 !== ["crossentropy", "ce"].indexOf(o) && (_a36 = "ce"), s = r, n = "" + _a36;
            } else {
              var _e178 = get$2(o);

              s = _e178, n = "" + getLossOrMetricName$1(o);
            }

            var _t135 = void 0;

            nameScope$1(n, () => {
              _t135 = s;
            }), a(_e177, n, _t135);
          }
        })(r[_e177]);
      };

      for (var _e177 = 0; _e177 < this.outputs.length; ++_e177) {
        _loop18(_e177);
      }
    }), this.collectedTrainableWeights = this.trainableWeights;
  }

  checkTrainableWeightsConsistency() {
    null != this.collectedTrainableWeights && this.trainableWeights.length !== this.collectedTrainableWeights.length && console.warn("Discrepancy between trainableweights and collected trainable weights. Did you set `model.trainable` without calling `model.compile()` afterwards?");
  }

  evaluate(e, t) {
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};
    var r = null == n.batchSize ? 32 : n.batchSize;
    checkBatchSize$1(r);
    var a = this.standardizeUserDataXY(e, t, !0, r);

    try {
      var s = a[0].concat(a[1]);
      return this.makeTestFunction(), singletonOrArray$1(this.testLoop(this.testFunction, s, r, n.verbose, n.steps));
    } finally {
      disposeNewTensors$1(a[0], e), disposeNewTensors$1(a[1], t);
    }
  }

  evaluateDataset(e, t) {
    var _this58 = this;

    return _asyncToGenerator(function* () {
      return _this58.makeTestFunction(), evaluateDataset$1(_this58, e, t);
    })();
  }

  checkNumSamples(e, t, n) {
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : "steps";
    var a;

    if (null != n) {
      if (a = null, null != t) throw new ValueError$1("If ".concat(r, " is set, batchSize must be null or undefined.Got batchSize = ").concat(t));
    } else {
      if (null == e) throw new ValueError$1("Either the input data should have a defined shape, or ".concat(r, " shoud be specified."));
      a = Array.isArray(e) ? e[0].shape[0] : e.shape[0];
    }

    return a;
  }

  execute(e, t) {
    if (Array.isArray(t) && 0 === t.length) throw new ValueError$1("`outputs` is an empty Array, which is not allowed.");
    var n = Array.isArray(t),
        r = this.retrieveSymbolicTensors(n ? t : [t]),
        a = new FeedDict$1();

    if (e instanceof Tensor$1 && (e = [e]), Array.isArray(e)) {
      if (e.length !== this.inputs.length) throw new ValueError$1("The number of inputs provided (".concat(e.length, ") does not match the number of inputs of this model (").concat(this.inputs.length, ")."));

      for (var _t137 = 0; _t137 < this.inputs.length; ++_t137) {
        a.add(this.inputs[_t137], e[_t137]);
      }
    } else for (var _t138 of this.inputs) {
      var _n63 = e[_t138.name];
      if (null == _n63) throw new ValueError$1("No value is provided for the model's input ".concat(_t138.name));
      a.add(_t138, _n63);
    }

    var s = execute$1(r, a);
    return n ? s : s[0];
  }

  retrieveSymbolicTensors(e) {
    var t = pyListRepeat$1(null, e.length);
    var n = e.length;

    for (var r of this.layers) {
      var a = Array.isArray(r.output) ? r.output : [r.output],
          s = a.map(e => e.name);

      for (var _r48 = 0; _r48 < e.length; ++_r48) {
        var o = s.indexOf(e[_r48]);
        if (-1 !== o && (t[_r48] = a[o], n--), 0 === n) break;
      }

      if (0 === n) break;
    }

    if (n > 0) {
      var _n64 = [];
      throw t.forEach((t, r) => {
        null == t && _n64.push(e[r]);
      }), new ValueError$1("Cannot find SymbolicTensors for output name(s): ".concat(JSON.stringify(_n64)));
    }

    return t;
  }

  predictLoop(e) {
    var _this59 = this;

    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 32;
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
    return tidy$1(() => {
      var r = this.checkNumSamples(e);
      if (n) throw new NotImplementedError$1("Verbose predictLoop() is not implemented yet.");
      var a = makeBatches$1(r, t),
          s = this.outputs.map(e => []);

      var _loop19 = function _loop19(_t139) {
        tidy$1(() => {
          var n = sliceArrays$1(e, a[_t139][0], a[_t139][1]),
              r = [];
          if (Array.isArray(n)) for (var _e179 = 0; _e179 < n.length; ++_e179) {
            r.push({
              key: _this59.inputs[_e179],
              value: n[_e179]
            });
          } else r.push({
            key: _this59.inputs[0],
            value: n
          });
          var s = new FeedDict$1(r);
          return execute$1(_this59.outputs, s);
        }).forEach((e, t) => s[t].push(e));
      };

      for (var _t139 = 0; _t139 < a.length; ++_t139) {
        _loop19(_t139);
      }

      return singletonOrArray$1(s.map(e => concat$5(e, 0)));
    });
  }

  predict(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};
    var n = ensureTensorsRank2OrHigher$1(e);
    checkInputData$1(n, this.inputNames, this.feedInputShapes, !1);

    try {
      var r = null == t.batchSize ? 32 : t.batchSize;
      return checkBatchSize$1(r), this.predictLoop(n, r);
    } finally {
      disposeNewTensors$1(n, e);
    }
  }

  predictOnBatch(e) {
    checkInputData$1(e, this.inputNames, this.feedInputShapes, !0);
    var t = (Array.isArray(e) ? e[0] : e).shape[0];
    return this.predictLoop(e, t);
  }

  standardizeUserDataXY(e, t) {
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !0;
    var r = arguments.length > 3 ? arguments[3] : undefined;
    if (null == this.optimizer_) throw new RuntimeError$1("You must compile a model before training/testing. Use LayersModel.compile(modelCompileArgs).");
    var a = [];

    for (var _e180 = 0; _e180 < this.feedOutputShapes.length; ++_e180) {
      var _t140 = this.feedOutputShapes[_e180];
      a.push(this.feedLossFns[_e180] === sparseCategoricalCrossentropy$3 ? _t140.slice(0, _t140.length - 1).concat([1]) : _t140);
    }

    if (checkArrayLengths$1(e = standardizeInputData$1(e, this.feedInputNames, this.feedInputShapes, !1, "input"), t = standardizeInputData$1(t, this.feedOutputNames, a, !1, "target")), checkLossAndTargetCompatibility$1(t, this.feedLossFns, this.feedOutputShapes), this.stateful && null != r && r > 0 && e[0].shape[0] % r != 0) throw new ValueError$1("In a stateful network, you should only pass inputs with a number of samples that is divisible by the batch size ".concat(r, ". Found: ").concat(e[0].shape[0], " sample(s)."));
    return [e, t];
  }

  standardizeUserData(e, t, n, r) {
    var _arguments = arguments,
        _this60 = this;

    return _asyncToGenerator(function* () {
      var a = _arguments.length > 4 && _arguments[4] !== undefined ? _arguments[4] : !0;
      var s = _arguments.length > 5 ? _arguments[5] : undefined;

      var [o, i] = _this60.standardizeUserDataXY(e, t, a, s);

      if (null != n) throw new Error("sample weight is not supported yet.");
      var l = null;

      if (null != r) {
        var _e181 = standardizeClassWeights$1(r, _this60.outputNames);

        l = [];

        for (var _t141 = 0; _t141 < _e181.length; ++_t141) {
          l.push(yield standardizeWeights$1(i[_t141], null, _e181[_t141]));
        }
      }

      return [o, i, l];
    })();
  }

  testLoop(e, t, n) {
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 0;
    var a = arguments.length > 4 ? arguments[4] : undefined;
    return tidy$1(() => {
      var s = this.checkNumSamples(t, n, a, "steps"),
          o = [];
      if (r > 0) throw new NotImplementedError$1("Verbose mode is not implemented yet.");
      if (null != a) throw new NotImplementedError$1("steps mode in testLoop() is not implemented yet");
      {
        var _r49 = makeBatches$1(s, n),
            _a37 = tensor1d$1(range$7(0, s));

        for (var _n65 = 0; _n65 < _r49.length; ++_n65) {
          var _s25 = _r49[_n65][0],
              i = _r49[_n65][1],
              l = sliceAlongFirstAxis$1(_a37, _s25, i - _s25),
              u = sliceArraysByIndices$1(t, l),
              c = e(u);
          if (0 === _n65) for (var _e182 = 0; _e182 < c.length; ++_e182) {
            o.push(scalar$1(0));
          }

          for (var _e183 = 0; _e183 < c.length; ++_e183) {
            o[_e183] = add$5(o[_e183], mul$1(i - _s25, c[_e183]));
          }
        }

        for (var _e184 = 0; _e184 < o.length; ++_e184) {
          o[_e184] = div$3(o[_e184], s);
        }
      }
      return o;
    });
  }

  getDedupedMetricsNames() {
    var e = this.metricsNames,
        t = [];

    for (var n = 0; n < e.length; ++n) {
      var r = e[n];
      var a = r;
      count$1(e, r) > 1 && (a += "_".concat(count$1(e.slice(0, n), r))), t.push(a);
    }

    return t;
  }

  makeTrainFunction() {
    return e => {
      var t = [],
          n = e.slice(0, this.inputs.length),
          r = e.slice(this.inputs.length, this.inputs.length + this.outputs.length),
          a = e.slice(this.inputs.length + this.outputs.length, this.inputs.length + 2 * this.outputs.length),
          s = [],
          o = this.collectedTrainableWeights.map(e => e.read());
      return [this.optimizer_.minimize(() => {
        var e = [];

        for (var _t142 = 0; _t142 < this.inputs.length; ++_t142) {
          e.push({
            key: this.inputs[_t142],
            value: n[_t142]
          });
        }

        var o = new FeedDict$1(e),
            i = execute$1(this.outputs, o, {
          training: !0
        });
        var l;

        for (var _e185 = 0; _e185 < this.lossFunctions.length; ++_e185) {
          var _n66 = (0, this.lossFunctions[_e185])(r[_e185], i[_e185]);

          null != a[_e185] && (_n66 = computeWeightedLoss$2(_n66, a[_e185]));

          var _s26 = mean$3(_n66);

          t.push(_s26), l = 0 === _e185 ? _n66 : add$5(l, _n66);
        }

        for (var _e186 = 0; _e186 < this.metricsTensors.length; ++_e186) {
          var _n67 = void 0;

          if (this.outputs.length > 1 && _e186 < this.outputs.length) _n67 = t[_e186];else {
            var _t143 = this.metricsTensors[_e186][1];
            _n67 = mean$3((0, this.metricsTensors[_e186][0])(r[_t143], i[_t143]));
          }
          keep$1(_n67), s.push(_n67);
        }

        return l = mean$3(l), this.calculateLosses().forEach(e => {
          l = add$5(l, e);
        }), l;
      }, !0, o)].concat(s);
    };
  }

  makeTestFunction() {
    this.testFunction = e => tidy$1(() => {
      var t = [];
      var n;
      var r = e.slice(0, this.inputs.length),
          a = e.slice(this.inputs.length, this.inputs.length + this.outputs.length),
          s = [];

      for (var _e187 = 0; _e187 < this.inputs.length; ++_e187) {
        s.push({
          key: this.inputs[_e187],
          value: r[_e187]
        });
      }

      var o = new FeedDict$1(s),
          i = execute$1(this.outputs, o);

      for (var _e188 = 0; _e188 < this.lossFunctions.length; ++_e188) {
        var _r50 = mean$3((0, this.lossFunctions[_e188])(a[_e188], i[_e188]));

        n = 0 === _e188 ? _r50 : add$5(n, _r50), t.push(n);
      }

      for (var _e189 = 0; _e189 < this.metricsTensors.length; ++_e189) {
        var _n68 = this.metricsTensors[_e189][1],
            _r51 = mean$3((0, this.metricsTensors[_e189][0])(a[_n68], i[_n68]));

        t.push(_r51);
      }

      return t;
    });
  }

  fit(e, t) {
    var _arguments2 = arguments,
        _this61 = this;

    return _asyncToGenerator(function* () {
      var n = _arguments2.length > 2 && _arguments2[2] !== undefined ? _arguments2[2] : {};
      return fitTensors$1(_this61, e, t, n);
    })();
  }

  fitDataset(e, t) {
    var _this62 = this;

    return _asyncToGenerator(function* () {
      return fitDataset$1(_this62, e, t);
    })();
  }

  trainOnBatch(e, t) {
    var _this63 = this;

    return _asyncToGenerator(function* () {
      var n = yield _this63.standardizeUserData(e, t),
          r = n[0],
          a = n[1],
          s = _this63.makeTrainFunction()(r.concat(a)),
          o = [];

      for (var _e190 of s) {
        var _t144 = yield _e190.data();

        o.push(_t144[0]);
      }

      return dispose$1(s), singletonOrArray$1(o);
    })();
  }

  getNamedWeights(e) {
    var t = [],
        n = null != e && e.trainableOnly,
        r = n ? this.trainableWeights : this.weights,
        a = this.getWeights(n);

    for (var _e191 = 0; _e191 < r.length; ++_e191) {
      n && !r[_e191].trainable || t.push({
        name: r[_e191].originalName,
        tensor: a[_e191]
      });
    }

    return t;
  }

  set stopTraining(e) {
    this.stopTraining_ = e;
  }

  get stopTraining() {
    return this.stopTraining_;
  }

  get optimizer() {
    return this.optimizer_;
  }

  set optimizer(e) {
    this.optimizer_ !== e && (this.optimizer_ = e, this.isOptimizerOwned = !1);
  }

  dispose() {
    var e = super.dispose();

    if (0 === e.refCountAfterDispose && null != this.optimizer && this.isOptimizerOwned) {
      var t = memory$1().numTensors;
      this.optimizer_.dispose(), e.numDisposedVariables += t - memory$1().numTensors;
    }

    return e;
  }

  getLossIdentifiers() {
    var e;
    if ("string" == typeof this.loss) e = toSnakeCase$1(this.loss);else if (Array.isArray(this.loss)) {
      for (var _e192 of this.loss) {
        if ("string" != typeof _e192) throw new Error("Serialization of non-string loss is not supported.");
      }

      e = this.loss.map(e => toSnakeCase$1(e));
    } else {
      var t = Object.keys(this.loss);
      e = {};
      var n = this.loss;

      for (var r of t) {
        if ("string" != typeof n[r]) throw new Error("Serialization of non-string loss is not supported.");
        e[r] = toSnakeCase$1(n[r]);
      }
    }
    return e;
  }

  getMetricIdentifiers() {
    if ("string" == typeof this.metrics || "function" == typeof this.metrics) return [toSnakeCase$1(getLossOrMetricName$1(this.metrics))];
    if (Array.isArray(this.metrics)) return this.metrics.map(e => toSnakeCase$1(getLossOrMetricName$1(e)));
    {
      var _e193 = {};

      for (var t in this.metrics) {
        _e193[t] = toSnakeCase$1(getLossOrMetricName$1(this.metrics[t]));
      }

      return _e193;
    }
  }

  getTrainingConfig() {
    return {
      loss: this.getLossIdentifiers(),
      metrics: this.getMetricIdentifiers(),
      optimizer_config: {
        class_name: this.optimizer.getClassName(),
        config: this.optimizer.getConfig()
      }
    };
  }

  loadTrainingConfig(e) {
    if (null != e.weighted_metrics) throw new Error("Loading weight_metrics is not supported yet.");
    if (null != e.loss_weights) throw new Error("Loading loss_weights is not supported yet.");
    if (null != e.sample_weight_mode) throw new Error("Loading sample_weight_mode is not supported yet.");
    var t = deserialize$1(convertPythonicToTs$1(e.optimizer_config));
    var n, r;
    if ("string" == typeof e.loss) n = toCamelCase$1(e.loss);else if (Array.isArray(e.loss)) n = e.loss.map(e => toCamelCase$1(e));else if (null != e.loss) {
      n = {};

      for (var _t145 in e.loss) {
        n[_t145] = toCamelCase$1(e.loss[_t145]);
      }
    }
    if (Array.isArray(e.metrics)) r = e.metrics.map(e => toCamelCase$1(e));else if (null != e.metrics) {
      r = {};

      for (var _t146 in e.metrics) {
        r[_t146] = toCamelCase$1(e.metrics[_t146]);
      }
    }
    this.compile({
      loss: n,
      metrics: r,
      optimizer: t
    });
  }

  save(e, t) {
    var _this64 = this;

    return _asyncToGenerator(function* () {
      if ("string" == typeof e) {
        var _t147 = getSaveHandlers$1(e);

        if (0 === _t147.length) throw new ValueError$1("Cannot find any save handlers for URL '".concat(e, "'"));
        if (_t147.length > 1) throw new ValueError$1("Found more than one (".concat(_t147.length, ") save handlers for URL '").concat(e, "'"));
        e = _t147[0];
      }

      if (null == e.save) throw new ValueError$1("LayersModel.save() cannot proceed because the IOHandler provided does not have the `save` attribute defined.");
      var n = yield encodeWeights$1(_this64.getNamedWeights(t)),
          r = {
        modelTopology: _this64.toJSON(null, !1),
        format: LAYERS_MODEL_FORMAT_NAME$1,
        generatedBy: "TensorFlow.js tfjs-layers v".concat(version$d),
        convertedBy: null
      };

      if (null != t && t.includeOptimizer && null != _this64.optimizer) {
        r.trainingConfig = _this64.getTrainingConfig();
        var _e194 = "optimizer",
            {
          data: _t148,
          specs: a
        } = yield encodeWeights$1(yield _this64.optimizer.getWeights(), _e194);
        n.specs.push(...a), n.data = concatenateArrayBuffers$1([n.data, _t148]);
      }

      return null != _this64.userDefinedMetadata && (checkUserDefinedMetadata$1(_this64.userDefinedMetadata, _this64.name, !0), r.userDefinedMetadata = _this64.userDefinedMetadata), r.weightData = n.data, r.weightSpecs = n.specs, e.save(r);
    })();
  }

  setUserDefinedMetadata(e) {
    checkUserDefinedMetadata$1(e, this.name), this.userDefinedMetadata = e;
  }

  getUserDefinedMetadata() {
    return this.userDefinedMetadata;
  }

}

LayersModel$1.className = "Model", registerClass$1(LayersModel$1);

class Functional$1 extends LayersModel$1 {}

function loadLayersModelInternal$1(_x45, _x46) {
  return _loadLayersModelInternal$.apply(this, arguments);
}

function _loadLayersModelInternal$() {
  _loadLayersModelInternal$ = _asyncToGenerator(function* (e, t) {
    if (null == t && (t = {}), "string" == typeof e) {
      var n = getLoadHandlers$1(e, t);
      if (0 === n.length) n.push(browserHTTPRequest$1(e, t));else if (n.length > 1) throw new ValueError$1("Found more than one (".concat(n.length, ") load handlers for URL '").concat(e, "'"));
      e = n[0];
    }

    return loadLayersModelFromIOHandler$1(e, void 0, t);
  });
  return _loadLayersModelInternal$.apply(this, arguments);
}

function loadLayersModelFromIOHandler$1(_x47, _x48, _x49) {
  return _loadLayersModelFromIOHandler$.apply(this, arguments);
}

function _loadLayersModelFromIOHandler$() {
  _loadLayersModelFromIOHandler$ = _asyncToGenerator(function* (e, t, n) {
    if (null == n && (n = {}), null == e.load) throw new ValueError$1("Cannot proceed with model loading because the IOHandler provided does not have the `load` method implemented.");
    var r = yield e.load();
    var a = r.modelTopology;
    null != a.model_config && (a = a.model_config);
    var s = null == n.strict || n.strict,
        o = null != r.weightData && null != r.weightSpecs && s,
        i = deserialize$1(convertPythonicToTs$1(a), t, o),
        l = r.trainingConfig;

    if (null != l && i.loadTrainingConfig(l), null != r.userDefinedMetadata && i.setUserDefinedMetadata(r.userDefinedMetadata), null != r.weightData) {
      if (null == r.weightSpecs) throw new ValueError$1("LayersModel artifacts contains weight data, but not weight specs. Therefore loading of weights cannot proceed.");
      var {
        modelWeights: _e1149,
        optimizerWeights: _t772
      } = decodeModelAndOptimizerWeights$1(r.weightData, r.weightSpecs);
      i.loadWeights(_e1149, s), null != i.optimizer && _t772.length > 0 && (yield i.optimizer.setWeights(_t772)), dispose$1(_e1149), dispose$1(_t772.map(e => e.tensor));
    }

    return i;
  });
  return _loadLayersModelFromIOHandler$.apply(this, arguments);
}

function decodeModelAndOptimizerWeights$1(e, t) {
  var n = decodeWeights$1(e, t),
      r = {},
      a = [];
  return t.forEach(e => {
    "optimizer" === e.group ? a.push({
      name: e.name,
      tensor: n[e.name]
    }) : r[e.name] = n[e.name];
  }), {
    modelWeights: r,
    optimizerWeights: a
  };
}

Functional$1.className = "Functional", registerClass$1(Functional$1);

class Sequential$1 extends LayersModel$1 {
  constructor(e) {
    if (super({
      inputs: [],
      outputs: []
    }), e = e || {}, this.trainable = !0, this.built = !1, this.name = null != e.name ? e.name : getUid$1("sequential_"), null != e.layers) for (var t of e.layers) {
      this.add(t);
    }
  }

  checkShape(e) {
    if (e.inboundNodes[0].outputTensors[0].shape.some(e => e < 0)) throw new ValueError$1("Negative dimension size caused by adding layer ".concat(e.name, " with input shape [").concat(e.inboundNodes[0].inputTensors[0].shape, "]"));
  }

  add(e) {
    var t = e instanceof Sequential$1 || e instanceof LayersModel$1;
    var n;

    if (t) {
      if (n = e, 1 !== n.outputs.length) throw new ValueError$1("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");
      if (1 !== n.inputs.length) throw new ValueError$1("All layers in a Sequential model should have a single input tensor. For multi-input layers, use the functional API.");
    }

    if (0 === this.outputs.length) {
      if (0 === e.inboundNodes.length) {
        if (null == e.batchInputShape) throw new ValueError$1("The first layer in a Sequential model must get an `inputShape` or `batchInputShape` argument.");

        var _t149 = Input$1({
          batchShape: e.batchInputShape,
          dtype: e.dtype,
          name: e.name + "_input"
        });

        e.apply(_t149);
      }

      if (t) this.outputs = n.outputs, this.inputs = n.inputs;else {
        if (1 !== e.inboundNodes.length) throw new ValueError$1("A layer added to a Sequential model must not already be connected somewhere else. LayersModel received layer ".concat(e.name, " which has ").concat(e.inboundNodes.length, " pre-existing inbound connections."));
        if (1 !== e.inboundNodes[0].outputTensors.length) throw new ValueError$1("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");
        this.checkShape(e), this.outputs = [e.inboundNodes[0].outputTensors[0]], this.inputs = getSourceInputs$1(this.outputs[0]);
      }
      this.inboundNodes = [], new Node$1({
        outboundLayer: this,
        inboundLayers: [],
        nodeIndices: [],
        tensorIndices: [],
        inputTensors: this.inputs,
        outputTensors: this.outputs,
        inputMasks: pyListRepeat$1(null, this.inputs.length),
        outputMasks: [null],
        inputShapes: this.inputs.map(e => e.shape),
        outputShapes: this.outputs[0].shape
      });
    } else {
      var _t150 = e.apply(this.outputs[0]);

      if (Array.isArray(_t150)) throw new TypeError("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");
      this.checkShape(e), this.outputs = [_t150], this.inboundNodes[0].outputTensors = this.outputs, this.inboundNodes[0].outputShapes = [this.outputs[0].shape];
    }

    this.layers.push(e), this.built = !1;
  }

  pop() {
    if (0 === this.layers.length) throw new TypeError("There are no layers in the model.");
    if (this.layers.pop(), 0 === this.layers.length) this.outputs = [], this.inboundNodes = [], this.outboundNodes = [];else {
      var _e195 = this.layers.length - 1;

      this.layers[_e195].outboundNodes = [], this.outputs = [this.layers[_e195].output], this.inboundNodes[0].outputTensors = this.outputs, this.inboundNodes[0].outputShapes = [this.outputs[0].shape];
    }
  }

  call(e, t) {
    return null == this.model && this.build(), this.model.call(e, t);
  }

  build(e) {
    if (getExactlyOneShape$1(e), 0 === this.inputs.length || 0 === this.outputs.length) throw new TypeError("Sequential model cannot be built: model is empty. Add some layers first.");
    this.model = new LayersModel$1({
      inputs: this.inputs,
      outputs: this.outputs[0],
      name: this.name + "_model"
    }), this.model.trainable = this.trainable, this.supportsMasking = this.model.supportsMasking, this.inputLayers = this.model.inputLayers, this.inputLayersNodeIndices = this.model.inputLayersNodeIndices, this.inputLayersTensorIndices = this.model.inputLayersTensorIndices, this.outputLayers = this.model.outputLayers, this.outputLayersNodeIndices = this.model.outputLayersNodeIndices, this.outputLayersTensorIndices = this.model.outputLayersTensorIndices, this.nodesByDepth = this.model.nodesByDepth, this.containerNodes = this.model.containerNodes, this.outputNames = this.model.outputNames, this.inputNames = this.model.inputNames, this.built = !0;
  }

  countParams() {
    return this.built || this.build(), super.countParams();
  }

  summary(e, t) {
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : console.log;
    this.built || this.build(), super.summary(e, t, n);
  }

  setWeights(e) {
    null == this.model && this.build(), this.model.setWeights(e);
  }

  evaluate(e, t) {
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};
    if (!this.built) throw new RuntimeError$1("The model needs to be compiled before being used.");
    return this.model.evaluate(e, t, n);
  }

  evaluateDataset(e, t) {
    var _this65 = this;

    return _asyncToGenerator(function* () {
      if (!_this65.built) throw new RuntimeError$1("The model needs to be compiled before being used.");
      return _this65.model.evaluateDataset(e, t);
    })();
  }

  predict(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};
    return null == this.model && this.build(), this.model.predict(e, t);
  }

  predictOnBatch(e) {
    return null == this.model && this.build(), this.model.predictOnBatch(e);
  }

  compile(e) {
    this.build(), this.model.compile(e), this.optimizer_ = this.model.optimizer, this.isOptimizerOwned = this.model.isOptimizerOwned, this.loss = this.model.loss, this.metrics = this.model.metrics, this.metricsTensors = this.model.metricsTensors, this.metricsNames = this.model.metricsNames;
  }

  get optimizer() {
    return null == this.model ? void 0 : this.model.optimizer;
  }

  set optimizer(e) {
    this.model.optimizer = e;
  }

  fit(e, t) {
    var _arguments3 = arguments,
        _this66 = this;

    return _asyncToGenerator(function* () {
      var n = _arguments3.length > 2 && _arguments3[2] !== undefined ? _arguments3[2] : {};
      if (!_this66.built) throw new RuntimeError$1("The model needs to be compiled before being used.");
      return _this66.model.fit(e, t, n);
    })();
  }

  fitDataset(e, t) {
    var _this67 = this;

    return _asyncToGenerator(function* () {
      if (!_this67.built) throw new RuntimeError$1("The model needs to be compiled before being used.");
      return _this67.model.fitDataset(e, t);
    })();
  }

  trainOnBatch(e, t) {
    var _this68 = this;

    return _asyncToGenerator(function* () {
      return _this68.model.trainOnBatch(e, t);
    })();
  }

  static fromConfig(e, t) {
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
    var a,
        s = {};

    if (t instanceof Array) {
      if (null == t[0].className || "Merge" === t[0].className) throw new ValueError$1("Legacy serialization format not supported yet.");
      a = t;
    } else assert$6(null != t.layers, () => "When the config data for a Sequential model is not an Array, it must be an Object that contains the 'layers' field."), a = t.layers, delete t.layers, s = t;

    var o = new e(s);
    if (!(o instanceof Sequential$1)) throw new NotImplementedError$1("Sequential.fromConfig called on non-Sequential input: ".concat(o));

    for (var _e196 of a) {
      var _t151 = deserialize$1(_e196, void 0, r);

      r && _t151.setFastWeightInitDuringBuild(!0), o.add(_t151);
    }

    return o;
  }

  set stopTraining(e) {
    if (null == this.model) throw new ValueError$1("Cannot set the stopTraining property of a sequential model before it is compiled.");
    this.model.stopTraining = e;
  }

  get stopTraining() {
    if (null == this.model) throw new ValueError$1("Cannot get the stopTraining property of a sequential model before it is compiled.");
    return this.model.stopTraining;
  }

  getConfig() {
    var e = [];

    for (var t of this.layers) {
      var n = {};
      n.className = t.getClassName(), n.config = t.getConfig(), e.push(n);
    }

    return {
      name: this.name,
      layers: e
    };
  }

}

function sequential$1(e) {
  return new Sequential$1(e);
}

function loadLayersModel$1(e, t) {
  return null == t && (t = {}), loadLayersModelInternal$1(e, t);
}

Sequential$1.className = "Sequential", registerClass$1(Sequential$1);

class Activation$3 extends Serializable$1 {
  getConfig() {
    return {};
  }

}

class Elu$2 extends Activation$3 {
  apply(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 1;
    return elu$7(e, t);
  }

}

Elu$2.className = "elu", registerClass$1(Elu$2);

class Selu$2 extends Activation$3 {
  apply(e) {
    return selu$5(e);
  }

}

Selu$2.className = "selu", registerClass$1(Selu$2);

class Relu$2 extends Activation$3 {
  apply(e) {
    return relu$6(e);
  }

}

Relu$2.className = "relu", registerClass$1(Relu$2);

class Relu6$2 extends Activation$3 {
  apply(e) {
    return tidy$1(() => minimum$6(6, relu$6(e)));
  }

}

Relu6$2.className = "relu6", registerClass$1(Relu6$2);

class Linear$1 extends Activation$3 {
  apply(e) {
    return e;
  }

}

Linear$1.className = "linear", registerClass$1(Linear$1);

class Sigmoid$2 extends Activation$3 {
  apply(e) {
    return sigmoid$5(e);
  }

}

Sigmoid$2.className = "sigmoid", registerClass$1(Sigmoid$2);

class HardSigmoid$1 extends Activation$3 {
  apply(e) {
    return hardSigmoid$1(e);
  }

}

HardSigmoid$1.className = "hardSigmoid", registerClass$1(HardSigmoid$1);

class Softplus$2 extends Activation$3 {
  apply(e) {
    return softplus$5(e);
  }

}

Softplus$2.className = "softplus", registerClass$1(Softplus$2);

class Softsign$1 extends Activation$3 {
  apply(e) {
    return softsign$1(e);
  }

}

Softsign$1.className = "softsign", registerClass$1(Softsign$1);

class Tanh$2 extends Activation$3 {
  apply(e) {
    return tanh$6(e);
  }

}

Tanh$2.className = "tanh", registerClass$1(Tanh$2);

class Softmax$4 extends Activation$3 {
  apply(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : -1;
    return softmax$6(e, t);
  }

}

Softmax$4.className = "softmax", registerClass$1(Softmax$4);

class LogSoftmax$2 extends Activation$3 {
  apply(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : -1;
    return logSoftmax$1(e, t);
  }

}

LogSoftmax$2.className = "logSoftmax", registerClass$1(LogSoftmax$2);

class Swish$1 extends Activation$3 {
  apply(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 1;
    return tidy$1(() => mul$1(sigmoid$5(mul$1(e, t)), e));
  }

}

Swish$1.className = "swish", registerClass$1(Swish$1);

class Mish$1 extends Activation$3 {
  apply(e) {
    return tidy$1(() => mul$1(e, tanh$6(softplus$5(e))));
  }

}

function serializeActivation$1(e) {
  return e.getClassName();
}

function deserializeActivation$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};
  return deserializeKerasObject$1(e, SerializationMap$1.getMap().classNameMap, t, "activation");
}

function getActivation$1(e) {
  if (null == e) return deserializeActivation$1({
    className: "linear",
    config: {}
  });

  if ("string" == typeof e) {
    var t = {};
    return t.className = e, t.config = {}, deserializeActivation$1(t);
  }

  return e instanceof Activation$3 ? e : deserializeActivation$1(e);
}

function assertObjectArgs$1(e) {
  if (null != e && "object" != typeof e) throw new Error("Argument to L1L2 regularizer's constructor is expected to be an object, but received: ".concat(e));
}

Mish$1.className = "mish", registerClass$1(Mish$1);

class Regularizer$1 extends Serializable$1 {}

class L1L2$1 extends Regularizer$1 {
  constructor(e) {
    super(), assertObjectArgs$1(e), this.l1 = null == e || null == e.l1 ? .01 : e.l1, this.l2 = null == e || null == e.l2 ? .01 : e.l2, this.hasL1 = 0 !== this.l1, this.hasL2 = 0 !== this.l2;
  }

  apply(e) {
    return tidy$1(() => {
      var t = zeros$4([1]);
      return this.hasL1 && (t = add$5(t, sum$6(mul$1(this.l1, abs$5(e))))), this.hasL2 && (t = add$5(t, sum$6(mul$1(this.l2, square$4(e))))), reshape$6(t, []);
    });
  }

  getConfig() {
    return {
      l1: this.l1,
      l2: this.l2
    };
  }

  static fromConfig(e, t) {
    return new e({
      l1: t.l1,
      l2: t.l2
    });
  }

}

L1L2$1.className = "L1L2", registerClass$1(L1L2$1);
var REGULARIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP$1 = {
  l1l2: "L1L2"
};

function serializeRegularizer$1(e) {
  return serializeKerasObject$1(e);
}

function deserializeRegularizer$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};
  return deserializeKerasObject$1(e, SerializationMap$1.getMap().classNameMap, t, "regularizer");
}

function getRegularizer$1(e) {
  return null == e ? null : "string" == typeof e ? deserializeRegularizer$1({
    className: e in REGULARIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP$1 ? REGULARIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP$1[e] : e,
    config: {}
  }) : e instanceof Regularizer$1 ? e : deserializeRegularizer$1(e);
}

class ReLU$1 extends Layer$1 {
  constructor(e) {
    super(null == e ? {} : e), this.supportsMasking = !0, null != e && (this.maxValue = e.maxValue);
  }

  call(e, t) {
    e = getExactlyOneTensor$1(e);
    var n = relu$6(e);
    return null != this.maxValue && (n = clipByValue$3(n, 0, this.maxValue)), n;
  }

  computeOutputShape(e) {
    return e;
  }

  getConfig() {
    var e = {
      maxValue: this.maxValue
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

ReLU$1.className = "ReLU", registerClass$1(ReLU$1);

class LeakyReLU$1 extends Layer$1 {
  constructor(e) {
    super(null == e ? {} : e), this.DEFAULT_ALPHA = .3, null == e && (e = {}), this.alpha = null == e.alpha ? this.DEFAULT_ALPHA : e.alpha;
  }

  call(e, t) {
    var n = getExactlyOneTensor$1(e);
    return leakyRelu$5(n, this.alpha);
  }

  computeOutputShape(e) {
    return e;
  }

  getConfig() {
    var e = {
      alpha: this.alpha
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

LeakyReLU$1.className = "LeakyReLU", registerClass$1(LeakyReLU$1);

class PReLU$1 extends Layer$1 {
  constructor(e) {
    if (super(null == e ? {} : e), this.DEFAULT_ALPHA_INITIALIZER = "zeros", null == e && (e = {}), this.supportsMasking = !0, this.alphaInitializer = getInitializer$1(e.alphaInitializer || this.DEFAULT_ALPHA_INITIALIZER), this.alphaRegularizer = getRegularizer$1(e.alphaRegularizer), this.alphaConstraint = getConstraint$1(e.alphaConstraint), null == e.sharedAxes) this.sharedAxes = null;else if (Array.isArray(e.sharedAxes)) this.sharedAxes = e.sharedAxes;else {
      if ("number" != typeof e.sharedAxes) throw new ValueError$1("Expected sharedAxes to be a number or an array of numbers, but got ".concat(e.sharedAxes));
      this.sharedAxes = [e.sharedAxes];
    }
  }

  build(e) {
    var t = (e = getExactlyOneShape$1(e)).slice(1);
    if (null != this.sharedAxes) for (var _e197 of this.sharedAxes) {
      t[_e197 - 1] = 1;
    }
    this.alpha = this.addWeight("alpha", t, "float32", this.alphaInitializer, this.alphaRegularizer, !0, this.alphaConstraint);
    var n = {};
    if (null != this.sharedAxes) for (var _t152 = 1; _t152 < e.length; ++_t152) {
      n[_t152] = e[_t152];
    }
    this.inputSpec = [new InputSpec$1({
      ndim: e.length,
      axes: n
    })], this.built = !0;
  }

  call(e, t) {
    return e = getExactlyOneTensor$1(e), prelu$6(e, this.alpha.read());
  }

  getConfig() {
    var e = {
      alphaInitializer: serializeInitializer$1(this.alphaInitializer),
      alphaRegularizer: serializeRegularizer$1(this.alphaRegularizer),
      alphaConstraint: serializeConstraint$1(this.alphaConstraint),
      sharedAxes: this.sharedAxes
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

PReLU$1.className = "PReLU", registerClass$1(PReLU$1);

class ELU$7 extends Layer$1 {
  constructor(e) {
    if (super(null == e ? {} : e), this.DEFAULT_ALPHA = 1, null == e && (e = {}), null != e.alpha && e.alpha !== this.DEFAULT_ALPHA) throw new NotImplementedError$1("Non-default alpha value (".concat(e.alpha, ") is not supported by the ELU layer yet."));
    this.alpha = null == e.alpha ? this.DEFAULT_ALPHA : e.alpha;
  }

  call(e, t) {
    var n = getExactlyOneTensor$1(e);
    return elu$8(n);
  }

  computeOutputShape(e) {
    return e;
  }

  getConfig() {
    var e = {
      alpha: this.alpha
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

ELU$7.className = "ELU", registerClass$1(ELU$7);

class ThresholdedReLU$1 extends Layer$1 {
  constructor(e) {
    super(null == e ? {} : e), this.DEFAULT_THETA = 1, null == e && (e = {}), this.theta = null == e.theta ? this.DEFAULT_THETA : e.theta;
  }

  call(e, t) {
    var n = getExactlyOneTensor$1(e);
    return mul$1(n, cast$7(greater$6(n, this.theta), "float32"));
  }

  computeOutputShape(e) {
    return e;
  }

  getConfig() {
    var e = {
      theta: this.theta
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

ThresholdedReLU$1.className = "ThresholdedReLU", registerClass$1(ThresholdedReLU$1);

class Softmax$3 extends Layer$1 {
  constructor(e) {
    super(null == e ? {} : e), this.DEFAULT_AXIS = 1, null == e && (e = {}), this.softmax = new Softmax$4().apply, this.axis = null == e.axis ? this.DEFAULT_AXIS : e.axis;
  }

  call(e, t) {
    var n = getExactlyOneTensor$1(e);
    return this.softmax(n, this.axis);
  }

  computeOutputShape(e) {
    return e;
  }

  getConfig() {
    var e = {
      axis: this.axis
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

function normalizeArray$1(e, t, n) {
  if ("number" == typeof e) return pyListRepeat$1(e, t);
  if (e.length !== t) throw new ValueError$1("The ".concat(n, " argument must be an integer or tuple of ").concat(t, " integers. Received: ").concat(e.length, " elements."));

  for (var r = 0; r < t; ++r) {
    var a = e[r];
    if (!isInteger$1(a)) throw new ValueError$1("The ".concat(n, " argument must be an integer or tuple of ").concat(t, " integers. Received: ").concat(JSON.stringify(e), " including a non-integer number ").concat(a));
  }

  return e;
}

function convOutputLength$1(e, t, n, r) {
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : 1;
  if (null == e) return e;
  var s;
  return s = "same" === n ? e : e - (t + (t - 1) * (a - 1)) + 1, Math.floor((s + r - 1) / r);
}

function deconvLength$1(e, t, n, r) {
  if (null == e) return null;
  if ("valid" === r) e = e * t + max$6([n - t, 0]);else {
    if ("same" !== r) throw new ValueError$1("Unsupport padding mode: ".concat(r, "."));
    e *= t;
  }
  return e;
}

function preprocessConv2DInput$1(e, t) {
  return tidy$1(() => (checkDataFormat$1(t), "channelsFirst" === t ? transpose$5(e, [0, 2, 3, 1]) : e));
}

function preprocessConv3DInput$1(e, t) {
  return tidy$1(() => (checkDataFormat$1(t), "channelsFirst" === t ? transpose$5(e, [0, 2, 3, 4, 1]) : e));
}

function conv1dWithBias$1(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 1;
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : "valid";
  var s = arguments.length > 5 ? arguments[5] : undefined;
  var o = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : 1;
  return tidy$1(() => {
    if (null == s && (s = imageDataFormat$1()), checkDataFormat$1(s), 3 !== e.shape.length) throw new ValueError$1("The input of a conv1dWithBias operation should be 3, but is ".concat(e.shape.length, " instead."));
    if (3 !== t.shape.length) throw new ValueError$1("The kernel for a conv1dWithBias operation should be 3, but is ".concat(t.shape.length, " instead"));
    if (null != n && 1 !== n.shape.length) throw new ValueError$1("The bias for a conv1dWithBias operation should be 1, but is ".concat(t.shape.length, " instead"));
    if ("channelsFirst" === s && (e = transpose$5(e, [0, 2, 1])), "causal" === a) throw new NotImplementedError$1("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");
    var i = conv1d$3(e, t, r, "same" === a ? "same" : "valid", "NWC", o);
    return null != n && (i = biasAdd$1(i, n)), i;
  });
}

function conv2dWithBiasActivation$1(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : [1, 1];
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : "valid";
  var s = arguments.length > 5 ? arguments[5] : undefined;
  var o = arguments.length > 6 ? arguments[6] : undefined;
  var i = arguments.length > 7 && arguments[7] !== undefined ? arguments[7] : null;
  return tidy$1(() => {
    if (null == s && (s = imageDataFormat$1()), checkDataFormat$1(s), 3 !== e.rank && 4 !== e.rank) throw new ValueError$1("conv2dWithBiasActivation expects input to be of rank 3 or 4, but received ".concat(e.rank, "."));
    if (3 !== t.rank && 4 !== t.rank) throw new ValueError$1("conv2dWithBiasActivation expects kernel to be of rank 3 or 4, but received ".concat(e.rank, "."));
    var l = preprocessConv2DInput$1(e, s);
    if ("causal" === a) throw new NotImplementedError$1("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");
    return l = conv2d$6({
      x: l,
      filter: t,
      strides: r,
      pad: "same" === a ? "same" : "valid",
      dilations: o,
      dataFormat: "NHWC",
      bias: n,
      activation: i
    }), "channelsFirst" === s && (l = transpose$5(l, [0, 3, 1, 2])), l;
  });
}

function conv3dWithBias$1(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : [1, 1, 1];
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : "valid";
  var s = arguments.length > 5 ? arguments[5] : undefined;
  var o = arguments.length > 6 ? arguments[6] : undefined;
  return tidy$1(() => {
    if (null == s && (s = imageDataFormat$1()), checkDataFormat$1(s), 4 !== e.rank && 5 !== e.rank) throw new ValueError$1("conv3dWithBias expects input to be of rank 4 or 5, but received ".concat(e.rank, "."));
    if (4 !== t.rank && 5 !== t.rank) throw new ValueError$1("conv3dWithBias expects kernel to be of rank 4 or 5, but received ".concat(e.rank, "."));
    var i = preprocessConv3DInput$1(e, s);
    if ("causal" === a) throw new NotImplementedError$1("The support for CAUSAL padding mode in conv3dWithBias is not implemented yet.");
    return i = conv3d$2(i, t, r, "same" === a ? "same" : "valid", "NDHWC", o), null != n && (i = biasAdd$1(i, n)), "channelsFirst" === s && (i = transpose$5(i, [0, 4, 1, 2, 3])), i;
  });
}

Softmax$3.className = "Softmax", registerClass$1(Softmax$3);

class BaseConv$1 extends Layer$1 {
  constructor(e, t) {
    if (super(t), this.bias = null, this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal", this.DEFAULT_BIAS_INITIALIZER = "zeros", BaseConv$1.verifyArgs(t), this.rank = e, assertPositiveInteger$1(this.rank, "rank"), 1 !== this.rank && 2 !== this.rank && 3 !== this.rank) throw new NotImplementedError$1("Convolution layer for rank other than 1, 2, or 3 (".concat(this.rank, ") is not implemented yet."));
    if (this.kernelSize = normalizeArray$1(t.kernelSize, e, "kernelSize"), this.strides = normalizeArray$1(null == t.strides ? 1 : t.strides, e, "strides"), this.padding = null == t.padding ? "valid" : t.padding, checkPaddingMode$1(this.padding), this.dataFormat = null == t.dataFormat ? "channelsLast" : t.dataFormat, checkDataFormat$1(this.dataFormat), this.activation = getActivation$1(t.activation), this.useBias = null == t.useBias || t.useBias, this.biasInitializer = getInitializer$1(t.biasInitializer || this.DEFAULT_BIAS_INITIALIZER), this.biasConstraint = getConstraint$1(t.biasConstraint), this.biasRegularizer = getRegularizer$1(t.biasRegularizer), this.activityRegularizer = getRegularizer$1(t.activityRegularizer), this.dilationRate = normalizeArray$1(null == t.dilationRate ? 1 : t.dilationRate, e, "dilationRate"), 1 === this.rank && Array.isArray(this.dilationRate) && 1 !== this.dilationRate.length) throw new ValueError$1("dilationRate must be a number or an array of a single number for 1D convolution, but received ".concat(JSON.stringify(this.dilationRate)));

    if (2 === this.rank) {
      if ("number" == typeof this.dilationRate) this.dilationRate = [this.dilationRate, this.dilationRate];else if (2 !== this.dilationRate.length) throw new ValueError$1("dilationRate must be a number or array of two numbers for 2D convolution, but received ".concat(JSON.stringify(this.dilationRate)));
    } else if (3 === this.rank) if ("number" == typeof this.dilationRate) this.dilationRate = [this.dilationRate, this.dilationRate, this.dilationRate];else if (3 !== this.dilationRate.length) throw new ValueError$1("dilationRate must be a number or array of three numbers for 3D convolution, but received ".concat(JSON.stringify(this.dilationRate)));
  }

  static verifyArgs(e) {
    if (assert$5("kernelSize" in e, "required key 'kernelSize' not in config"), "number" != typeof e.kernelSize && !checkArrayTypeAndLength$1(e.kernelSize, "number", 1, 3)) throw new ValueError$1("BaseConv expects config.kernelSize to be number or number[] with length 1, 2, or 3, but received ".concat(JSON.stringify(e.kernelSize), "."));
  }

  getConfig() {
    var e = {
      kernelSize: this.kernelSize,
      strides: this.strides,
      padding: this.padding,
      dataFormat: this.dataFormat,
      dilationRate: this.dilationRate,
      activation: serializeActivation$1(this.activation),
      useBias: this.useBias,
      biasInitializer: serializeInitializer$1(this.biasInitializer),
      biasRegularizer: serializeRegularizer$1(this.biasRegularizer),
      activityRegularizer: serializeRegularizer$1(this.activityRegularizer),
      biasConstraint: serializeConstraint$1(this.biasConstraint)
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

class Conv$1 extends BaseConv$1 {
  constructor(e, t) {
    super(e, t), this.kernel = null, Conv$1.verifyArgs(t), this.filters = t.filters, assertPositiveInteger$1(this.filters, "filters"), this.kernelInitializer = getInitializer$1(t.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER), this.kernelConstraint = getConstraint$1(t.kernelConstraint), this.kernelRegularizer = getRegularizer$1(t.kernelRegularizer);
  }

  build(e) {
    e = getExactlyOneShape$1(e);
    var t = "channelsFirst" === this.dataFormat ? 1 : e.length - 1;
    if (null == e[t]) throw new ValueError$1("The channel dimension of the input should be defined. Found ".concat(e[t]));
    var n = e[t],
        r = this.kernelSize.concat([n, this.filters]);
    this.kernel = this.addWeight("kernel", r, null, this.kernelInitializer, this.kernelRegularizer, !0, this.kernelConstraint), this.useBias && (this.bias = this.addWeight("bias", [this.filters], null, this.biasInitializer, this.biasRegularizer, !0, this.biasConstraint)), this.inputSpec = [{
      ndim: this.rank + 2,
      axes: {
        [t]: n
      }
    }], this.built = !0;
  }

  call(e, t) {
    return tidy$1(() => {
      var t;
      e = getExactlyOneTensor$1(e);
      var n = null == this.bias ? null : this.bias.read(),
          r = mapActivationToFusedKernel$1(this.activation.getClassName());
      if (null != r && 2 === this.rank) t = conv2dWithBiasActivation$1(e, this.kernel.read(), n, this.strides, this.padding, this.dataFormat, this.dilationRate, r);else {
        if (1 === this.rank) t = conv1dWithBias$1(e, this.kernel.read(), n, this.strides[0], this.padding, this.dataFormat, this.dilationRate[0]);else if (2 === this.rank) t = conv2dWithBiasActivation$1(e, this.kernel.read(), n, this.strides, this.padding, this.dataFormat, this.dilationRate);else {
          if (3 !== this.rank) throw new NotImplementedError$1("convolutions greater than 3D are not implemented yet.");
          t = conv3dWithBias$1(e, this.kernel.read(), n, this.strides, this.padding, this.dataFormat, this.dilationRate);
        }
        null != this.activation && (t = this.activation.apply(t));
      }
      return t;
    });
  }

  computeOutputShape(e) {
    e = getExactlyOneShape$1(e);
    var t = [],
        n = "channelsLast" === this.dataFormat ? e.slice(1, e.length - 1) : e.slice(2);

    for (var _e198 = 0; _e198 < n.length; ++_e198) {
      var _r52 = convOutputLength$1(n[_e198], this.kernelSize[_e198], this.padding, this.strides[_e198], "number" == typeof this.dilationRate ? this.dilationRate : this.dilationRate[_e198]);

      t.push(_r52);
    }

    var r = [e[0]];
    return "channelsLast" === this.dataFormat ? (r = r.concat(t), r.push(this.filters)) : (r.push(this.filters), r = r.concat(t)), r;
  }

  getConfig() {
    var e = {
      filters: this.filters,
      kernelInitializer: serializeInitializer$1(this.kernelInitializer),
      kernelRegularizer: serializeRegularizer$1(this.kernelRegularizer),
      kernelConstraint: serializeConstraint$1(this.kernelConstraint)
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

  static verifyArgs(e) {
    if (!("filters" in e) || "number" != typeof e.filters || e.filters < 1) throw new ValueError$1("Convolution layer expected config.filters to be a 'number' > 0 but got ".concat(JSON.stringify(e.filters)));
  }

}

class Conv2D$2 extends Conv$1 {
  constructor(e) {
    super(2, e), Conv2D$2.verifyArgs(e);
  }

  getConfig() {
    var e = super.getConfig();
    return delete e.rank, e;
  }

  static verifyArgs(e) {
    if ("number" != typeof e.kernelSize && !checkArrayTypeAndLength$1(e.kernelSize, "number", 1, 2)) throw new ValueError$1("Conv2D expects config.kernelSize to be number or number[] with length 1 or 2, but received ".concat(JSON.stringify(e.kernelSize), "."));
  }

}

Conv2D$2.className = "Conv2D", registerClass$1(Conv2D$2);

class Conv3D$2 extends Conv$1 {
  constructor(e) {
    super(3, e), Conv3D$2.verifyArgs(e);
  }

  getConfig() {
    var e = super.getConfig();
    return delete e.rank, e;
  }

  static verifyArgs(e) {
    if ("number" != typeof e.kernelSize && (!Array.isArray(e.kernelSize) || 1 !== e.kernelSize.length && 3 !== e.kernelSize.length)) throw new ValueError$1("Conv3D expects config.kernelSize to be number or [number, number, number], but received ".concat(JSON.stringify(e.kernelSize), "."));
  }

}

Conv3D$2.className = "Conv3D", registerClass$1(Conv3D$2);

class Conv2DTranspose$1 extends Conv2D$2 {
  constructor(e) {
    if (super(e), this.inputSpec = [new InputSpec$1({
      ndim: 4
    })], "same" !== this.padding && "valid" !== this.padding) throw new ValueError$1("Conv2DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode ".concat(this.padding));
  }

  build(e) {
    if (4 !== (e = getExactlyOneShape$1(e)).length) throw new ValueError$1("Input should have rank 4; Received input shape: " + JSON.stringify(e));
    var t = "channelsFirst" === this.dataFormat ? 1 : e.length - 1;
    if (null == e[t]) throw new ValueError$1("The channel dimension of the inputs should be defined. Found `None`.");
    var n = e[t],
        r = this.kernelSize.concat([this.filters, n]);
    this.kernel = this.addWeight("kernel", r, "float32", this.kernelInitializer, this.kernelRegularizer, !0, this.kernelConstraint), this.useBias && (this.bias = this.addWeight("bias", [this.filters], "float32", this.biasInitializer, this.biasRegularizer, !0, this.biasConstraint)), this.inputSpec = [new InputSpec$1({
      ndim: 4,
      axes: {
        [t]: n
      }
    })], this.built = !0;
  }

  call(e, t) {
    return tidy$1(() => {
      var t = getExactlyOneTensor$1(e);
      if (4 !== t.shape.length) throw new ValueError$1("Conv2DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-".concat(t.shape.length));
      var n = t.shape;
      var r, a;
      "channelsFirst" === this.dataFormat ? (r = 2, a = 3) : (r = 1, a = 2);
      var s = n[a],
          o = this.kernelSize[1],
          i = this.strides[1],
          l = [n[0], deconvLength$1(n[r], this.strides[0], this.kernelSize[0], this.padding), deconvLength$1(s, i, o, this.padding), this.filters];
      "channelsLast" !== this.dataFormat && (t = transpose$5(t, [0, 2, 3, 1]));
      var u = conv2dTranspose$2(t, this.kernel.read(), l, this.strides, this.padding);
      return "channelsLast" !== this.dataFormat && (u = transpose$5(u, [0, 3, 1, 2])), null != this.bias && (u = biasAdd$1(u, this.bias.read(), this.dataFormat)), null != this.activation && (u = this.activation.apply(u)), u;
    });
  }

  computeOutputShape(e) {
    var t = (e = getExactlyOneShape$1(e)).slice();
    var n, r, a;
    "channelsFirst" === this.dataFormat ? (n = 1, r = 2, a = 3) : (n = 3, r = 1, a = 2);
    var s = this.kernelSize[0],
        o = this.kernelSize[1],
        i = this.strides[0],
        l = this.strides[1];
    return t[n] = this.filters, t[r] = deconvLength$1(t[r], i, s, this.padding), t[a] = deconvLength$1(t[a], l, o, this.padding), t;
  }

  getConfig() {
    var e = super.getConfig();
    return delete e.dilationRate, e;
  }

}

Conv2DTranspose$1.className = "Conv2DTranspose", registerClass$1(Conv2DTranspose$1);

class Conv3DTranspose$1 extends Conv3D$2 {
  constructor(e) {
    if (super(e), this.inputSpec = [new InputSpec$1({
      ndim: 5
    })], "same" !== this.padding && "valid" !== this.padding) throw new ValueError$1("Conv3DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode ".concat(this.padding));
  }

  build(e) {
    if (5 !== (e = getExactlyOneShape$1(e)).length) throw new ValueError$1("Input should have rank 5; Received input shape: " + JSON.stringify(e));
    var t = "channelsFirst" === this.dataFormat ? 1 : e.length - 1;
    if (null == e[t]) throw new ValueError$1("The channel dimension of the inputs should be defined. Found `None`.");
    var n = e[t],
        r = this.kernelSize.concat([this.filters, n]);
    this.kernel = this.addWeight("kernel", r, "float32", this.kernelInitializer, this.kernelRegularizer, !0, this.kernelConstraint), this.useBias && (this.bias = this.addWeight("bias", [this.filters], "float32", this.biasInitializer, this.biasRegularizer, !0, this.biasConstraint)), this.inputSpec = [new InputSpec$1({
      ndim: 5,
      axes: {
        [t]: n
      }
    })], this.built = !0;
  }

  call(e, t) {
    return tidy$1(() => {
      var t = getExactlyOneTensor$1(e);
      if (5 !== t.shape.length) throw new ValueError$1("Conv3DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-".concat(t.shape.length));
      var n = t.shape;
      var r, a, s;
      "channelsFirst" === this.dataFormat ? (s = 2, r = 3, a = 4) : (s = 1, r = 2, a = 3);
      var o = n[r],
          i = n[a],
          l = this.kernelSize[1],
          u = this.kernelSize[2],
          c = this.strides[1],
          p = this.strides[2],
          d = [n[0], deconvLength$1(n[s], this.strides[0], this.kernelSize[0], this.padding), deconvLength$1(o, c, l, this.padding), deconvLength$1(i, p, u, this.padding), this.filters];
      "channelsLast" !== this.dataFormat && (t = transpose$5(t, [0, 2, 3, 4, 1]));
      var h = conv3dTranspose$2(t, this.kernel.read(), d, this.strides, this.padding);
      return "channelsLast" !== this.dataFormat && (h = transpose$5(h, [0, 4, 1, 2, 3])), null !== this.bias && (h = biasAdd$1(h, this.bias.read(), this.dataFormat)), null !== this.activation && (h = this.activation.apply(h)), h;
    });
  }

  computeOutputShape(e) {
    var t = (e = getExactlyOneShape$1(e)).slice();
    var n, r, a, s;
    "channelsFirst" === this.dataFormat ? (n = 1, r = 2, a = 3, s = 4) : (n = 4, r = 1, a = 2, s = 3);
    var o = this.kernelSize[0],
        i = this.kernelSize[1],
        l = this.kernelSize[2],
        u = this.strides[0],
        c = this.strides[1],
        p = this.strides[2];
    return t[n] = this.filters, t[r] = deconvLength$1(t[r], u, o, this.padding), t[a] = deconvLength$1(t[a], c, i, this.padding), t[s] = deconvLength$1(t[s], p, l, this.padding), t;
  }

  getConfig() {
    var e = super.getConfig();
    return delete e.dilationRate, e;
  }

}

Conv3DTranspose$1.className = "Conv3DTranspose", registerClass$1(Conv3DTranspose$1);

class SeparableConv$1 extends Conv$1 {
  constructor(e, t) {
    if (super(e, t), this.DEFAULT_DEPTHWISE_INITIALIZER = "glorotUniform", this.DEFAULT_POINTWISE_INITIALIZER = "glorotUniform", this.depthwiseKernel = null, this.pointwiseKernel = null, null == t.filters) throw new ValueError$1("The `filters` configuration field is required by SeparableConv, but is unspecified.");
    if (null != t.kernelInitializer || null != t.kernelRegularizer || null != t.kernelConstraint) throw new ValueError$1("Fields kernelInitializer, kernelRegularizer and kernelConstraint are invalid for SeparableConv2D. Use depthwiseInitializer, depthwiseRegularizer, depthwiseConstraint, pointwiseInitializer, pointwiseRegularizer and pointwiseConstraint instead.");
    if (null != t.padding && "same" !== t.padding && "valid" !== t.padding) throw new ValueError$1("SeparableConv".concat(this.rank, "D supports only padding modes: 'same' and 'valid', but received ").concat(JSON.stringify(t.padding)));
    this.depthMultiplier = null == t.depthMultiplier ? 1 : t.depthMultiplier, this.depthwiseInitializer = getInitializer$1(t.depthwiseInitializer || this.DEFAULT_DEPTHWISE_INITIALIZER), this.depthwiseRegularizer = getRegularizer$1(t.depthwiseRegularizer), this.depthwiseConstraint = getConstraint$1(t.depthwiseConstraint), this.pointwiseInitializer = getInitializer$1(t.depthwiseInitializer || this.DEFAULT_POINTWISE_INITIALIZER), this.pointwiseRegularizer = getRegularizer$1(t.pointwiseRegularizer), this.pointwiseConstraint = getConstraint$1(t.pointwiseConstraint);
  }

  build(e) {
    if ((e = getExactlyOneShape$1(e)).length < this.rank + 2) throw new ValueError$1("Inputs to SeparableConv".concat(this.rank, "D should have rank ").concat(this.rank + 2, ", but received input shape: ").concat(JSON.stringify(e)));
    var t = "channelsFirst" === this.dataFormat ? 1 : e.length - 1;
    if (null == e[t] || e[t] < 0) throw new ValueError$1("The channel dimension of the inputs should be defined, but found ".concat(JSON.stringify(e[t])));
    var n = e[t],
        r = this.kernelSize.concat([n, this.depthMultiplier]),
        a = [];

    for (var _e199 = 0; _e199 < this.rank; ++_e199) {
      a.push(1);
    }

    a.push(n * this.depthMultiplier, this.filters);
    var s = !0;
    this.depthwiseKernel = this.addWeight("depthwise_kernel", r, "float32", this.depthwiseInitializer, this.depthwiseRegularizer, s, this.depthwiseConstraint), this.pointwiseKernel = this.addWeight("pointwise_kernel", a, "float32", this.pointwiseInitializer, this.pointwiseRegularizer, s, this.pointwiseConstraint), this.bias = this.useBias ? this.addWeight("bias", [this.filters], "float32", this.biasInitializer, this.biasRegularizer, s, this.biasConstraint) : null, this.inputSpec = [new InputSpec$1({
      ndim: this.rank + 2,
      axes: {
        [t]: n
      }
    })], this.built = !0;
  }

  call(e, t) {
    return tidy$1(() => {
      var t;
      if (e = getExactlyOneTensor$1(e), 1 === this.rank) throw new NotImplementedError$1("1D separable convolution is not implemented yet.");
      return 2 === this.rank && ("channelsFirst" === this.dataFormat && (e = transpose$5(e, [0, 2, 3, 1])), t = separableConv2d$2(e, this.depthwiseKernel.read(), this.pointwiseKernel.read(), this.strides, this.padding, this.dilationRate, "NHWC")), this.useBias && (t = biasAdd$1(t, this.bias.read(), this.dataFormat)), null != this.activation && (t = this.activation.apply(t)), "channelsFirst" === this.dataFormat && (t = transpose$5(t, [0, 3, 1, 2])), t;
    });
  }

  getConfig() {
    var e = super.getConfig();
    return delete e.rank, delete e.kernelInitializer, delete e.kernelRegularizer, delete e.kernelConstraint, e.depthwiseInitializer = serializeInitializer$1(this.depthwiseInitializer), e.pointwiseInitializer = serializeInitializer$1(this.pointwiseInitializer), e.depthwiseRegularizer = serializeRegularizer$1(this.depthwiseRegularizer), e.pointwiseRegularizer = serializeRegularizer$1(this.pointwiseRegularizer), e.depthwiseConstraint = serializeConstraint$1(this.depthwiseConstraint), e.pointwiseConstraint = serializeConstraint$1(this.pointwiseConstraint), e;
  }

}

SeparableConv$1.className = "SeparableConv";

class SeparableConv2D$1 extends SeparableConv$1 {
  constructor(e) {
    super(2, e);
  }

}

SeparableConv2D$1.className = "SeparableConv2D", registerClass$1(SeparableConv2D$1);

class Conv1D$1 extends Conv$1 {
  constructor(e) {
    super(1, e), Conv1D$1.verifyArgs(e), this.inputSpec = [{
      ndim: 3
    }];
  }

  getConfig() {
    var e = super.getConfig();
    return delete e.rank, delete e.dataFormat, e;
  }

  static verifyArgs(e) {
    if ("number" != typeof e.kernelSize && !checkArrayTypeAndLength$1(e.kernelSize, "number", 1, 1)) throw new ValueError$1("Conv1D expects config.kernelSize to be number or number[] with length 1, but received ".concat(JSON.stringify(e.kernelSize), "."));
  }

}

Conv1D$1.className = "Conv1D", registerClass$1(Conv1D$1);

class Cropping2D$1 extends Layer$1 {
  constructor(e) {
    super(e), this.cropping = "number" == typeof e.cropping ? [[e.cropping, e.cropping], [e.cropping, e.cropping]] : "number" == typeof e.cropping[0] ? [[e.cropping[0], e.cropping[0]], [e.cropping[1], e.cropping[1]]] : e.cropping, this.dataFormat = void 0 === e.dataFormat ? "channelsLast" : e.dataFormat, this.inputSpec = [{
      ndim: 4
    }];
  }

  computeOutputShape(e) {
    return "channelsFirst" === this.dataFormat ? [e[0], e[1], e[2] - this.cropping[0][0] - this.cropping[0][1], e[3] - this.cropping[1][0] - this.cropping[1][1]] : [e[0], e[1] - this.cropping[0][0] - this.cropping[0][1], e[2] - this.cropping[1][0] - this.cropping[1][1], e[3]];
  }

  call(e, t) {
    return tidy$1(() => {
      if (e = getExactlyOneTensor$1(e), "channelsLast" === this.dataFormat) {
        var _t153 = sliceAlongAxis$1(e, this.cropping[0][0], e.shape[1] - this.cropping[0][0] - this.cropping[0][1], 2);

        return sliceAlongAxis$1(_t153, this.cropping[1][0], e.shape[2] - this.cropping[1][1] - this.cropping[1][0], 3);
      }

      {
        var _t154 = sliceAlongAxis$1(e, this.cropping[0][0], e.shape[2] - this.cropping[0][0] - this.cropping[0][1], 3);

        return sliceAlongAxis$1(_t154, this.cropping[1][0], e.shape[3] - this.cropping[1][1] - this.cropping[1][0], 4);
      }
    });
  }

  getConfig() {
    var e = {
      cropping: this.cropping,
      dataFormat: this.dataFormat
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

Cropping2D$1.className = "Cropping2D", registerClass$1(Cropping2D$1);

class UpSampling2D$1 extends Layer$1 {
  constructor(e) {
    super(e), this.DEFAULT_SIZE = [2, 2], this.inputSpec = [{
      ndim: 4
    }], this.size = null == e.size ? this.DEFAULT_SIZE : e.size, this.dataFormat = null == e.dataFormat ? "channelsLast" : e.dataFormat, checkDataFormat$1(this.dataFormat), this.interpolation = null == e.interpolation ? "nearest" : e.interpolation, checkInterpolationFormat$1(this.interpolation);
  }

  computeOutputShape(e) {
    return "channelsFirst" === this.dataFormat ? [e[0], e[1], null == e[2] ? null : this.size[0] * e[2], null == e[3] ? null : this.size[1] * e[3]] : [e[0], null == e[1] ? null : this.size[0] * e[1], null == e[2] ? null : this.size[1] * e[2], e[3]];
  }

  call(e, t) {
    return tidy$1(() => {
      var t = getExactlyOneTensor$1(e);
      var n = t.shape;

      if ("channelsFirst" === this.dataFormat) {
        t = transpose$5(t, [0, 2, 3, 1]);

        var _e200 = this.size[0] * n[2],
            r = this.size[1] * n[3],
            a = "nearest" === this.interpolation ? image$2.resizeNearestNeighbor(t, [_e200, r]) : image$2.resizeBilinear(t, [_e200, r]);

        return transpose$5(a, [0, 3, 1, 2]);
      }

      {
        var _e201 = this.size[0] * n[1],
            _r53 = this.size[1] * n[2];

        return "nearest" === this.interpolation ? image$2.resizeNearestNeighbor(t, [_e201, _r53]) : image$2.resizeBilinear(t, [_e201, _r53]);
      }
    });
  }

  getConfig() {
    var e = {
      size: this.size,
      dataFormat: this.dataFormat
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

function depthwiseConv2d$4(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : [1, 1];
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : "valid";
  var a = arguments.length > 4 ? arguments[4] : undefined;
  var s = arguments.length > 5 ? arguments[5] : undefined;
  return tidy$1(() => {
    null == a && (a = imageDataFormat$1()), checkDataFormat$1(a);
    var o = preprocessConv2DInput$1(e, a);
    if (4 !== e.rank) throw new ValueError$1("Input for depthwiseConv2d is required to be 4-D, but is instead ".concat(e.rank, "-D"));
    if (4 !== t.rank) throw new ValueError$1("depthwiseKernel is required to be 4-D, but is instead ".concat(t.rank, "-D"));
    return o = depthwiseConv2d$5(o, t, n, "same" === r ? "same" : "valid", "NHWC", s), "channelsFirst" === a && (o = transpose$5(o, [0, 3, 1, 2])), o;
  });
}

UpSampling2D$1.className = "UpSampling2D", registerClass$1(UpSampling2D$1);

class DepthwiseConv2D$1 extends BaseConv$1 {
  constructor(e) {
    super(2, e), this.depthwiseKernel = null, this.depthMultiplier = null == e.depthMultiplier ? 1 : e.depthMultiplier, this.depthwiseInitializer = getInitializer$1(e.depthwiseInitializer || this.DEFAULT_KERNEL_INITIALIZER), this.depthwiseConstraint = getConstraint$1(e.depthwiseConstraint), this.depthwiseRegularizer = getRegularizer$1(e.depthwiseRegularizer);
  }

  build(e) {
    if ((e = getExactlyOneShape$1(e)).length < 4) throw new ValueError$1("Inputs to DepthwiseConv2D should have rank 4. Received input shape: ".concat(JSON.stringify(e), "."));
    var t = "channelsFirst" === this.dataFormat ? 1 : 3;
    if (null == e[t] || e[t] < 0) throw new ValueError$1("The channel dimension of the inputs to DepthwiseConv2D should be defined, but is not (".concat(e[t], ")."));
    var n = e[t];
    this.depthwiseKernel = this.addWeight("depthwise_kernel", [this.kernelSize[0], this.kernelSize[1], n, this.depthMultiplier], null, this.depthwiseInitializer, this.depthwiseRegularizer, !0, this.depthwiseConstraint), this.bias = this.useBias ? this.addWeight("bias", [n * this.depthMultiplier], null, this.biasInitializer, this.biasRegularizer, !0, this.biasConstraint) : null, this.built = !0;
  }

  call(e, t) {
    return tidy$1(() => {
      var t = depthwiseConv2d$4(e = getExactlyOneTensor$1(e), this.depthwiseKernel.read(), this.strides, this.padding, this.dataFormat, null);
      return this.useBias && (t = biasAdd$1(t, this.bias.read(), this.dataFormat)), null != this.activation && (t = this.activation.apply(t)), t;
    });
  }

  computeOutputShape(e) {
    e = getExactlyOneShape$1(e);
    var t = "channelsFirst" === this.dataFormat ? e[3] : e[2],
        n = "channelsFirst" === this.dataFormat ? e[1] * this.depthMultiplier : e[3] * this.depthMultiplier,
        r = convOutputLength$1("channelsFirst" === this.dataFormat ? e[2] : e[1], this.kernelSize[0], this.padding, this.strides[0]),
        a = convOutputLength$1(t, this.kernelSize[1], this.padding, this.strides[1]);
    return "channelsFirst" === this.dataFormat ? [e[0], n, r, a] : [e[0], r, a, n];
  }

  getConfig() {
    var e = super.getConfig();
    return e.depthMultiplier = this.depthMultiplier, e.depthwiseInitializer = serializeInitializer$1(this.depthwiseInitializer), e.depthwiseRegularizer = serializeRegularizer$1(this.depthwiseRegularizer), e.depthwiseConstraint = serializeConstraint$1(this.depthwiseRegularizer), e;
  }

}

function standardizeArgs$1(e, t, n, r) {
  if (Array.isArray(e)) {
    if (null != t || null != n) throw new ValueError$1("When inputs is an array, neither initialState or constants should be provided");
    null != r && (n = e.slice(e.length - r, e.length), e = e.slice(0, e.length - r)), e.length > 1 && (t = e.slice(1, e.length)), e = e[0];
  }

  function a(e) {
    return null == e || Array.isArray(e) ? e : [e];
  }

  return {
    inputs: e,
    initialState: t = a(t),
    constants: n = a(n)
  };
}

function rnn$2(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
  var a = arguments.length > 4 ? arguments[4] : undefined;
  var s = arguments.length > 5 ? arguments[5] : undefined;
  var o = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : !1;
  var i = arguments.length > 7 && arguments[7] !== undefined ? arguments[7] : !1;
  return tidy$1(() => {
    var l = t.shape.length;
    if (l < 3) throw new ValueError$1("Input should be at least 3D, but is ".concat(l, "D."));
    var u = [1, 0].concat(range$7(2, l));
    if (t = transpose$5(t, u), null != s) throw new NotImplementedError$1("The rnn() functoin of the deeplearn.js backend does not support constants yet.");
    o && console.warn("Backend rnn(): the unroll = true option is not applicable to the imperative deeplearn.js backend."), null != a && ((a = cast$7(cast$7(a, "bool"), "float32")).rank === l - 1 && (a = expandDims$7(a, -1)), a = transpose$5(a, u)), r && (t = reverse$5(t, 0), null != a && (a = reverse$5(a, 0)));
    var c = [];
    var p,
        d = n;
    var h = t.shape[0],
        m = unstack$1(t);
    var f, g;
    null != a && (f = unstack$1(a));

    var _loop20 = function _loop20(_t155) {
      var n = m[_t155],
          r = tidy$1(() => e(n, d));
      if (null == a) p = r[0], d = r[1];else {
        var _e202 = tidy$1(() => {
          var e = f[_t155],
              n = sub$5(onesLike$5(e), e);
          return {
            output: add$5(mul$1(r[0], e), mul$1(d[0], n)),
            newStates: d.map((t, a) => add$5(mul$1(r[1][a], e), mul$1(t, n)))
          };
        });

        p = _e202.output, d = _e202.newStates;
      }
      i && c.push(p);
    };

    for (var _t155 = 0; _t155 < h; ++_t155) {
      _loop20(_t155);
    }

    return i && (g = stack$1(c, 1)), [p, g, d];
  });
}

DepthwiseConv2D$1.className = "DepthwiseConv2D", registerClass$1(DepthwiseConv2D$1);

class RNN$1 extends Layer$1 {
  constructor(e) {
    var t;
    if (super(e), null == e.cell) throw new ValueError$1("cell property is missing for the constructor of RNN.");
    if (t = Array.isArray(e.cell) ? new StackedRNNCells$1({
      cells: e.cell
    }) : e.cell, null == t.stateSize) throw new ValueError$1("The RNN cell should have an attribute `stateSize` (tuple of integers, one integer per RNN state).");
    this.cell = t, this.returnSequences = null != e.returnSequences && e.returnSequences, this.returnState = null != e.returnState && e.returnState, this.goBackwards = null != e.goBackwards && e.goBackwards, this._stateful = null != e.stateful && e.stateful, this.unroll = null != e.unroll && e.unroll, this.supportsMasking = !0, this.inputSpec = [new InputSpec$1({
      ndim: 3
    })], this.stateSpec = null, this.states_ = null, this.numConstants = null, this.keptStates = [];
  }

  getStates() {
    return null == this.states_ ? range$7(0, Array.isArray(this.cell.stateSize) ? this.cell.stateSize.length : 1).map(e => null) : this.states_;
  }

  setStates(e) {
    this.states_ = e;
  }

  computeOutputShape(e) {
    isArrayOfShapes$1(e) && (e = e[0]), e = e;
    var t = this.cell.stateSize;
    Array.isArray(t) || (t = [t]);
    var n = t[0];
    var r;

    if (r = this.returnSequences ? [e[0], e[1], n] : [e[0], n], this.returnState) {
      var _n69 = [];

      for (var _r54 of t) {
        _n69.push([e[0], _r54]);
      }

      return [r].concat(_n69);
    }

    return r;
  }

  computeMask(e, t) {
    return tidy$1(() => {
      Array.isArray(t) && (t = t[0]);
      var e = this.returnSequences ? t : null;

      if (this.returnState) {
        var _t156 = this.states.map(e => null);

        return [e].concat(_t156);
      }

      return e;
    });
  }

  get states() {
    if (null == this.states_) {
      var _e203 = Array.isArray(this.cell.stateSize) ? this.cell.stateSize.length : 1,
          t = [];

      for (var n = 0; n < _e203; ++n) {
        t.push(null);
      }

      return t;
    }

    return this.states_;
  }

  set states(e) {
    this.states_ = e;
  }

  build(e) {
    if (null != this.numConstants) throw new NotImplementedError$1("Constants support is not implemented in RNN yet.");
    isArrayOfShapes$1(e) && (e = e[0]), e = e;
    var t = this.stateful ? e[0] : null,
        n = e.slice(2);
    this.inputSpec[0] = new InputSpec$1({
      shape: [t, null, ...n]
    });
    var r = [e[0]].concat(e.slice(2));
    var a;

    if (this.cell.build(r), a = Array.isArray(this.cell.stateSize) ? this.cell.stateSize : [this.cell.stateSize], null != this.stateSpec) {
      if (!arraysEqual$1(this.stateSpec.map(e => e.shape[e.shape.length - 1]), a)) throw new ValueError$1("An initialState was passed that is not compatible with cell.stateSize. Received stateSpec=".concat(this.stateSpec, "; However cell.stateSize is ").concat(this.cell.stateSize));
    } else this.stateSpec = a.map(e => new InputSpec$1({
      shape: [null, e]
    }));

    this.stateful && this.resetStates();
  }

  resetStates(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;
    tidy$1(() => {
      if (!this.stateful) throw new AttributeError$1("Cannot call resetStates() on an RNN Layer that is not stateful.");
      var n = this.inputSpec[0].shape[0];
      if (null == n) throw new ValueError$1("If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.");
      if (null == this.states_) this.states_ = Array.isArray(this.cell.stateSize) ? this.cell.stateSize.map(e => zeros$4([n, e])) : [zeros$4([n, this.cell.stateSize])];else if (null == e) dispose$1(this.states_), null != this.keptStates && (dispose$1(this.keptStates), this.keptStates = []), Array.isArray(this.cell.stateSize) ? this.states_ = this.cell.stateSize.map(e => zeros$4([n, e])) : this.states_[0] = zeros$4([n, this.cell.stateSize]);else {
        if (Array.isArray(e) || (e = [e]), e.length !== this.states_.length) throw new ValueError$1("Layer ".concat(this.name, " expects ").concat(this.states_.length, " state(s), but it received ").concat(e.length, " state value(s). Input received: ").concat(e));
        !0 === t ? this.keptStates.push(this.states_.slice()) : dispose$1(this.states_);

        for (var _t157 = 0; _t157 < this.states_.length; ++_t157) {
          var r = e[_t157],
              a = Array.isArray(this.cell.stateSize) ? this.cell.stateSize[_t157] : this.cell.stateSize,
              s = [n, a];
          if (!arraysEqual$1(r.shape, s)) throw new ValueError$1("State ".concat(_t157, " is incompatible with layer ").concat(this.name, ": expected shape=").concat(s, ", received shape=").concat(r.shape));
          this.states_[_t157] = r;
        }
      }
      this.states_ = this.states_.map(e => keep$1(e.clone()));
    });
  }

  apply(e, t) {
    var n = null == t ? null : t.initialState,
        r = null == t ? null : t.constants;
    null == t && (t = {});
    var a = standardizeArgs$1(e, n, r, this.numConstants);
    e = a.inputs, n = a.initialState, r = a.constants;
    var s = [],
        o = [];

    if (null != n) {
      t.initialState = n, s = s.concat(n), this.stateSpec = [];

      for (var _e204 of n) {
        this.stateSpec.push(new InputSpec$1({
          shape: _e204.shape
        }));
      }

      o = o.concat(this.stateSpec);
    }

    if (null != r && (t.constants = r, s = s.concat(r), this.numConstants = r.length), s[0] instanceof SymbolicTensor$1) {
      var _n70 = [e].concat(s),
          _r55 = this.inputSpec.concat(o),
          _a38 = this.inputSpec;

      this.inputSpec = _r55;
      var i = super.apply(_n70, t);
      return this.inputSpec = _a38, i;
    }

    return super.apply(e, t);
  }

  call(e, t) {
    return tidy$1(() => {
      var n = null == t ? null : t.mask,
          r = null == t ? null : t.training;
      var a = null == t ? null : t.initialState;
      e = getExactlyOneTensor$1(e), null == a && (a = this.stateful ? this.states_ : this.getInitialState(e));
      var s = Array.isArray(this.cell.stateSize) ? this.cell.stateSize.length : 1;
      if (a.length !== s) throw new ValueError$1("RNN Layer has ".concat(s, " state(s) but was passed ").concat(a.length, " initial state(s)."));
      this.unroll && console.warn("Ignoring unroll = true for RNN layer, due to imperative backend.");
      var o = {
        training: r
      },
          i = rnn$2((e, t) => {
        var n = this.cell.call([e].concat(t), o);
        return [n[0], n.slice(1)];
      }, e, a, this.goBackwards, n, null, this.unroll, this.returnSequences),
          l = i[0],
          u = i[1],
          c = i[2];
      this.stateful && this.resetStates(c, r);
      var p = this.returnSequences ? u : l;
      return this.returnState ? [p].concat(c) : p;
    });
  }

  getInitialState(e) {
    return tidy$1(() => {
      var t = zeros$4(e.shape);
      return t = sum$6(t, [1, 2]), t = expandDims$6(t), Array.isArray(this.cell.stateSize) ? this.cell.stateSize.map(e => e > 1 ? tile$6(t, [1, e]) : t) : this.cell.stateSize > 1 ? [tile$6(t, [1, this.cell.stateSize])] : [t];
    });
  }

  get trainableWeights() {
    return this.trainable ? this.cell.trainableWeights : [];
  }

  get nonTrainableWeights() {
    return this.trainable ? this.cell.nonTrainableWeights : this.cell.weights;
  }

  setFastWeightInitDuringBuild(e) {
    super.setFastWeightInitDuringBuild(e), null != this.cell && this.cell.setFastWeightInitDuringBuild(e);
  }

  getConfig() {
    var e = super.getConfig(),
        t = {
      returnSequences: this.returnSequences,
      returnState: this.returnState,
      goBackwards: this.goBackwards,
      stateful: this.stateful,
      unroll: this.unroll
    };
    null != this.numConstants && (t.numConstants = this.numConstants);
    var n = this.cell.getConfig();
    return this.getClassName() === RNN$1.className && (t.cell = {
      className: this.cell.getClassName(),
      config: n
    }), Object.assign({}, n, e, t);
  }

  static fromConfig(e, t) {
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};
    var r = deserialize$1(t.cell, n);
    return new e(Object.assign(t, {
      cell: r
    }));
  }

}

RNN$1.className = "RNN", registerClass$1(RNN$1);

class RNNCell$1 extends Layer$1 {}

class SimpleRNNCell$1 extends RNNCell$1 {
  constructor(e) {
    super(e), this.DEFAULT_ACTIVATION = "tanh", this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal", this.DEFAULT_RECURRENT_INITIALIZER = "orthogonal", this.DEFAULT_BIAS_INITIALIZER = "zeros", this.units = e.units, assertPositiveInteger$1(this.units, "units"), this.activation = getActivation$1(null == e.activation ? this.DEFAULT_ACTIVATION : e.activation), this.useBias = null == e.useBias || e.useBias, this.kernelInitializer = getInitializer$1(e.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER), this.recurrentInitializer = getInitializer$1(e.recurrentInitializer || this.DEFAULT_RECURRENT_INITIALIZER), this.biasInitializer = getInitializer$1(e.biasInitializer || this.DEFAULT_BIAS_INITIALIZER), this.kernelRegularizer = getRegularizer$1(e.kernelRegularizer), this.recurrentRegularizer = getRegularizer$1(e.recurrentRegularizer), this.biasRegularizer = getRegularizer$1(e.biasRegularizer), this.kernelConstraint = getConstraint$1(e.kernelConstraint), this.recurrentConstraint = getConstraint$1(e.recurrentConstraint), this.biasConstraint = getConstraint$1(e.biasConstraint), this.dropout = min$6([1, max$6([0, null == e.dropout ? 0 : e.dropout])]), this.recurrentDropout = min$6([1, max$6([0, null == e.recurrentDropout ? 0 : e.recurrentDropout])]), this.stateSize = this.units, this.dropoutMask = null, this.recurrentDropoutMask = null;
  }

  build(e) {
    e = getExactlyOneShape$1(e), this.kernel = this.addWeight("kernel", [e[e.length - 1], this.units], null, this.kernelInitializer, this.kernelRegularizer, !0, this.kernelConstraint), this.recurrentKernel = this.addWeight("recurrent_kernel", [this.units, this.units], null, this.recurrentInitializer, this.recurrentRegularizer, !0, this.recurrentConstraint), this.bias = this.useBias ? this.addWeight("bias", [this.units], null, this.biasInitializer, this.biasRegularizer, !0, this.biasConstraint) : null, this.built = !0;
  }

  call(e, t) {
    return tidy$1(() => {
      if (2 !== (e = e).length) throw new ValueError$1("SimpleRNNCell expects 2 input Tensors, got ".concat(e.length, "."));
      var n = e[1];
      e = e[0];
      var r = null != t.training && t.training;
      var a;
      0 < this.dropout && this.dropout < 1 && null == this.dropoutMask && (this.dropoutMask = generateDropoutMask$1({
        ones: () => onesLike$5(e),
        rate: this.dropout,
        training: r
      })), 0 < this.recurrentDropout && this.recurrentDropout < 1 && null == this.recurrentDropoutMask && (this.recurrentDropoutMask = generateDropoutMask$1({
        ones: () => onesLike$5(n),
        rate: this.recurrentDropout,
        training: r
      }));
      var s = this.dropoutMask,
          o = this.recurrentDropoutMask;
      a = dot$3(null != s ? mul$1(e, s) : e, this.kernel.read()), null != this.bias && (a = biasAdd$1(a, this.bias.read())), null != o && (n = mul$1(n, o));
      var i = add$5(a, dot$3(n, this.recurrentKernel.read()));
      return null != this.activation && (i = this.activation.apply(i)), [i, i];
    });
  }

  getConfig() {
    var e = super.getConfig(),
        t = {
      units: this.units,
      activation: serializeActivation$1(this.activation),
      useBias: this.useBias,
      kernelInitializer: serializeInitializer$1(this.kernelInitializer),
      recurrentInitializer: serializeInitializer$1(this.recurrentInitializer),
      biasInitializer: serializeInitializer$1(this.biasInitializer),
      kernelRegularizer: serializeRegularizer$1(this.kernelRegularizer),
      recurrentRegularizer: serializeRegularizer$1(this.recurrentRegularizer),
      biasRegularizer: serializeRegularizer$1(this.biasRegularizer),
      activityRegularizer: serializeRegularizer$1(this.activityRegularizer),
      kernelConstraint: serializeConstraint$1(this.kernelConstraint),
      recurrentConstraint: serializeConstraint$1(this.recurrentConstraint),
      biasConstraint: serializeConstraint$1(this.biasConstraint),
      dropout: this.dropout,
      recurrentDropout: this.recurrentDropout
    };
    return Object.assign({}, e, t);
  }

}

SimpleRNNCell$1.className = "SimpleRNNCell", registerClass$1(SimpleRNNCell$1);

class SimpleRNN$1 extends RNN$1 {
  constructor(e) {
    e.cell = new SimpleRNNCell$1(e), super(e);
  }

  call(e, t) {
    return tidy$1(() => (null != this.cell.dropoutMask && (dispose$1(this.cell.dropoutMask), this.cell.dropoutMask = null), null != this.cell.recurrentDropoutMask && (dispose$1(this.cell.recurrentDropoutMask), this.cell.recurrentDropoutMask = null), super.call(e, {
      mask: null == t ? null : t.mask,
      training: null == t ? null : t.training,
      initialState: null == t ? null : t.initialState
    })));
  }

  static fromConfig(e, t) {
    return new e(t);
  }

}

SimpleRNN$1.className = "SimpleRNN", registerClass$1(SimpleRNN$1);

class GRUCell$1 extends RNNCell$1 {
  constructor(e) {
    if (super(e), this.DEFAULT_ACTIVATION = "tanh", this.DEFAULT_RECURRENT_ACTIVATION = "hardSigmoid", this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal", this.DEFAULT_RECURRENT_INITIALIZER = "orthogonal", this.DEFAULT_BIAS_INITIALIZER = "zeros", e.resetAfter) throw new ValueError$1("GRUCell does not support reset_after parameter set to true.");
    this.units = e.units, assertPositiveInteger$1(this.units, "units"), this.activation = getActivation$1(void 0 === e.activation ? this.DEFAULT_ACTIVATION : e.activation), this.recurrentActivation = getActivation$1(void 0 === e.recurrentActivation ? this.DEFAULT_RECURRENT_ACTIVATION : e.recurrentActivation), this.useBias = null == e.useBias || e.useBias, this.kernelInitializer = getInitializer$1(e.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER), this.recurrentInitializer = getInitializer$1(e.recurrentInitializer || this.DEFAULT_RECURRENT_INITIALIZER), this.biasInitializer = getInitializer$1(e.biasInitializer || this.DEFAULT_BIAS_INITIALIZER), this.kernelRegularizer = getRegularizer$1(e.kernelRegularizer), this.recurrentRegularizer = getRegularizer$1(e.recurrentRegularizer), this.biasRegularizer = getRegularizer$1(e.biasRegularizer), this.kernelConstraint = getConstraint$1(e.kernelConstraint), this.recurrentConstraint = getConstraint$1(e.recurrentConstraint), this.biasConstraint = getConstraint$1(e.biasConstraint), this.dropout = min$6([1, max$6([0, null == e.dropout ? 0 : e.dropout])]), this.recurrentDropout = min$6([1, max$6([0, null == e.recurrentDropout ? 0 : e.recurrentDropout])]), this.implementation = e.implementation, this.stateSize = this.units, this.dropoutMask = null, this.recurrentDropoutMask = null;
  }

  build(e) {
    e = getExactlyOneShape$1(e), this.kernel = this.addWeight("kernel", [e[e.length - 1], 3 * this.units], null, this.kernelInitializer, this.kernelRegularizer, !0, this.kernelConstraint), this.recurrentKernel = this.addWeight("recurrent_kernel", [this.units, 3 * this.units], null, this.recurrentInitializer, this.recurrentRegularizer, !0, this.recurrentConstraint), this.bias = this.useBias ? this.addWeight("bias", [3 * this.units], null, this.biasInitializer, this.biasRegularizer, !0, this.biasConstraint) : null, this.built = !0;
  }

  call(e, t) {
    return tidy$1(() => {
      if (2 !== (e = e).length) throw new ValueError$1("GRUCell expects 2 input Tensors (inputs, h, c), got ".concat(e.length, "."));
      var n = null != t.training && t.training;
      var r = e[1];
      e = e[0], 0 < this.dropout && this.dropout < 1 && null == this.dropoutMask && (this.dropoutMask = generateDropoutMask$1({
        ones: () => onesLike$5(e),
        rate: this.dropout,
        training: n,
        count: 3
      })), 0 < this.recurrentDropout && this.recurrentDropout < 1 && null == this.recurrentDropoutMask && (this.recurrentDropoutMask = generateDropoutMask$1({
        ones: () => onesLike$5(r),
        rate: this.recurrentDropout,
        training: n,
        count: 3
      }));
      var a = this.recurrentDropoutMask;
      var s, o, i;
      0 < this.dropout && this.dropout < 1 && (e = mul$1(e, this.dropoutMask[0]));
      var l = dot$3(e, this.kernel.read());
      this.useBias && (l = biasAdd$1(l, this.bias.read())), 0 < this.recurrentDropout && this.recurrentDropout < 1 && (r = mul$1(r, a[0]));
      var u = this.recurrentKernel.read(),
          [c, p] = split$4(u, [2 * this.units, this.units], u.rank - 1),
          d = dot$3(r, c),
          [h, m, f] = split$4(l, 3, l.rank - 1),
          [g, $] = split$4(d, 2, d.rank - 1);
      s = this.recurrentActivation.apply(add$5(h, g)), o = this.recurrentActivation.apply(add$5(m, $));
      var y = dot$3(mul$1(o, r), p);
      i = this.activation.apply(add$5(f, y));
      var b = add$5(mul$1(s, r), mul$1(add$5(1, neg$5(s)), i));
      return [b, b];
    });
  }

  getConfig() {
    var e = super.getConfig(),
        t = {
      units: this.units,
      activation: serializeActivation$1(this.activation),
      recurrentActivation: serializeActivation$1(this.recurrentActivation),
      useBias: this.useBias,
      kernelInitializer: serializeInitializer$1(this.kernelInitializer),
      recurrentInitializer: serializeInitializer$1(this.recurrentInitializer),
      biasInitializer: serializeInitializer$1(this.biasInitializer),
      kernelRegularizer: serializeRegularizer$1(this.kernelRegularizer),
      recurrentRegularizer: serializeRegularizer$1(this.recurrentRegularizer),
      biasRegularizer: serializeRegularizer$1(this.biasRegularizer),
      activityRegularizer: serializeRegularizer$1(this.activityRegularizer),
      kernelConstraint: serializeConstraint$1(this.kernelConstraint),
      recurrentConstraint: serializeConstraint$1(this.recurrentConstraint),
      biasConstraint: serializeConstraint$1(this.biasConstraint),
      dropout: this.dropout,
      recurrentDropout: this.recurrentDropout,
      implementation: this.implementation,
      resetAfter: !1
    };
    return Object.assign({}, e, t);
  }

}

GRUCell$1.className = "GRUCell", registerClass$1(GRUCell$1);

class GRU$1 extends RNN$1 {
  constructor(e) {
    0 === e.implementation && console.warn("`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call."), e.cell = new GRUCell$1(e), super(e);
  }

  call(e, t) {
    return tidy$1(() => (null != this.cell.dropoutMask && (dispose$1(this.cell.dropoutMask), this.cell.dropoutMask = null), null != this.cell.recurrentDropoutMask && (dispose$1(this.cell.recurrentDropoutMask), this.cell.recurrentDropoutMask = null), super.call(e, {
      mask: null == t ? null : t.mask,
      training: null == t ? null : t.training,
      initialState: null == t ? null : t.initialState
    })));
  }

  static fromConfig(e, t) {
    return 0 === t.implmentation && (t.implementation = 1), new e(t);
  }

}

GRU$1.className = "GRU", registerClass$1(GRU$1);

class LSTMCell$1 extends RNNCell$1 {
  constructor(e) {
    super(e), this.DEFAULT_ACTIVATION = "tanh", this.DEFAULT_RECURRENT_ACTIVATION = "hardSigmoid", this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal", this.DEFAULT_RECURRENT_INITIALIZER = "orthogonal", this.DEFAULT_BIAS_INITIALIZER = "zeros", this.units = e.units, assertPositiveInteger$1(this.units, "units"), this.activation = getActivation$1(void 0 === e.activation ? this.DEFAULT_ACTIVATION : e.activation), this.recurrentActivation = getActivation$1(void 0 === e.recurrentActivation ? this.DEFAULT_RECURRENT_ACTIVATION : e.recurrentActivation), this.useBias = null == e.useBias || e.useBias, this.kernelInitializer = getInitializer$1(e.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER), this.recurrentInitializer = getInitializer$1(e.recurrentInitializer || this.DEFAULT_RECURRENT_INITIALIZER), this.biasInitializer = getInitializer$1(e.biasInitializer || this.DEFAULT_BIAS_INITIALIZER), this.unitForgetBias = e.unitForgetBias, this.kernelRegularizer = getRegularizer$1(e.kernelRegularizer), this.recurrentRegularizer = getRegularizer$1(e.recurrentRegularizer), this.biasRegularizer = getRegularizer$1(e.biasRegularizer), this.kernelConstraint = getConstraint$1(e.kernelConstraint), this.recurrentConstraint = getConstraint$1(e.recurrentConstraint), this.biasConstraint = getConstraint$1(e.biasConstraint), this.dropout = min$6([1, max$6([0, null == e.dropout ? 0 : e.dropout])]), this.recurrentDropout = min$6([1, max$6([0, null == e.recurrentDropout ? 0 : e.recurrentDropout])]), this.implementation = e.implementation, this.stateSize = [this.units, this.units], this.dropoutMask = null, this.recurrentDropoutMask = null;
  }

  build(e) {
    var t;
    var n;

    if (e = getExactlyOneShape$1(e), this.kernel = this.addWeight("kernel", [e[e.length - 1], 4 * this.units], null, this.kernelInitializer, this.kernelRegularizer, !0, this.kernelConstraint), this.recurrentKernel = this.addWeight("recurrent_kernel", [this.units, 4 * this.units], null, this.recurrentInitializer, this.recurrentRegularizer, !0, this.recurrentConstraint), this.useBias) {
      if (this.unitForgetBias) {
        var _e205 = this.biasInitializer,
            r = this.units;
        n = new ((t = class extends Initializer$1 {
          apply(t, n) {
            var a = _e205.apply([r]),
                s = new Ones$1().apply([r]),
                o = _e205.apply([2 * r]);

            return concatAlongFirstAxis$1(concatAlongFirstAxis$1(a, s), o);
          }

        }).className = "CustomInit", t)();
      } else n = this.biasInitializer;

      this.bias = this.addWeight("bias", [4 * this.units], null, n, this.biasRegularizer, !0, this.biasConstraint);
    } else this.bias = null;

    this.built = !0;
  }

  call(e, t) {
    return tidy$1(() => {
      var n = null != t.training && t.training;
      if (3 !== (e = e).length) throw new ValueError$1("LSTMCell expects 3 input Tensors (inputs, h, c), got ".concat(e.length, "."));
      var r = e[1];
      var a = e[2];
      e = e[0], 0 < this.dropout && this.dropout < 1 && null == this.dropoutMask && (this.dropoutMask = generateDropoutMask$1({
        ones: () => onesLike$5(e),
        rate: this.dropout,
        training: n,
        count: 4
      })), 0 < this.recurrentDropout && this.recurrentDropout < 1 && null == this.recurrentDropoutMask && (this.recurrentDropoutMask = generateDropoutMask$1({
        ones: () => onesLike$5(r),
        rate: this.recurrentDropout,
        training: n,
        count: 4
      }));
      var s = this.recurrentDropoutMask;
      var o, i, l, u;
      0 < this.dropout && this.dropout < 1 && (e = mul$1(e, this.dropoutMask[0]));
      var c = dot$3(e, this.kernel.read());
      0 < this.recurrentDropout && this.recurrentDropout < 1 && (r = mul$1(r, s[0])), c = add$5(c, dot$3(r, this.recurrentKernel.read())), this.useBias && (c = biasAdd$1(c, this.bias.read()));
      var [p, d, h, m] = split$4(c, 4, c.rank - 1);
      o = this.recurrentActivation.apply(p), i = this.recurrentActivation.apply(d), l = add$5(mul$1(i, a), mul$1(o, this.activation.apply(h))), u = this.recurrentActivation.apply(m);
      var f = mul$1(u, this.activation.apply(l));
      return [f, f, l];
    });
  }

  getConfig() {
    var e = super.getConfig(),
        t = {
      units: this.units,
      activation: serializeActivation$1(this.activation),
      recurrentActivation: serializeActivation$1(this.recurrentActivation),
      useBias: this.useBias,
      kernelInitializer: serializeInitializer$1(this.kernelInitializer),
      recurrentInitializer: serializeInitializer$1(this.recurrentInitializer),
      biasInitializer: serializeInitializer$1(this.biasInitializer),
      unitForgetBias: this.unitForgetBias,
      kernelRegularizer: serializeRegularizer$1(this.kernelRegularizer),
      recurrentRegularizer: serializeRegularizer$1(this.recurrentRegularizer),
      biasRegularizer: serializeRegularizer$1(this.biasRegularizer),
      activityRegularizer: serializeRegularizer$1(this.activityRegularizer),
      kernelConstraint: serializeConstraint$1(this.kernelConstraint),
      recurrentConstraint: serializeConstraint$1(this.recurrentConstraint),
      biasConstraint: serializeConstraint$1(this.biasConstraint),
      dropout: this.dropout,
      recurrentDropout: this.recurrentDropout,
      implementation: this.implementation
    };
    return Object.assign({}, e, t);
  }

}

LSTMCell$1.className = "LSTMCell", registerClass$1(LSTMCell$1);

class LSTM$1 extends RNN$1 {
  constructor(e) {
    0 === e.implementation && console.warn("`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call."), e.cell = new LSTMCell$1(e), super(e);
  }

  call(e, t) {
    return tidy$1(() => (null != this.cell.dropoutMask && (dispose$1(this.cell.dropoutMask), this.cell.dropoutMask = null), null != this.cell.recurrentDropoutMask && (dispose$1(this.cell.recurrentDropoutMask), this.cell.recurrentDropoutMask = null), super.call(e, {
      mask: null == t ? null : t.mask,
      training: null == t ? null : t.training,
      initialState: null == t ? null : t.initialState
    })));
  }

  static fromConfig(e, t) {
    return 0 === t.implmentation && (t.implementation = 1), new e(t);
  }

}

LSTM$1.className = "LSTM", registerClass$1(LSTM$1);

class StackedRNNCells$1 extends RNNCell$1 {
  constructor(e) {
    super(e), this.cells = e.cells;
  }

  get stateSize() {
    var e = [];

    for (var t of this.cells.slice().reverse()) {
      Array.isArray(t.stateSize) ? e.push(...t.stateSize) : e.push(t.stateSize);
    }

    return e;
  }

  call(e, t) {
    return tidy$1(() => {
      var n = (e = e).slice(1);
      var r = [];

      for (var _e206 of this.cells.slice().reverse()) {
        Array.isArray(_e206.stateSize) ? r.push(n.splice(0, _e206.stateSize.length)) : r.push(n.splice(0, 1));
      }

      r.reverse();
      var a = [];
      var s;

      for (var o = 0; o < this.cells.length; ++o) {
        var i = this.cells[o];
        n = r[o], s = 0 === o ? [e[0]].concat(n) : [s[0]].concat(n), s = i.call(s, t), a.push(s.slice(1));
      }

      n = [];

      for (var _e207 of a.slice().reverse()) {
        n.push(..._e207);
      }

      return [s[0]].concat(n);
    });
  }

  build(e) {
    var t;
    isArrayOfShapes$1(e) && (e = e[0]), e = e, this.cells.forEach((n, r) => {
      nameScope$1("RNNCell_".concat(r), () => {
        n.build(e), t = Array.isArray(n.stateSize) ? n.stateSize[0] : n.stateSize, e = [e[0], t];
      });
    }), this.built = !0;
  }

  getConfig() {
    var e = super.getConfig(),
        t = this.cells.map(e => ({
      className: e.getClassName(),
      config: e.getConfig()
    }));
    return Object.assign({}, e, {
      cells: t
    });
  }

  static fromConfig(e, t) {
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};
    var r = [];

    for (var _e208 of t.cells) {
      r.push(deserialize$1(_e208, n));
    }

    return new e({
      cells: r
    });
  }

  get trainableWeights() {
    if (!this.trainable) return [];
    var e = [];

    for (var t of this.cells) {
      e.push(...t.trainableWeights);
    }

    return e;
  }

  get nonTrainableWeights() {
    var e = [];

    for (var t of this.cells) {
      e.push(...t.nonTrainableWeights);
    }

    if (!this.trainable) {
      var _t158 = [];

      for (var _e209 of this.cells) {
        _t158.push(..._e209.trainableWeights);
      }

      return _t158.concat(e);
    }

    return e;
  }

  getWeights() {
    var e = [];

    for (var t of this.cells) {
      e.push(...t.weights);
    }

    return batchGetValue$1(e);
  }

  setWeights(e) {
    var t = [];

    for (var n of this.cells) {
      var r = e.splice(n.weights.length);

      for (var _e210 = 0; _e210 < n.weights.length; ++_e210) {
        t.push([n.weights[_e210], r[_e210]]);
      }
    }

    batchSetValue$1(t);
  }

}

function generateDropoutMask$1(e) {
  var {
    ones: t,
    rate: n,
    training: r = !1,
    count: a = 1
  } = e,
      s = () => dropout$4(t(), n),
      o = () => inTrainPhase$1(s, t, r);

  return !a || a <= 1 ? keep$1(o().clone()) : Array(a).fill(void 0).map(o).map(e => keep$1(e.clone()));
}

StackedRNNCells$1.className = "StackedRNNCells", registerClass$1(StackedRNNCells$1);

var __rest$1 = function __rest$1(e, t) {
  var n = {};

  for (var r in e) {
    Object.prototype.hasOwnProperty.call(e, r) && t.indexOf(r) < 0 && (n[r] = e[r]);
  }

  if (null != e && "function" == typeof Object.getOwnPropertySymbols) {
    var a = 0;

    for (r = Object.getOwnPropertySymbols(e); a < r.length; a++) {
      t.indexOf(r[a]) < 0 && Object.prototype.propertyIsEnumerable.call(e, r[a]) && (n[r[a]] = e[r[a]]);
    }
  }

  return n;
};

class ConvRNN2D$1 extends RNN$1 {
  constructor(e) {
    if (e.unroll) throw new NotImplementedError$1("Unrolling is not possible with convolutional RNNs.");
    if (Array.isArray(e.cell)) throw new NotImplementedError$1("It is not possible at the moment to stack convolutional cells.");
    super(e), this.inputSpec = [new InputSpec$1({
      ndim: 5
    })];
  }

  call(e, t) {
    return tidy$1(() => {
      if (null != this.cell.dropoutMask && (dispose$1(this.cell.dropoutMask), this.cell.dropoutMask = null), null != this.cell.recurrentDropoutMask && (dispose$1(this.cell.recurrentDropoutMask), this.cell.recurrentDropoutMask = null), t && t.constants) throw new ValueError$1("ConvRNN2D cell does not support constants");
      return super.call(e, {
        mask: null == t ? null : t.mask,
        training: null == t ? null : t.training,
        initialState: null == t ? null : t.initialState
      });
    });
  }

  computeOutputShape(e) {
    var t = this.computeSingleOutputShape(e);
    return this.returnSequences || (t = [t[0], ...t.slice(2)]), this.returnState && (t = [t, ...Array(2).fill([e[0], ...t.slice(-3)])]), t;
  }

  getInitialState(e) {
    return tidy$1(() => {
      var {
        stateSize: t
      } = this.cell,
          n = this.computeSingleOutputShape(e.shape),
          r = zeros$4([n[0], ...n.slice(2)]);
      return Array.isArray(t) ? Array(t.length).fill(r) : [r];
    });
  }

  resetStates(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;
    tidy$1(() => {
      if (!this.stateful) throw new AttributeError$1("Cannot call resetStates() on an RNN Layer that is not stateful.");
      var n = this.inputSpec[0].shape,
          r = this.computeSingleOutputShape(n),
          a = [r[0], ...r.slice(2)];
      if (null == n[0]) throw new ValueError$1("If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.");
      if (null == this.getStates()) this.states_ = Array.isArray(this.cell.stateSize) ? this.cell.stateSize.map(() => zeros$4(a)) : [zeros$4(a)];else if (null == e) dispose$1(this.states_), null != this.keptStates && (dispose$1(this.keptStates), this.keptStates = []), Array.isArray(this.cell.stateSize) ? this.states_ = this.cell.stateSize.map(() => zeros$4(a)) : this.states_[0] = zeros$4(a);else {
        if (Array.isArray(e) || (e = [e]), e.length !== this.states_.length) throw new ValueError$1("Layer ".concat(this.name, " expects ").concat(this.states_.length, " state(s), but it received ").concat(e.length, " state value(s). Input received: ").concat(e));
        t ? this.keptStates.push(this.states_.slice()) : dispose$1(this.states_);

        for (var _t159 = 0; _t159 < this.states_.length; ++_t159) {
          var _n71 = e[_t159],
              _r56 = a;
          if (!arraysEqual$1(_n71.shape, _r56)) throw new ValueError$1("State ".concat(_t159, " is incompatible with layer ").concat(this.name, ": expected shape=").concat(_r56, ", received shape=").concat(_n71.shape));
          this.states_[_t159] = _n71;
        }
      }
      this.states_ = this.states_.map(e => keep$1(e.clone()));
    });
  }

  computeSingleOutputShape(e) {
    var {
      dataFormat: t,
      filters: n,
      kernelSize: r,
      padding: a,
      strides: s,
      dilationRate: o
    } = this.cell,
        i = "channelsFirst" === t,
        l = e[i ? 4 : 3],
        u = convOutputLength$1(e[i ? 3 : 2], r[0], a, s[0], o[0]),
        c = convOutputLength$1(l, r[1], a, s[1], o[1]);
    return [...e.slice(0, 2), ...(i ? [n, u, c] : [u, c, n])];
  }

}

ConvRNN2D$1.className = "ConvRNN2D";

class ConvLSTM2DCell$1 extends LSTMCell$1 {
  constructor(e) {
    var {
      filters: t,
      kernelSize: n,
      strides: r,
      padding: a,
      dataFormat: s,
      dilationRate: o
    } = e;
    super(Object.assign({}, e, {
      units: t
    })), this.filters = t, assertPositiveInteger$1(this.filters, "filters"), this.kernelSize = normalizeArray$1(n, 2, "kernelSize"), this.kernelSize.forEach(e => assertPositiveInteger$1(e, "kernelSize")), this.strides = normalizeArray$1(r || 1, 2, "strides"), this.strides.forEach(e => assertPositiveInteger$1(e, "strides")), this.padding = a || "valid", checkPaddingMode$1(this.padding), this.dataFormat = s || "channelsLast", checkDataFormat$1(this.dataFormat), this.dilationRate = normalizeArray$1(o || 1, 2, "dilationRate"), this.dilationRate.forEach(e => assertPositiveInteger$1(e, "dilationRate"));
  }

  build(e) {
    var t;
    e = getExactlyOneShape$1(e);
    var n = "channelsFirst" === this.dataFormat ? 1 : e.length - 1;
    if (null == e[n]) throw new ValueError$1("The channel dimension of the input should be defined. Found ".concat(e[n]));
    var r = this.kernelSize.concat([e[n], 4 * this.filters]);
    this.kernel = this.addWeight("kernel", r, null, this.kernelInitializer, this.kernelRegularizer, !0, this.kernelConstraint);
    var a = this.kernelSize.concat([this.filters, 4 * this.filters]);

    if (this.recurrentKernel = this.addWeight("recurrent_kernel", a, null, this.recurrentInitializer, this.recurrentRegularizer, !0, this.recurrentConstraint), this.useBias) {
      var _e211;

      if (this.unitForgetBias) {
        var _n72 = this.biasInitializer,
            _r57 = this.filters;
        _e211 = new (t = class extends Initializer$1 {
          apply(e, t) {
            return concatenate$2([_n72.apply([_r57]), ones$3([_r57]), _n72.apply([2 * _r57])]);
          }

        }, t.className = "CustomInit", t)();
      } else _e211 = this.biasInitializer;

      this.bias = this.addWeight("bias", [4 * this.filters], null, _e211, this.biasRegularizer, !0, this.biasConstraint);
    }

    this.built = !0;
  }

  call(e, t) {
    return tidy$1(() => {
      if (3 !== e.length) throw new ValueError$1("ConvLSTM2DCell expects 3 input Tensors (inputs, h, c), got ".concat(e.length, "."));
      var n = t.training || !1,
          r = e[0],
          a = e[1],
          s = e[2];
      0 < this.dropout && this.dropout < 1 && null == this.dropoutMask && (this.dropoutMask = generateDropoutMask$1({
        ones: () => onesLike$5(r),
        rate: this.dropout,
        training: n,
        count: 4
      }));

      var o = this.dropoutMask,
          i = (e, t, n) => t && t[n] ? mul$1(t[n], e) : e;

      var l = i(r, o, 0),
          u = i(r, o, 1),
          c = i(r, o, 2),
          p = i(r, o, 3);
      0 < this.recurrentDropout && this.recurrentDropout < 1 && null == this.recurrentDropoutMask && (this.recurrentDropoutMask = generateDropoutMask$1({
        ones: () => onesLike$5(a),
        rate: this.recurrentDropout,
        training: n,
        count: 4
      }));
      var d = this.recurrentDropoutMask;
      var h = i(a, d, 0),
          m = i(a, d, 1),
          f = i(a, d, 2),
          g = i(a, d, 3);
      var [$, y, b, x] = split$4(this.kernel.read(), 4, 3),
          [v, I, C, S] = this.useBias ? split$4(this.bias.read(), 4) : [null, null, null, null];
      l = this.inputConv(l, $, v, this.padding), u = this.inputConv(u, y, I, this.padding), c = this.inputConv(c, b, C, this.padding), p = this.inputConv(p, x, S, this.padding);
      var [k, T, N, w] = split$4(this.recurrentKernel.read(), 4, 3);
      h = this.recurrentConv(h, k), m = this.recurrentConv(m, T), f = this.recurrentConv(f, N), g = this.recurrentConv(g, w);
      var E = this.recurrentActivation.apply(add$5(l, h)),
          A = this.recurrentActivation.apply(add$5(u, m)),
          D = add$5(mul$1(A, s), mul$1(E, this.activation.apply(add$5(c, f)))),
          R = mul$1(this.recurrentActivation.apply(add$5(p, g)), this.activation.apply(D));
      return [R, R, D];
    });
  }

  getConfig() {
    var e = super.getConfig(),
        t = __rest$1(e, ["units"]);

    return Object.assign({}, t, {
      filters: this.filters,
      kernelSize: this.kernelSize,
      padding: this.padding,
      dataFormat: this.dataFormat,
      dilationRate: this.dilationRate,
      strides: this.strides
    });
  }

  inputConv(e, t, n, r) {
    var a = conv2d$7(e, t, this.strides, r || "valid", "channelsFirst" === this.dataFormat ? "NCHW" : "NHWC", this.dilationRate);
    return n ? biasAdd$1(a, n, this.dataFormat) : a;
  }

  recurrentConv(e, t) {
    return conv2d$7(e, t, 1, "same", "channelsFirst" === this.dataFormat ? "NCHW" : "NHWC");
  }

}

ConvLSTM2DCell$1.className = "ConvLSTM2DCell", registerClass$1(ConvLSTM2DCell$1);

class ConvLSTM2D$1 extends ConvRNN2D$1 {
  constructor(e) {
    var t = new ConvLSTM2DCell$1(e);
    super(Object.assign({}, e, {
      cell: t
    }));
  }

  static fromConfig(e, t) {
    return new e(t);
  }

}

ConvLSTM2D$1.className = "ConvLSTM2D", registerClass$1(ConvLSTM2D$1);

class Dropout$1 extends Layer$1 {
  constructor(e) {
    super(e), this.rate = Math.max(Math.min(e.rate, 1), 0), this.noiseShape = e.noiseShape, this.seed = e.seed, this.supportsMasking = !0;
  }

  getNoiseShape(e) {
    if (null == this.noiseShape) return this.noiseShape;
    var t = e.shape,
        n = [];

    for (var _e212 = 0; _e212 < this.noiseShape.length; ++_e212) {
      n.push(null == this.noiseShape[_e212] ? t[_e212] : this.noiseShape[_e212]);
    }

    return n;
  }

  call(e, t) {
    return tidy$1(() => {
      this.invokeCallHook(e, t);
      var n = getExactlyOneTensor$1(e);

      if (0 < this.rate && this.rate < 1) {
        var _e213 = null != t.training && t.training,
            r = this.getNoiseShape(n);

        return inTrainPhase$1(() => dropout$4(n, this.rate, r, this.seed), () => n, _e213);
      }

      return e;
    });
  }

  getConfig() {
    var e = {
      rate: this.rate,
      noiseShape: this.noiseShape,
      seed: this.seed
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

  dispose() {
    return super.dispose();
  }

}

Dropout$1.className = "Dropout", registerClass$1(Dropout$1);

class SpatialDropout1D$1 extends Dropout$1 {
  constructor(e) {
    super(e), this.inputSpec = [{
      ndim: 3
    }];
  }

  getNoiseShape(e) {
    var t = e.shape;
    return [t[0], 1, t[2]];
  }

}

SpatialDropout1D$1.className = "SpatialDropout1D", registerClass$1(SpatialDropout1D$1);

class Dense$1 extends Layer$1 {
  constructor(e) {
    if (super(e), this.activation = null, this.useBias = !0, this.kernel = null, this.bias = null, this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal", this.DEFAULT_BIAS_INITIALIZER = "zeros", null == e.batchInputShape && null == e.inputShape && null != e.inputDim) {
      var t = null;
      null != e.batchSize && (t = e.batchSize), this.batchInputShape = [t, e.inputDim];
    }

    this.units = e.units, assertPositiveInteger$1(this.units, "units"), this.activation = getActivation$1(e.activation), null != e.useBias && (this.useBias = e.useBias), this.kernelInitializer = getInitializer$1(e.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER), this.biasInitializer = getInitializer$1(e.biasInitializer || this.DEFAULT_BIAS_INITIALIZER), this.kernelConstraint = getConstraint$1(e.kernelConstraint), this.biasConstraint = getConstraint$1(e.biasConstraint), this.kernelRegularizer = getRegularizer$1(e.kernelRegularizer), this.biasRegularizer = getRegularizer$1(e.biasRegularizer), this.activityRegularizer = getRegularizer$1(e.activityRegularizer), this.supportsMasking = !0, this.inputSpec = [{
      minNDim: 2
    }];
  }

  build(e) {
    var t = (e = getExactlyOneShape$1(e))[e.length - 1];
    null == this.kernel && (this.kernel = this.addWeight("kernel", [t, this.units], null, this.kernelInitializer, this.kernelRegularizer, !0, this.kernelConstraint), this.useBias && (this.bias = this.addWeight("bias", [this.units], null, this.biasInitializer, this.biasRegularizer, !0, this.biasConstraint))), this.inputSpec = [{
      minNDim: 2,
      axes: {
        [-1]: t
      }
    }], this.built = !0;
  }

  computeOutputShape(e) {
    var t = (e = getExactlyOneShape$1(e)).slice();
    return t[t.length - 1] = this.units, t;
  }

  call(e, t) {
    return tidy$1(() => {
      this.invokeCallHook(e, t);
      var n = getExactlyOneTensor$1(e),
          r = mapActivationToFusedKernel$1(this.activation.getClassName());
      var a;
      return null != r ? a = dot$3(n, this.kernel.read(), r, this.bias ? this.bias.read() : null) : (a = dot$3(n, this.kernel.read()), null != this.bias && (a = biasAdd$1(a, this.bias.read())), null != this.activation && (a = this.activation.apply(a))), a;
    });
  }

  getConfig() {
    var e = {
      units: this.units,
      activation: serializeActivation$1(this.activation),
      useBias: this.useBias,
      kernelInitializer: serializeInitializer$1(this.kernelInitializer),
      biasInitializer: serializeInitializer$1(this.biasInitializer),
      kernelRegularizer: serializeRegularizer$1(this.kernelRegularizer),
      biasRegularizer: serializeRegularizer$1(this.biasRegularizer),
      activityRegularizer: serializeRegularizer$1(this.activityRegularizer),
      kernelConstraint: serializeConstraint$1(this.kernelConstraint),
      biasConstraint: serializeConstraint$1(this.biasConstraint)
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

Dense$1.className = "Dense", registerClass$1(Dense$1);

class Flatten$1 extends Layer$1 {
  constructor(e) {
    super(e = e || {}), this.inputSpec = [{
      minNDim: 3
    }], this.dataFormat = e.dataFormat;
  }

  computeOutputShape(e) {
    e = getExactlyOneShape$1(e);

    for (var t of e.slice(1)) {
      if (null == t) throw new ValueError$1("The shape of the input to \"Flatten\" is not fully defined (got ".concat(e.slice(1), "). Make sure to pass a complete \"input_shape\" or \"batch_input_shape\" argument to the first layer in your model."));
    }

    return [e[0], arrayProd$1(e, 1)];
  }

  call(e, t) {
    return tidy$1(() => {
      this.invokeCallHook(e, t);
      var n = getExactlyOneTensor$1(e);

      if ("channelsFirst" === this.dataFormat && n.rank > 1) {
        var _e214 = [0];

        for (var _t160 = 2; _t160 < n.rank; ++_t160) {
          _e214.push(_t160);
        }

        _e214.push(1), n = transpose$5(n, _e214);
      }

      return batchFlatten$1(n);
    });
  }

  getConfig() {
    var e = {};
    null != this.dataFormat && (e.dataFormat = this.dataFormat);
    var t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

Flatten$1.className = "Flatten", registerClass$1(Flatten$1);

class Activation$2 extends Layer$1 {
  constructor(e) {
    super(e), this.supportsMasking = !0, this.activation = getActivation$1(e.activation);
  }

  call(e, t) {
    return tidy$1(() => {
      this.invokeCallHook(e, t);
      var n = getExactlyOneTensor$1(e);
      return this.activation.apply(n);
    });
  }

  getConfig() {
    var e = {
      activation: serializeActivation$1(this.activation)
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

Activation$2.className = "Activation", registerClass$1(Activation$2);

class RepeatVector$1 extends Layer$1 {
  constructor(e) {
    super(e), this.n = e.n, this.inputSpec = [{
      ndim: 2
    }];
  }

  computeOutputShape(e) {
    return [e[0], this.n, e[1]];
  }

  call(e, t) {
    return tidy$1(() => repeat$2(e = getExactlyOneTensor$1(e), this.n));
  }

  getConfig() {
    var e = {
      n: this.n
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

RepeatVector$1.className = "RepeatVector", registerClass$1(RepeatVector$1);

class Reshape$2 extends Layer$1 {
  constructor(e) {
    super(e), this.targetShape = e.targetShape;

    for (var _e215 = 0; _e215 < this.targetShape.length; ++_e215) {
      this.isUnknown(this.targetShape[_e215]) && (this.targetShape[_e215] = null);
    }
  }

  isUnknown(e) {
    return e < 0 || null == e;
  }

  fixUnknownDimension(e, t) {
    var n = "Total size of new array must be unchanged.",
        r = t.slice();
    var a = 1,
        s = null;

    for (var _e216 = 0; _e216 < r.length; ++_e216) {
      var _t161 = r[_e216];

      if (this.isUnknown(_t161)) {
        if (null !== s) throw new ValueError$1("Can only specifiy one unknown dimension.");
        s = _e216;
      } else a *= _t161;
    }

    var o = arrayProd$1(e);

    if (null !== s) {
      if (0 === a || o % a != 0) throw new ValueError$1(n);
      r[s] = o / a;
    } else if (o !== a) throw new ValueError$1(n);

    return r;
  }

  computeOutputShape(e) {
    var t = !1;

    for (var n = 0; n < e.length; ++n) {
      if (this.isUnknown(e[n])) {
        t = !0;
        break;
      }
    }

    return t ? e.slice(0, 1).concat(this.targetShape) : e.slice(0, 1).concat(this.fixUnknownDimension(e.slice(1), this.targetShape));
  }

  call(e, t) {
    return tidy$1(() => {
      this.invokeCallHook(e, t);
      var n = getExactlyOneTensor$1(e),
          r = n.shape,
          a = r.slice(0, 1).concat(this.fixUnknownDimension(r.slice(1), this.targetShape));
      return reshape$6(n, a);
    });
  }

  getConfig() {
    var e = {
      targetShape: this.targetShape
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

Reshape$2.className = "Reshape", registerClass$1(Reshape$2);

class Permute$1 extends Layer$1 {
  constructor(e) {
    if (super(e), null == e.dims) throw new Error("Required configuration field `dims` is missing during Permute constructor call.");
    if (!Array.isArray(e.dims)) throw new Error("Permute constructor requires `dims` to be an Array, but received ".concat(e.dims, " instead."));
    var t = range$7(1, e.dims.length + 1);
    if (!arraysEqual$1(e.dims.slice().sort(), t)) throw new Error("Invalid permutation `dims`: " + JSON.stringify(e.dims) + " `dims` must contain consecutive integers starting from 1.");
    this.dims = e.dims, this.dimsIncludingBatch = [0].concat(this.dims), this.inputSpec = [new InputSpec$1({
      ndim: this.dims.length + 1
    })];
  }

  computeOutputShape(e) {
    var t = (e = getExactlyOneShape$1(e)).slice();
    return this.dims.forEach((n, r) => {
      t[r + 1] = e[n];
    }), t;
  }

  call(e, t) {
    return transpose$5(getExactlyOneTensor$1(e), this.dimsIncludingBatch);
  }

  getConfig() {
    var e = {
      dims: this.dims
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

Permute$1.className = "Permute", registerClass$1(Permute$1);

class Masking$1 extends Layer$1 {
  constructor(e) {
    super(null == e ? {} : e), this.supportsMasking = !0, this.maskValue = null != e ? null == e.maskValue ? 0 : e.maskValue : 0;
  }

  computeOutputShape(e) {
    return e;
  }

  getConfig() {
    var e = super.getConfig(),
        t = {
      maskValue: this.maskValue
    };
    return Object.assign(t, e), t;
  }

  computeMask(e, t) {
    var n = getExactlyOneTensor$1(e);
    return any$5(notEqual$5(n, this.maskValue), -1);
  }

  call(e, t) {
    return tidy$1(() => {
      this.invokeCallHook(e, t);
      var n = getExactlyOneTensor$1(e),
          r = any$5(notEqual$5(n, this.maskValue), -1, !0);
      return mul$1(n, cast$7(r, n.dtype));
    });
  }

}

Masking$1.className = "Masking", registerClass$1(Masking$1);

class Embedding$1 extends Layer$1 {
  constructor(e) {
    if (super(e), this.embeddings = null, this.DEFAULT_EMBEDDINGS_INITIALIZER = "randomUniform", null == e.batchInputShape && null == e.inputShape) {
      var t = null;
      null != e.batchSize && (t = e.batchSize), this.batchInputShape = null == e.inputLength ? [t, null] : [t].concat(toList$1(e.inputLength));
    }

    this.inputDim = e.inputDim, assertPositiveInteger$1(this.inputDim, "inputDim"), this.outputDim = e.outputDim, assertPositiveInteger$1(this.outputDim, "outputDim"), this.embeddingsInitializer = getInitializer$1(e.embeddingsInitializer || this.DEFAULT_EMBEDDINGS_INITIALIZER), this.embeddingsRegularizer = getRegularizer$1(e.embeddingsRegularizer), this.activityRegularizer = getRegularizer$1(e.activityRegularizer), this.embeddingsConstraint = getConstraint$1(e.embeddingsConstraint), this.maskZero = e.maskZero, this.supportsMasking = e.maskZero, this.inputLength = e.inputLength;
  }

  build(e) {
    this.embeddings = this.addWeight("embeddings", [this.inputDim, this.outputDim], this.dtype, this.embeddingsInitializer, this.embeddingsRegularizer, !0, this.embeddingsConstraint), this.built = !0;
  }

  warnOnIncompatibleInputShape(e) {}

  computeMask(e, t) {
    return tidy$1(() => this.maskZero ? (e = getExactlyOneTensor$1(e), notEqual$5(e, zerosLike$5(e))) : null);
  }

  computeOutputShape(e) {
    if (e = getExactlyOneShape$1(e), null == this.inputLength) return [...e, this.outputDim];
    var t = toList$1(this.inputLength);
    if (t.length !== e.length - 1) throw new ValueError$1("\"inputLength\" is ".concat(this.inputLength, ", but received input shape has shape ").concat(e));
    {
      var n = 0;

      for (var r = 0; r < t.length; ++r) {
        var a = t[r],
            s = e[r + 1];
        if (null != a && null != s && a !== s) throw new ValueError$1("\"inputLength\" is ".concat(this.inputLength, ", but received input shape has shape ").concat(e));
        null == a && (t[n] = s), n++;
      }
    }
    return [e[0], ...t, this.outputDim];
  }

  call(e, t) {
    return tidy$1(() => {
      this.invokeCallHook(e, t);
      var n = getExactlyOneTensor$1(e);
      "int32" !== n.dtype && (n = cast$6(n, "int32"));
      var r = gather$2(this.embeddings.read(), reshape$6(n, [n.size]));
      return reshape$6(r, getExactlyOneShape$1(this.computeOutputShape(n.shape)));
    });
  }

  getConfig() {
    var e = {
      inputDim: this.inputDim,
      outputDim: this.outputDim,
      embeddingsInitializer: serializeInitializer$1(this.embeddingsInitializer),
      embeddingsRegularizer: serializeRegularizer$1(this.embeddingsRegularizer),
      activityRegularizer: serializeRegularizer$1(this.activityRegularizer),
      embeddingsConstraint: serializeConstraint$1(this.embeddingsConstraint),
      maskZero: this.maskZero,
      inputLength: this.inputLength
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

Embedding$1.className = "Embedding", registerClass$1(Embedding$1);

class Merge$1 extends Layer$1 {
  constructor(e) {
    super(e || {}), this.supportsMasking = !0;
  }

  mergeFunction(e) {
    throw new NotImplementedError$1();
  }

  computeElementwiseOpOutputShape(e, t) {
    if (null == e || null == t) return null;
    if (e.length < t.length) return this.computeElementwiseOpOutputShape(t, e);
    if (0 === t.length) return e;
    var n = e.slice(0, e.length - t.length);

    for (var r = 0; r < t.length; ++r) {
      var a = e[e.length - t.length + r],
          s = t[r];
      if (null == a || null == s || a < 0 || s < 0) n.push(null);else if (1 === a) n.push(s);else if (1 === s) n.push(a);else {
        if (a !== s) throw new ValueError$1("Operands could not be broadcast together with shapes " + JSON.stringify(e) + " " + JSON.stringify(t));
        n.push(a);
      }
    }

    return n;
  }

  build(e) {
    if (Array.isArray(e) && !Array.isArray(e[0]) && (e = [getExactlyOneShape$1(e)]), (e = e).length < 2) throw new ValueError$1("A merge layer should be called on an Array of at least 2 inputs. Got ".concat(e.length, " input(s)."));
    var t = [];

    for (var _n73 of e) {
      null != _n73 && null !== _n73[0] && t.push(_n73[0]);
    }

    if (t = unique$6(t), t.length > 1) throw new ValueError$1("Can not merge tensors with different batch sizes. Got tensors with shapes: ".concat(JSON.stringify(e), "."));
    var n = null == e[0] ? null : e[0].slice(1);

    for (var _t162 = 1; _t162 < e.length; ++_t162) {
      var _r58 = null == e[_t162] ? null : e[_t162].slice(1);

      n = this.computeElementwiseOpOutputShape(n, _r58);
    }

    var r = e.map(e => e.length);
    this.reshapeRequired = -1 !== e.indexOf(null) || 1 !== unique$6(r).length;
  }

  call(e, t) {
    return tidy$1(() => {
      if (e = e, this.reshapeRequired) {
        var _t163 = [],
            n = e.map(e => e.rank);

        if (-1 === n.indexOf(null)) {
          var r = max$6(n);

          for (var _n74 of e) {
            var _e217 = _n74.rank;

            for (var _t164 = 0; _t164 < r - _e217; ++_t164) {
              _n74 = expandDims$6(_n74, 1);
            }

            _t163.push(_n74);
          }

          return this.mergeFunction(_t163);
        }

        {
          var _n75 = !1;

          for (var _r60 of e) {
            var _e218 = _r60.rank;

            if (null == _e218) {
              var _e219 = _r60.shape,
                  _a39 = _e219[0],
                  s = _e219.slice(1).concat([_a39]);

              var o = reshape$6(_r60, [_a39].concat(arrayProd$1(_e219.slice(1))));
              o = transpose$5(o, [1, 0]), o = reshape$6(o, s), _t163.push(o), _n75 = !0;
            } else if (_e218 > 1) {
              var _a40 = range$7(1, _e218).concat([0]);

              _t163.push(transpose$5(_r60, _a40)), _n75 = !0;
            } else _t163.push(_r60);
          }

          var _r59 = this.mergeFunction(_t163);

          var a = _r59.rank;
          if (_n75) if (null == a) {
            var _e220 = _r59.shape,
                _t165 = _e220[_e220.length - 1],
                _n76 = [_t165].concat(_e220.slice(0, _e220.length - 1));

            _r59 = reshape$6(transpose$5(reshape$6(_r59, [-1, _t165]), [1, 0]), _n76);
          } else if (a > 1) {
            var _e221 = [a - 1].concat(range$7(0, a - 1));

            _r59 = transpose$5(_r59, _e221);
          }
          return _r59;
        }
      }

      return this.mergeFunction(e);
    });
  }

  computeOutputShape(e) {
    var t;
    t = null == (e = e)[0] ? null : e[0].slice(1);

    for (var _n77 = 1; _n77 < e.length; ++_n77) {
      var r = null == e[_n77] ? null : e[_n77].slice(1);
      t = this.computeElementwiseOpOutputShape(t, r);
    }

    var n = [];

    for (var _t166 of e) {
      null != _t166 && null !== _t166[0] && n.push(_t166[0]);
    }

    return n = unique$6(n), t = 1 === n.length ? n.concat(t) : [null].concat(t), t;
  }

  computeMask(e, t) {
    return tidy$1(() => {
      if (null == t) return null;
      if (!Array.isArray(t)) throw new ValueError$1("`mask` should be an Array");
      if (!Array.isArray(e)) throw new ValueError$1("`inputs` should be an Array");
      if (t.length !== e.length) throw new ValueError$1("The Array 'inputs' and 'mask' are expected to have the same length, but have different lengths (".concat(e.length, " vs ").concat(t.length, ")"));
      if (t.every(e => null == e)) return null;
      var n = (t = t.map(e => null == e ? e : expandDims$7(e, 0)))[0];

      for (var _e222 = 1; _e222 < t.length - 1; ++_e222) {
        n = logicalAnd$5(n, t[_e222]);
      }

      return n;
    });
  }

}

class Add$2 extends Merge$1 {
  constructor(e) {
    super(e);
  }

  mergeFunction(e) {
    return tidy$1(() => {
      var t = e[0].clone();

      for (var n = 1; n < e.length; ++n) {
        t = add$5(t, e[n]);
      }

      return t;
    });
  }

}

Add$2.className = "Add", registerClass$1(Add$2);

class Multiply$2 extends Merge$1 {
  constructor(e) {
    super(e);
  }

  mergeFunction(e) {
    return tidy$1(() => {
      var t = e[0].clone();

      for (var n = 1; n < e.length; ++n) {
        t = mul$1(t, e[n]);
      }

      return t;
    });
  }

}

Multiply$2.className = "Multiply", registerClass$1(Multiply$2);

class Average$1 extends Merge$1 {
  constructor(e) {
    super(e);
  }

  mergeFunction(e) {
    return tidy$1(() => {
      var t = e[0].clone();

      for (var n = 1; n < e.length; ++n) {
        t = add$5(t, e[n]);
      }

      return mul$1(1 / e.length, t);
    });
  }

}

Average$1.className = "Average", registerClass$1(Average$1);

class Maximum$2 extends Merge$1 {
  constructor(e) {
    super(e);
  }

  mergeFunction(e) {
    return tidy$1(() => {
      var t = e[0];

      for (var n = 1; n < e.length; ++n) {
        t = maximum$6(t, e[n]);
      }

      return t;
    });
  }

}

Maximum$2.className = "Maximum", registerClass$1(Maximum$2);

class Minimum$2 extends Merge$1 {
  constructor(e) {
    super(e);
  }

  mergeFunction(e) {
    return tidy$1(() => {
      var t = e[0];

      for (var n = 1; n < e.length; ++n) {
        t = minimum$6(t, e[n]);
      }

      return t;
    });
  }

}

Minimum$2.className = "Minimum", registerClass$1(Minimum$2);

class Concatenate$1 extends Merge$1 {
  constructor(e) {
    super(e), this.DEFAULT_AXIS = -1, null == e && (e = {}), this.axis = null == e.axis ? this.DEFAULT_AXIS : e.axis, this.supportsMasking = !0, this.reshapeRequired = !1;
  }

  build(e) {
    if (!Array.isArray(e) || !Array.isArray(e[0]) || 1 === e.length) throw new ValueError$1("A `Concatenate` layer should be called on a list of at least 2 inputs");
    e = e;
    var t = !0;

    for (var _n78 of e) {
      if (null != _n78) {
        t = !1;
        break;
      }
    }

    if (t) return;
    var n = [];

    for (var _t167 = 0; _t167 < e.length; ++_t167) {
      var r = e[_t167].slice();

      r.splice(this.axis, 1);
      var a = !1;

      for (var _e223 of n) {
        if (arraysEqual$1(_e223, r)) {
          a = !0;
          break;
        }
      }

      a || n.push(r);
    }

    if (n.length > 1) throw new ValueError$1("A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got input shapes: " + JSON.stringify(e));
  }

  mergeFunction(e) {
    return tidy$1(() => concatenate$2(e, this.axis));
  }

  computeOutputShape(e) {
    if (!Array.isArray(e) || !Array.isArray(e[0])) throw new ValueError$1("A `Concatenate` layer should be called on a list of inputs.");
    var t = e,
        n = t[0].slice(),
        r = this.axis < 0 ? n.length + this.axis : this.axis;

    for (var _e224 of t.slice(1)) {
      if (null == n[r] || null == _e224[r]) {
        n[r] = null;
        break;
      }

      n[r] += _e224[r];
    }

    return n;
  }

  computeMask(e, t) {
    if (null == t) return null;
    if (!Array.isArray(t)) throw new ValueError$1("`mask` should be an array for Concatenate");
    if (!Array.isArray(e)) throw new ValueError$1("`inputs` should be an array for Concatenate");
    if (t.length !== e.length) throw new ValueError$1("Mismatch in the length of mask (".concat(t.length, ") and the legnth of inputs (").concat(e.length, ")"));
    return tidy$1(() => {
      var n = !0;
      if (t.forEach(e => {
        null == e || (n = !1);
      }), n) return null;
      var r = [];

      for (var _n79 = 0; _n79 < e.length; ++_n79) {
        r.push(null == t[_n79] ? cast$7(onesLike$5(e[_n79]), "bool") : t[_n79].rank < e[_n79].rank ? expandDims$7(t[_n79], -1) : t[_n79]);
      }

      var a = concat$5(r, this.axis);
      return all$5(a, -1, !1);
    });
  }

  getConfig() {
    var e = {
      axis: this.axis
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

function interpretAxis$1(e, t) {
  for (; e < 0;) {
    e += t;
  }

  return e;
}

function batchDot$1(e, t, n) {
  if (e.shape.length > 3 || t.shape.length > 3) throw new NotImplementedError$1("batchDot is not implemented for tensors of 4D or higher rank yet");
  if (assert$6(e.shape.length >= 2, () => "batchDot requires the rank of x to be >= 2, but got ".concat(e.shape.length)), assert$6(e.shape.length >= 2, () => "batchDot requires the rank of y to be >= 2, but got ".concat(t.shape.length)), "number" == typeof n && (n = [n, n]), "complex64" === e.dtype || "complex64" === t.dtype) throw new NotImplementedError$1("batchDot is not implemented for complex64-type Tensors yet.");
  var r = e.shape.length,
      a = t.shape.length;
  null == n && (n = [r - 1, a - 2]);
  var s = n;
  return tidy$1(() => {
    var n, o;

    if (r > a) {
      n = r - a;
      var _e225 = [];

      for (var _t168 = 0; _t168 < n; ++_t168) {
        _e225.push(1);
      }

      t = reshape$6(t, t.shape.concat(_e225));
    } else if (a > r) {
      n = a - r;
      var _t169 = [];

      for (var _e226 = 0; _e226 < n; ++_e226) {
        _t169.push(1);
      }

      e = reshape$6(e, e.shape.concat(_t169));
    } else n = 0;

    if (o = 2 === e.shape.length && 2 === t.shape.length ? s[0] === s[1] ? sum$6(mul$1(e, t), s[0]) : sum$6(mul$1(transpose$5(e, [1, 0]), t), s[1]) : matMul$3(e, t, s[0] !== e.shape.length - 1, s[1] === t.shape.length - 1), n > 0) {
      var _e227;

      _e227 = r > a ? r + a - 3 : r - 1;
      var _t170 = [];

      for (var _r61 = _e227; _r61 < _e227 + n; ++_r61) {
        _t170.push(_r61);
      }

      o = squeeze$1(o, _t170);
    }

    return 1 === o.shape.length && (o = expandDims$7(o, 1)), o;
  });
}

Concatenate$1.className = "Concatenate", registerClass$1(Concatenate$1);

class Dot$1 extends Merge$1 {
  constructor(e) {
    super(e), this.axes = e.axes, this.normalize = null != e.normalize && e.normalize, this.supportsMasking = !0, this.reshapeRequired = !1;
  }

  build(e) {
    assert$6(Array.isArray(e) && 2 === e.length && Array.isArray(e[0]) && Array.isArray(e[1]), () => "A `Dot` layer should be called on a list of exactly 2 inputs.");
    var t = e[0],
        n = e[1];
    if (t.length > 3 || n.length > 3) throw new NotImplementedError$1("Dot layer does not support tensors of 4D or higher rank yet.");
    var r = this.interpretAxes(t, n);
    if (t[r[0]] !== n[r[1]]) throw new ValueError$1("Dimension incompatibility: ".concat(t[r[0]], " !== ").concat(n[r[1]]));
  }

  mergeFunction(e) {
    if (2 !== e.length) throw new ValueError$1("A `Dot` layer must be called on exactly 2 inputs, but received ".concat(e.length, " input(s)."));
    var t,
        n = e[0],
        r = e[1];
    return t = Array.isArray(this.axes) ? this.axes.map((t, n) => interpretAxis$1(t, e[n].shape.length)) : [interpretAxis$1(this.axes, n.shape.length), interpretAxis$1(this.axes, r.shape.length)], this.normalize && (n = l2Normalize$1(n, t[0]), r = l2Normalize$1(r, t[1])), batchDot$1(n, r, t);
  }

  interpretAxes(e, t) {
    var n;
    return n = Array.isArray(this.axes) ? this.axes : [interpretAxis$1(this.axes, e.length), interpretAxis$1(this.axes, t.length)], n;
  }

  computeOutputShape(e) {
    assert$6(Array.isArray(e) && 2 === e.length && Array.isArray(e[0]) && Array.isArray(e[1]), () => "A `Dot` layer should be called on a list of exactly 2 inputs.");
    var t = e[0].slice(),
        n = e[1].slice();
    if (t.length > 3 || n.length > 3) throw new NotImplementedError$1("Dot layer does not support tensors of 4D or higher rank yet.");
    var r = this.interpretAxes(t, n);
    t.splice(r[0], 1), n.splice(r[1], 1), n.splice(0, 1);
    var a = t.concat(n);
    return 1 === a.length && a.push(1), a;
  }

  computeMask(e, t) {
    return null;
  }

  getConfig() {
    var e = {
      axes: this.axes,
      normalize: this.normalize
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

Dot$1.className = "Dot", registerClass$1(Dot$1);

class GaussianNoise$1 extends Layer$1 {
  constructor(e) {
    super(e), this.supportsMasking = !0, this.stddev = e.stddev;
  }

  computeOutputShape(e) {
    return e;
  }

  getConfig() {
    var e = super.getConfig(),
        t = {
      stddev: this.stddev
    };
    return Object.assign(t, e), t;
  }

  call(e, t) {
    return tidy$1(() => {
      this.invokeCallHook(e, t);
      var n = getExactlyOneTensor$1(e);
      return inTrainPhase$1(() => add$5(randomNormal$3(n.shape, 0, this.stddev), n), () => n, t.training || !1);
    });
  }

}

GaussianNoise$1.className = "GaussianNoise", registerClass$1(GaussianNoise$1);

class GaussianDropout$1 extends Layer$1 {
  constructor(e) {
    super(e), this.supportsMasking = !0, this.rate = e.rate;
  }

  computeOutputShape(e) {
    return e;
  }

  getConfig() {
    var e = super.getConfig(),
        t = {
      rate: this.rate
    };
    return Object.assign(t, e), t;
  }

  call(e, t) {
    return tidy$1(() => {
      this.invokeCallHook(e, t);
      var n = getExactlyOneTensor$1(e);
      return this.rate > 0 && this.rate < 1 ? inTrainPhase$1(() => {
        var e = Math.sqrt(this.rate / (1 - this.rate));
        return mul$1(n, randomNormal$3(n.shape, 1, e));
      }, () => n, t.training || !1) : n;
    });
  }

}

GaussianDropout$1.className = "GaussianDropout", registerClass$1(GaussianDropout$1);

class AlphaDropout$1 extends Layer$1 {
  constructor(e) {
    super(e), this.supportsMasking = !0, this.rate = e.rate, this.noiseShape = e.noiseShape;
  }

  _getNoiseShape(e) {
    return this.noiseShape || getExactlyOneTensor$1(e).shape;
  }

  computeOutputShape(e) {
    return e;
  }

  getConfig() {
    var e = super.getConfig(),
        t = {
      rate: this.rate
    };
    return Object.assign(t, e), t;
  }

  call(e, t) {
    return tidy$1(() => {
      if (this.rate < 1 && this.rate > 0) {
        var n = this._getNoiseShape(e),
            r = () => {
          var t = getExactlyOneTensor$1(e),
              r = -1.7580993408473766;
          var a = greaterEqual$5(randomUniform$2(n), this.rate);
          a = cast$6(a, "float32");
          var s = ((1 - this.rate) * (1 + this.rate * r ** 2)) ** -.5,
              o = -s * r * this.rate,
              i = add$5(mul$1(t, a), mul$1(add$5(a, -1), r));
          return add$5(mul$1(i, s), o);
        };

        return inTrainPhase$1(r, () => getExactlyOneTensor$1(e), t.training || !1);
      }

      return e;
    });
  }

}

function batchNormalization$2(e, t, n, r, a) {
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : .001;
  var o;
  if (2 === e.rank) o = batchNorm2d$1(e, t, n, r, a, s);else if (3 === e.rank) o = batchNorm3d$1(e, t, n, r, a, s);else {
    if (4 !== e.rank) throw new NotImplementedError$1("batchNormalization is not implemented for array of rank ".concat(e.rank, " yet"));
    o = batchNorm4d$1(e, t, n, r, a, s);
  }
  return o;
}

function regularNormalizeBatchInTraining$1(e, t, n, r) {
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : .001;
  return tidy$1(() => {
    var s = moments$1(e, r),
        o = s.mean,
        i = s.variance;
    return [batchNormalization$2(e, o, i, n, t, a), o, i];
  });
}

function broadcastNormalizeBatchInTraining$1(e, t, n, r) {
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : .001;
  return tidy$1(() => {
    var s = moments$1(e, r),
        o = s.mean,
        i = s.variance,
        l = [];

    for (var _t171 of range$7(0, e.rank)) {
      -1 !== r.indexOf(_t171) ? l.push(1) : l.push(e.shape[_t171]);
    }

    var u = reshape$6(o, l),
        c = reshape$6(i, l),
        p = null == t ? null : reshape$6(t, l),
        d = null == n ? null : reshape$6(n, l);
    return [batchNormalization$2(e, u, c, d, p, a), o, i];
  });
}

function normalizeBatchInTraining$1(e, t, n, r) {
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : .001;
  return arraysEqual$1(r.slice().sort(), range$7(0, e.rank - 1)) ? regularNormalizeBatchInTraining$1(e, t, n, r, a) : broadcastNormalizeBatchInTraining$1(e, t, n, r, a);
}

AlphaDropout$1.className = "AlphaDropout", registerClass$1(AlphaDropout$1);

class BatchNormalization$1 extends Layer$1 {
  constructor(e) {
    null == e && (e = {}), super(e), this.supportsMasking = !0, this.axis = null == e.axis ? -1 : e.axis, this.momentum = null == e.momentum ? .99 : e.momentum, this.epsilon = null == e.epsilon ? .001 : e.epsilon, this.center = null == e.center || e.center, this.scale = null == e.scale || e.scale, this.betaInitializer = getInitializer$1(e.betaInitializer || "zeros"), this.gammaInitializer = getInitializer$1(e.gammaInitializer || "ones"), this.movingMeanInitializer = getInitializer$1(e.movingMeanInitializer || "zeros"), this.movingVarianceInitializer = getInitializer$1(e.movingVarianceInitializer || "ones"), this.betaConstraint = getConstraint$1(e.betaConstraint), this.gammaConstraint = getConstraint$1(e.gammaConstraint), this.betaRegularizer = getRegularizer$1(e.betaRegularizer), this.gammaRegularizer = getRegularizer$1(e.gammaRegularizer);
  }

  build(e) {
    e = getExactlyOneShape$1(e);
    var t = this.axis >= 0 ? this.axis : this.axis + e.length,
        n = e[t];
    if (null == n) throw new ValueError$1("Axis ".concat(t, " of input tensor should have a defined dimension but the layer received an input with shape ").concat(JSON.stringify(e), "."));
    this.inputSpec = [new InputSpec$1({
      ndim: e.length,
      axes: {
        [t]: n
      }
    })];
    var r = [n];
    this.scale && (this.gamma = this.addWeight("gamma", r, null, this.gammaInitializer, this.gammaRegularizer, !0, this.gammaConstraint)), this.center && (this.beta = this.addWeight("beta", r, null, this.betaInitializer, this.betaRegularizer, !0, this.betaConstraint)), this.movingMean = this.addWeight("moving_mean", r, null, this.movingMeanInitializer, null, !1), this.movingVariance = this.addWeight("moving_variance", r, null, this.movingVarianceInitializer, null, !1), this.built = !0;
  }

  call(e, t) {
    return tidy$1(() => {
      var n = null != t.training && t.training,
          r = getExactlyOneTensor$1(e),
          a = r.shape,
          s = a.length,
          o = range$7(0, s),
          i = this.axis >= 0 ? this.axis : this.axis + s;
      o.splice(i, 1);
      var l = pyListRepeat$1(1, s);
      l[i] = a[i];
      var u = o.slice();
      u.sort();
      var c = !arraysEqual$1(u, range$7(0, s).slice(0, s - 1));
      if (!n) return (() => {
        if (c) {
          var _e228 = reshape$6(this.movingMean.read(), l),
              _t172 = reshape$6(this.movingVariance.read(), l),
              _n80 = this.center ? reshape$6(this.beta.read(), l) : null,
              _a41 = this.scale ? reshape$6(this.gamma.read(), l) : null;

          return batchNormalization$2(r, _e228, _t172, _n80, _a41, this.epsilon);
        }

        return batchNormalization$2(r, this.movingMean.read(), this.movingVariance.read(), null == this.beta ? null : this.beta.read(), null == this.gamma ? null : this.gamma.read(), this.epsilon);
      })();

      var [p, d, h] = normalizeBatchInTraining$1(r, this.gamma.read(), this.beta.read(), o, this.epsilon),
          m = (e, t, n) => {
        tidy$1(() => {
          var r = 1 - n,
              a = e.read(),
              s = mul$1(sub$5(a, t), r);
          e.write(sub$5(a, s));
        });
      };

      return (() => {
        m(this.movingMean, d, this.momentum), m(this.movingVariance, h, this.momentum);
      })(), p;
    });
  }

  getConfig() {
    var e = {
      axis: this.axis,
      momentum: this.momentum,
      epsilon: this.epsilon,
      center: this.center,
      scale: this.scale,
      betaInitializer: serializeInitializer$1(this.betaInitializer),
      gammaInitializer: serializeInitializer$1(this.gammaInitializer),
      movingMeanInitializer: serializeInitializer$1(this.movingMeanInitializer),
      movingVarianceInitializer: serializeInitializer$1(this.movingVarianceInitializer),
      betaRegularizer: serializeRegularizer$1(this.betaRegularizer),
      gammaRegularizer: serializeRegularizer$1(this.gammaRegularizer),
      betaConstraint: serializeConstraint$1(this.betaConstraint),
      gammaConstraint: serializeConstraint$1(this.gammaConstraint)
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

BatchNormalization$1.className = "BatchNormalization", registerClass$1(BatchNormalization$1);

class LayerNormalization$1 extends Layer$1 {
  constructor(e) {
    if (null == e && (e = {}), super(e), this.axis = null == e.axis ? -1 : e.axis, "number" == typeof this.axis) {
      if (!Number.isInteger(this.axis)) throw new Error("Expected axis to be an integer, but received ".concat(this.axis));
    } else {
      if (!Array.isArray(this.axis)) throw new Error("Expected axis to be an integer or an array of integers, but received ".concat(JSON.stringify(this.axis)));

      for (var _e229 of this.axis) {
        if (!Number.isInteger(_e229)) throw new Error("Expected axis to be an array of integers, but received ".concat(JSON.stringify(this.axis)));
      }
    }

    this.epsilon = null == e.epsilon ? .001 : e.epsilon, this.center = null == e.center || e.center, this.scale = null == e.scale || e.scale, this.betaInitializer = getInitializer$1(e.betaInitializer || "zeros"), this.gammaInitializer = getInitializer$1(e.gammaInitializer || "ones"), this.betaRegularizer = getRegularizer$1(e.betaRegularizer), this.gammaRegularizer = getRegularizer$1(e.gammaRegularizer), this.supportsMasking = !0;
  }

  build(e) {
    var t = (e = getExactlyOneShape$1(e)).length;
    "number" == typeof this.axis && (this.axis = [this.axis]);

    for (var _e230 = 0; _e230 < this.axis.length; ++_e230) {
      this.axis[_e230] < 0 && (this.axis[_e230] += t);
    }

    for (var _e231 of this.axis) {
      if (_e231 < 0 || _e231 >= t) throw new Error("Invalid axis: ".concat(_e231));
    }

    if (this.axis.length !== unique$6(this.axis).length) throw new Error("Found duplicate axes in: ".concat(this.axis));
    var n = this.axis.map(t => e[t]);
    this.gamma = this.scale ? this.addWeight("gamma", n, "float32", this.gammaInitializer, this.gammaRegularizer, !0) : null, this.beta = this.center ? this.addWeight("beta", n, "float32", this.betaInitializer, this.betaRegularizer, !0) : null, this.built = !0;
  }

  call(e, t) {
    var n = getExactlyOneTensor$1(e),
        r = n.shape,
        a = r.length;
    return tidy$1(() => {
      var {
        mean: e,
        variance: t
      } = moments$1(n, this.axis, !0);
      var s = pyListRepeat$1(1, a);

      for (var _e232 of this.axis) {
        s[_e232] = r[_e232];
      }

      var o = e => null != e && e.shape.length !== a && this.axis !== [a - 1] ? reshape$6(e, s) : e;

      var i = o(this.gamma.read()),
          l = o(this.beta.read());
      var u = [],
          c = [];

      for (var _e233 = 0; _e233 < a; ++_e233) {
        -1 !== this.axis.indexOf(_e233) ? (u.push(r[_e233]), c.push(1)) : (u.push(1), c.push(r[_e233]));
      }

      return e = tile$7(e, u), t = tile$7(t, u), i = tile$7(i, c), l = tile$7(l, c), batchNormalization$2(n, e, t, l, i, this.epsilon);
    });
  }

  getConfig() {
    var e = {
      axis: this.axis,
      epsilon: this.epsilon,
      center: this.center,
      scale: this.scale,
      betaInitializer: serializeInitializer$1(this.betaInitializer),
      gammaInitializer: serializeInitializer$1(this.gammaInitializer),
      betaRegularizer: serializeRegularizer$1(this.betaRegularizer),
      gammaRegularizer: serializeRegularizer$1(this.gammaRegularizer)
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

function spatial2dPadding$1(e, t, n) {
  return tidy$1(() => {
    if (4 !== e.rank) throw new ValueError$1("temporalPadding expects input tensor to be 4-D, but received a ".concat(e.rank, "-D tensor."));
    if (null == t && (t = [[1, 1], [1, 1]]), 2 !== t.length || 2 !== t[0].length || 2 !== t[1].length) throw new ValueError$1("spatial2dPadding expects `padding` to be an Array of two Arrays, each of which is an Array of two integers.");
    if (null == n && (n = imageDataFormat$1()), "channelsLast" !== n && "channelsFirst" !== n) throw new ValueError$1("Unknown data format: ".concat(n, ". Supported data formats are 'channelsLast' and 'channelsFirst."));
    var r;
    return r = "channelsFirst" === n ? [[0, 0], [0, 0], t[0], t[1]] : [[0, 0], t[0], t[1], [0, 0]], pad$1(e, r);
  });
}

LayerNormalization$1.className = "LayerNormalization", registerClass$1(LayerNormalization$1);

class ZeroPadding2D$1 extends Layer$1 {
  constructor(e) {
    if (null == e && (e = {}), super(e), this.dataFormat = null == e.dataFormat ? imageDataFormat$1() : e.dataFormat, null == e.padding) this.padding = [[1, 1], [1, 1]];else if ("number" == typeof e.padding) this.padding = [[e.padding, e.padding], [e.padding, e.padding]];else {
      if (e.padding = e.padding, 2 !== e.padding.length) throw new ValueError$1("ZeroPadding2D expects padding to be a length-2 array, but received a length-".concat(e.padding.length, " array."));
      var t, n;
      if ("number" == typeof e.padding[0]) t = [e.padding[0], e.padding[0]], n = [e.padding[1], e.padding[1]];else {
        if (e.padding = e.padding, 2 !== e.padding[0].length) throw new ValueError$1("ZeroPadding2D expects height padding to be a length-2 array, but received a length-".concat(e.padding[0].length, " array."));
        if (t = e.padding[0], 2 !== e.padding[1].length) throw new ValueError$1("ZeroPadding2D expects width padding to be a length-2 array, but received a length-".concat(e.padding[1].length, " array."));
        n = e.padding[1];
      }
      this.padding = [t, n];
    }
    this.inputSpec = [new InputSpec$1({
      ndim: 4
    })];
  }

  computeOutputShape(e) {
    var t, n;
    return e = getExactlyOneShape$1(e), "channelsFirst" === this.dataFormat ? (t = null != e[2] && e[2] >= 0 ? e[2] + this.padding[0][0] + this.padding[0][1] : null, n = null != e[3] && e[3] >= 0 ? e[3] + this.padding[1][0] + this.padding[1][1] : null, [e[0], e[1], t, n]) : (t = null != e[1] && e[1] >= 0 ? e[1] + this.padding[0][0] + this.padding[0][1] : null, n = null != e[2] && e[2] >= 0 ? e[2] + this.padding[1][0] + this.padding[1][1] : null, [e[0], t, n, e[3]]);
  }

  call(e, t) {
    return tidy$1(() => spatial2dPadding$1(getExactlyOneTensor$1(e), this.padding, this.dataFormat));
  }

  getConfig() {
    var e = {
      padding: this.padding,
      dataFormat: this.dataFormat
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

function pool2d$1(e, t, n, r, a, s) {
  return tidy$1(() => {
    var o;
    checkDataFormat$1(a), checkPoolMode$1(s), checkPaddingMode$1(r), null == n && (n = [1, 1]), null == r && (r = "valid"), null == a && (a = imageDataFormat$1()), null == s && (s = "max"), e = preprocessConv2DInput$1(e, a);
    var i = "same" === r ? "same" : "valid";
    return o = "max" === s ? maxPool$5(e, t, n, i) : avgPool$5(e, t, n, i), "channelsFirst" === a && (o = transpose$5(o, [0, 3, 1, 2])), o;
  });
}

function pool3d$3(e, t, n, r, a, s) {
  return tidy$1(() => {
    var o;
    checkDataFormat$1(a), checkPoolMode$1(s), checkPaddingMode$1(r), null == n && (n = [1, 1, 1]), null == r && (r = "valid"), null == a && (a = imageDataFormat$1()), null == s && (s = "max"), e = preprocessConv3DInput$1(e, a);
    var i = "same" === r ? "same" : "valid";
    return o = "max" === s ? maxPool3d$3(e, t, n, i) : avgPool3d$2(e, t, n, i), "channelsFirst" === a && (o = transpose$5(o, [0, 4, 1, 2, 3])), o;
  });
}

ZeroPadding2D$1.className = "ZeroPadding2D", registerClass$1(ZeroPadding2D$1);

class Pooling1D$1 extends Layer$1 {
  constructor(e) {
    if (null == e.poolSize && (e.poolSize = 2), super(e), "number" == typeof e.poolSize) this.poolSize = [e.poolSize];else {
      if (!Array.isArray(e.poolSize) || 1 !== e.poolSize.length || "number" != typeof e.poolSize[0]) throw new ValueError$1("poolSize for 1D convolutional layer must be a number or an Array of a single number, but received ".concat(JSON.stringify(e.poolSize)));
      this.poolSize = e.poolSize;
    }
    if (assertPositiveInteger$1(this.poolSize, "poolSize"), null == e.strides) this.strides = this.poolSize;else if ("number" == typeof e.strides) this.strides = [e.strides];else {
      if (!Array.isArray(e.strides) || 1 !== e.strides.length || "number" != typeof e.strides[0]) throw new ValueError$1("strides for 1D convolutional layer must be a number or an Array of a single number, but received ".concat(JSON.stringify(e.strides)));
      this.strides = e.strides;
    }
    assertPositiveInteger$1(this.strides, "strides"), this.padding = null == e.padding ? "valid" : e.padding, checkPaddingMode$1(this.padding), this.inputSpec = [new InputSpec$1({
      ndim: 3
    })];
  }

  computeOutputShape(e) {
    var t = convOutputLength$1((e = getExactlyOneShape$1(e))[1], this.poolSize[0], this.padding, this.strides[0]);
    return [e[0], t, e[2]];
  }

  call(e, t) {
    return tidy$1(() => {
      this.invokeCallHook(e, t), e = expandDims$6(getExactlyOneTensor$1(e), 2);
      var n = this.poolingFunction(getExactlyOneTensor$1(e), [this.poolSize[0], 1], [this.strides[0], 1], this.padding, "channelsLast");
      return squeeze$1(n, [2]);
    });
  }

  getConfig() {
    var e = {
      poolSize: this.poolSize,
      padding: this.padding,
      strides: this.strides
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

class MaxPooling1D$1 extends Pooling1D$1 {
  constructor(e) {
    super(e);
  }

  poolingFunction(e, t, n, r, a) {
    return checkDataFormat$1(a), checkPaddingMode$1(r), pool2d$1(e, t, n, r, a, "max");
  }

}

MaxPooling1D$1.className = "MaxPooling1D", registerClass$1(MaxPooling1D$1);

class AveragePooling1D$1 extends Pooling1D$1 {
  constructor(e) {
    super(e);
  }

  poolingFunction(e, t, n, r, a) {
    return checkDataFormat$1(a), checkPaddingMode$1(r), pool2d$1(e, t, n, r, a, "avg");
  }

}

AveragePooling1D$1.className = "AveragePooling1D", registerClass$1(AveragePooling1D$1);

class Pooling2D$1 extends Layer$1 {
  constructor(e) {
    if (null == e.poolSize && (e.poolSize = [2, 2]), super(e), this.poolSize = Array.isArray(e.poolSize) ? e.poolSize : [e.poolSize, e.poolSize], null == e.strides) this.strides = this.poolSize;else if (Array.isArray(e.strides)) {
      if (2 !== e.strides.length) throw new ValueError$1("If the strides property of a 2D pooling layer is an Array, it is expected to have a length of 2, but received length ".concat(e.strides.length, "."));
      this.strides = e.strides;
    } else this.strides = [e.strides, e.strides];
    assertPositiveInteger$1(this.poolSize, "poolSize"), assertPositiveInteger$1(this.strides, "strides"), this.padding = null == e.padding ? "valid" : e.padding, this.dataFormat = null == e.dataFormat ? "channelsLast" : e.dataFormat, checkDataFormat$1(this.dataFormat), checkPaddingMode$1(this.padding), this.inputSpec = [new InputSpec$1({
      ndim: 4
    })];
  }

  computeOutputShape(e) {
    e = getExactlyOneShape$1(e);
    var t = "channelsFirst" === this.dataFormat ? e[2] : e[1],
        n = "channelsFirst" === this.dataFormat ? e[3] : e[2];
    return t = convOutputLength$1(t, this.poolSize[0], this.padding, this.strides[0]), n = convOutputLength$1(n, this.poolSize[1], this.padding, this.strides[1]), "channelsFirst" === this.dataFormat ? [e[0], e[1], t, n] : [e[0], t, n, e[3]];
  }

  call(e, t) {
    return tidy$1(() => (this.invokeCallHook(e, t), this.poolingFunction(getExactlyOneTensor$1(e), this.poolSize, this.strides, this.padding, this.dataFormat)));
  }

  getConfig() {
    var e = {
      poolSize: this.poolSize,
      padding: this.padding,
      strides: this.strides,
      dataFormat: this.dataFormat
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

class MaxPooling2D$1 extends Pooling2D$1 {
  constructor(e) {
    super(e);
  }

  poolingFunction(e, t, n, r, a) {
    return checkDataFormat$1(a), checkPaddingMode$1(r), pool2d$1(e, t, n, r, a, "max");
  }

}

MaxPooling2D$1.className = "MaxPooling2D", registerClass$1(MaxPooling2D$1);

class AveragePooling2D$1 extends Pooling2D$1 {
  constructor(e) {
    super(e);
  }

  poolingFunction(e, t, n, r, a) {
    return checkDataFormat$1(a), checkPaddingMode$1(r), pool2d$1(e, t, n, r, a, "avg");
  }

}

AveragePooling2D$1.className = "AveragePooling2D", registerClass$1(AveragePooling2D$1);

class Pooling3D$1 extends Layer$1 {
  constructor(e) {
    if (null == e.poolSize && (e.poolSize = [2, 2, 2]), super(e), this.poolSize = Array.isArray(e.poolSize) ? e.poolSize : [e.poolSize, e.poolSize, e.poolSize], null == e.strides) this.strides = this.poolSize;else if (Array.isArray(e.strides)) {
      if (3 !== e.strides.length) throw new ValueError$1("If the strides property of a 3D pooling layer is an Array, it is expected to have a length of 3, but received length ".concat(e.strides.length, "."));
      this.strides = e.strides;
    } else this.strides = [e.strides, e.strides, e.strides];
    assertPositiveInteger$1(this.poolSize, "poolSize"), assertPositiveInteger$1(this.strides, "strides"), this.padding = null == e.padding ? "valid" : e.padding, this.dataFormat = null == e.dataFormat ? "channelsLast" : e.dataFormat, checkDataFormat$1(this.dataFormat), checkPaddingMode$1(this.padding), this.inputSpec = [new InputSpec$1({
      ndim: 5
    })];
  }

  computeOutputShape(e) {
    e = getExactlyOneShape$1(e);
    var t = "channelsFirst" === this.dataFormat ? e[2] : e[1],
        n = "channelsFirst" === this.dataFormat ? e[3] : e[2],
        r = "channelsFirst" === this.dataFormat ? e[4] : e[3];
    return t = convOutputLength$1(t, this.poolSize[0], this.padding, this.strides[0]), n = convOutputLength$1(n, this.poolSize[1], this.padding, this.strides[1]), r = convOutputLength$1(r, this.poolSize[2], this.padding, this.strides[2]), "channelsFirst" === this.dataFormat ? [e[0], e[1], t, n, r] : [e[0], t, n, r, e[4]];
  }

  call(e, t) {
    return tidy$1(() => (this.invokeCallHook(e, t), this.poolingFunction(getExactlyOneTensor$1(e), this.poolSize, this.strides, this.padding, this.dataFormat)));
  }

  getConfig() {
    var e = {
      poolSize: this.poolSize,
      padding: this.padding,
      strides: this.strides,
      dataFormat: this.dataFormat
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

class MaxPooling3D$1 extends Pooling3D$1 {
  constructor(e) {
    super(e);
  }

  poolingFunction(e, t, n, r, a) {
    return checkDataFormat$1(a), checkPaddingMode$1(r), pool3d$3(e, t, n, r, a, "max");
  }

}

MaxPooling3D$1.className = "MaxPooling3D", registerClass$1(MaxPooling3D$1);

class AveragePooling3D$1 extends Pooling3D$1 {
  constructor(e) {
    super(e);
  }

  poolingFunction(e, t, n, r, a) {
    return checkDataFormat$1(a), checkPaddingMode$1(r), pool3d$3(e, t, n, r, a, "avg");
  }

}

AveragePooling3D$1.className = "AveragePooling3D", registerClass$1(AveragePooling3D$1);

class GlobalPooling1D$1 extends Layer$1 {
  constructor(e) {
    super(e), this.inputSpec = [new InputSpec$1({
      ndim: 3
    })];
  }

  computeOutputShape(e) {
    return [e[0], e[2]];
  }

  call(e, t) {
    throw new NotImplementedError$1();
  }

}

class GlobalAveragePooling1D$1 extends GlobalPooling1D$1 {
  constructor(e) {
    super(e || {});
  }

  call(e, t) {
    return tidy$1(() => {
      var t = getExactlyOneTensor$1(e);
      return mean$3(t, 1);
    });
  }

}

GlobalAveragePooling1D$1.className = "GlobalAveragePooling1D", registerClass$1(GlobalAveragePooling1D$1);

class GlobalMaxPooling1D$1 extends GlobalPooling1D$1 {
  constructor(e) {
    super(e || {});
  }

  call(e, t) {
    return tidy$1(() => {
      var t = getExactlyOneTensor$1(e);
      return max$7(t, 1);
    });
  }

}

GlobalMaxPooling1D$1.className = "GlobalMaxPooling1D", registerClass$1(GlobalMaxPooling1D$1);

class GlobalPooling2D$1 extends Layer$1 {
  constructor(e) {
    super(e), this.dataFormat = null == e.dataFormat ? "channelsLast" : e.dataFormat, checkDataFormat$1(this.dataFormat), this.inputSpec = [new InputSpec$1({
      ndim: 4
    })];
  }

  computeOutputShape(e) {
    return e = e, "channelsLast" === this.dataFormat ? [e[0], e[3]] : [e[0], e[1]];
  }

  call(e, t) {
    throw new NotImplementedError$1();
  }

  getConfig() {
    var e = {
      dataFormat: this.dataFormat
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

class GlobalAveragePooling2D$1 extends GlobalPooling2D$1 {
  call(e, t) {
    return tidy$1(() => {
      var t = getExactlyOneTensor$1(e);
      return mean$3(t, "channelsLast" === this.dataFormat ? [1, 2] : [2, 3]);
    });
  }

}

GlobalAveragePooling2D$1.className = "GlobalAveragePooling2D", registerClass$1(GlobalAveragePooling2D$1);

class GlobalMaxPooling2D$1 extends GlobalPooling2D$1 {
  call(e, t) {
    return tidy$1(() => {
      var t = getExactlyOneTensor$1(e);
      return max$7(t, "channelsLast" === this.dataFormat ? [1, 2] : [2, 3]);
    });
  }

}

GlobalMaxPooling2D$1.className = "GlobalMaxPooling2D", registerClass$1(GlobalMaxPooling2D$1);

class Wrapper$1 extends Layer$1 {
  constructor(e) {
    super(e), this.layer = e.layer;
  }

  build(e) {
    this.built = !0;
  }

  get trainable() {
    return null != this.layer && this.layer.trainable;
  }

  set trainable(e) {
    null != this.layer && (this.layer.trainable = e);
  }

  get trainableWeights() {
    return this.layer.trainableWeights;
  }

  get nonTrainableWeights() {
    return this.layer.nonTrainableWeights;
  }

  get updates() {
    return this.layer._updates;
  }

  get losses() {
    return this.layer.losses;
  }

  getWeights() {
    return this.layer.getWeights();
  }

  setWeights(e) {
    this.layer.setWeights(e);
  }

  getConfig() {
    var e = {
      layer: {
        className: this.layer.getClassName(),
        config: this.layer.getConfig()
      }
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

  setFastWeightInitDuringBuild(e) {
    super.setFastWeightInitDuringBuild(e), null != this.layer && this.layer.setFastWeightInitDuringBuild(e);
  }

  static fromConfig(e, t) {
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};
    var r = deserialize$1(t.layer, n);
    delete t.layer;
    var a = {
      layer: r
    };
    return Object.assign(a, t), new e(a);
  }

}

class TimeDistributed$1 extends Wrapper$1 {
  constructor(e) {
    super(e), this.supportsMasking = !0;
  }

  build(e) {
    if ((e = getExactlyOneShape$1(e)).length < 3) throw new ValueError$1("TimeDistributed layer expects an input shape >= 3D, but received input shape ".concat(JSON.stringify(e)));
    this.inputSpec = [{
      shape: e
    }];
    var t = [e[0]].concat(e.slice(2));
    this.layer.built || (this.layer.build(t), this.layer.built = !0), super.build(e);
  }

  computeOutputShape(e) {
    var t = [(e = getExactlyOneShape$1(e))[0]].concat(e.slice(2)),
        n = this.layer.computeOutputShape(t);
    return [n[0], e[1]].concat(n.slice(1));
  }

  call(e, t) {
    return tidy$1(() => rnn$2((e, n) => [getExactlyOneTensor$1(this.layer.call(e, t)), []], e = getExactlyOneTensor$1(e), [], !1, null, null, !1, !0)[1]);
  }

}

function checkBidirectionalMergeMode$1(e) {
  checkStringTypeUnionValue$1(VALID_BIDIRECTIONAL_MERGE_MODES$1, "BidirectionalMergeMode", e);
}

TimeDistributed$1.className = "TimeDistributed", registerClass$1(TimeDistributed$1);
var DEFAULT_BIDIRECTIONAL_MERGE_MODE$1 = "concat";

class Bidirectional$1 extends Wrapper$1 {
  constructor(e) {
    super(e);
    var t = e.layer.getConfig(),
        n = {};
    n.className = e.layer.getClassName(), n.config = t, this.forwardLayer = deserialize$1(n), t.goBackwards = !0 !== t.goBackwards;
    var r = {};
    if (r.className = e.layer.getClassName(), r.config = t, this.backwardLayer = deserialize$1(r), this.forwardLayer.name = "forward_" + this.forwardLayer.name, this.backwardLayer.name = "backward_" + this.backwardLayer.name, this.mergeMode = void 0 === e.mergeMode ? DEFAULT_BIDIRECTIONAL_MERGE_MODE$1 : e.mergeMode, checkBidirectionalMergeMode$1(this.mergeMode), e.weights) throw new NotImplementedError$1("weights support is not implemented for Bidirectional layer yet.");
    this._stateful = e.layer.stateful, this.returnSequences = e.layer.returnSequences, this.returnState = e.layer.returnState, this.supportsMasking = !0, this._trainable = !0, this.inputSpec = e.layer.inputSpec, this.numConstants = null;
  }

  get trainable() {
    return this._trainable;
  }

  set trainable(e) {
    this._trainable = e, null != this.forwardLayer && (this.forwardLayer.trainable = e), null != this.backwardLayer && (this.backwardLayer.trainable = e);
  }

  getWeights() {
    return this.forwardLayer.getWeights().concat(this.backwardLayer.getWeights());
  }

  setWeights(e) {
    var t = Math.floor(e.length / 2);
    this.forwardLayer.setWeights(e.slice(0, t)), this.backwardLayer.setWeights(e.slice(t));
  }

  computeOutputShape(e) {
    var t,
        n,
        r,
        a = this.forwardLayer.computeOutputShape(e);
    return Array.isArray(a) && Array.isArray(a[0]) || (a = [a]), a = a, this.returnState ? (r = a.slice(1), t = a[0]) : t = a[0], t = t, "concat" === this.mergeMode ? (t[t.length - 1] *= 2, n = [t]) : n = null == this.mergeMode ? [t, t.slice()] : [t], this.returnState ? null == this.mergeMode ? n.concat(r).concat(r.slice()) : [t].concat(r).concat(r.slice()) : singletonOrArray$1(n);
  }

  apply(e, t) {
    var n = null == t ? null : t.initialState,
        r = null == t ? null : t.constants;
    null == t && (t = {});
    var a = standardizeArgs$1(e, n, r, this.numConstants);
    if (e = a.inputs, n = a.initialState, r = a.constants, Array.isArray(e) && (n = e.slice(1), e = e[0]), (null == n || 0 === n.length) && null == r) return super.apply(e, t);
    var s = [],
        o = [];

    if (null != n) {
      var _e234 = n.length;
      if (_e234 % 2 > 0) throw new ValueError$1("When passing `initialState` to a Bidrectional RNN, the state should be an Array containing the states of the underlying RNNs.");
      t.initialState = n, s.push(...n);

      var _r62 = n.map(e => new InputSpec$1({
        shape: e.shape
      }));

      this.forwardLayer.stateSpec = _r62.slice(0, _e234 / 2), this.backwardLayer.stateSpec = _r62.slice(_e234 / 2), o.push(..._r62);
    }

    if (null != r) throw new NotImplementedError$1("Support for constants in Bidirectional layers is not implemented yet.");
    var i = s[0] instanceof SymbolicTensor$1;

    for (var _e235 of s) {
      if (_e235 instanceof SymbolicTensor$1 !== i) throw new ValueError$1("The initial state of a Bidirectional layer cannot be specified as a mix of symbolic and non-symbolic tensors");
    }

    if (i) {
      var _n81 = [e].concat(s),
          _r63 = this.inputSpec.concat(o),
          _a42 = this.inputSpec;

      this.inputSpec = _r63;

      var _i6 = super.apply(_n81, t);

      return this.inputSpec = _a42, _i6;
    }

    return super.apply(e, t);
  }

  call(e, t) {
    return tidy$1(() => {
      var n = t.initialState;
      var r, a, s, o;
      if (null == n) r = this.forwardLayer.call(e, t), a = this.backwardLayer.call(e, t);else {
        var _s27 = n.slice(0, n.length / 2),
            _o11 = n.slice(n.length / 2);

        r = this.forwardLayer.call(e, Object.assign(t, {
          initialState: _s27
        })), a = this.backwardLayer.call(e, Object.assign(t, {
          initialState: _o11
        }));
      }
      return this.returnState && (Array.isArray(r) && (s = r.slice(1).concat(a.slice(1))), r = r[0], a = a[0]), this.returnSequences && (a = reverse$5(a, 1)), "concat" === this.mergeMode ? o = concatenate$2([r, a]) : "sum" === this.mergeMode ? o = add$5(r, a) : "ave" === this.mergeMode ? o = mul$1(.5, add$5(r, a)) : "mul" === this.mergeMode ? o = mul$1(r, a) : null == this.mergeMode && (o = [r, a]), this.returnState ? null == this.mergeMode ? o.concat(s) : [o].concat(s) : o;
    });
  }

  resetStates(e) {
    this.forwardLayer.resetStates(), this.backwardLayer.resetStates();
  }

  build(e) {
    nameScope$1(this.forwardLayer.name, () => {
      this.forwardLayer.build(e);
    }), nameScope$1(this.backwardLayer.name, () => {
      this.backwardLayer.build(e);
    }), this.built = !0;
  }

  computeMask(e, t) {
    var n;

    if (Array.isArray(t) && (t = t[0]), n = this.returnSequences ? null == this.mergeMode ? [t, t] : t : null == this.mergeMode ? [null, null] : null, this.returnState) {
      var _e236 = this.forwardLayer.states.map(e => null);

      return Array.isArray(n) ? n.concat(_e236).concat(_e236) : [n].concat(_e236).concat(_e236);
    }

    return n;
  }

  get trainableWeights() {
    return this.forwardLayer.trainableWeights.concat(this.backwardLayer.trainableWeights);
  }

  get nonTrainableWeights() {
    return this.forwardLayer.nonTrainableWeights.concat(this.backwardLayer.nonTrainableWeights);
  }

  setFastWeightInitDuringBuild(e) {
    super.setFastWeightInitDuringBuild(e), null != this.forwardLayer && this.forwardLayer.setFastWeightInitDuringBuild(e), null != this.backwardLayer && this.backwardLayer.setFastWeightInitDuringBuild(e);
  }

  getConfig() {
    var e = {
      mergeMode: this.mergeMode
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

  static fromConfig(e, t) {
    var n = deserialize$1(t.layer);
    if (delete t.layer, null != t.numConstants) throw new NotImplementedError$1("Deserialization of a Bidirectional layer with numConstants present is not supported yet.");
    var r = t;
    return r.layer = n, new e(r);
  }

}

function conv1d$2(e) {
  return new Conv1D$1(e);
}

function conv2d$5(e) {
  return new Conv2D$2(e);
}

function dense$1(e) {
  return new Dense$1(e);
}

function dropout$3(e) {
  return new Dropout$1(e);
}

function flatten$4(e) {
  return new Flatten$1(e);
}

function maxPooling1d$1(e) {
  return new MaxPooling1D$1(e);
}

function maxPooling2d$1(e) {
  return new MaxPooling2D$1(e);
}

var DataType$1, SaverDef$1;
Bidirectional$1.className = "Bidirectional", registerClass$1(Bidirectional$1), function (e) {
  e[e.DT_INVALID = 0] = "DT_INVALID", e[e.DT_FLOAT = 1] = "DT_FLOAT", e[e.DT_DOUBLE = 2] = "DT_DOUBLE", e[e.DT_INT32 = 3] = "DT_INT32", e[e.DT_UINT8 = 4] = "DT_UINT8", e[e.DT_INT16 = 5] = "DT_INT16", e[e.DT_INT8 = 6] = "DT_INT8", e[e.DT_STRING = 7] = "DT_STRING", e[e.DT_COMPLEX64 = 8] = "DT_COMPLEX64", e[e.DT_INT64 = 9] = "DT_INT64", e[e.DT_BOOL = 10] = "DT_BOOL", e[e.DT_QINT8 = 11] = "DT_QINT8", e[e.DT_QUINT8 = 12] = "DT_QUINT8", e[e.DT_QINT32 = 13] = "DT_QINT32", e[e.DT_BFLOAT16 = 14] = "DT_BFLOAT16", e[e.DT_FLOAT_REF = 101] = "DT_FLOAT_REF", e[e.DT_DOUBLE_REF = 102] = "DT_DOUBLE_REF", e[e.DT_INT32_REF = 103] = "DT_INT32_REF", e[e.DT_UINT8_REF = 104] = "DT_UINT8_REF", e[e.DT_INT16_REF = 105] = "DT_INT16_REF", e[e.DT_INT8_REF = 106] = "DT_INT8_REF", e[e.DT_STRING_REF = 107] = "DT_STRING_REF", e[e.DT_COMPLEX64_REF = 108] = "DT_COMPLEX64_REF", e[e.DT_INT64_REF = 109] = "DT_INT64_REF", e[e.DT_BOOL_REF = 110] = "DT_BOOL_REF", e[e.DT_QINT8_REF = 111] = "DT_QINT8_REF", e[e.DT_QUINT8_REF = 112] = "DT_QUINT8_REF", e[e.DT_QINT32_REF = 113] = "DT_QINT32_REF", e[e.DT_BFLOAT16_REF = 114] = "DT_BFLOAT16_REF";
}(DataType$1 || (DataType$1 = {})), function (e) {
  var t;
  (t = e.CheckpointFormatVersion || (e.CheckpointFormatVersion = {}))[t.LEGACY = 0] = "LEGACY", t[t.V1 = 1] = "V1", t[t.V2 = 2] = "V2";
}(SaverDef$1 || (SaverDef$1 = {}));
var version$c = "3.8.0";
var ZipMismatchMode$1;
!function (e) {
  e[e.FAIL = 0] = "FAIL", e[e.SHORTEST = 1] = "SHORTEST", e[e.LONGEST = 2] = "LONGEST";
}(ZipMismatchMode$1 || (ZipMismatchMode$1 = {}));
var version$b = "3.8.0";

function assertNotComplex$3(e, t) {
  Array.isArray(e) || (e = [e]), e.forEach(e => {
    null != e && assert$6("complex64" !== e.dtype, () => "".concat(t, " does not support complex64 tensors in the CPU backend."));
  });
}

var whereImpl$4 = whereImpl$5;

class MathBackendCPU$1 extends KernelBackend$1 {
  constructor() {
    super(), this.blockSize = 48, this.firstUse = !0, this.data = new DataStorage$1(this, engine$1());
  }

  nextDataId() {
    return MathBackendCPU$1.nextDataId++;
  }

  write(e, t, n) {
    this.firstUse && (this.firstUse = !1, env$1().get("IS_NODE") && warn$1("\n============================\nHi there 👋. Looks like you are running TensorFlow.js in Node.js. To speed things up dramatically, install our node backend, which binds to TensorFlow C++, by running npm i @tensorflow/tfjs-node, or npm i @tensorflow/tfjs-node-gpu if you have CUDA. Then call require('@tensorflow/tfjs-node'); (-gpu suffix for CUDA) at the start of your program. Visit https://github.com/tensorflow/tfjs-node for more details.\n============================"));
    var r = {
      id: this.nextDataId()
    };
    return this.data.set(r, {
      values: e,
      dtype: n,
      refCount: 1
    }), r;
  }

  makeTensorInfo(e, t, n) {
    var r;

    if ("string" === t && null != n && n.length > 0 && isString$1(n[0])) {
      var a = n.map(e => encodeString$1(e));
      r = this.write(a, e, t);
    } else r = this.write(n, e, t);

    return {
      dataId: r,
      shape: e,
      dtype: t
    };
  }

  refCount(e) {
    return this.data.has(e) ? this.data.get(e).refCount : 0;
  }

  incRef(e) {
    this.data.get(e).refCount++;
  }

  decRef(e) {
    this.data.has(e) && this.data.get(e).refCount--;
  }

  move(e, t, n, r, a) {
    this.data.set(e, {
      values: t,
      dtype: r,
      refCount: a
    });
  }

  numDataIds() {
    return this.data.numDataIds();
  }

  read(e) {
    var _this69 = this;

    return _asyncToGenerator(function* () {
      return _this69.readSync(e);
    })();
  }

  readSync(e) {
    var {
      dtype: t,
      complexTensorInfos: n
    } = this.data.get(e);
    return "complex64" === t ? mergeRealAndImagArrays$1(this.readSync(n.real.dataId), this.readSync(n.imag.dataId)) : this.data.get(e).values;
  }

  bufferSync(e) {
    var t = this.readSync(e.dataId);
    var n = t;
    if ("string" === e.dtype) try {
      n = t.map(e => decodeString$1(e));
    } catch (e) {
      throw new Error("Failed to decode encoded string bytes into utf-8");
    }
    return buffer$1(e.shape, e.dtype, n);
  }

  makeOutput(e, t, n) {
    var r = this.write(e, t, n);
    return engine$1().makeTensorFromDataId(r, t, n, this);
  }

  disposeData(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;

    if (this.data.has(e)) {
      if (this.data.get(e).refCount--, !t && this.data.get(e).refCount > 0) return !1;
      var {
        complexTensorInfos: n
      } = this.data.get(e);
      null != n && (this.disposeData(n.real.dataId, !0), this.disposeData(n.imag.dataId, !0)), this.data.delete(e);
    }

    return !0;
  }

  disposeIntermediateTensorInfo(e) {
    this.disposeData(e.dataId);
  }

  time(e) {
    return _asyncToGenerator(function* () {
      var t = now$1();
      return e(), {
        kernelMs: now$1() - t
      };
    })();
  }

  memory() {
    return {
      unreliable: !0,
      reasons: ["The reported memory is an upper bound. Due to automatic garbage collection, the true allocated memory may be less."]
    };
  }

  where(e) {
    assertNotComplex$3([e], "where");
    var t = this.readSync(e.dataId);
    return whereImpl$4(e.shape, t);
  }

  dispose() {}

  floatPrecision() {
    return 32;
  }

  epsilon() {
    return super.epsilon();
  }

}

function simpleAbsImpl$1(e) {
  var t = new Float32Array(e.length);

  for (var n = 0; n < e.length; ++n) {
    t[n] = Math.abs(e[n]);
  }

  return t;
}

MathBackendCPU$1.nextDataId = 0;

var abs$4 = e => {
  var {
    x: t
  } = e.inputs,
      n = e.backend;
  assertNotComplex$3(t, "abs");
  var r = new Float32Array(sizeFromShape$1(t.shape));
  return r = simpleAbsImpl$1(n.data.get(t.dataId).values), n.makeOutput(r, t.shape, "float32");
},
    absConfig$3 = {
  kernelName: Abs$1,
  backendName: "cpu",
  kernelFunc: abs$4
};

function createSimpleBinaryKernelImpl$1(e) {
  return (t, n, r, a, s) => {
    var o = assertAndGetBroadcastShape$1(t, n),
        i = o.length,
        l = computeStrides$1(o),
        u = getTypedArrayFromDType$1(s, sizeFromShape$1(o)),
        c = t.length,
        p = n.length,
        d = computeStrides$1(t),
        h = computeStrides$1(n),
        m = getBroadcastDims$3(t, o),
        f = getBroadcastDims$3(n, o);
    if (m.length + f.length === 0) for (var _t173 = 0; _t173 < u.length; ++_t173) {
      u[_t173] = e(r[_t173 % r.length], a[_t173 % a.length]);
    } else {
      var _loop21 = function _loop21(_t174) {
        var n = indexToLoc$1(_t174, i, l),
            s = n.slice(-c);
        m.forEach(e => s[e] = 0);
        var o = locToIndex$1(s, c, d),
            g = n.slice(-p);
        f.forEach(e => g[e] = 0);
        var $ = locToIndex$1(g, p, h);
        u[_t174] = e(r[o], a[$]);
      };

      for (var _t174 = 0; _t174 < u.length; ++_t174) {
        _loop21(_t174);
      }
    }
    return [u, o];
  };
}

function complex$4(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    real: r,
    imag: a
  } = t,
      s = n.data.get(r.dataId).values,
      o = n.data.get(a.dataId).values,
      i = n.makeTensorInfo(r.shape, "complex64");
  return n.data.get(i.dataId).complexTensorInfos = {
    real: n.makeTensorInfo(r.shape, "float32", s),
    imag: n.makeTensorInfo(a.shape, "float32", o)
  }, i;
}

var complexConfig$3 = {
  kernelName: Complex$1,
  backendName: "cpu",
  kernelFunc: complex$4
};

function zeros$3(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : "float32";
  if ("complex64" === n) return complex$4({
    inputs: {
      real: zeros$3(e, t, "float32"),
      imag: zeros$3(e, t, "float32")
    },
    backend: e
  });
  var r = makeZerosTypedArray$1(sizeFromShape$1(t), n);
  return e.makeTensorInfo(t, n, r);
}

function identity$4(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    x: r
  } = t;
  return n.incRef(r.dataId), {
    dataId: r.dataId,
    shape: r.shape,
    dtype: r.dtype
  };
}

var identityConfig$3 = {
  kernelName: Identity$3,
  backendName: "cpu",
  kernelFunc: identity$4
};

function real$4(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    input: r
  } = t,
      a = n.data.get(r.dataId).complexTensorInfos.real,
      s = n.data.get(a.dataId).values;
  return n.makeTensorInfo(a.shape, a.dtype, s);
}

var realConfig$3 = {
  kernelName: Real$1,
  backendName: "cpu",
  kernelFunc: real$4
};

function cast$5(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    dtype: s
  } = r;

  if ("complex64" === s) {
    if ("complex64" === a.dtype) return identity$4({
      inputs: {
        x: a
      },
      backend: n
    });

    var _e237 = zeros$3(n, a.shape, a.dtype),
        _t175 = cast$5({
      inputs: {
        x: a
      },
      backend: n,
      attrs: {
        dtype: "float32"
      }
    }),
        _r64 = complex$4({
      inputs: {
        real: _t175,
        imag: _e237
      },
      backend: n
    });

    return n.disposeIntermediateTensorInfo(_e237), n.disposeIntermediateTensorInfo(_t175), _r64;
  }

  if ("complex64" === a.dtype) {
    var _e238 = real$4({
      inputs: {
        input: a
      },
      backend: n
    }),
        _t176 = cast$5({
      inputs: {
        x: _e238
      },
      backend: n,
      attrs: {
        dtype: s
      }
    });

    return n.disposeIntermediateTensorInfo(_e238), _t176;
  }

  if (!hasEncodingLoss$1(a.dtype, s)) {
    var _e239 = identity$4({
      inputs: {
        x: a
      },
      backend: n
    });

    return {
      dataId: _e239.dataId,
      shape: _e239.shape,
      dtype: s
    };
  }

  if ("int32" === s) {
    var _e240 = n.data.get(a.dataId).values,
        _t177 = Int32Array.from(_e240);

    return n.makeTensorInfo(a.shape, "int32", _t177);
  }

  if ("bool" === s) {
    var _e241 = n.data.get(a.dataId).values,
        _t178 = toTypedArray$1([0], a.dtype),
        [_r65, _s28] = createSimpleBinaryKernelImpl$1((e, t) => e !== t ? 1 : 0)(a.shape, [], _e241, _t178, "bool");

    return n.makeTensorInfo(_s28, "bool", _r65);
  }

  throw new Error("Error in Cast: failed to cast ".concat(a.dtype, " to ").concat(s));
}

var castConfig$3 = {
  kernelName: Cast$1,
  backendName: "cpu",
  kernelFunc: cast$5
};

function binaryKernelFunc$3(e, t, n, r) {
  return null == n ? _ref3 => {
    var {
      inputs: n,
      backend: a
    } = _ref3;
    var {
      a: s,
      b: o
    } = n,
        i = a;
    assertNotComplex$3([s, o], e);
    var l = i.data.get(s.dataId).values,
        u = i.data.get(o.dataId).values,
        c = "string" === s.dtype ? fromUint8ToStringArray$1(l) : l,
        p = "string" === s.dtype ? fromUint8ToStringArray$1(u) : u,
        d = r || s.dtype,
        [h, m] = t(s.shape, o.shape, c, p, d);
    return i.makeTensorInfo(m, d, h);
  } : _ref4 => {
    var {
      inputs: e,
      backend: a
    } = _ref4;
    var {
      a: s,
      b: o
    } = e,
        i = a;

    if ("complex64" === s.dtype || "complex64" === o.dtype) {
      var _e242 = cast$5({
        inputs: {
          x: s
        },
        backend: i,
        attrs: {
          dtype: "complex64"
        }
      }),
          _t179 = i.data.get(_e242.dataId),
          _r66 = _t179.complexTensorInfos.imag,
          _a43 = i.data.get(_t179.complexTensorInfos.real.dataId).values,
          l = i.data.get(_r66.dataId).values,
          u = cast$5({
        inputs: {
          x: o
        },
        backend: i,
        attrs: {
          dtype: "complex64"
        }
      }),
          c = i.data.get(u.dataId),
          _p6 = c.complexTensorInfos.imag,
          d = i.data.get(c.complexTensorInfos.real.dataId).values,
          h = i.data.get(_p6.dataId).values,
          [m, f, g] = n(s.shape, o.shape, _a43, l, d, h),
          $ = i.makeTensorInfo(g, "float32", m),
          y = i.makeTensorInfo(g, "float32", f),
          b = complex$4({
        inputs: {
          real: $,
          imag: y
        },
        backend: i
      });

      return i.disposeIntermediateTensorInfo(_e242), i.disposeIntermediateTensorInfo(u), i.disposeIntermediateTensorInfo($), i.disposeIntermediateTensorInfo(y), b;
    }

    {
      var _e243 = i.data.get(s.dataId).values,
          _n82 = i.data.get(o.dataId).values,
          _a44 = r || s.dtype,
          [_l6, _u4] = t(s.shape, o.shape, _e243, _n82, _a44);

      return i.makeTensorInfo(_u4, _a44, _l6);
    }
  };
}

function createComplexBinaryKernelImpl$1(e) {
  return (t, n, r, a, s, o) => {
    var i = assertAndGetBroadcastShape$1(t, n),
        l = sizeFromShape$1(i),
        u = i.length,
        c = computeStrides$1(i),
        p = getTypedArrayFromDType$1("float32", l),
        d = getTypedArrayFromDType$1("float32", l),
        h = getBroadcastDims$3(t, i),
        m = getBroadcastDims$3(n, i),
        f = mergeRealAndImagArrays$1(r, a),
        g = mergeRealAndImagArrays$1(s, o),
        $ = t.length,
        y = computeStrides$1(t),
        b = n.length,
        x = computeStrides$1(n);
    if (h.length + m.length === 0) for (var _t180 = 0; _t180 < p.length; _t180++) {
      var _n83 = _t180 % f.length,
          _r67 = _t180 % g.length,
          _a45 = e(f[2 * _n83], f[2 * _n83 + 1], g[2 * _r67], g[2 * _r67 + 1]);

      p[_t180] = _a45.real, d[_t180] = _a45.imag;
    } else {
      var _loop22 = function _loop22(_t181) {
        var n = indexToLoc$1(_t181, u, c),
            r = n.slice(-$);
        h.forEach(e => r[e] = 0);
        var a = locToIndex$1(r, $, y),
            s = n.slice(-b);
        m.forEach(e => s[e] = 0);
        var o = locToIndex$1(s, b, x),
            i = e(f[2 * a], f[2 * a + 1], g[2 * o], g[2 * o + 1]);
        p[_t181] = i.real, d[_t181] = i.imag;
      };

      for (var _t181 = 0; _t181 < p.length; _t181++) {
        _loop22(_t181);
      }
    }
    return [p, d, i];
  };
}

var addImpl$1 = createSimpleBinaryKernelImpl$1((e, t) => e + t),
    addComplexImpl$1 = createComplexBinaryKernelImpl$1((e, t, n, r) => ({
  real: e + n,
  imag: t + r
})),
    add$4 = binaryKernelFunc$3(Add$3, addImpl$1, addComplexImpl$1),
    addConfig$3 = {
  kernelName: Add$3,
  backendName: "cpu",
  kernelFunc: add$4
};

function bincountImpl$1(e, t, n, r, a) {
  var s = sizeFromShape$1(r),
      o = makeZerosTypedArray$1(a, n);

  for (var _n84 = 0; _n84 < e.length; _n84++) {
    var _r68 = e[_n84];
    if (_r68 < 0) throw new Error("Input x must be non-negative!");
    _r68 >= a || (o[_r68] += s > 0 ? t[_n84] : 1);
  }

  return o;
}

function bincountReduceImpl$1(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
  var a = e.shape[0],
      s = e.shape[1],
      o = buffer$1([a, n], t.dtype);

  for (var i = 0; i < a; i++) {
    for (var _a46 = 0; _a46 < s; _a46++) {
      var _s29 = e.get(i, _a46);

      if (_s29 < 0) throw new Error("Input x must be non-negative!");
      _s29 >= n || o.set(r ? 1 : t.size > 0 ? o.get(i, _s29) + t.get(i, _a46) : o.get(i, _s29) + 1, i, _s29);
    }
  }

  return o;
}

function createSimpleUnaryImpl$1(e) {
  return (t, n, r) => {
    var a = getTypedArrayFromDType$1(n, t.length);

    for (var _n85 = 0; _n85 < t.length; ++_n85) {
      a[_n85] = e(t[_n85], r);
    }

    return a;
  };
}

function unaryKernelFunc$3(e, t, n) {
  return _ref5 => {
    var {
      inputs: r,
      attrs: a,
      backend: s
    } = _ref5;
    var {
      x: o
    } = r;
    if (assertNotComplex$3(o, e), "string" === o.dtype || "string" === n) throw new Error("unaryKernelFunc does not support string input/output");
    var i = s,
        l = i.data.get(o.dataId).values,
        u = sizeFromShape$1(o.shape),
        c = n || o.dtype,
        p = getArrayFromDType$1(c, u);

    for (var _e244 = 0; _e244 < u; ++_e244) {
      p[_e244] = t(l[_e244], a);
    }

    return i.makeTensorInfo(o.shape, c, p);
  };
}

function unaryKernelFuncFromImpl$1(e, t, n) {
  return _ref6 => {
    var {
      inputs: r,
      attrs: a,
      backend: s
    } = _ref6;
    var {
      x: o
    } = r;
    if (assertNotComplex$3(o, e), "string" === o.dtype || "string" === n) throw new Error("unaryKernelFunc does not support string input/output");
    var i = s,
        l = i.data.get(o.dataId).values,
        u = n || o.dtype,
        c = t(l, u, a);
    return i.makeTensorInfo(o.shape, u, c);
  };
}

var ceilImpl$1 = createSimpleUnaryImpl$1(e => Math.ceil(e)),
    ceil$4 = unaryKernelFuncFromImpl$1(Ceil$1, ceilImpl$1),
    ceilConfig$3 = {
  kernelName: Ceil$1,
  backendName: "cpu",
  kernelFunc: ceil$4
};

function concatImpl$3(e, t, n, r) {
  var a = getArrayFromDType$1(n, sizeFromShape$1(t));

  if (r && "string" !== n) {
    var _t182 = 0;
    e.forEach(e => {
      var n = sizeFromShape$1(e.shape);
      a.set(e.vals, _t182), _t182 += n;
    });
  } else {
    var _r69 = 0;
    e.forEach(e => {
      var s = "string" === n ? fromUint8ToStringArray$1(e.vals) : e.vals;
      var o = 0;

      for (var _n86 = 0; _n86 < e.shape[0]; ++_n86) {
        var i = _n86 * t[1] + _r69;

        for (var _t183 = 0; _t183 < e.shape[1]; ++_t183) {
          a[i + _t183] = s[o++];
        }
      }

      _r69 += e.shape[1];
    });
  }

  return a;
}

var equalImpl$1 = createSimpleBinaryKernelImpl$1((e, t) => e === t ? 1 : 0),
    equal$4 = binaryKernelFunc$3(Equal$1, equalImpl$1, null, "bool"),
    equalConfig$3 = {
  kernelName: Equal$1,
  backendName: "cpu",
  kernelFunc: equal$4
},
    expImpl$1 = createSimpleUnaryImpl$1(e => Math.exp(e)),
    exp$4 = unaryKernelFuncFromImpl$1(Exp$1, expImpl$1),
    expConfig$3 = {
  kernelName: Exp$1,
  backendName: "cpu",
  kernelFunc: exp$4
},
    expm1Impl$1 = createSimpleUnaryImpl$1(e => Math.expm1(e)),
    expm1$4 = unaryKernelFuncFromImpl$1(Expm1$1, expm1Impl$1),
    expm1Config$3 = {
  kernelName: Expm1$1,
  backendName: "cpu",
  kernelFunc: expm1$4
},
    floorImpl$1 = createSimpleUnaryImpl$1(e => Math.floor(e)),
    floor$4 = unaryKernelFuncFromImpl$1(Floor$1, floorImpl$1),
    floorConfig$3 = {
  kernelName: Floor$1,
  backendName: "cpu",
  kernelFunc: floor$4
};

function gatherNdImpl$1(e, t, n, r, a, s, o, i, l) {
  var u = buffer$1([r, s], n);

  for (var _n87 = 0; _n87 < r; _n87++) {
    var _r70 = [];
    var c = 0;

    for (var _t184 = 0; _t184 < a; _t184++) {
      var _s30 = e[_n87 * a + _t184];
      c += _s30 * o[_t184], _r70.push(_s30);
    }

    if (c < 0 || c >= l / s) throw new Error("Invalid indices: ".concat(_r70, " does not index into ").concat(i));

    for (var _e245 = 0; _e245 < s; _e245++) {
      u.values[_n87 * s + _e245] = t.get(...t.indexToLoc(c * s + _e245));
    }
  }

  return u;
}

function gatherV2Impl$1(e, t, n) {
  var r = buffer$1(n, e.dtype);

  for (var _n88 = 0; _n88 < r.size; ++_n88) {
    var a = r.indexToLoc(_n88).slice(),
        s = t.locToIndex([a[0], a[2]]);
    a[2] = t.values[s];
    var o = e.locToIndex(a);
    r.values[_n88] = e.values[o];
  }

  return r;
}

var greaterImpl$1 = createSimpleBinaryKernelImpl$1((e, t) => e > t ? 1 : 0),
    greater$5 = binaryKernelFunc$3(Greater$1, greaterImpl$1, null, "bool"),
    greaterConfig$3 = {
  kernelName: Greater$1,
  backendName: "cpu",
  kernelFunc: greater$5
},
    greaterEqualImpl$1 = createSimpleBinaryKernelImpl$1((e, t) => e >= t ? 1 : 0),
    greaterEqual$4 = binaryKernelFunc$3(GreaterEqual$1, greaterEqualImpl$1, null, "bool"),
    greaterEqualConfig$3 = {
  kernelName: GreaterEqual$1,
  backendName: "cpu",
  kernelFunc: greaterEqual$4
},
    lessImpl$1 = createSimpleBinaryKernelImpl$1((e, t) => e < t ? 1 : 0),
    less$5 = binaryKernelFunc$3(Less$1, lessImpl$1, null, "bool"),
    lessConfig$3 = {
  kernelName: Less$1,
  backendName: "cpu",
  kernelFunc: less$5
},
    lessEqualImpl$1 = createSimpleBinaryKernelImpl$1((e, t) => e <= t ? 1 : 0),
    lessEqual$4 = binaryKernelFunc$3(LessEqual$1, lessEqualImpl$1, null, "bool"),
    lessEqualConfig$3 = {
  kernelName: LessEqual$1,
  backendName: "cpu",
  kernelFunc: lessEqual$4
};

function linSpaceImpl$1(e, t, n) {
  var r = (t - e) / (n - 1),
      a = makeZerosTypedArray$1(n, "float32");
  a[0] = e;

  for (var _e246 = 1; _e246 < a.length; _e246++) {
    a[_e246] = a[_e246 - 1] + r;
  }

  return a;
}

var logImpl$1 = createSimpleUnaryImpl$1(e => Math.log(e)),
    log$5 = unaryKernelFuncFromImpl$1(Log$1, logImpl$1),
    logConfig$3 = {
  kernelName: Log$1,
  backendName: "cpu",
  kernelFunc: log$5
};

function maxImpl$3(e, t, n, r) {
  var a = getTypedArrayFromDType$1(r, sizeFromShape$1(n));

  for (var _n89 = 0; _n89 < a.length; ++_n89) {
    var _r71 = _n89 * t;

    var s = e[_r71];

    for (var _n90 = 0; _n90 < t; ++_n90) {
      var _t185 = e[_r71 + _n90];
      (Number.isNaN(_t185) || _t185 > s) && (s = _t185);
    }

    a[_n89] = s;
  }

  return a;
}

var maximumImpl$1 = createSimpleBinaryKernelImpl$1((e, t) => Math.max(e, t)),
    maximum$5 = binaryKernelFunc$3(Maximum$3, maximumImpl$1),
    maximumConfig$3 = {
  kernelName: Maximum$3,
  backendName: "cpu",
  kernelFunc: maximum$5
},
    minimumImpl$1 = createSimpleBinaryKernelImpl$1((e, t) => Math.min(e, t)),
    minimum$5 = binaryKernelFunc$3(Minimum$3, minimumImpl$1),
    minimumConfig$3 = {
  kernelName: Minimum$3,
  backendName: "cpu",
  kernelFunc: minimum$5
},
    multiplyImpl$1 = createSimpleBinaryKernelImpl$1((e, t) => e * t),
    multiplyComplexImpl$1 = createComplexBinaryKernelImpl$1((e, t, n, r) => ({
  real: e * n - t * r,
  imag: e * r + t * n
})),
    multiply$4 = binaryKernelFunc$3(Multiply$3, multiplyImpl$1, multiplyComplexImpl$1),
    multiplyConfig$3 = {
  kernelName: Multiply$3,
  backendName: "cpu",
  kernelFunc: multiply$4
};

function negImpl$1(e, t, n) {
  var r = createScalarValue$1(-1, n);
  return multiplyImpl$1([], t, r, e, n);
}

function neg$4(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    x: r
  } = t;
  assertNotComplex$3(r, "neg");
  var a = n.data.get(r.dataId).values,
      [s, o] = negImpl$1(a, r.shape, r.dtype);
  return n.makeTensorInfo(o, r.dtype, s);
}

var negConfig$3 = {
  kernelName: Neg$1,
  backendName: "cpu",
  kernelFunc: neg$4
},
    notEqualImpl$1 = createSimpleBinaryKernelImpl$1((e, t) => e !== t ? 1 : 0),
    notEqual$4 = binaryKernelFunc$3(NotEqual$1, notEqualImpl$1, null, "bool"),
    notEqualConfig$3 = {
  kernelName: NotEqual$1,
  backendName: "cpu",
  kernelFunc: notEqual$4
};

function transposeImpl$3(e, t, n, r, a) {
  var s = t.length,
      o = sizeFromShape$1(t),
      i = computeStrides$1(t),
      l = computeStrides$1(a),
      u = getTypedArrayFromDType$1(n, sizeFromShape$1(a));

  for (var _t186 = 0; _t186 < o; ++_t186) {
    var _n91 = indexToLoc$1(_t186, s, i),
        _a47 = new Array(_n91.length);

    for (var _e247 = 0; _e247 < _a47.length; _e247++) {
      _a47[_e247] = _n91[r[_e247]];
    }

    u[locToIndex$1(_a47, s, l)] = e[_t186];
  }

  return u;
}

function transpose$4(e) {
  var {
    inputs: t,
    attrs: n,
    backend: r
  } = e,
      {
    x: a
  } = t,
      {
    perm: s
  } = n;
  assertNotComplex$3(a, "transpose");
  var o = new Array(a.shape.length);

  for (var _e248 = 0; _e248 < o.length; _e248++) {
    o[_e248] = a.shape[s[_e248]];
  }

  var i = transposeImpl$3(r.data.get(a.dataId).values, a.shape, a.dtype, s, o);
  return {
    dataId: r.write(i, o, a.dtype),
    shape: o,
    dtype: a.dtype
  };
}

var transposeConfig$3 = {
  kernelName: Transpose$1,
  backendName: "cpu",
  kernelFunc: transpose$4
};

function prodImpl$1(e, t, n, r) {
  var [a, s] = computeOutAndReduceShapes$1(e, r),
      o = upcastType$1(t, "int32"),
      i = makeZerosTypedArray$1(sizeFromShape$1(a), o),
      l = sizeFromShape$1(s);

  for (var _e249 = 0; _e249 < i.length; ++_e249) {
    var _t187 = _e249 * l;

    var _r72 = 1;

    for (var _e250 = 0; _e250 < l; ++_e250) {
      _r72 *= n[_t187 + _e250];
    }

    i[_e249] = _r72;
  }

  return {
    outVals: i,
    outShape: a,
    outDtype: o
  };
}

function prod$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    axis: s,
    keepDims: o
  } = r;
  assertNotComplex$3(a, "prod");
  var i = a.shape.length,
      l = parseAxisParam$1(s, a.shape),
      u = getAxesPermutation$1(l, i);
  var c = l,
      p = a;
  var d = [];
  null != u && (p = transpose$4({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      perm: u
    }
  }), d.push(p), c = getInnerMostAxes$1(c.length, i));
  var h = n.data.get(p.dataId).values,
      {
    outVals: m,
    outShape: f,
    outDtype: g
  } = prodImpl$1(p.shape, p.dtype, h, c);
  var $ = f;
  return o && ($ = expandShapeToKeepDim$1(f, l)), d.forEach(e => n.disposeIntermediateTensorInfo(e)), n.makeTensorInfo($, g, m);
}

var prodConfig$3 = {
  kernelName: Prod$1,
  backendName: "cpu",
  kernelFunc: prod$4
};

function rangeImpl$1(e, t, n, r) {
  if (e === t || e < t && n < 0 || t < e && n > 1) return makeZerosTypedArray$1(0, r);
  var a = makeZerosTypedArray$1(Math.abs(Math.ceil((t - e) / n)), r);
  t < e && 1 === n && (n = -1), a[0] = e;

  for (var _e251 = 1; _e251 < a.length; _e251++) {
    a[_e251] = a[_e251 - 1] + n;
  }

  return a;
}

var rsqrtImpl$1 = createSimpleUnaryImpl$1(e => 1 / Math.sqrt(e)),
    rsqrt$4 = unaryKernelFuncFromImpl$1(Rsqrt$1, rsqrtImpl$1),
    rsqrtConfig$3 = {
  kernelName: Rsqrt$1,
  backendName: "cpu",
  kernelFunc: rsqrt$4
};

function sliceImpl$1(e, t, n, r, a) {
  var s = isSliceContinous$1(r, t, n),
      o = sizeFromShape$1(n),
      i = computeStrides$1(r);

  if (s) {
    var _n92 = computeFlatOffset$1(t, i);

    return "string" === a ? e.slice(_n92, _n92 + o) : e.subarray(_n92, _n92 + o);
  }

  var l = buffer$1(r, a, "string" === a ? fromUint8ToStringArray$1(e) : e),
      u = buffer$1(n, a);

  for (var _e252 = 0; _e252 < u.size; ++_e252) {
    var _n93 = u.indexToLoc(_e252),
        _r73 = _n93.map((e, n) => e + t[n]);

    u.set(l.get(..._r73), ..._n93);
  }

  return "string" === a ? fromStringArrayToUint8$1(u.values) : u.values;
}

function slice$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    begin: s,
    size: o
  } = r;
  assertNotComplex$3(a, "slice");
  var [i, l] = parseSliceParams$1(a, s, o);
  assertParamsValid$1(a, i, l);
  var u = sliceImpl$1(n.data.get(a.dataId).values, i, l, a.shape, a.dtype);
  return n.makeTensorInfo(l, a.dtype, u);
}

var sliceConfig$3 = {
  kernelName: Slice$1,
  backendName: "cpu",
  kernelFunc: slice$4
};

function sparseFillEmptyRowsImpl$1(e, t, n, r, a, s, o) {
  var i = t[0],
      l = s[0],
      u = new Array(l),
      c = new Array(i),
      p = t[1];

  if (0 === l) {
    if (0 !== i) throw new Error("Received SparseTensor with denseShape[0] = 0 but\n         indices.shape[0] = ".concat(i));
    return [getArrayFromDType$1(n, 0), [0, p], getArrayFromDType$1(a, 0), u, c];
  }

  var d = !0,
      h = 0;
  var m = new Array(l).fill(0);

  for (var _t188 = 0; _t188 < i; ++_t188) {
    var _n94 = e[_t188 * p];
    if (_n94 < 0) throw new Error("indices(".concat(_t188, ", 0) is invalid: ").concat(_n94, " < 0"));
    if (_n94 >= l) throw new Error("indices(".concat(_t188, ", 0) is invalid: ").concat(_n94, " >= ").concat(l));
    ++m[_n94], d = d && _n94 >= h, h = _n94;
  }

  var f = !0;

  for (var _e253 = 0; _e253 < l; ++_e253) {
    var _t189 = 0 === m[_e253];

    u[_e253] = _t189, f = f && !_t189, m[_e253] = Math.max(m[_e253], 1), _e253 > 0 && (m[_e253] += m[_e253 - 1]);
  }

  if (f && d) {
    var _t190 = e,
        _n95 = r;

    for (var _e254 = 0; _e254 < i; ++_e254) {
      c[_e254] = _e254;
    }

    return [_t190, [i, p], _n95, u, c];
  }

  {
    var _t191 = m[l - 1],
        _s31 = getArrayFromDType$1(n, _t191 * p),
        _d2 = getArrayFromDType$1(a, _t191),
        _h2 = new Array(l).fill(0);

    for (var _t192 = 0; _t192 < i; ++_t192) {
      var _n96 = e[_t192 * p],
          _a48 = (0 === _n96 ? 0 : m[_n96 - 1]) + _h2[_n96];

      _h2[_n96]++;

      for (var _n97 = 0; _n97 < p; ++_n97) {
        _s31[_a48 * p + _n97] = e[_t192 * p + _n97];
      }

      _d2[_a48] = r[_t192], c[_t192] = _a48;
    }

    for (var _e255 = 0; _e255 < l; ++_e255) {
      if (0 === _h2[_e255]) {
        var _t193 = 0 === _e255 ? 0 : m[_e255 - 1];

        _s31[_t193 * p + 0] = _e255;

        for (var _e256 = 1; _e256 < p; ++_e256) {
          _s31[_t193 * p + _e256] = 0;
        }

        _d2[_t193] = o;
      }
    }

    return [_s31, [_t191, p], _d2, u, c];
  }
}

function sparseReshapeImpl$1(e, t, n, r, a) {
  var s = sizeFromShape$1(r),
      o = t[0],
      i = a.length,
      l = [];
  var u = 1,
      c = -1;

  for (var _e257 = 0; _e257 < i; ++_e257) {
    var _t194 = a[_e257];

    if (-1 === _t194) {
      if (-1 !== c) throw new Error("only one output dimension may be -1, not both ".concat(c, " and ").concat(_e257));
      c = _e257, l.push(1);
    } else {
      if (_t194 < 0) throw new Error("size ".concat(_e257, " must be non-negative, not ").concat(_t194));
      u *= _t194, l.push(_t194);
    }
  }

  if (-1 !== c) {
    if (u <= 0) throw new Error("reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero");

    var _e258 = Math.trunc(s / u);

    if (u * _e258 !== s) throw new Error("Input to reshape is a SparseTensor with ".concat(s, "\n          dense values, but the requested shape requires a multiple of ").concat(u, ". inputShape=").concat(r, " outputShape= ").concat(l));
    l[c] = _e258;
  }

  var p = sizeFromShape$1(l);
  if (p !== s) throw new Error("Input to reshape is a tensor with ".concat(s, " dense values, but the requested shape has ").concat(p, ". inputShape=").concat(r, " outputShape=").concat(l));
  var d = r.length,
      h = [];

  if (d > 0) {
    h[d - 1] = 1;

    for (var _e259 = d - 2; _e259 >= 0; --_e259) {
      h[_e259] = h[_e259 + 1] * r[_e259 + 1];
    }
  }

  var m = [];

  if (i > 0) {
    m[i - 1] = 1;

    for (var _e260 = i - 2; _e260 >= 0; --_e260) {
      m[_e260] = m[_e260 + 1] * l[_e260 + 1];
    }
  }

  var f = getArrayFromDType$1(n, o * i);

  for (var _t195 = 0; _t195 < o; ++_t195) {
    var _n98 = 0;

    for (var _r74 = 0; _r74 < d; ++_r74) {
      _n98 += e[_t195 * d + _r74] * h[_r74];
    }

    for (var _e261 = 0; _e261 < i; ++_e261) {
      f[_t195 * i + _e261] = Math.trunc(_n98 / m[_e261]), _n98 %= m[_e261];
    }
  }

  return [f, [o, i], l];
}

function sparseSegmentReductionImpl$1(e, t, n, r, a) {
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : !1;
  var o = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : 0;
  var i = r.length;
  if (i !== a.length) throw new Error("segmentIds and indices should have same size.");
  var l = [t[0], e.length / t[0]],
      u = l[1],
      c = i > 0 ? a[i - 1] + 1 : 0;
  if (c < 0) throw new Error("segment ids must be >= 0");
  var p = t.slice();
  p[0] = c;
  var d = getArrayFromDType$1(n, p.reduce((e, t) => e * t, 1));
  if (0 === i) return c > 0 && d.fill(o), [d, p];
  if (c <= 0) throw new Error("segment ids must be >= 0");
  var h = 0,
      m = 1,
      f = 0,
      g = a[h];

  for (;;) {
    var _t196 = 0;

    if (m < i) {
      if (_t196 = a[m], g === _t196) {
        ++m;
        continue;
      }

      if (g >= _t196) throw new Error("segment ids are not increasing");
    }

    if (g < 0 || g >= c) throw new Error("Segment id ".concat(g, " out of range [0, ").concat(c, "), possibly because segmentIds input is not sorted."));
    g > f && d.fill(o, f * u, g * u);

    for (var _t197 = h; _t197 < m; ++_t197) {
      var _n99 = r[_t197];
      if (_n99 < 0 || _n99 >= l[0]) throw new Error("Bad: indices[".concat(_t197, "] == ").concat(r[_t197], " out of range [0, ").concat(l[0], ")"));

      for (var _t198 = 0; _t198 < u; _t198++) {
        d[g * u + _t198] += e[_n99 * u + _t198];
      }
    }

    if (s) for (var _e262 = 0; _e262 < u; _e262++) {
      d[g * u + _e262] /= m - h;
    }
    if (h = m, ++m, f = g + 1, g = _t196, m > i) break;
  }

  return f < c && d.fill(o, f * u, c * u), [d, p];
}

var squaredDifferenceImpl$1 = createSimpleBinaryKernelImpl$1((e, t) => {
  var n = e - t;
  return n * n;
}),
    squaredDifference$4 = binaryKernelFunc$3(SquaredDifference$1, squaredDifferenceImpl$1),
    squaredDifferenceConfig$3 = {
  kernelName: SquaredDifference$1,
  backendName: "cpu",
  kernelFunc: squaredDifference$4
};

function stridedSliceImpl$1(e, t, n, r) {
  var a = buffer$1(e, t.dtype);

  for (var _e263 = 0; _e263 < a.size; _e263++) {
    var s = a.indexToLoc(_e263),
        o = new Array(s.length);

    for (var _e264 = 0; _e264 < o.length; _e264++) {
      o[_e264] = s[_e264] * n[_e264] + r[_e264];
    }

    a.set(t.get(...o), ...s);
  }

  return a;
}

class StringNGramsOp$1 {
  constructor(e, t, n, r, a, s) {
    this.separator = encodeString$1(e), this.nGramWidths = t, this.leftPad = encodeString$1(n), this.rightPad = encodeString$1(r), this.padWidth = a, this.preserveShort = s;
  }

  getPadWidth(e) {
    return Math.min(this.padWidth < 0 ? e - 1 : this.padWidth, e - 1);
  }

  getNumNGrams(e, t) {
    var n = this.getPadWidth(t);
    return Math.max(0, e + 2 * n - t + 1);
  }

  createNGrams(e, t, n, r, a, s) {
    var _this70 = this;

    var _loop23 = function _loop23(o) {
      var i = _this70.getPadWidth(s),
          l = Math.max(0, i - o),
          u = Math.max(0, i - (a - (o + 1))),
          c = s - (l + u),
          p = t + (l > 0 ? 0 : o - i);

      var d = 0;
      d += l * _this70.leftPad.length;

      for (var _t199 = 0; _t199 < c; ++_t199) {
        d += e[p + _t199].length;
      }

      d += u * _this70.rightPad.length, d += (l + u + c - 1) * _this70.separator.length, n[r + o] = new Uint8Array(d);
      var h = n[r + o];
      var m = 0;

      var f = e => e.forEach(e => h[m++] = e);

      for (var _e265 = 0; _e265 < l; ++_e265) {
        f(_this70.leftPad), f(_this70.separator);
      }

      for (var _t200 = 0; _t200 < c - 1; ++_t200) {
        f(e[p + _t200]), f(_this70.separator);
      }

      if (c > 0) {
        f(e[p + c - 1]);

        for (var _e266 = 0; _e266 < u; ++_e266) {
          f(_this70.separator), f(_this70.rightPad);
        }
      } else {
        for (var _e267 = 0; _e267 < u - 1; ++_e267) {
          f(_this70.rightPad), f(_this70.separator);
        }

        f(_this70.rightPad);
      }
    };

    for (var o = 0; o < a; ++o) {
      _loop23(o);
    }
  }

  compute(e, t) {
    var _this71 = this;

    var n = e.length,
        r = t.length;

    if (r > 0) {
      var _e268 = t[0];
      if (0 !== _e268) throw new Error("First split value must be 0, got ".concat(_e268));

      for (var _a49 = 1; _a49 < r; ++_a49) {
        var _r75 = t[_a49] >= _e268;

        if (_r75 = _r75 && t[_a49] <= n, !_r75) throw new Error("Invalid split value ".concat(t[_a49], ", must be in [").concat(_e268, ", ").concat(n, "]"));
        _e268 = t[_a49];
      }

      if (_e268 !== n) throw new Error("Last split value must be data size. Expected ".concat(n, ", got ").concat(_e268));
    }

    var a = r - 1,
        s = getArrayFromDType$1("int32", r);

    if (0 === n || 0 === r) {
      var _e269 = new Array(n);

      for (var _e270 = 0; _e270 <= a; ++_e270) {
        s[_e270] = 0;
      }

      return [_e269, s];
    }

    s[0] = 0;

    var _loop24 = function _loop24(_e271) {
      var n = t[_e271] - t[_e271 - 1];
      var r = 0;
      _this71.nGramWidths.forEach(e => {
        r += _this71.getNumNGrams(n, e);
      }), _this71.preserveShort && n > 0 && 0 === r && (r = 1), s[_e271] = s[_e271 - 1] + r;
    };

    for (var _e271 = 1; _e271 <= a; ++_e271) {
      _loop24(_e271);
    }

    var o = new Array(s[a]);

    var _loop25 = function _loop25(_n100) {
      var r = t[_n100];
      var a = s[_n100];

      if (_this71.nGramWidths.forEach(s => {
        var i = _this71.getNumNGrams(t[_n100 + 1] - t[_n100], s);

        _this71.createNGrams(e, r, o, a, i, s), a += i;
      }), _this71.preserveShort && a === s[_n100]) {
        var _s32 = t[_n100 + 1] - t[_n100];

        if (0 === _s32) return "continue";

        _this71.createNGrams(e, r, o, a, 1, _s32 + 2 * _this71.padWidth);
      }
    };

    for (var _n100 = 0; _n100 < a; ++_n100) {
      var _ret = _loop25(_n100);

      if (_ret === "continue") continue;
    }

    return [o, s];
  }

}

function stringNGramsImpl$1(e, t, n, r, a, s, o, i) {
  return new StringNGramsOp$1(n, r, a, s, o, i).compute(e, t);
}

function split$3(e, t, n) {
  if (!e.length) return [];

  if (0 === t.length) {
    var _t201 = new Array(e.length);

    for (var _n101 = 0; _n101 < e.length; ++_n101) {
      _t201[_n101] = e.subarray(_n101, _n101 + 1);
    }

    return _t201;
  }

  if (1 === t.length) {
    var _r76 = t[0],
        _a50 = [];
    var s = e.indexOf(_r76);

    for (; -1 !== s;) {
      var _t202 = e.subarray(0, s);

      n && 0 === _t202.length || _a50.push(_t202), s = (e = e.subarray(s + 1)).indexOf(_r76);
    }

    return n && 0 === e.length || _a50.push(e), _a50;
  }

  var r = [];
  var a = 0;

  for (var _s33 = 0; _s33 < e.length + 1; _s33++) {
    if (_s33 === e.length || -1 !== t.indexOf(e[_s33])) {
      var _t203 = e.subarray(a, _s33);

      n && 0 === _t203.length || r.push(_t203), a = _s33 + 1;
    }
  }

  return r;
}

function stringSplitImpl$1(e, t, n) {
  var r = e.length,
      a = [];
  var s = 0,
      o = 0;
  var i = new Array(r);

  for (var _l7 = 0; _l7 < r; ++_l7) {
    var _r77 = split$3(e[_l7], t, n),
        _u5 = _r77.length;

    i[_l7] = _u5, s += _u5, o = Math.max(o, _u5), a.push(..._r77);
  }

  var l = getArrayFromDType$1("int32", 2 * s),
      u = new Array(s),
      c = [r, o];
  var p = 0;

  for (var _e272 = 0; _e272 < r; ++_e272) {
    for (var _t204 = 0; _t204 < i[_e272]; ++_t204) {
      l[2 * p] = _e272, l[2 * p + 1] = _t204, u[p] = a[p], ++p;
    }
  }

  return [l, u, c];
}

function stringToHashBucketFastImpl$1(e, t) {
  var n = getArrayFromDType$1("int32", e.length);

  for (var r = 0; r < e.length; ++r) {
    n[r] = fingerPrint64$1(e[r]).modulo(t).getLowBitsUnsigned();
  }

  return n;
}

var subImpl$1 = createSimpleBinaryKernelImpl$1((e, t) => e - t),
    subComplexImpl$1 = createComplexBinaryKernelImpl$1((e, t, n, r) => ({
  real: e - n,
  imag: t - r
})),
    sub$4 = binaryKernelFunc$3(Sub$1, subImpl$1, subComplexImpl$1),
    subConfig$3 = {
  kernelName: Sub$1,
  backendName: "cpu",
  kernelFunc: sub$4
};

function tileImpl$1(e, t) {
  var n = new Array(e.rank);

  for (var _r78 = 0; _r78 < n.length; _r78++) {
    n[_r78] = e.shape[_r78] * t[_r78];
  }

  var r = buffer$1(n, e.dtype);

  for (var _t205 = 0; _t205 < r.values.length; ++_t205) {
    var _n102 = r.indexToLoc(_t205),
        a = new Array(e.rank);

    for (var _t206 = 0; _t206 < a.length; _t206++) {
      a[_t206] = _n102[_t206] % e.shape[_t206];
    }

    var s = e.locToIndex(a);
    r.values[_t205] = e.values[s];
  }

  return r;
}

var comparePair$1 = (e, t) => {
  var n = t.value - e.value;
  return 0 === n ? e.index - t.index : n;
};

function select$5(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : e.length - 1;

  for (; r > n;) {
    if (r - n > 600) {
      var _a51 = r - n + 1,
          _s34 = t - n + 1,
          _o12 = Math.log(_a51),
          i = .5 * Math.exp(2 * _o12 / 3),
          l = .5 * Math.sqrt(_o12 * i * (_a51 - i) / _a51) * Math.sign(_s34 - _a51 / 2);

      select$5(e, t, Math.max(n, Math.floor(t - _s34 * i / _a51 + l)), Math.min(r, Math.floor(t + (_a51 - _s34) * i / _a51 + l)));
    }

    var a = e[t];
    var s = n,
        o = r;

    for (swap$1(e, n, t), comparePair$1(e[r], a) > 0 && swap$1(e, n, r); s < o;) {
      for (swap$1(e, s, o), s++, o--; comparePair$1(e[s], a) < 0;) {
        s += 1;
      }

      for (; comparePair$1(e[o], a) > 0;) {
        o -= 1;
      }
    }

    0 === comparePair$1(e[n], a) ? swap$1(e, n, o) : (o += 1, swap$1(e, o, r)), o <= t && (n = o + 1), t <= o && (r = o - 1);
  }
}

function topKImpl$1(e, t, n, r, a) {
  var s = t[t.length - 1],
      [o, i] = [e.length / s, s],
      l = getTypedArrayFromDType$1(n, o * r),
      u = getTypedArrayFromDType$1("int32", o * r);

  var _loop26 = function _loop26(_t207) {
    var n = _t207 * i,
        s = e.subarray(n, n + i);
    var o = new Array(s.length);
    s.forEach((e, t) => o[t] = {
      value: e,
      index: t
    }), r < o.length && (select$5(o, r), o = o.slice(0, r)), a && o.sort(comparePair$1);
    var c = _t207 * r,
        p = l.subarray(c, c + r),
        d = u.subarray(c, c + r);

    for (var _e273 = 0; _e273 < r; _e273++) {
      p[_e273] = o[_e273].value, d[_e273] = o[_e273].index;
    }
  };

  for (var _t207 = 0; _t207 < o; _t207++) {
    _loop26(_t207);
  }

  var c = t.slice();
  return c[c.length - 1] = r, [buffer$1(c, n, l), buffer$1(c, "int32", u)];
}

function uniqueImpl$1(e, t, n, r) {
  var a = parseAxisParam$1(t, n)[0],
      s = [1, n[0], 1];

  for (var _e274 = 0; _e274 < a; _e274++) {
    s[0] *= n[_e274];
  }

  s[1] = n[a];

  for (var _e275 = a + 1; _e275 < n.length; _e275++) {
    s[2] *= n[_e275];
  }

  var o = {},
      i = new Int32Array(n[a]),
      l = new TensorBuffer$1(s, r, e),
      u = [],
      c = 1 === s[0] && 1 === s[2];

  for (var _t208 = 0; _t208 < n[a]; _t208++) {
    var _n103 = void 0;

    if (c) _n103 = e[_t208].toString();else {
      var _e276 = [];

      for (var _n104 = 0; _n104 < s[0]; _n104++) {
        for (var _r79 = 0; _r79 < s[2]; _r79++) {
          _e276.push(l.get(_n104, _t208, _r79));
        }
      }

      _n103 = _e276.join(",");
    }
    if (void 0 !== o[_n103]) i[_t208] = o[_n103];else {
      var _e277 = Object.keys(o).length;
      o[_n103] = _e277, i[_t208] = _e277, u.push(_t208);
    }
  }

  var p = s.slice();
  p[1] = Object.keys(o).length;
  var d = new TensorBuffer$1(p, r);
  u.forEach((e, t) => {
    for (var _n105 = 0; _n105 < s[0]; _n105++) {
      for (var _r80 = 0; _r80 < s[2]; _r80++) {
        d.set(l.get(_n105, e, _r80), _n105, t, _r80);
      }
    }
  });
  var h = n.slice();
  return h[a] = p[1], {
    outputValues: d.values,
    outputShape: h,
    indices: i
  };
}

var shared$1 = {
  __proto__: null,
  simpleAbsImpl: simpleAbsImpl$1,
  addImpl: addImpl$1,
  bincountImpl: bincountImpl$1,
  bincountReduceImpl: bincountReduceImpl$1,
  ceilImpl: ceilImpl$1,
  concatImpl: concatImpl$3,
  equalImpl: equalImpl$1,
  expImpl: expImpl$1,
  expm1Impl: expm1Impl$1,
  floorImpl: floorImpl$1,
  gatherNdImpl: gatherNdImpl$1,
  gatherV2Impl: gatherV2Impl$1,
  greaterImpl: greaterImpl$1,
  greaterEqualImpl: greaterEqualImpl$1,
  lessImpl: lessImpl$1,
  lessEqualImpl: lessEqualImpl$1,
  linSpaceImpl: linSpaceImpl$1,
  logImpl: logImpl$1,
  maxImpl: maxImpl$3,
  maximumImpl: maximumImpl$1,
  minimumImpl: minimumImpl$1,
  multiplyImpl: multiplyImpl$1,
  negImpl: negImpl$1,
  notEqualImpl: notEqualImpl$1,
  prodImpl: prodImpl$1,
  rangeImpl: rangeImpl$1,
  rsqrtImpl: rsqrtImpl$1,
  sliceImpl: sliceImpl$1,
  sparseFillEmptyRowsImpl: sparseFillEmptyRowsImpl$1,
  sparseReshapeImpl: sparseReshapeImpl$1,
  sparseSegmentReductionImpl: sparseSegmentReductionImpl$1,
  squaredDifferenceImpl: squaredDifferenceImpl$1,
  stridedSliceImpl: stridedSliceImpl$1,
  stringNGramsImpl: stringNGramsImpl$1,
  stringSplitImpl: stringSplitImpl$1,
  stringToHashBucketFastImpl: stringToHashBucketFastImpl$1,
  subImpl: subImpl$1,
  tileImpl: tileImpl$1,
  topKImpl: topKImpl$1,
  transposeImpl: transposeImpl$3,
  uniqueImpl: uniqueImpl$1
};
var version$a = "3.8.0";
registerBackend$1("cpu", () => new MathBackendCPU$1(), 1);
var elu$6 = unaryKernelFunc$3(Elu$3, e => e >= 0 ? e : Math.exp(e) - 1),
    eluConfig$3 = {
  kernelName: Elu$3,
  backendName: "cpu",
  kernelFunc: elu$6
};

function leakyRelu$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    alpha: s
  } = r;
  assertNotComplex$3([a], "leakyRelu");
  var o = sizeFromShape$1(a.shape),
      i = n.data.get(a.dataId).values,
      l = getTypedArrayFromDType$1("float32", o);

  for (var _e278 = 0; _e278 < i.length; _e278++) {
    l[_e278] = i[_e278] < 0 ? s * i[_e278] : i[_e278];
  }

  return n.makeTensorInfo(a.shape, "float32", l);
}

var leakyReluConfig$3 = {
  kernelName: LeakyRelu$1,
  backendName: "cpu",
  kernelFunc: leakyRelu$4
},
    preluImpl$1 = createSimpleBinaryKernelImpl$1((e, t) => e < 0 ? t * e : e);

function prelu$5(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    x: r,
    alpha: a
  } = t;
  assertNotComplex$3([r, a], "prelu");
  var s = n.data.get(r.dataId).values,
      o = n.data.get(a.dataId).values,
      [i, l] = preluImpl$1(r.shape, a.shape, s, o, r.dtype);
  return n.makeTensorInfo(l, r.dtype, i);
}

var preluConfig$3 = {
  kernelName: Prelu$1,
  backendName: "cpu",
  kernelFunc: prelu$5
},
    relu$5 = unaryKernelFunc$3(Relu$3, e => Math.max(0, e)),
    reluConfig$3 = {
  kernelName: Relu$3,
  backendName: "cpu",
  kernelFunc: relu$5
},
    relu6$4 = unaryKernelFunc$3(Relu6$3, e => Math.min(Math.max(0, e), 6)),
    relu6Config$3 = {
  kernelName: Relu6$3,
  backendName: "cpu",
  kernelFunc: relu6$4
},
    sigmoid$4 = unaryKernelFunc$3(Sigmoid$3, e => 1 / (1 + Math.exp(-e))),
    sigmoidConfig$3 = {
  kernelName: Sigmoid$3,
  backendName: "cpu",
  kernelFunc: sigmoid$4
};

function applyActivation$2(e, t, n, r, a) {
  if ("linear" === n) return identity$4({
    inputs: {
      x: t
    },
    backend: e
  });
  if ("relu" === n) return relu$5({
    inputs: {
      x: t
    },
    backend: e
  });
  if ("elu" === n) return elu$6({
    inputs: {
      x: t
    },
    backend: e
  });
  if ("relu6" === n) return relu6$4({
    inputs: {
      x: t
    },
    backend: e
  });
  if ("prelu" === n) return prelu$5({
    inputs: {
      x: t,
      alpha: r
    },
    backend: e
  });
  if ("leakyrelu" === n) return leakyRelu$4({
    inputs: {
      x: t
    },
    backend: e,
    attrs: {
      alpha: a
    }
  });
  if ("sigmoid" === n) return sigmoid$4({
    inputs: {
      x: t
    },
    backend: e
  });
  throw new Error("Activation ".concat(n, " has not been implemented for the CPU backend."));
}

function reshape$5(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    shape: s
  } = r,
      o = sizeFromShape$1(a.shape),
      i = inferFromImplicitShape$1(s, o),
      l = sizeFromShape$1(i);
  assert$6(o === l, () => "The new shape (".concat(i, ") has ").concat(l, " elements and the old shape (").concat(a.shape, ") has ").concat(o, " elements. The new shape and old shape must have the same number of elements.")), n.incRef(a.dataId);
  var u = n.data.get(a.dataId);

  if (null != u.complexTensorInfos) {
    var _e279 = u.complexTensorInfos.imag;
    u.complexTensorInfos.real.shape = i, _e279.shape = i;
  }

  return {
    dataId: a.dataId,
    shape: i,
    dtype: a.dtype
  };
}

var reshapeConfig$3 = {
  kernelName: Reshape$3,
  backendName: "cpu",
  kernelFunc: reshape$5
};

function batchMatMul$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    a,
    b: s
  } = t,
      {
    transposeA: o,
    transposeB: i
  } = r;
  assertNotComplex$3([a, s], "matMul");
  var l = a.shape.length,
      u = s.shape.length,
      c = o ? a.shape[l - 2] : a.shape[l - 1],
      p = i ? s.shape[u - 1] : s.shape[u - 2],
      d = o ? a.shape[l - 1] : a.shape[l - 2],
      h = i ? s.shape[u - 2] : s.shape[u - 1],
      m = a.shape.slice(0, -2),
      f = s.shape.slice(0, -2),
      g = sizeFromShape$1(m),
      $ = sizeFromShape$1(f);
  assert$6(l >= 2 && u >= 2 && (g === $ || 1 === g || 1 === $), () => "Error in matMul: the input batch dimensions must either be the same or at least one input batch dimension must be 1. Got input batch dimensions of (".concat(m, ") and (").concat(f, ")."));
  var y = (g > $ ? a.shape.slice(0, -2) : s.shape.slice(0, -2)).concat([d, h]);
  assert$6(c === p, () => "Error in matMul: inner shapes (".concat(c, ") and (").concat(p, ") of Tensors with shapes ").concat(a.shape, " and ").concat(s.shape, " and transposeA=").concat(o, " and transposeB=").concat(i, " must match."));
  var b = i ? [$, h, p] : [$, p, h],
      x = reshape$5({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      shape: o ? [g, c, d] : [g, d, c]
    }
  }),
      v = reshape$5({
    inputs: {
      x: s
    },
    backend: n,
    attrs: {
      shape: b
    }
  }),
      I = o ? x.shape[1] : x.shape[2],
      C = o ? x.shape[2] : x.shape[1],
      S = i ? v.shape[1] : v.shape[2],
      k = Math.max(g, $),
      T = n.data.get(x.dataId).values,
      N = n.data.get(v.dataId).values,
      w = computeStrides$1(x.shape),
      E = computeStrides$1(v.shape),
      [A, D, R] = o ? [w[0], 1, w[1]] : [w[0], w[1], 1],
      [_, F, P] = i ? [1, E[1], E[0]] : [E[1], 1, E[0]],
      O = C * S,
      M = buffer$1([k, C, S], x.dtype),
      L = M.values,
      z = n.blockSize;

  for (var _e280 = 0; _e280 < k; _e280++) {
    for (var _t209 = 0; _t209 < C; _t209 += z) {
      for (var _n106 = 0; _n106 < S; _n106 += z) {
        for (var _r81 = 0; _r81 < I; _r81 += z) {
          var _a52 = Math.min(_t209 + z, C),
              _s35 = Math.min(_n106 + z, S),
              _o13 = Math.min(_r81 + z, I);

          for (var _i7 = _t209; _i7 < _a52; _i7++) {
            for (var _t210 = _n106; _t210 < _s35; _t210++) {
              var _n107 = 0;

              for (var _a53 = _r81; _a53 < _o13; _a53++) {
                var _r82 = Math.min(_e280, g - 1) * A,
                    _s36 = Math.min(_e280, $ - 1) * P;

                _n107 += T[_r82 + _i7 * D + _a53 * R] * N[_a53 * _ + _t210 * F + _s36];
              }

              L[_e280 * O + (_i7 * S + _t210)] += _n107;
            }
          }
        }
      }
    }
  }

  return n.disposeIntermediateTensorInfo(x), n.disposeIntermediateTensorInfo(v), n.makeTensorInfo(y, M.dtype, M.values);
}

var batchMatMulConfig$3 = {
  kernelName: BatchMatMul$1,
  backendName: "cpu",
  kernelFunc: batchMatMul$3
};

function _fusedMatMul$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    a,
    b: s,
    bias: o,
    preluActivationWeights: i
  } = t,
      {
    transposeA: l,
    transposeB: u,
    activation: c,
    leakyreluAlpha: p
  } = r;
  var d, h, m;
  var f = [];
  d = batchMatMul$3({
    inputs: {
      a,
      b: s
    },
    attrs: {
      transposeA: l,
      transposeB: u
    },
    backend: n
  }), o && (h = add$4({
    inputs: {
      a: d,
      b: o
    },
    backend: n
  }), f.push(d), d = h), c && (m = applyActivation$2(n, d, c, i, p), f.push(d), d = m);

  for (var _e281 of f) {
    n.disposeIntermediateTensorInfo(_e281);
  }

  return d;
}

var _fusedMatMulConfig$3 = {
  kernelName: _FusedMatMul$1,
  backendName: "cpu",
  kernelFunc: _fusedMatMul$3
},
    acos$4 = unaryKernelFunc$3(Acos$1, e => Math.acos(e)),
    acosConfig$3 = {
  kernelName: Acos$1,
  backendName: "cpu",
  kernelFunc: acos$4
},
    acosh$4 = unaryKernelFunc$3(Acosh$1, e => Math.acosh(e)),
    acoshConfig$3 = {
  kernelName: Acosh$1,
  backendName: "cpu",
  kernelFunc: acosh$4
};

function addN$4(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      r = t;
  assertNotComplex$3(t, "addN");
  var a = r.map(e => n.data.get(e.dataId).values),
      s = buffer$1(r[0].shape, r[0].dtype),
      o = s.values;

  for (var _e282 = 0; _e282 < r.length; _e282++) {
    var _t211 = a[_e282];

    for (var _e283 = 0; _e283 < o.length; _e283++) {
      o[_e283] += _t211[_e283];
    }
  }

  return n.makeTensorInfo(s.shape, s.dtype, s.values);
}

var addNConfig$3 = {
  kernelName: AddN$1,
  backendName: "cpu",
  kernelFunc: addN$4
};

function all$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    axis: s,
    keepDims: o
  } = r;
  assertNotComplex$3(a, "all");
  var i = parseAxisParam$1(s, a.shape);
  var l = i;
  var u = getAxesPermutation$1(l, a.shape.length);
  var c = a;
  null != u && (c = transpose$4({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      perm: u
    }
  }), l = getInnerMostAxes$1(l.length, a.shape.length)), assertAxesAreInnerMostDims$1("all", l, c.shape.length);
  var [p, d] = computeOutAndReduceShapes$1(c.shape, l),
      h = sizeFromShape$1(d),
      m = makeZerosTypedArray$1(sizeFromShape$1(p), c.dtype),
      f = n.data.get(c.dataId).values;

  for (var _e284 = 0; _e284 < m.length; ++_e284) {
    var _t212 = _e284 * h;

    var _n108 = f[_t212];

    for (var _e285 = 0; _e285 < h; ++_e285) {
      var _r83 = f[_t212 + _e285];
      _n108 = _n108 && _r83;
    }

    m[_e284] = _n108;
  }

  null != u && n.disposeIntermediateTensorInfo(c);
  var g = n.makeTensorInfo(p, c.dtype, m);

  if (o) {
    var _e286 = reshape$5({
      inputs: {
        x: g
      },
      backend: n,
      attrs: {
        shape: expandShapeToKeepDim$1(p, i)
      }
    });

    return n.disposeIntermediateTensorInfo(g), _e286;
  }

  return g;
}

var allConfig$3 = {
  kernelName: All$1,
  backendName: "cpu",
  kernelFunc: all$4
};

function any$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    axis: s,
    keepDims: o
  } = r;
  assertNotComplex$3(a, "any");
  var i = parseAxisParam$1(s, a.shape);
  var l = i;
  var u = getAxesPermutation$1(l, a.shape.length);
  var c = a;
  null != u && (c = transpose$4({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      perm: u
    }
  }), l = getInnerMostAxes$1(l.length, a.shape.length)), assertAxesAreInnerMostDims$1("any", l, c.shape.length);
  var [p, d] = computeOutAndReduceShapes$1(c.shape, l),
      h = sizeFromShape$1(d),
      m = makeZerosTypedArray$1(sizeFromShape$1(p), c.dtype),
      f = n.data.get(c.dataId).values;

  for (var _e287 = 0; _e287 < m.length; ++_e287) {
    var _t213 = _e287 * h;

    var _n109 = f[_t213];

    for (var _e288 = 0; _e288 < h; ++_e288) {
      var _r84 = f[_t213 + _e288];
      _n109 = _n109 || _r84;
    }

    m[_e287] = _n109;
  }

  null != u && n.disposeIntermediateTensorInfo(c);
  var g = n.makeTensorInfo(p, c.dtype, m);

  if (o) {
    var _e289 = reshape$5({
      inputs: {
        x: g
      },
      backend: n,
      attrs: {
        shape: expandShapeToKeepDim$1(p, i)
      }
    });

    return n.disposeIntermediateTensorInfo(g), _e289;
  }

  return g;
}

var anyConfig$3 = {
  kernelName: Any$1,
  backendName: "cpu",
  kernelFunc: any$4
};

function argMax$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    axis: s
  } = r;
  assertNotComplex$3(a, "argMax");
  var o = parseAxisParam$1(s, a.shape);
  var i = getAxesPermutation$1(o, a.shape.length);
  var l = a;
  var u = [];
  null != i && (l = transpose$4({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      perm: i
    }
  }), u.push(l), o = getInnerMostAxes$1(o.length, l.shape.length)), o = [o[0]], assertAxesAreInnerMostDims$1("argMax", o, l.shape.length);
  var [c, p] = computeOutAndReduceShapes$1(l.shape, o),
      d = makeZerosTypedArray$1(sizeFromShape$1(c), "int32"),
      h = sizeFromShape$1(p),
      m = n.data.get(l.dataId).values;

  for (var _e290 = 0; _e290 < d.length; ++_e290) {
    var _t214 = _e290 * h;

    var _n110 = m[_t214],
        _r85 = 0;

    for (var _e291 = 0; _e291 < h; ++_e291) {
      var _a54 = m[_t214 + _e291];
      _a54 > _n110 && (_n110 = _a54, _r85 = _e291);
    }

    d[_e290] = _r85;
  }

  return u.forEach(e => n.disposeIntermediateTensorInfo(e)), n.makeTensorInfo(c, "int32", d);
}

var argMaxConfig$3 = {
  kernelName: ArgMax$1,
  backendName: "cpu",
  kernelFunc: argMax$4
};

function argMin$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    axis: s
  } = r;
  assertNotComplex$3(a, "argMin");
  var o = parseAxisParam$1(s, a.shape);
  var i = getAxesPermutation$1(o, a.shape.length);
  var l = a;
  var u = [];
  null != i && (l = transpose$4({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      perm: i
    }
  }), u.push(l), o = getInnerMostAxes$1(o.length, l.shape.length)), o = [o[0]], assertAxesAreInnerMostDims$1("argMin", o, l.shape.length);
  var [c, p] = computeOutAndReduceShapes$1(l.shape, o),
      d = makeZerosTypedArray$1(sizeFromShape$1(c), "int32"),
      h = sizeFromShape$1(p),
      m = n.data.get(l.dataId).values;

  for (var _e292 = 0; _e292 < d.length; ++_e292) {
    var _t215 = _e292 * h;

    var _n111 = m[_t215],
        _r86 = 0;

    for (var _e293 = 0; _e293 < h; ++_e293) {
      var _a55 = m[_t215 + _e293];
      _a55 < _n111 && (_n111 = _a55, _r86 = _e293);
    }

    d[_e292] = _r86;
  }

  return u.forEach(e => n.disposeIntermediateTensorInfo(e)), n.makeTensorInfo(c, "int32", d);
}

var argMinConfig$3 = {
  kernelName: ArgMin$1,
  backendName: "cpu",
  kernelFunc: argMin$4
},
    asin$4 = unaryKernelFunc$3(Asin$1, e => Math.asin(e)),
    asinConfig$3 = {
  kernelName: Asin$1,
  backendName: "cpu",
  kernelFunc: asin$4
},
    asinh$4 = unaryKernelFunc$3(Asinh$1, e => Math.asinh(e)),
    asinhConfig$3 = {
  kernelName: Asinh$1,
  backendName: "cpu",
  kernelFunc: asinh$4
},
    atan$4 = unaryKernelFunc$3(Atan$1, e => Math.atan(e)),
    atanConfig$3 = {
  kernelName: Atan$1,
  backendName: "cpu",
  kernelFunc: atan$4
},
    atan2Impl$1 = createSimpleBinaryKernelImpl$1((e, t) => Math.atan2(e, t)),
    atan2$4 = binaryKernelFunc$3(Atan2$1, atan2Impl$1),
    atan2Config$3 = {
  kernelName: Atan2$1,
  backendName: "cpu",
  kernelFunc: atan2$4
},
    atanh$4 = unaryKernelFunc$3(Atanh$1, e => Math.atanh(e)),
    atanhConfig$3 = {
  kernelName: Atanh$1,
  backendName: "cpu",
  kernelFunc: atanh$4
};

function pool$2(e, t, n, r, a, s) {
  var o = a.strideHeight,
      i = a.strideWidth,
      l = a.dilationHeight,
      u = a.dilationWidth,
      c = a.effectiveFilterHeight,
      p = a.effectiveFilterWidth,
      d = a.padInfo.top,
      h = a.padInfo.left,
      m = "max" === s ? Number.NEGATIVE_INFINITY : Number.POSITIVE_INFINITY,
      f = buffer$1(a.outShape, n),
      g = f.values,
      $ = a.outShape[1] * a.outShape[2] * a.outShape[3],
      y = a.outShape[2] * a.outShape[3],
      b = a.outShape[3];

  for (var _t216 = 0; _t216 < a.batchSize; ++_t216) {
    var _n112 = _t216 * $,
        _f = _t216 * r[0];

    for (var _t217 = 0; _t217 < a.inChannels; ++_t217) {
      for (var _$ = 0; _$ < a.outHeight; ++_$) {
        var x = _$ * o - d,
            v = Math.max(0, x),
            I = Math.min(a.inHeight, c + x),
            C = _n112 + _$ * y;

        for (var _n113 = 0; _n113 < a.outWidth; ++_n113) {
          var _o14 = _n113 * i - h,
              _c4 = Math.max(0, _o14),
              _d3 = Math.min(a.inWidth, p + _o14);

          var _$2 = m,
              _y = 0,
              _x50 = 0;

          for (var _n114 = v; _n114 < I; _n114 += l) {
            var _a56 = _f + _n114 * r[1];

            for (var _n115 = _c4; _n115 < _d3; _n115 += u) {
              var _o15 = e[_a56 + _n115 * r[2] + _t217];
              "max" === s && _o15 > _$2 ? _$2 = _o15 : "avg" === s && (_y += _o15, _x50++);
            }

            if (isNaN(_$2)) break;
          }

          g[C + _n113 * b + _t217] = "avg" === s ? _y / _x50 : _$2;
        }
      }
    }
  }

  return f;
}

function maxPoolPositions$1(e, t, n, r) {
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : !1;
  var o = buffer$1(r.outShape, "int32"),
      i = r.strideHeight,
      l = r.strideWidth,
      u = r.dilationHeight,
      c = r.dilationWidth,
      p = r.effectiveFilterHeight,
      d = r.effectiveFilterWidth,
      h = r.padInfo.top,
      m = r.padInfo.left,
      f = buffer$1(t, n, e);

  for (var _e294 = 0; _e294 < r.batchSize; ++_e294) {
    for (var _t218 = 0; _t218 < r.inChannels; ++_t218) {
      for (var _n116 = 0; _n116 < r.outHeight; ++_n116) {
        var g = _n116 * i - h;
        var $ = g;

        for (; $ < 0;) {
          $ += u;
        }

        var y = Math.min(r.inHeight, p + g);

        for (var _i8 = 0; _i8 < r.outWidth; ++_i8) {
          var _p7 = _i8 * l - m;

          var _h3 = _p7;

          for (; _h3 < 0;) {
            _h3 += c;
          }

          var b = Math.min(r.inWidth, d + _p7);
          var x = Number.NEGATIVE_INFINITY,
              v = -1;

          for (var _n117 = $; _n117 < y; _n117 += u) {
            var _o16 = _n117 - g;

            for (var _i9 = _h3; _i9 < b; _i9 += c) {
              var _l8 = _i9 - _p7,
                  _u6 = f.get(_e294, _n117, _i9, _t218);

              _u6 > x && (x = _u6, v = a ? s ? ((_e294 * r.inHeight + _n117) * r.inWidth + _i9) * r.inChannels + _t218 : (_n117 * r.inWidth + _i9) * r.inChannels + _t218 : _o16 * d + _l8);
            }
          }

          o.set(v, _e294, _n116, _i8, _t218);
        }
      }
    }
  }

  return o;
}

function pool3d$2(e, t, n, r, a, s) {
  var o = a.strideDepth,
      i = a.strideHeight,
      l = a.strideWidth,
      u = a.dilationDepth,
      c = a.dilationHeight,
      p = a.dilationWidth,
      d = a.effectiveFilterDepth,
      h = a.effectiveFilterHeight,
      m = a.effectiveFilterWidth,
      f = a.padInfo.front,
      g = a.padInfo.top,
      $ = a.padInfo.left,
      y = "max" === s ? Number.NEGATIVE_INFINITY : Number.POSITIVE_INFINITY,
      b = buffer$1(a.outShape, n),
      x = b.values,
      v = a.outShape[1] * a.outShape[2] * a.outShape[3] * a.outShape[4],
      I = a.outShape[2] * a.outShape[3] * a.outShape[4],
      C = a.outShape[3] * a.outShape[4],
      S = a.outShape[4];

  for (var _t219 = 0; _t219 < a.batchSize; ++_t219) {
    var _n118 = _t219 * v,
        _b = _t219 * r[0];

    for (var _t220 = 0; _t220 < a.inChannels; ++_t220) {
      for (var _v = 0; _v < a.outDepth; ++_v) {
        var k = _v * o - f;
        var T = k;

        for (; T < 0;) {
          T += u;
        }

        var N = Math.min(a.inDepth, d + k),
            w = _n118 + _v * I;

        for (var _n119 = 0; _n119 < a.outHeight; ++_n119) {
          var _o17 = _n119 * i - g;

          var _d4 = _o17;

          for (; _d4 < 0;) {
            _d4 += c;
          }

          var _f2 = Math.min(a.inHeight, h + _o17),
              _v2 = w + _n119 * C;

          for (var _n120 = 0; _n120 < a.outWidth; ++_n120) {
            var _o18 = _n120 * l - $;

            var _i10 = _o18;

            for (; _i10 < 0;) {
              _i10 += p;
            }

            var _h4 = Math.min(a.inWidth, m + _o18),
                _g = _v2 + _n120 * S;

            var _I = y,
                _C = 0,
                _k = 0;

            for (var _n121 = T; _n121 < N; _n121 += u) {
              var _a57 = _b + _n121 * r[1];

              for (var _n122 = _d4; _n122 < _f2; _n122 += c) {
                var _o19 = _a57 + _n122 * r[2];

                for (var _n123 = _i10; _n123 < _h4; _n123 += p) {
                  var _a58 = e[_o19 + _n123 * r[3] + _t220];
                  if ("max" === s && _a58 > _I ? _I = _a58 : "avg" === s && (_C += _a58, _k++), isNaN(_I)) break;
                }

                if (isNaN(_I)) break;
              }

              if (isNaN(_I)) break;
            }

            x[_g + _t220] = "avg" === s ? _C / _k : _I;
          }
        }
      }
    }
  }

  return b;
}

function maxPool3dPositions$1(e, t) {
  var n = buffer$1(t.outShape, "int32"),
      r = t.strideDepth,
      a = t.strideHeight,
      s = t.strideWidth,
      o = t.dilationDepth,
      i = t.dilationHeight,
      l = t.dilationWidth,
      u = t.effectiveFilterDepth,
      c = t.effectiveFilterHeight,
      p = t.effectiveFilterWidth,
      d = t.padInfo.front,
      h = t.padInfo.top,
      m = t.padInfo.left;

  for (var f = 0; f < t.batchSize; ++f) {
    for (var g = 0; g < t.inChannels; ++g) {
      for (var $ = 0; $ < t.outDepth; ++$) {
        var y = $ * r - d;
        var b = y;

        for (; b < 0;) {
          b += o;
        }

        var x = Math.min(t.inDepth, u + y);

        for (var _r87 = 0; _r87 < t.outHeight; ++_r87) {
          var _u7 = _r87 * a - h;

          var _d5 = _u7;

          for (; _d5 < 0;) {
            _d5 += i;
          }

          var v = Math.min(t.inHeight, c + _u7);

          for (var _a59 = 0; _a59 < t.outWidth; ++_a59) {
            var _h5 = _a59 * s - m;

            var I = _h5;

            for (; I < 0;) {
              I += l;
            }

            var C = Math.min(t.inWidth, p + _h5);
            var S = Number.NEGATIVE_INFINITY,
                k = -1;

            for (var _t221 = b; _t221 < x; _t221 += o) {
              var _n124 = _t221 - y;

              for (var _r88 = _d5; _r88 < v; _r88 += i) {
                var _a60 = _r88 - _u7;

                for (var _s37 = I; _s37 < C; _s37 += l) {
                  var _o20 = _s37 - _h5,
                      _i11 = e.get(f, _t221, _r88, _s37, g);

                  _i11 >= S && (S = _i11, k = _n124 * c * p + _a60 * c + _o20);
                }
              }
            }

            n.set(k, f, $, _r87, _a59, g);
          }
        }
      }
    }
  }

  return n;
}

function avgPool$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t;
  assertNotComplex$3(a, "avgPool");
  var {
    filterSize: s,
    strides: o,
    pad: i,
    dimRoundingMode: l
  } = r;
  assert$6(eitherStridesOrDilationsAreOne$1(o, 1), () => "Error in avgPool: Either strides or dilations must be 1. Got strides ".concat(o, " and dilations '1'"));
  var u = computePool2DInfo$1(a.shape, s, o, 1, i, l);
  var c;
  if (1 === u.filterWidth && 1 === u.filterHeight && arraysEqual$1(u.inShape, u.outShape)) c = identity$4({
    inputs: {
      x: a
    },
    backend: n
  });else {
    var _e295 = n.data.get(a.dataId).values,
        _t222 = computeStrides$1(a.shape),
        _r89 = pool$2(_e295, a.shape, a.dtype, _t222, u, "avg");

    c = n.makeTensorInfo(u.outShape, a.dtype, _r89.values);
  }
  return c;
}

var avgPoolConfig$3 = {
  kernelName: AvgPool$1,
  backendName: "cpu",
  kernelFunc: avgPool$4
};

function avgPool3D$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    filterSize: s,
    strides: o,
    pad: i,
    dimRoundingMode: l,
    dataFormat: u
  } = r;
  assertNotComplex$3(a, "avgPool3d");
  var c = computePool3DInfo$1(a.shape, s, o, 1, i, l, u),
      p = pool3d$2(n.data.get(a.dataId).values, a.shape, a.dtype, computeStrides$1(a.shape), c, "avg");
  return n.makeTensorInfo(p.shape, "float32", p.values);
}

var avgPool3DConfig$3 = {
  kernelName: AvgPool3D$1,
  backendName: "cpu",
  kernelFunc: avgPool3D$3
};

function avgPool3DGrad$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    dy: a,
    input: s
  } = t,
      {
    filterSize: o,
    strides: i,
    pad: l,
    dimRoundingMode: u
  } = r;
  assertNotComplex$3([a, s], "avgPool3DGrad");
  var c = computePool3DInfo$1(s.shape, o, i, 1, l, u),
      p = c.strideDepth,
      d = c.strideHeight,
      h = c.strideWidth,
      m = c.filterDepth,
      f = c.filterHeight,
      g = c.filterWidth,
      $ = c.dilationDepth,
      y = c.dilationHeight,
      b = c.dilationWidth,
      x = c.effectiveFilterDepth,
      v = c.effectiveFilterHeight,
      I = c.effectiveFilterWidth,
      C = x - 1 - c.padInfo.front,
      S = I - 1 - c.padInfo.left,
      k = v - 1 - c.padInfo.top,
      T = buffer$1(s.shape, "float32"),
      N = 1 / (m * f * g),
      w = n.bufferSync(a);

  for (var _e296 = 0; _e296 < c.batchSize; ++_e296) {
    for (var _t223 = 0; _t223 < c.inChannels; ++_t223) {
      for (var _n125 = 0; _n125 < c.inDepth; ++_n125) {
        for (var _r90 = 0; _r90 < c.inHeight; ++_r90) {
          for (var _a61 = 0; _a61 < c.inWidth; ++_a61) {
            var _s38 = _n125 - C,
                _o21 = _r90 - k,
                _i12 = _a61 - S;

            var _l9 = 0;

            for (var _n126 = 0; _n126 < x; _n126 += $) {
              var _r91 = (_s38 + _n126) / p;

              if (!(_r91 < 0 || _r91 >= c.outDepth || Math.floor(_r91) !== _r91)) for (var _n127 = 0; _n127 < v; _n127 += y) {
                var _a62 = (_o21 + _n127) / d;

                if (!(_a62 < 0 || _a62 >= c.outHeight || Math.floor(_a62) !== _a62)) for (var _n128 = 0; _n128 < I; _n128 += b) {
                  var _s39 = (_i12 + _n128) / h;

                  _s39 < 0 || _s39 >= c.outWidth || Math.floor(_s39) !== _s39 || (_l9 += w.get(_e296, _r91, _a62, _s39, _t223));
                }
              }
            }

            T.set(_l9 * N, _e296, _n125, _r90, _a61, _t223);
          }
        }
      }
    }
  }

  return n.makeTensorInfo(T.shape, T.dtype, T.values);
}

var avgPool3DGradConfig$2 = {
  kernelName: AvgPool3DGrad$1,
  backendName: "cpu",
  kernelFunc: avgPool3DGrad$3
};

function avgPoolGrad$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    dy: a,
    input: s
  } = t,
      o = s;
  assertNotComplex$3([a, s], "avgPoolGrad");
  var {
    filterSize: i,
    strides: l,
    pad: u
  } = r,
      c = computePool2DInfo$1(o.shape, i, l, 1, u),
      p = c.strideHeight,
      d = c.strideWidth,
      h = c.filterHeight,
      m = c.filterWidth,
      f = c.dilationHeight,
      g = c.dilationWidth,
      $ = c.effectiveFilterHeight,
      y = c.effectiveFilterWidth,
      b = y - 1 - c.padInfo.left,
      x = $ - 1 - c.padInfo.top,
      v = buffer$1(o.shape, "float32"),
      I = 1 / (h * m),
      C = n.data.get(a.dataId).values,
      S = buffer$1(a.shape, "float32", C);

  for (var _e297 = 0; _e297 < c.batchSize; ++_e297) {
    for (var _t224 = 0; _t224 < c.inChannels; ++_t224) {
      for (var _n129 = 0; _n129 < c.inHeight; ++_n129) {
        for (var _r92 = 0; _r92 < c.inWidth; ++_r92) {
          var _a63 = _n129 - x,
              _s40 = _r92 - b;

          var _o22 = 0;

          for (var _n130 = 0; _n130 < $; _n130 += f) {
            var _r93 = (_a63 + _n130) / p;

            if (!(_r93 < 0 || _r93 >= c.outHeight || Math.floor(_r93) !== _r93)) for (var _n131 = 0; _n131 < y; _n131 += g) {
              var _a64 = (_s40 + _n131) / d;

              _a64 < 0 || _a64 >= c.outWidth || Math.floor(_a64) !== _a64 || (_o22 += S.get(_e297, _r93, _a64, _t224));
            }
          }

          v.set(_o22 * I, _e297, _n129, _r92, _t224);
        }
      }
    }
  }

  return n.makeTensorInfo(v.shape, v.dtype, v.values);
}

var avgPoolGradConfig$4 = {
  kernelName: AvgPoolGrad$1,
  backendName: "cpu",
  kernelFunc: avgPoolGrad$4
};

function batchNorm$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    scale: s,
    offset: o,
    mean: i,
    variance: l
  } = t;
  assert$6(i.shape.length === l.shape.length, () => "Batch normalization gradient requires mean and variance to have equal ranks."), assert$6(null == o || i.shape.length === o.shape.length, () => "Batch normalization gradient requires mean and offset to have equal ranks."), assert$6(null == s || i.shape.length === s.shape.length, () => "Batch normalization gradient requires mean and scale to have equal ranks."), assertNotComplex$3([a, i, l, s, o], "batchNorm");
  var {
    varianceEpsilon: u
  } = r;
  null == u && (u = .001);
  var c = n.data.get(a.dataId).values,
      p = n.data.get(i.dataId).values,
      d = n.data.get(l.dataId).values,
      h = s ? n.data.get(s.dataId).values : new Float32Array([1]),
      m = o ? n.data.get(o.dataId).values : new Float32Array([0]),
      f = new Float32Array(c.length),
      g = m.length,
      $ = h.length,
      y = d.length,
      b = p.length;
  var x = 0,
      v = 0,
      I = 0,
      C = 0;

  for (var _e298 = 0; _e298 < c.length; ++_e298) {
    f[_e298] = m[x++] + (c[_e298] - p[v++]) * h[I++] / Math.sqrt(d[C++] + u), x >= g && (x = 0), v >= b && (v = 0), I >= $ && (I = 0), C >= y && (C = 0);
  }

  return n.makeTensorInfo(a.shape, a.dtype, f);
}

var batchNormConfig$3 = {
  kernelName: FusedBatchNorm$1,
  backendName: "cpu",
  kernelFunc: batchNorm$4
};

function batchToSpaceND$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    blockShape: s,
    crops: o
  } = r;
  assertNotComplex$3([a], "batchToSpaceND");
  var i = s.reduce((e, t) => e * t),
      l = getReshaped$1(a.shape, s, i),
      u = getPermuted$1(l.length, s.length),
      c = getReshapedPermuted$1(a.shape, s, i),
      p = getSliceBeginCoords$1(o, s.length),
      d = getSliceSize$1(c, o, s.length),
      h = reshape$5({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      shape: l
    }
  }),
      m = transpose$4({
    inputs: {
      x: h
    },
    backend: n,
    attrs: {
      perm: u
    }
  }),
      f = reshape$5({
    inputs: {
      x: m
    },
    backend: n,
    attrs: {
      shape: c
    }
  }),
      g = slice$4({
    inputs: {
      x: f
    },
    backend: n,
    attrs: {
      begin: p,
      size: d
    }
  });
  return n.disposeIntermediateTensorInfo(h), n.disposeIntermediateTensorInfo(m), n.disposeIntermediateTensorInfo(f), g;
}

var batchToSpaceNDConfig$3 = {
  kernelName: BatchToSpaceND$1,
  backendName: "cpu",
  kernelFunc: batchToSpaceND$4
};

function bincount$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    weights: s
  } = t,
      {
    size: o
  } = r,
      i = bincountImpl$1(n.data.get(a.dataId).values, n.data.get(s.dataId).values, s.dtype, s.shape, o);
  return n.makeTensorInfo([o], s.dtype, i);
}

var bincountConfig$3 = {
  kernelName: Bincount$1,
  backendName: "cpu",
  kernelFunc: bincount$4
},
    clip$1 = unaryKernelFunc$3(ClipByValue$1, (e, t) => e > t.clipValueMax ? t.clipValueMax : e < t.clipValueMin ? t.clipValueMin : e),
    clipConfig$1 = {
  kernelName: ClipByValue$1,
  backendName: "cpu",
  kernelFunc: clip$1
},
    complexAbs$3 = e => {
  var {
    x: t
  } = e.inputs,
      n = e.backend,
      r = new Float32Array(sizeFromShape$1(t.shape)),
      a = n.data.get(t.dataId),
      s = a.complexTensorInfos.imag,
      o = n.data.get(a.complexTensorInfos.real.dataId).values,
      i = n.data.get(s.dataId).values;

  for (var _e299 = 0; _e299 < o.length; _e299++) {
    r[_e299] = Math.hypot(o[_e299], i[_e299]);
  }

  return n.makeOutput(r, t.shape, "float32");
},
    complexAbsConfig$3 = {
  kernelName: ComplexAbs$1,
  backendName: "cpu",
  kernelFunc: complexAbs$3
};

function imag$4(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    input: r
  } = t,
      a = n.data.get(r.dataId).complexTensorInfos.imag,
      s = n.data.get(a.dataId).values;
  return n.makeTensorInfo(a.shape, a.dtype, s);
}

var imagConfig$3 = {
  kernelName: Imag$1,
  backendName: "cpu",
  kernelFunc: imag$4
};

function concat$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    axis: a
  } = r,
      s = parseAxisParam$1(a, t[0].shape)[0];
  var o = computeOutShape$4(t.map(e => e.shape), s);
  if (0 === sizeFromShape$1(o)) return n.makeTensorInfo(o, t[0].dtype, []);
  var i = t.filter(e => sizeFromShape$1(e.shape) > 0);
  if (1 === i.length) return identity$4({
    inputs: {
      x: i[0]
    },
    backend: n
  });

  if (assertParamsConsistent$1(i.map(e => e.shape), s), "complex64" === i[0].dtype) {
    var _e300 = i.map(e => real$4({
      inputs: {
        input: e
      },
      backend: n
    })),
        _t225 = i.map(e => imag$4({
      inputs: {
        input: e
      },
      backend: n
    })),
        _r94 = concat$4({
      inputs: _e300,
      backend: n,
      attrs: {
        axis: s
      }
    }),
        _a65 = concat$4({
      inputs: _t225,
      backend: n,
      attrs: {
        axis: s
      }
    }),
        _o23 = complex$4({
      inputs: {
        real: _r94,
        imag: _a65
      },
      backend: n
    });

    return _e300.forEach(e => n.disposeIntermediateTensorInfo(e)), _t225.forEach(e => n.disposeIntermediateTensorInfo(e)), n.disposeIntermediateTensorInfo(_r94), n.disposeIntermediateTensorInfo(_a65), _o23;
  }

  var l = i.map(e => {
    var t = sizeFromShape$1(e.shape.slice(s));
    return reshape$5({
      inputs: {
        x: e
      },
      backend: n,
      attrs: {
        shape: [-1, t]
      }
    });
  }),
      u = l.map(e => ({
    vals: n.data.get(e.dataId).values,
    shape: e.shape
  }));
  o = computeOutShape$4(l.map(e => e.shape), 1);
  var c = concatImpl$3(u, o, t[0].dtype, 1 === l[0].shape[0]),
      p = computeOutShape$4(i.map(e => e.shape), s),
      d = n.makeTensorInfo(p, t[0].dtype, c);
  return l.forEach(e => n.disposeIntermediateTensorInfo(e)), d;
}

var concatConfig$3 = {
  kernelName: Concat$1,
  backendName: "cpu",
  kernelFunc: concat$4
};

function conv2D$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    filter: s
  } = t,
      {
    strides: o,
    pad: i,
    dataFormat: l,
    dilations: u,
    dimRoundingMode: c
  } = r;
  assertNotComplex$3([a, s], "conv2d");
  var p = convertConv2DDataFormat$1(l),
      d = computeConv2DInfo$1(a.shape, s.shape, o, u, i, c, !1, p),
      h = d.filterHeight,
      m = d.filterWidth,
      f = d.dilationHeight,
      g = d.dilationWidth,
      $ = d.padInfo.left,
      y = d.padInfo.top,
      b = "channelsLast" === d.dataFormat,
      x = new TensorBuffer$1(d.outShape, a.dtype),
      v = computeStrides$1(a.shape),
      I = computeStrides$1(s.shape),
      C = v[0],
      S = b ? v[1] : v[2],
      k = b ? v[2] : 1,
      T = b ? 1 : v[1],
      N = x.strides[0],
      w = b ? x.strides[1] : x.strides[2],
      E = b ? x.strides[2] : 1,
      A = b ? 1 : x.strides[1],
      D = n.data.get(a.dataId).values,
      R = n.data.get(s.dataId).values,
      _ = x.values;

  for (var _e301 = 0; _e301 < d.batchSize; ++_e301) {
    var _t226 = _e301 * C,
        _n132 = _e301 * N;

    for (var _e302 = 0; _e302 < d.outHeight; ++_e302) {
      var _r95 = _n132 + _e302 * w,
          _a66 = _e302 * d.strideHeight - y;

      for (var _e303 = 0; _e303 < h; ++_e303) {
        var _n133 = _a66 + _e303 * f;

        if (_n133 < 0 || _n133 >= d.inHeight) continue;

        var _s41 = _e303 * I[0],
            _o24 = _t226 + _n133 * S;

        for (var _e304 = 0; _e304 < d.outWidth; ++_e304) {
          var _t227 = _r95 + _e304 * E,
              _n134 = _e304 * d.strideWidth - $;

          for (var _e305 = 0; _e305 < m; ++_e305) {
            var _r96 = _n134 + _e305 * g;

            if (_r96 < 0 || _r96 >= d.inWidth) continue;

            var _a67 = _o24 + _r96 * k;

            var _i13 = _s41 + _e305 * I[1];

            for (var _e306 = 0; _e306 < d.inChannels; ++_e306) {
              var _n135 = D[_a67 + _e306 * T];

              for (var _e307 = 0; _e307 < d.outChannels; ++_e307) {
                _[_t227 + _e307 * A] += _n135 * R[_i13 + _e307];
              }

              _i13 += d.outChannels;
            }
          }
        }
      }
    }
  }

  return n.makeTensorInfo(x.shape, x.dtype, _);
}

var conv2DConfig$3 = {
  kernelName: Conv2D$3,
  backendName: "cpu",
  kernelFunc: conv2D$1
};

function conv2DBackpropFilter$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    dy: s
  } = t,
      {
    strides: o,
    pad: i,
    dataFormat: l,
    dimRoundingMode: u,
    filterShape: c
  } = r;
  assertNotComplex$3([a, s], "conv2dBackpropFilter");
  var p = convertConv2DDataFormat$1(l),
      d = computeConv2DInfo$1(a.shape, c, o, 1, i, u, !1, p),
      {
    strideHeight: h,
    strideWidth: m,
    filterHeight: f,
    filterWidth: g
  } = d,
      $ = "channelsLast" === d.dataFormat,
      y = new TensorBuffer$1(d.filterShape, "float32"),
      b = d.padInfo.left,
      x = d.padInfo.top,
      v = n.data.get(a.dataId).values,
      I = n.data.get(s.dataId).values,
      C = new TensorBuffer$1(a.shape, a.dtype, v),
      S = new TensorBuffer$1(s.shape, s.dtype, I);

  for (var _e308 = 0; _e308 < f; ++_e308) {
    var _t228 = Math.max(0, Math.ceil((x - _e308) / h)),
        _n136 = Math.min(d.outHeight, (d.inHeight + x - _e308) / h);

    for (var _r97 = 0; _r97 < g; ++_r97) {
      var _a68 = Math.max(0, Math.ceil((b - _r97) / m)),
          _s42 = Math.min(d.outWidth, (d.inWidth + b - _r97) / m);

      for (var _o25 = 0; _o25 < d.inChannels; ++_o25) {
        for (var _i14 = 0; _i14 < d.outChannels; ++_i14) {
          var _l10 = 0;

          for (var _u8 = 0; _u8 < d.batchSize; ++_u8) {
            for (var _c5 = _t228; _c5 < _n136; ++_c5) {
              var _t229 = _e308 + _c5 * h - x;

              for (var _e309 = _a68; _e309 < _s42; ++_e309) {
                var _n137 = _r97 + _e309 * m - b;

                _l10 += $ ? C.get(_u8, _t229, _n137, _o25) * S.get(_u8, _c5, _e309, _i14) : C.get(_u8, _o25, _t229, _n137) * S.get(_u8, _i14, _c5, _e309);
              }
            }
          }

          y.set(_l10, _e308, _r97, _o25, _i14);
        }
      }
    }
  }

  return n.makeTensorInfo(y.shape, y.dtype, y.values);
}

var conv2DBackpropFilterConfig$3 = {
  kernelName: Conv2DBackpropFilter$1,
  backendName: "cpu",
  kernelFunc: conv2DBackpropFilter$4
};

function conv2DBackpropInput$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    dy: a,
    filter: s
  } = t,
      {
    inputShape: o,
    strides: i,
    pad: l,
    dataFormat: u,
    dimRoundingMode: c
  } = r;
  assertNotComplex$3([a, s], "conv2dBackpropInput");
  var p = computeStrides$1(s.shape),
      d = computeStrides$1(a.shape);
  var h = convertConv2DDataFormat$1(u);
  var m = computeConv2DInfo$1(o, s.shape, i, 1, l, c, !1, h),
      f = new TensorBuffer$1(m.inShape, "float32"),
      g = f.values,
      $ = n.data.get(a.dataId).values,
      y = n.data.get(s.dataId).values,
      [b, x, v] = p,
      {
    batchSize: I,
    filterHeight: C,
    filterWidth: S,
    inChannels: k,
    inHeight: T,
    inWidth: N,
    outChannels: w,
    outHeight: E,
    outWidth: A,
    strideHeight: D,
    strideWidth: R
  } = m;
  h = m.dataFormat;

  var _ = C - 1 - m.padInfo.top,
      F = S - 1 - m.padInfo.left,
      P = "channelsLast" === h,
      O = f.strides[0],
      M = P ? f.strides[1] : f.strides[2],
      L = P ? f.strides[2] : 1,
      z = P ? 1 : f.strides[1],
      B = d[0],
      V = P ? d[1] : d[2],
      G = P ? d[2] : 1,
      U = P ? 1 : d[1];

  for (var _e310 = 0; _e310 < I; ++_e310) {
    for (var _t230 = 0; _t230 < k; ++_t230) {
      for (var _n138 = 0; _n138 < T; ++_n138) {
        var _r98 = _n138 - _,
            _a69 = Math.max(0, Math.ceil(_r98 / D)),
            _s43 = Math.min(E, (C + _r98) / D);

        for (var _o26 = 0; _o26 < N; ++_o26) {
          var _i15 = _o26 - F,
              _l11 = Math.max(0, Math.ceil(_i15 / R)),
              _u9 = Math.min(A, (S + _i15) / R);

          var _c6 = 0;

          for (var _n139 = _a69; _n139 < _s43; ++_n139) {
            var _a70 = _n139 * D - _r98;

            for (var _r99 = _l11; _r99 < _u9; ++_r99) {
              var _s44 = B * _e310 + V * _n139 + G * _r99,
                  _o27 = b * (C - 1 - _a70) + x * (S - 1 - (_r99 * R - _i15)) + v * _t230;

              for (var _e311 = 0; _e311 < w; ++_e311) {
                _c6 += $[_s44 + U * _e311] * y[_o27 + _e311];
              }
            }
          }

          g[O * _e310 + M * _n138 + L * _o26 + z * _t230] = _c6;
        }
      }
    }
  }

  return n.makeTensorInfo(f.shape, f.dtype, f.values);
}

var conv2DBackpropInputConfig$3 = {
  kernelName: Conv2DBackpropInput$1,
  backendName: "cpu",
  kernelFunc: conv2DBackpropInput$4
};

function conv3D$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    filter: s
  } = t,
      {
    strides: o,
    pad: i,
    dilations: l
  } = r;
  assertNotComplex$3([a, s], "conv3d");
  var u = computeConv3DInfo$1(a.shape, s.shape, o, l, i),
      {
    filterDepth: c,
    filterHeight: p,
    filterWidth: d,
    dilationDepth: h,
    dilationHeight: m,
    dilationWidth: f,
    padInfo: g
  } = u,
      $ = g.front,
      y = g.left,
      b = g.top,
      x = new TensorBuffer$1(u.outShape, a.dtype),
      v = n.data.get(a.dataId).values,
      I = n.data.get(s.dataId).values,
      C = x.values,
      S = computeStrides$1(a.shape),
      k = computeStrides$1(s.shape);

  for (var _e312 = 0; _e312 < u.batchSize; ++_e312) {
    var _t231 = _e312 * S[0],
        _n140 = _e312 * x.strides[0];

    for (var _e313 = 0; _e313 < u.outDepth; ++_e313) {
      var _r100 = _n140 + _e313 * x.strides[1],
          _a71 = _e313 * u.strideDepth - $;

      for (var _e314 = 0; _e314 < c; ++_e314) {
        var _n141 = _a71 + _e314 * h;

        if (_n141 < 0 || _n141 >= u.inDepth) continue;

        var _s45 = _e314 * k[0],
            _o28 = _t231 + _n141 * S[1];

        for (var _e315 = 0; _e315 < u.outHeight; ++_e315) {
          var _t232 = _r100 + _e315 * x.strides[2],
              _n142 = _e315 * u.strideHeight - b;

          for (var _e316 = 0; _e316 < p; ++_e316) {
            var _r101 = _n142 + _e316 * m;

            if (_r101 < 0 || _r101 >= u.inHeight) continue;

            var _a72 = _s45 + _e316 * k[1],
                _i16 = _o28 + _r101 * S[2];

            for (var _e317 = 0; _e317 < u.outWidth; ++_e317) {
              var _n143 = _t232 + _e317 * u.outChannels,
                  _r102 = _e317 * u.strideWidth - y;

              for (var _e318 = 0; _e318 < d; ++_e318) {
                var _t233 = _r102 + _e318 * f;

                if (_t233 < 0 || _t233 >= u.inWidth) continue;

                var _s46 = _i16 + _t233 * u.inChannels;

                var _o29 = _a72 + _e318 * k[2];

                for (var _e319 = 0; _e319 < u.inChannels; ++_e319) {
                  var _t234 = v[_s46 + _e319];

                  for (var _e320 = 0; _e320 < u.outChannels; ++_e320) {
                    C[_n143 + _e320] += _t234 * I[_o29 + _e320];
                  }

                  _o29 += u.outChannels;
                }
              }
            }
          }
        }
      }
    }
  }

  return n.makeTensorInfo(x.shape, x.dtype, x.values);
}

var conv3DConfig$3 = {
  kernelName: Conv3D$3,
  backendName: "cpu",
  kernelFunc: conv3D$3
};

function conv3DBackpropFilterV2$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    dy: s
  } = t,
      {
    strides: o,
    pad: i,
    filterShape: l
  } = r;
  assertNotComplex$3([a, s], "conv3dBackpropFilterV2");
  var u = computeStrides$1(a.shape),
      c = computeStrides$1(s.shape),
      p = computeConv3DInfo$1(a.shape, l, o, 1, i),
      d = p.strideDepth,
      h = p.strideHeight,
      m = p.strideWidth,
      f = p.filterDepth,
      g = p.filterHeight,
      $ = p.filterWidth,
      y = new TensorBuffer$1(p.filterShape, "float32"),
      b = y.values,
      [x, v, I, C] = y.strides,
      S = n.data.get(s.dataId).values,
      [k, T, N, w] = c,
      E = n.data.get(a.dataId).values,
      [A, D, R, _] = u,
      F = p.padInfo.front,
      P = p.padInfo.left,
      O = p.padInfo.top;

  for (var _e321 = 0; _e321 < f; ++_e321) {
    var _t235 = Math.max(0, Math.ceil((F - _e321) / d)),
        _n144 = Math.min(p.outDepth, (p.inDepth + F - _e321) / d),
        _r103 = _e321 * x;

    for (var _a73 = 0; _a73 < g; ++_a73) {
      var _s47 = Math.max(0, Math.ceil((O - _a73) / h)),
          _o30 = Math.min(p.outHeight, (p.inHeight + O - _a73) / h),
          _i17 = _a73 * v + _r103;

      for (var _r104 = 0; _r104 < $; ++_r104) {
        var _l12 = Math.max(0, Math.ceil((P - _r104) / m)),
            _u10 = Math.min(p.outWidth, (p.inWidth + P - _r104) / m),
            _c7 = _r104 * I + _i17;

        for (var _i18 = 0; _i18 < p.inChannels; ++_i18) {
          var _f3 = _i18 * C + _c7;

          for (var _c8 = 0; _c8 < p.outChannels; ++_c8) {
            var _g2 = 0;

            for (var _f4 = 0; _f4 < p.batchSize; ++_f4) {
              var _p8 = _f4 * A,
                  _$3 = _f4 * k;

              for (var _f5 = _t235; _f5 < _n144; ++_f5) {
                var _t236 = (_e321 + _f5 * d - F) * D + _p8,
                    _n145 = _f5 * T + _$3;

                for (var _e322 = _s47; _e322 < _o30; ++_e322) {
                  var _s48 = (_a73 + _e322 * h - O) * R + _t236,
                      _o31 = _e322 * N + _n145;

                  for (var _e323 = _l12; _e323 < _u10; ++_e323) {
                    _g2 += E[(_r104 + _e323 * m - P) * _ + _s48 + _i18] * S[_e323 * w + _o31 + _c8];
                  }
                }
              }
            }

            b[_f3 + _c8] = _g2;
          }
        }
      }
    }
  }

  return n.makeTensorInfo(y.shape, y.dtype, y.values);
}

var conv3DBackpropFilterV2Config$3 = {
  kernelName: Conv3DBackpropFilterV2$1,
  backendName: "cpu",
  kernelFunc: conv3DBackpropFilterV2$3
};

function conv3DBackpropInputV2$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    dy: a,
    filter: s
  } = t,
      {
    pad: o,
    strides: i,
    inputShape: l
  } = r;
  assertNotComplex$3([a], "conv3dBackpropInputV2");
  var u = computeStrides$1(a.shape),
      c = computeStrides$1(s.shape),
      p = computeConv3DInfo$1(l, s.shape, i, 1, o),
      d = new TensorBuffer$1(p.inShape, "float32"),
      h = d.values,
      [m, f, g, $] = d.strides,
      y = n.data.get(a.dataId).values,
      [b, x, v, I] = u,
      C = n.data.get(s.dataId).values,
      [S, k, T, N] = c,
      {
    batchSize: w,
    filterDepth: E,
    filterHeight: A,
    filterWidth: D,
    inChannels: R,
    inDepth: _,
    inHeight: F,
    inWidth: P,
    outChannels: O,
    outDepth: M,
    outHeight: L,
    outWidth: z,
    strideDepth: B,
    strideHeight: V,
    strideWidth: G
  } = p,
      U = E - 1 - p.padInfo.front,
      W = A - 1 - p.padInfo.top,
      q = D - 1 - p.padInfo.left;

  for (var _e324 = 0; _e324 < w; ++_e324) {
    for (var _t237 = 0; _t237 < R; ++_t237) {
      for (var _n146 = 0; _n146 < _; ++_n146) {
        var _r105 = _n146 - U,
            _a74 = Math.max(0, Math.ceil(_r105 / B)),
            _s49 = Math.min(M, (E + _r105) / B);

        for (var _o32 = 0; _o32 < F; ++_o32) {
          var _i19 = _o32 - W,
              _l13 = Math.max(0, Math.ceil(_i19 / V)),
              _u11 = Math.min(L, (A + _i19) / V);

          for (var _c9 = 0; _c9 < P; ++_c9) {
            var _p9 = _c9 - q,
                _d6 = Math.max(0, Math.ceil(_p9 / G)),
                _w = Math.min(z, (D + _p9) / G);

            var _R = 0;

            for (var _n147 = _a74; _n147 < _s49; ++_n147) {
              var _a75 = _n147 * B - _r105;

              for (var _r106 = _l13; _r106 < _u11; ++_r106) {
                var _s50 = _r106 * V - _i19;

                for (var _o33 = _d6; _o33 < _w; ++_o33) {
                  var _i20 = b * _e324 + x * _n147 + v * _r106 + I * _o33,
                      _l14 = S * (E - 1 - _a75) + k * (A - 1 - _s50) + T * (D - 1 - (_o33 * G - _p9)) + N * _t237;

                  for (var _e325 = 0; _e325 < O; ++_e325) {
                    _R += y[_i20 + _e325] * C[_l14 + _e325];
                  }
                }
              }
            }

            h[m * _e324 + f * _n146 + g * _o32 + $ * _c9 + _t237] = _R;
          }
        }
      }
    }
  }

  return n.makeTensorInfo(d.shape, d.dtype, d.values);
}

var conv3DBackpropInputV2Config$1 = {
  kernelName: Conv3DBackpropInputV2$1,
  backendName: "cpu",
  kernelFunc: conv3DBackpropInputV2$1
},
    cos$4 = unaryKernelFunc$3(Cos$1, e => Math.cos(e)),
    cosConfig$3 = {
  kernelName: Cos$1,
  backendName: "cpu",
  kernelFunc: cos$4
},
    cosh$4 = unaryKernelFunc$3(Cosh$1, e => Math.cosh(e)),
    coshConfig$3 = {
  kernelName: Cosh$1,
  backendName: "cpu",
  kernelFunc: cosh$4
};

function cropAndResize$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    image: a,
    boxes: s,
    boxInd: o
  } = t,
      {
    cropSize: i,
    method: l,
    extrapolationValue: u
  } = r,
      [c, p, d, h] = a.shape,
      m = s.shape[0],
      [f, g] = i,
      $ = buffer$1([m, f, g, h], "float32"),
      y = n.data.get(s.dataId).values,
      b = n.data.get(o.dataId).values,
      x = n.data.get(a.dataId).values,
      v = computeStrides$1(a.shape),
      I = computeStrides$1($.shape);

  for (var _e326 = 0; _e326 < m; _e326++) {
    var _t238 = 4 * _e326,
        _n148 = y[_t238],
        _r107 = y[_t238 + 1],
        _a76 = y[_t238 + 2],
        _s51 = y[_t238 + 3],
        _o34 = b[_e326];

    if (_o34 >= c) continue;

    var _i21 = f > 1 ? (_a76 - _n148) * (p - 1) / (f - 1) : 0,
        _m = g > 1 ? (_s51 - _r107) * (d - 1) / (g - 1) : 0;

    for (var _t239 = 0; _t239 < f; _t239++) {
      var _c10 = f > 1 ? _n148 * (p - 1) + _t239 * _i21 : .5 * (_n148 + _a76) * (p - 1);

      if (_c10 < 0 || _c10 > p - 1) for (var _n149 = 0; _n149 < g; _n149++) {
        for (var _r108 = 0; _r108 < h; _r108++) {
          $.values[_r108 + _n149 * I[2] + _t239 * I[1] + _e326 * I[0]] = u;
        }
      } else if ("bilinear" === l) {
        var _n150 = Math.floor(_c10),
            _a77 = Math.ceil(_c10),
            _i22 = _c10 - _n150;

        for (var _l15 = 0; _l15 < g; _l15++) {
          var _c11 = g > 1 ? _r107 * (d - 1) + _l15 * _m : .5 * (_r107 + _s51) * (d - 1);

          if (_c11 < 0 || _c11 > d - 1) {
            for (var _n151 = 0; _n151 < h; _n151++) {
              $.values[_n151 + _l15 * I[2] + _t239 * I[1] + _e326 * I[0]] = u;
            }

            continue;
          }

          var _p10 = Math.floor(_c11),
              _f6 = Math.ceil(_c11),
              _y2 = _c11 - _p10;

          for (var _r109 = 0; _r109 < h; _r109++) {
            var _s52 = _r109 + _p10 * v[2] + _n150 * v[1] + _o34 * v[0];

            var _u12 = x[_s52];
            _s52 = _r109 + _f6 * v[2] + _n150 * v[1] + _o34 * v[0];
            var _c12 = x[_s52];
            _s52 = _r109 + _p10 * v[2] + _a77 * v[1] + _o34 * v[0];
            var _d7 = x[_s52];
            _s52 = _r109 + _f6 * v[2] + _a77 * v[1] + _o34 * v[0];

            var _h6 = x[_s52],
                _m2 = _u12 + (_c12 - _u12) * _y2;

            _s52 = _r109 + _l15 * I[2] + _t239 * I[1] + _e326 * I[0], $.values[_s52] = _m2 + (_d7 + (_h6 - _d7) * _y2 - _m2) * _i22;
          }
        }
      } else for (var _n152 = 0; _n152 < g; ++_n152) {
        var _a78 = g > 1 ? _r107 * (d - 1) + _n152 * _m : .5 * (_r107 + _s51) * (d - 1);

        if (_a78 < 0 || _a78 > d - 1) {
          for (var _r110 = 0; _r110 < h; _r110++) {
            $.values[_r110 + _n152 * I[2] + _t239 * I[1] + _e326 * I[0]] = u;
          }

          continue;
        }

        var _i23 = Math.round(_a78),
            _l16 = Math.round(_c10);

        for (var _r111 = 0; _r111 < h; _r111++) {
          $.values[_r111 + _n152 * I[2] + _t239 * I[1] + _e326 * I[0]] = x[_r111 + _i23 * v[2] + _l16 * v[1] + _o34 * v[0]];
        }
      }
    }
  }

  return n.makeTensorInfo($.shape, $.dtype, $.values);
}

var cropAndResizeConfig$3 = {
  kernelName: CropAndResize$1,
  backendName: "cpu",
  kernelFunc: cropAndResize$4
};

function cumsum$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    axis: s,
    exclusive: o,
    reverse: i
  } = r;
  assertNotComplex$3(a, "cumsum");
  var l = getAxesPermutation$1([s], a.shape.length);
  var u = a;
  null != l && (u = transpose$4({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      perm: l
    }
  }));
  var c = getInnerMostAxes$1(1, a.shape.length)[0];
  if (c !== u.shape.length - 1) throw new Error("backend.cumsum in CPU expects an inner-most axis=".concat(u.shape.length - 1, " but got axis=").concat(c));
  var p = upcastType$1(u.dtype, "int32"),
      d = makeZerosTypedArray$1(sizeFromShape$1(u.shape), p),
      h = n.data.get(u.dataId).values,
      m = u.shape[u.shape.length - 1],
      f = i ? (e, t) => e + m - t - 1 : (e, t) => e + t;

  for (var _e327 = 0; _e327 < h.length; _e327 += m) {
    for (var _t240 = 0; _t240 < m; _t240++) {
      var _n153 = f(_e327, _t240);

      if (0 === _t240) d[_n153] = o ? 0 : h[_n153];else {
        var _r112 = f(_e327, _t240 - 1);

        d[_n153] = o ? h[_r112] + d[_r112] : h[_n153] + d[_r112];
      }
    }
  }

  var g = n.makeTensorInfo(u.shape, p, d);

  if (null != l) {
    var _e328 = transpose$4({
      inputs: {
        x: g
      },
      backend: n,
      attrs: {
        perm: getUndoAxesPermutation$1(l)
      }
    });

    return n.disposeIntermediateTensorInfo(g), n.disposeIntermediateTensorInfo(u), _e328;
  }

  return g;
}

var cumsumConfig$3 = {
  kernelName: Cumsum$1,
  backendName: "cpu",
  kernelFunc: cumsum$4
};

function denseBincount$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    weights: s
  } = t,
      {
    size: o,
    binaryOutput: i
  } = r;

  if (1 === a.shape.length) {
    var _e329 = bincountImpl$1(n.data.get(a.dataId).values, n.data.get(s.dataId).values, s.dtype, s.shape, o);

    return n.makeTensorInfo([o], s.dtype, _e329);
  }

  if (2 === a.shape.length) {
    var _e330 = bincountReduceImpl$1(n.bufferSync(a), n.bufferSync(s), o, i);

    return n.makeTensorInfo(_e330.shape, s.dtype, _e330.values);
  }

  throw new Error("Error in denseBincount: input must be at most rank 2, but got rank".concat(a.shape.length, "."));
}

var denseBincountConfig$3 = {
  kernelName: DenseBincount$1,
  backendName: "cpu",
  kernelFunc: denseBincount$4
};

function depthToSpace$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    blockSize: s,
    dataFormat: o
  } = r;
  assert$6("NHWC" === o, () => "Only NHWC dataFormat supported on CPU for depthToSpace. Got ".concat(o)), assert$6(s > 1, () => "blockSize should be > 1 for depthToSpace, but was: ".concat(s));
  var i = a.shape[0],
      l = a.shape[1],
      u = a.shape[2],
      c = a.shape[3],
      p = l * s,
      d = u * s,
      h = c / (s * s),
      m = n.data.get(a.dataId).values,
      f = new Float32Array(i * p * d * h);
  var g = 0;

  for (var _e331 = 0; _e331 < i; ++_e331) {
    for (var _t241 = 0; _t241 < p; ++_t241) {
      var _n154 = Math.floor(_t241 / s),
          _r113 = _t241 % s;

      for (var _t242 = 0; _t242 < d; ++_t242) {
        var _a79 = Math.floor(_t242 / s),
            _o35 = (_r113 * s + _t242 % s) * h;

        for (var _t243 = 0; _t243 < h; ++_t243) {
          f[g++] = m[_t243 + _o35 + c * (_a79 + u * (_n154 + l * _e331))];
        }
      }
    }
  }

  return n.makeTensorInfo([i, p, d, h], a.dtype, f);
}

var depthToSpaceConfig$3 = {
  kernelName: DepthToSpace$1,
  backendName: "cpu",
  kernelFunc: depthToSpace$4
};

function depthwiseConv2dNative$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    filter: s
  } = t,
      {
    strides: o,
    pad: i,
    dilations: l,
    dimRoundingMode: u
  } = r;
  assertNotComplex$3([a, s], "depthwiseConv2DNative");
  var c = computeStrides$1(a.shape),
      p = computeStrides$1(s.shape);
  var d = l;
  null == d && (d = [1, 1]), assert$6(eitherStridesOrDilationsAreOne$1(o, d), () => "Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ".concat(o, " and dilations '").concat(d, "'"));
  var h = computeConv2DInfo$1(a.shape, s.shape, o, d, i, u, !0),
      {
    filterHeight: m,
    filterWidth: f,
    dilationHeight: g,
    dilationWidth: $,
    padInfo: y
  } = h,
      b = y.left,
      x = y.top,
      v = h.outChannels / h.inChannels,
      I = new TensorBuffer$1(h.outShape, a.dtype),
      C = n.data.get(a.dataId).values,
      S = n.data.get(s.dataId).values,
      k = I.values;

  for (var _e332 = 0; _e332 < h.batchSize; ++_e332) {
    var _t244 = _e332 * c[0],
        _n155 = _e332 * I.strides[0];

    for (var _e333 = 0; _e333 < h.outHeight; ++_e333) {
      var _r114 = _n155 + _e333 * I.strides[1],
          _a80 = _e333 * h.strideHeight - x;

      for (var _e334 = 0; _e334 < m; ++_e334) {
        var _n156 = _a80 + _e334 * g;

        if (_n156 < 0 || _n156 >= h.inHeight) continue;

        var _s53 = _e334 * p[0],
            _o36 = _t244 + _n156 * c[1];

        for (var _e335 = 0; _e335 < h.outWidth; ++_e335) {
          var _t245 = _r114 + _e335 * I.strides[2],
              _n157 = _e335 * h.strideWidth - b;

          for (var _e336 = 0; _e336 < f; ++_e336) {
            var _r115 = _n157 + _e336 * $;

            if (_r115 < 0 || _r115 >= h.inWidth) continue;

            var _a81 = _o36 + _r115 * h.inChannels;

            var _i24 = _t245,
                _l17 = _s53 + _e336 * p[1];

            for (var _e337 = 0; _e337 < h.inChannels; ++_e337) {
              var _t246 = C[_a81 + _e337];

              for (var _e338 = 0; _e338 < v; ++_e338) {
                k[_i24 + _e338] += _t246 * S[_l17 + _e338];
              }

              _i24 += v, _l17 += v;
            }
          }
        }
      }
    }
  }

  return n.makeTensorInfo(I.shape, I.dtype, I.values);
}

var depthwiseConv2dNativeConfig$3 = {
  kernelName: DepthwiseConv2dNative$1,
  backendName: "cpu",
  kernelFunc: depthwiseConv2dNative$3
};

function depthwiseConv2dNativeBackpropFilter$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    dy: s
  } = t,
      {
    strides: o,
    dilations: i,
    pad: l,
    dimRoundingMode: u,
    filterShape: c
  } = r;
  assertNotComplex$3([a, s], "depthwiseConv2dNativeBackpropFilter");
  var p = computeConv2DInfo$1(a.shape, c, o, i, l, u, !0),
      {
    strideHeight: d,
    strideWidth: h,
    filterHeight: m,
    filterWidth: f
  } = p,
      g = new TensorBuffer$1(p.filterShape, "float32"),
      $ = p.padInfo.left,
      y = p.padInfo.top,
      b = p.outChannels / p.inChannels,
      x = n.data.get(a.dataId).values,
      v = new TensorBuffer$1(a.shape, a.dtype, x),
      I = n.data.get(s.dataId).values,
      C = new TensorBuffer$1(s.shape, s.dtype, I);

  for (var _e339 = 0; _e339 < m; ++_e339) {
    var _t247 = Math.max(0, Math.ceil((y - _e339) / d)),
        _n158 = Math.min(p.outHeight, (p.inHeight + y - _e339) / d);

    for (var _r116 = 0; _r116 < f; ++_r116) {
      var _a82 = Math.max(0, Math.ceil(($ - _r116) / h)),
          _s54 = Math.min(p.outWidth, (p.inWidth + $ - _r116) / h);

      for (var _o37 = 0; _o37 < p.outChannels; ++_o37) {
        var _i25 = Math.trunc(_o37 / b),
            _l18 = _o37 % b;

        var _u13 = 0;

        for (var _l19 = 0; _l19 < p.batchSize; ++_l19) {
          for (var _c13 = _t247; _c13 < _n158; ++_c13) {
            var _t248 = _e339 + _c13 * d - y;

            for (var _e340 = _a82; _e340 < _s54; ++_e340) {
              _u13 += v.get(_l19, _t248, _r116 + _e340 * h - $, _i25) * C.get(_l19, _c13, _e340, _o37);
            }
          }
        }

        g.set(_u13, _e339, _r116, _i25, _l18);
      }
    }
  }

  return n.makeTensorInfo(g.shape, g.dtype, g.values);
}

var depthwiseConv2dNativeBackpropFilterConfig$3 = {
  kernelName: DepthwiseConv2dNativeBackpropFilter$1,
  backendName: "cpu",
  kernelFunc: depthwiseConv2dNativeBackpropFilter$4
};

function depthwiseConv2dNativeBackpropInput$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    dy: a,
    filter: s
  } = t,
      {
    strides: o,
    dilations: i,
    pad: l,
    dimRoundingMode: u,
    inputShape: c
  } = r;
  assertNotComplex$3([a, s], "depthwiseConv2DNativeBackpropInput");
  var p = computeStrides$1(a.shape),
      d = computeStrides$1(s.shape),
      h = computeConv2DInfo$1(c, s.shape, o, i, l, u, !0),
      m = new TensorBuffer$1(h.inShape, "float32"),
      f = m.values,
      [g, $, y] = m.strides,
      b = n.data.get(a.dataId).values,
      [x, v, I] = p,
      C = n.data.get(s.dataId).values,
      [S, k, T] = d,
      {
    batchSize: N,
    filterHeight: w,
    filterWidth: E,
    inChannels: A,
    inHeight: D,
    inWidth: R,
    outChannels: _,
    outHeight: F,
    outWidth: P,
    strideHeight: O,
    strideWidth: M
  } = h,
      L = w - 1 - h.padInfo.top,
      z = E - 1 - h.padInfo.left,
      B = _ / A;

  for (var _e341 = 0; _e341 < N; ++_e341) {
    for (var _t249 = 0; _t249 < A; ++_t249) {
      for (var _n159 = 0; _n159 < D; ++_n159) {
        var _r117 = _n159 - L,
            _a83 = Math.max(0, Math.ceil(_r117 / O)),
            _s55 = Math.min(F, (w + _r117) / O);

        for (var _o38 = 0; _o38 < R; ++_o38) {
          var _i26 = _o38 - z,
              _l20 = Math.max(0, Math.ceil(_i26 / M)),
              _u14 = Math.min(P, (E + _i26) / M);

          var _c14 = 0;

          for (var _n160 = _a83; _n160 < _s55; ++_n160) {
            var _a84 = _n160 * O - _r117;

            for (var _r118 = _l20; _r118 < _u14; ++_r118) {
              var _s56 = x * _e341 + v * _n160 + I * _r118,
                  _o39 = S * (w - 1 - _a84) + k * (E - 1 - (_r118 * M - _i26)) + T * _t249;

              for (var _e342 = 0; _e342 < B; ++_e342) {
                _c14 += b[_s56 + (_t249 * B + _e342)] * C[_o39 + _e342];
              }
            }
          }

          f[g * _e341 + $ * _n159 + y * _o38 + _t249] = _c14;
        }
      }
    }
  }

  return n.makeTensorInfo(m.shape, m.dtype, m.values);
}

var depthwiseConv2dNativeBackpropInputConfig$3 = {
  kernelName: DepthwiseConv2dNativeBackpropInput$1,
  backendName: "cpu",
  kernelFunc: depthwiseConv2dNativeBackpropInput$4
};

function diag$4(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    x: r
  } = t,
      a = sizeFromShape$1(r.shape),
      s = n.data.get(r.dataId).values,
      o = buffer$1([a, a], r.dtype),
      i = o.values;

  for (var _e343 = 0; _e343 < s.length; _e343++) {
    i[_e343 * a + _e343] = s[_e343];
  }

  var l = [...r.shape, ...r.shape];
  return n.makeTensorInfo(l, o.dtype, o.values);
}

var diagConfig$3 = {
  kernelName: Diag$1,
  backendName: "cpu",
  kernelFunc: diag$4
},
    dilation2dConfig$1 = {
  kernelName: Dilation2D$1,
  backendName: "cpu",
  kernelFunc: _ref7 => {
    var {
      inputs: e,
      backend: t,
      attrs: n
    } = _ref7;
    var {
      x: r,
      filter: a
    } = e,
        {
      strides: s,
      pad: o,
      dilations: i
    } = n,
        l = t,
        u = l.data.get(r.dataId).values,
        c = r.shape.length,
        p = l.data.get(a.dataId).values,
        d = a.shape.length,
        {
      batchSize: h,
      inHeight: m,
      inWidth: f,
      inChannels: g,
      outHeight: $,
      outWidth: y,
      padInfo: b,
      strideHeight: x,
      strideWidth: v,
      filterHeight: I,
      filterWidth: C,
      dilationHeight: S,
      dilationWidth: k,
      outShape: T
    } = computeDilation2DInfo$1(r.shape, a.shape, s, o, "NHWC", i),
        N = sizeFromShape$1(T),
        w = T.length,
        E = getArrayFromDType$1(r.dtype, N);

    for (var _e344 = 0; _e344 < h; ++_e344) {
      for (var _t250 = 0; _t250 < $; ++_t250) {
        var _n161 = _t250 * x - b.top;

        for (var _s57 = 0; _s57 < y; ++_s57) {
          var _o40 = _s57 * v - b.left;

          for (var _i27 = 0; _i27 < g; ++_i27) {
            var _l21 = Number.MIN_SAFE_INTEGER;

            for (var _t251 = 0; _t251 < I; ++_t251) {
              var _s58 = _n161 + _t251 * S;

              if (_s58 >= 0 && _s58 < m) for (var _n162 = 0; _n162 < C; ++_n162) {
                var _h7 = _o40 + _n162 * k;

                if (_h7 >= 0 && _h7 < f) {
                  var _o41 = locToIndex$1([_e344, _s58, _h7, _i27], c, computeStrides$1(r.shape)),
                      _m3 = locToIndex$1([_t251, _n162, _i27], d, computeStrides$1(a.shape)),
                      _f7 = u[_o41] + p[_m3];

                  _f7 > _l21 && (_l21 = _f7);
                }
              }
            }

            E[locToIndex$1([_e344, _t250, _s57, _i27], w, computeStrides$1(T))] = _l21;
          }
        }
      }
    }

    return {
      dataId: l.write(toTypedArray$1(E, r.dtype), T, r.dtype),
      shape: T,
      dtype: r.dtype
    };
  }
},
    dilation2dBackpropFilterConfig$1 = {
  kernelName: Dilation2DBackpropFilter$1,
  backendName: "cpu",
  kernelFunc: _ref8 => {
    var {
      inputs: e,
      backend: t,
      attrs: n
    } = _ref8;
    var {
      x: r,
      filter: a,
      dy: s
    } = e,
        {
      strides: o,
      pad: i,
      dilations: l
    } = n,
        u = t,
        c = toNestedArray$1(r.shape, u.data.get(r.dataId).values),
        p = toNestedArray$1(a.shape, u.data.get(a.dataId).values),
        {
      batchSize: d,
      inHeight: h,
      inWidth: m,
      inChannels: f,
      outHeight: g,
      outWidth: $,
      padInfo: y,
      strideHeight: b,
      strideWidth: x,
      filterHeight: v,
      filterWidth: I,
      dilationHeight: C,
      dilationWidth: S,
      outShape: k
    } = computeDilation2DInfo$1(r.shape, a.shape, o, i, "NHWC", l);
    assert$6(s.rank === k.length, () => "Error in ".concat(Dilation2DBackpropFilter$1, ", dy must have the same rank as output ").concat(k.length, ", but got ").concat(s.rank));
    var T = toNestedArray$1(k, u.data.get(s.dataId).values),
        N = makeZerosNestedTypedArray$1(a.shape, a.dtype);

    for (var _e345 = 0; _e345 < d; ++_e345) {
      for (var _t252 = 0; _t252 < g; ++_t252) {
        var _n163 = _t252 * b - y.top;

        for (var _r119 = 0; _r119 < $; ++_r119) {
          var _a85 = _r119 * x - y.left;

          for (var _s59 = 0; _s59 < f; ++_s59) {
            var _o42 = Number.MIN_SAFE_INTEGER,
                _i28 = 0,
                _l22 = 0;

            for (var _t253 = 0; _t253 < v; ++_t253) {
              var _r120 = _n163 + _t253 * C;

              if (_r120 >= 0 && _r120 < h) for (var _n164 = 0; _n164 < I; ++_n164) {
                var _u15 = _a85 + _n164 * S;

                if (_u15 >= 0 && _u15 < m) {
                  var _a86 = c[_e345][_r120][_u15][_s59] + p[_t253][_n164][_s59];

                  _a86 > _o42 && (_o42 = _a86, _i28 = _t253, _l22 = _n164);
                }
              }
            }

            N[_i28][_l22][_s59] += T[_e345][_t252][_r119][_s59];
          }
        }
      }
    }

    return {
      dataId: u.write(toTypedArray$1(N, r.dtype), a.shape, a.dtype),
      shape: a.shape,
      dtype: a.dtype
    };
  }
},
    dilation2dBackpropInputConfig$1 = {
  kernelName: Dilation2DBackpropInput$1,
  backendName: "cpu",
  kernelFunc: _ref9 => {
    var {
      inputs: e,
      backend: t,
      attrs: n
    } = _ref9;
    var {
      x: r,
      filter: a,
      dy: s
    } = e,
        {
      strides: o,
      pad: i,
      dilations: l
    } = n,
        u = t,
        c = toNestedArray$1(r.shape, u.data.get(r.dataId).values),
        p = toNestedArray$1(a.shape, u.data.get(a.dataId).values),
        {
      batchSize: d,
      inHeight: h,
      inWidth: m,
      inChannels: f,
      outHeight: g,
      outWidth: $,
      padInfo: y,
      strideHeight: b,
      strideWidth: x,
      filterHeight: v,
      filterWidth: I,
      dilationHeight: C,
      dilationWidth: S,
      outShape: k
    } = computeDilation2DInfo$1(r.shape, a.shape, o, i, "NHWC", l);
    assert$6(s.rank === k.length, () => "Error in ".concat(Dilation2DBackpropInput$1, ", dy must have the same rank as output ").concat(k.length, ", but got ").concat(s.rank));
    var T = toNestedArray$1(k, u.data.get(s.dataId).values),
        N = makeZerosNestedTypedArray$1(r.shape, r.dtype);

    for (var _e346 = 0; _e346 < d; ++_e346) {
      for (var _t254 = 0; _t254 < g; ++_t254) {
        var _n165 = _t254 * b - y.top;

        for (var _r121 = 0; _r121 < $; ++_r121) {
          var _a87 = _r121 * x - y.left;

          for (var _s60 = 0; _s60 < f; ++_s60) {
            var _o43 = Number.MIN_SAFE_INTEGER,
                _i29 = _n165 < 0 ? 0 : _n165,
                _l23 = _a87 < 0 ? 0 : _a87;

            for (var _t255 = 0; _t255 < v; ++_t255) {
              var _r122 = _n165 + _t255 * C;

              if (_r122 >= 0 && _r122 < h) for (var _n166 = 0; _n166 < I; ++_n166) {
                var _u16 = _a87 + _n166 * S;

                if (_u16 >= 0 && _u16 < m) {
                  var _a88 = c[_e346][_r122][_u16][_s60] + p[_t255][_n166][_s60];

                  _a88 > _o43 && (_o43 = _a88, _i29 = _r122, _l23 = _u16);
                }
              }
            }

            N[_e346][_i29][_l23][_s60] += T[_e346][_t254][_r121][_s60];
          }
        }
      }
    }

    return {
      dataId: u.write(toTypedArray$1(N, r.dtype), r.shape, r.dtype),
      shape: r.shape,
      dtype: r.dtype
    };
  }
};

function sum$5(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    axis: s,
    keepDims: o
  } = r;
  var i;
  assertNotComplex$3(a, "sum"), i = "bool" === a.dtype ? cast$5({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      dtype: "int32"
    }
  }) : identity$4({
    inputs: {
      x: a
    },
    backend: n
  });
  var l = i.shape.length,
      u = parseAxisParam$1(s, i.shape),
      c = getAxesPermutation$1(u, l);
  var p = u,
      d = i;
  null != c && (d = transpose$4({
    inputs: {
      x: i
    },
    backend: n,
    attrs: {
      perm: c
    }
  }), p = getInnerMostAxes$1(p.length, l)), assertAxesAreInnerMostDims$1("sum", p, d.shape.length);
  var [h, m] = computeOutAndReduceShapes$1(d.shape, p);
  var f = zeros$3(n, h, upcastType$1(d.dtype, "int32"));
  var g = sizeFromShape$1(m),
      $ = n.data.get(f.dataId).values,
      y = n.data.get(d.dataId).values;

  for (var _e347 = 0; _e347 < $.length; ++_e347) {
    var _t256 = _e347 * g;

    var _n167 = 0;

    for (var _e348 = 0; _e348 < g; ++_e348) {
      _n167 += y[_t256 + _e348];
    }

    $[_e347] = _n167;
  }

  if (o) {
    var _e349 = f;
    f = reshape$5({
      inputs: {
        x: f
      },
      backend: n,
      attrs: {
        shape: expandShapeToKeepDim$1(f.shape, u)
      }
    }), n.disposeIntermediateTensorInfo(_e349);
  }

  return n.disposeIntermediateTensorInfo(i), null != c && n.disposeIntermediateTensorInfo(d), f;
}

var sumConfig$3 = {
  kernelName: Sum$1,
  backendName: "cpu",
  kernelFunc: sum$5
};

function einsum$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    equation: a
  } = r,
      s = t,
      {
    allDims: o,
    summedDims: i,
    idDims: l
  } = decodeEinsumEquation$1(a, s.length);
  checkEinsumDimSizes$1(o.length, l, s);
  var {
    path: u,
    steps: c
  } = getEinsumComputePath$1(i, l),
      p = c.length;
  var d = null,
      h = o.length;
  var m = [];

  for (var _e350 = 0; _e350 < p; ++_e350) {
    for (var _t257 of c[_e350]) {
      var {
        permutationIndices: _e351,
        expandDims: _r123
      } = getEinsumPermutation$1(h, l[_t257]);

      var _a89 = void 0;

      isIdentityPermutation$1(_e351) ? _a89 = s[_t257] : (_a89 = transpose$4({
        inputs: {
          x: s[_t257]
        },
        backend: n,
        attrs: {
          perm: _e351
        }
      }), m.push(_a89));

      var _o44 = _a89.shape.slice();

      for (var _e352 = 0; _e352 < _r123.length; ++_e352) {
        _o44.splice(_r123[_e352], 0, 1);
      }

      arraysEqual$1(_a89.shape, _o44) || (_a89 = reshape$5({
        inputs: {
          x: _a89
        },
        backend: n,
        attrs: {
          shape: _o44
        }
      }), m.push(_a89)), null === d ? d = _a89 : (d = multiply$4({
        inputs: {
          a: _a89,
          b: d
        },
        backend: n
      }), m.push(d));
    }

    _e350 < p - 1 && (u[_e350] >= 0 && (d = sum$5({
      inputs: {
        x: d
      },
      backend: n,
      attrs: {
        axis: u[_e350] - (o.length - h),
        keepDims: !1
      }
    }), m.push(d)), h--);
  }

  for (var _e353 of m) {
    _e353 !== d && n.disposeIntermediateTensorInfo(_e353);
  }

  return d;
}

var einsumConfig$3 = {
  kernelName: Einsum$1,
  backendName: "cpu",
  kernelFunc: einsum$4
};

function eluGrad$3(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    dy: r,
    y: a
  } = t;
  assertNotComplex$3([r, a], "eluGrad");
  var s = new Float32Array(sizeFromShape$1(a.shape)),
      o = n.data.get(a.dataId).values,
      i = n.data.get(r.dataId).values;

  for (var _e354 = 0; _e354 < o.length; ++_e354) {
    var _t258 = o[_e354];
    s[_e354] = _t258 >= 1 ? i[_e354] : i[_e354] * (_t258 + 1);
  }

  return n.makeTensorInfo(a.shape, "float32", s);
}

var eluGradConfig$4 = {
  kernelName: EluGrad$1,
  backendName: "cpu",
  kernelFunc: eluGrad$3
},
    p$1 = ERF_P$1,
    a1$1 = ERF_A1$1,
    a2$1 = ERF_A2$1,
    a3$1 = ERF_A3$1,
    a4$1 = ERF_A4$1,
    a5$1 = ERF_A5$1,
    erf$4 = unaryKernelFunc$3(Erf$1, e => {
  var t = Math.sign(e),
      n = Math.abs(e),
      r = 1 / (1 + p$1 * n);
  return t * (1 - ((((a5$1 * r + a4$1) * r + a3$1) * r + a2$1) * r + a1$1) * r * Math.exp(-n * n));
}),
    erfConfig$3 = {
  kernelName: Erf$1,
  backendName: "cpu",
  kernelFunc: erf$4
};

function expandDims$5(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    input: a
  } = t,
      {
    dim: s
  } = r,
      o = a.shape.length,
      i = a.shape.slice();
  var l = s;
  return s < 0 && (assert$6(-(o + 1) <= s, () => "Axis must be in the interval [".concat(-(o + 1), ", ").concat(o, "]")), l = o + s + 1), i.splice(l, 0, 1), reshape$5({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      shape: i
    }
  });
}

var expandDimsConfig$3 = {
  kernelName: ExpandDims$1,
  backendName: "cpu",
  kernelFunc: expandDims$5
},
    realDivImpl$1 = createSimpleBinaryKernelImpl$1((e, t) => e / t),
    div$2 = binaryKernelFunc$3(RealDiv$1, realDivImpl$1),
    realDivConfig$3 = {
  kernelName: RealDiv$1,
  backendName: "cpu",
  kernelFunc: div$2
};

function fftBatch$1(e, t, n) {
  var r = e.shape,
      a = r[0],
      s = r[1],
      o = n.data.get(e.dataId),
      i = o.complexTensorInfos.real,
      l = o.complexTensorInfos.imag,
      u = [a, s],
      c = sizeFromShape$1(u),
      p = getTypedArrayFromDType$1("float32", c),
      d = getTypedArrayFromDType$1("float32", c);

  for (var _e355 = 0; _e355 < a; _e355++) {
    var _r124 = slice$4({
      inputs: {
        x: i
      },
      backend: n,
      attrs: {
        begin: [_e355, 0],
        size: [1, s]
      }
    }),
        _a90 = slice$4({
      inputs: {
        x: l
      },
      backend: n,
      attrs: {
        begin: [_e355, 0],
        size: [1, s]
      }
    }),
        _o45 = complex$4({
      inputs: {
        real: _r124,
        imag: _a90
      },
      backend: n
    }),
        {
      real: _u17,
      imag: _c15
    } = fftImpl$3(_o45, t, n),
        _h8 = mergeRealAndImagArrays$1(_u17, _c15);

    for (var _t259 = 0; _t259 < s; _t259++) {
      var _n168 = getComplexWithIndex$1(_h8, _t259);

      p[_e355 * s + _t259] = _n168.real, d[_e355 * s + _t259] = _n168.imag;
    }

    n.disposeIntermediateTensorInfo(_r124), n.disposeIntermediateTensorInfo(_a90), n.disposeIntermediateTensorInfo(_o45);
  }

  var h = n.makeTensorInfo(u, "float32", p),
      m = n.makeTensorInfo(u, "float32", d),
      f = complex$4({
    inputs: {
      real: h,
      imag: m
    },
    backend: n
  });
  return n.disposeIntermediateTensorInfo(h), n.disposeIntermediateTensorInfo(m), f;
}

function fftImpl$3(e, t, n) {
  var r = sizeFromShape$1(e.shape),
      a = n.data.get(e.dataId),
      s = n.data.get(a.complexTensorInfos.real.dataId).values,
      o = n.data.get(a.complexTensorInfos.imag.dataId).values;

  if (isExponentOf2$1(r)) {
    var _a91 = fftRadix2$1(s, o, r, t, n),
        i = [e.shape[0], e.shape[1]];

    if (t) {
      var _e356 = n.makeTensorInfo(i, "float32", _a91.real),
          _t260 = n.makeTensorInfo(i, "float32", _a91.imag),
          _s61 = n.makeTensorInfo([], "float32", createScalarValue$1(r, "float32")),
          _o46 = identity$4({
        inputs: {
          x: _s61
        },
        backend: n
      }),
          l = realDivConfig$3.kernelFunc({
        inputs: {
          a: _e356,
          b: _s61
        },
        backend: n
      }),
          u = realDivConfig$3.kernelFunc({
        inputs: {
          a: _t260,
          b: _o46
        },
        backend: n
      }),
          c = n.data.get(l.dataId).values,
          _p11 = n.data.get(u.dataId).values;

      return n.disposeIntermediateTensorInfo(_e356), n.disposeIntermediateTensorInfo(_t260), n.disposeIntermediateTensorInfo(_s61), n.disposeIntermediateTensorInfo(_o46), n.disposeIntermediateTensorInfo(l), n.disposeIntermediateTensorInfo(u), {
        real: c,
        imag: _p11
      };
    }

    return _a91;
  }

  return splitRealAndImagArrays$1(fourierTransformByMatmul$1(mergeRealAndImagArrays$1(s, o), r, t));
}

function isExponentOf2$1(e) {
  return 0 == (e & e - 1);
}

function fftRadix2$1(e, t, n, r, a) {
  if (1 === n) return {
    real: e,
    imag: t
  };

  var s = mergeRealAndImagArrays$1(e, t),
      o = n / 2,
      i = complexWithEvenIndex$1(s),
      l = i.real,
      u = i.imag,
      c = [l.length],
      p = a.makeTensorInfo(c, "float32", l),
      d = a.makeTensorInfo(c, "float32", u),
      h = complex$4({
    inputs: {
      real: p,
      imag: d
    },
    backend: a
  }),
      m = complexWithOddIndex$1(s),
      f = m.real,
      g = m.imag,
      $ = [f.length],
      y = a.makeTensorInfo($, "float32", f),
      b = a.makeTensorInfo($, "float32", g),
      x = complex$4({
    inputs: {
      real: y,
      imag: b
    },
    backend: a
  }),
      v = fftRadix2$1(l, u, o, r, a),
      I = v.real,
      C = v.imag,
      S = [I.length],
      k = a.makeTensorInfo(S, "float32", I),
      T = a.makeTensorInfo(S, "float32", C),
      N = complex$4({
    inputs: {
      real: k,
      imag: T
    },
    backend: a
  }),
      w = fftRadix2$1(f, g, o, r, a),
      E = w.real,
      A = w.imag,
      D = [E.length],
      R = a.makeTensorInfo(D, "float32", E),
      _ = a.makeTensorInfo(D, "float32", A),
      F = complex$4({
    inputs: {
      real: R,
      imag: _
    },
    backend: a
  }),
      P = exponents$1(n, r),
      O = [P.real.length],
      M = a.makeTensorInfo(O, "float32", P.real),
      L = a.makeTensorInfo(O, "float32", P.imag),
      z = complex$4({
    inputs: {
      real: M,
      imag: L
    },
    backend: a
  }),
      B = multiply$4({
    inputs: {
      a: z,
      b: F
    },
    backend: a
  }),
      V = add$4({
    inputs: {
      a: N,
      b: B
    },
    backend: a
  }),
      G = sub$4({
    inputs: {
      a: N,
      b: B
    },
    backend: a
  }),
      U = real$4({
    inputs: {
      input: V
    },
    backend: a
  }),
      W = real$4({
    inputs: {
      input: G
    },
    backend: a
  }),
      q = imag$4({
    inputs: {
      input: V
    },
    backend: a
  }),
      H = imag$4({
    inputs: {
      input: G
    },
    backend: a
  }),
      K = concat$4({
    inputs: [U, W],
    backend: a,
    attrs: {
      axis: 0
    }
  }),
      j = concat$4({
    inputs: [q, H],
    backend: a,
    attrs: {
      axis: 0
    }
  }),
      X = a.data.get(K.dataId).values,
      Y = a.data.get(j.dataId).values;

  return a.disposeIntermediateTensorInfo(p), a.disposeIntermediateTensorInfo(d), a.disposeIntermediateTensorInfo(h), a.disposeIntermediateTensorInfo(y), a.disposeIntermediateTensorInfo(b), a.disposeIntermediateTensorInfo(x), a.disposeIntermediateTensorInfo(k), a.disposeIntermediateTensorInfo(T), a.disposeIntermediateTensorInfo(N), a.disposeIntermediateTensorInfo(R), a.disposeIntermediateTensorInfo(_), a.disposeIntermediateTensorInfo(F), a.disposeIntermediateTensorInfo(M), a.disposeIntermediateTensorInfo(L), a.disposeIntermediateTensorInfo(z), a.disposeIntermediateTensorInfo(B), a.disposeIntermediateTensorInfo(V), a.disposeIntermediateTensorInfo(G), a.disposeIntermediateTensorInfo(U), a.disposeIntermediateTensorInfo(q), a.disposeIntermediateTensorInfo(W), a.disposeIntermediateTensorInfo(H), a.disposeIntermediateTensorInfo(K), a.disposeIntermediateTensorInfo(j), {
    real: X,
    imag: Y
  };
}

function fourierTransformByMatmul$1(e, t, n) {
  var r = new Float32Array(2 * t);

  for (var a = 0; a < t; a++) {
    var s = 0,
        o = 0;

    for (var _r125 = 0; _r125 < t; _r125++) {
      var i = exponent$1(a * _r125, t, n),
          l = getComplexWithIndex$1(e, _r125);
      s += l.real * i.real - l.imag * i.imag, o += l.real * i.imag + l.imag * i.real;
    }

    n && (s /= t, o /= t), assignToTypedArray$1(r, s, o, a);
  }

  return r;
}

function fft$4(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    input: r
  } = t,
      a = sizeFromShape$1(r.shape),
      s = r.shape[r.shape.length - 1],
      o = reshape$5({
    inputs: {
      x: r
    },
    backend: n,
    attrs: {
      shape: [a / s, s]
    }
  }),
      i = fftBatch$1(o, !1, n),
      l = reshape$5({
    inputs: {
      x: i
    },
    backend: n,
    attrs: {
      shape: r.shape
    }
  });
  return n.disposeIntermediateTensorInfo(o), n.disposeIntermediateTensorInfo(i), l;
}

var fftConfig$3 = {
  kernelName: FFT$1,
  backendName: "cpu",
  kernelFunc: fft$4
};

function fill$4(e) {
  var {
    backend: t,
    attrs: n
  } = e,
      {
    shape: r,
    value: a,
    dtype: s
  } = n,
      o = s || inferDtype$1(a),
      i = getArrayFromDType$1(o, sizeFromShape$1(r));
  return fillValues$1(i, a, o), t.makeTensorInfo(r, o, i);
}

var fillConfig$3 = {
  kernelName: Fill$1,
  backendName: "cpu",
  kernelFunc: fill$4
};

function fillValues$1(e, t, n) {
  e.fill(t);
}

var flipLeftRightConfig$3 = {
  kernelName: FlipLeftRight$1,
  backendName: "cpu",
  kernelFunc: _ref10 => {
    var {
      inputs: e,
      backend: t
    } = _ref10;
    var {
      image: n
    } = e,
        r = t,
        a = getTypedArrayFromDType$1(n.dtype, sizeFromShape$1(n.shape)),
        [s, o, i, l] = n.shape,
        u = r.data.get(n.dataId).values;

    for (var _e357 = 0; _e357 < s; _e357++) {
      var _t261 = _e357 * i * o * l;

      for (var _e358 = 0; _e358 < o; _e358++) {
        var _n169 = _e358 * (i * l);

        for (var _e359 = 0; _e359 < i; _e359++) {
          var _r126 = _e359 * l;

          for (var _s62 = 0; _s62 < l; _s62++) {
            var _o47 = Math.round(i - _e359 - 1),
                c = _t261 + _n169 + _r126 + _s62;

            var _p12 = u[c];
            _o47 >= 0 && _o47 < i && (_p12 = u[_t261 + _n169 + _o47 * l + _s62]), a[c] = _p12;
          }
        }
      }
    }

    return {
      dataId: r.write(a, n.shape, n.dtype),
      shape: n.shape,
      dtype: n.dtype
    };
  }
},
    floorDivImpl$1 = createSimpleBinaryKernelImpl$1((e, t) => Math.floor(e / t)),
    floorDiv$4 = binaryKernelFunc$3(FloorDiv$1, floorDivImpl$1, null, "int32"),
    floorDivConfig$3 = {
  kernelName: FloorDiv$1,
  backendName: "cpu",
  kernelFunc: floorDiv$4
};

function fusedConv2D$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    filter: s,
    bias: o,
    preluActivationWeights: i
  } = t,
      {
    strides: l,
    pad: u,
    dataFormat: c,
    dilations: p,
    dimRoundingMode: d,
    activation: h,
    leakyreluAlpha: m
  } = r;
  var f = conv2D$1({
    inputs: {
      x: a,
      filter: s
    },
    backend: n,
    attrs: {
      strides: l,
      pad: u,
      dataFormat: c,
      dilations: p,
      dimRoundingMode: d
    }
  });

  if (o) {
    var _e360 = f;
    f = add$4({
      inputs: {
        a: f,
        b: o
      },
      backend: n
    }), n.disposeIntermediateTensorInfo(_e360);
  }

  if (h) {
    var _e361 = f;
    f = applyActivation$2(n, f, h, i, m), n.disposeIntermediateTensorInfo(_e361);
  }

  return f;
}

var fusedConv2DConfig$3 = {
  kernelName: FusedConv2D$1,
  backendName: "cpu",
  kernelFunc: fusedConv2D$1
};

function fusedDepthwiseConv2D$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    filter: s,
    bias: o,
    preluActivationWeights: i
  } = t,
      {
    strides: l,
    pad: u,
    dataFormat: c,
    dilations: p,
    dimRoundingMode: d,
    activation: h,
    leakyreluAlpha: m
  } = r;
  var f = depthwiseConv2dNative$3({
    inputs: {
      x: a,
      filter: s
    },
    backend: n,
    attrs: {
      strides: l,
      pad: u,
      dataFormat: c,
      dilations: p,
      dimRoundingMode: d
    }
  });

  if (o) {
    var _e362 = f;
    f = add$4({
      inputs: {
        a: f,
        b: o
      },
      backend: n
    }), n.disposeIntermediateTensorInfo(_e362);
  }

  if (h) {
    var _e363 = f;
    f = applyActivation$2(n, f, h, i, m), n.disposeIntermediateTensorInfo(_e363);
  }

  return f;
}

var fusedDepthwiseConv2DConfig$3 = {
  kernelName: FusedDepthwiseConv2D$1,
  backendName: "cpu",
  kernelFunc: fusedDepthwiseConv2D$3
};

function gatherNd$3(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    params: r,
    indices: a
  } = t,
      s = sizeFromShape$1(r.shape),
      o = a.shape,
      i = o[o.length - 1],
      [l, u, c, p] = prepareAndValidate$1(r, a);
  if (0 === u) return n.makeTensorInfo(l, r.dtype, []);
  var d = gatherNdImpl$1(n.data.get(a.dataId).values, n.bufferSync(r), r.dtype, u, i, c, p, r.shape, s);
  return n.makeTensorInfo(l, r.dtype, d.values);
}

var gatherNdConfig$3 = {
  kernelName: GatherNd$1,
  backendName: "cpu",
  kernelFunc: gatherNd$3
};

function gatherV2$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    indices: s
  } = t,
      {
    axis: o,
    batchDims: i
  } = r;
  assertNotComplex$3([a, s], "gatherV2");
  var l = i;
  null == i && (l = 0);
  var u = sizeFromShape$1(s.shape),
      c = collectGatherOpShapeInfo$1(a, s, parseAxisParam$1(o, a.shape)[0], l),
      p = reshape$5({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      shape: [c.batchSize, c.outerSize, c.dimSize, c.sliceSize]
    }
  }),
      d = reshape$5({
    inputs: {
      x: s
    },
    backend: n,
    attrs: {
      shape: [c.batchSize, u / c.batchSize]
    }
  }),
      h = [c.batchSize, c.outerSize, u / c.batchSize, c.sliceSize],
      m = n.bufferSync(d),
      f = gatherV2Impl$1(n.bufferSync(p), m, h);
  return n.disposeIntermediateTensorInfo(p), n.disposeIntermediateTensorInfo(d), n.makeTensorInfo(c.outputShape, f.dtype, f.values);
}

var gatherV2Config$3 = {
  kernelName: GatherV2$1,
  backendName: "cpu",
  kernelFunc: gatherV2$3
};

function ifft$4(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    input: r
  } = t,
      a = sizeFromShape$1(r.shape),
      s = r.shape[r.shape.length - 1],
      o = reshape$5({
    inputs: {
      x: r
    },
    backend: n,
    attrs: {
      shape: [a / s, s]
    }
  }),
      i = fftBatch$1(o, !0, n),
      l = reshape$5({
    inputs: {
      x: i
    },
    backend: n,
    attrs: {
      shape: r.shape
    }
  });
  return n.disposeIntermediateTensorInfo(o), n.disposeIntermediateTensorInfo(i), l;
}

var ifftConfig$3 = {
  kernelName: IFFT$1,
  backendName: "cpu",
  kernelFunc: ifft$4
},
    isFinite$5 = unaryKernelFunc$3(IsFinite$1, e => Number.isFinite(e) ? 1 : 0, "bool"),
    isFiniteConfig$3 = {
  kernelName: IsFinite$1,
  backendName: "cpu",
  kernelFunc: isFinite$5
},
    isInf$4 = unaryKernelFunc$3(IsInf$1, e => Infinity === Math.abs(e) ? 1 : 0, "bool"),
    isInfConfig$3 = {
  kernelName: IsInf$1,
  backendName: "cpu",
  kernelFunc: isInf$4
},
    isNaN$5 = unaryKernelFunc$3(IsNan$1, e => Number.isNaN(e) ? 1 : 0, "bool"),
    isNaNConfig$3 = {
  kernelName: IsNan$1,
  backendName: "cpu",
  kernelFunc: isNaN$5
};

function linSpace$3(e) {
  var {
    backend: t,
    attrs: n
  } = e,
      {
    start: r,
    stop: a,
    num: s
  } = n,
      o = linSpaceImpl$1(r, a, s);
  return t.makeTensorInfo([o.length], "float32", o);
}

var linSpaceConfig$3 = {
  kernelName: LinSpace$1,
  backendName: "cpu",
  kernelFunc: linSpace$3
},
    log1p$4 = unaryKernelFunc$3(Log1p$1, e => Math.log1p(e)),
    log1pConfig$3 = {
  kernelName: Log1p$1,
  backendName: "cpu",
  kernelFunc: log1p$4
},
    logicalAndImpl$1 = createSimpleBinaryKernelImpl$1((e, t) => e && t),
    logicalAnd$4 = binaryKernelFunc$3(LogicalAnd$1, logicalAndImpl$1, null, "bool"),
    logicalAndConfig$3 = {
  kernelName: LogicalAnd$1,
  backendName: "cpu",
  kernelFunc: logicalAnd$4
},
    logicalNot$4 = unaryKernelFunc$3(LogicalNot$1, e => e ? 0 : 1, "bool"),
    logicalNotConfig$3 = {
  kernelName: LogicalNot$1,
  backendName: "cpu",
  kernelFunc: logicalNot$4
},
    logicalOrImpl$1 = createSimpleBinaryKernelImpl$1((e, t) => e || t),
    logicalOr$4 = binaryKernelFunc$3(LogicalOr$1, logicalOrImpl$1, null, "bool"),
    logicalOrConfig$3 = {
  kernelName: LogicalOr$1,
  backendName: "cpu",
  kernelFunc: logicalOr$4
};

function lRN$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    depthRadius: s,
    bias: o,
    alpha: i,
    beta: l
  } = r;
  assertNotComplex$3(a, "LRN");
  var u = a.shape[3],
      c = u - 1,
      p = n.data.get(a.dataId).values,
      d = sizeFromShape$1(a.shape),
      h = new Float32Array(d);

  function m(e) {
    var t = e % u;
    var n = e - t + Math.max(0, t - s);
    var r = e - t + Math.min(t + s, c);
    var a = 0;

    for (; n <= r; n++) {
      var _e364 = p[n];
      a += _e364 * _e364;
    }

    return a;
  }

  for (var _e365 = 0; _e365 < d; _e365++) {
    var _t262 = m(_e365),
        _n170 = p[_e365] * Math.pow(o + i * _t262, -l);

    h[_e365] = _n170;
  }

  return n.makeTensorInfo(a.shape, a.dtype, h);
}

var lRNConfig$1 = {
  kernelName: LRN$1,
  backendName: "cpu",
  kernelFunc: lRN$1
};

function lRNGrad$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    y: s,
    dy: o
  } = t,
      {
    depthRadius: i,
    bias: l,
    alpha: u,
    beta: c
  } = r;
  assertNotComplex$3(o, "LRNGrad");
  var p = sizeFromShape$1(o.shape),
      d = o.shape[3],
      h = n.data.get(o.dataId).values,
      m = n.data.get(a.dataId).values,
      f = n.data.get(s.dataId).values,
      g = new Float32Array(p),
      $ = p;

  for (var _e366 = 0; _e366 < $; _e366++) {
    var _t263 = _e366 % d,
        _n171 = _e366 - _t263 + Math.max(0, _t263 - i),
        _r127 = _e366 - _t263 + Math.min(d, _t263 + i + 1);

    var _a92 = 0;

    for (var _e367 = _n171; _e367 < _r127; _e367++) {
      _a92 += Math.pow(m[_e367], 2);
    }

    _a92 = u * _a92 + l;

    for (var _t264 = _n171; _t264 < _r127; _t264++) {
      var _n172 = -2 * u * c * m[_t264] * f[_e366] / _a92;

      _e366 === _t264 && (_n172 += Math.pow(_a92, -c)), _n172 *= h[_e366], g[_t264] += _n172;
    }
  }

  return n.makeTensorInfo(o.shape, a.dtype, g);
}

var lRNGradConfig$1 = {
  kernelName: LRNGrad$1,
  backendName: "cpu",
  kernelFunc: lRNGrad$1
};

function max$5(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    reductionIndices: s,
    keepDims: o
  } = r,
      i = n;
  var l = a.shape;
  var u = l.length,
      c = parseAxisParam$1(s, l);
  var p = c;
  var d = getAxesPermutation$1(p, u);
  var h = i.data.get(a.dataId).values;

  if (null != d) {
    var _e368 = new Array(u);

    for (var _t265 = 0; _t265 < _e368.length; _t265++) {
      _e368[_t265] = l[d[_t265]];
    }

    h = transposeImpl$3(h, l, a.dtype, d, _e368), p = getInnerMostAxes$1(p.length, u), l = _e368;
  }

  assertNotComplex$3(a, "max"), assertAxesAreInnerMostDims$1("max", p, u);
  var [m, f] = computeOutAndReduceShapes$1(l, p),
      g = maxImpl$3(h, sizeFromShape$1(f), m, a.dtype),
      $ = i.write(g, m, a.dtype);
  var y = m;
  return o && (y = expandShapeToKeepDim$1(m, c)), {
    dataId: $,
    shape: y,
    dtype: a.dtype
  };
}

var maxConfig$3 = {
  kernelName: Max$1,
  backendName: "cpu",
  kernelFunc: max$5
};

function maxPool$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t;
  assertNotComplex$3(a, "maxPool");
  var {
    filterSize: s,
    strides: o,
    pad: i,
    dimRoundingMode: l
  } = r;
  assert$6(eitherStridesOrDilationsAreOne$1(o, 1), () => "Error in maxPool: Either strides or dilations must be 1. Got strides ".concat(o, " and dilations '1'"));
  var u = computePool2DInfo$1(a.shape, s, o, 1, i, l);
  var c;
  if (1 === u.filterWidth && 1 === u.filterHeight && arraysEqual$1(u.inShape, u.outShape)) c = identity$4({
    inputs: {
      x: a
    },
    backend: n
  });else {
    var _e369 = n.data.get(a.dataId).values,
        _t266 = computeStrides$1(a.shape),
        _r128 = pool$2(_e369, a.shape, a.dtype, _t266, u, "max");

    c = n.makeTensorInfo(u.outShape, a.dtype, _r128.values);
  }
  return c;
}

var maxPoolConfig$3 = {
  kernelName: MaxPool$1,
  backendName: "cpu",
  kernelFunc: maxPool$4
};

function maxPool3D$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    filterSize: s,
    strides: o,
    pad: i,
    dimRoundingMode: l,
    dataFormat: u
  } = r;
  assertNotComplex$3(a, "maxPool3d");
  var c = computePool3DInfo$1(a.shape, s, o, 1, i, l, u),
      p = pool3d$2(n.data.get(a.dataId).values, a.shape, a.dtype, computeStrides$1(a.shape), c, "max");
  return n.makeTensorInfo(p.shape, "float32", p.values);
}

var maxPool3DConfig$3 = {
  kernelName: MaxPool3D$1,
  backendName: "cpu",
  kernelFunc: maxPool3D$1
};

function maxPool3DGrad$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    dy: a,
    input: s
  } = t,
      {
    filterSize: o,
    strides: i,
    pad: l,
    dimRoundingMode: u
  } = r;
  assertNotComplex$3([a, s], "maxPool3DGrad");
  var c = computePool3DInfo$1(s.shape, o, i, 1, l, u),
      p = maxPool3dPositions$1(n.bufferSync(s), c),
      d = c.strideDepth,
      h = c.strideHeight,
      m = c.strideWidth,
      f = c.dilationDepth,
      g = c.dilationHeight,
      $ = c.dilationWidth,
      y = c.effectiveFilterDepth,
      b = c.effectiveFilterHeight,
      x = c.effectiveFilterWidth,
      v = y - 1 - c.padInfo.front,
      I = x - 1 - c.padInfo.left,
      C = b - 1 - c.padInfo.top,
      S = buffer$1(s.shape, "float32"),
      k = n.bufferSync(a);

  for (var _e370 = 0; _e370 < c.batchSize; ++_e370) {
    for (var _t267 = 0; _t267 < c.inChannels; ++_t267) {
      for (var _n173 = 0; _n173 < c.inDepth; ++_n173) {
        for (var _r129 = 0; _r129 < c.inHeight; ++_r129) {
          for (var _a93 = 0; _a93 < c.inWidth; ++_a93) {
            var _s63 = _n173 - v,
                _o48 = _r129 - C,
                _i30 = _a93 - I;

            var _l24 = 0;

            for (var _n174 = 0; _n174 < y; _n174 += f) {
              var _r130 = (_s63 + _n174) / d;

              if (!(_r130 < 0 || _r130 >= c.outDepth || Math.floor(_r130) !== _r130)) for (var _a94 = 0; _a94 < b; _a94 += g) {
                var _s64 = (_o48 + _a94) / h;

                if (!(_s64 < 0 || _s64 >= c.outHeight || Math.floor(_s64) !== _s64)) for (var _o49 = 0; _o49 < x; _o49 += $) {
                  var _u18 = (_i30 + _o49) / m;

                  if (_u18 < 0 || _u18 >= c.outWidth || Math.floor(_u18) !== _u18) continue;

                  var _d8 = y * b * x - 1 - p.get(_e370, _r130, _s64, _u18, _t267) === _n174 * b * x + _a94 * x + _o49 ? 1 : 0;

                  0 !== _d8 && (_l24 += k.get(_e370, _r130, _s64, _u18, _t267) * _d8);
                }
              }
            }

            S.set(_l24, _e370, _n173, _r129, _a93, _t267);
          }
        }
      }
    }
  }

  return n.makeTensorInfo(S.shape, S.dtype, S.values);
}

var maxPool3DGradConfig$2 = {
  kernelName: MaxPool3DGrad$1,
  backendName: "cpu",
  kernelFunc: maxPool3DGrad$3
};

function maxPoolGrad$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    dy: a,
    input: s,
    output: o
  } = t,
      i = s;
  assertNotComplex$3([s, o], "maxPoolGrad");
  var {
    filterSize: l,
    strides: u,
    pad: c,
    dimRoundingMode: p
  } = r,
      d = computePool2DInfo$1(i.shape, l, u, 1, c, p),
      h = n.data.get(i.dataId).values,
      m = buffer$1(d.outShape, i.dtype, maxPoolPositions$1(h, i.shape, i.dtype, d).values),
      f = d.strideHeight,
      g = d.strideWidth,
      $ = d.dilationHeight,
      y = d.dilationWidth,
      b = d.effectiveFilterHeight,
      x = d.effectiveFilterWidth,
      v = x - 1 - d.padInfo.left,
      I = b - 1 - d.padInfo.top,
      C = buffer$1(i.shape, "float32"),
      S = n.data.get(a.dataId).values,
      k = buffer$1(a.shape, "float32", S);

  for (var _e371 = 0; _e371 < d.batchSize; ++_e371) {
    for (var _t268 = 0; _t268 < d.inChannels; ++_t268) {
      for (var _n175 = 0; _n175 < d.inHeight; ++_n175) {
        for (var _r131 = 0; _r131 < d.inWidth; ++_r131) {
          var _a95 = _n175 - I,
              _s65 = _r131 - v;

          var _o50 = 0;

          for (var _n176 = 0; _n176 < b; _n176 += $) {
            var _r132 = (_a95 + _n176) / f;

            if (!(_r132 < 0 || _r132 >= d.outHeight || Math.floor(_r132) !== _r132)) for (var _a96 = 0; _a96 < x; _a96 += y) {
              var _i31 = (_s65 + _a96) / g;

              if (_i31 < 0 || _i31 >= d.outWidth || Math.floor(_i31) !== _i31) continue;

              var _l25 = b * x - 1 - m.get(_e371, _r132, _i31, _t268) === _n176 * x + _a96 ? 1 : 0;

              0 !== _l25 && (_o50 += k.get(_e371, _r132, _i31, _t268) * _l25);
            }
          }

          C.set(_o50, _e371, _n175, _r131, _t268);
        }
      }
    }
  }

  return n.makeTensorInfo(C.shape, C.dtype, C.values);
}

var maxPoolGradConfig$4 = {
  kernelName: MaxPoolGrad$1,
  backendName: "cpu",
  kernelFunc: maxPoolGrad$4
};

function maxPoolWithArgmaxImpl$3(e, t, n, r, a) {
  var s = pool$2(e, t, n, computeStrides$1(t), a, "max"),
      o = maxPoolPositions$1(e, t, n, a, !0, r);
  return [s.values, o.values];
}

var maxPoolWithArgmaxConfig$3 = {
  kernelName: MaxPoolWithArgmax$1,
  backendName: "cpu",
  kernelFunc: _ref11 => {
    var {
      inputs: e,
      attrs: t,
      backend: n
    } = _ref11;
    var {
      x: r
    } = e,
        {
      filterSize: a,
      strides: s,
      pad: o,
      includeBatchInIndex: i
    } = t,
        l = n;
    assertNotComplex$3(r, "MaxPoolWithArgmax");
    var u = l.data.get(r.dataId).values,
        c = computePool2DInfo$1(r.shape, a, s, [1, 1], o),
        [p, d] = maxPoolWithArgmaxImpl$3(u, r.shape, r.dtype, i, c),
        h = l.write(p, c.outShape, r.dtype),
        m = l.write(d, c.outShape, r.dtype);
    return [{
      dataId: h,
      shape: c.outShape,
      dtype: r.dtype
    }, {
      dataId: m,
      shape: c.outShape,
      dtype: "int32"
    }];
  }
};

function mean$2(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    axis: s,
    keepDims: o
  } = r,
      i = parseAxisParam$1(s, a.shape),
      l = sizeFromShape$1(computeOutAndReduceShapes$1(a.shape, i)[1]),
      u = [],
      c = n.makeTensorInfo([], "float32", new Float32Array([l]));
  u.push(c);
  var p = cast$5({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      dtype: "float32"
    }
  });
  u.push(p);
  var d = div$2({
    inputs: {
      a: p,
      b: c
    },
    backend: n
  });
  u.push(d);
  var h = sum$5({
    inputs: {
      x: d
    },
    backend: n,
    attrs: {
      axis: s,
      keepDims: o
    }
  });
  return u.forEach(e => n.disposeIntermediateTensorInfo(e)), h;
}

var meanConfig$3 = {
  kernelName: Mean$1,
  backendName: "cpu",
  kernelFunc: mean$2
};

function min$5(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    axis: s,
    keepDims: o
  } = r;
  assertNotComplex$3(a, "min");
  var i = parseAxisParam$1(s, a.shape);
  var l = i;
  var u = getAxesPermutation$1(l, a.shape.length);
  var c = a;
  null != u && (c = transpose$4({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      perm: u
    }
  }), l = getInnerMostAxes$1(l.length, a.shape.length)), assertAxesAreInnerMostDims$1("min", l, c.shape.length);
  var [p, d] = computeOutAndReduceShapes$1(c.shape, l),
      h = sizeFromShape$1(d),
      m = makeZerosTypedArray$1(sizeFromShape$1(p), c.dtype),
      f = n.data.get(c.dataId).values;

  for (var _e372 = 0; _e372 < m.length; ++_e372) {
    var _t269 = _e372 * h;

    var _n177 = f[_t269];

    for (var _e373 = 0; _e373 < h; ++_e373) {
      var _r133 = f[_t269 + _e373];
      (Number.isNaN(_r133) || _r133 < _n177) && (_n177 = _r133);
    }

    m[_e372] = _n177;
  }

  null != u && n.disposeIntermediateTensorInfo(c);
  var g = n.makeTensorInfo(p, c.dtype, m);

  if (o) {
    var _e374 = reshape$5({
      inputs: {
        x: g
      },
      backend: n,
      attrs: {
        shape: expandShapeToKeepDim$1(p, i)
      }
    });

    return n.disposeIntermediateTensorInfo(g), _e374;
  }

  return g;
}

var minConfig$3 = {
  kernelName: Min$1,
  backendName: "cpu",
  kernelFunc: min$5
};

function mirrorPad$2(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    paddings: s,
    mode: o
  } = r;
  assertNotComplex$3(a, "mirrorPad");
  var i = s.map((e, t) => e[0] + a.shape[t] + e[1]),
      l = s.map(e => e[0]),
      u = s.map((e, t) => e[0] + a.shape[t]),
      c = "reflect" === o ? 0 : 1,
      p = n.data.get(a.dataId).values,
      d = a.shape.length,
      h = computeStrides$1(a.shape),
      m = sizeFromShape$1(i),
      f = i.length,
      g = computeStrides$1(i),
      $ = getTypedArrayFromDType$1(a.dtype, m);

  for (var _e375 = 0; _e375 < m; _e375++) {
    var _t270 = indexToLoc$1(_e375, f, g);

    for (var _e376 = 0; _e376 < f; _e376++) {
      _t270[_e376] < l[_e376] ? _t270[_e376] = 2 * l[_e376] - _t270[_e376] - c : _t270[_e376] >= u[_e376] && (_t270[_e376] = 2 * (u[_e376] - 1) - _t270[_e376] + c);
    }

    _t270 = _t270.map((e, t) => e - l[t]);

    var _n178 = locToIndex$1(_t270, d, h);

    $[_e375] = p[_n178];
  }

  return {
    dataId: n.write($, i, a.dtype),
    shape: i,
    dtype: a.dtype
  };
}

var mirrorPadConfig$3 = {
  kernelName: MirrorPad$1,
  backendName: "cpu",
  kernelFunc: mirrorPad$2
},
    modImpl$1 = createSimpleBinaryKernelImpl$1((e, t) => {
  var n = e % t;
  return e < 0 && t < 0 || e >= 0 && t >= 0 ? n : (n + t) % t;
}),
    mod$4 = binaryKernelFunc$3(Mod$1, modImpl$1),
    modConfig$3 = {
  kernelName: Mod$1,
  backendName: "cpu",
  kernelFunc: mod$4
};

function softmax$5(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    logits: a
  } = t,
      {
    dim: s
  } = r,
      o = a.shape.length;
  var i = s;
  if (-1 === i && (i = o - 1), i !== o - 1) throw Error("Softmax along a non-last dimension is not yet supported. Logits was rank ".concat(o, " and dim was ").concat(i));
  var l = parseAxisParam$1([i], a.shape),
      u = max$5({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      reductionIndices: l,
      keepDims: !1
    }
  }),
      c = expandShapeToKeepDim$1(u.shape, l),
      p = reshape$5({
    inputs: {
      x: u
    },
    backend: n,
    attrs: {
      shape: c
    }
  }),
      d = sub$4({
    inputs: {
      a,
      b: p
    },
    backend: n
  }),
      h = exp$4({
    inputs: {
      x: d
    },
    backend: n
  }),
      m = sum$5({
    inputs: {
      x: h
    },
    backend: n,
    attrs: {
      axis: l,
      keepDims: !1
    }
  }),
      f = reshape$5({
    inputs: {
      x: m
    },
    backend: n,
    attrs: {
      shape: c
    }
  }),
      g = div$2({
    inputs: {
      a: h,
      b: f
    },
    backend: n
  });
  return n.disposeIntermediateTensorInfo(u), n.disposeIntermediateTensorInfo(p), n.disposeIntermediateTensorInfo(d), n.disposeIntermediateTensorInfo(h), n.disposeIntermediateTensorInfo(m), n.disposeIntermediateTensorInfo(f), g;
}

var softmaxConfig$3 = {
  kernelName: Softmax$5,
  backendName: "cpu",
  kernelFunc: softmax$5
};

function multinomial$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    logits: a
  } = t,
      {
    numSamples: s,
    seed: o,
    normalized: i
  } = r;
  assertNotComplex$3(a, "multinomial");
  var l = i ? a : softmax$5({
    inputs: {
      logits: a
    },
    backend: n,
    attrs: {
      dim: -1
    }
  }),
      u = l.shape[0],
      c = l.shape[1],
      p = n.data.get(l.dataId).values,
      d = [u, s],
      h = makeZerosTypedArray$1(sizeFromShape$1(d), "int32");

  for (var _e377 = 0; _e377 < u; ++_e377) {
    var _t271 = _e377 * c,
        _n179 = new Float32Array(c - 1);

    _n179[0] = p[_t271];

    for (var _e378 = 1; _e378 < _n179.length; ++_e378) {
      _n179[_e378] = _n179[_e378 - 1] + p[_t271 + _e378];
    }

    var _r134 = seedrandom$2.alea(o.toString()),
        _a97 = _e377 * s;

    for (var _e379 = 0; _e379 < s; ++_e379) {
      var _t272 = _r134();

      h[_a97 + _e379] = _n179.length;

      for (var _r135 = 0; _r135 < _n179.length; _r135++) {
        if (_t272 < _n179[_r135]) {
          h[_a97 + _e379] = _r135;
          break;
        }
      }
    }
  }

  return i || n.disposeIntermediateTensorInfo(l), n.makeTensorInfo(d, "int32", h);
}

var multinomialConfig$3 = {
  kernelName: Multinomial$1,
  backendName: "cpu",
  kernelFunc: multinomial$4
},
    nonMaxSuppressionV3Impl$4 = nonMaxSuppressionV3Impl$5;

function nonMaxSuppressionV3$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    boxes: a,
    scores: s
  } = t,
      {
    maxOutputSize: o,
    iouThreshold: i,
    scoreThreshold: l
  } = r;
  assertNotComplex$3(a, "NonMaxSuppression");
  var u = n.data.get(a.dataId).values,
      c = n.data.get(s.dataId).values,
      {
    selectedIndices: p
  } = nonMaxSuppressionV3Impl$4(u, c, o, i, l);
  return n.makeTensorInfo([p.length], "int32", new Int32Array(p));
}

var nonMaxSuppressionV3Config$3 = {
  kernelName: NonMaxSuppressionV3$1,
  backendName: "cpu",
  kernelFunc: nonMaxSuppressionV3$3
},
    nonMaxSuppressionV4Impl$4 = nonMaxSuppressionV4Impl$5;

function nonMaxSuppressionV4$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    boxes: a,
    scores: s
  } = t,
      {
    maxOutputSize: o,
    iouThreshold: i,
    scoreThreshold: l,
    padToMaxOutputSize: u
  } = r;
  assertNotComplex$3(a, "NonMaxSuppressionPadded");
  var c = n.data.get(a.dataId).values,
      p = n.data.get(s.dataId).values,
      {
    selectedIndices: d,
    validOutputs: h
  } = nonMaxSuppressionV4Impl$4(c, p, o, i, l, u);
  return [n.makeTensorInfo([d.length], "int32", new Int32Array(d)), n.makeTensorInfo([], "int32", new Int32Array([h]))];
}

var nonMaxSuppressionV4Config$3 = {
  kernelName: NonMaxSuppressionV4$1,
  backendName: "cpu",
  kernelFunc: nonMaxSuppressionV4$3
},
    nonMaxSuppressionV5Impl$4 = nonMaxSuppressionV5Impl$5;

function nonMaxSuppressionV5$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    boxes: a,
    scores: s
  } = t,
      {
    maxOutputSize: o,
    iouThreshold: i,
    scoreThreshold: l,
    softNmsSigma: u
  } = r;
  assertNotComplex$3(a, "NonMaxSuppressionWithScore");
  var c = n.data.get(a.dataId).values,
      p = n.data.get(s.dataId).values,
      d = o,
      h = i,
      m = l,
      f = u,
      {
    selectedIndices: g,
    selectedScores: $
  } = nonMaxSuppressionV5Impl$4(c, p, d, h, m, f);
  return [n.makeTensorInfo([g.length], "int32", new Int32Array(g)), n.makeTensorInfo([$.length], "float32", new Float32Array($))];
}

var nonMaxSuppressionV5Config$3 = {
  kernelName: NonMaxSuppressionV5$1,
  backendName: "cpu",
  kernelFunc: nonMaxSuppressionV5$3
};

function oneHot$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    indices: a
  } = t,
      {
    depth: s,
    onValue: o,
    offValue: i
  } = r;
  assertNotComplex$3(a, "oneHot");
  var l = sizeFromShape$1(a.shape),
      u = new Float32Array(l * s);
  u.fill(i);
  var c = n.data.get(a.dataId).values;

  for (var _e380 = 0; _e380 < l; ++_e380) {
    c[_e380] >= 0 && c[_e380] < s && (u[_e380 * s + c[_e380]] = o);
  }

  return n.makeTensorInfo([...a.shape, s], "int32", u);
}

var oneHotConfig$3 = {
  kernelName: OneHot$1,
  backendName: "cpu",
  kernelFunc: oneHot$4
};

function zerosLike$4(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    x: r
  } = t;
  if ("string" === r.dtype) throw new Error("zerosLike is not supported for string tensors");

  if ("complex64" === r.dtype) {
    var _e381 = real$4({
      inputs: {
        input: r
      },
      backend: n
    }),
        _t273 = zerosLike$4({
      inputs: {
        x: _e381
      },
      backend: n
    }),
        a = imag$4({
      inputs: {
        input: r
      },
      backend: n
    }),
        s = zerosLike$4({
      inputs: {
        x: a
      },
      backend: n
    }),
        o = complex$4({
      inputs: {
        real: _t273,
        imag: s
      },
      backend: n
    });

    return n.disposeIntermediateTensorInfo(_e381), n.disposeIntermediateTensorInfo(_t273), n.disposeIntermediateTensorInfo(a), n.disposeIntermediateTensorInfo(s), o;
  }

  return fill$4({
    backend: n,
    attrs: {
      shape: r.shape,
      value: 0,
      dtype: r.dtype
    }
  });
}

var zerosLikeConfig$3 = {
  kernelName: ZerosLike$1,
  backendName: "cpu",
  kernelFunc: zerosLike$4
};

function onesLike$4(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    x: r
  } = t;
  if ("string" === r.dtype) throw new Error("onesLike is not supported for string tensors");

  if ("complex64" === r.dtype) {
    var _e382 = real$4({
      inputs: {
        input: r
      },
      backend: n
    }),
        _t274 = onesLike$4({
      inputs: {
        x: _e382
      },
      backend: n
    }),
        a = imag$4({
      inputs: {
        input: r
      },
      backend: n
    }),
        s = zerosLike$4({
      inputs: {
        x: a
      },
      backend: n
    }),
        o = complex$4({
      inputs: {
        real: _t274,
        imag: s
      },
      backend: n
    });

    return n.disposeIntermediateTensorInfo(_e382), n.disposeIntermediateTensorInfo(_t274), n.disposeIntermediateTensorInfo(a), n.disposeIntermediateTensorInfo(s), o;
  }

  return fill$4({
    backend: n,
    attrs: {
      shape: r.shape,
      value: 1,
      dtype: r.dtype
    }
  });
}

var onesLikeConfig$3 = {
  kernelName: OnesLike$1,
  backendName: "cpu",
  kernelFunc: onesLike$4
};

function pack$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    axis: a
  } = r;
  if (1 === t.length) return expandDims$5({
    inputs: {
      input: t[0]
    },
    backend: n,
    attrs: {
      dim: a
    }
  });
  var s = t[0].shape,
      o = t[0].dtype;
  t.forEach(e => {
    assertShapesMatch$1(s, e.shape, "All tensors passed to stack must have matching shapes"), assert$6(o === e.dtype, () => "All tensors passed to stack must have matching dtypes");
  });
  var i = [],
      l = concat$4({
    inputs: t.map(e => {
      var t = expandDims$5({
        inputs: {
          input: e
        },
        backend: n,
        attrs: {
          dim: a
        }
      });
      return i.push(t), t;
    }),
    backend: n,
    attrs: {
      axis: a
    }
  });
  return i.forEach(e => n.disposeIntermediateTensorInfo(e)), l;
}

var packConfig$3 = {
  kernelName: Pack$1,
  backendName: "cpu",
  kernelFunc: pack$3
};

function padV2$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    paddings: s,
    constantValue: o
  } = r;
  assertNotComplex$3(a, "pad");
  var i = s.map((e, t) => e[0] + a.shape[t] + e[1]),
      l = s.map(e => e[0]),
      u = n.data.get(a.dataId).values,
      c = sizeFromShape$1(a.shape),
      p = a.shape.length,
      d = computeStrides$1(a.shape),
      h = sizeFromShape$1(i),
      m = i.length,
      f = computeStrides$1(i),
      g = getTypedArrayFromDType$1(a.dtype, h);
  0 !== o && g.fill(o);

  for (var _e383 = 0; _e383 < c; _e383++) {
    g[locToIndex$1(indexToLoc$1(_e383, p, d).map((e, t) => e + l[t]), m, f)] = u[_e383];
  }

  return {
    dataId: n.write(g, i, a.dtype),
    shape: i,
    dtype: a.dtype
  };
}

var padV2Config$3 = {
  kernelName: PadV2$1,
  backendName: "cpu",
  kernelFunc: padV2$3
},
    powImpl$1 = createSimpleBinaryKernelImpl$1((e, t) => Math.pow(e, t)),
    pow$4 = binaryKernelFunc$3(Pow$1, powImpl$1),
    powConfig$3 = {
  kernelName: Pow$1,
  backendName: "cpu",
  kernelFunc: pow$4
};

function range$6(e) {
  var {
    backend: t,
    attrs: n
  } = e,
      {
    start: r,
    stop: a,
    dtype: s,
    step: o
  } = n,
      i = rangeImpl$1(r, a, o, s);
  return t.makeTensorInfo([i.length], s, i);
}

var rangeConfig$3 = {
  kernelName: Range$1,
  backendName: "cpu",
  kernelFunc: range$6
},
    reciprocal$4 = unaryKernelFunc$3(Reciprocal$1, e => 1 / e),
    reciprocalConfig$3 = {
  kernelName: Reciprocal$1,
  backendName: "cpu",
  kernelFunc: reciprocal$4
};

function resizeBilinear$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    images: a
  } = t,
      {
    alignCorners: s,
    halfPixelCenters: o,
    size: i
  } = r;
  assertNotComplex$3(a, "resizeBilinear");
  var l = computeStrides$1(a.shape),
      [u, c] = i,
      [p, d, h, m] = a.shape,
      f = n.data.get(a.dataId).values,
      g = new Float32Array(sizeFromShape$1([p, u, c, m])),
      $ = [s && u > 1 ? d - 1 : d, s && c > 1 ? h - 1 : h],
      y = [s && u > 1 ? u - 1 : u, s && c > 1 ? c - 1 : c];
  var b = 0;
  var x = $[0] / y[0],
      v = $[1] / y[1];

  for (var _e384 = 0; _e384 < p; _e384++) {
    for (var _t275 = 0; _t275 < u; _t275++) {
      var _n180 = void 0;

      _n180 = o ? x * (_t275 + .5) - .5 : x * _t275;

      var _r136 = Math.max(0, Math.floor(_n180)),
          _a98 = _n180 - _r136,
          _s66 = Math.min(d - 1, Math.ceil(_n180)),
          _i32 = _e384 * l[0] + _r136 * l[1],
          _u19 = _e384 * l[0] + _s66 * l[1];

      for (var _e385 = 0; _e385 < c; _e385++) {
        var _t276 = void 0;

        _t276 = o ? v * (_e385 + .5) - .5 : v * _e385;

        var _n181 = Math.max(0, Math.floor(_t276)),
            _r137 = _t276 - _n181,
            _s67 = Math.min(h - 1, Math.ceil(_t276)),
            _c16 = _i32 + _n181 * l[2],
            _p13 = _u19 + _n181 * l[2],
            _d9 = _i32 + _s67 * l[2],
            _$4 = _u19 + _s67 * l[2];

        for (var _e386 = 0; _e386 < m; _e386++) {
          var _t277 = f[_c16 + _e386],
              _n182 = f[_p13 + _e386],
              _s68 = _t277 + (f[_d9 + _e386] - _t277) * _r137;

          g[b++] = _s68 + (_n182 + (f[_$4 + _e386] - _n182) * _r137 - _s68) * _a98;
        }
      }
    }
  }

  return n.makeTensorInfo([p, u, c, m], "float32", g);
}

var resizeBilinearConfig$3 = {
  kernelName: ResizeBilinear$1,
  backendName: "cpu",
  kernelFunc: resizeBilinear$4
};

function resizeBilinearGrad$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    images: a,
    dy: s
  } = t,
      {
    alignCorners: o
  } = r;
  assertNotComplex$3([s, a], "resizeBilinearGrad");
  var i = computeStrides$1(a.shape),
      [l, u, c, p] = a.shape,
      [, d, h] = s.shape,
      m = new Float32Array(l * u * c * p),
      f = [o && d > 1 ? u - 1 : u, o && h > 1 ? c - 1 : c],
      g = [o && d > 1 ? d - 1 : d, o && h > 1 ? h - 1 : h],
      $ = f[0] / g[0],
      y = f[1] / g[1],
      b = n.data.get(s.dataId).values;
  var x = 0;

  for (var _e387 = 0; _e387 < l; _e387++) {
    var _t278 = _e387 * i[0];

    for (var _e388 = 0; _e388 < d; _e388++) {
      var _n183 = _e388 * $,
          _r138 = Math.floor(_n183),
          _a99 = Math.min(Math.ceil(_n183), u - 1),
          _s69 = _t278 + _r138 * i[1],
          _o51 = _t278 + _a99 * i[1],
          _l26 = _n183 - _r138,
          _d10 = 1 - _l26;

      for (var _e389 = 0; _e389 < h; _e389++) {
        var _t279 = _e389 * y,
            _n184 = Math.floor(_t279),
            _r139 = Math.min(Math.ceil(_t279), c - 1),
            _a100 = _t279 - _n184,
            _u20 = 1 - _a100,
            _h9 = _s69 + _n184 * i[2],
            _f8 = _s69 + _r139 * i[2],
            _g3 = _o51 + _n184 * i[2],
            _$5 = _o51 + _r139 * i[2],
            v = _d10 * _u20,
            I = _d10 * _a100,
            C = _l26 * _u20,
            S = _l26 * _a100;

        for (var _e390 = 0; _e390 < p; _e390++) {
          var _t280 = b[x++];
          m[_h9 + _e390] += _t280 * v, m[_f8 + _e390] += _t280 * I, m[_g3 + _e390] += _t280 * C, m[_$5 + _e390] += _t280 * S;
        }
      }
    }
  }

  return n.makeTensorInfo([l, c, u, p], "float32", m);
}

var resizeBilinearGradConfig$4 = {
  kernelName: ResizeBilinearGrad$1,
  backendName: "cpu",
  kernelFunc: resizeBilinearGrad$3
};

function resizeNearestNeighbor$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    images: a
  } = t,
      {
    alignCorners: s,
    halfPixelCenters: o,
    size: i
  } = r;
  assertNotComplex$3(a, "resizeNearestNeighbor");
  var l = computeStrides$1(a.shape),
      [u, c] = i,
      [p, d, h, m] = a.shape,
      f = n.data.get(a.dataId).values,
      g = new Float32Array(p * u * c * m),
      $ = [s && u > 1 ? d - 1 : d, s && c > 1 ? h - 1 : h],
      y = [s && u > 1 ? u - 1 : u, s && c > 1 ? c - 1 : c],
      b = $[0] / y[0],
      x = $[1] / y[1];
  var v = 0;

  for (var _e391 = 0; _e391 < p; _e391++) {
    var _t281 = _e391 * l[0];

    for (var _e392 = 0; _e392 < u; _e392++) {
      var _n185 = o ? b * (_e392 + .5) : b * _e392;

      var _r140 = Math.min(d - 1, s ? Math.round(_n185) : Math.floor(_n185));

      o && (_r140 = Math.max(0, _r140));

      var _a101 = _t281 + _r140 * l[1];

      for (var _e393 = 0; _e393 < c; _e393++) {
        var _t282 = o ? x * (_e393 + .5) : x * _e393;

        var _n186 = Math.min(h - 1, s ? Math.round(_t282) : Math.floor(_t282));

        o && (_n186 = Math.max(0, _n186));

        var _r141 = _a101 + _n186 * l[2];

        for (var _e394 = 0; _e394 < m; _e394++) {
          g[v++] = f[_r141 + _e394];
        }
      }
    }
  }

  return n.makeTensorInfo([p, u, c, m], a.dtype, g);
}

var resizeNearestNeighborConfig$3 = {
  kernelName: ResizeNearestNeighbor$1,
  backendName: "cpu",
  kernelFunc: resizeNearestNeighbor$4
};

function resizeNearestNeighborGrad$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    images: a,
    dy: s
  } = t,
      {
    alignCorners: o
  } = r;
  assertNotComplex$3([s, a], "resizeNearestNeighborGrad");
  var i = computeStrides$1(a.shape),
      l = computeStrides$1(s.shape),
      [u, c, p, d] = a.shape,
      [, h, m] = s.shape,
      f = new Float32Array(u * c * p * d),
      g = n.data.get(s.dataId).values,
      $ = [o && h > 1 ? c - 1 : c, o && m > 1 ? p - 1 : p],
      y = [o && h > 1 ? h - 1 : h, o && m > 1 ? m - 1 : m],
      b = $[0] / y[0],
      x = $[1] / y[1],
      v = 1 / b,
      I = 1 / x,
      C = 2 * Math.ceil(v) + 2,
      S = 2 * Math.ceil(I) + 2;

  for (var _e395 = 0; _e395 < u; _e395++) {
    var _t283 = _e395 * i[0];

    for (var _e396 = 0; _e396 < c; _e396++) {
      var _n187 = _t283 + _e396 * i[1],
          _r142 = Math.floor(_e396 * v),
          _a102 = Math.floor(_r142 - C / 2);

      for (var _r143 = 0; _r143 < p; _r143++) {
        var _s70 = _n187 + _r143 * i[2],
            _u21 = Math.floor(_r143 * I),
            _$6 = Math.floor(_u21 - S / 2);

        for (var _n188 = 0; _n188 < d; _n188++) {
          var _i33 = 0;

          for (var _s71 = 0; _s71 < C; _s71++) {
            var _u22 = _s71 + _a102;

            if (_u22 < 0 || _u22 >= h) continue;

            var _d11 = _t283 + _u22 * l[1],
                _f9 = _u22 * b;

            if (_e396 === Math.min(c - 1, o ? Math.round(_f9) : Math.floor(_f9))) for (var _e397 = 0; _e397 < S; _e397++) {
              var _t284 = _e397 + _$6;

              if (_t284 < 0 || _t284 >= m) continue;

              var _a103 = _d11 + _t284 * l[2],
                  _s72 = _t284 * x;

              _r143 === Math.min(p - 1, o ? Math.round(_s72) : Math.floor(_s72)) && (_i33 += g[_a103 + _n188]);
            }
          }

          f[_s70 + _n188] = _i33;
        }
      }
    }
  }

  return n.makeTensorInfo(a.shape, a.dtype, f);
}

var resizeNearestNeighborGradConfig$4 = {
  kernelName: ResizeNearestNeighborGrad$1,
  backendName: "cpu",
  kernelFunc: resizeNearestNeighborGrad$3
};

function reverse$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    dims: s
  } = r;
  assertNotComplex$3(a, "reverse");
  var o = a.shape.length,
      i = parseAxisParam$1(s, a.shape);
  if (0 === o) return identity$4({
    inputs: {
      x: a
    },
    backend: n
  });
  var l = new TensorBuffer$1(a.shape, a.dtype),
      u = n.bufferSync(a);

  var _loop27 = function _loop27(_e398) {
    var t = l.indexToLoc(_e398),
        n = t.slice();
    i.forEach(e => n[e] = a.shape[e] - 1 - n[e]), l.set(u.get(...n), ...t);
  };

  for (var _e398 = 0; _e398 < l.size; _e398++) {
    _loop27(_e398);
  }

  return n.makeTensorInfo(l.shape, l.dtype, l.values);
}

var reverseConfig$3 = {
  kernelName: Reverse$1,
  backendName: "cpu",
  kernelFunc: reverse$4
},
    rotateWithOffsetConfig$3 = {
  kernelName: RotateWithOffset$1,
  backendName: "cpu",
  kernelFunc: _ref12 => {
    var {
      inputs: e,
      attrs: t,
      backend: n
    } = _ref12;
    var {
      image: r
    } = e,
        {
      radians: a,
      fillValue: s,
      center: o
    } = t,
        i = n,
        l = getTypedArrayFromDType$1(r.dtype, sizeFromShape$1(r.shape)),
        [u, c, p, d] = r.shape,
        [h, m] = getImageCenter$1(o, c, p),
        f = Math.sin(a),
        g = Math.cos(a),
        $ = i.data.get(r.dataId).values;

    for (var _e399 = 0; _e399 < u; _e399++) {
      var _t285 = _e399 * p * c * d;

      for (var _e400 = 0; _e400 < c; _e400++) {
        var _n189 = _e400 * (p * d);

        for (var _r144 = 0; _r144 < p; _r144++) {
          var _a104 = _r144 * d;

          for (var _o52 = 0; _o52 < d; _o52++) {
            var _i34 = [u, _e400, _r144, _o52],
                y = _i34[2],
                b = _i34[1];
            var x = (y - h) * g - (b - m) * f,
                v = (y - h) * f + (b - m) * g;
            x = Math.round(x + h), v = Math.round(v + m);
            var I = s;
            "number" != typeof s && (I = 3 === _o52 ? 255 : s[_o52]), x >= 0 && x < p && v >= 0 && v < c && (I = $[_t285 + v * (p * d) + x * d + _o52]), l[_t285 + _n189 + _a104 + _o52] = I;
          }
        }
      }
    }

    return {
      dataId: i.write(l, r.shape, r.dtype),
      shape: r.shape,
      dtype: r.dtype
    };
  }
},
    round$5 = unaryKernelFunc$3(Round$1, e => {
  var t = Math.floor(e);
  return e - t < .5 ? Math.floor(e) : e - t > .5 ? Math.ceil(e) : t % 2 == 0 ? t : t + 1;
}),
    roundConfig$3 = {
  kernelName: Round$1,
  backendName: "cpu",
  kernelFunc: round$5
};

function scatterImpl$1(e, t, n, r, a, s, o, i, l, u) {
  var c = [r / a, a],
      p = e.values,
      d = t.values;
  if (0 === r) return buffer$1(n, t.dtype);
  var h = buffer$1(c, t.dtype);
  h.values.fill(l);

  for (var _e401 = 0; _e401 < s; _e401++) {
    var _s73 = [];
    var _l27 = 0;

    for (var _t286 = 0; _t286 < o; _t286++) {
      var _n190 = p[_e401 * o + _t286];
      _s73.push(_n190), _l27 += _n190 * i[_t286];
    }

    if (_l27 < 0 || _l27 >= r / a) throw new Error("Invalid indices: ".concat(_s73, " does not index into ").concat(n));

    for (var _n191 = 0; _n191 < a; _n191++) {
      u ? h.values[_l27 * a + _n191] += d[_e401 * a + _n191] : h.values[_l27 * a + _n191] = 0 === t.rank ? d[0] : d[_e401 * a + _n191];
    }
  }

  return h;
}

function scatterNd$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    indices: a,
    updates: s
  } = t,
      {
    shape: o
  } = r,
      {
    sliceRank: i,
    numUpdates: l,
    sliceSize: u,
    strides: c,
    outputSize: p
  } = calculateShapes$1(s, a, o),
      d = scatterImpl$1(n.bufferSync(a), n.bufferSync(s), o, p, u, l, i, c, 0, !0);
  return n.makeTensorInfo(o, d.dtype, d.values);
}

var scatterNdConfig$3 = {
  kernelName: ScatterNd$1,
  backendName: "cpu",
  kernelFunc: scatterNd$3
};

function select$4(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    condition: r,
    t: a,
    e: s
  } = t;
  assertNotComplex$3([r, a, s], "select");
  var o = r.shape.length,
      i = n.data.get(r.dataId).values,
      l = n.data.get(a.dataId).values,
      u = n.data.get(s.dataId).values,
      c = upcastType$1(a.dtype, s.dtype),
      p = makeZerosTypedArray$1(sizeFromShape$1(a.shape), c);
  var d = 0;
  var h = 0 === o || o > 1 || 1 === a.shape.length ? 1 : sizeFromShape$1(a.shape.slice(1));

  for (var _e402 = 0; _e402 < i.length; _e402++) {
    for (var _t287 = 0; _t287 < h; _t287++) {
      p[d++] = 1 === i[_e402] ? l[_e402] : u[_e402];
    }
  }

  return n.makeTensorInfo(a.shape, c, p);
}

var selectConfig$3 = {
  kernelName: Select$1,
  backendName: "cpu",
  kernelFunc: select$4
},
    scaleAlpha$1 = SELU_SCALEALPHA$1,
    scale$1 = SELU_SCALE$1,
    selu$4 = unaryKernelFunc$3(Selu$3, e => e >= 0 ? scale$1 * e : scaleAlpha$1 * (Math.exp(e) - 1)),
    seluConfig$3 = {
  kernelName: Selu$3,
  backendName: "cpu",
  kernelFunc: selu$4
},
    sign$4 = unaryKernelFunc$3(Sign$1, e => e < 0 ? -1 : e > 0 ? 1 : 0),
    signConfig$3 = {
  kernelName: Sign$1,
  backendName: "cpu",
  kernelFunc: sign$4
},
    sin$4 = unaryKernelFunc$3(Sin$1, e => Math.sin(e)),
    sinConfig$3 = {
  kernelName: Sin$1,
  backendName: "cpu",
  kernelFunc: sin$4
},
    sinh$4 = unaryKernelFunc$3(Sinh$1, e => Math.sinh(e)),
    sinhConfig$3 = {
  kernelName: Sinh$1,
  backendName: "cpu",
  kernelFunc: sinh$4
},
    epsilon$2 = 1.1920928955078125e-7,
    threshold$2 = Math.log(epsilon$2) + 2,
    softplus$4 = unaryKernelFunc$3(Softplus$3, e => {
  var t = e > -threshold$2,
      n = e < threshold$2,
      r = Math.exp(e);
  var a;
  return a = n ? r : t ? e : Math.log(1 + r), a;
}),
    softplusConfig$3 = {
  kernelName: Softplus$3,
  backendName: "cpu",
  kernelFunc: softplus$4
};

function spaceToBatchND$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    blockShape: s,
    paddings: o
  } = r;
  assertNotComplex$3([a], "spaceToBatchND");
  var i = sizeFromShape$1(s),
      l = [[0, 0]];
  l.push(...o);

  for (var _e403 = 1 + s.length; _e403 < a.shape.length; ++_e403) {
    l.push([0, 0]);
  }

  var u = padV2Config$3.kernelFunc({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      paddings: l,
      constantValue: 0
    }
  }),
      c = getReshaped$1(u.shape, s, i, !1),
      p = getPermuted$1(c.length, s.length, !1),
      d = getReshapedPermuted$1(u.shape, s, i, !1),
      h = reshape$5({
    inputs: {
      x: u
    },
    backend: n,
    attrs: {
      shape: c
    }
  }),
      m = transpose$4({
    inputs: {
      x: h
    },
    backend: n,
    attrs: {
      perm: p
    }
  }),
      f = reshape$5({
    inputs: {
      x: m
    },
    backend: n,
    attrs: {
      shape: d
    }
  });
  return n.disposeIntermediateTensorInfo(u), n.disposeIntermediateTensorInfo(h), n.disposeIntermediateTensorInfo(m), f;
}

var spaceToBatchNDConfig$3 = {
  kernelName: SpaceToBatchND$1,
  backendName: "cpu",
  kernelFunc: spaceToBatchND$4
};

function sparseFillEmptyRows$4(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    indices: r,
    values: a,
    denseShape: s,
    defaultValue: o
  } = t;
  if (1 !== s.shape.length) throw new Error("Dense shape must be a vector, saw:\n        ".concat(s.shape));
  if (2 !== r.shape.length) throw new Error("Indices must be a matrix, saw:\n        ".concat(r.shape));
  if (1 !== a.shape.length) throw new Error("Values must be a vector, saw:\n        ".concat(a.shape));
  if (0 !== o.shape.length) throw new Error("Default value must be a scalar, saw:\n        ".concat(o.shape));
  var i = n.data.get(r.dataId).values,
      l = n.data.get(a.dataId).values,
      u = n.data.get(s.dataId).values,
      c = n.data.get(o.dataId).values[0],
      [p, d, h, m, f] = sparseFillEmptyRowsImpl$1(i, r.shape, r.dtype, l, a.dtype, u, c);
  return [n.makeTensorInfo(d, r.dtype, p), n.makeTensorInfo([d[0]], a.dtype, h), n.makeTensorInfo([m.length], "bool", new Uint8Array(m.map(e => Number(e)))), n.makeTensorInfo([f.length], r.dtype, new Int32Array(f))];
}

var sparseFillEmptyRowsConfig$3 = {
  kernelName: SparseFillEmptyRows$1,
  backendName: "cpu",
  kernelFunc: sparseFillEmptyRows$4
};

function sparseReshape$4(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    inputIndices: r,
    inputShape: a,
    newShape: s
  } = t;
  if (2 !== r.shape.length) throw new Error("Input indices should be a matrix but received shape\n        ".concat(r.shape));
  if (1 !== a.shape.length) throw new Error("Input shape should be a vector but received shape\n        ".concat(a.shape));
  if (1 !== s.shape.length) throw new Error("Target shape should be a vector but received shape ".concat(s.shape));
  var o = Array.from(n.data.get(a.dataId).values),
      i = n.data.get(r.dataId).values,
      l = Array.from(n.data.get(s.dataId).values),
      [u, c, p] = sparseReshapeImpl$1(i, r.shape, r.dtype, o, l);
  return [n.makeTensorInfo(c, r.dtype, u), n.makeTensorInfo([p.length], s.dtype, new Int32Array(p))];
}

var sparseReshapeConfig$3 = {
  kernelName: SparseReshape$1,
  backendName: "cpu",
  kernelFunc: sparseReshape$4
};

function sparseSegmentMean$4(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    data: r,
    indices: a,
    segmentIds: s
  } = t;
  if (r.shape.length < 1) throw new Error("Data should be at least 1 dimensional but received scalar");
  if (1 !== a.shape.length) throw new Error("Indices should be a vector but received shape\n          ".concat(a.shape));
  if (1 !== s.shape.length) throw new Error("Segment ids should be a vector but received shape\n          ".concat(s.shape));
  var o = n.data.get(r.dataId).values,
      i = n.data.get(a.dataId).values,
      l = n.data.get(s.dataId).values,
      [u, c] = sparseSegmentReductionImpl$1(o, r.shape, r.dtype, i, l, !0);
  return n.makeTensorInfo(c, r.dtype, u);
}

var sparseSegmentMeanConfig$3 = {
  kernelName: SparseSegmentMean$1,
  backendName: "cpu",
  kernelFunc: sparseSegmentMean$4
};

function sparseSegmentSum$4(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    data: r,
    indices: a,
    segmentIds: s
  } = t;
  if (r.shape.length < 1) throw new Error("Data should be at least 1 dimensional but received scalar");
  if (1 !== a.shape.length) throw new Error("Indices should be a vector but received shape\n         ".concat(a.shape));
  if (1 !== s.shape.length) throw new Error("Segment ids should be a vector but received shape\n         ".concat(s.shape));
  var o = n.data.get(r.dataId).values,
      i = n.data.get(a.dataId).values,
      l = n.data.get(s.dataId).values,
      [u, c] = sparseSegmentReductionImpl$1(o, r.shape, r.dtype, i, l);
  return n.makeTensorInfo(c, r.dtype, u);
}

var sparseSegmentSumConfig$3 = {
  kernelName: SparseSegmentSum$1,
  backendName: "cpu",
  kernelFunc: sparseSegmentSum$4
};

function sparseToDense$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    sparseIndices: a,
    sparseValues: s,
    defaultValue: o
  } = t,
      {
    outputShape: i
  } = r,
      {
    sliceRank: l,
    numUpdates: u,
    sliceSize: c,
    strides: p,
    outputSize: d
  } = calculateShapes$1(s, a, i),
      h = scatterImpl$1(n.bufferSync(a), n.bufferSync(s), i, d, c, u, l, p, n.data.get(o.dataId).values[0], !1);
  return n.makeTensorInfo(i, h.dtype, h.values);
}

var sparseToDenseConfig$3 = {
  kernelName: SparseToDense$1,
  backendName: "cpu",
  kernelFunc: sparseToDense$4
};

function splitV$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    numOrSizeSplits: s,
    axis: o
  } = r,
      i = parseAxisParam$1(o, a.shape)[0],
      l = prepareSplitSize$1(a, s, i),
      u = new Array(a.shape.length).fill(0),
      c = a.shape.slice();
  return l.map(e => {
    var t = [...c];
    t[i] = e;
    var r = slice$4({
      inputs: {
        x: a
      },
      backend: n,
      attrs: {
        begin: u,
        size: t
      }
    });
    return u[i] += e, r;
  });
}

var splitVConfig$3 = {
  kernelName: SplitV$1,
  backendName: "cpu",
  kernelFunc: splitV$3
},
    sqrt$4 = unaryKernelFunc$3(Sqrt$1, e => Math.sqrt(e)),
    sqrtConfig$3 = {
  kernelName: Sqrt$1,
  backendName: "cpu",
  kernelFunc: sqrt$4
},
    squareConfig$3 = {
  kernelName: Square$1,
  backendName: "cpu",
  kernelFunc: _ref13 => {
    var {
      inputs: e,
      backend: t
    } = _ref13;
    var {
      x: n
    } = e,
        r = t;
    assertNotComplex$3(n, "square");
    var a = r.data.get(n.dataId).values,
        s = new Float32Array(a.length);

    for (var _e404 = 0; _e404 < a.length; ++_e404) {
      var _t288 = a[_e404];
      s[_e404] = _t288 * _t288;
    }

    return {
      dataId: r.write(s, n.shape, n.dtype),
      shape: n.shape,
      dtype: n.dtype
    };
  }
},
    step$4 = unaryKernelFunc$3(Step$1, (e, t) => {
  var n = t;
  return isNaN(e) ? NaN : e > 0 ? 1 : n.alpha;
}),
    stepConfig$3 = {
  kernelName: Step$1,
  backendName: "cpu",
  kernelFunc: step$4
};

function stridedSlice$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    begin: s,
    end: o,
    strides: i,
    beginMask: l,
    endMask: u,
    ellipsisMask: c,
    newAxisMask: p,
    shrinkAxisMask: d
  } = r;
  assertNotComplex$3(a, "stridedSlice");
  var {
    nonStrided: h,
    $begin: m,
    $strides: f,
    size: g,
    newShape: $,
    outShape: y
  } = sliceInfo$1(a.shape, s, o, i, l, u, c, p, d),
      b = reshape$5({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      shape: $
    }
  });
  var x;

  if (h) {
    var _e405 = slice$4({
      inputs: {
        x: b
      },
      backend: n,
      attrs: {
        begin: m,
        size: g
      }
    });

    x = reshape$5({
      inputs: {
        x: _e405
      },
      backend: n,
      attrs: {
        shape: y
      }
    }), n.disposeIntermediateTensorInfo(_e405);
  } else if (y.some(e => 0 === e)) x = n.makeTensorInfo(y, a.dtype, []);else {
    var _e406 = stridedSliceImpl$1(y, n.bufferSync(b), f, m);

    x = n.makeTensorInfo(_e406.shape, _e406.dtype, _e406.values);
  }

  var v = reshape$5({
    inputs: {
      x
    },
    backend: n,
    attrs: {
      shape: y
    }
  });
  return n.disposeIntermediateTensorInfo(b), n.disposeIntermediateTensorInfo(x), v;
}

var stridedSliceConfig$3 = {
  kernelName: StridedSlice$1,
  backendName: "cpu",
  kernelFunc: stridedSlice$4
};

function stringNGrams$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    separator: a,
    nGramWidths: s,
    leftPad: o,
    rightPad: i,
    padWidth: l,
    preserveShortSequences: u
  } = r,
      {
    data: c,
    dataSplits: p
  } = t,
      d = n.data.get(c.dataId).values,
      h = n.data.get(p.dataId).values,
      [m, f] = stringNGramsImpl$1(d, h, a, s, o, i, l, u);
  return [n.makeTensorInfo([m.length], "string", m), n.makeTensorInfo(p.shape, "int32", f)];
}

var stringNGramsConfig$3 = {
  kernelName: StringNGrams$1,
  backendName: "cpu",
  kernelFunc: stringNGrams$4
};

function stringSplit$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    skipEmpty: a
  } = r,
      {
    input: s,
    delimiter: o
  } = t;
  if ("string" !== s.dtype) throw new Error("Input must be of datatype string");
  if (1 !== s.shape.length) throw new Error("Input must be a vector, got shape: ".concat(s.shape));
  if (0 !== o.shape.length) throw new Error("Delimiter must be a scalar, got shape: ".concat(o.shape));
  var i = n.data.get(s.dataId).values,
      l = n.data.get(o.dataId).values[0],
      [u, c, p] = stringSplitImpl$1(i, l, a),
      d = c.length;
  return [n.makeTensorInfo([d, 2], "int32", u), n.makeTensorInfo([d], "string", c), n.makeTensorInfo([2], "int32", new Int32Array(p))];
}

var stringSplitConfig$3 = {
  kernelName: StringSplit$1,
  backendName: "cpu",
  kernelFunc: stringSplit$4
};

function stringToHashBucketFast$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    numBuckets: a
  } = r,
      {
    input: s
  } = t;
  if ("string" !== s.dtype) throw new Error("Input must be of datatype string");
  if (a <= 0) throw new Error("Number of buckets must be at least 1");
  var o = stringToHashBucketFastImpl$1(n.data.get(s.dataId).values, a);
  return n.makeTensorInfo(s.shape, "int32", o);
}

var stringToHashBucketFastConfig$3 = {
  kernelName: StringToHashBucketFast$1,
  backendName: "cpu",
  kernelFunc: stringToHashBucketFast$4
},
    tan$4 = unaryKernelFunc$3(Tan$1, e => Math.tan(e)),
    tanConfig$3 = {
  kernelName: Tan$1,
  backendName: "cpu",
  kernelFunc: tan$4
},
    tanh$5 = unaryKernelFunc$3(Tanh$3, e => Math.tanh(e)),
    tanhConfig$3 = {
  kernelName: Tanh$3,
  backendName: "cpu",
  kernelFunc: tanh$5
};

function tile$5(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    reps: s
  } = r;
  assertNotComplex$3(a, "tile");
  var o = tileImpl$1(n.bufferSync(a), s);
  return n.makeTensorInfo(o.shape, o.dtype, o.values);
}

var tileConfig$3 = {
  kernelName: Tile$1,
  backendName: "cpu",
  kernelFunc: tile$5
};

function topK$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    k: s,
    sorted: o
  } = r;
  assertNotComplex$3(a, "topk");
  var i = n.data.get(a.dataId).values,
      [l, u] = topKImpl$1(i, a.shape, a.dtype, s, o);
  return [n.makeTensorInfo(l.shape, l.dtype, l.values), n.makeTensorInfo(u.shape, u.dtype, u.values)];
}

var topKConfig$3 = {
  kernelName: TopK$1,
  backendName: "cpu",
  kernelFunc: topK$3
};

function transform$4(e) {
  var {
    inputs: t,
    attrs: n,
    backend: r
  } = e,
      {
    image: a,
    transforms: s
  } = t,
      {
    interpolation: o,
    fillMode: i,
    fillValue: l,
    outputShape: u
  } = n,
      [c, p, d, h] = a.shape,
      [m, f] = null != u ? u : [p, d],
      g = [c, m, f, h],
      $ = computeStrides$1(a.shape),
      y = $[0],
      b = $[1],
      x = $[2],
      v = getTypedArrayFromDType$1(a.dtype, sizeFromShape$1(g));
  v.fill(l);
  var I = r.data.get(a.dataId).values,
      C = r.data.get(s.dataId).values;

  for (var _e407 = 0; _e407 < c; ++_e407) {
    var _t289 = 1 === s.shape[0] ? C : C.subarray(8 * _e407, 8 * _e407 + 8);

    for (var _n192 = 0; _n192 < m; ++_n192) {
      for (var _r145 = 0; _r145 < f; ++_r145) {
        for (var _a105 = 0; _a105 < h; ++_a105) {
          var _s74 = void 0;

          var _u23 = _t289[6] * _r145 + _t289[7] * _n192 + 1;

          if (0 === _u23) continue;

          var _c17 = (_t289[3] * _r145 + _t289[4] * _n192 + _t289[5]) / _u23,
              _h10 = mapCoord$1((_t289[0] * _r145 + _t289[1] * _n192 + _t289[2]) / _u23, d, i),
              _m4 = mapCoord$1(_c17, p, i);

          switch (o) {
            case "nearest":
              _s74 = nearestInterpolation$1(I, p, d, y, b, x, _e407, _m4, _h10, _a105, l);
              break;

            case "bilinear":
              _s74 = bilinearInterpolation$1(I, p, d, y, b, x, _e407, _m4, _h10, _a105, l);
              break;

            default:
              throw new Error("Error in Transform: Expect 'nearest' or 'bilinear', but got ".concat(o));
          }

          v[_e407 * y + _n192 * b + _r145 * x + _a105] = _s74;
        }
      }
    }

    return r.makeTensorInfo(g, a.dtype, v);
  }

  return {
    dataId: r.write(v, g, a.dtype),
    shape: a.shape,
    dtype: a.dtype
  };
}

var transformConfig$3 = {
  kernelName: Transform$1,
  backendName: "cpu",
  kernelFunc: transform$4
};

function mapCoord$1(e, t, n) {
  switch (n) {
    case "reflect":
      return mapCoordReflect$1(e, t);

    case "wrap":
      return mapCoordWrap$1(e, t);

    case "nearest":
      return mapCoordNearest$1(e, t);

    default:
      return mapCoordConstant$1(e);
  }
}

function mapCoordReflect$1(e, t) {
  var n = e;
  if (n < 0) {
    if (t <= 1) n = 0;else {
      var _e408 = 2 * t;

      n < _e408 && (n = _e408 * Math.trunc(-n / _e408) + n), n = n < -t ? n + _e408 : -n - 1;
    }
  } else if (n > t - 1) if (t <= 1) n = 0;else {
    var _e409 = 2 * t;

    n -= _e409 * Math.trunc(n / _e409), n >= t && (n = _e409 - n - 1);
  }
  return clamp$1(0, n, t - 1);
}

function mapCoordWrap$1(e, t) {
  var n = e;
  return n < 0 ? t <= 1 ? n = 0 : n += t * (Math.trunc(-n / (t - 1)) + 1) : n > t - 1 && (t <= 1 ? n = 0 : n -= t * Math.trunc(n / (t - 1))), clamp$1(0, n, t - 1);
}

function mapCoordConstant$1(e, t) {
  return e;
}

function mapCoordNearest$1(e, t) {
  return clamp$1(0, e, t - 1);
}

function readWithFillValue$1(e, t, n, r, a, s, o, i, l, u, c) {
  return 0 <= i && i < t && 0 <= l && l < n ? e[o * r + i * a + l * s + u] : c;
}

function nearestInterpolation$1(e, t, n, r, a, s, o, i, l, u, c) {
  return readWithFillValue$1(e, t, n, r, a, s, o, Math.round(i), Math.round(l), u, c);
}

function bilinearInterpolation$1(e, t, n, r, a, s, o, i, l, u, c) {
  var p = Math.floor(i),
      d = Math.floor(l),
      h = p + 1,
      m = d + 1;
  return (h - i) * ((m - l) * readWithFillValue$1(e, t, n, r, a, s, o, p, d, u, c) + (l - d) * readWithFillValue$1(e, t, n, r, a, s, o, p, m, u, c)) + (i - p) * ((m - l) * readWithFillValue$1(e, t, n, r, a, s, o, h, d, u, c) + (l - d) * readWithFillValue$1(e, t, n, r, a, s, o, h, m, u, c));
}

function unique$5(e) {
  var {
    inputs: t,
    attrs: n,
    backend: r
  } = e,
      {
    axis: a
  } = n,
      {
    x: s
  } = t;
  assertNotComplex$3(s, "unique");
  var o = r.data.get(s.dataId).values,
      {
    outputValues: i,
    outputShape: l,
    indices: u
  } = uniqueImpl$1(o, a, s.shape, s.dtype);
  return [r.makeTensorInfo(l, s.dtype, i), r.makeTensorInfo([u.length], "int32", u)];
}

var uniqueConfig$3 = {
  kernelName: Unique$1,
  backendName: "cpu",
  kernelFunc: unique$5
};

function unpack$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    value: a
  } = t;
  var {
    axis: s
  } = r;
  s < 0 && (s += a.shape.length);
  var o = a.shape.length,
      i = a.shape[s],
      l = new Array(o - 1);
  var u = 0;

  for (var _e410 = 0; _e410 < o; _e410++) {
    _e410 !== s && (l[u++] = a.shape[_e410]);
  }

  var c = new Array(o).fill(0),
      p = a.shape.slice();
  p[s] = 1;
  var d = new Array(i);

  for (var _e411 = 0; _e411 < d.length; _e411++) {
    c[s] = _e411;

    var _t290 = slice$4({
      inputs: {
        x: a
      },
      backend: n,
      attrs: {
        begin: c,
        size: p
      }
    });

    d[_e411] = reshape$5({
      inputs: {
        x: _t290
      },
      backend: n,
      attrs: {
        shape: l
      }
    }), n.disposeIntermediateTensorInfo(_t290);
  }

  return d;
}

var unpackConfig$3 = {
  kernelName: Unpack$1,
  backendName: "cpu",
  kernelFunc: unpack$3
};

function unsortedSegmentSum$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    segmentIds: s
  } = t,
      {
    numSegments: o
  } = r;
  assertNotComplex$3(a, "unsortedSegmentSum");
  var i = [],
      l = [],
      u = a.shape.length - s.shape.length;
  var c = s;

  for (var _e412 = 0; _e412 < u; ++_e412) {
    var _t291 = expandDims$5({
      inputs: {
        input: c
      },
      backend: n,
      attrs: {
        dim: _e412 + 1
      }
    });

    c = _t291, l.push(_t291);
  }

  for (var _e413 = 0; _e413 < o; ++_e413) {
    var _t292 = createScalarValue$1(_e413, "int32"),
        _r146 = n.makeTensorInfo([], "int32", _t292),
        _s75 = equal$4({
      inputs: {
        a: _r146,
        b: c
      },
      backend: n
    }),
        _o53 = cast$5({
      inputs: {
        x: _s75
      },
      backend: n,
      attrs: {
        dtype: "float32"
      }
    }),
        _u24 = multiply$4({
      inputs: {
        a: _o53,
        b: a
      },
      backend: n
    }),
        _p14 = sum$5({
      inputs: {
        x: _u24
      },
      backend: n,
      attrs: {
        axis: 0,
        keepDims: !1
      }
    });

    i.push(_p14), l.push(_r146), l.push(_s75), l.push(_o53), l.push(_u24), l.push(_p14);
  }

  var p = pack$3({
    inputs: i,
    backend: n,
    attrs: {
      axis: 0
    }
  });
  return l.forEach(e => n.disposeIntermediateTensorInfo(e)), p;
}

var unsortedSegmentSumConfig$3 = {
  kernelName: UnsortedSegmentSum$1,
  backendName: "cpu",
  kernelFunc: unsortedSegmentSum$4
},
    kernelConfigs$3 = [_fusedMatMulConfig$3, absConfig$3, acosConfig$3, acoshConfig$3, addConfig$3, addNConfig$3, allConfig$3, anyConfig$3, argMaxConfig$3, argMinConfig$3, asinConfig$3, asinhConfig$3, atanConfig$3, atan2Config$3, atanhConfig$3, avgPoolConfig$3, avgPool3DConfig$3, avgPool3DGradConfig$2, avgPoolGradConfig$4, batchMatMulConfig$3, batchNormConfig$3, batchToSpaceNDConfig$3, bincountConfig$3, castConfig$3, ceilConfig$3, clipConfig$1, complexConfig$3, complexAbsConfig$3, concatConfig$3, conv2DBackpropFilterConfig$3, conv2DBackpropInputConfig$3, conv2DConfig$3, conv3DBackpropFilterV2Config$3, conv3DBackpropInputV2Config$1, conv3DConfig$3, cosConfig$3, coshConfig$3, cropAndResizeConfig$3, cumsumConfig$3, denseBincountConfig$3, depthToSpaceConfig$3, depthwiseConv2dNativeConfig$3, depthwiseConv2dNativeBackpropFilterConfig$3, depthwiseConv2dNativeBackpropInputConfig$3, diagConfig$3, dilation2dConfig$1, dilation2dBackpropInputConfig$1, dilation2dBackpropFilterConfig$1, realDivConfig$3, einsumConfig$3, eluConfig$3, eluGradConfig$4, equalConfig$3, erfConfig$3, expConfig$3, expandDimsConfig$3, expm1Config$3, fftConfig$3, fillConfig$3, flipLeftRightConfig$3, floorConfig$3, floorDivConfig$3, fusedConv2DConfig$3, fusedDepthwiseConv2DConfig$3, gatherNdConfig$3, gatherV2Config$3, greaterConfig$3, greaterEqualConfig$3, identityConfig$3, ifftConfig$3, imagConfig$3, isFiniteConfig$3, isInfConfig$3, isNaNConfig$3, leakyReluConfig$3, lessConfig$3, lessEqualConfig$3, linSpaceConfig$3, logConfig$3, log1pConfig$3, logicalAndConfig$3, logicalNotConfig$3, logicalOrConfig$3, lRNConfig$1, lRNGradConfig$1, maximumConfig$3, maxPoolConfig$3, maxPool3DConfig$3, maxPool3DGradConfig$2, maxPoolGradConfig$4, maxPoolWithArgmaxConfig$3, maxConfig$3, meanConfig$3, minConfig$3, minimumConfig$3, mirrorPadConfig$3, modConfig$3, multinomialConfig$3, multiplyConfig$3, negConfig$3, nonMaxSuppressionV3Config$3, nonMaxSuppressionV4Config$3, nonMaxSuppressionV5Config$3, notEqualConfig$3, oneHotConfig$3, onesLikeConfig$3, packConfig$3, padV2Config$3, powConfig$3, preluConfig$3, prodConfig$3, rangeConfig$3, realConfig$3, reciprocalConfig$3, reluConfig$3, relu6Config$3, reshapeConfig$3, resizeBilinearConfig$3, resizeBilinearGradConfig$4, resizeNearestNeighborConfig$3, resizeNearestNeighborGradConfig$4, reverseConfig$3, rotateWithOffsetConfig$3, roundConfig$3, rsqrtConfig$3, scatterNdConfig$3, selectConfig$3, seluConfig$3, sigmoidConfig$3, signConfig$3, sinConfig$3, sinhConfig$3, sliceConfig$3, softmaxConfig$3, softplusConfig$3, spaceToBatchNDConfig$3, sparseFillEmptyRowsConfig$3, sparseReshapeConfig$3, sparseSegmentMeanConfig$3, sparseSegmentSumConfig$3, sparseToDenseConfig$3, splitVConfig$3, sqrtConfig$3, squareConfig$3, squaredDifferenceConfig$3, stepConfig$3, stridedSliceConfig$3, stringNGramsConfig$3, stringSplitConfig$3, stringToHashBucketFastConfig$3, subConfig$3, sumConfig$3, tanConfig$3, tanhConfig$3, tileConfig$3, topKConfig$3, transposeConfig$3, transformConfig$3, uniqueConfig$3, unpackConfig$3, unsortedSegmentSumConfig$3, zerosLikeConfig$3];

for (var _e414 of kernelConfigs$3) {
  registerKernel$1(_e414);
}

var contexts$1 = {},
    WEBGL_ATTRIBUTES$1 = {
  alpha: !1,
  antialias: !1,
  premultipliedAlpha: !1,
  preserveDrawingBuffer: !1,
  depth: !1,
  stencil: !1,
  failIfMajorPerformanceCaveat: !0
};

function setWebGLContext$1(e, t) {
  contexts$1[e] = t;
}

function getWebGLContext$1(e) {
  if (!(e in contexts$1)) {
    var _t293 = getWebGLRenderingContext$1(e);

    if (null === _t293) return console.log("Could not get context for WebGL version", e), null;
    contexts$1[e] = _t293;
  }

  var t = contexts$1[e];
  return t.isContextLost() ? (delete contexts$1[e], getWebGLContext$1(e)) : (t.disable(t.DEPTH_TEST), t.disable(t.STENCIL_TEST), t.disable(t.BLEND), t.disable(t.DITHER), t.disable(t.POLYGON_OFFSET_FILL), t.disable(t.SAMPLE_COVERAGE), t.enable(t.SCISSOR_TEST), t.enable(t.CULL_FACE), t.cullFace(t.BACK), contexts$1[e]);
}

function createCanvas$1(e) {
  if ("undefined" != typeof OffscreenCanvas && 2 === e) return new OffscreenCanvas(300, 150);
  if ("undefined" != typeof document) return document.createElement("canvas");
  throw new Error("Cannot create a canvas in this context");
}

function getWebGLRenderingContext$1(e) {
  if (1 !== e && 2 !== e) throw new Error("Cannot get WebGL rendering context, WebGL is disabled.");
  var t = createCanvas$1(e);
  return t.addEventListener("webglcontextlost", t => {
    t.preventDefault(), delete contexts$1[e];
  }, !1), 1 === e ? t.getContext("webgl", WEBGL_ATTRIBUTES$1) || t.getContext("experimental-webgl", WEBGL_ATTRIBUTES$1) : t.getContext("webgl2", WEBGL_ATTRIBUTES$1);
}

var PackingScheme$1, TextureUsage$1, PhysicalTextureType$1;

function getUnpackedMatrixTextureShapeWidthHeight$1(e, t) {
  return [t, e];
}

function getUnpackedArraySizeFromMatrixSize$1(e, t) {
  return e * t;
}

function getDenseTexShape$1(e) {
  var t = sizeFromShape$1(e);
  return sizeToSquarishShape$1(Math.ceil(t / 4));
}

function getPackedMatrixTextureShapeWidthHeight$1(e, t) {
  return [Math.max(1, Math.ceil(t / 2)), Math.max(1, Math.ceil(e / 2))];
}

function getPackedRGBAArraySizeFromMatrixShape$1(e, t) {
  var [n, r] = getPackedMatrixTextureShapeWidthHeight$1(e, t);
  return n * r * 4;
}

function getTextureConfig$1(e, t) {
  var n = e;
  var r, a, s, o, i, l, u, c, p, d;
  return 2 === env$1().getNumber("WEBGL_VERSION") ? (r = n.R32F, a = n.R16F, s = n.RGBA16F, o = n.RGBA32F, i = n.RED, u = 4, c = 1, p = n.HALF_FLOAT, d = n.FLOAT) : (r = e.RGBA, a = e.RGBA, s = e.RGBA, o = n.RGBA, i = e.RGBA, u = 4, c = 4, p = null != t ? t.HALF_FLOAT_OES : null, d = e.FLOAT), l = e.RGBA, {
    internalFormatFloat: r,
    internalFormatHalfFloat: a,
    internalFormatPackedHalfFloat: s,
    internalFormatPackedFloat: o,
    textureFormatFloat: i,
    downloadTextureFormat: l,
    downloadUnpackNumChannels: u,
    defaultNumChannels: c,
    textureTypeHalfFloat: p,
    textureTypeFloat: d
  };
}

function callAndCheck$1(e, t) {
  var n = t();
  return env$1().getBool("DEBUG") && checkWebGLError$1(e), n;
}

function checkWebGLError$1(e) {
  var t = e.getError();
  if (t !== e.NO_ERROR) throw new Error("WebGL Error: " + getWebGLErrorMessage$1(e, t));
}

!function (e) {
  e[e.DENSE = 0] = "DENSE", e[e.SHARED_BATCH = 1] = "SHARED_BATCH";
}(PackingScheme$1 || (PackingScheme$1 = {})), function (e) {
  e[e.RENDER = 0] = "RENDER", e[e.UPLOAD = 1] = "UPLOAD", e[e.PIXELS = 2] = "PIXELS", e[e.DOWNLOAD = 3] = "DOWNLOAD";
}(TextureUsage$1 || (TextureUsage$1 = {})), function (e) {
  e[e.UNPACKED_FLOAT16 = 0] = "UNPACKED_FLOAT16", e[e.UNPACKED_FLOAT32 = 1] = "UNPACKED_FLOAT32", e[e.PACKED_4X1_UNSIGNED_BYTE = 2] = "PACKED_4X1_UNSIGNED_BYTE", e[e.PACKED_2X2_FLOAT32 = 3] = "PACKED_2X2_FLOAT32", e[e.PACKED_2X2_FLOAT16 = 4] = "PACKED_2X2_FLOAT16";
}(PhysicalTextureType$1 || (PhysicalTextureType$1 = {}));
var MIN_FLOAT16$1 = 5.96e-8,
    MAX_FLOAT16$1 = 65504;

function canBeRepresented$1(e) {
  return !!(env$1().getBool("WEBGL_RENDER_FLOAT32_ENABLED") || 0 === e || MIN_FLOAT16$1 < Math.abs(e) && Math.abs(e) < MAX_FLOAT16$1);
}

function getWebGLErrorMessage$1(e, t) {
  switch (t) {
    case e.NO_ERROR:
      return "NO_ERROR";

    case e.INVALID_ENUM:
      return "INVALID_ENUM";

    case e.INVALID_VALUE:
      return "INVALID_VALUE";

    case e.INVALID_OPERATION:
      return "INVALID_OPERATION";

    case e.INVALID_FRAMEBUFFER_OPERATION:
      return "INVALID_FRAMEBUFFER_OPERATION";

    case e.OUT_OF_MEMORY:
      return "OUT_OF_MEMORY";

    case e.CONTEXT_LOST_WEBGL:
      return "CONTEXT_LOST_WEBGL";

    default:
      return "Unknown error code ".concat(t);
  }
}

function getExtensionOrThrow$1(e, t) {
  return throwIfNull$1(e, () => e.getExtension(t), 'Extension "' + t + '" not supported on this browser.');
}

function createVertexShader$3(e, t) {
  var n = throwIfNull$1(e, () => e.createShader(e.VERTEX_SHADER), "Unable to create vertex WebGLShader.");
  if (callAndCheck$1(e, () => e.shaderSource(n, t)), callAndCheck$1(e, () => e.compileShader(n)), !1 === e.getShaderParameter(n, e.COMPILE_STATUS)) throw console.log(e.getShaderInfoLog(n)), new Error("Failed to compile vertex shader.");
  return n;
}

function createFragmentShader$1(e, t) {
  var n = throwIfNull$1(e, () => e.createShader(e.FRAGMENT_SHADER), "Unable to create fragment WebGLShader.");
  if (callAndCheck$1(e, () => e.shaderSource(n, t)), callAndCheck$1(e, () => e.compileShader(n)), !1 === e.getShaderParameter(n, e.COMPILE_STATUS)) throw logShaderSourceAndInfoLog$1(t, e.getShaderInfoLog(n)), new Error("Failed to compile fragment shader.");
  return n;
}

var lineNumberRegex$1 = /ERROR: [0-9]+:([0-9]+):/g;

function logShaderSourceAndInfoLog$1(e, t) {
  var n = lineNumberRegex$1.exec(t);
  if (null == n) return console.log("Couldn't parse line number in error: ".concat(t)), void console.log(e);
  var r = +n[1],
      a = e.split("\n"),
      s = a.length.toString().length + 2,
      o = a.map((e, t) => rightPad$1((t + 1).toString(), s) + e);
  var i = 0;

  for (var _e415 = 0; _e415 < o.length; _e415++) {
    i = Math.max(o[_e415].length, i);
  }

  var l = o.slice(0, r - 1),
      u = o.slice(r - 1, r),
      c = o.slice(r);
  console.log(l.join("\n")), console.log(t.split("\n")[0]), console.log("%c ".concat(rightPad$1(u[0], i)), "border:1px solid red; background-color:#e3d2d2; color:#a61717"), console.log(c.join("\n"));
}

function createProgram$1(e) {
  return throwIfNull$1(e, () => e.createProgram(), "Unable to create WebGLProgram.");
}

function linkProgram$1(e, t) {
  if (callAndCheck$1(e, () => e.linkProgram(t)), !1 === e.getProgramParameter(t, e.LINK_STATUS)) throw console.log(e.getProgramInfoLog(t)), new Error("Failed to link vertex and fragment shaders.");
}

function validateProgram$1(e, t) {
  if (callAndCheck$1(e, () => e.validateProgram(t)), !1 === e.getProgramParameter(t, e.VALIDATE_STATUS)) throw console.log(e.getProgramInfoLog(t)), new Error("Shader program validation failed.");
}

function createStaticVertexBuffer$1(e, t) {
  var n = throwIfNull$1(e, () => e.createBuffer(), "Unable to create WebGLBuffer");
  return callAndCheck$1(e, () => e.bindBuffer(e.ARRAY_BUFFER, n)), callAndCheck$1(e, () => e.bufferData(e.ARRAY_BUFFER, t, e.STATIC_DRAW)), n;
}

function createStaticIndexBuffer$1(e, t) {
  var n = throwIfNull$1(e, () => e.createBuffer(), "Unable to create WebGLBuffer");
  return callAndCheck$1(e, () => e.bindBuffer(e.ELEMENT_ARRAY_BUFFER, n)), callAndCheck$1(e, () => e.bufferData(e.ELEMENT_ARRAY_BUFFER, t, e.STATIC_DRAW)), n;
}

function createTexture$1(e) {
  return throwIfNull$1(e, () => e.createTexture(), "Unable to create WebGLTexture.");
}

function validateTextureSize$1(e, t) {
  var n = env$1().getNumber("WEBGL_MAX_TEXTURE_SIZE");
  if (e <= 0 || t <= 0) throw new Error("Requested texture size [".concat(e, "x").concat(t, "] is invalid."));
  if (e > n || t > n) throw new Error("Requested texture size [".concat(e, "x").concat(t, "] greater than WebGL maximum on this browser / GPU [").concat(n, "x").concat(n, "]."));
}

function createFramebuffer$1(e) {
  return throwIfNull$1(e, () => e.createFramebuffer(), "Unable to create WebGLFramebuffer.");
}

function bindVertexBufferToProgramAttribute$1(e, t, n, r, a, s, o) {
  var i = e.getAttribLocation(t, n);
  return -1 !== i && (callAndCheck$1(e, () => e.bindBuffer(e.ARRAY_BUFFER, r)), callAndCheck$1(e, () => e.vertexAttribPointer(i, a, e.FLOAT, !1, s, o)), callAndCheck$1(e, () => e.enableVertexAttribArray(i)), !0);
}

function bindTextureUnit$1(e, t, n) {
  validateTextureUnit$1(e, n), callAndCheck$1(e, () => e.activeTexture(e.TEXTURE0 + n)), callAndCheck$1(e, () => e.bindTexture(e.TEXTURE_2D, t));
}

function getProgramUniformLocationOrThrow$1(e, t, n) {
  return throwIfNull$1(e, () => e.getUniformLocation(t, n), 'uniform "' + n + '" not present in program.');
}

function getProgramUniformLocation$1(e, t, n) {
  return e.getUniformLocation(t, n);
}

function bindTextureToProgramUniformSampler$1(e, t, n, r) {
  callAndCheck$1(e, () => bindTextureUnit$1(e, t, r)), callAndCheck$1(e, () => e.uniform1i(n, r));
}

function bindColorTextureToFramebuffer$1(e, t, n) {
  callAndCheck$1(e, () => e.bindFramebuffer(e.FRAMEBUFFER, n)), callAndCheck$1(e, () => e.framebufferTexture2D(e.FRAMEBUFFER, e.COLOR_ATTACHMENT0, e.TEXTURE_2D, t, 0));
}

function unbindColorTextureFromFramebuffer$1(e, t) {
  callAndCheck$1(e, () => e.bindFramebuffer(e.FRAMEBUFFER, t)), callAndCheck$1(e, () => e.framebufferTexture2D(e.FRAMEBUFFER, e.COLOR_ATTACHMENT0, e.TEXTURE_2D, null, 0));
}

function validateFramebuffer$1(e) {
  var t = e.checkFramebufferStatus(e.FRAMEBUFFER);
  if (t !== e.FRAMEBUFFER_COMPLETE) throw new Error("Error binding framebuffer: " + getFramebufferErrorMessage$1(e, t));
}

function getFramebufferErrorMessage$1(e, t) {
  switch (t) {
    case e.FRAMEBUFFER_INCOMPLETE_ATTACHMENT:
      return "FRAMEBUFFER_INCOMPLETE_ATTACHMENT";

    case e.FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT:
      return "FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT";

    case e.FRAMEBUFFER_INCOMPLETE_DIMENSIONS:
      return "FRAMEBUFFER_INCOMPLETE_DIMENSIONS";

    case e.FRAMEBUFFER_UNSUPPORTED:
      return "FRAMEBUFFER_UNSUPPORTED";

    default:
      return "unknown error ".concat(t);
  }
}

function throwIfNull$1(e, t, n) {
  var r = callAndCheck$1(e, () => t());
  if (null == r) throw new Error(n);
  return r;
}

function validateTextureUnit$1(e, t) {
  var n = e.MAX_COMBINED_TEXTURE_IMAGE_UNITS - 1,
      r = t + e.TEXTURE0;
  if (r < e.TEXTURE0 || r > n) throw new Error("textureUnit must be in [gl.TEXTURE0, gl.TEXTURE".concat(n, "]."));
}

function getBatchDim$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 2;
  return sizeFromShape$1(e.slice(0, e.length - t));
}

function getRowsCols$1(e) {
  if (0 === e.length) throw Error("Cannot get rows and columns of an empty shape array.");
  return [e.length > 1 ? e[e.length - 2] : 1, e[e.length - 1]];
}

function getShapeAs3D$1(e) {
  var t = [1, 1, 1];
  return 0 === e.length || 1 === e.length && 1 === e[0] || (t = [getBatchDim$1(e), ...getRowsCols$1(e)]), t;
}

function getTextureShapeFromLogicalShape$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;
  var n = env$1().getNumber("WEBGL_MAX_TEXTURE_SIZE");

  if (t && (n *= 2, 1 === (e = e.map((t, n) => n >= e.length - 2 ? nearestLargerEven$1(e[n]) : e[n])).length && (e = [2, e[0]])), 2 !== e.length) {
    var _t294 = squeezeShape$1(e);

    e = _t294.newShape;
  }

  var r = sizeFromShape$1(e);
  if (e.length <= 1 && r <= n) return [1, r];
  if (2 === e.length && e[0] <= n && e[1] <= n) return e;
  if (3 === e.length && e[0] * e[1] <= n && e[2] <= n) return [e[0] * e[1], e[2]];
  if (3 === e.length && e[0] <= n && e[1] * e[2] <= n) return [e[0], e[1] * e[2]];
  if (4 === e.length && e[0] * e[1] * e[2] <= n && e[3] <= n) return [e[0] * e[1] * e[2], e[3]];
  if (4 === e.length && e[0] <= n && e[1] * e[2] * e[3] <= n) return [e[0], e[1] * e[2] * e[3]];

  if (t) {
    var _t295 = getBatchDim$1(e);

    var _n193 = 2,
        a = 2;
    return e.length && ([_n193, a] = getRowsCols$1(e)), r = _t295 * (_n193 / 2) * (a / 2), sizeToSquarishShape$1(r).map(e => 2 * e);
  }

  return sizeToSquarishShape$1(r);
}

function isEven$1(e) {
  return e % 2 == 0;
}

function isReshapeFree$1(e, t) {
  if (arraysEqual$1(e = e.slice(-2), t = t.slice(-2))) return !0;
  if (!e.length || !t.length) return !0;
  if (0 === e[0] || 0 === e[1] || 0 === t[0] || 0 === t[1]) return !0;

  if (e.length !== t.length) {
    var n = e.slice(-1)[0],
        r = t.slice(-1)[0];
    if (n === r) return !0;
    if (isEven$1(n) && isEven$1(r) && (1 === e[0] || 1 === t[0])) return !0;
  }

  return e[1] === t[1] && isEven$1(e[0]) && isEven$1(t[0]);
}

var MAX_TEXTURE_SIZE$1, MAX_TEXTURES_IN_SHADER$1;

function getWebGLMaxTextureSize$1(e) {
  if (null == MAX_TEXTURE_SIZE$1) {
    var t = getWebGLContext$1(e);
    MAX_TEXTURE_SIZE$1 = t.getParameter(t.MAX_TEXTURE_SIZE);
  }

  return MAX_TEXTURE_SIZE$1;
}

function getMaxTexturesInShader$1(e) {
  if (null == MAX_TEXTURES_IN_SHADER$1) {
    var t = getWebGLContext$1(e);
    MAX_TEXTURES_IN_SHADER$1 = t.getParameter(t.MAX_TEXTURE_IMAGE_UNITS);
  }

  return Math.min(16, MAX_TEXTURES_IN_SHADER$1);
}

function getWebGLDisjointQueryTimerVersion$1(e) {
  if (0 === e) return 0;
  var t;
  var n = getWebGLContext$1(e);
  return t = hasExtension$1(n, "EXT_disjoint_timer_query_webgl2") && 2 === e ? 2 : hasExtension$1(n, "EXT_disjoint_timer_query") ? 1 : 0, t;
}

function hasExtension$1(e, t) {
  return null != e.getExtension(t);
}

function isWebGLVersionEnabled$1(e) {
  try {
    if (null != getWebGLContext$1(e)) return !0;
  } catch (e) {
    return console.log("Error when getting WebGL context: ", e), !1;
  }

  return !1;
}

function isCapableOfRenderingToFloatTexture$1(e) {
  if (0 === e) return !1;
  var t = getWebGLContext$1(e);

  if (1 === e) {
    if (!hasExtension$1(t, "OES_texture_float")) return !1;
  } else if (!hasExtension$1(t, "EXT_color_buffer_float")) return !1;

  return createFloatTextureAndBindToFramebuffer$1(t);
}

function isDownloadFloatTextureEnabled$1(e) {
  if (0 === e) return !1;
  var t = getWebGLContext$1(e);

  if (1 !== e) {
    if (hasExtension$1(t, "EXT_color_buffer_float")) return createFloatTextureAndBindToFramebuffer$1(t);
    var _e416 = "EXT_color_buffer_half_float";

    if (hasExtension$1(t, _e416)) {
      var n = t.getExtension(_e416);
      return createHalfFloatTextureAndBindToFramebuffer$1(t, n);
    }

    return !1;
  }

  return !!hasExtension$1(t, "OES_texture_float") && !!hasExtension$1(t, "WEBGL_color_buffer_float") && createFloatTextureAndBindToFramebuffer$1(t);
}

function createFloatTextureAndBindToFramebuffer$1(e) {
  var t = getTextureConfig$1(e),
      n = e.createTexture();
  e.bindTexture(e.TEXTURE_2D, n), e.texImage2D(e.TEXTURE_2D, 0, t.internalFormatFloat, 1, 1, 0, t.textureFormatFloat, t.textureTypeFloat, null);
  var r = e.createFramebuffer();
  e.bindFramebuffer(e.FRAMEBUFFER, r), e.framebufferTexture2D(e.FRAMEBUFFER, e.COLOR_ATTACHMENT0, e.TEXTURE_2D, n, 0);
  var a = e.checkFramebufferStatus(e.FRAMEBUFFER) === e.FRAMEBUFFER_COMPLETE;
  return e.bindTexture(e.TEXTURE_2D, null), e.bindFramebuffer(e.FRAMEBUFFER, null), e.deleteTexture(n), e.deleteFramebuffer(r), a;
}

function createHalfFloatTextureAndBindToFramebuffer$1(e, t) {
  var n = getTextureConfig$1(e, t),
      r = e.createTexture();
  e.bindTexture(e.TEXTURE_2D, r), e.texImage2D(e.TEXTURE_2D, 0, n.internalFormatHalfFloat, 1, 1, 0, n.textureFormatFloat, n.textureTypeHalfFloat, null);
  var a = e.createFramebuffer();
  e.bindFramebuffer(e.FRAMEBUFFER, a), e.framebufferTexture2D(e.FRAMEBUFFER, e.COLOR_ATTACHMENT0, e.TEXTURE_2D, r, 0);
  var s = e.checkFramebufferStatus(e.FRAMEBUFFER) === e.FRAMEBUFFER_COMPLETE;
  return e.bindTexture(e.TEXTURE_2D, null), e.bindFramebuffer(e.FRAMEBUFFER, null), e.deleteTexture(r), e.deleteFramebuffer(a), s;
}

function isWebGLFenceEnabled$1(e) {
  return 2 === e && null != getWebGLContext$1(e).fenceSync;
}

function assertNotComplex$2(e, t) {
  Array.isArray(e) || (e = [e]), e.forEach(e => {
    null != e && assert$6("complex64" !== e.dtype, () => "".concat(t, " does not support complex64 tensors in the WebGL backend."));
  });
}

var ENV$3 = env$1();

function getGlslDifferences$1() {
  var e, t, n, r, a, s, o, i, l, u;
  return 2 === env$1().getNumber("WEBGL_VERSION") ? (e = "#version 300 es", t = "in", n = "out", r = "in", a = "texture", s = "outputColor", o = "out vec4 outputColor;", i = "\n      bool isnan_custom(float val) {\n        return (val > 0.0 || val < 0.0) ? false : val != 0.0;\n      }\n\n      bvec4 isnan_custom(vec4 val) {\n        return bvec4(isnan_custom(val.x),\n          isnan_custom(val.y), isnan_custom(val.z), isnan_custom(val.w));\n      }\n\n      #define isnan(value) isnan_custom(value)\n    ", l = "", u = "\n      #define round(value) newRound(value)\n      int newRound(float value) {\n        return int(floor(value + 0.5));\n      }\n\n      ivec4 newRound(vec4 value) {\n        return ivec4(floor(value + vec4(0.5)));\n      }\n    ") : (e = "", t = "attribute", n = "varying", r = "varying", a = "texture2D", s = "gl_FragColor", o = "", i = "\n      #define isnan(value) isnan_custom(value)\n      bool isnan_custom(float val) {\n        return (val > 0. || val < 1. || val == 0.) ? false : true;\n      }\n      bvec4 isnan_custom(vec4 val) {\n        return bvec4(isnan(val.x), isnan(val.y), isnan(val.z), isnan(val.w));\n      }\n    ", l = "\n      uniform float INFINITY;\n\n      bool isinf(float val) {\n        return abs(val) == INFINITY;\n      }\n      bvec4 isinf(vec4 val) {\n        return equal(abs(val), vec4(INFINITY));\n      }\n    ", u = "\n      int round(float value) {\n        return int(floor(value + 0.5));\n      }\n\n      ivec4 round(vec4 value) {\n        return ivec4(floor(value + vec4(0.5)));\n      }\n    "), {
    version: e,
    attribute: t,
    varyingVs: n,
    varyingFs: r,
    texture2D: a,
    output: s,
    defineOutput: o,
    defineSpecialNaN: i,
    defineSpecialInf: l,
    defineRound: u
  };
}

function getLogicalCoordinatesFromFlatIndex$1(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : "index";
  var r = computeStrides$1(t);
  return r.map((t, a) => "int ".concat(e[a], " = ").concat(n, " / ").concat(t, "; ").concat(a === r.length - 1 ? "int ".concat(e[a + 1], " = ").concat(n, " - ").concat(e[a], " * ").concat(t) : "index -= ".concat(e[a], " * ").concat(t), ";")).join("");
}

function getLogicalCoordinatesFromFlatIndexByUniform$1(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : "index";
  var r = computeStrides$1(t);
  return r.map((t, a) => "int ".concat(e[a], " = ").concat(n, " / outShapeStrides[").concat(a, "]; ").concat(a === r.length - 1 ? "int ".concat(e[a + 1], " = ").concat(n, " - ").concat(e[a], " * outShapeStrides[").concat(a, "]") : "index -= ".concat(e[a], " * outShapeStrides[").concat(a, "]"), ";")).join("");
}

function getFlatIndexFrom3D$1(e) {
  var t = computeStrides$1(e).map(e => e.toString());
  return "\n  int getFlatIndex(ivec3 coords) {\n    return coords.x * ".concat(t[0], " + coords.y * ").concat(t[1], " + coords.z;\n  }\n");
}

ENV$3.registerFlag("HAS_WEBGL", () => ENV$3.getNumber("WEBGL_VERSION") > 0), ENV$3.registerFlag("WEBGL_VERSION", () => isWebGLVersionEnabled$1(2) ? 2 : isWebGLVersionEnabled$1(1) ? 1 : 0), ENV$3.registerFlag("WEBGL_CHECK_NUMERICAL_PROBLEMS", () => !1), ENV$3.registerFlag("WEBGL_BUFFER_SUPPORTED", () => 2 === ENV$3.get("WEBGL_VERSION")), ENV$3.registerFlag("WEBGL_CPU_FORWARD", () => !0), ENV$3.registerFlag("WEBGL_FORCE_F16_TEXTURES", () => !1), ENV$3.registerFlag("WEBGL_PACK", () => ENV$3.getBool("HAS_WEBGL")), ENV$3.registerFlag("WEBGL_PACK_NORMALIZATION", () => ENV$3.getBool("WEBGL_PACK")), ENV$3.registerFlag("WEBGL_PACK_CLIP", () => ENV$3.getBool("WEBGL_PACK")), ENV$3.registerFlag("WEBGL_PACK_DEPTHWISECONV", () => ENV$3.getBool("WEBGL_PACK")), ENV$3.registerFlag("WEBGL_PACK_BINARY_OPERATIONS", () => ENV$3.getBool("WEBGL_PACK")), ENV$3.registerFlag("WEBGL_PACK_UNARY_OPERATIONS", () => ENV$3.getBool("WEBGL_PACK")), ENV$3.registerFlag("WEBGL_PACK_ARRAY_OPERATIONS", () => ENV$3.getBool("WEBGL_PACK")), ENV$3.registerFlag("WEBGL_PACK_IMAGE_OPERATIONS", () => ENV$3.getBool("WEBGL_PACK")), ENV$3.registerFlag("WEBGL_PACK_REDUCE", () => ENV$3.getBool("WEBGL_PACK")), ENV$3.registerFlag("WEBGL_LAZILY_UNPACK", () => ENV$3.getBool("WEBGL_PACK")), ENV$3.registerFlag("WEBGL_CONV_IM2COL", () => ENV$3.getBool("WEBGL_PACK")), ENV$3.registerFlag("WEBGL_MAX_TEXTURE_SIZE", () => getWebGLMaxTextureSize$1(ENV$3.getNumber("WEBGL_VERSION"))), ENV$3.registerFlag("WEBGL_MAX_TEXTURES_IN_SHADER", () => getMaxTexturesInShader$1(ENV$3.getNumber("WEBGL_VERSION"))), ENV$3.registerFlag("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION", () => {
  var e = ENV$3.getNumber("WEBGL_VERSION");
  return 0 === e ? 0 : getWebGLDisjointQueryTimerVersion$1(e);
}), ENV$3.registerFlag("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE", () => ENV$3.getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") > 0 && !isMobile$1()), ENV$3.registerFlag("WEBGL_RENDER_FLOAT32_CAPABLE", () => isCapableOfRenderingToFloatTexture$1(ENV$3.getNumber("WEBGL_VERSION"))), ENV$3.registerFlag("WEBGL_RENDER_FLOAT32_ENABLED", () => !ENV$3.getBool("WEBGL_FORCE_F16_TEXTURES") && ENV$3.getBool("WEBGL_RENDER_FLOAT32_CAPABLE")), ENV$3.registerFlag("WEBGL_DOWNLOAD_FLOAT_ENABLED", () => isDownloadFloatTextureEnabled$1(ENV$3.getNumber("WEBGL_VERSION"))), ENV$3.registerFlag("WEBGL_FENCE_API_ENABLED", () => isWebGLFenceEnabled$1(ENV$3.getNumber("WEBGL_VERSION"))), ENV$3.registerFlag("WEBGL_SIZE_UPLOAD_UNIFORM", () => ENV$3.getBool("WEBGL_RENDER_FLOAT32_ENABLED") ? 4 : 0), ENV$3.registerFlag("WEBGL_DELETE_TEXTURE_THRESHOLD", () => -1, e => {
  if (e < 0 && -1 !== e) throw new Error("WEBGL_DELETE_TEXTURE_THRESHOLD must be -1 (indicating never delete) or at least 0, but got ".concat(e, "."));
}), ENV$3.registerFlag("WEBGL_FLUSH_THRESHOLD", () => isMobile$1() && ENV$3.getBool("IS_CHROME") ? 1 : -1, e => {
  if (e < 0 && -1 !== e) throw new Error("WEBGL_FLUSH_THRESHOLD must be -1 (indicating never manual flush) or at least 0, but got ".concat(e, "."));
}), ENV$3.registerFlag("CPU_HANDOFF_SIZE_THRESHOLD", () => 128), ENV$3.registerFlag("WEBGL_USE_SHAPES_UNIFORMS", () => !1), ENV$3.registerFlag("TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD", () => 1e5), ENV$3.registerFlag("TOPK_K_CPU_HANDOFF_THRESHOLD", () => 128);
var ENCODE_FLOAT_SNIPPET$1 = "\n  const float FLOAT_MAX = 1.70141184e38;\n  const float FLOAT_MIN = 1.17549435e-38;\n\n  lowp vec4 encode_float(highp float v) {\n    if (isnan(v)) {\n      return vec4(255, 255, 255, 255);\n    }\n\n    highp float av = abs(v);\n\n    if(av < FLOAT_MIN) {\n      return vec4(0.0, 0.0, 0.0, 0.0);\n    } else if(v > FLOAT_MAX) {\n      return vec4(0.0, 0.0, 128.0, 127.0) / 255.0;\n    } else if(v < -FLOAT_MAX) {\n      return vec4(0.0, 0.0,  128.0, 255.0) / 255.0;\n    }\n\n    highp vec4 c = vec4(0,0,0,0);\n\n    highp float e = floor(log2(av));\n    highp float m = exp2(fract(log2(av))) - 1.0;\n\n    c[2] = floor(128.0 * m);\n    m -= c[2] / 128.0;\n    c[1] = floor(32768.0 * m);\n    m -= c[1] / 32768.0;\n    c[0] = floor(8388608.0 * m);\n\n    highp float ebias = e + 127.0;\n    c[3] = floor(ebias / 2.0);\n    ebias -= c[3] * 2.0;\n    c[2] += floor(ebias) * 128.0;\n\n    c[3] += 128.0 * step(0.0, -v);\n\n    return c / 255.0;\n  }\n";

class DecodeMatrixProgram$1 {
  constructor(e) {
    this.variableNames = ["A"], this.packedInputs = !1, this.packedOutput = !0, this.outPackingScheme = PackingScheme$1.DENSE;
    var t = getDenseTexShape$1(e),
        n = getGlslDifferences$1();
    this.outputShape = e, this.userCode = "\n      ivec3 outCoordsFromFlatIndex(int index) {\n        ".concat(getLogicalCoordinatesFromFlatIndex$1(["r", "c", "d"], e), "\n        return ivec3(r, c, d);\n      }\n\n      void main() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n          vec2(").concat(t[0], ", ").concat(t[1], "));\n        int index = 4 * (resTexRC.x * ").concat(t[1], " + resTexRC.y);\n\n        vec4 result = vec4(0.);\n\n        for (int i=0; i<4; i++) {\n          int flatIndex = index + i;\n          ivec3 rc = outCoordsFromFlatIndex(flatIndex);\n          result[i] = getA(rc.x, rc.y, rc.z);\n        }\n\n        ").concat(n.output, " = result;\n      }\n    ");
  }

}

class DecodeMatrixPackedProgram$1 {
  constructor(e) {
    this.variableNames = ["A"], this.packedInputs = !0, this.packedOutput = !0, this.outPackingScheme = PackingScheme$1.DENSE;
    var t = getDenseTexShape$1(e),
        n = getGlslDifferences$1();
    this.outputShape = e, this.userCode = "\n      ivec3 outCoordsFromFlatIndex(int index) {\n        ".concat(getLogicalCoordinatesFromFlatIndex$1(["r", "c", "d"], e), "\n        return ivec3(r, c, d);\n      }\n\n      void main() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n          vec2(").concat(t[0], ", ").concat(t[1], "));\n        int index = 4 * (resTexRC.x * ").concat(t[1], " + resTexRC.y);\n\n        vec4 result = vec4(0.);\n\n        for (int i=0; i<4; i++) {\n          int flatIndex = index + i;\n          ivec3 rc = outCoordsFromFlatIndex(flatIndex);\n          result[i] = getChannel(getA(rc.x, rc.y, rc.z), vec2(rc.y, rc.z));\n        }\n\n        ").concat(n.output, " = result;\n      }\n    ");
  }

}

class EncodeFloatProgram$1 {
  constructor(e) {
    this.variableNames = ["A"], this.outTexUsage = TextureUsage$1.DOWNLOAD;
    var t = getGlslDifferences$1();
    this.outputShape = e, this.userCode = "\n      ".concat(ENCODE_FLOAT_SNIPPET$1, "\n\n      void main() {\n        float x = getAAtOutCoords();\n        ").concat(t.output, " = encode_float(x);\n      }\n    ");
  }

}

class EncodeFloatPackedProgram$1 {
  constructor(e) {
    this.variableNames = ["A"], this.packedInputs = !0, this.packedOutput = !1, this.outTexUsage = TextureUsage$1.DOWNLOAD;
    var t = getGlslDifferences$1();
    this.outputShape = e, this.userCode = "\n      ".concat(ENCODE_FLOAT_SNIPPET$1, "\n\n      void main() {\n        ivec3 coords = getOutputCoords();\n        float x = getChannel(getAAtOutCoords(), vec2(coords.y, coords.z));\n        ").concat(t.output, " = encode_float(x);\n      }\n    ");
  }

}

class EncodeMatrixProgram$1 {
  constructor(e, t) {
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
    this.variableNames = ["A"];
    var r = getGlslDifferences$1(),
        [a, s] = t;
    this.outputShape = e;
    var o = "result";
    n && (o = "floor(result * 255. + 0.5)"), this.userCode = "\n      ".concat(getFlatIndexFrom3D$1(e), "\n\n      void main() {\n        ivec3 coords = getOutputCoords();\n\n        int flatIndex = getFlatIndex(coords);\n        int offset = imod(flatIndex, 4);\n\n        flatIndex = idiv(flatIndex, 4, 1.);\n\n        int r = flatIndex / ").concat(s, ";\n        int c = imod(flatIndex, ").concat(s, ");\n        vec2 uv = (vec2(c, r) + halfCR) / vec2(").concat(s, ".0, ").concat(a, ".0);\n        vec4 values = ").concat(r.texture2D, "(A, uv);\n\n        float result;\n\n        if(offset == 0) {\n          result = values[0];\n        } else if(offset == 1) {\n          result = values[1];\n        } else if(offset == 2) {\n          result = values[2];\n        } else {\n          result = values[3];\n        }\n\n        ").concat(r.output, " = vec4(").concat(o, ", 0., 0., 0.);\n      }\n    ");
  }

}

class EncodeMatrixPackedProgram$1 {
  constructor(e, t) {
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
    this.variableNames = ["A"], this.packedInputs = !1, this.packedOutput = !0;
    var r = getGlslDifferences$1(),
        [a, s] = t;
    this.outputShape = e;
    var o = "",
        i = "result";
    n && (i = "floor(result * 255. + 0.5)");

    for (var _t296 = 0; _t296 <= 1; _t296++) {
      for (var _n194 = 0; _n194 <= 1; _n194++) {
        var _i35 = 2 * _t296 + _n194;

        o += "\n          localCoords = coords;\n          if(localCoords[2] + ".concat(_n194, " < ").concat(e[2], ") {\n            localCoords[2] += ").concat(_n194, ";\n            if(localCoords[1] + ").concat(_t296, " < ").concat(e[1], ") {\n              localCoords[1] += ").concat(_t296, ";\n\n              flatIndex = getFlatIndex(localCoords);\n              offset = imod(flatIndex, 4);\n\n              flatIndex = idiv(flatIndex, 4, 1.);\n\n              r = flatIndex / ").concat(s, ";\n              c = imod(flatIndex, ").concat(s, ");\n              uv = (vec2(c, r) + halfCR) / vec2(").concat(s, ".0, ").concat(a, ".0);\n              values = ").concat(r.texture2D, "(A, uv);\n\n              if(offset == 0) {\n                result[").concat(_i35, "] = values[0];\n              } else if(offset == 1) {\n                result[").concat(_i35, "] = values[1];\n              } else if(offset == 2) {\n                result[").concat(_i35, "] = values[2];\n              } else {\n                result[").concat(_i35, "] = values[3];\n              }\n            }\n          }\n        ");
      }
    }

    this.userCode = "\n      ".concat(getFlatIndexFrom3D$1(e), "\n\n      void main() {\n        ivec3 coords = getOutputCoords();\n\n        vec4 result = vec4(0.);\n        int flatIndex, r, c, offset;\n        ivec3 localCoords;\n        vec2 uv;\n        vec4 values;\n\n        ").concat(o, "\n\n        ").concat(r.output, " = ").concat(i, ";\n      }\n    ");
  }

}

function createVertexShader$2(e) {
  var t = getGlslDifferences$1();
  return createVertexShader$3(e, "".concat(t.version, "\n    precision highp float;\n    ").concat(t.attribute, " vec3 clipSpacePos;\n    ").concat(t.attribute, " vec2 uv;\n    ").concat(t.varyingVs, " vec2 resultUV;\n\n    void main() {\n      gl_Position = vec4(clipSpacePos, 1);\n      resultUV = uv;\n    }"));
}

function createVertexBuffer$1(e) {
  return createStaticVertexBuffer$1(e, new Float32Array([-1, 1, 0, 0, 1, -1, -1, 0, 0, 0, 1, 1, 0, 1, 1, 1, -1, 0, 1, 0]));
}

function createIndexBuffer$1(e) {
  return createStaticIndexBuffer$1(e, new Uint16Array([0, 1, 2, 2, 1, 3]));
}

function createAndConfigureTexture$1(e, t, n, r, a, s) {
  validateTextureSize$1(t, n);
  var o = createTexture$1(e),
      i = e.TEXTURE_2D;
  return callAndCheck$1(e, () => e.bindTexture(i, o)), callAndCheck$1(e, () => e.texParameteri(i, e.TEXTURE_WRAP_S, e.CLAMP_TO_EDGE)), callAndCheck$1(e, () => e.texParameteri(i, e.TEXTURE_WRAP_T, e.CLAMP_TO_EDGE)), callAndCheck$1(e, () => e.texParameteri(i, e.TEXTURE_MIN_FILTER, e.NEAREST)), callAndCheck$1(e, () => e.texParameteri(i, e.TEXTURE_MAG_FILTER, e.NEAREST)), callAndCheck$1(e, () => e.texImage2D(i, 0, r, t, n, 0, a, s, null)), callAndCheck$1(e, () => e.bindTexture(e.TEXTURE_2D, null)), o;
}

function getInternalFormatForFloat32MatrixTexture$1(e) {
  return e.internalFormatFloat;
}

function createFloat32MatrixTexture$1(e, t, n, r) {
  var [a, s] = getUnpackedMatrixTextureShapeWidthHeight$1(t, n);
  return createAndConfigureTexture$1(e, a, s, getInternalFormatForFloat32MatrixTexture$1(r), r.textureFormatFloat, e.FLOAT);
}

function getInternalFormatForFloat16MatrixTexture$1(e) {
  return e.internalFormatHalfFloat;
}

function createFloat16MatrixTexture$1(e, t, n, r) {
  var [a, s] = getUnpackedMatrixTextureShapeWidthHeight$1(t, n);
  return createAndConfigureTexture$1(e, a, s, getInternalFormatForFloat16MatrixTexture$1(r), r.textureFormatFloat, r.textureTypeHalfFloat);
}

function getInternalFormatForUnsignedBytesMatrixTexture$1(e) {
  return e.downloadTextureFormat;
}

function createUnsignedBytesMatrixTexture$1(e, t, n, r) {
  var [a, s] = getUnpackedMatrixTextureShapeWidthHeight$1(t, n);
  return createAndConfigureTexture$1(e, a, s, getInternalFormatForUnsignedBytesMatrixTexture$1(r), e.RGBA, e.UNSIGNED_BYTE);
}

function getInternalFormatForPackedMatrixTexture$1(e) {
  return e.internalFormatPackedFloat;
}

function createPackedMatrixTexture$1(e, t, n, r) {
  var [a, s] = getPackedMatrixTextureShapeWidthHeight$1(t, n);
  return createAndConfigureTexture$1(e, a, s, getInternalFormatForPackedMatrixTexture$1(r), e.RGBA, e.FLOAT);
}

function getInternalFormatForFloat16PackedMatrixTexture$1(e) {
  return e.internalFormatPackedHalfFloat;
}

function createFloat16PackedMatrixTexture$1(e, t, n, r) {
  var [a, s] = getPackedMatrixTextureShapeWidthHeight$1(t, n);
  return createAndConfigureTexture$1(e, a, s, getInternalFormatForFloat16PackedMatrixTexture$1(r), e.RGBA, r.textureTypeHalfFloat);
}

function bindVertexProgramAttributeStreams$1(e, t, n) {
  return callAndCheck$1(e, () => e.bindBuffer(e.ARRAY_BUFFER, n)), bindVertexBufferToProgramAttribute$1(e, t, "clipSpacePos", n, 3, 20, 0) && bindVertexBufferToProgramAttribute$1(e, t, "uv", n, 2, 20, 12);
}

function uploadDenseMatrixToTexture$1(e, t, n, r, a, s) {
  var o, i, l;
  callAndCheck$1(e, () => e.bindTexture(e.TEXTURE_2D, t)), a instanceof Uint8Array ? (o = new Uint8Array(n * r * 4), i = e.UNSIGNED_BYTE, l = e.RGBA) : (o = new Float32Array(n * r * 4), i = e.FLOAT, l = s.internalFormatPackedFloat), o.set(a), callAndCheck$1(e, () => e.texImage2D(e.TEXTURE_2D, 0, l, n, r, 0, e.RGBA, i, o)), callAndCheck$1(e, () => e.bindTexture(e.TEXTURE_2D, null));
}

function uploadPixelDataToTexture$1(e, t, n) {
  callAndCheck$1(e, () => e.bindTexture(e.TEXTURE_2D, t)), n.data instanceof Uint8Array ? callAndCheck$1(e, () => e.texImage2D(e.TEXTURE_2D, 0, e.RGBA, n.width, n.height, 0, e.RGBA, e.UNSIGNED_BYTE, n.data)) : callAndCheck$1(e, () => e.texImage2D(e.TEXTURE_2D, 0, e.RGBA, e.RGBA, e.UNSIGNED_BYTE, n)), callAndCheck$1(e, () => e.bindTexture(e.TEXTURE_2D, null));
}

function createBufferFromOutputTexture$1(e, t, n, r) {
  var a = e.createBuffer();
  callAndCheck$1(e, () => e.bindBuffer(e.PIXEL_PACK_BUFFER, a));
  var s = 16 * t * n;
  return callAndCheck$1(e, () => e.bufferData(e.PIXEL_PACK_BUFFER, s, e.STREAM_READ)), callAndCheck$1(e, () => e.readPixels(0, 0, n, t, e.RGBA, e.FLOAT, 0)), callAndCheck$1(e, () => e.bindBuffer(e.PIXEL_PACK_BUFFER, null)), a;
}

function downloadFloat32MatrixFromBuffer$1(e, t, n) {
  var r = e,
      a = new Float32Array(n);
  return r.bindBuffer(r.PIXEL_PACK_BUFFER, t), r.getBufferSubData(r.PIXEL_PACK_BUFFER, 0, a), r.bindBuffer(r.PIXEL_PACK_BUFFER, null), a;
}

function downloadByteEncodedFloatMatrixFromOutputTexture$1(e, t, n, r) {
  var [a, s] = getUnpackedMatrixTextureShapeWidthHeight$1(t, n),
      o = new Uint8Array(getUnpackedArraySizeFromMatrixSize$1(t * n, 4));
  return callAndCheck$1(e, () => e.readPixels(0, 0, a, s, r.downloadTextureFormat, e.UNSIGNED_BYTE, o)), new Float32Array(o.buffer);
}

function downloadPackedMatrixFromBuffer$1(e, t, n, r, a, s, o, i) {
  var l = e,
      u = new Float32Array(getPackedRGBAArraySizeFromMatrixShape$1(s, o));
  return l.bindBuffer(l.PIXEL_PACK_BUFFER, t), l.getBufferSubData(l.PIXEL_PACK_BUFFER, 0, u), l.bindBuffer(l.PIXEL_PACK_BUFFER, null), u;
}

function downloadMatrixFromPackedOutputTexture$1(e, t, n) {
  var r = new Float32Array(t * n * 4);
  return callAndCheck$1(e, () => e.readPixels(0, 0, n, t, e.RGBA, e.FLOAT, r)), r;
}

class GPGPUContext$1 {
  constructor(e) {
    this.outputTexture = null, this.program = null, this.disposed = !1, this.vertexAttrsAreBound = !1, this.itemsToPoll = [];
    var t = env$1().getNumber("WEBGL_VERSION");
    null != e ? (this.gl = e, setWebGLContext$1(t, e)) : this.gl = getWebGLContext$1(t);
    var n = "WEBGL_color_buffer_float";
    var r = "EXT_color_buffer_half_float";

    if (1 === env$1().getNumber("WEBGL_VERSION")) {
      var _e417 = "OES_texture_half_float";
      if (this.textureFloatExtension = getExtensionOrThrow$1(this.gl, "OES_texture_float"), hasExtension$1(this.gl, _e417)) this.textureHalfFloatExtension = getExtensionOrThrow$1(this.gl, _e417);else if (env$1().get("WEBGL_FORCE_F16_TEXTURES")) throw new Error("GL context does not support half float textures, yet the environment flag WEBGL_FORCE_F16_TEXTURES is set to true.");
      if (this.colorBufferFloatExtension = this.gl.getExtension(n), hasExtension$1(this.gl, r)) this.colorBufferHalfFloatExtension = getExtensionOrThrow$1(this.gl, r);else if (env$1().get("WEBGL_FORCE_F16_TEXTURES")) throw new Error("GL context does not support color renderable half floats, yet the environment flag WEBGL_FORCE_F16_TEXTURES is set to true.");
    } else if (n = "EXT_color_buffer_float", hasExtension$1(this.gl, n)) this.colorBufferFloatExtension = this.gl.getExtension(n);else {
      if (!hasExtension$1(this.gl, r)) throw new Error("GL context does not support color renderable floats");
      this.colorBufferHalfFloatExtension = this.gl.getExtension(r);
    }

    this.vertexBuffer = createVertexBuffer$1(this.gl), this.indexBuffer = createIndexBuffer$1(this.gl), this.framebuffer = createFramebuffer$1(this.gl), this.textureConfig = getTextureConfig$1(this.gl, this.textureHalfFloatExtension);
  }

  get debug() {
    return env$1().getBool("DEBUG");
  }

  dispose() {
    if (this.disposed) return;
    null != this.program && console.warn("Disposing a GPGPUContext that still has a bound WebGLProgram. This is probably a resource leak, delete the program with GPGPUContext.deleteProgram before disposing."), null != this.outputTexture && console.warn("Disposing a GPGPUContext that still has a bound output matrix texture.  This is probably a resource leak, delete the output matrix texture with GPGPUContext.deleteMatrixTexture before disposing.");
    var e = this.gl;
    callAndCheck$1(e, () => e.finish()), callAndCheck$1(e, () => e.bindFramebuffer(e.FRAMEBUFFER, null)), callAndCheck$1(e, () => e.deleteFramebuffer(this.framebuffer)), callAndCheck$1(e, () => e.bindBuffer(e.ARRAY_BUFFER, null)), callAndCheck$1(e, () => e.bindBuffer(e.ELEMENT_ARRAY_BUFFER, null)), callAndCheck$1(e, () => e.deleteBuffer(this.indexBuffer)), this.disposed = !0;
  }

  createFloat32MatrixTexture(e, t) {
    return this.throwIfDisposed(), createFloat32MatrixTexture$1(this.gl, e, t, this.textureConfig);
  }

  createFloat16MatrixTexture(e, t) {
    return this.throwIfDisposed(), createFloat16MatrixTexture$1(this.gl, e, t, this.textureConfig);
  }

  createUnsignedBytesMatrixTexture(e, t) {
    return this.throwIfDisposed(), createUnsignedBytesMatrixTexture$1(this.gl, e, t, this.textureConfig);
  }

  uploadPixelDataToTexture(e, t) {
    this.throwIfDisposed(), uploadPixelDataToTexture$1(this.gl, e, t);
  }

  uploadDenseMatrixToTexture(e, t, n, r) {
    this.throwIfDisposed(), uploadDenseMatrixToTexture$1(this.gl, e, t, n, r, this.textureConfig);
  }

  createFloat16PackedMatrixTexture(e, t) {
    return this.throwIfDisposed(), createFloat16PackedMatrixTexture$1(this.gl, e, t, this.textureConfig);
  }

  createPackedMatrixTexture(e, t) {
    return this.throwIfDisposed(), createPackedMatrixTexture$1(this.gl, e, t, this.textureConfig);
  }

  deleteMatrixTexture(e) {
    this.throwIfDisposed(), this.outputTexture === e && (unbindColorTextureFromFramebuffer$1(this.gl, this.framebuffer), this.outputTexture = null), callAndCheck$1(this.gl, () => this.gl.deleteTexture(e));
  }

  downloadByteEncodedFloatMatrixFromOutputTexture(e, t, n) {
    return this.downloadMatrixDriver(e, () => downloadByteEncodedFloatMatrixFromOutputTexture$1(this.gl, t, n, this.textureConfig));
  }

  downloadPackedMatrixFromBuffer(e, t, n, r, a, s) {
    return downloadPackedMatrixFromBuffer$1(this.gl, e, t, n, r, a, s);
  }

  downloadFloat32MatrixFromBuffer(e, t) {
    return downloadFloat32MatrixFromBuffer$1(this.gl, e, t);
  }

  createBufferFromTexture(e, t, n) {
    this.bindTextureToFrameBuffer(e);
    var r = createBufferFromOutputTexture$1(this.gl, t, n);
    return this.unbindTextureToFrameBuffer(), r;
  }

  createAndWaitForFence() {
    var e = this.createFence(this.gl);
    return this.pollFence(e);
  }

  createFence(e) {
    var t, n;

    if (env$1().getBool("WEBGL_FENCE_API_ENABLED")) {
      var r = e,
          a = r.fenceSync(r.SYNC_GPU_COMMANDS_COMPLETE, 0);
      e.flush(), n = () => {
        var e = r.clientWaitSync(a, 0, 0);
        return e === r.ALREADY_SIGNALED || e === r.CONDITION_SATISFIED;
      }, t = a;
    } else env$1().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") > 0 ? (t = this.beginQuery(), this.endQuery(), n = () => this.isQueryAvailable(t, env$1().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"))) : n = () => !0;

    return {
      query: t,
      isFencePassed: n
    };
  }

  downloadMatrixFromPackedTexture(e, t, n) {
    return this.downloadMatrixDriver(e, () => downloadMatrixFromPackedOutputTexture$1(this.gl, t, n));
  }

  createProgram(e) {
    this.throwIfDisposed();
    var t = this.gl,
        n = createFragmentShader$1(t, e);
    null == this.vertexShader && (this.vertexShader = createVertexShader$2(t));
    var r = createProgram$1(t);
    return callAndCheck$1(t, () => t.attachShader(r, this.vertexShader)), callAndCheck$1(t, () => t.attachShader(r, n)), linkProgram$1(t, r), this.debug && validateProgram$1(t, r), this.vertexAttrsAreBound || (this.setProgram(r), this.vertexAttrsAreBound = bindVertexProgramAttributeStreams$1(t, this.program, this.vertexBuffer)), r;
  }

  deleteProgram(e) {
    this.throwIfDisposed(), e === this.program && (this.program = null), null != e && callAndCheck$1(this.gl, () => this.gl.deleteProgram(e));
  }

  setProgram(e) {
    this.throwIfDisposed(), this.program = e, null != this.program && this.debug && validateProgram$1(this.gl, this.program), callAndCheck$1(this.gl, () => this.gl.useProgram(e));
  }

  getUniformLocation(e, t) {
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !0;
    return this.throwIfDisposed(), n ? getProgramUniformLocationOrThrow$1(this.gl, e, t) : getProgramUniformLocation$1(this.gl, e, t);
  }

  getAttributeLocation(e, t) {
    return this.throwIfDisposed(), callAndCheck$1(this.gl, () => this.gl.getAttribLocation(e, t));
  }

  getUniformLocationNoThrow(e, t) {
    return this.throwIfDisposed(), this.gl.getUniformLocation(e, t);
  }

  setInputMatrixTexture(e, t, n) {
    this.throwIfDisposed(), this.throwIfNoProgram(), bindTextureToProgramUniformSampler$1(this.gl, e, t, n);
  }

  setOutputMatrixTexture(e, t, n) {
    this.setOutputMatrixTextureDriver(e, n, t);
  }

  setOutputPackedMatrixTexture(e, t, n) {
    this.throwIfDisposed();
    var [r, a] = getPackedMatrixTextureShapeWidthHeight$1(t, n);
    this.setOutputMatrixTextureDriver(e, r, a);
  }

  setOutputMatrixWriteRegion(e, t, n, r) {
    this.setOutputMatrixWriteRegionDriver(n, e, r, t);
  }

  setOutputPackedMatrixWriteRegion(e, t, n, r) {
    throw new Error("setOutputPackedMatrixWriteRegion not implemented.");
  }

  debugValidate() {
    null != this.program && validateProgram$1(this.gl, this.program), validateFramebuffer$1(this.gl);
  }

  executeProgram() {
    this.throwIfDisposed(), this.throwIfNoProgram();
    var e = this.gl;
    this.debug && this.debugValidate(), callAndCheck$1(e, () => e.drawElements(e.TRIANGLES, 6, e.UNSIGNED_SHORT, 0));
  }

  blockUntilAllProgramsCompleted() {
    this.throwIfDisposed(), callAndCheck$1(this.gl, () => this.gl.finish());
  }

  getQueryTimerExtension() {
    return null == this.disjointQueryTimerExtension && (this.disjointQueryTimerExtension = getExtensionOrThrow$1(this.gl, 2 === env$1().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") ? "EXT_disjoint_timer_query_webgl2" : "EXT_disjoint_timer_query")), this.disjointQueryTimerExtension;
  }

  getQueryTimerExtensionWebGL2() {
    return this.getQueryTimerExtension();
  }

  getQueryTimerExtensionWebGL1() {
    return this.getQueryTimerExtension();
  }

  beginQuery() {
    if (2 === env$1().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")) {
      var _e418 = this.gl,
          _t297 = this.getQueryTimerExtensionWebGL2(),
          n = _e418.createQuery();

      return _e418.beginQuery(_t297.TIME_ELAPSED_EXT, n), n;
    }

    var e = this.getQueryTimerExtensionWebGL1(),
        t = e.createQueryEXT();
    return e.beginQueryEXT(e.TIME_ELAPSED_EXT, t), t;
  }

  endQuery() {
    if (2 === env$1().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")) {
      var _e419 = this.gl,
          t = this.getQueryTimerExtensionWebGL2();
      return void _e419.endQuery(t.TIME_ELAPSED_EXT);
    }

    var e = this.getQueryTimerExtensionWebGL1();
    e.endQueryEXT(e.TIME_ELAPSED_EXT);
  }

  waitForQueryAndGetTime(e) {
    var _this72 = this;

    return _asyncToGenerator(function* () {
      return yield repeatedTry$1(() => _this72.disposed || _this72.isQueryAvailable(e, env$1().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"))), _this72.getQueryTime(e, env$1().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"));
    })();
  }

  getQueryTime(e, t) {
    if (0 === t) return null;

    if (2 === t) {
      var _t298 = this.gl;
      return _t298.getQueryParameter(e, _t298.QUERY_RESULT) / 1e6;
    }

    {
      var _t299 = this.getQueryTimerExtensionWebGL1();

      return _t299.getQueryObjectEXT(e, _t299.QUERY_RESULT_EXT) / 1e6;
    }
  }

  isQueryAvailable(e, t) {
    if (0 === t) return !0;

    if (2 === t) {
      var _t300 = this.gl,
          n = this.getQueryTimerExtensionWebGL2(),
          r = _t300.getQueryParameter(e, _t300.QUERY_RESULT_AVAILABLE);

      return null == this.disjoint && (this.disjoint = this.gl.getParameter(n.GPU_DISJOINT_EXT)), r && !this.disjoint;
    }

    {
      var _t301 = this.getQueryTimerExtensionWebGL1(),
          _n195 = _t301.getQueryObjectEXT(e, _t301.QUERY_RESULT_AVAILABLE_EXT);

      return null == this.disjoint && (this.disjoint = this.gl.getParameter(_t301.GPU_DISJOINT_EXT)), _n195 && !this.disjoint;
    }
  }

  pollFence(e) {
    return new Promise(t => {
      this.addItemToPoll(() => e.isFencePassed(), () => t());
    });
  }

  pollItems() {
    var e = linearSearchLastTrue$1(this.itemsToPoll.map(e => e.isDoneFn));

    for (var t = 0; t <= e; ++t) {
      var {
        resolveFn: _e420
      } = this.itemsToPoll[t];

      _e420();
    }

    this.itemsToPoll = this.itemsToPoll.slice(e + 1);
  }

  addItemToPoll(e, t) {
    this.itemsToPoll.push({
      isDoneFn: e,
      resolveFn: t
    }), this.itemsToPoll.length > 1 || repeatedTry$1(() => (this.pollItems(), 0 === this.itemsToPoll.length));
  }

  bindTextureToFrameBuffer(e) {
    this.throwIfDisposed(), bindColorTextureToFramebuffer$1(this.gl, e, this.framebuffer), this.debug && validateFramebuffer$1(this.gl);
  }

  unbindTextureToFrameBuffer() {
    null != this.outputTexture ? (bindColorTextureToFramebuffer$1(this.gl, this.outputTexture, this.framebuffer), this.debug && validateFramebuffer$1(this.gl)) : unbindColorTextureFromFramebuffer$1(this.gl, this.framebuffer);
  }

  downloadMatrixDriver(e, t) {
    this.bindTextureToFrameBuffer(e);
    var n = t();
    return this.unbindTextureToFrameBuffer(), n;
  }

  setOutputMatrixTextureDriver(e, t, n) {
    this.throwIfDisposed();
    var r = this.gl;
    bindColorTextureToFramebuffer$1(r, e, this.framebuffer), this.debug && validateFramebuffer$1(r), this.outputTexture = e, callAndCheck$1(r, () => r.viewport(0, 0, t, n)), callAndCheck$1(r, () => r.scissor(0, 0, t, n));
  }

  setOutputMatrixWriteRegionDriver(e, t, n, r) {
    this.throwIfDisposed(), callAndCheck$1(this.gl, () => this.gl.scissor(e, t, n, r));
  }

  throwIfDisposed() {
    if (this.disposed) throw new Error("Attempted to use disposed GPGPUContext.");
  }

  throwIfNoProgram() {
    if (null == this.program) throw new Error("No GPU program is currently set.");
  }

}

function linearSearchLastTrue$1(e) {
  var t = 0;

  for (; t < e.length && e[t](); ++t) {
    ;
  }

  return t - 1;
}

var {
  getBroadcastDims: getBroadcastDims$2
} = backend_util$1;

function makeShader$1(e, t, n) {
  var r = [];

  if (e.forEach(e => {
    var t = sizeFromShape$1(e.shapeInfo.logicalShape);

    if (e.shapeInfo.isUniform ? r.push("uniform float ".concat(e.name).concat(t > 1 ? "[".concat(t, "]") : "", ";")) : (r.push("uniform sampler2D ".concat(e.name, ";")), r.push("uniform int offset".concat(e.name, ";"))), n.enableShapeUniforms) {
      var {
        uniformShape: _t302
      } = getUniformInfoFromShape$1(n.packedInputs, e.shapeInfo.logicalShape, e.shapeInfo.texShape);

      switch (_t302.length) {
        case 1:
          r.push("uniform int ".concat(e.name, "Shape;"));
          break;

        case 2:
          r.push("uniform ivec2 ".concat(e.name, "Shape;"));
          break;

        case 3:
          r.push("uniform ivec3 ".concat(e.name, "Shape;"));
          break;

        case 4:
          r.push("uniform ivec4 ".concat(e.name, "Shape;"));
      }

      r.push("uniform ivec2 ".concat(e.name, "TexShape;"));
    }
  }), n.enableShapeUniforms) {
    switch (t.logicalShape.length) {
      case 1:
        r.push("uniform int outShape;");
        break;

      case 2:
        r.push("uniform ivec2 outShape;"), r.push("uniform int outShapeStrides;");
        break;

      case 3:
        r.push("uniform ivec3 outShape;"), r.push("uniform ivec2 outShapeStrides;");
        break;

      case 4:
        r.push("uniform ivec4 outShape;"), r.push("uniform ivec3 outShapeStrides;");
    }

    r.push("uniform ivec2 outTexShape;");
  }

  n.customUniforms && n.customUniforms.forEach(e => {
    r.push("uniform ".concat(e.type, " ").concat(e.name).concat(e.arrayIndex ? "[".concat(e.arrayIndex, "]") : "", ";"));
  });
  var a = r.join("\n"),
      s = e.map(e => getInputSamplingSnippet$1(e, t, n.packedInputs, n.enableShapeUniforms)).join("\n"),
      o = t.texShape,
      i = getGlslDifferences$1(),
      l = getFloatTextureSampleSnippet$1(i);
  var u,
      c,
      p = getShaderPrefix$1(i);
  return t.isPacked ? (u = getPackedOutputSamplingSnippet$1(t.logicalShape, o, n.enableShapeUniforms), c = getFloatTextureSetRGBASnippet$1(i)) : (u = getOutputSamplingSnippet$1(t.logicalShape, o, n.enableShapeUniforms), c = getFloatTextureSetRSnippet$1(i)), n.packedInputs && (p += SHADER_PACKED_PREFIX$1), [p, l, c, a, u, s, n.userCode].join("\n");
}

function getSamplerFromInInfo$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;
  var n = e.shapeInfo.logicalShape;

  switch (n.length) {
    case 0:
      return getSamplerScalar$1(e, t);

    case 1:
      return getSampler1D$1(e, t);

    case 2:
      return getSampler2D$1(e, t);

    case 3:
      return getSampler3D$1(e, t);

    case 4:
      return getSampler4D$1(e, t);

    case 5:
      return getSampler5D$1(e);

    case 6:
      return getSampler6D$1(e);

    default:
      throw new Error("".concat(n.length, "-D input sampling is not yet supported"));
  }
}

function getPackedSamplerFromInInfo$1(e, t) {
  switch (e.shapeInfo.logicalShape.length) {
    case 0:
      return getPackedSamplerScalar$1(e);

    case 1:
      return getPackedSampler1D$1(e, t);

    case 2:
      return getPackedSampler2D$1(e, t);

    case 3:
      return getPackedSampler3D$1(e, t);

    default:
      return getPackedSamplerND$1(e, t);
  }
}

function getInputSamplingSnippet$1(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  var r = arguments.length > 3 ? arguments[3] : undefined;
  var a = "";
  return a += n ? getPackedSamplerFromInInfo$1(e, r) : getSamplerFromInInfo$1(e, r), e.shapeInfo.logicalShape.length <= t.logicalShape.length && (a += n ? getPackedSamplerAtOutputCoords$1(e, t) : getSamplerAtOutputCoords$1(e, t)), a;
}

function getPackedOutputSamplingSnippet$1(e, t, n) {
  switch (e.length) {
    case 0:
      return getOutputScalarCoords$1();

    case 1:
      return getOutputPacked1DCoords$1(e, t, n);

    case 2:
      return getOutputPacked2DCoords$1(e, t, n);

    case 3:
      return getOutputPacked3DCoords$1(e, t, n);

    default:
      return getOutputPackedNDCoords$1(e, t, n);
  }
}

function getOutputSamplingSnippet$1(e, t, n) {
  switch (e.length) {
    case 0:
      return getOutputScalarCoords$1();

    case 1:
      return getOutput1DCoords$1(e, t, n);

    case 2:
      return getOutput2DCoords$1(e, t, n);

    case 3:
      return getOutput3DCoords$1(e, t, n);

    case 4:
      return getOutput4DCoords$1(e, t, n);

    case 5:
      return getOutput5DCoords$1(e, t);

    case 6:
      return getOutput6DCoords$1(e, t);

    default:
      throw new Error("".concat(e.length, "-D output sampling is not yet supported"));
  }
}

function getFloatTextureSampleSnippet$1(e) {
  return "\n    float sampleTexture(sampler2D textureSampler, vec2 uv) {\n      return ".concat(e.texture2D, "(textureSampler, uv).r;\n    }\n  ");
}

function getFloatTextureSetRSnippet$1(e) {
  return "\n    void setOutput(float val) {\n      ".concat(e.output, " = vec4(val, 0, 0, 0);\n    }\n  ");
}

function getFloatTextureSetRGBASnippet$1(e) {
  return "\n    void setOutput(vec4 val) {\n      ".concat(e.output, " = val;\n    }\n  ");
}

function getShaderPrefix$1(e) {
  return "".concat(e.version, "\n    precision highp float;\n    precision highp int;\n    precision highp sampler2D;\n    ").concat(e.varyingFs, " vec2 resultUV;\n    ").concat(e.defineOutput, "\n    const vec2 halfCR = vec2(0.5, 0.5);\n\n    struct ivec5\n    {\n      int x;\n      int y;\n      int z;\n      int w;\n      int u;\n    };\n\n    struct ivec6\n    {\n      int x;\n      int y;\n      int z;\n      int w;\n      int u;\n      int v;\n    };\n\n    uniform float NAN;\n    ").concat(e.defineSpecialNaN, "\n    ").concat(e.defineSpecialInf, "\n    ").concat(e.defineRound, "\n\n    int imod(int x, int y) {\n      return x - y * (x / y);\n    }\n\n    int idiv(int a, int b, float sign) {\n      int res = a / b;\n      int mod = imod(a, b);\n      if (sign < 0. && mod != 0) {\n        res -= 1;\n      }\n      return res;\n    }\n\n    //Based on the work of Dave Hoskins\n    //https://www.shadertoy.com/view/4djSRW\n    #define HASHSCALE1 443.8975\n    float random(float seed){\n      vec2 p = resultUV * seed;\n      vec3 p3  = fract(vec3(p.xyx) * HASHSCALE1);\n      p3 += dot(p3, p3.yzx + 19.19);\n      return fract((p3.x + p3.y) * p3.z);\n    }\n\n    ").concat(SAMPLE_1D_SNIPPET$1, "\n    ").concat(SAMPLE_2D_SNIPPET$1, "\n    ").concat(SAMPLE_3D_SNIPPET$1, "\n  ");
}

var SAMPLE_1D_SNIPPET$1 = "\nvec2 uvFromFlat(int texNumR, int texNumC, int index) {\n  int texR = index / texNumC;\n  int texC = index - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\nvec2 packedUVfrom1D(int texNumR, int texNumC, int index) {\n  int texelIndex = index / 2;\n  int texR = texelIndex / texNumC;\n  int texC = texelIndex - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\n",
    SAMPLE_2D_SNIPPET$1 = "\nvec2 packedUVfrom2D(int texelsInLogicalRow, int texNumR,\n  int texNumC, int row, int col) {\n  int texelIndex = (row / 2) * texelsInLogicalRow + (col / 2);\n  int texR = texelIndex / texNumC;\n  int texC = texelIndex - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\n",
    SAMPLE_3D_SNIPPET$1 = "\nvec2 packedUVfrom3D(int texNumR, int texNumC,\n    int texelsInBatch, int texelsInLogicalRow, int b,\n    int row, int col) {\n  int index = b * texelsInBatch + (row / 2) * texelsInLogicalRow + (col / 2);\n  int texR = index / texNumC;\n  int texC = index - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\n",
    SHADER_PACKED_PREFIX$1 = "\n  float getChannel(vec4 frag, vec2 innerDims) {\n    vec2 modCoord = mod(innerDims, 2.);\n    return modCoord.x == 0. ?\n      (modCoord.y == 0. ? frag.r : frag.g) :\n      (modCoord.y == 0. ? frag.b : frag.a);\n  }\n  float getChannel(vec4 frag, int dim) {\n    float modCoord = mod(float(dim), 2.);\n    return modCoord == 0. ? frag.r : frag.g;\n  }\n";

function getOutputScalarCoords$1() {
  return "\n    int getOutputCoords() {\n      return 0;\n    }\n  ";
}

function getOutputPacked1DCoords$1(e, t, n) {
  var r = [Math.ceil(t[0] / 2), Math.ceil(t[1] / 2)];
  return 1 === r[0] ? n ? "\n      int getOutputCoords() {\n        return 2 * int(resultUV.x * ceil(float(outTexShape[1]) / 2.0));\n      }\n    " : "\n      int getOutputCoords() {\n        return 2 * int(resultUV.x * ".concat(r[1], ".0);\n      }\n    ") : 1 === r[1] ? n ? "\n      int getOutputCoords() {\n        return 2 * int(resultUV.y * ceil(float(outTexShape[0]) / 2.0));\n      }\n    " : "\n      int getOutputCoords() {\n        return 2 * int(resultUV.y * ".concat(r[0], ".0);\n      }\n    ") : n ? "\n    int getOutputCoords() {\n      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(packedTexShape[0], packedTexShape[1]));\n      return 2 * (resTexRC.x * packedTexShape[1] + resTexRC.y);\n    }\n  " : "\n    int getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(".concat(r[0], ", ").concat(r[1], "));\n      return 2 * (resTexRC.x * ").concat(r[1], " + resTexRC.y);\n    }\n  ");
}

function getOutput1DCoords$1(e, t, n) {
  return 1 === t[0] ? n ? "\n      int getOutputCoords() {\n        return int(resultUV.x * float(outTexShape[1]));\n      }\n    " : "\n      int getOutputCoords() {\n        return int(resultUV.x * ".concat(t[1], ".0);\n      }\n    ") : 1 === t[1] ? n ? "\n      int getOutputCoords() {\n        return int(resultUV.y * float(outTexShape[0]));\n      }\n    " : "\n      int getOutputCoords() {\n        return int(resultUV.y * ".concat(t[0], ".0);\n      }\n    ") : n ? "\n    int getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(outTexShape[0], outTexShape[1]));\n      return resTexRC.x * outTexShape[1] + resTexRC.y;\n    }\n  " : "\n    int getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(".concat(t[0], ", ").concat(t[1], "));\n      return resTexRC.x * ").concat(t[1], " + resTexRC.y;\n    }\n  ");
}

function getOutputPacked3DCoords$1(e, t, n) {
  if (n) return "\n    ivec3 getOutputCoords() {\n      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\n      int texelsInLogicalRow = int(ceil(float(outShape[2]) / 2.0));\n      int texelsInBatch = texelsInLogicalRow * int(ceil(float(outShape[1]) / 2.0));\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(packedTexShape[0], packedTexShape[1]));\n      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;\n\n      int b = index / texelsInBatch;\n      index -= b * texelsInBatch;\n\n      int r = 2 * (index / texelsInLogicalRow);\n      int c = imod(index, texelsInLogicalRow) * 2;\n\n      return ivec3(b, r, c);\n    }\n  ";
  var r = [Math.ceil(t[0] / 2), Math.ceil(t[1] / 2)],
      a = Math.ceil(e[2] / 2),
      s = a * Math.ceil(e[1] / 2);
  return "\n    ivec3 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(".concat(r[0], ", ").concat(r[1], "));\n      int index = resTexRC.x * ").concat(r[1], " + resTexRC.y;\n\n      int b = index / ").concat(s, ";\n      index -= b * ").concat(s, ";\n\n      int r = 2 * (index / ").concat(a, ");\n      int c = imod(index, ").concat(a, ") * 2;\n\n      return ivec3(b, r, c);\n    }\n  ");
}

function getOutput3DCoords$1(e, t, n) {
  if (n) return "\n  ivec3 getOutputCoords() {\n    ivec2 resTexRC = ivec2(resultUV.yx *\n                           vec2(outTexShape[0], outTexShape[1]));\n    int index = resTexRC.x * outTexShape[1] + resTexRC.y;\n    ".concat(getLogicalCoordinatesFromFlatIndexByUniform$1(["r", "c", "d"], e), "\n    return ivec3(r, c, d);\n  }\n");
  var r = getLogicalCoordinatesFromFlatIndex$1(["r", "c", "d"], e);
  return "\n    ivec3 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(".concat(t[0], ", ").concat(t[1], "));\n      int index = resTexRC.x * ").concat(t[1], " + resTexRC.y;\n      ").concat(r, "\n      return ivec3(r, c, d);\n    }\n  ");
}

function getOutputPackedNDCoords$1(e, t, n) {
  if (n) return "\n    ivec4 getOutputCoords() {\n      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(packedTexShape[0], packedTexShape[1]));\n      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;\n\n      int texelsInLogicalRow = int(ceil(float(outShape[3]) / 2.0));\n      int texelsInBatch = texelsInLogicalRow * int(ceil(float(outShape[2]) / 2.0));\n      int texelsInBatchN = texelsInBatch * outShape[1];\n\n      int b2 = index / texelsInBatchN;\n      index -= b2 * texelsInBatchN;\n\n      int b = index / texelsInBatch;\n      index -= b * texelsInBatch;\n\n      int r = 2 * (index / texelsInLogicalRow);\n      int c = imod(index, texelsInLogicalRow) * 2;\n\n      return ivec4(b2, b, r, c);\n    }\n  ";
  var r = [Math.ceil(t[0] / 2), Math.ceil(t[1] / 2)],
      a = Math.ceil(e[e.length - 1] / 2),
      s = a * Math.ceil(e[e.length - 2] / 2);
  var o = s,
      i = "",
      l = "b, r, c";

  for (var _t303 = 2; _t303 < e.length - 1; _t303++) {
    o *= e[e.length - _t303 - 1], i = "\n      int b".concat(_t303, " = index / ").concat(o, ";\n      index -= b").concat(_t303, " * ").concat(o, ";\n    ") + i, l = "b".concat(_t303, ", ") + l;
  }

  return "\n    ivec".concat(e.length, " getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(").concat(r[0], ", ").concat(r[1], "));\n      int index = resTexRC.x * ").concat(r[1], " + resTexRC.y;\n\n      ").concat(i, "\n\n      int b = index / ").concat(s, ";\n      index -= b * ").concat(s, ";\n\n      int r = 2 * (index / ").concat(a, ");\n      int c = imod(index, ").concat(a, ") * 2;\n\n      return ivec").concat(e.length, "(").concat(l, ");\n    }\n  ");
}

function getOutput4DCoords$1(e, t, n) {
  if (n) return "\n    ivec4 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n        vec2(outTexShape[0], outTexShape[1]));\n      int index = resTexRC.x * outTexShape[1] + resTexRC.y;\n      ".concat(getLogicalCoordinatesFromFlatIndexByUniform$1(["r", "c", "d", "d2"], e), "\n      return ivec4(r, c, d, d2);\n    }\n  ");
  var r = getLogicalCoordinatesFromFlatIndex$1(["r", "c", "d", "d2"], e);
  return "\n    ivec4 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n        vec2(".concat(t[0], ", ").concat(t[1], "));\n      int index = resTexRC.x * ").concat(t[1], " + resTexRC.y;\n      ").concat(r, "\n      return ivec4(r, c, d, d2);\n    }\n  ");
}

function getOutput5DCoords$1(e, t) {
  var n = getLogicalCoordinatesFromFlatIndex$1(["r", "c", "d", "d2", "d3"], e);
  return "\n    ivec5 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx * vec2(".concat(t[0], ",\n                             ").concat(t[1], "));\n\n      int index = resTexRC.x * ").concat(t[1], " + resTexRC.y;\n\n      ").concat(n, "\n\n      ivec5 outShape = ivec5(r, c, d, d2, d3);\n      return outShape;\n    }\n  ");
}

function getOutput6DCoords$1(e, t) {
  var n = getLogicalCoordinatesFromFlatIndex$1(["r", "c", "d", "d2", "d3", "d4"], e);
  return "\n    ivec6 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n        vec2(".concat(t[0], ", ").concat(t[1], "));\n      int index = resTexRC.x * ").concat(t[1], " + resTexRC.y;\n\n      ").concat(n, "\n\n      ivec6 result = ivec6(r, c, d, d2, d3, d4);\n      return result;\n    }\n  ");
}

function getOutputPacked2DCoords$1(e, t, n) {
  var r = [Math.ceil(t[0] / 2), Math.ceil(t[1] / 2)];
  if (arraysEqual$1(e, t)) return n ? "\n      ivec2 getOutputCoords() {\n        ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\n        return 2 * ivec2(resultUV.yx * vec2(packedTexShape[0], packedTexShape[1]));\n      }\n    " : "\n      ivec2 getOutputCoords() {\n        return 2 * ivec2(resultUV.yx * vec2(".concat(r[0], ", ").concat(r[1], "));\n      }\n    ");
  var a = Math.ceil(e[1] / 2);
  return n ? "\n    ivec2 getOutputCoords() {\n      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\n      int texelsInLogicalRow = int(ceil(float(outShape[1]) / 2.0));\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(packedTexShape[0], packedTexShape[1]));\n\n      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;\n      int r = 2 * (index / texelsInLogicalRow);\n      int c = imod(index, texelsInLogicalRow) * 2;\n\n      return ivec2(r, c);\n    }\n  " : "\n    ivec2 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(".concat(r[0], ", ").concat(r[1], "));\n\n      int index = resTexRC.x * ").concat(r[1], " + resTexRC.y;\n      int r = 2 * (index / ").concat(a, ");\n      int c = imod(index, ").concat(a, ") * 2;\n\n      return ivec2(r, c);\n    }\n  ");
}

function getOutput2DCoords$1(e, t, n) {
  return arraysEqual$1(e, t) ? n ? "\n      ivec2 getOutputCoords() {\n        return ivec2(resultUV.yx * vec2(outTexShape[0], outTexShape[1]));\n      }\n    " : "\n      ivec2 getOutputCoords() {\n        return ivec2(resultUV.yx * vec2(".concat(t[0], ", ").concat(t[1], "));\n      }\n    ") : 1 === e[1] ? n ? "\n      ivec2 getOutputCoords() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n                               vec2(outTexShape[0], outTexShape[1]));\n        int index = resTexRC.x * outTexShape[1] + resTexRC.y;\n        return ivec2(index, 0);\n      }\n    " : "\n      ivec2 getOutputCoords() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n                               vec2(".concat(t[0], ", ").concat(t[1], "));\n        int index = resTexRC.x * ").concat(t[1], " + resTexRC.y;\n        return ivec2(index, 0);\n      }\n    ") : 1 === e[0] ? n ? "\n      ivec2 getOutputCoords() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n                               vec2(outTexShape[0], outTexShape[1]));\n        int index = resTexRC.x * outTexShape[1] + resTexRC.y;\n        return ivec2(0, index);\n      }\n    " : "\n      ivec2 getOutputCoords() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n                               vec2(".concat(t[0], ", ").concat(t[1], "));\n        int index = resTexRC.x * ").concat(t[1], " + resTexRC.y;\n        return ivec2(0, index);\n      }\n    ") : n ? "\n    ivec2 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(outTexShape[0], outTexShape[1]));\n      int index = resTexRC.x * outTexShape[1] + resTexRC.y;\n      int r = index / outShape[1];\n      int c = index - r * outShape[1];\n      return ivec2(r, c);\n    }\n  " : "\n    ivec2 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(".concat(t[0], ", ").concat(t[1], "));\n      int index = resTexRC.x * ").concat(t[1], " + resTexRC.y;\n      int r = index / ").concat(e[1], ";\n      int c = index - r * ").concat(e[1], ";\n      return ivec2(r, c);\n    }\n  ");
}

function getFlatOffsetUniformName$1(e) {
  return "offset".concat(e);
}

function getPackedSamplerScalar$1(e) {
  var t = e.name;
  return "\n    vec4 ".concat("get" + t.charAt(0).toUpperCase() + t.slice(1), "() {\n      return ").concat(getGlslDifferences$1().texture2D, "(").concat(t, ", halfCR);\n    }\n  ");
}

function getSamplerScalar$1(e, t) {
  var n = e.name,
      r = "get" + n.charAt(0).toUpperCase() + n.slice(1);
  if (e.shapeInfo.isUniform) return "float ".concat(r, "() {return ").concat(n, ";}");
  var [a, s] = e.shapeInfo.texShape;
  if (1 === a && 1 === s) return "\n      float ".concat(r, "() {\n        return sampleTexture(").concat(n, ", halfCR);\n      }\n    ");
  var o = getFlatOffsetUniformName$1(n);
  if (t) return "\n    float ".concat(r, "() {\n      vec2 uv = uvFromFlat(").concat(n, "TexShape[0], ").concat(n, "TexShape[1], ").concat(o, ");\n      return sampleTexture(").concat(n, ", uv);\n    }\n  ");
  var [i, l] = e.shapeInfo.texShape;
  return "\n    float ".concat(r, "() {\n      vec2 uv = uvFromFlat(").concat(i, ", ").concat(l, ", ").concat(o, ");\n      return sampleTexture(").concat(n, ", uv);\n    }\n  ");
}

function getPackedSampler1D$1(e, t) {
  var n = e.name,
      r = "get" + n.charAt(0).toUpperCase() + n.slice(1),
      a = e.shapeInfo.texShape,
      s = getGlslDifferences$1();
  if (t) return "\n    vec4 ".concat(r, "(int index) {\n      ivec2 packedTexShape = ivec2(ceil(float(").concat(n, "TexShape[0]) / 2.0), ceil(float(").concat(n, "TexShape[1]) / 2.0));\n      vec2 uv = packedUVfrom1D(\n        packedTexShape[0], packedTexShape[1], index);\n      return ").concat(s.texture2D, "(").concat(n, ", uv);\n    }\n  ");
  var o = [Math.ceil(a[0] / 2), Math.ceil(a[1] / 2)];
  return "\n    vec4 ".concat(r, "(int index) {\n      vec2 uv = packedUVfrom1D(\n        ").concat(o[0], ", ").concat(o[1], ", index);\n      return ").concat(s.texture2D, "(").concat(n, ", uv);\n    }\n  ");
}

function getSampler1D$1(e, t) {
  var n = e.name,
      r = "get" + n.charAt(0).toUpperCase() + n.slice(1);
  if (e.shapeInfo.isUniform) return "\n      float ".concat(r, "(int index) {\n        ").concat(getUniformSampler$1(e), "\n      }\n    ");
  var a = e.shapeInfo.texShape,
      s = a[0],
      o = a[1];
  if (1 === o && 1 === s) return "\n      float ".concat(r, "(int index) {\n        return sampleTexture(").concat(n, ", halfCR);\n      }\n    ");
  var i = getFlatOffsetUniformName$1(n);
  return 1 === o ? t ? "\n      float ".concat(r, "(int index) {\n        vec2 uv = vec2(0.5, (float(index + ").concat(i, ") + 0.5) / float(").concat(n, "TexShape[0]));\n        return sampleTexture(").concat(n, ", uv);\n      }\n    ") : "\n      float ".concat(r, "(int index) {\n        vec2 uv = vec2(0.5, (float(index + ").concat(i, ") + 0.5) / ").concat(s, ".0);\n        return sampleTexture(").concat(n, ", uv);\n      }\n    ") : 1 === s ? t ? "\n      float ".concat(r, "(int index) {\n        vec2 uv = vec2((float(index + ").concat(i, ") + 0.5) / float(").concat(n, "TexShape[1]), 0.5);\n        return sampleTexture(").concat(n, ", uv);\n      }\n    ") : "\n      float ".concat(r, "(int index) {\n        vec2 uv = vec2((float(index + ").concat(i, ") + 0.5) / ").concat(o, ".0, 0.5);\n        return sampleTexture(").concat(n, ", uv);\n      }\n    ") : t ? "\n    float ".concat(r, "(int index) {\n      vec2 uv = uvFromFlat(").concat(n, "TexShape[0], ").concat(n, "TexShape[1], index + ").concat(i, ");\n      return sampleTexture(").concat(n, ", uv);\n    }\n  ") : "\n    float ".concat(r, "(int index) {\n      vec2 uv = uvFromFlat(").concat(s, ", ").concat(o, ", index + ").concat(i, ");\n      return sampleTexture(").concat(n, ", uv);\n    }\n  ");
}

function getPackedSampler2D$1(e, t) {
  var n = e.shapeInfo.logicalShape,
      r = e.name,
      a = "get" + r.charAt(0).toUpperCase() + r.slice(1),
      s = e.shapeInfo.texShape,
      o = s[0],
      i = s[1],
      l = getGlslDifferences$1();
  if (null != s && arraysEqual$1(n, s)) return t ? "\n      vec4 ".concat(a, "(int row, int col) {\n        vec2 uv = (vec2(col, row) + halfCR) / vec2(").concat(r, "TexShape[1], ").concat(r, "TexShape[0]);\n\n        return ").concat(l.texture2D, "(").concat(r, ", uv);\n      }\n    ") : "\n      vec4 ".concat(a, "(int row, int col) {\n        vec2 uv = (vec2(col, row) + halfCR) / vec2(").concat(i, ".0, ").concat(o, ".0);\n\n        return ").concat(l.texture2D, "(").concat(r, ", uv);\n      }\n    ");
  if (t) return "\n    vec4 ".concat(a, "(int row, int col) {\n      ivec2 packedTexShape = ivec2(ceil(float(").concat(r, "TexShape[0]) / 2.0), ceil(float(").concat(r, "TexShape[1]) / 2.0));\n      int valuesPerRow = int(ceil(float(").concat(r, "Shape[1]) / 2.0));\n      vec2 uv = packedUVfrom2D(valuesPerRow, packedTexShape[0], packedTexShape[1], row, col);\n      return ").concat(l.texture2D, "(").concat(r, ", uv);\n    }\n  ");
  var u = [Math.ceil(s[0] / 2), Math.ceil(s[1] / 2)];
  return "\n    vec4 ".concat(a, "(int row, int col) {\n      vec2 uv = packedUVfrom2D(").concat(Math.ceil(n[1] / 2), ", ").concat(u[0], ", ").concat(u[1], ", row, col);\n      return ").concat(l.texture2D, "(").concat(r, ", uv);\n    }\n  ");
}

function getSampler2D$1(e, t) {
  var n = e.shapeInfo.logicalShape,
      r = e.name,
      a = "get" + r.charAt(0).toUpperCase() + r.slice(1),
      s = e.shapeInfo.texShape;
  if (null != s && arraysEqual$1(n, s)) return t ? "\n      float ".concat(a, "(int row, int col) {\n        vec2 uv = (vec2(col, row) + halfCR) / vec2(").concat(r, "TexShape[1], ").concat(r, "TexShape[0]);\n        return sampleTexture(").concat(r, ", uv);\n      }\n    ") : "\n    float ".concat(a, "(int row, int col) {\n      vec2 uv = (vec2(col, row) + halfCR) / vec2(").concat(s[1], ".0, ").concat(s[0], ".0);\n      return sampleTexture(").concat(r, ", uv);\n    }\n  ");
  var {
    newShape: o,
    keptDims: i
  } = squeezeShape$1(n);

  if (o.length < n.length) {
    var _n196 = ["row", "col"];
    return "\n      ".concat(getSamplerFromInInfo$1(squeezeInputInfo$1(e, o), t), "\n      float ").concat(a, "(int row, int col) {\n        return ").concat(a, "(").concat(getSqueezedParams$1(_n196, i), ");\n      }\n    ");
  }

  if (e.shapeInfo.isUniform) return "\n      float ".concat(a, "(int row, int col) {\n        int index = round(dot(vec2(row, col), vec2(").concat(n[1], ", 1)));\n        ").concat(getUniformSampler$1(e), "\n      }\n    ");
  var l = s[0],
      u = s[1],
      c = getFlatOffsetUniformName$1(r);
  return 1 === u ? t ? "\n      float ".concat(a, "(int row, int col) {\n        float index = dot(vec3(row, col, ").concat(c, "), vec3(").concat(r, "Shape[1], 1, 1));\n        vec2 uv = vec2(0.5, (index + 0.5) / float(").concat(r, "TexShape[0]));\n        return sampleTexture(").concat(r, ", uv);\n      }\n    ") : "\n    float ".concat(a, "(int row, int col) {\n      float index = dot(vec3(row, col, ").concat(c, "), vec3(").concat(n[1], ", 1, 1));\n      vec2 uv = vec2(0.5, (index + 0.5) / ").concat(l, ".0);\n      return sampleTexture(").concat(r, ", uv);\n    }\n  ") : 1 === l ? t ? "\n      float ".concat(a, "(int row, int col) {\n        float index = dot(vec3(row, col, ").concat(c, "), vec3(").concat(r, "Shape[1], 1, 1));\n        vec2 uv = vec2((index + 0.5) / float(").concat(r, "TexShape[1]), 0.5);\n        return sampleTexture(").concat(r, ", uv);\n      }\n    ") : "\n    float ".concat(a, "(int row, int col) {\n      float index = dot(vec3(row, col, ").concat(c, "), vec3(").concat(n[1], ", 1, 1));\n      vec2 uv = vec2((index + 0.5) / ").concat(u, ".0, 0.5);\n      return sampleTexture(").concat(r, ", uv);\n    }\n  ") : t ? "\n      float ".concat(a, "(int row, int col) {\n        // Explicitly use integer operations as dot() only works on floats.\n        int index = row * ").concat(r, "Shape[1] + col + ").concat(c, ";\n        vec2 uv = uvFromFlat(").concat(r, "TexShape[0], ").concat(r, "TexShape[1], index);\n        return sampleTexture(").concat(r, ", uv);\n      }\n    ") : "\n  float ".concat(a, "(int row, int col) {\n    // Explicitly use integer operations as dot() only works on floats.\n    int index = row * ").concat(n[1], " + col + ").concat(c, ";\n    vec2 uv = uvFromFlat(").concat(l, ", ").concat(u, ", index);\n    return sampleTexture(").concat(r, ", uv);\n  }\n");
}

function getPackedSampler3D$1(e, t) {
  var n = e.shapeInfo.logicalShape,
      r = e.name,
      a = "get" + r.charAt(0).toUpperCase() + r.slice(1),
      s = e.shapeInfo.texShape,
      o = [Math.ceil(s[0] / 2), Math.ceil(s[1] / 2)];

  if (1 === n[0]) {
    var _r147 = [1, 2],
        _s76 = ["b", "row", "col"];
    return "\n        ".concat(getPackedSamplerFromInInfo$1(squeezeInputInfo$1(e, n.slice(1)), t), "\n        vec4 ").concat(a, "(int b, int row, int col) {\n          return ").concat(a, "(").concat(getSqueezedParams$1(_s76, _r147), ");\n        }\n      ");
  }

  var i = getGlslDifferences$1();
  if (t) return "\n    vec4 ".concat(a, "(int b, int row, int col) {\n      ivec2 packedTexShape = ivec2(ceil(float(").concat(r, "TexShape[0]) / 2.0), ceil(float(").concat(r, "TexShape[1]) / 2.0));\n      int valuesPerRow = int(ceil(float(").concat(r, "Shape[2]) / 2.0));\n      int texelsInBatch = valuesPerRow * int(ceil(float(").concat(r, "Shape[1]) / 2.0));\n      vec2 uv = packedUVfrom3D(\n        packedTexShape[0], packedTexShape[1], texelsInBatch, valuesPerRow, b, row, col);\n      return ").concat(i.texture2D, "(").concat(r, ", uv);\n    }\n  ");
  var l = o[0],
      u = o[1],
      c = Math.ceil(n[2] / 2);
  return "\n    vec4 ".concat(a, "(int b, int row, int col) {\n      vec2 uv = packedUVfrom3D(\n        ").concat(l, ", ").concat(u, ", ").concat(c * Math.ceil(n[1] / 2), ", ").concat(c, ", b, row, col);\n      return ").concat(i.texture2D, "(").concat(r, ", uv);\n    }\n  ");
}

function getSampler3D$1(e, t) {
  var n = e.shapeInfo.logicalShape,
      r = e.name,
      a = "get" + r.charAt(0).toUpperCase() + r.slice(1),
      s = n[1] * n[2],
      o = n[2],
      {
    newShape: i,
    keptDims: l
  } = squeezeShape$1(n);

  if (i.length < n.length) {
    var _n197 = ["row", "col", "depth"];
    return "\n        ".concat(getSamplerFromInInfo$1(squeezeInputInfo$1(e, i), t), "\n        float ").concat(a, "(int row, int col, int depth) {\n          return ").concat(a, "(").concat(getSqueezedParams$1(_n197, l), ");\n        }\n      ");
  }

  if (e.shapeInfo.isUniform) return "\n      float ".concat(a, "(int row, int col, int depth) {\n        int index = round(dot(vec3(row, col, depth),\n                          vec3(").concat(s, ", ").concat(o, ", 1)));\n        ").concat(getUniformSampler$1(e), "\n      }\n    ");
  var u = e.shapeInfo.texShape,
      c = u[0],
      p = u[1],
      d = e.shapeInfo.flatOffset;
  if (p === s && null == d) return t ? "\n      float ".concat(a, "(int row, int col, int depth) {\n        int stride1 = ").concat(r, "Shape[2];\n        float texR = float(row);\n        float texC = dot(vec2(col, depth), vec2(stride1, 1));\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(").concat(r, "TexShape[1], ").concat(r, "TexShape[0]);\n        return sampleTexture(").concat(r, ", uv);\n      }\n    ") : "\n        float ".concat(a, "(int row, int col, int depth) {\n          float texR = float(row);\n          float texC = dot(vec2(col, depth), vec2(").concat(o, ", 1));\n          vec2 uv = (vec2(texC, texR) + halfCR) /\n                     vec2(").concat(p, ".0, ").concat(c, ".0);\n          return sampleTexture(").concat(r, ", uv);\n        }\n      ");
  if (p === o && null == d) return t ? "\n      float ".concat(a, "(int row, int col, int depth) {\n        float texR = dot(vec2(row, col), vec2(").concat(r, "Shape[1], 1));\n        float texC = float(depth);\n        vec2 uv = (vec2(texC, texR) + halfCR) / vec2(").concat(r, "TexShape[1], ").concat(r, "TexShape[0]);\n        return sampleTexture(").concat(r, ", uv);\n      }\n    ") : "\n    float ".concat(a, "(int row, int col, int depth) {\n      float texR = dot(vec2(row, col), vec2(").concat(n[1], ", 1));\n      float texC = float(depth);\n      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(").concat(p, ".0, ").concat(c, ".0);\n      return sampleTexture(").concat(r, ", uv);\n    }\n  ");
  var h = getFlatOffsetUniformName$1(r);
  return t ? "\n    float ".concat(a, "(int row, int col, int depth) {\n      // Explicitly use integer operations as dot() only works on floats.\n      int stride0 = ").concat(r, "Shape[1] * ").concat(r, "Shape[2];\n      int stride1 = ").concat(r, "Shape[2];\n      int index = row * ").concat(s, " + col * ").concat(o, " + depth + ").concat(h, ";\n      vec2 uv = uvFromFlat(").concat(r, "TexShape[0], ").concat(r, "TexShape[1], index);\n      return sampleTexture(").concat(r, ", uv);\n    }\n    ") : "\n      float ".concat(a, "(int row, int col, int depth) {\n        // Explicitly use integer operations as dot() only works on floats.\n        int index = row * ").concat(s, " + col * ").concat(o, " + depth + ").concat(h, ";\n        vec2 uv = uvFromFlat(").concat(c, ", ").concat(p, ", index);\n        return sampleTexture(").concat(r, ", uv);\n      }\n  ");
}

function getPackedSamplerND$1(e, t) {
  var n = e.name,
      r = "get" + n.charAt(0).toUpperCase() + n.slice(1),
      a = getGlslDifferences$1();
  if (t) return "\n    vec4 ".concat(r, "(int b2, int b, int row, int col) {\n      int valuesPerRow = int(ceil(float(").concat(n, "Shape[3]) / 2.0));\n      int texelsInBatch = valuesPerRow * int(ceil(float(").concat(n, "Shape[2]) / 2.0));\n      int index = b * texelsInBatch + (row / 2) * valuesPerRow + (col / 2);\n      texelsInBatch *= ").concat(n, "Shape[1];\n      index = b2 * texelsInBatch + index;\n      ivec2 packedTexShape = ivec2(ceil(float(").concat(n, "TexShape[0]) / 2.0), ceil(float(").concat(n, "TexShape[1]) / 2.0));\n      int texR = index / packedTexShape[1];\n      int texC = index - texR * packedTexShape[1];\n      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(packedTexShape[1], packedTexShape[0]); return ").concat(a.texture2D, "(").concat(n, ", uv);\n    }\n  ");
  var s = e.shapeInfo.logicalShape,
      o = s.length,
      i = e.shapeInfo.texShape,
      l = [Math.ceil(i[0] / 2), Math.ceil(i[1] / 2)],
      u = l[0],
      c = l[1],
      p = Math.ceil(s[o - 1] / 2);
  var d = p * Math.ceil(s[o - 2] / 2),
      h = "int b, int row, int col",
      m = "b * ".concat(d, " + (row / 2) * ").concat(p, " + (col / 2)");

  for (var _e421 = 2; _e421 < o - 1; _e421++) {
    h = "int b".concat(_e421, ", ") + h, d *= s[o - _e421 - 1], m = "b".concat(_e421, " * ").concat(d, " + ") + m;
  }

  return "\n    vec4 ".concat(r, "(").concat(h, ") {\n      int index = ").concat(m, ";\n      int texR = index / ").concat(c, ";\n      int texC = index - texR * ").concat(c, ";\n      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(").concat(c, ", ").concat(u, ");\n      return ").concat(a.texture2D, "(").concat(n, ", uv);\n    }\n  ");
}

function getSampler4D$1(e, t) {
  var n = e.shapeInfo.logicalShape,
      r = e.name,
      a = "get" + r.charAt(0).toUpperCase() + r.slice(1),
      s = n[3],
      o = n[2] * s,
      i = n[1] * o,
      {
    newShape: l,
    keptDims: u
  } = squeezeShape$1(n);

  if (l.length < n.length) {
    var _n198 = ["row", "col", "depth", "depth2"];
    return "\n      ".concat(getSamplerFromInInfo$1(squeezeInputInfo$1(e, l), t), "\n      float ").concat(a, "(int row, int col, int depth, int depth2) {\n        return ").concat(a, "(").concat(getSqueezedParams$1(_n198, u), ");\n      }\n    ");
  }

  if (e.shapeInfo.isUniform) return "\n      float ".concat(a, "(int row, int col, int depth, int depth2) {\n        int index = round(dot(vec4(row, col, depth, depth2),\n                          vec4(").concat(i, ", ").concat(o, ", ").concat(s, ", 1)));\n        ").concat(getUniformSampler$1(e), "\n      }\n    ");
  var c = e.shapeInfo.flatOffset,
      p = e.shapeInfo.texShape,
      d = p[0],
      h = p[1],
      m = "int stride2 = ".concat(r, "Shape[3];"),
      f = "int stride1 = ".concat(r, "Shape[2] * stride2;"),
      g = "int stride0 = ".concat(r, "Shape[1] * stride1;");
  if (h === i && null == c) return t ? "\n      float ".concat(a, "(int row, int col, int depth, int depth2) {\n        ").concat(m, "\n        ").concat(f, "\n        float texR = float(row);\n        float texC =\n            dot(vec3(col, depth, depth2),\n                vec3(stride1, stride2, 1));\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(").concat(r, "TexShape[1], ").concat(r, "TexShape[0]);\n        return sampleTexture(").concat(r, ", uv);\n      }\n    ") : "\n      float ".concat(a, "(int row, int col, int depth, int depth2) {\n        float texR = float(row);\n        float texC =\n            dot(vec3(col, depth, depth2),\n                vec3(").concat(o, ", ").concat(s, ", 1));\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(").concat(h, ".0, ").concat(d, ".0);\n        return sampleTexture(").concat(r, ", uv);\n      }\n    ");
  if (h === s && null == c) return t ? "\n      float ".concat(a, "(int row, int col, int depth, int depth2) {\n        float texR = dot(vec3(row, col, depth),\n                         vec3(").concat(r, "Shape[1] * ").concat(r, "Shape[2], ").concat(r, "Shape[2], 1));\n        float texC = float(depth2);\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                  vec2(").concat(r, "TexShape[1], ").concat(r, "TexShape[0]);\n        return sampleTexture(").concat(r, ", uv);\n      }\n    ") : "\n      float ".concat(a, "(int row, int col, int depth, int depth2) {\n        float texR = dot(vec3(row, col, depth),\n                         vec3(").concat(n[1] * n[2], ", ").concat(n[2], ", 1));\n        float texC = float(depth2);\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                  vec2(").concat(h, ".0, ").concat(d, ".0);\n        return sampleTexture(").concat(r, ", uv);\n      }\n    ");
  var $ = getFlatOffsetUniformName$1(r);
  return t ? "\n    float ".concat(a, "(int row, int col, int depth, int depth2) {\n      // Explicitly use integer operations as dot() only works on floats.\n      ").concat(m, "\n      ").concat(f, "\n      ").concat(g, "\n      int index = row * stride0 + col * stride1 +\n          depth * stride2 + depth2;\n      vec2 uv = uvFromFlat(").concat(r, "TexShape[0], ").concat(r, "TexShape[1], index + ").concat($, ");\n      return sampleTexture(").concat(r, ", uv);\n    }\n  ") : "\n    float ".concat(a, "(int row, int col, int depth, int depth2) {\n      // Explicitly use integer operations as dot() only works on floats.\n      int index = row * ").concat(i, " + col * ").concat(o, " +\n          depth * ").concat(s, " + depth2;\n      vec2 uv = uvFromFlat(").concat(d, ", ").concat(h, ", index + ").concat($, ");\n      return sampleTexture(").concat(r, ", uv);\n    }\n  ");
}

function getSampler5D$1(e) {
  var t = e.shapeInfo.logicalShape,
      n = e.name,
      r = "get" + n.charAt(0).toUpperCase() + n.slice(1),
      a = t[4],
      s = t[3] * a,
      o = t[2] * s,
      i = t[1] * o,
      {
    newShape: l,
    keptDims: u
  } = squeezeShape$1(t);

  if (l.length < t.length) {
    var _t304 = ["row", "col", "depth", "depth2", "depth3"];
    return "\n      ".concat(getSamplerFromInInfo$1(squeezeInputInfo$1(e, l)), "\n      float ").concat(r, "(int row, int col, int depth, int depth2, int depth3) {\n        return ").concat(r, "(").concat(getSqueezedParams$1(_t304, u), ");\n      }\n    ");
  }

  if (e.shapeInfo.isUniform) return "\n      float ".concat(r, "(int row, int col, int depth, int depth2, int depth3) {\n        float index = dot(\n          vec4(row, col, depth, depth2),\n          vec4(").concat(i, ", ").concat(o, ", ").concat(s, ", ").concat(a, ")) +\n          depth3;\n        ").concat(getUniformSampler$1(e), "\n      }\n    ");
  var c = e.shapeInfo.flatOffset,
      p = e.shapeInfo.texShape,
      d = p[0],
      h = p[1];
  return h === i && null == c ? "\n      float ".concat(r, "(int row, int col, int depth, int depth2, int depth3) {\n        int texR = row;\n        float texC = dot(vec4(col, depth, depth2, depth3),\n                         vec4(").concat(o, ", ").concat(s, ", ").concat(a, ", 1));\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(").concat(h, ".0, ").concat(d, ".0);\n        return sampleTexture(").concat(n, ", uv);\n      }\n    ") : h === a && null == c ? "\n      float ".concat(r, "(int row, int col, int depth, int depth2, int depth3) {\n        float texR = dot(\n          vec4(row, col, depth, depth2),\n          vec4(").concat(t[1] * t[2] * t[3], ",\n               ").concat(t[2] * t[3], ", ").concat(t[3], ", 1));\n        int texC = depth3;\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                  vec2(").concat(h, ".0, ").concat(d, ".0);\n        return sampleTexture(").concat(n, ", uv);\n      }\n    ") : "\n    float ".concat(r, "(int row, int col, int depth, int depth2, int depth3) {\n      // Explicitly use integer operations as dot() only works on floats.\n      int index = row * ").concat(i, " + col * ").concat(o, " + depth * ").concat(s, " +\n          depth2 * ").concat(a, " + depth3 + ").concat(getFlatOffsetUniformName$1(n), ";\n      vec2 uv = uvFromFlat(").concat(d, ", ").concat(h, ", index);\n      return sampleTexture(").concat(n, ", uv);\n    }\n  ");
}

function getSampler6D$1(e) {
  var t = e.shapeInfo.logicalShape,
      n = e.name,
      r = "get" + n.charAt(0).toUpperCase() + n.slice(1),
      {
    newShape: a,
    keptDims: s
  } = squeezeShape$1(t);

  if (a.length < t.length) {
    var _t305 = ["row", "col", "depth", "depth2", "depth3", "depth4"];
    return "\n      ".concat(getSamplerFromInInfo$1(squeezeInputInfo$1(e, a)), "\n      float ").concat(r, "(int row, int col, int depth,\n                    int depth2, int depth3, int depth4) {\n        return ").concat(r, "(").concat(getSqueezedParams$1(_t305, s), ");\n      }\n    ");
  }

  var o = t[5],
      i = t[4] * o,
      l = t[3] * i,
      u = t[2] * l,
      c = t[1] * u;
  if (e.shapeInfo.isUniform) return "\n      float ".concat(r, "(int row, int col, int depth,\n                  int depth2, int depth3, int depth4) {\n        int index = round(dot(\n          vec4(row, col, depth, depth2),\n          vec4(").concat(c, ", ").concat(u, ", ").concat(l, ", ").concat(i, ")) +\n          dot(\n            vec2(depth3, depth4),\n            vec2(").concat(o, ", 1)));\n        ").concat(getUniformSampler$1(e), "\n      }\n    ");
  var p = e.shapeInfo.flatOffset,
      d = e.shapeInfo.texShape,
      h = d[0],
      m = d[1];
  return m === c && null == p ? "\n      float ".concat(r, "(int row, int col, int depth,\n                    int depth2, int depth3, int depth4) {\n        int texR = row;\n        float texC = dot(vec4(col, depth, depth2, depth3),\n          vec4(").concat(u, ", ").concat(l, ", ").concat(i, ", ").concat(o, ")) +\n               float(depth4);\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(").concat(m, ".0, ").concat(h, ".0);\n        return sampleTexture(").concat(n, ", uv);\n      }\n    ") : m === o && null == p ? "\n      float ".concat(r, "(int row, int col, int depth,\n                    int depth2, int depth3, int depth4) {\n        float texR = dot(vec4(row, col, depth, depth2),\n          vec4(").concat(t[1] * t[2] * t[3] * t[4], ",\n               ").concat(t[2] * t[3] * t[4], ",\n               ").concat(t[3] * t[4], ",\n               ").concat(t[4], ")) + float(depth3);\n        int texC = depth4;\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                  vec2(").concat(m, ".0, ").concat(h, ".0);\n        return sampleTexture(").concat(n, ", uv);\n      }\n    ") : "\n    float ".concat(r, "(int row, int col, int depth,\n                  int depth2, int depth3, int depth4) {\n      // Explicitly use integer operations as dot() only works on floats.\n      int index = row * ").concat(c, " + col * ").concat(u, " + depth * ").concat(l, " +\n          depth2 * ").concat(i, " + depth3 * ").concat(o, " + depth4 + ").concat(getFlatOffsetUniformName$1(n), ";\n      vec2 uv = uvFromFlat(").concat(h, ", ").concat(m, ", index);\n      return sampleTexture(").concat(n, ", uv);\n    }\n  ");
}

function getUniformSampler$1(e) {
  var t = e.name,
      n = sizeFromShape$1(e.shapeInfo.logicalShape);
  return n < 2 ? "return ".concat(t, ";") : "\n    for (int i = 0; i < ".concat(n, "; i++) {\n      if (i == index) {\n        return ").concat(t, "[i];\n      }\n    }\n  ");
}

function getPackedSamplerAtOutputCoords$1(e, t) {
  var n = e.name,
      r = n.charAt(0).toUpperCase() + n.slice(1),
      a = "get" + r + "AtOutCoords",
      s = e.shapeInfo.logicalShape.length,
      o = t.logicalShape.length,
      i = getBroadcastDims$2(e.shapeInfo.logicalShape, t.logicalShape),
      l = getCoordsDataType$1(o),
      u = o - s;
  var c;
  var p = ["x", "y", "z", "w", "u", "v"];
  c = 0 === s ? "" : o < 2 && i.length >= 1 ? "coords = 0;" : i.map(e => "coords.".concat(p[e + u], " = 0;")).join("\n");
  var d = "";
  d = o < 2 && s > 0 ? "coords" : e.shapeInfo.logicalShape.map((e, t) => "coords.".concat(p[t + u])).join(", ");
  var h = "return outputValue;";
  var m = 1 === sizeFromShape$1(e.shapeInfo.logicalShape),
      f = 1 === sizeFromShape$1(t.logicalShape);

  if (1 !== s || m || f) {
    if (m && !f) h = 1 === o ? "\n        return vec4(outputValue.x, outputValue.x, 0., 0.);\n      " : "\n        return vec4(outputValue.x);\n      ";else if (i.length) {
      var _e422 = s - 2,
          _t306 = s - 1;

      i.indexOf(_e422) > -1 && i.indexOf(_t306) > -1 ? h = "return vec4(outputValue.x);" : i.indexOf(_e422) > -1 ? h = "return vec4(outputValue.x, outputValue.y, outputValue.x, outputValue.y);" : i.indexOf(_t306) > -1 && (h = "return vec4(outputValue.xx, outputValue.zz);");
    }
  } else h = "\n      return vec4(outputValue.xy, outputValue.xy);\n    ";

  return "\n    vec4 ".concat(a, "() {\n      ").concat(l, " coords = getOutputCoords();\n      ").concat(c, "\n      vec4 outputValue = get").concat(r, "(").concat(d, ");\n      ").concat(h, "\n    }\n  ");
}

function getSamplerAtOutputCoords$1(e, t) {
  var n = e.name,
      r = n.charAt(0).toUpperCase() + n.slice(1),
      a = "get" + r + "AtOutCoords",
      s = e.shapeInfo.logicalShape.length,
      o = t.logicalShape.length;
  if (!e.shapeInfo.isUniform && s === o && null == e.shapeInfo.flatOffset && arraysEqual$1(e.shapeInfo.texShape, t.texShape)) return "\n      float ".concat(a, "() {\n        return sampleTexture(").concat(n, ", resultUV);\n      }\n    ");
  var i = getCoordsDataType$1(o),
      l = getBroadcastDims$2(e.shapeInfo.logicalShape, t.logicalShape),
      u = o - s;
  var c;
  var p = ["x", "y", "z", "w", "u", "v"];
  c = 0 === s ? "" : o < 2 && l.length >= 1 ? "coords = 0;" : l.map(e => "coords.".concat(p[e + u], " = 0;")).join("\n");
  var d = "";
  return d = o < 2 && s > 0 ? "coords" : e.shapeInfo.logicalShape.map((e, t) => "coords.".concat(p[t + u])).join(", "), "\n    float ".concat(a, "() {\n      ").concat(i, " coords = getOutputCoords();\n      ").concat(c, "\n      return get").concat(r, "(").concat(d, ");\n    }\n  ");
}

function getCoordsDataType$1(e) {
  if (e <= 1) return "int";
  if (2 === e) return "ivec2";
  if (3 === e) return "ivec3";
  if (4 === e) return "ivec4";
  if (5 === e) return "ivec5";
  if (6 === e) return "ivec6";
  throw Error("GPU for rank ".concat(e, " is not yet supported"));
}

function getUniformInfoFromShape$1(e, t, n) {
  var {
    newShape: r
  } = squeezeShape$1(t),
      a = t.length,
      s = e && 3 === a && 1 === t[0],
      o = s ? t.slice(1) : r,
      i = !e && a > 1 && !arraysEqual$1(t, n) && r.length < a || s;
  return {
    useSqueezeShape: i,
    uniformShape: i ? o : t
  };
}

function squeezeInputInfo$1(e, t) {
  var n = JSON.parse(JSON.stringify(e));
  return n.shapeInfo.logicalShape = t, n;
}

function getSqueezedParams$1(e, t) {
  return t.map(t => e[t]).join(", ");
}

function compileProgram$1(e, t, n, r) {
  var a = n.map((e, n) => {
    var r = {
      logicalShape: e.shape,
      texShape: e.isUniform ? null : e.texData.texShape,
      isUniform: e.isUniform,
      isPacked: !e.isUniform && e.texData.isPacked,
      flatOffset: null
    };
    return null != e.texData && null != e.texData.slice && e.texData.slice.flatOffset > 0 && (r.flatOffset = e.texData.slice.flatOffset), {
      name: t.variableNames[n],
      shapeInfo: r
    };
  }),
      s = a.map(e => e.shapeInfo),
      o = {
    logicalShape: r.shape,
    texShape: r.texData.texShape,
    isUniform: !1,
    isPacked: r.texData.isPacked,
    flatOffset: null
  },
      i = makeShader$1(a, o, t),
      l = e.createProgram(i);
  var u = null;
  var c = e.getUniformLocation(l, "NAN", !1);
  1 === env$1().getNumber("WEBGL_VERSION") && (u = e.getUniformLocation(l, "INFINITY", !1));
  var p = !1,
      d = {},
      h = {},
      m = {};

  for (var _n199 = 0; _n199 < t.variableNames.length; _n199++) {
    var _r148 = t.variableNames[_n199];
    d[_r148] = e.getUniformLocation(l, _r148, p), d["offset".concat(_r148)] = e.getUniformLocation(l, "offset".concat(_r148), p), t.enableShapeUniforms && (h["".concat(_r148, "Shape")] = e.getUniformLocation(l, "".concat(_r148, "Shape"), p), m["".concat(_r148, "TexShape")] = e.getUniformLocation(l, "".concat(_r148, "TexShape"), p));
  }

  var f, g, $;
  t.enableShapeUniforms && (f = e.getUniformLocation(l, "outShape", p), $ = e.getUniformLocation(l, "outShapeStrides", p), g = e.getUniformLocation(l, "outTexShape", p));
  var y = [];
  return t.customUniforms && t.customUniforms.forEach((t, n) => {
    y[n] = e.getUniformLocation(l, t.name, p);
  }), {
    program: t,
    source: i,
    webGLProgram: l,
    uniformLocations: d,
    customUniformLocations: y,
    inShapeInfos: s,
    outShapeInfo: o,
    infLoc: u,
    nanLoc: c,
    inShapesLocations: h,
    inTexShapesLocations: m,
    outShapeLocation: f,
    outShapeStridesLocation: $,
    outTexShapeLocation: g
  };
}

function validateBinaryAndProgram$1(e, t) {
  if (e.length !== t.length) throw Error("Binary was compiled with ".concat(e.length, " inputs, but was executed with ").concat(t.length, " inputs"));
  e.forEach((e, n) => {
    var r = e.logicalShape,
        a = t[n],
        s = a.shape;
    if (!arraysEqual$1(r, s)) throw Error("Binary was compiled with different shapes than the current args. Shapes ".concat(r, " and ").concat(s, " must match"));
    if (e.isUniform && a.isUniform) return;
    var o = e.texShape,
        i = a.isUniform ? null : a.texData.texShape;
    if (!arraysEqual$1(o, i)) throw Error("Binary was compiled with different texture shapes than the current args. Shape ".concat(o, " and ").concat(i, " must match"));
  });
}

function runProgram$1(e, t, n, r, a) {
  t.program.enableShapeUniforms || (validateBinaryAndProgram$1(t.inShapeInfos, n), validateBinaryAndProgram$1([t.outShapeInfo], [r]));
  var s = r.texData.texture,
      o = r.texData.texShape;
  r.texData.isPacked ? e.setOutputPackedMatrixTexture(s, o[0], o[1]) : e.setOutputMatrixTexture(s, o[0], o[1]), e.setProgram(t.webGLProgram), 1 === env$1().getNumber("WEBGL_VERSION") && null !== t.infLoc && e.gl.uniform1f(t.infLoc, Infinity), null !== t.nanLoc && e.gl.uniform1f(t.nanLoc, NaN), n.forEach((n, r) => {
    var a = t.program.variableNames[r],
        s = t.uniformLocations[a],
        o = t.uniformLocations["offset".concat(a)],
        i = t.inShapesLocations["".concat(a, "Shape")],
        l = t.inTexShapesLocations["".concat(a, "TexShape")];

    if (i) {
      var {
        uniformShape: _r149
      } = getUniformInfoFromShape$1(t.program.packedInputs, n.shape, n.texData.texShape);

      switch (_r149.length) {
        case 1:
          e.gl.uniform1iv(i, new Int32Array(_r149));
          break;

        case 2:
          e.gl.uniform2iv(i, new Int32Array(_r149));
          break;

        case 3:
          e.gl.uniform3iv(i, new Int32Array(_r149));
          break;

        case 4:
          e.gl.uniform4iv(i, new Int32Array(_r149));
      }
    }

    if (l && e.gl.uniform2i(l, n.texData.texShape[0], n.texData.texShape[1]), null != s) if (n.isUniform) {
      if (sizeFromShape$1(n.shape) < 2) e.gl.uniform1f(s, n.uniformValues[0]);else {
        var _t307 = n.uniformValues;
        _t307 instanceof Float32Array || (_t307 = new Float32Array(_t307)), e.gl.uniform1fv(s, _t307);
      }
    } else null != n.texData.slice && null != o && e.gl.uniform1i(o, n.texData.slice.flatOffset), e.setInputMatrixTexture(n.texData.texture, s, r);
  });
  var i = t.outShapeLocation;
  if (i) switch (r.shape.length) {
    case 1:
      e.gl.uniform1iv(i, new Int32Array(r.shape));
      break;

    case 2:
      e.gl.uniform2iv(i, new Int32Array(r.shape));
      break;

    case 3:
      e.gl.uniform3iv(i, new Int32Array(r.shape));
      break;

    case 4:
      e.gl.uniform4iv(i, new Int32Array(r.shape));
  }

  if (t.outShapeStridesLocation) {
    var _n200 = computeStrides$1(r.shape);

    switch (r.shape.length) {
      case 2:
        e.gl.uniform1iv(t.outShapeStridesLocation, new Int32Array(_n200));
        break;

      case 3:
        e.gl.uniform2iv(t.outShapeStridesLocation, new Int32Array(_n200));
        break;

      case 4:
        e.gl.uniform3iv(t.outShapeStridesLocation, new Int32Array(_n200));
    }
  }

  t.outTexShapeLocation && e.gl.uniform2i(t.outTexShapeLocation, r.texData.texShape[0], r.texData.texShape[1]), t.program.customUniforms && a && t.program.customUniforms.forEach((n, r) => {
    var s = t.customUniformLocations[r],
        o = a[r];
    if ("float" === n.type) e.gl.uniform1fv(s, o);else if ("vec2" === n.type) e.gl.uniform2fv(s, o);else if ("vec3" === n.type) e.gl.uniform3fv(s, o);else if ("vec4" === n.type) e.gl.uniform4fv(s, o);else if ("int" === n.type) e.gl.uniform1iv(s, o);else if ("ivec2" === n.type) e.gl.uniform2iv(s, o);else if ("ivec3" === n.type) e.gl.uniform3iv(s, o);else {
      if ("ivec4" !== n.type) throw Error("uniform type ".concat(n.type, " is not supported yet."));
      e.gl.uniform4iv(s, o);
    }
  }), e.executeProgram();
}

function makeShaderKey$1(e, t, n) {
  var r = "";
  t.concat(n).forEach(t => {
    var a = null != t.texData && null != t.texData.slice && t.texData.slice.flatOffset > 0;

    if (e.enableShapeUniforms && !t.isUniform) {
      var s = t.texData.texShape,
          {
        useSqueezeShape: o,
        uniformShape: i
      } = getUniformInfoFromShape$1(e.packedInputs, t.shape, s);
      var l = "",
          u = "",
          c = "";

      if (1 === i.length && e.packedInputs) {
        var _e423 = [Math.ceil(s[0] / 2), Math.ceil(s[1] / 2)];
        l = "".concat(_e423[0] > 1, "_").concat(_e423[1] > 1);
      } else if (2 !== i.length || e.packedInputs) {
        if (i.length > 2 && !e.packedInputs) {
          var _e424 = computeStrides$1(i);

          c = "".concat(_e424[0] === s[1], "_").concat(_e424[_e424.length - 1] === s[1]);
        }
      } else u = "".concat(i[0] > 1, "_").concat(i[1] > 1);

      var _p15 = t.shape.length,
          d = 2 === _p15 && arraysEqual$1(t.shape, s),
          h = 1 === sizeFromShape$1(t.shape),
          m = getBroadcastDims$3(t.shape, n.shape),
          f = !e.packedInputs && _p15 === n.shape.length && arraysEqual$1(s, n.texData.texShape);
      r += "".concat(_p15, "_").concat(f, "_").concat(o, "_").concat(i.length, "_").concat(h, "_").concat(m, "_").concat(d, "_").concat(l, "_").concat(u, "_").concat(c, "_").concat(e.packedInputs || _p15 > 2 ? "" : "".concat(s[0] > 1, "_").concat(s[1] > 1), "_").concat(a);
    } else r += "".concat(t.shape, "_").concat(t.isUniform ? "uniform" : t.texData.texShape, "_").concat(a);
  });
  var a = e.constructor.name;
  return a += "_" + r + "_" + e.userCode + "".concat(env$1().getNumber("WEBGL_VERSION")), a;
}

function useShapeUniforms$1(e) {
  return env$1().getBool("WEBGL_USE_SHAPES_UNIFORMS") && e <= 4;
}

var {
  addImpl: addImplCPU$1,
  bincountImpl: bincountImplCPU$1,
  bincountReduceImpl: bincountReduceImplCPU$1,
  ceilImpl: ceilImplCPU$1,
  concatImpl: concatImplCPU$1,
  equalImpl: equalImplCPU$1,
  expImpl: expImplCPU$1,
  expm1Impl: expm1ImplCPU$1,
  floorImpl: floorImplCPU$1,
  gatherNdImpl: gatherNdImplCPU$1,
  gatherV2Impl: gatherV2ImplCPU$1,
  greaterImpl: greaterImplCPU$1,
  greaterEqualImpl: greaterEqualImplCPU$1,
  lessImpl: lessImplCPU$1,
  lessEqualImpl: lessEqualImplCPU$1,
  linSpaceImpl: linSpaceImplCPU$1,
  logImpl: logImplCPU$1,
  maxImpl: maxImplCPU$1,
  maximumImpl: maximumImplCPU$1,
  minimumImpl: minimumImplCPU$1,
  multiplyImpl: multiplyImplCPU$1,
  negImpl: negImplCPU$1,
  notEqualImpl: notEqualImplCPU$1,
  prodImpl: prodImplCPU$1,
  rangeImpl: rangeImplCPU$1,
  rsqrtImpl: rsqrtImplCPU$1,
  simpleAbsImpl: simpleAbsImplCPU$1,
  sliceImpl: sliceImplCPU$1,
  sparseFillEmptyRowsImpl: sparseFillEmptyRowsImplCPU$1,
  sparseReshapeImpl: sparseReshapeImplCPU$1,
  sparseSegmentReductionImpl: sparseSegmentReductionImplCPU$1,
  stridedSliceImpl: stridedSliceImplCPU$1,
  stringNGramsImpl: stringNGramsImplCPU$1,
  stringSplitImpl: stringSplitImplCPU$1,
  stringToHashBucketFastImpl: stringToHashBucketFastImplCPU$1,
  subImpl: subImplCPU$1,
  tileImpl: tileImplCPU$1,
  topKImpl: topKImplCPU$1,
  transposeImpl: transposeImplCPU$1,
  uniqueImpl: uniqueImplCPU$1
} = shared$1;

function getVecChannels$1(e, t) {
  return ["x", "y", "z", "w", "u", "v"].slice(0, t).map(t => "".concat(e, ".").concat(t));
}

function getChannels$1(e, t) {
  return 1 === t ? [e] : getVecChannels$1(e, t);
}

function getSourceCoords$5(e, t) {
  if (1 === e) return "rc";
  var n = "";

  for (var r = 0; r < e; r++) {
    n += t[r], r < e - 1 && (n += ",");
  }

  return n;
}

class PackProgram$1 {
  constructor(e) {
    this.variableNames = ["A"], this.packedInputs = !1, this.packedOutput = !0, this.outputShape = e;
    var t = e.length;
    if (0 === t) this.userCode = "\n        void main() {\n          setOutput(vec4(getA(), 0., 0., 0.));\n        }\n      ";else {
      var n = getChannels$1("rc", t),
          r = getCoordsDataType$1(t),
          a = getOutOfBoundsCondition$1(t, e, n),
          s = getSetup$1(t, e[e.length - 1], e[e.length - 2], n),
          o = getOutput$1(e, n);
      this.userCode = "\n        void main() {\n          ".concat(r, " rc = getOutputCoords();\n\n          if(").concat(a, ") {\n            setOutput(vec4(0));\n          } else {\n            ").concat(s, "\n\n            setOutput(vec4(").concat(o, "));\n          }\n        }\n      ");
    }
  }

}

function getSourceCoordsArr$1(e, t) {
  var n = [];

  for (var r = 0; r <= 1; r++) {
    for (var a = 0; a <= 1; a++) {
      var s = "".concat(0 === r ? "r" : "rp1", ", ").concat(0 === a ? "c" : "cp1");

      for (var _n201 = 2; _n201 < e; _n201++) {
        s = "".concat(t[t.length - 1 - _n201], ",") + s;
      }

      n.push(s);
    }
  }

  return n;
}

function getOutOfBoundsCondition$1(e, t, n) {
  if (1 === e) return "rc > ".concat(t[0]);
  var r = "";

  for (var a = e - 2; a < e; a++) {
    r += "".concat(n[a], " >= ").concat(t[a]), a < e - 1 && (r += "||");
  }

  return r;
}

function getSetup$1(e, t, n, r) {
  if (1 === e) return "";
  var a = r.slice(-2);
  return "\n    int r = ".concat(a[0], ";\n    int c = ").concat(a[1], ";\n    int rp1 = r + 1;\n    int cp1 = c + 1;\n\n    bool cEdge = cp1 >= ").concat(t, ";\n    bool rEdge = rp1 >= ").concat(n, ";\n  ");
}

function getOutput$1(e, t) {
  var n = e.length,
      r = getSourceCoordsArr$1(n, t);
  return 1 === n ? "getA(rc),\n            rc + 1 >= ".concat(e[0], " ? 0. : getA(rc + 1),\n            0, 0") : "getA(".concat(r[0], "),\n          cEdge ? 0. : getA(").concat(r[1], "),\n          rEdge ? 0. : getA(").concat(r[2], "),\n          rEdge || cEdge ? 0. : getA(").concat(r[3], ")");
}

class ReshapePackedProgram$1 {
  constructor(e, t) {
    this.variableNames = ["A"], this.packedInputs = !0, this.packedOutput = !0, this.outputShape = e;
    var n = "";

    for (var _e425 = 0; _e425 < 4; _e425++) {
      var _t308 = "thisRC = rc;";
      _e425 % 2 == 1 && (_t308 += "thisRC.z += 1;"), _e425 > 1 && (_t308 += "thisRC.y += 1;"), n += "\n        ".concat(_t308, "\n        ").concat(_e425 > 0 ? "if(thisRC.y < rows && thisRC.z < cols){" : "", "\n          int flatIndex = getFlatIndex(thisRC);\n\n          ivec3 inputRC = inputCoordsFromReshapedOutCoords(flatIndex);\n          vec2 inputRCInnerDims = vec2(float(inputRC.y),float(inputRC.z));\n\n          result[").concat(_e425, "] =\n            getChannel(getA(inputRC.x, inputRC.y, inputRC.z), inputRCInnerDims);\n        ").concat(_e425 > 0 ? "}" : "", "\n      ");
    }

    this.userCode = "\n      ".concat(getReshapedInputCoords$1(t), "\n      ").concat(getFlatIndexFrom3D$1(e), "\n\n      void main() {\n        ivec3 rc = getOutputCoords();\n\n        vec4 result = vec4(0.);\n\n        ivec3 thisRC;\n        int rows = ").concat(e[1], ";\n        int cols = ").concat(e[2], ";\n\n        ").concat(n, "\n\n        setOutput(result);\n      }\n    ");
  }

}

function getReshapedInputCoords$1(e) {
  return "\n    ivec3 inputCoordsFromReshapedOutCoords(int index) {\n      ".concat(getLogicalCoordinatesFromFlatIndex$1(["r", "c", "d"], e), "\n      return ivec3(r, c, d);\n    }\n  ");
}

class TextureManager$1 {
  constructor(e) {
    this.gpgpu = e, this.numUsedTextures = 0, this.numFreeTextures = 0, this._numBytesAllocated = 0, this._numBytesFree = 0, this.freeTextures = {}, this.logEnabled = !1, this.usedTextures = {};
  }

  acquireTexture(e, t, n) {
    var r = getPhysicalFromLogicalTextureType$1(t, n),
        a = getKeyFromTextureShape$1(e, r, n);
    a in this.freeTextures || (this.freeTextures[a] = []), a in this.usedTextures || (this.usedTextures[a] = []);
    var s = computeBytes$1(e, r, this.gpgpu.gl, this.gpgpu.textureConfig, n);

    if (this.freeTextures[a].length > 0) {
      this.numFreeTextures--, this.numUsedTextures++, this._numBytesFree -= s, this.log();

      var _e426 = this.freeTextures[a].shift();

      return this.usedTextures[a].push(_e426), _e426;
    }

    var o;
    return r === PhysicalTextureType$1.PACKED_2X2_FLOAT32 ? o = this.gpgpu.createPackedMatrixTexture(e[0], e[1]) : r === PhysicalTextureType$1.PACKED_2X2_FLOAT16 ? o = this.gpgpu.createFloat16PackedMatrixTexture(e[0], e[1]) : r === PhysicalTextureType$1.UNPACKED_FLOAT32 ? o = this.gpgpu.createFloat32MatrixTexture(e[0], e[1]) : r === PhysicalTextureType$1.UNPACKED_FLOAT16 ? o = this.gpgpu.createFloat16MatrixTexture(e[0], e[1]) : r === PhysicalTextureType$1.PACKED_4X1_UNSIGNED_BYTE && (o = this.gpgpu.createUnsignedBytesMatrixTexture(e[0], e[1])), this.usedTextures[a].push(o), this.numUsedTextures++, this._numBytesAllocated += s, this.log(), o;
  }

  releaseTexture(e, t, n, r) {
    if (null == this.freeTextures) return;
    var a = getPhysicalFromLogicalTextureType$1(n, r),
        s = getKeyFromTextureShape$1(t, a, r);
    s in this.freeTextures || (this.freeTextures[s] = []);
    var o = computeBytes$1(t, a, this.gpgpu.gl, this.gpgpu.textureConfig, r),
        i = env$1().get("WEBGL_DELETE_TEXTURE_THRESHOLD");
    -1 !== i && this._numBytesAllocated > i ? (this.gpgpu.deleteMatrixTexture(e), this._numBytesAllocated -= o) : (this.freeTextures[s].push(e), this.numFreeTextures++, this._numBytesFree += o), this.numUsedTextures--;
    var l = this.usedTextures[s],
        u = l.indexOf(e);
    if (u < 0) throw new Error("Cannot release a texture that was never provided by this texture manager");
    l.splice(u, 1), this.log();
  }

  log() {
    if (!this.logEnabled) return;
    console.log("Free/Used", "".concat(this.numFreeTextures, " / ").concat(this.numUsedTextures), "(".concat(this.numFreeTextures + this.numUsedTextures, ")"));
    var e = this._numBytesFree / this._numBytesAllocated;
    console.log("Bytes allocated: ".concat(this._numBytesAllocated)), console.log("Bytes unused: ".concat(this._numBytesFree, " (").concat(Math.round(100 * e), "%)"));
  }

  get numBytesAllocated() {
    return this._numBytesAllocated;
  }

  get numBytesFree() {
    return this._numBytesFree;
  }

  getNumUsedTextures() {
    return this.numUsedTextures;
  }

  getNumFreeTextures() {
    return this.numFreeTextures;
  }

  dispose() {
    if (null != this.freeTextures) {
      for (var _e427 in this.freeTextures) {
        this.freeTextures[_e427].forEach(e => {
          this.gpgpu.deleteMatrixTexture(e);
        });
      }

      for (var _e428 in this.usedTextures) {
        this.usedTextures[_e428].forEach(e => {
          this.gpgpu.deleteMatrixTexture(e);
        });
      }

      this.freeTextures = null, this.usedTextures = null, this.numUsedTextures = 0, this.numFreeTextures = 0, this._numBytesAllocated = 0, this._numBytesFree = 0;
    }
  }

}

function numBytesForInternalFormat$1(e, t) {
  if (t === e.R32F) return 4;
  if (t === e.R16F) return 2;
  if (t === e.RGBA32F) return 16;
  if (t === e.RGBA) return 16;
  if (t === e.RGBA16F) return 8;
  throw new Error("Unknown internal format ".concat(t));
}

function computeBytes$1(e, t, n, r, a) {
  var s = internalFormatForPhysicalTexType$1(t, r);
  var o;

  if (a) {
    var [_t309, _n202] = getPackedMatrixTextureShapeWidthHeight$1(e[0], e[1]);
    o = _t309 * _n202;
  } else {
    var [_t310, _n203] = getUnpackedMatrixTextureShapeWidthHeight$1(e[0], e[1]);
    o = _t310 * _n203;
  }

  return o * numBytesForInternalFormat$1(n, s);
}

function internalFormatForPhysicalTexType$1(e, t) {
  switch (e) {
    case PhysicalTextureType$1.PACKED_2X2_FLOAT32:
      return getInternalFormatForPackedMatrixTexture$1(t);

    case PhysicalTextureType$1.PACKED_2X2_FLOAT16:
      return getInternalFormatForFloat16PackedMatrixTexture$1(t);

    case PhysicalTextureType$1.UNPACKED_FLOAT32:
      return getInternalFormatForFloat32MatrixTexture$1(t);

    case PhysicalTextureType$1.UNPACKED_FLOAT16:
      return getInternalFormatForFloat16MatrixTexture$1(t);

    case PhysicalTextureType$1.PACKED_4X1_UNSIGNED_BYTE:
      return getInternalFormatForUnsignedBytesMatrixTexture$1(t);

    default:
      throw new Error("Unknown physical texture type ".concat(e));
  }
}

function getPhysicalTextureForRendering$1(e) {
  return env$1().getBool("WEBGL_RENDER_FLOAT32_ENABLED") ? e ? PhysicalTextureType$1.PACKED_2X2_FLOAT32 : PhysicalTextureType$1.UNPACKED_FLOAT32 : e ? PhysicalTextureType$1.PACKED_2X2_FLOAT16 : PhysicalTextureType$1.UNPACKED_FLOAT16;
}

function getPhysicalFromLogicalTextureType$1(e, t) {
  if (e === TextureUsage$1.UPLOAD) return PhysicalTextureType$1.PACKED_2X2_FLOAT32;
  if (e === TextureUsage$1.RENDER || null == e) return getPhysicalTextureForRendering$1(t);
  if (e === TextureUsage$1.DOWNLOAD || e === TextureUsage$1.PIXELS) return PhysicalTextureType$1.PACKED_4X1_UNSIGNED_BYTE;
  throw new Error("Unknown logical texture type ".concat(e));
}

function getKeyFromTextureShape$1(e, t, n) {
  return "".concat(e[0], "_").concat(e[1], "_").concat(t, "_").concat(n);
}

class UnaryOpProgram$1 {
  constructor(e, t) {
    this.variableNames = ["A"], this.outputShape = e, this.enableShapeUniforms = useShapeUniforms$1(this.outputShape.length), this.userCode = "\n      float unaryOperation(float x) {\n        ".concat(t, "\n      }\n\n      void main() {\n        float x = getAAtOutCoords();\n        float y = unaryOperation(x);\n\n        setOutput(y);\n      }\n    ");
  }

}

var CHECK_NAN_SNIPPET$5 = "if (isnan(x)) return x;",
    LINEAR$3 = "return x;",
    ABS$3 = "return abs(x);",
    ELU$6 = "return (x >= 0.0) ? x : (exp(x) - 1.0);",
    RELU$5 = CHECK_NAN_SNIPPET$5 + "\n  return (x < 0.0) ? 0.0 : x;\n",
    RELU6$5 = CHECK_NAN_SNIPPET$5 + "\n  return (x < 0.0) ? 0.0 : min(6.0, x);\n",
    CLONE$1 = "return x;",
    SIGMOID$5 = "return 1.0 / (1.0 + exp(-1.0 * x));",
    LINEAR$2 = "return x;",
    ELU$5 = "\n  vec4 result;\n\n  result.r = (x.r >= 0.0) ? x.r : (exp(x.r) - 1.0);\n  result.g = (x.g >= 0.0) ? x.g : (exp(x.g) - 1.0);\n  result.b = (x.b >= 0.0) ? x.b : (exp(x.b) - 1.0);\n  result.a = (x.a >= 0.0) ? x.a : (exp(x.a) - 1.0);\n\n  return result;\n",
    RELU$4 = "\n  vec4 result = x * vec4(greaterThanEqual(x, vec4(0.0)));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n",
    RELU6$4 = "\n  vec4 result = min(x, vec4(6.)) * vec4(greaterThanEqual(x, vec4(0.0)));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n",
    SIGMOID$4 = "return 1.0 / (1.0 + exp(-1.0 * x));";

class UnaryOpPackedProgram$1 {
  constructor(e, t) {
    this.variableNames = ["A"], this.packedInputs = !0, this.packedOutput = !0, this.outputShape = e, this.enableShapeUniforms = useShapeUniforms$1(this.outputShape.length), this.userCode = "\n      vec4 unaryOperation(vec4 x) {\n        ".concat(t, "\n      }\n\n      void main() {\n        vec4 x = getAAtOutCoords();\n        vec4 y = unaryOperation(x);\n\n        setOutput(y);\n      }\n    ");
  }

}

class UnpackProgram$1 {
  constructor(e) {
    this.variableNames = ["A"], this.packedInputs = !0, this.packedOutput = !1, this.outputShape = e;
    var t = e.length,
        n = getChannels$1("rc", t),
        r = getCoordsDataType$1(t),
        a = getSourceCoords$5(t, n),
        s = n.slice(-2),
        o = t <= 1 ? "rc" : "vec2(".concat(s.join(","), ")");
    this.userCode = "\n      void main() {\n        ".concat(r, " rc = getOutputCoords();\n        vec4 packedInput = getA(").concat(a, ");\n\n        setOutput(getChannel(packedInput, ").concat(o, "));\n      }\n    ");
  }

}

var whereImpl$3 = whereImpl$5,
    EPSILON_FLOAT32$2 = 1e-7,
    EPSILON_FLOAT16$2 = 1e-4,
    binaryCaches$1 = {};

function getBinaryCache$1(e) {
  return e in binaryCaches$1 || (binaryCaches$1[e] = {}), binaryCaches$1[e];
}

var CPU_HANDOFF_SIZE_THRESHOLD$1 = env$1().getNumber("CPU_HANDOFF_SIZE_THRESHOLD"),
    BEFORE_PAGING_CONSTANT$1 = 600;

function numMBBeforeWarning$1() {
  return null == env$1().global.screen ? 1024 : env$1().global.screen.height * env$1().global.screen.width * window.devicePixelRatio * BEFORE_PAGING_CONSTANT$1 / 1024 / 1024;
}

class MathBackendWebGL$1 extends KernelBackend$1 {
  constructor(e) {
    if (super(), this.pendingRead = new WeakMap(), this.pendingDisposal = new WeakSet(), this.dataRefCount = new WeakMap(), this.numBytesInGPU = 0, this.uploadWaitMs = 0, this.downloadWaitMs = 0, this.lastGlFlushTime = 0, this.warnedAboutMemory = !1, this.pendingDeletes = 0, this.disposed = !1, !env$1().getBool("HAS_WEBGL")) throw new Error("WebGL is not supported on this device");

    if (null == e) {
      var _e429 = getWebGLContext$1(env$1().getNumber("WEBGL_VERSION"));

      this.binaryCache = getBinaryCache$1(env$1().getNumber("WEBGL_VERSION")), this.gpgpu = new GPGPUContext$1(_e429), this.canvas = _e429.canvas, this.gpgpuCreatedLocally = !0;
    } else this.gpgpu = e, this.binaryCache = {}, this.gpgpuCreatedLocally = !1, this.canvas = e.gl.canvas;

    this.textureManager = new TextureManager$1(this.gpgpu), this.numMBBeforeWarning = numMBBeforeWarning$1(), this.texData = new DataStorage$1(this, engine$1());
  }

  nextDataId() {
    return MathBackendWebGL$1.nextDataId++;
  }

  numDataIds() {
    return this.texData.numDataIds() - this.pendingDeletes;
  }

  write(e, t, n) {
    if ((env$1().getBool("WEBGL_CHECK_NUMERICAL_PROBLEMS") || env$1().getBool("DEBUG")) && this.checkNumericalProblems(e), "complex64" === n && null != e) throw new Error("Cannot write to a complex64 dtype. Please use tf.complex(real, imag).");
    var r = {
      id: this.nextDataId()
    };
    return this.texData.set(r, {
      shape: t,
      dtype: n,
      values: e,
      usage: TextureUsage$1.UPLOAD,
      refCount: 1
    }), r;
  }

  refCount(e) {
    return this.texData.has(e) ? this.texData.get(e).refCount : 0;
  }

  incRef(e) {
    this.texData.get(e).refCount++;
  }

  decRef(e) {
    this.texData.has(e) && this.texData.get(e).refCount--;
  }

  move(e, t, n, r, a) {
    if (env$1().getBool("DEBUG") && this.checkNumericalProblems(t), "complex64" === r) throw new Error("Cannot write to a complex64 dtype. Please use tf.complex(real, imag).");
    this.texData.set(e, {
      shape: n,
      dtype: r,
      values: t,
      usage: TextureUsage$1.UPLOAD,
      refCount: a
    });
  }

  disposeIntermediateTensorInfo(e) {
    this.disposeData(e.dataId);
  }

  readSync(e) {
    var t = this.texData.get(e),
        {
      values: n,
      dtype: r,
      complexTensorInfos: a,
      slice: s,
      shape: o,
      isPacked: i
    } = t;

    if (null != s) {
      var _t311;

      _t311 = i ? new UnaryOpPackedProgram$1(o, CLONE$1) : new UnaryOpProgram$1(o, CLONE$1);

      var _n204 = this.runWebGLProgram(_t311, [{
        dataId: e,
        shape: o,
        dtype: r
      }], r),
          _a106 = this.readSync(_n204.dataId);

      return this.disposeIntermediateTensorInfo(_n204), _a106;
    }

    if (null != n) return this.convertAndCacheOnCPU(e);
    if ("string" === r) return n;
    var l = null != this.activeTimers;
    var u, c;
    return l && (u = now$1()), c = "complex64" === r ? mergeRealAndImagArrays$1(this.readSync(a.real.dataId), this.readSync(a.imag.dataId)) : this.getValuesFromTexture(e), l && (this.downloadWaitMs += now$1() - u), this.convertAndCacheOnCPU(e, c);
  }

  read(e) {
    var _this73 = this;

    return _asyncToGenerator(function* () {
      if (_this73.pendingRead.has(e)) {
        var _t312 = _this73.pendingRead.get(e);

        return new Promise(e => _t312.push(e));
      }

      var t = _this73.texData.get(e),
          {
        values: n,
        shape: r,
        slice: a,
        dtype: s,
        complexTensorInfos: o,
        isPacked: i
      } = t;

      if (null != a) {
        var _t313;

        _t313 = i ? new UnaryOpPackedProgram$1(r, CLONE$1) : new UnaryOpProgram$1(r, CLONE$1);

        var _n205 = _this73.runWebGLProgram(_t313, [{
          dataId: e,
          shape: r,
          dtype: s
        }], s),
            _a107 = _this73.read(_n205.dataId);

        return _this73.disposeIntermediateTensorInfo(_n205), _a107;
      }

      if (null != n) return _this73.convertAndCacheOnCPU(e);
      if (!env$1().getBool("WEBGL_DOWNLOAD_FLOAT_ENABLED") && 2 === env$1().getNumber("WEBGL_VERSION")) throw new Error("tensor.data() with WEBGL_DOWNLOAD_FLOAT_ENABLED=false and WEBGL_VERSION=2 not yet supported.");
      var l,
          u,
          c = null;

      if ("complex64" !== s && env$1().get("WEBGL_BUFFER_SUPPORTED")) {
        l = _this73.decode(e);

        var _t314 = _this73.texData.get(l.dataId);

        c = _this73.gpgpu.createBufferFromTexture(_t314.texture, ...getDenseTexShape$1(r));
      }

      if (_this73.pendingRead.set(e, []), "complex64" !== s && (yield _this73.gpgpu.createAndWaitForFence()), "complex64" === s) {
        var _e430 = yield Promise.all([_this73.read(o.real.dataId), _this73.read(o.imag.dataId)]);

        u = mergeRealAndImagArrays$1(_e430[0], _e430[1]);
      } else if (null == c) u = _this73.getValuesFromTexture(e);else {
        var _e431 = sizeFromShape$1(r);

        u = _this73.gpgpu.downloadFloat32MatrixFromBuffer(c, _e431);
      }

      if (null != l && _this73.disposeIntermediateTensorInfo(l), null != c) {
        var _e432 = _this73.gpgpu.gl;
        callAndCheck$1(_e432, () => _e432.deleteBuffer(c));
      }

      var p = _this73.convertAndCacheOnCPU(e, u),
          d = _this73.pendingRead.get(e);

      return _this73.pendingRead.delete(e), d.forEach(e => e(p)), _this73.pendingDisposal.has(e) && (_this73.pendingDisposal.delete(e), _this73.disposeData(e) && engine$1().removeDataId(e, _this73), _this73.pendingDeletes--), p;
    })();
  }

  bufferSync(e) {
    var t = this.readSync(e.dataId);
    var n = t;
    if ("string" === e.dtype) try {
      n = t.map(e => decodeString$1(e));
    } catch (e) {
      throw new Error("Failed to decode encoded string bytes into utf-8");
    }
    return buffer$1(e.shape, e.dtype, n);
  }

  checkNumericalProblems(e) {
    if (null != e) for (var t = 0; t < e.length; t++) {
      var n = e[t];

      if (!canBeRepresented$1(n)) {
        if (env$1().getBool("WEBGL_RENDER_FLOAT32_CAPABLE")) throw Error("The value ".concat(n, " cannot be represented with your current settings. Consider enabling float32 rendering: 'tf.env().set('WEBGL_RENDER_FLOAT32_ENABLED', true);'"));
        throw Error("The value ".concat(n, " cannot be represented on this device."));
      }
    }
  }

  getValuesFromTexture(e) {
    var {
      shape: t,
      dtype: n,
      isPacked: r
    } = this.texData.get(e),
        a = sizeFromShape$1(t);

    if (env$1().getBool("WEBGL_DOWNLOAD_FLOAT_ENABLED")) {
      var _n206 = this.decode(e),
          _r150 = this.texData.get(_n206.dataId),
          _s77 = this.gpgpu.downloadMatrixFromPackedTexture(_r150.texture, ...getDenseTexShape$1(t)).subarray(0, a);

      return this.disposeIntermediateTensorInfo(_n206), _s77;
    }

    var s = env$1().getBool("WEBGL_PACK") && !0 === r,
        o = s ? getShapeAs3D$1(t) : t,
        i = s ? new EncodeFloatPackedProgram$1(o) : new EncodeFloatProgram$1(o),
        l = this.runWebGLProgram(i, [{
      shape: o,
      dtype: n,
      dataId: e
    }], "float32"),
        u = this.texData.get(l.dataId),
        c = this.gpgpu.downloadByteEncodedFloatMatrixFromOutputTexture(u.texture, u.texShape[0], u.texShape[1]).subarray(0, a);
    return this.disposeIntermediateTensorInfo(l), c;
  }

  timerAvailable() {
    return env$1().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0;
  }

  time(e) {
    var _this74 = this;

    return _asyncToGenerator(function* () {
      var t = _this74.activeTimers,
          n = [];
      var r = !1;
      null == _this74.programTimersStack ? (_this74.programTimersStack = n, r = !0) : _this74.activeTimers.push(n), _this74.activeTimers = n, e();
      var a = flatten$6(_this74.activeTimers.map(e => e.query)).filter(e => null != e),
          s = flatten$6(_this74.activeTimers.map(e => e.name)).filter(e => null != e);
      _this74.activeTimers = t, r && (_this74.programTimersStack = null);
      var o = {
        uploadWaitMs: _this74.uploadWaitMs,
        downloadWaitMs: _this74.downloadWaitMs,
        kernelMs: null,
        wallMs: null
      };

      if (env$1().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0) {
        var _e433 = yield Promise.all(a);

        o.kernelMs = sum$7(_e433), o.getExtraProfileInfo = () => _e433.map((e, t) => ({
          name: s[t],
          ms: e
        })).map(e => "".concat(e.name, ": ").concat(e.ms)).join(", ");
      } else o.kernelMs = {
        error: "WebGL query timers are not supported in this environment."
      };

      return _this74.uploadWaitMs = 0, _this74.downloadWaitMs = 0, o;
    })();
  }

  memory() {
    return {
      unreliable: !1,
      numBytesInGPU: this.numBytesInGPU,
      numBytesInGPUAllocated: this.textureManager.numBytesAllocated,
      numBytesInGPUFree: this.textureManager.numBytesFree
    };
  }

  startTimer() {
    return env$1().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0 ? this.gpgpu.beginQuery() : {
      startMs: now$1(),
      endMs: null
    };
  }

  endTimer(e) {
    return env$1().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0 ? (this.gpgpu.endQuery(), e) : (e.endMs = now$1(), e);
  }

  getQueryTime(e) {
    var _this75 = this;

    return _asyncToGenerator(function* () {
      return env$1().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0 ? _this75.gpgpu.waitForQueryAndGetTime(e) : e.endMs - e.startMs;
    })();
  }

  disposeData(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;
    if (this.pendingDisposal.has(e)) return !1;
    if (!this.texData.has(e)) return !0;
    if (t ? this.texData.get(e).refCount = 0 : this.texData.get(e).refCount--, !t && this.texData.get(e).refCount > 0) return !1;
    if (this.pendingRead.has(e)) return this.pendingDisposal.add(e), this.pendingDeletes++, !1;
    this.releaseGPUData(e);
    var {
      complexTensorInfos: n
    } = this.texData.get(e);
    return null != n && (this.disposeData(n.real.dataId, t), this.disposeData(n.imag.dataId, t)), this.texData.delete(e), !0;
  }

  releaseGPUData(e) {
    var {
      texture: t,
      dtype: n,
      texShape: r,
      usage: a,
      isPacked: s,
      slice: o
    } = this.texData.get(e),
        i = o && o.origDataId || e,
        l = this.dataRefCount.get(i);
    l > 1 ? this.dataRefCount.set(i, l - 1) : (this.dataRefCount.delete(i), null != t && (this.numBytesInGPU -= this.computeBytes(r, n), this.textureManager.releaseTexture(t, r, a, s)));
    var u = this.texData.get(e);
    u.texture = null, u.texShape = null, u.isPacked = !1, u.slice = null;
  }

  getTexture(e) {
    return this.uploadToGPU(e), this.texData.get(e).texture;
  }

  getDataInfo(e) {
    return this.texData.get(e);
  }

  shouldExecuteOnCPU(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : CPU_HANDOFF_SIZE_THRESHOLD$1;
    return env$1().getBool("WEBGL_CPU_FORWARD") && e.every(e => null == this.texData.get(e.dataId).texture && sizeFromShape$1(e.shape) < t);
  }

  getGPGPUContext() {
    return this.gpgpu;
  }

  where(e) {
    warn$1("tf.where() in webgl locks the UI thread. Call tf.whereAsync() instead");
    var t = e.dataSync();
    return whereImpl$3(e.shape, t);
  }

  packedUnaryOp(e, t, n) {
    var r = new UnaryOpPackedProgram$1(e.shape, t),
        a = this.compileAndRun(r, [e], n);
    return engine$1().makeTensorFromDataId(a.dataId, a.shape, a.dtype);
  }

  abs(e) {
    if (this.shouldExecuteOnCPU([e]) && "complex64" !== e.dtype) {
      var _t315 = simpleAbsImplCPU$1(this.texData.get(e.dataId).values);

      return this.makeOutput(e.shape, e.dtype, _t315);
    }

    if (env$1().getBool("WEBGL_PACK_UNARY_OPERATIONS")) return this.packedUnaryOp(e, ABS$3, e.dtype);
    var t = new UnaryOpProgram$1(e.shape, ABS$3),
        n = this.compileAndRun(t, [e]);
    return engine$1().makeTensorFromDataId(n.dataId, n.shape, n.dtype);
  }

  makeTensorInfo(e, t, n) {
    var r;

    if ("string" === t && null != n && n.length > 0 && isString$1(n[0])) {
      var a = n.map(e => encodeString$1(e));
      r = this.write(a, e, t);
    } else r = this.write(n, e, t);

    return this.texData.get(r).usage = null, {
      dataId: r,
      shape: e,
      dtype: t
    };
  }

  makeOutput(e, t, n) {
    var {
      dataId: r
    } = this.makeTensorInfo(e, t, n);
    return engine$1().makeTensorFromDataId(r, e, t, this);
  }

  unpackTensor(e) {
    var t = new UnpackProgram$1(e.shape);
    return this.runWebGLProgram(t, [e], e.dtype);
  }

  packTensor(e) {
    var t = new PackProgram$1(e.shape);
    return this.runWebGLProgram(t, [e], e.dtype, null, !0);
  }

  packedReshape(e, t) {
    var n = [getBatchDim$1(e.shape), ...getRowsCols$1(e.shape)],
        r = {
      dtype: e.dtype,
      shape: n,
      dataId: e.dataId
    },
        a = [getBatchDim$1(t), ...getRowsCols$1(t)],
        s = new ReshapePackedProgram$1(a, n),
        o = this.runWebGLProgram(s, [r], e.dtype, null, !0);
    return {
      dataId: o.dataId,
      shape: t,
      dtype: o.dtype
    };
  }

  decode(e) {
    var t = this.texData.get(e),
        {
      isPacked: n,
      shape: r,
      dtype: a
    } = t,
        s = getShapeAs3D$1(r);
    var o;
    return o = n ? new DecodeMatrixPackedProgram$1(s) : new DecodeMatrixProgram$1(s), {
      dtype: a,
      shape: r,
      dataId: this.runWebGLProgram(o, [{
        shape: s,
        dtype: a,
        dataId: e
      }], a, null, !0).dataId
    };
  }

  runWebGLProgram(e, t, n, r) {
    var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;
    var s = this.makeTensorInfo(e.outputShape, n),
        o = this.texData.get(s.dataId);

    if (e.packedOutput && (o.isPacked = !0), e.outPackingScheme === PackingScheme$1.DENSE) {
      var _t316 = getDenseTexShape$1(e.outputShape);

      o.texShape = _t316.map(e => 2 * e);
    }

    if (null != e.outTexUsage && (o.usage = e.outTexUsage), 0 === sizeFromShape$1(s.shape)) return o.values = getTypedArrayFromDType$1(s.dtype, 0), s;
    var i = [],
        l = t.map(t => {
      if ("complex64" === t.dtype) throw new Error("GPGPUProgram does not support complex64 input. For complex64 dtypes, please separate the program into real and imaginary parts.");
      var n = this.texData.get(t.dataId);

      if (null == n.texture) {
        if (!e.packedInputs && sizeFromShape$1(t.shape) <= env$1().getNumber("WEBGL_SIZE_UPLOAD_UNIFORM")) return {
          shape: t.shape,
          texData: null,
          isUniform: !0,
          uniformValues: n.values
        };
        e.packedInputs && (n.isPacked = !0, n.shape = t.shape);
      } else if (!!n.isPacked != !!e.packedInputs) t = n.isPacked ? this.unpackTensor(t) : this.packTensor(t), i.push(t), n = this.texData.get(t.dataId);else if (n.isPacked && !isReshapeFree$1(n.shape, t.shape)) {
        var _e434 = t,
            _r151 = t.shape;
        t.shape = n.shape, t = this.packedReshape(t, _r151), i.push(t), n = this.texData.get(t.dataId), _e434.shape = _r151;
      }

      return this.uploadToGPU(t.dataId), {
        shape: t.shape,
        texData: n,
        isUniform: !1
      };
    });
    this.uploadToGPU(s.dataId);
    var u = {
      shape: s.shape,
      texData: o,
      isUniform: !1
    },
        c = makeShaderKey$1(e, l, u),
        p = this.getAndSaveBinary(c, () => compileProgram$1(this.gpgpu, e, l, u)),
        d = null != this.activeTimers;
    var h;
    d && (h = this.startTimer()), runProgram$1(this.gpgpu, p, l, u, r), i.forEach(e => this.disposeIntermediateTensorInfo(e)), d && (h = this.endTimer(h), this.activeTimers.push({
      name: e.constructor.name,
      query: this.getQueryTime(h)
    }));
    var m = env$1().get("WEBGL_FLUSH_THRESHOLD");

    if (m > 0) {
      var _e435 = now$1();

      _e435 - this.lastGlFlushTime > m && (this.gpgpu.gl.flush(), this.lastGlFlushTime = _e435);
    }

    if (!env$1().getBool("WEBGL_LAZILY_UNPACK") && o.isPacked && !1 === a) {
      var _e436 = this.unpackTensor(s);

      return this.disposeIntermediateTensorInfo(s), _e436;
    }

    return s;
  }

  compileAndRun(e, t, n, r) {
    var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;
    return this.runWebGLProgram(e, t, n = n || t[0].dtype, r, a);
  }

  getAndSaveBinary(e, t) {
    return e in this.binaryCache || (this.binaryCache[e] = t()), this.binaryCache[e];
  }

  getTextureManager() {
    return this.textureManager;
  }

  dispose() {
    this.disposed || (env$1().getBool("IS_TEST") || Object.keys(this.binaryCache).forEach(e => {
      this.gpgpu.deleteProgram(this.binaryCache[e].webGLProgram), delete this.binaryCache[e];
    }), this.textureManager.dispose(), null != this.canvas && "undefined" != typeof HTMLCanvasElement && this.canvas instanceof HTMLCanvasElement ? this.canvas.remove() : this.canvas = null, this.gpgpuCreatedLocally && (this.gpgpu.program = null, this.gpgpu.dispose()), this.disposed = !0);
  }

  floatPrecision() {
    return null == this.floatPrecisionValue && (this.floatPrecisionValue = tidy$1(() => {
      if (!env$1().get("WEBGL_RENDER_FLOAT32_ENABLED")) {
        var _e437 = env$1().getBool("DEBUG");

        env$1().set("DEBUG", !1);
        var t = this.abs(scalar$1(1e-8)).dataSync()[0];
        if (env$1().set("DEBUG", _e437), t > 0) return 32;
      }

      return 16;
    })), this.floatPrecisionValue;
  }

  epsilon() {
    return 32 === this.floatPrecision() ? EPSILON_FLOAT32$2 : EPSILON_FLOAT16$2;
  }

  uploadToGPU(e) {
    var t = this.texData.get(e),
        {
      shape: n,
      dtype: r,
      values: a,
      texture: s,
      usage: o,
      isPacked: i
    } = t;
    if (null != s) return;
    var l = null != this.activeTimers;
    var u;
    l && (u = now$1());
    var c = t.texShape;

    if (null == c && (c = getTextureShapeFromLogicalShape$1(n, i), t.texShape = c), null != a) {
      var _e438 = getShapeAs3D$1(n);

      var _s78,
          _o54 = c[1],
          _p16 = c[0];

      var d = a instanceof Uint8Array;
      i ? ([_o54, _p16] = getPackedMatrixTextureShapeWidthHeight$1(c[0], c[1]), _s78 = new EncodeMatrixPackedProgram$1(_e438, [_p16, _o54], d)) : _s78 = new EncodeMatrixProgram$1(_e438, [_p16, _o54], d);
      var h = this.makeTensorInfo([_p16, _o54], r);
      this.texData.get(h.dataId).usage = d ? TextureUsage$1.PIXELS : TextureUsage$1.UPLOAD, this.gpgpu.uploadDenseMatrixToTexture(this.getTexture(h.dataId), _o54, _p16, a);
      var m = this.runWebGLProgram(_s78, [h], r, null, !0),
          f = this.texData.get(m.dataId);
      t.texture = f.texture, t.texShape = f.texShape, t.isPacked = f.isPacked, t.usage = f.usage, this.disposeIntermediateTensorInfo(h), this.texData.delete(m.dataId), t.values = null, l && (this.uploadWaitMs += now$1() - u);
    } else {
      var _e439 = this.acquireTexture(c, o, r, i);

      t.texture = _e439;
    }
  }

  convertAndCacheOnCPU(e, t) {
    var n = this.texData.get(e),
        {
      dtype: r
    } = n;
    return this.releaseGPUData(e), null != t && (n.values = float32ToTypedArray$1(t, r)), n.values;
  }

  acquireTexture(e, t, n, r) {
    if (this.numBytesInGPU += this.computeBytes(e, n), !this.warnedAboutMemory && this.numBytesInGPU > 1024 * this.numMBBeforeWarning * 1024) {
      var _e440 = (this.numBytesInGPU / 1024 / 1024).toFixed(2);

      this.warnedAboutMemory = !0, console.warn("High memory usage in GPU: ".concat(_e440, " MB, most likely due to a memory leak"));
    }

    return this.textureManager.acquireTexture(e, t, r);
  }

  computeBytes(e, t) {
    return e[0] * e[1] * bytesPerElement$1(t);
  }

}

function float32ToTypedArray$1(e, t) {
  if ("float32" === t || "complex64" === t) return e;

  if ("int32" === t || "bool" === t) {
    var n = "int32" === t ? new Int32Array(e.length) : new Uint8Array(e.length);

    for (var _t317 = 0; _t317 < n.length; ++_t317) {
      n[_t317] = Math.round(e[_t317]);
    }

    return n;
  }

  throw new Error("Unknown dtype ".concat(t));
}

MathBackendWebGL$1.nextDataId = 0;
var version$9 = "3.8.0";
isBrowser$1() && registerBackend$1("webgl", () => new MathBackendWebGL$1(), 2);
var CHECK_NAN_SNIPPET$4 = "\n  if (isnan(a)) return a;\n  if (isnan(b)) return b;\n";

class BinaryOpProgram$1 {
  constructor(e, t, n) {
    this.variableNames = ["A", "B"], this.outputShape = assertAndGetBroadcastShape$1(t, n), this.enableShapeUniforms = useShapeUniforms$1(this.outputShape.length), this.userCode = "\n      float binaryOperation(float a, float b) {\n        ".concat(e, "\n      }\n\n      void main() {\n        float a = getAAtOutCoords();\n        float b = getBAtOutCoords();\n        setOutput(binaryOperation(a, b));\n      }\n    ");
  }

}

var CHECK_NAN_SNIPPET$3 = "\n  result.r = isNaN.r > 0. ? NAN : result.r;\n  result.g = isNaN.g > 0. ? NAN : result.g;\n  result.b = isNaN.b > 0. ? NAN : result.b;\n  result.a = isNaN.a > 0. ? NAN : result.a;\n";

class BinaryOpPackedProgram$1 {
  constructor(e, t, n) {
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
    this.variableNames = ["A", "B"], this.supportsBroadcasting = !0, this.packedInputs = !0, this.packedOutput = !0, this.outputShape = assertAndGetBroadcastShape$1(t, n);
    var a = this.outputShape.length;
    this.enableShapeUniforms = useShapeUniforms$1(a);
    var s = "";
    if (r) if (0 === a || 1 === sizeFromShape$1(this.outputShape)) s = "\n          result.y = 0.;\n          result.z = 0.;\n          result.w = 0.;\n        ";else if (s = "\n          ".concat(getCoordsDataType$1(a), " coords = getOutputCoords();\n        "), 1 === a) s += this.enableShapeUniforms ? "\n            result.y = (coords + 1) >= outShape ? 0. : result.y;\n            result.z = 0.;\n            result.w = 0.;\n          " : "\n            result.y = (coords + 1) >= ".concat(this.outputShape[0], " ? 0. : result.y;\n            result.z = 0.;\n            result.w = 0.;\n          ");else {
      var _e441 = getChannels$1("coords", a);

      s += this.enableShapeUniforms ? "\n            bool nextRowOutOfBounds =\n              (".concat(_e441[a - 2], " + 1) >= outShape[").concat(a, " - 2];\n            bool nextColOutOfBounds =\n              (").concat(_e441[a - 1], " + 1) >= outShape[").concat(a, " - 1];\n            result.y = nextColOutOfBounds ? 0. : result.y;\n            result.z = nextRowOutOfBounds ? 0. : result.z;\n            result.w = nextColOutOfBounds || nextRowOutOfBounds ? 0. : result.w;\n          ") : "\n            bool nextRowOutOfBounds =\n              (".concat(_e441[a - 2], " + 1) >= ").concat(this.outputShape[a - 2], ";\n            bool nextColOutOfBounds =\n              (").concat(_e441[a - 1], " + 1) >= ").concat(this.outputShape[a - 1], ";\n            result.y = nextColOutOfBounds ? 0. : result.y;\n            result.z = nextRowOutOfBounds ? 0. : result.z;\n            result.w = nextColOutOfBounds || nextRowOutOfBounds ? 0. : result.w;\n          ");
    }
    this.userCode = "\n      vec4 binaryOperation(vec4 a, vec4 b) {\n        ".concat(e, "\n      }\n\n      void main() {\n        vec4 a = getAAtOutCoords();\n        vec4 b = getBAtOutCoords();\n\n        vec4 result = binaryOperation(a, b);\n        ").concat(s, "\n\n        setOutput(result);\n      }\n    ");
  }

}

function identity$3(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    x: r
  } = t;
  return n.incRef(r.dataId), {
    dataId: r.dataId,
    shape: r.shape,
    dtype: r.dtype
  };
}

var identityConfig$2 = {
  kernelName: Identity$3,
  backendName: "webgl",
  kernelFunc: identity$3
};

function complex$3(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    real: r,
    imag: a
  } = t,
      s = n.makeTensorInfo(r.shape, "complex64"),
      o = n.texData.get(s.dataId),
      i = identity$3({
    inputs: {
      x: r
    },
    backend: n
  }),
      l = identity$3({
    inputs: {
      x: a
    },
    backend: n
  });
  return o.complexTensorInfos = {
    real: i,
    imag: l
  }, s;
}

var complexConfig$2 = {
  kernelName: Complex$1,
  backendName: "webgl",
  kernelFunc: complex$3
},
    LEAKYRELU$1 = "return (a < 0.) ? b * a : a;",
    LEAKYRELU_PACKED$1 = "\n  vec4 aLessThanZero = vec4(lessThan(a, vec4(0.)));\n  return (aLessThanZero * (b * a)) + ((vec4(1.0) - aLessThanZero) * a);\n";

function leakyRelu$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    alpha: s
  } = r,
      o = n.makeTensorInfo([], "float32", createScalarValue$1(s, "float32")),
      i = env$1().getBool("WEBGL_PACK_BINARY_OPERATIONS") ? new BinaryOpPackedProgram$1(LEAKYRELU_PACKED$1, a.shape, o.shape) : new BinaryOpProgram$1(LEAKYRELU$1, a.shape, o.shape),
      l = n.runWebGLProgram(i, [a, o], a.dtype);
  return n.disposeIntermediateTensorInfo(o), l;
}

var leakyReluConfig$2 = {
  kernelName: LeakyRelu$1,
  backendName: "webgl",
  kernelFunc: leakyRelu$3
},
    PRELU$1 = "return (a < 0.) ? b * a : a;",
    PRELU_PACKED$1 = "\n  vec4 aLessThanZero = vec4(lessThan(a, vec4(0.)));\n  return (aLessThanZero * (b * a)) + ((vec4(1.0) - aLessThanZero) * a);\n";

function prelu$4(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    x: r,
    alpha: a
  } = t,
      s = env$1().getBool("WEBGL_PACK_BINARY_OPERATIONS") ? new BinaryOpPackedProgram$1(PRELU_PACKED$1, r.shape, a.shape) : new BinaryOpProgram$1(PRELU$1, r.shape, a.shape);
  return n.runWebGLProgram(s, [r, a], r.dtype);
}

var preluConfig$2 = {
  kernelName: Prelu$1,
  backendName: "webgl",
  kernelFunc: prelu$4
},
    CHECK_NAN_SNIPPET_UNARY$1 = "if (isnan(x)) return x;",
    CHECK_NAN_SNIPPET_BINARY$1 = "\n  if (isnan(a)) return a;\n  if (isnan(b)) return b;\n",
    CHECK_NAN_SNIPPET_BINARY_PACKED$1 = "\n  result.r = isNaN.r > 0. ? NAN : result.r;\n  result.g = isNaN.g > 0. ? NAN : result.g;\n  result.b = isNaN.b > 0. ? NAN : result.b;\n  result.a = isNaN.a > 0. ? NAN : result.a;\n";

function unaryKernelFunc$2(_ref14) {
  var {
    opSnippet: e,
    packedOpSnippet: t,
    cpuKernelImpl: n,
    dtype: r
  } = _ref14;
  return _ref15 => {
    var {
      inputs: a,
      backend: s
    } = _ref15;
    var {
      x: o
    } = a,
        i = s,
        l = r || o.dtype;

    if (i.shouldExecuteOnCPU([o]) && null != n) {
      var _e442 = i.texData.get(o.dataId),
          _t318 = n(_e442.values, l);

      return i.makeTensorInfo(o.shape, l, _t318);
    }

    var u;
    return u = env$1().getBool("WEBGL_PACK_UNARY_OPERATIONS") && null != t ? new UnaryOpPackedProgram$1(o.shape, t) : new UnaryOpProgram$1(o.shape, e), i.runWebGLProgram(u, [o], l);
  };
}

function binaryKernelFunc$2(_ref16) {
  var {
    opSnippet: e,
    packedOpSnippet: t,
    checkOutOfBounds: n = !1,
    supportsComplex: r = !1,
    cpuKernelImpl: a,
    dtype: s
  } = _ref16;
  return _ref17 => {
    var {
      inputs: o,
      backend: i
    } = _ref17;
    var {
      a: l,
      b: u
    } = o,
        c = i;

    if (r && "complex64" === l.dtype) {
      var _t319 = c.texData.get(l.dataId),
          _n207 = c.texData.get(u.dataId),
          [_r152, _a108] = [[_t319.complexTensorInfos.real, _n207.complexTensorInfos.real], [_t319.complexTensorInfos.imag, _n207.complexTensorInfos.imag]].map(t => {
        var [n, r] = t,
            a = {
          dataId: n.dataId,
          dtype: n.dtype,
          shape: l.shape
        },
            s = {
          dataId: r.dataId,
          dtype: r.dtype,
          shape: u.shape
        },
            o = new BinaryOpProgram$1(e, l.shape, u.shape);
        return c.runWebGLProgram(o, [a, s], upcastType$1(n.dtype, r.dtype));
      }),
          _s79 = complex$3({
        inputs: {
          real: _r152,
          imag: _a108
        },
        backend: c
      });

      return c.disposeIntermediateTensorInfo(_r152), c.disposeIntermediateTensorInfo(_a108), _s79;
    }

    var p = s || upcastType$1(l.dtype, u.dtype);

    if (("string" === l.dtype || "string" === u.dtype || c.shouldExecuteOnCPU([l, u])) && null != a) {
      var _e443 = c.texData.get(l.dataId).values,
          _t320 = c.texData.get(u.dataId).values,
          _n208 = "string" === l.dtype ? fromUint8ToStringArray$1(_e443) : _e443,
          _r153 = "string" === l.dtype ? fromUint8ToStringArray$1(_t320) : _t320,
          [_s80, _o55] = a(l.shape, u.shape, _n208, _r153, p),
          _i36 = c.makeTensorInfo(_o55, p);

      return c.texData.get(_i36.dataId).values = _s80, _i36;
    }

    var d;
    return d = env$1().getBool("WEBGL_PACK_BINARY_OPERATIONS") && null != t ? new BinaryOpPackedProgram$1(t, l.shape, u.shape, n) : new BinaryOpProgram$1(e, l.shape, u.shape), c.runWebGLProgram(d, [l, u], p);
  };
}

function mapActivationToShaderProgram$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;
  if ("linear" === e) return t ? LINEAR$2 : LINEAR$3;
  if ("relu" === e) return t ? RELU$4 : RELU$5;
  if ("elu" === e) return t ? ELU$5 : ELU$6;
  if ("relu6" === e) return t ? RELU6$4 : RELU6$5;
  if ("prelu" === e) return t ? PRELU_PACKED$1 : PRELU$1;
  if ("leakyrelu" === e) return t ? LEAKYRELU_PACKED$1 : LEAKYRELU$1;
  if ("sigmoid" === e) return t ? SIGMOID$4 : SIGMOID$5;
  throw new Error("Activation ".concat(e, " has not been implemented for the WebGL backend."));
}

class MatMulPackedProgram$1 {
  constructor(e, t, n) {
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
    var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;
    var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : !1;
    var o = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : null;
    var i = arguments.length > 7 && arguments[7] !== undefined ? arguments[7] : !1;
    var l = arguments.length > 8 && arguments[8] !== undefined ? arguments[8] : !1;
    this.variableNames = ["matrixA", "matrixB"], this.packedInputs = !0, this.packedOutput = !0, this.outputShape = n;
    var u = Math.ceil((r ? e[1] : e[2]) / 2),
        c = r ? "i * 2, rc.y" : "rc.y, i * 2",
        p = a ? "rc.z, i * 2" : "i * 2, rc.z",
        d = r ? ["a.xxyy", "a.zzww"] : ["a.xxzz", "a.yyww"],
        h = a ? ["b.xzxz", "b.ywyw"] : ["b.xyxy", "b.zwzw"];
    var m = "",
        f = "";
    o && (m = i ? "vec4 activation(vec4 a) {\n          vec4 b = getPreluActivationWeightsAtOutCoords();\n          ".concat(o, "\n        }") : l ? "vec4 activation(vec4 a) {\n          vec4 b = getLeakyreluAlphaAtOutCoords();\n          ".concat(o, "\n        }") : "vec4 activation(vec4 x) {\n          ".concat(o, "\n        }"), f = "result = activation(result);");
    var g = s ? "result += getBiasAtOutCoords();" : "";
    s && this.variableNames.push("bias"), i && this.variableNames.push("preluActivationWeights"), l && this.variableNames.push("leakyreluAlpha");
    var $ = "rc.x",
        y = "rc.x";
    e[0] < t[0] ? $ = "int(min(float(rc.x), ".concat(e[0] - 1, ".))") : t[0] < e[0] && (y = "int(min(float(rc.x), ".concat(t[0] - 1, ".))")), this.userCode = "\n      ".concat(m, "\n\n      const float sharedDimension = ").concat(u, ".0;\n\n      vec4 dot2x2ARowBCol(ivec3 rc) {\n        vec4 result = vec4(0);\n        for (int i = 0; i < ").concat(u, "; i++) {\n          int batchA = ").concat($, ";\n          int batchB = ").concat(y, ";\n          vec4 a = getMatrixA(batchA, ").concat(c, ");\n          vec4 b = getMatrixB(batchB, ").concat(p, ");\n\n          // These swizzled products need to be separately added.\n          // See: https://github.com/tensorflow/tfjs/issues/1735\n          result += (").concat(d[0], " * ").concat(h[0], ");\n          result += (").concat(d[1], " * ").concat(h[1], ");\n        }\n        return result;\n      }\n\n      void main() {\n        ivec3 rc = getOutputCoords();\n        vec4 result = dot2x2ARowBCol(rc);\n\n        ").concat(g, "\n\n        ").concat(f, "\n\n        setOutput(result);\n      }\n    ");
  }

}

var COMPLEX_MULTIPLY$1 = {
  REAL: "return areal * breal - aimag * bimag;",
  IMAG: "return areal * bimag + aimag * breal;"
};

class BinaryOpComplexProgram$1 {
  constructor(e, t, n) {
    this.variableNames = ["AReal", "AImag", "BReal", "BImag"], this.outputShape = assertAndGetBroadcastShape$1(t, n), this.userCode = "\n      float binaryOpComplex(\n          float areal, float aimag, float breal, float bimag) {\n        ".concat(e, "\n      }\n\n      void main() {\n        float areal = getARealAtOutCoords();\n        float aimag = getAImagAtOutCoords();\n        float breal = getBRealAtOutCoords();\n        float bimag = getBImagAtOutCoords();\n        setOutput(binaryOpComplex(areal, aimag, breal, bimag));\n      }\n    ");
  }

}

var MUL$1 = "return a * b;";

function multiply$3(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    a: r,
    b: a
  } = t,
      s = upcastType$1(r.dtype, a.dtype);

  if ("complex64" === r.dtype) {
    var _e444 = n.texData.get(r.dataId),
        _t321 = n.texData.get(a.dataId),
        _s81 = new BinaryOpComplexProgram$1(COMPLEX_MULTIPLY$1.REAL, r.shape, a.shape),
        _o56 = new BinaryOpComplexProgram$1(COMPLEX_MULTIPLY$1.IMAG, r.shape, a.shape),
        i = [{
      dataId: _e444.complexTensorInfos.real.dataId,
      dtype: _e444.complexTensorInfos.real.dtype,
      shape: r.shape
    }, {
      dataId: _e444.complexTensorInfos.imag.dataId,
      dtype: _e444.complexTensorInfos.imag.dtype,
      shape: r.shape
    }, {
      dataId: _t321.complexTensorInfos.real.dataId,
      dtype: _t321.complexTensorInfos.real.dtype,
      shape: a.shape
    }, {
      dataId: _t321.complexTensorInfos.imag.dataId,
      dtype: _t321.complexTensorInfos.imag.dtype,
      shape: a.shape
    }],
        l = n.runWebGLProgram(_s81, i, "float32"),
        u = n.runWebGLProgram(_o56, i, "float32"),
        c = complex$3({
      inputs: {
        real: l,
        imag: u
      },
      backend: n
    });

    return n.disposeIntermediateTensorInfo(l), n.disposeIntermediateTensorInfo(u), c;
  }

  if (n.shouldExecuteOnCPU([r, a])) {
    var _e445 = n.texData.get(r.dataId),
        _t322 = n.texData.get(a.dataId),
        [_o57, _i37] = multiplyImplCPU$1(r.shape, a.shape, _e445.values, _t322.values, s),
        _l28 = n.makeTensorInfo(_i37, s);

    return n.texData.get(_l28.dataId).values = _o57, _l28;
  }

  var o;
  return o = env$1().getBool("WEBGL_PACK_BINARY_OPERATIONS") ? new BinaryOpPackedProgram$1(MUL$1, r.shape, a.shape) : new BinaryOpProgram$1(MUL$1, r.shape, a.shape), n.runWebGLProgram(o, [r, a], s);
}

var multiplyConfig$2 = {
  kernelName: Multiply$3,
  backendName: "webgl",
  kernelFunc: multiply$3
};

function packedReshape$1(e, t, n) {
  var r = [getBatchDim$1(e.shape), ...getRowsCols$1(e.shape)],
      a = {
    dtype: e.dtype,
    shape: r,
    dataId: e.dataId
  },
      s = [getBatchDim$1(t), ...getRowsCols$1(t)],
      o = new ReshapePackedProgram$1(s, r),
      i = n.runWebGLProgram(o, [a], e.dtype, null, !0);
  return {
    dataId: i.dataId,
    shape: t,
    dtype: i.dtype
  };
}

function reshape$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    shape: s
  } = r,
      o = n,
      i = sizeFromShape$1(a.shape),
      l = inferFromImplicitShape$1(s, i),
      u = sizeFromShape$1(l);
  assert$6(i === u, () => "The new shape (".concat(l, ") has ").concat(u, " elements and the old shape (").concat(a.shape, ") has ").concat(i, " elements. The new shape and old shape must have the same number of elements."));
  var c = o.texData.get(a.dataId);
  return !c.isPacked || isReshapeFree$1(a.shape, l) || null !== c.texture && isReshapeFree$1(c.shape, l) ? (o.incRef(a.dataId), {
    dataId: a.dataId,
    shape: l,
    dtype: a.dtype
  }) : packedReshape$1(a, l, o);
}

var reshapeConfig$2 = {
  kernelName: Reshape$3,
  backendName: "webgl",
  kernelFunc: reshape$4
};

class MeanProgram$1 {
  constructor(e, t) {
    this.variableNames = ["x"];
    var {
      windowSize: n,
      batchSize: r,
      inSize: a,
      outSize: s
    } = e;
    this.outputShape = [r, s];
    var o = 4 * Math.floor(n / 4),
        i = n % 4;
    var l = "sumValue += dot(values, ones);";

    if (null != t) {
      var _e446 = 1 / t;

      l = "sumValue += dot(values * ".concat(isInt$1(_e446) ? _e446.toPrecision(2) : _e446, ", ones);");
    }

    var u = "";
    a % n > 0 && (u = "\n        if (inIdx < 0 || inIdx >= ".concat(a, ") {\n          return 0.0;\n        }\n      ")), this.userCode = "\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\n\n      float getValue(int batch, int inIdx) {\n        ".concat(u, "\n        return getX(batch, inIdx);\n      }\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n        int outIdx = coords[1];\n        int inOffset = outIdx * ").concat(n, ";\n\n        float sumValue = 0.0;\n\n        for (int i = 0; i < ").concat(o, "; i += 4) {\n          int inIdx = inOffset + i;\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            getValue(batch, inIdx + 3)\n          );\n\n          ").concat(l, "\n        }\n\n        int inIdx = inOffset + ").concat(o, ";\n        if (").concat(1 === i, ") {\n          vec4 values = vec4(getValue(batch, inIdx), 0.0, 0.0, 0.0);\n\n          ").concat(l, "\n        } else if (").concat(2 === i, ") {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1), 0.0, 0.0);\n\n          ").concat(l, "\n        } else if (").concat(3 === i, ") {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2), 0.0);\n\n          ").concat(l, "\n        }\n        setOutput(sumValue);\n      }\n    ");
  }

}

class ReduceProgram$1 {
  constructor(e, t) {
    this.variableNames = ["x"];
    var {
      windowSize: n,
      batchSize: r,
      inSize: a,
      outSize: s
    } = e;
    this.outputShape = [r, s];
    var o = "0.0",
        i = "";
    "prod" === t ? o = "1.0" : "min" === t ? (o = "1.0 / 1e-20", i = "min") : "max" === t && (o = "-1.0 / 1e-20", i = "max");
    var l = "".concat(t, "(").concat(t, "(").concat(t, "(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])");
    "sum" === t ? l = "sumValue" : "prod" === t ? l = "prodValue" : "all" === t ? l = "allValue" : "any" === t && (l = "anyValue");
    var u = 4 * Math.floor(n / 4),
        c = n % 4;
    var p = "\n      if (".concat("sum" === t, ") {\n        sumValue += dot(values, ones);\n      } else if (").concat("prod" === t, ") {\n        vec2 tmp = vec2(values[0], values[1]) * vec2(values[2], values[3]);\n        prodValue *= tmp[0] * tmp[1];\n      } else {\n        minMaxValue = ").concat(i, "(values, minMaxValue);\n        if (").concat("min" === t, " || ").concat("max" === t, ") {\n          minMaxValue = ").concat(i, "(values, minMaxValue);\n          bvec4 isNaN = isnan(values);\n          if (isNaN.r || isNaN.g || isNaN.b || isNaN.a) {\n            minMaxValue = vec4(NAN);\n          }\n        }\n      }\n    "),
        d = "vec4";
    "all" === t ? (o = "1.0", p = "\n        bool reducedAllValue = all(values);\n        float floatedReducedAllValue = float(reducedAllValue);\n        allValue = float(allValue >= 1.0 && floatedReducedAllValue >= 1.0);\n      ", d = "bvec4") : "any" === t && (o = "0.0", p = "\n        bool reducedAnyValue = any(values);\n        float floatedReducedAnyValue = float(reducedAnyValue);\n        anyValue = float(anyValue >= 1.0 || floatedReducedAnyValue >= 1.0);\n      ", d = "bvec4");
    var h = "";
    a % n > 0 && (h = "\n        if (inIdx < 0 || inIdx >= ".concat(a, ") {\n          return initializationValue;\n        }\n      ")), this.userCode = "\n      const float initializationValue = ".concat(o, ";\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\n\n      float getValue(int batch, int inIdx) {\n        ").concat(h, "\n        return getX(batch, inIdx);\n      }\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n        int outIdx = coords[1];\n        int inOffset = outIdx * ").concat(n, ";\n\n        vec4 minMaxValue = vec4(").concat(o, ");\n        float prodValue = 1.0;\n        float sumValue = 0.0;\n        float allValue = 1.0;\n        float anyValue = 0.0;\n\n        for (int i = 0; i < ").concat(u, "; i += 4) {\n          int inIdx = inOffset + i;\n          ").concat(d, " values = ").concat(d, "(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            getValue(batch, inIdx + 3)\n          );\n\n          ").concat(p, "\n        }\n\n        int inIdx = inOffset + ").concat(u, ";\n        if (").concat(1 === c, ") {\n          ").concat(d, " values = ").concat(d, "(\n            getValue(batch, inIdx),\n            initializationValue,\n            initializationValue,\n            initializationValue\n          );\n\n          ").concat(p, "\n        } else if (").concat(2 === c, ") {\n          ").concat(d, " values = ").concat(d, "(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            initializationValue,\n            initializationValue\n          );\n\n          ").concat(p, "\n        } else if (").concat(3 === c, ") {\n          ").concat(d, " values = ").concat(d, "(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            initializationValue\n          );\n\n          ").concat(p, "\n        }\n        setOutput(").concat(l, ");\n      }\n    ");
  }

}

function getReductionStages$1(e) {
  var t = [];

  for (; 0 === t.length || 1 !== t[t.length - 1].outSize;) {
    var n = t.length ? t[t.length - 1].outSize : e[1],
        r = computeOptimalWindowSize$1(n);
    t.push({
      inSize: n,
      windowSize: r,
      outSize: Math.ceil(n / r)
    });
  }

  return t;
}

function reduce$1(e, t, n, r) {
  var a = getReductionStages$1(e.shape);
  var s = e;

  for (var o = 0; o < a.length; o++) {
    var {
      inSize: i,
      windowSize: l,
      outSize: u
    } = a[o];

    var c = void 0,
        _p17 = void 0;

    c = "mean" === n ? 0 === o ? new MeanProgram$1({
      windowSize: l,
      inSize: i,
      batchSize: e.shape[0],
      outSize: u
    }, i) : new MeanProgram$1({
      windowSize: l,
      inSize: i,
      batchSize: e.shape[0],
      outSize: u
    }) : new ReduceProgram$1({
      windowSize: l,
      inSize: i,
      batchSize: e.shape[0],
      outSize: u
    }, n), _p17 = s, s = r.runWebGLProgram(c, [s], t), _p17.dataId !== e.dataId && r.disposeIntermediateTensorInfo(_p17);
  }

  return s;
}

class TransposeProgram$1 {
  constructor(e, t) {
    this.variableNames = ["A"];
    var n = new Array(e.length);

    for (var _r154 = 0; _r154 < n.length; _r154++) {
      n[_r154] = e[t[_r154]];
    }

    this.outputShape = n, this.rank = n.length;
    var r = getCoordsDataType$1(this.rank),
        a = getSwitchedCoords$1(t);
    this.userCode = "\n    void main() {\n      ".concat(r, " resRC = getOutputCoords();\n      setOutput(getA(").concat(a, "));\n    }\n    ");
  }

}

function getSwitchedCoords$1(e) {
  var t = e.length;
  if (t > 6) throw Error("Transpose for rank ".concat(t, " is not yet supported"));
  var n = ["resRC.x", "resRC.y", "resRC.z", "resRC.w", "resRC.u", "resRC.v"],
      r = new Array(t);

  for (var _t323 = 0; _t323 < e.length; _t323++) {
    r[e[_t323]] = n[_t323];
  }

  return r.join();
}

class TransposePackedProgram$1 {
  constructor(e, t) {
    this.variableNames = ["A"], this.packedInputs = !0, this.packedOutput = !0;
    var n = new Array(e.length);

    for (var _r155 = 0; _r155 < n.length; _r155++) {
      n[_r155] = e[t[_r155]];
    }

    if (this.outputShape = n, this.rank = n.length, this.rank > 6) throw Error("Packed transpose for rank ".concat(this.rank, " is not yet supported."));
    var r = getCoordsDataType$1(this.rank),
        a = getVecChannels$1("rc", this.rank),
        s = new Array(this.rank);

    for (var _e447 = 0; _e447 < t.length; _e447++) {
      s[t[_e447]] = a[_e447];
    }

    var o = "vec2(".concat(s.slice(-2).join(), ")"),
        i = "++".concat(a[this.rank - 1], " < ").concat(n[this.rank - 1]),
        l = "getChannel(getA(".concat(s.join(), "), ").concat(o, ")");
    this.userCode = "\n    void main() {\n      ".concat(r, " rc = getOutputCoords();\n      vec4 result = vec4(0.);\n      result[0] = ").concat(l, ";\n      if(").concat(i, ") {\n        result[1] = ").concat(l, ";\n      }\n      --").concat(a[this.rank - 1], ";\n      if(++").concat(a[this.rank - 2], " < ").concat(n[this.rank - 2], ") {\n        result[2] = ").concat(l, ";\n        if(").concat(i, ") {\n          result[3] = ").concat(l, ";\n        }\n      }\n      setOutput(result);\n    }\n    ");
  }

}

function transposeImpl$2(e, t, n) {
  var r = env$1().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new TransposePackedProgram$1(e.shape, t) : new TransposeProgram$1(e.shape, t);
  return n.runWebGLProgram(r, [e], e.dtype);
}

function sumImpl$1(e, t, n, r) {
  var a = e.shape.length,
      s = parseAxisParam$1(t, e.shape);
  var o = s;
  var i = getAxesPermutation$1(o, a),
      l = null != i;
  var u = e;
  l && (u = transposeImpl$2(e, i, r), o = getInnerMostAxes$1(o.length, a)), assertAxesAreInnerMostDims$1("sum", o, a);
  var [c, p] = computeOutAndReduceShapes$1(u.shape, o);
  var d = c;
  n && (d = expandShapeToKeepDim$1(c, s));
  var h = sizeFromShape$1(p),
      m = reshape$4({
    inputs: {
      x: u
    },
    attrs: {
      shape: [sizeFromShape$1(e.shape) / h, h]
    },
    backend: r
  }),
      f = reduce$1(m, sumOutType$1(e.dtype), "sum", r),
      g = reshape$4({
    inputs: {
      x: f
    },
    attrs: {
      shape: d
    },
    backend: r
  });
  return r.disposeIntermediateTensorInfo(m), r.disposeIntermediateTensorInfo(f), l && r.disposeIntermediateTensorInfo(u), g;
}

function sum$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    axis: s,
    keepDims: o
  } = r;
  return sumImpl$1(a, s, o, n);
}

var sumConfig$2 = {
  kernelName: Sum$1,
  backendName: "webgl",
  kernelFunc: sum$4
};

function transpose$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    perm: s
  } = r,
      o = n,
      i = new Array(a.shape.length);

  for (var _e448 = 0; _e448 < i.length; _e448++) {
    i[_e448] = a.shape[s[_e448]];
  }

  var l;

  if (o.shouldExecuteOnCPU([a])) {
    var _e449 = o.texData.get(a.dataId),
        _t324 = transposeImplCPU$1(_e449.values, a.shape, a.dtype, s, i);

    l = o.makeTensorInfo(i, a.dtype), o.texData.get(l.dataId).values = _t324;
  } else l = transposeImpl$2(a, s, o);

  return l;
}

var transposeConfig$2 = {
  kernelName: Transpose$1,
  backendName: "webgl",
  kernelFunc: transpose$3
},
    MATMUL_SHARED_DIM_THRESHOLD$1 = 1e3;

function batchMatMulImpl$1(_ref18) {
  var {
    a: e,
    b: t,
    transposeA: n,
    transposeB: r,
    backend: a,
    bias: s = null,
    preluActivationWeights: o = null,
    leakyreluAlpha: i = 0,
    activation: l = null
  } = _ref18;
  var u = e.shape.length,
      c = t.shape.length,
      p = n ? e.shape[u - 2] : e.shape[u - 1],
      d = r ? t.shape[c - 1] : t.shape[c - 2],
      h = n ? e.shape[u - 1] : e.shape[u - 2],
      m = r ? t.shape[c - 2] : t.shape[c - 1],
      f = e.shape.slice(0, -2),
      g = t.shape.slice(0, -2),
      $ = sizeFromShape$1(f),
      y = sizeFromShape$1(g);
  assert$6(u >= 2 && c >= 2 && ($ === y || 1 === $ || 1 === y), () => "Error in matMul: the input batch dimensions must either be the same or at least one input batch dimension must be 1. Got input batch dimensions of (".concat(f, ") and (").concat(g, ")."));
  var b = ($ > y ? e.shape.slice(0, -2) : t.shape.slice(0, -2)).concat([h, m]);
  assert$6(p === d, () => "Error in matMul: inner shapes (".concat(p, ") and (").concat(d, ") of Tensors with shapes ").concat(e.shape, " and ").concat(t.shape, " and transposeA=").concat(n, " and transposeB=").concat(r, " must match."));
  var x = n ? [$, p, h] : [$, h, p],
      v = r ? [y, m, d] : [y, d, m],
      I = reshape$4({
    inputs: {
      x: e
    },
    backend: a,
    attrs: {
      shape: x
    }
  }),
      C = reshape$4({
    inputs: {
      x: t
    },
    backend: a,
    attrs: {
      shape: v
    }
  }),
      S = [I, C],
      k = Math.max($, y),
      T = n ? I.shape[1] : I.shape[2],
      N = null != s,
      w = null != o,
      E = "leakyrelu" === l,
      A = null != l ? mapActivationToShaderProgram$1(l, !0) : null;
  var D;

  if ((1 === h || 1 === m) && T > MATMUL_SHARED_DIM_THRESHOLD$1 && !1 === (N || w || E || null != A)) {
    var _e450 = I,
        _t325 = C;
    n && (_e450 = transpose$3({
      inputs: {
        x: I
      },
      backend: a,
      attrs: {
        perm: [0, 2, 1]
      }
    }), S.push(_e450)), r && (_t325 = transpose$3({
      inputs: {
        x: C
      },
      backend: a,
      attrs: {
        perm: [0, 2, 1]
      }
    }), S.push(_t325));

    var _s82 = 1 === m;

    var _o58 = _e450;
    1 !== m && (_o58 = reshape$4({
      inputs: {
        x: _e450
      },
      backend: a,
      attrs: {
        shape: [k, T, 1]
      }
    }), S.push(_o58));

    var _i38 = 1 === m ? 2 : 1;

    var _l29 = _t325;
    _s82 && (_l29 = reshape$4({
      inputs: {
        x: _t325
      },
      backend: a,
      attrs: {
        shape: [k, 1, T]
      }
    }), S.push(_l29));

    var _u25 = multiply$3({
      inputs: {
        a: _o58,
        b: _l29
      },
      backend: a
    });

    D = sum$4({
      inputs: {
        x: _u25
      },
      backend: a,
      attrs: {
        axis: _i38,
        keepDims: !0
      }
    }), S.push(_u25);
  } else {
    var _l30 = upcastType$1(e.dtype, t.dtype),
        _u26 = new MatMulPackedProgram$1(x, v, [k, h, m], n, r, N, A, w, E),
        _c18 = [I, C];

    if (null != s && _c18.push(s), w && _c18.push(o), E) {
      var _e451 = a.makeTensorInfo([], "float32", createScalarValue$1(i, "float32"));

      _c18.push(_e451), S.push(_e451);
    }

    D = a.runWebGLProgram(_u26, _c18, _l30);
  }

  var R = reshape$4({
    inputs: {
      x: D
    },
    backend: a,
    attrs: {
      shape: b
    }
  });
  S.push(D);

  for (var _e452 of S) {
    a.disposeIntermediateTensorInfo(_e452);
  }

  return R;
}

function _fusedMatMul$2(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    a,
    b: s,
    bias: o,
    preluActivationWeights: i
  } = t,
      {
    transposeA: l,
    transposeB: u,
    activation: c,
    leakyreluAlpha: p
  } = r;
  return batchMatMulImpl$1({
    a,
    b: s,
    transposeA: l,
    transposeB: u,
    backend: n,
    bias: o,
    preluActivationWeights: i,
    leakyreluAlpha: p,
    activation: c
  });
}

var _fusedMatMulConfig$2 = {
  kernelName: _FusedMatMul$1,
  backendName: "webgl",
  kernelFunc: _fusedMatMul$2
},
    ABS$2 = "return abs(x);";

function abs$3(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    x: r
  } = t;

  if (n.shouldExecuteOnCPU([r]) && "complex64" !== r.dtype) {
    var _e453 = n.texData.get(r.dataId),
        _t326 = simpleAbsImplCPU$1(_e453.values);

    return n.makeTensorInfo(r.shape, r.dtype, _t326);
  }

  var a;
  return a = env$1().getBool("WEBGL_PACK_UNARY_OPERATIONS") ? new UnaryOpPackedProgram$1(r.shape, ABS$2) : new UnaryOpProgram$1(r.shape, ABS$2), n.runWebGLProgram(a, [r], r.dtype);
}

var absConfig$2 = {
  kernelName: Abs$1,
  backendName: "webgl",
  kernelFunc: abs$3
},
    ACOS$1 = CHECK_NAN_SNIPPET$5 + "\n  if (abs(x) > 1.) {\n    return NAN;\n  }\n  return acos(x);\n",
    acos$3 = unaryKernelFunc$2({
  opSnippet: ACOS$1
}),
    acosConfig$2 = {
  kernelName: Acos$1,
  backendName: "webgl",
  kernelFunc: acos$3
},
    ACOSH$1 = CHECK_NAN_SNIPPET$5 + "\n  if (x < 1.0) return NAN;\nreturn log(x + sqrt(x * x - 1.0));",
    acosh$3 = unaryKernelFunc$2({
  opSnippet: ACOSH$1
}),
    acoshConfig$2 = {
  kernelName: Acosh$1,
  backendName: "webgl",
  kernelFunc: acosh$3
},
    ADD$1 = "return a + b;",
    addKernelFunc$1 = binaryKernelFunc$2({
  opSnippet: ADD$1,
  packedOpSnippet: ADD$1,
  supportsComplex: !0,
  cpuKernelImpl: addImplCPU$1
}),
    addConfig$2 = {
  kernelName: Add$3,
  backendName: "webgl",
  kernelFunc: addKernelFunc$1
};

class AddNProgram$1 {
  constructor(e, t) {
    this.outputShape = [], this.outputShape = e, this.variableNames = t.map((e, t) => "T".concat(t));
    var n = [];
    this.variableNames.forEach(e => {
      n.push("float v".concat(e, " = get").concat(e, "AtOutCoords();"));
    });
    var r = this.variableNames.map(e => "v".concat(e)).join(" + ");
    this.userCode = "\n      void main() {\n        ".concat(n.join("\n        "), "\n\n        float result = ").concat(r, ";\n        setOutput(result);\n      }\n    ");
  }

}

class AddNPackedProgram$1 {
  constructor(e, t) {
    this.outputShape = [], this.packedInputs = !0, this.packedOutput = !0, this.outputShape = e, this.variableNames = t.map((e, t) => "T".concat(t));
    var n = [];
    this.variableNames.forEach(e => {
      n.push("vec4 v".concat(e, " = get").concat(e, "AtOutCoords();"));
    });
    var r = this.variableNames.map(e => "v".concat(e)).join(" + ");
    this.userCode = "\n      void main() {\n        ".concat(n.join("\n        "), "\n\n        vec4 result = ").concat(r, ";\n        setOutput(result);\n      }\n    ");
  }

}

function addN$3(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      r = t;
  if (1 === r.length) return identity$3({
    inputs: {
      x: r[0]
    },
    backend: n
  });

  if (r.length > env$1().get("WEBGL_MAX_TEXTURES_IN_SHADER")) {
    var _e454 = Math.floor(r.length / 2),
        _t327 = addN$3({
      inputs: r.slice(0, _e454),
      backend: n
    }),
        _a109 = addN$3({
      inputs: r.slice(_e454),
      backend: n
    });

    return addN$3({
      inputs: [_t327, _a109],
      backend: n
    });
  }

  var a = r.map(e => e.dtype).reduce((e, t) => upcastType$1(e, t)),
      s = r.map(e => e.shape),
      o = env$1().getBool("WEBGL_PACK") ? new AddNPackedProgram$1(r[0].shape, s) : new AddNProgram$1(r[0].shape, s);
  return n.runWebGLProgram(o, r, a);
}

var addNConfig$2 = {
  kernelName: AddN$1,
  backendName: "webgl",
  kernelFunc: addN$3
};

function all$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    axis: s,
    keepDims: o
  } = r,
      i = a.shape.length,
      l = parseAxisParam$1(s, a.shape);
  var u = l;
  var c = getAxesPermutation$1(u, i);
  var p = a;
  null != c && (p = transpose$3({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      perm: c
    }
  }), u = getInnerMostAxes$1(u.length, i)), assertAxesAreInnerMostDims$1("all", u, i);
  var [d, h] = computeOutAndReduceShapes$1(p.shape, u),
      m = reshape$4({
    inputs: {
      x: p
    },
    backend: n,
    attrs: {
      shape: [-1, sizeFromShape$1(h)]
    }
  }),
      f = reduce$1(m, m.dtype, "all", n);
  var g;
  return g = reshape$4(o ? {
    inputs: {
      x: f
    },
    backend: n,
    attrs: {
      shape: expandShapeToKeepDim$1(d, l)
    }
  } : {
    inputs: {
      x: f
    },
    backend: n,
    attrs: {
      shape: d
    }
  }), n.disposeIntermediateTensorInfo(m), n.disposeIntermediateTensorInfo(f), null != c && n.disposeIntermediateTensorInfo(p), g;
}

var allConfig$2 = {
  kernelName: All$1,
  backendName: "webgl",
  kernelFunc: all$3
};

function any$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    axis: s,
    keepDims: o
  } = r,
      i = a.shape.length,
      l = parseAxisParam$1(s, a.shape);
  var u = l;
  var c = getAxesPermutation$1(u, i);
  var p = a;
  null != c && (p = transpose$3({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      perm: c
    }
  }), u = getInnerMostAxes$1(u.length, i)), assertAxesAreInnerMostDims$1("any", u, i);
  var [d, h] = computeOutAndReduceShapes$1(p.shape, u),
      m = reshape$4({
    inputs: {
      x: p
    },
    backend: n,
    attrs: {
      shape: [-1, sizeFromShape$1(h)]
    }
  }),
      f = reduce$1(m, m.dtype, "any", n);
  var g;
  return g = reshape$4(o ? {
    inputs: {
      x: f
    },
    backend: n,
    attrs: {
      shape: expandShapeToKeepDim$1(d, l)
    }
  } : {
    inputs: {
      x: f
    },
    backend: n,
    attrs: {
      shape: d
    }
  }), n.disposeIntermediateTensorInfo(m), n.disposeIntermediateTensorInfo(f), null != c && n.disposeIntermediateTensorInfo(p), g;
}

var anyConfig$2 = {
  kernelName: Any$1,
  backendName: "webgl",
  kernelFunc: any$3
};

class ArgMinMaxProgram$1 {
  constructor(e, t, n) {
    this.variableNames = ["A"];
    var {
      windowSize: r,
      batchSize: a,
      outSize: s
    } = e;
    n || this.variableNames.push("bestIndicesA"), this.outputShape = [a, s], this.userCode = "\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n        int outIdx = coords[1];\n        int inOffset = outIdx * ".concat(r, ";\n\n        int bestIndex = inOffset;\n        float bestValue = getA(batch, bestIndex);\n\n        for (int i = 0; i < ").concat(r, "; i++) {\n          int inIdx = ").concat(n ? "inOffset + i;" : "round(getBestIndicesA(batch, inOffset + i));", ";\n          float candidate = getA(batch, inIdx);\n          if (candidate ").concat("max" === t ? ">" : "<", " bestValue) {\n            bestValue = candidate;\n            bestIndex = inIdx;\n          }\n        }\n        setOutput(float(bestIndex));\n      }\n    ");
  }

}

class ArgMinMaxPackedProgram$1 {
  constructor(e, t, n, r) {
    this.variableNames = ["A"], this.packedInputs = !0, this.packedOutput = !0, assert$6(e.length > 2, () => "Packed arg".concat(n.charAt(0).toUpperCase() + n.slice(1), " supports only inputs with rank above 2."));
    var a = Math.ceil(e[e.length - 1] / t);
    this.outputShape = e.slice(0, -1), a > 1 && this.outputShape.push(a), r || this.variableNames.push("bestIndicesA");
    var s = this.outputShape,
        o = s.length,
        i = getCoordsDataType$1(o),
        l = getChannels$1("coords", o);
    var u, c;

    if (1 === a) {
      c = o + 1;

      var _e455 = getCoordsDataType$1(c);

      u = "\n        ".concat(_e455, " sourceLocR = ").concat(_e455, "(").concat(l.join(), ", 0);\n        ++").concat(l[o - 1], ";\n        ").concat(_e455, " sourceLocG = ").concat(_e455, "(").concat(l.join(), ", 0);\n        ++").concat(l[o - 2], ";\n        ").concat(_e455, " sourceLocA = ").concat(_e455, "(").concat(l.join(), ", 0);\n        --").concat(l[o - 1], ";\n        ").concat(_e455, " sourceLocB = ").concat(_e455, "(").concat(l.join(), ", 0);\n        --").concat(l[o - 2], ";");
    } else c = o, u = "\n        ".concat(i, " sourceLocR = coords;\n        ++").concat(l[o - 1], ";\n        ").concat(i, " sourceLocG = coords;\n        ++").concat(l[o - 2], ";\n        ").concat(i, " sourceLocA = coords;\n        --").concat(l[o - 1], ";\n        ").concat(i, " sourceLocB = coords;\n        --").concat(l[o - 2], ";");

    var p = ["x", "y", "z", "w", "u", "v"].slice(0, c),
        d = "." + p[c - 1],
        h = p.map(e => "int " + e),
        m = getChannels$1("sourceLocR", c - 1).concat("inIdx.r"),
        f = getChannels$1("sourceLocG", c - 1).concat("inIdx.g"),
        g = getChannels$1("sourceLocB", c - 1).concat("inIdx.b"),
        $ = getChannels$1("sourceLocA", c - 1).concat("inIdx.a"),
        y = "max" === n ? "greaterThan" : "lessThan",
        b = r ? "" : "\n          inIdx = round(vec4(getBestIndicesAChannel(".concat(m.join(), "),\n                             getBestIndicesAChannel(").concat(f.join(), "),\n                             getBestIndicesAChannel(").concat(g.join(), "),\n                             getBestIndicesAChannel(").concat($.join(), ")));"),
        x = "vec4(\n            getAChannel(".concat(m.join(), "),\n            hasNextCol ? getAChannel(").concat(f.join(), ") : 0.,\n            hasNextRow ? getAChannel(").concat(g.join(), ") : 0.,\n            hasNextRow && hasNextCol ? getAChannel(").concat($.join(), ") : 0.)"),
        v = r ? "" : "\n      float getBestIndicesAChannel(".concat(h.join(), ") {\n        return getChannel(getBestIndicesA(").concat(p.join(), "),\n                                          vec2(").concat(p.slice(-2).join(), "));\n      }");
    this.userCode = "\n      float getAChannel(".concat(h.join(), ") {\n        return getChannel(getA(").concat(p.join(), "),\n                               vec2(").concat(p.slice(-2).join(), "));\n      }\n      ").concat(v, "\n      void main() {\n        ").concat(i, " coords = getOutputCoords();\n        bool hasNextCol = ").concat(l[o - 1], " < ").concat(s[o - 1] - 1, ";\n        bool hasNextRow = ").concat(l[o - 2], " < ").concat(s[o - 2] - 1, ";\n        ").concat(u, "\n        ivec4 srcIdx = ivec4(sourceLocR").concat(d, ", sourceLocG").concat(d, ",\n          sourceLocB").concat(d, ", sourceLocA").concat(d, ") * ").concat(t, ";\n        ivec4 inIdx = srcIdx;\n        vec4 bestIndex = vec4(inIdx);\n        vec4 bestValue = ").concat(x, ";\n\n        for (int i = 0; i < ").concat(t, "; i++) {\n          inIdx = srcIdx;\n          ").concat(b, "\n          vec4 candidate = ").concat(x, ";\n          bvec4 nan = isnan(candidate);\n          bvec4 replace = bvec4(\n            vec4(").concat(y, "(candidate, bestValue)) * (vec4(1.0) - vec4(nan)));\n\n          bestValue = vec4(replace.x  ? candidate.x : bestValue.x,\n                           replace.y  ? candidate.y : bestValue.y,\n                           replace.z  ? candidate.z : bestValue.z,\n                           replace.w  ? candidate.w : bestValue.w);\n          bestIndex = mix(bestIndex, vec4(inIdx), vec4(replace));\n          srcIdx++;\n        }\n        setOutput(bestIndex);\n      }\n    ");
  }

}

function argReduce$1(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : null;
  var a = t.shape[0],
      s = t.shape[1];
  null != r && (a = r.shape[0], s = r.shape[1]);
  var o = computeOptimalWindowSize$1(s),
      i = {
    windowSize: o,
    inSize: s,
    batchSize: a,
    outSize: Math.ceil(s / o)
  },
      l = new ArgMinMaxProgram$1(i, n, null == r),
      u = [t];
  null != r && u.push(r);
  var c = e.runWebGLProgram(l, u, "int32");
  if (1 === c.shape[1]) return c;
  var p = argReduce$1(e, t, n, c);
  return e.disposeIntermediateTensorInfo(c), p;
}

function argReducePacked$1(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : null;
  var a = null != r ? r.shape : t.shape,
      s = computeOptimalWindowSize$1(a[a.length - 1]),
      o = new ArgMinMaxPackedProgram$1(a, s, n, null == r),
      i = e.runWebGLProgram(o, null == r ? [t] : [t, r], "int32");

  if (i.shape.length === t.shape.length) {
    var _r156 = argReducePacked$1(e, t, n, i);

    return e.disposeIntermediateTensorInfo(i), _r156;
  }

  return i;
}

function argMinMaxReduce$1(e, t, n, r) {
  var a = [n];

  if (assertAxesAreInnerMostDims$1("arg" + r.charAt(0).toUpperCase() + r.slice(1), a, t.shape.length), !env$1().getBool("WEBGL_PACK_REDUCE") || t.shape.length <= 2) {
    var _n209 = [],
        [s, o] = computeOutAndReduceShapes$1(t.shape, a),
        i = sizeFromShape$1(o),
        l = reshape$4({
      inputs: {
        x: t
      },
      backend: e,
      attrs: {
        shape: [-1, i]
      }
    });

    _n209.push(l);

    var u = argReduce$1(e, l, r);

    _n209.push(u);

    var c = reshape$4({
      inputs: {
        x: u
      },
      backend: e,
      attrs: {
        shape: s
      }
    });
    return _n209.forEach(t => e.disposeIntermediateTensorInfo(t)), c;
  }

  return argReducePacked$1(e, t, r);
}

function argMax$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    axis: s
  } = r;
  var o = parseAxisParam$1(s, a.shape);
  var i = getAxesPermutation$1(o, a.shape.length);
  var l = a;
  var u = [];
  null != i && (l = transpose$3({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      perm: i
    }
  }), u.push(l), o = getInnerMostAxes$1(o.length, l.shape.length)), assertAxesAreInnerMostDims$1("argMax", [o[0]], l.shape.length);
  var c = argMinMaxReduce$1(n, l, o[0], "max");
  return u.forEach(e => n.disposeIntermediateTensorInfo(e)), c;
}

var argMaxConfig$2 = {
  kernelName: ArgMax$1,
  backendName: "webgl",
  kernelFunc: argMax$3
};

function argMin$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    axis: s
  } = r;
  var o = parseAxisParam$1(s, a.shape);
  var i = getAxesPermutation$1(o, a.shape.length);
  var l = a;
  var u = [];
  null != i && (l = transpose$3({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      perm: i
    }
  }), u.push(l), o = getInnerMostAxes$1(o.length, l.shape.length)), assertAxesAreInnerMostDims$1("argMin", [o[0]], l.shape.length);
  var c = argMinMaxReduce$1(n, l, o[0], "min");
  return u.forEach(e => n.disposeIntermediateTensorInfo(e)), c;
}

var argMinConfig$2 = {
  kernelName: ArgMin$1,
  backendName: "webgl",
  kernelFunc: argMin$3
},
    ASIN$1 = CHECK_NAN_SNIPPET$5 + "\n  if (abs(x) > 1.) {\n    return NAN;\n  }\n  return asin(x);\n",
    asin$3 = unaryKernelFunc$2({
  opSnippet: ASIN$1
}),
    asinConfig$2 = {
  kernelName: Asin$1,
  backendName: "webgl",
  kernelFunc: asin$3
},
    ASINH$1 = CHECK_NAN_SNIPPET$5 + "return log(x + sqrt(x * x + 1.0));",
    asinh$3 = unaryKernelFunc$2({
  opSnippet: ASINH$1
}),
    asinhConfig$2 = {
  kernelName: Asinh$1,
  backendName: "webgl",
  kernelFunc: asinh$3
},
    ATAN$1 = CHECK_NAN_SNIPPET$5 + "\n  return atan(x);\n",
    atan$3 = unaryKernelFunc$2({
  opSnippet: ATAN$1
}),
    atanConfig$2 = {
  kernelName: Atan$1,
  backendName: "webgl",
  kernelFunc: atan$3
},
    ATAN2$1 = CHECK_NAN_SNIPPET_BINARY$1 + "\n  return atan(a, b);\n",
    ATAN2_PACKED$1 = "\n  vec4 result = atan(a, b);\n  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));\n  " + CHECK_NAN_SNIPPET_BINARY_PACKED$1 + "\n  return result;\n",
    atan2$3 = binaryKernelFunc$2({
  opSnippet: ATAN2$1,
  packedOpSnippet: ATAN2_PACKED$1
}),
    atan2Config$2 = {
  kernelName: Atan2$1,
  backendName: "webgl",
  kernelFunc: atan2$3
},
    ATANH$1 = CHECK_NAN_SNIPPET$5 + "\n  if ((x < -1.0) || (x > 1.0)) return NAN;\nreturn (log(1.0 + x) - log(1.0 - x)) / 2.0;",
    atanh$3 = unaryKernelFunc$2({
  opSnippet: ATANH$1
}),
    atanhConfig$2 = {
  kernelName: Atanh$1,
  backendName: "webgl",
  kernelFunc: atanh$3
};

class Pool2DProgram$1 {
  constructor(e, t, n) {
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
    var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;
    if (this.variableNames = ["x"], "avg" === t && n) throw new Error("Cannot compute positions for average pool.");
    var s = e.filterWidth,
        o = e.strideHeight,
        i = e.strideWidth,
        l = e.dilationHeight,
        u = e.dilationWidth,
        c = e.effectiveFilterHeight,
        p = e.effectiveFilterWidth,
        d = e.padInfo.top,
        h = e.padInfo.left;
    this.outputShape = e.outShape;
    var m = "avg" === t;
    var f = "0.0";
    if (m || (f = "-1.0 / 1e-20"), n) return void (this.userCode = "\n        const ivec2 strides = ivec2(".concat(o, ", ").concat(i, ");\n        const ivec2 pads = ivec2(").concat(d, ", ").concat(h, ");\n\n        void main() {\n          ivec4 coords = getOutputCoords();\n          int batch = coords[0];\n          int d = coords[3];\n\n          ivec2 xRCCorner = coords.yz * strides - pads;\n          int xRCorner = xRCCorner.x;\n          int xCCorner = xRCCorner.y;\n\n          // max/min x(?, ?, d) to get y(yR, yC, d).\n          // ? = to be determined\n          float minMaxValue = 0.0;\n          float minMaxValueFound = 0.0;\n          int minMaxPosition = 0;\n          float avgValue = 0.0;\n\n          for (int wR = 0; wR < ").concat(c, ";\n              wR += ").concat(l, ") {\n            int xR = xRCorner + wR;\n\n            if (xR < 0 || xR >= ").concat(e.inHeight, ") {\n              continue;\n            }\n\n            for (int wC = 0; wC < ").concat(p, ";\n                wC += ").concat(u, ") {\n              int xC = xCCorner + wC;\n\n              if (xC < 0 || xC >= ").concat(e.inWidth, ") {\n                continue;\n              }\n\n              float value = getX(batch, xR, xC, d);\n\n              // If a min / max value has already been found, use it. If not,\n              // use the current value.\n              float currMinMaxValue = mix(\n                  value, minMaxValue, minMaxValueFound);\n              if (value >= currMinMaxValue) {\n                minMaxValue = value;\n                minMaxValueFound = 1.0;\n                minMaxPosition = ").concat(r ? a ? "((batch  * ".concat(e.inHeight, " + xR) * ").concat(e.inWidth, " + xC) * ").concat(e.inChannels, " + d") : "(xR * ".concat(e.inWidth, " + xC) * ").concat(e.inChannels, " + d") : "wR * ".concat(p, " + wC"), ";\n              }\n            }\n          }\n          setOutput(float(minMaxPosition));\n        }\n      "));
    var g = "".concat(t, "(").concat(t, "(").concat(t, "(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])");
    "avg" === t && (g = "avgValue / count");
    var $ = 4 * Math.floor(s / 4),
        y = s % 4,
        b = "\n      if (".concat(m, ") {\n        avgValue += dot(values, ones);\n      } else {\n        minMaxValue = max(values, minMaxValue);\n      }\n    ");
    this.userCode = "\n      const ivec2 strides = ivec2(".concat(o, ", ").concat(i, ");\n      const ivec2 pads = ivec2(").concat(d, ", ").concat(h, ");\n      const float initializationValue = ").concat(f, ";\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\n\n      float count = 0.0;\n\n      float getValue(int batch, int xR, int xC, int d) {\n        if (xC < 0 || xC >= ").concat(e.inWidth, ") {\n          return initializationValue;\n        }\n        count += 1.0;\n        return getX(batch, xR, xC, d);\n      }\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d = coords[3];\n\n        ivec2 xRCCorner = coords.yz * strides - pads;\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        // max/min x(?, ?, d) to get y(yR, yC, d).\n        // ? = to be determined\n        vec4 minMaxValue = vec4(").concat(f, ");\n        float avgValue = 0.0;\n        count = 0.0;\n\n        for (int wR = 0; wR < ").concat(c, ";\n            wR += ").concat(l, ") {\n          int xR = xRCorner + wR;\n\n          if (xR < 0 || xR >= ").concat(e.inHeight, ") {\n            continue;\n          }\n\n          for (int wC = 0; wC < ").concat($, "; wC += 4) {\n            int xC = xCCorner + wC * ").concat(u, ";\n\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              getValue(batch, xR, xC + ").concat(u, ", d),\n              getValue(batch, xR, xC + 2 * ").concat(u, ", d),\n              getValue(batch, xR, xC + 3 * ").concat(u, ", d)\n            );\n\n            ").concat(b, "\n          }\n\n          int xC = xCCorner + ").concat($, ";\n          if (").concat(1 === y, ") {\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              initializationValue,\n              initializationValue,\n              initializationValue\n            );\n\n            ").concat(b, "\n          } else if (").concat(2 === y, ") {\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              getValue(batch, xR, xC + ").concat(u, ", d),\n              initializationValue,\n              initializationValue\n            );\n\n            ").concat(b, "\n          } else if (").concat(3 === y, ") {\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              getValue(batch, xR, xC + ").concat(u, ", d),\n              getValue(batch, xR, xC + 2 * ").concat(u, ", d),\n              initializationValue\n            );\n\n            ").concat(b, "\n          }\n        }\n        setOutput(").concat(g, ");\n      }\n    ");
  }

}

class Pool3DProgram$1 {
  constructor(e, t, n) {
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
    var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;
    if (this.variableNames = ["x"], "avg" === t && n) throw new Error("Cannot compute positions for average pool.");
    var s = e.filterWidth,
        o = e.strideDepth,
        i = e.strideHeight,
        l = e.strideWidth,
        u = e.dilationDepth,
        c = e.dilationHeight,
        p = e.dilationWidth,
        d = e.effectiveFilterDepth,
        h = e.effectiveFilterHeight,
        m = e.effectiveFilterWidth,
        f = e.padInfo.front,
        g = e.padInfo.top,
        $ = e.padInfo.left;
    this.outputShape = e.outShape;
    var y = "avg" === t;
    var b = "0.0";
    if (y || (b = "-1.0 / 1e-20"), n) return void (this.userCode = "\n        const ivec3 strides =\n            ivec3(".concat(o, ", ").concat(i, ", ").concat(l, ");\n        const ivec3 pads = ivec3(").concat(f, ", ").concat(g, ", ").concat($, ");\n\n        void main() {\n          ivec5 coords = getOutputCoords();\n          int batch = coords.x;\n          int ch = coords.u;\n\n          ivec3 xCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\n          int xDCorner = xCorner.x;\n          int xRCorner = xCorner.y;\n          int xCCorner = xCorner.z;\n\n          // max/min x(?, ?, ?, ch) to get y(yD, yR, yC, ch).\n          // ? = to be determined\n          float minMaxValue = 0.0;\n          float minMaxValueFound = 0.0;\n          int minMaxPosition = 0;\n\n          for (int wD = 0; wD < ").concat(d, ";\n              wD += ").concat(u, ") {\n            int xD = xDCorner + wD;\n\n            if (xD < 0 || xD >= ").concat(e.inDepth, ") {\n              continue;\n            }\n\n            for (int wR = 0; wR < ").concat(h, ";\n                wR += ").concat(c, ") {\n              int xR = xRCorner + wR;\n\n              if (xR < 0 || xR >= ").concat(e.inHeight, ") {\n                continue;\n              }\n\n              for (int wC = 0; wC < ").concat(m, ";\n                  wC += ").concat(p, ") {\n                int xC = xCCorner + wC;\n\n                if (xC < 0 || xC >= ").concat(e.inWidth, ") {\n                  continue;\n                }\n\n                float value = getX(batch, xD, xR, xC, ch);\n\n                // If a min / max value has already been found, use it. If not,\n                // use the current value.\n                float currMinMaxValue = mix(\n                    value, minMaxValue, minMaxValueFound);\n                if (value >= currMinMaxValue) {\n                  minMaxValue = value;\n                  minMaxValueFound = 1.0;\n                  minMaxPosition = ").concat(r ? a ? "(((batch * ".concat(e.inDepth, " + xD) * ").concat(e.inHeight, " + xR) * ").concat(e.inWidth, " + xC) * ").concat(e.inChannels, " + ch") : "((xD * ".concat(e.inHeight, " + xR) * ").concat(e.inWidth, " + xC) * ").concat(e.inChannels, " + ch") : "wD * ".concat(h, " * ").concat(m, " +\n                      wR * ").concat(m, " + wC"), ";\n                }\n              }\n            }\n          }\n          setOutput(float(minMaxPosition));\n        }\n      "));
    var x = "".concat(t, "(").concat(t, "(").concat(t, "(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])");
    "avg" === t && (x = "avgValue / count");
    var v = 4 * Math.floor(s / 4),
        I = s % 4,
        C = "\n      if (".concat(y, ") {\n        avgValue += dot(values, ones);\n      } else {\n        minMaxValue = max(values, minMaxValue);\n      }\n    ");
    this.userCode = "\n      const ivec3 strides =\n        ivec3(".concat(o, ", ").concat(i, ", ").concat(l, ");\n      const ivec3 pads = ivec3(").concat(f, ", ").concat(g, ", ").concat($, ");\n      const float initializationValue = ").concat(b, ";\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\n\n      float count = 0.0;\n\n      float getValue(int batch, int xD, int xR, int xC, int ch) {\n        if (xC < 0 || xC >= ").concat(e.inWidth, ") {\n          return initializationValue;\n        }\n        count += 1.0;\n        return getX(batch, xD, xR, xC, ch);\n      }\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int ch = coords.u;\n\n        ivec3 xCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\n        int xDCorner = xCorner.x;\n        int xRCorner = xCorner.y;\n        int xCCorner = xCorner.z;\n\n        // max/min x(?, ?, ?, d) to get y(yD, yR, yC, ch).\n        // ? = to be determined\n        vec4 minMaxValue = vec4(").concat(b, ");\n        float avgValue = 0.0;\n        count = 0.0;\n\n        for (int wD = 0; wD < ").concat(d, ";\n            wD += ").concat(u, ") {\n          int xD = xDCorner + wD;\n\n          if (xD < 0 || xD >= ").concat(e.inDepth, ") {\n            continue;\n          }\n\n          for (int wR = 0; wR < ").concat(h, ";\n            wR += ").concat(c, ") {\n            int xR = xRCorner + wR;\n\n            if (xR < 0 || xR >= ").concat(e.inHeight, ") {\n              continue;\n            }\n\n            for (int wC = 0; wC < ").concat(v, "; wC += 4) {\n              int xC = xCCorner + wC * ").concat(p, ";\n\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                getValue(batch, xD, xR, xC + ").concat(p, ", ch),\n                getValue(batch, xD, xR, xC + 2 * ").concat(p, ", ch),\n                getValue(batch, xD, xR, xC + 3 * ").concat(p, ", ch)\n              );\n\n              ").concat(C, "\n            }\n\n            int xC = xCCorner + ").concat(v, ";\n            if (").concat(1 === I, ") {\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                initializationValue,\n                initializationValue,\n                initializationValue\n              );\n\n              ").concat(C, "\n            } else if (").concat(2 === I, ") {\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                getValue(batch, xD, xR, xC + ").concat(p, ", ch),\n                initializationValue,\n                initializationValue\n              );\n\n              ").concat(C, "\n            } else if (").concat(3 === I, ") {\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                getValue(batch, xD, xR, xC + ").concat(p, ", ch),\n                getValue(batch, xD, xR, xC + 2 * ").concat(p, ", ch),\n                initializationValue\n              );\n\n              ").concat(C, "\n            }\n          }\n          setOutput(").concat(x, ");\n        }\n      }\n    ");
  }

}

function avgPool$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t;
  assertNotComplex$2(a, "avgPool");
  var {
    filterSize: s,
    strides: o,
    pad: i,
    dimRoundingMode: l
  } = r;
  assert$6(eitherStridesOrDilationsAreOne$1(o, 1), () => "Error in avgPool: Either strides or dilations must be 1. Got strides ".concat(o, " and dilations '1'"));
  var u = computePool2DInfo$1(a.shape, s, o, 1, i, l);
  if (1 === u.filterWidth && 1 === u.filterHeight && arraysEqual$1(u.inShape, u.outShape)) return identity$3({
    inputs: {
      x: a
    },
    backend: n
  });
  var c = new Pool2DProgram$1(u, "avg", !1);
  return n.runWebGLProgram(c, [a], "float32");
}

var avgPoolConfig$2 = {
  kernelName: AvgPool$1,
  backendName: "webgl",
  kernelFunc: avgPool$3
};

function avgPool3D$2(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    filterSize: s,
    strides: o,
    pad: i,
    dimRoundingMode: l,
    dataFormat: u
  } = r,
      c = computePool3DInfo$1(a.shape, s, o, [1, 1, 1], i, l, u),
      p = new Pool3DProgram$1(c, "avg", !1);
  return n.runWebGLProgram(p, [a], "float32");
}

var avgPool3DConfig$2 = {
  kernelName: AvgPool3D$1,
  backendName: "webgl",
  kernelFunc: avgPool3D$2
};

class AvgPool2DBackpropProgram$1 {
  constructor(e) {
    this.variableNames = ["dy"], this.outputShape = e.inShape;
    var t = e.effectiveFilterHeight,
        n = e.effectiveFilterWidth;
    this.userCode = "\n      const ivec2 pads = ivec2(".concat(t - 1 - e.padInfo.top, ", ").concat(n - 1 - e.padInfo.left, ");\n      const float avgMultiplier = float(").concat(1 / (e.filterHeight * e.filterWidth), ");\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n\n        ivec2 dyRCCorner = coords.yz - pads;\n        int dyRCorner = dyRCCorner.x;\n        int dyCCorner = dyRCCorner.y;\n\n        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ").concat(t, ";\n            wR += ").concat(e.dilationHeight, ") {\n          float dyR = float(dyRCorner + wR) / ").concat(e.strideHeight, ".0;\n\n          if (dyR < 0.0 || dyR >= ").concat(e.outHeight, ".0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          for (int wC = 0; wC < ").concat(n, ";\n            wC+= ").concat(e.dilationWidth, ") {\n            float dyC = float(dyCCorner + wC) / ").concat(e.strideWidth, ".0;\n\n            if (dyC < 0.0 || dyC >= ").concat(e.outWidth, ".0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            float dyValue = getDy(b, idyR, idyC, d);\n\n            dotProd += dyValue * avgMultiplier;\n          }\n        }\n        setOutput(dotProd);\n      }\n    ");
  }

}

class AvgPool3DBackpropProgram$1 {
  constructor(e) {
    this.variableNames = ["dy"], this.outputShape = e.inShape;
    var t = e.effectiveFilterDepth,
        n = e.effectiveFilterHeight,
        r = e.effectiveFilterWidth;
    this.userCode = "\n      const ivec3 pads = ivec3(".concat(t - 1 - e.padInfo.front, ", ").concat(n - 1 - e.padInfo.top, ", ").concat(r - 1 - e.padInfo.left, ");\n      const float avgMultiplier = float(").concat(1 / (e.filterDepth * e.filterHeight * e.filterWidth), ");\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int ch = coords.u;\n\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\n        int dyDCorner = dyCorner.x;\n        int dyRCorner = dyCorner.y;\n        int dyCCorner = dyCorner.z;\n\n        // Convolve dy(?, ?, ?, d) with pos mask(:, :, :, ch) to get\n        // dx(xD, xR, xC, ch).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n\n        for (int wD = 0; wD < ").concat(t, ";\n            wD += ").concat(e.dilationDepth, ") {\n          float dyD = float(dyDCorner + wD) / ").concat(e.strideDepth, ".0;\n\n          if (dyD < 0.0 || dyD >= ").concat(e.outDepth, ".0 || fract(dyD) > 0.0) {\n            continue;\n          }\n          int idyD = int(dyD);\n\n          for (int wR = 0; wR < ").concat(n, ";\n              wR += ").concat(e.dilationHeight, ") {\n            float dyR = float(dyRCorner + wR) / ").concat(e.strideHeight, ".0;\n\n            if (dyR < 0.0 || dyR >= ").concat(e.outHeight, ".0 ||\n                fract(dyR) > 0.0) {\n              continue;\n            }\n            int idyR = int(dyR);\n\n            for (int wC = 0; wC < ").concat(r, ";\n                wC += ").concat(e.dilationWidth, ") {\n              float dyC = float(dyCCorner + wC) / ").concat(e.strideWidth, ".0;\n\n              if (dyC < 0.0 || dyC >= ").concat(e.outWidth, ".0 ||\n                  fract(dyC) > 0.0) {\n                continue;\n              }\n              int idyC = int(dyC);\n\n              float dyValue = getDy(batch, idyD, idyR, idyC, ch);\n\n              dotProd += dyValue * avgMultiplier;\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    ");
  }

}

function avgPool3DGrad$2(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    dy: a,
    input: s
  } = t,
      o = s,
      {
    filterSize: i,
    strides: l,
    pad: u,
    dimRoundingMode: c
  } = r,
      p = computePool3DInfo$1(o.shape, i, l, [1, 1, 1], u, c),
      d = new AvgPool3DBackpropProgram$1(p);
  return n.runWebGLProgram(d, [a], o.dtype);
}

var avgPoolGrad3DConfig$1 = {
  kernelName: AvgPool3DGrad$1,
  backendName: "webgl",
  kernelFunc: avgPool3DGrad$2
};

function avgPoolGrad$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    dy: a,
    input: s
  } = t,
      o = s;
  assertNotComplex$2([a, s], "avgPoolGrad");
  var {
    filterSize: i,
    strides: l,
    pad: u
  } = r,
      c = computePool2DInfo$1(o.shape, i, l, 1, u),
      p = new AvgPool2DBackpropProgram$1(c);
  return n.runWebGLProgram(p, [a], o.dtype);
}

var avgPoolGradConfig$3 = {
  kernelName: AvgPoolGrad$1,
  backendName: "webgl",
  kernelFunc: avgPoolGrad$3
};

function batchMatMul$2(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    a,
    b: s
  } = t,
      {
    transposeA: o,
    transposeB: i
  } = r;
  return batchMatMulImpl$1({
    a,
    b: s,
    transposeA: o,
    transposeB: i,
    backend: n
  });
}

var batchMatMulConfig$2 = {
  kernelName: BatchMatMul$1,
  backendName: "webgl",
  kernelFunc: batchMatMul$2
};

class BatchNormProgram$1 {
  constructor(e, t, n, r, a, s) {
    this.outputShape = [], this.variableNames = ["x", "mean", "variance"], assertAndGetBroadcastShape$1(e, t), assertAndGetBroadcastShape$1(e, n);
    var o = "0.0";
    null != r && (assertAndGetBroadcastShape$1(e, r), this.variableNames.push("offset"), o = "getOffsetAtOutCoords()");
    var i = "1.0";
    null != a && (assertAndGetBroadcastShape$1(e, a), this.variableNames.push("scale"), i = "getScaleAtOutCoords()"), this.outputShape = e, this.userCode = "\n      void main() {\n        float x = getXAtOutCoords();\n        float mean = getMeanAtOutCoords();\n        float variance = getVarianceAtOutCoords();\n        float offset = ".concat(o, ";\n        float scale = ").concat(i, ";\n        float inv = scale * inversesqrt(variance + float(").concat(s, "));\n        setOutput(dot(vec3(x, -mean, offset), vec3(inv, inv, 1)));\n      }\n    ");
  }

}

class BatchNormPackedProgram$1 {
  constructor(e, t, n, r, a, s) {
    this.packedInputs = !0, this.packedOutput = !0, this.variableNames = ["x", "mean", "variance"], assertAndGetBroadcastShape$1(e, t), assertAndGetBroadcastShape$1(e, n);
    var o = "vec4(0.0)";
    null != r && (assertAndGetBroadcastShape$1(e, r), this.variableNames.push("offset"), o = "getOffsetAtOutCoords()");
    var i = "vec4(1.0)";
    null != a && (assertAndGetBroadcastShape$1(e, a), this.variableNames.push("scale"), i = "getScaleAtOutCoords()"), this.outputShape = e, this.userCode = "\n      void main() {\n        vec4 offset = ".concat(o, ";\n        vec4 scale = ").concat(i, ";\n\n        vec4 x = getXAtOutCoords();\n        vec4 mean = getMeanAtOutCoords();\n        vec4 variance = getVarianceAtOutCoords();\n\n        vec4 inv = scale * inversesqrt(variance + vec4(").concat(s, "));\n\n        setOutput((x - mean) * inv + offset);\n      }\n    ");
  }

}

var batchNorm$3 = _ref19 => {
  var {
    inputs: e,
    backend: t,
    attrs: n
  } = _ref19;
  var {
    x: r,
    mean: a,
    variance: s,
    offset: o,
    scale: i
  } = e;
  assert$6(a.shape.length === s.shape.length, () => "Batch normalization gradient requires mean and variance to have equal ranks."), assert$6(null == o || a.shape.length === o.shape.length, () => "Batch normalization gradient requires mean and offset to have equal ranks."), assert$6(null == i || a.shape.length === i.shape.length, () => "Batch normalization gradient requires mean and scale to have equal ranks.");
  var {
    varianceEpsilon: l
  } = n;
  null == l && (l = .001);
  var u = [r, a, s];
  var c = null;
  null != o && (c = o.shape, u.push(o));
  var p = null;
  null != i && (p = i.shape, u.push(i));
  var d = env$1().getBool("WEBGL_PACK_NORMALIZATION") ? new BatchNormPackedProgram$1(r.shape, a.shape, s.shape, c, p, l) : new BatchNormProgram$1(r.shape, a.shape, s.shape, c, p, l);
  return t.runWebGLProgram(d, u, u[0].dtype);
},
    batchNormConfig$2 = {
  kernelName: FusedBatchNorm$1,
  backendName: "webgl",
  kernelFunc: batchNorm$3
};

class SliceProgram$1 {
  constructor(e) {
    this.variableNames = ["source"], this.outputShape = e, this.rank = e.length;
    var t = getCoordsDataType$1(this.rank);
    this.customUniforms = [{
      name: "start",
      arrayIndex: this.rank,
      type: "int"
    }];
    var n = getCoords$3(this.rank);
    var r;
    r = "\n        ".concat(t, " sourceLoc;\n        ").concat(t, " coords = getOutputCoords();\n        ").concat(e.map((e, t) => "sourceLoc.".concat(coords$1[t], " = start[").concat(t, "] + coords.").concat(coords$1[t], ";")).join("\n"), "\n      "), this.userCode = "\n      void main() {\n        ".concat(r, "\n        setOutput(getSource(").concat(n, "));\n      }\n    ");
  }

}

var coords$1 = ["x", "y", "z", "w", "u", "v"];

function getCoords$3(e) {
  if (1 === e) return "sourceLoc";
  if (e <= 6) return coords$1.slice(0, e).map(e => "sourceLoc." + e).join(",");
  throw Error("Slicing for rank ".concat(e, " is not yet supported"));
}

class SlicePackedProgram$1 {
  constructor(e) {
    this.variableNames = ["source"], this.packedInputs = !0, this.packedOutput = !0, this.outputShape = e, this.rank = e.length, this.customUniforms = [{
      name: "start",
      arrayIndex: this.rank,
      type: "int"
    }];
    var t = getCoordsDataType$1(this.rank),
        n = getChannels$1("coords", this.rank),
        r = getChannels$1("sourceLoc", this.rank),
        a = 1 === this.rank ? "sourceLoc" : "vec2(".concat(r.slice(-2).join(), ")"),
        s = "getChannel(getSource(".concat(r.join(), "), ").concat(a, ")"),
        o = "\n      result.x = ".concat(s, ";\n      if (++").concat(n[this.rank - 1], " < ").concat(e[this.rank - 1], ") {\n        ++").concat(r[this.rank - 1], ";\n        result.y = ").concat(s, ";\n        --").concat(r[this.rank - 1], ";\n      }\n    "),
        i = 1 === this.rank ? "" : "\n      --".concat(n[this.rank - 1], ";\n      if (++").concat(n[this.rank - 2], " < ").concat(e[this.rank - 2], ") {\n        ++").concat(r[this.rank - 2], ";\n        result.z = ").concat(s, ";\n        if (++").concat(n[this.rank - 1], " < ").concat(e[this.rank - 1], ") {\n          ++").concat(r[this.rank - 1], ";\n          result.w = ").concat(s, ";\n        }\n      }\n    "),
        l = this.rank <= 4 ? "sourceLoc = coords +\n            ".concat(t, "(").concat(e.map((e, t) => "start[".concat(t, "]")).join(), ");") : e.map((e, t) => "".concat(r[t], " = ").concat(n[t], " + start[").concat(t, "];")).join("\n");
    this.userCode = "\n      void main() {\n        ".concat(t, " coords = getOutputCoords();\n        ").concat(t, " sourceLoc;\n        ").concat(l, "\n        vec4 result = vec4(0.);\n        ").concat(o, "\n        ").concat(i, "\n        setOutput(result);\n      }\n    ");
  }

}

function shallowSlice$1(e, t, n, r) {
  var a = r.texData.get(e.dataId),
      s = r.makeTensorInfo(n, e.dtype),
      o = r.texData.get(s.dataId);
  Object.assign(o, a), o.refCount = 1, o.shape = n, o.dtype = e.dtype;
  var i = computeFlatOffset$1(t, computeStrides$1(e.shape));
  a.slice && (i += a.slice.flatOffset), o.slice = {
    flatOffset: i,
    origDataId: a.slice && a.slice.origDataId || e.dataId
  };
  var l = r.dataRefCount.get(o.slice.origDataId) || 1;
  return r.dataRefCount.set(o.slice.origDataId, l + 1), s;
}

function slice$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    begin: s,
    size: o
  } = r,
      [i, l] = parseSliceParams$1(a, s, o);
  if (assertParamsValid$1(a, i, l), 0 === sizeFromShape$1(l)) return n.makeTensorInfo(l, a.dtype, []);

  if (n.shouldExecuteOnCPU([a]) || "string" === a.dtype) {
    var _e456 = n.texData.get(a.dataId),
        _t328 = sliceImplCPU$1(_e456.values, i, l, a.shape, a.dtype);

    return n.makeTensorInfo(l, a.dtype, _t328);
  }

  var {
    isPacked: u
  } = n.texData.get(a.dataId),
      c = isSliceContinous$1(a.shape, i, l);

  if (u || !c) {
    var _e457 = env$1().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new SlicePackedProgram$1(l) : new SliceProgram$1(l);

    return n.runWebGLProgram(_e457, [a], a.dtype, [i]);
  }

  return n.uploadToGPU(a.dataId), shallowSlice$1(a, i, l, n);
}

var sliceConfig$2 = {
  kernelName: Slice$1,
  backendName: "webgl",
  kernelFunc: slice$3
},
    batchToSpaceND$3 = e => {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    blockShape: s,
    crops: o
  } = r;
  assert$6(a.shape.length <= 4, () => "batchToSpaceND for rank > 4 with a WebGL backend not implemented yet");
  var i = s.reduce((e, t) => e * t),
      l = getReshaped$1(a.shape, s, i),
      u = getPermuted$1(l.length, s.length),
      c = getReshapedPermuted$1(a.shape, s, i),
      p = getSliceBeginCoords$1(o, s.length),
      d = getSliceSize$1(c, o, s.length),
      h = [],
      m = reshape$4({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      shape: l
    }
  }),
      f = transpose$3({
    inputs: {
      x: m
    },
    backend: n,
    attrs: {
      perm: u
    }
  }),
      g = reshape$4({
    inputs: {
      x: f
    },
    backend: n,
    attrs: {
      shape: c
    }
  }),
      $ = slice$3({
    inputs: {
      x: g
    },
    backend: n,
    attrs: {
      begin: p,
      size: d
    }
  });
  return h.push(m), h.push(f), h.push(g), h.forEach(e => n.disposeIntermediateTensorInfo(e)), $;
},
    batchToSpaceNDConfig$2 = {
  kernelName: BatchToSpaceND$1,
  backendName: "webgl",
  kernelFunc: batchToSpaceND$3
};

function bincount$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    weights: s
  } = t,
      {
    size: o
  } = r,
      i = n.readSync(a.dataId),
      l = n.readSync(s.dataId),
      u = bincountImplCPU$1(i, l, s.dtype, s.shape, o);
  return n.makeTensorInfo([o], s.dtype, u);
}

var bincountConfig$2 = {
  kernelName: Bincount$1,
  backendName: "webgl",
  kernelFunc: bincount$3
},
    NOT_EQUAL$1 = "return float(a != b);",
    notEqual$3 = binaryKernelFunc$2({
  opSnippet: NOT_EQUAL$1,
  cpuKernelImpl: notEqualImplCPU$1,
  dtype: "bool"
}),
    notEqualConfig$2 = {
  kernelName: NotEqual$1,
  backendName: "webgl",
  kernelFunc: notEqual$3
};

function real$3(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    input: r
  } = t;
  return identity$3({
    inputs: {
      x: n.texData.get(r.dataId).complexTensorInfos.real
    },
    backend: n
  });
}

var realConfig$2 = {
  kernelName: Real$1,
  backendName: "webgl",
  kernelFunc: real$3
},
    TO_INT$1 = "return float(int(x));";

function int$1(e, t) {
  var n = new UnaryOpProgram$1(e.shape, TO_INT$1),
      r = t.runWebGLProgram(n, [e], "int32");
  return {
    dataId: r.dataId,
    shape: r.shape,
    dtype: r.dtype
  };
}

function cast$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    dtype: s
  } = r;

  if ("complex64" === s) {
    if ("complex64" === a.dtype) return identity$3({
      inputs: {
        x: a
      },
      backend: n
    });

    var _e458 = zeros$4(a.shape),
        _t329 = cast$4({
      inputs: {
        x: a
      },
      backend: n,
      attrs: {
        dtype: "float32"
      }
    }),
        _r157 = complex$3({
      inputs: {
        real: _t329,
        imag: _e458
      },
      backend: n
    });

    return _e458.dispose(), n.disposeIntermediateTensorInfo(_t329), _r157;
  }

  if ("complex64" === a.dtype) {
    var _e459 = real$3({
      inputs: {
        input: a
      },
      backend: n
    }),
        _t330 = cast$4({
      inputs: {
        x: _e459
      },
      backend: n,
      attrs: {
        dtype: s
      }
    });

    return n.disposeIntermediateTensorInfo(_e459), _t330;
  }

  if (!hasEncodingLoss$1(a.dtype, s)) {
    var _e460 = identity$3({
      inputs: {
        x: a
      },
      backend: n
    });

    return {
      dataId: _e460.dataId,
      shape: _e460.shape,
      dtype: s
    };
  }

  if ("int32" === s) return int$1(a, n);

  if ("bool" === s) {
    var _e461 = n.makeTensorInfo([], "bool", getTypedArrayFromDType$1("bool", 1)),
        _t331 = notEqual$3({
      inputs: {
        a,
        b: _e461
      },
      backend: n
    });

    return n.disposeIntermediateTensorInfo(_e461), _t331;
  }

  throw new Error("Error in Cast: failed to cast ".concat(a.dtype, " to ").concat(s));
}

var castConfig$2 = {
  kernelName: Cast$1,
  backendName: "webgl",
  kernelFunc: cast$4
},
    CEIL$1 = "return ceil(x);",
    ceil$3 = unaryKernelFunc$2({
  opSnippet: CEIL$1,
  packedOpSnippet: CEIL$1,
  cpuKernelImpl: ceilImplCPU$1
}),
    ceilConfig$2 = {
  kernelName: Ceil$1,
  backendName: "webgl",
  kernelFunc: ceil$3
};

class ClipProgram$1 {
  constructor(e) {
    this.variableNames = ["A"], this.customUniforms = [{
      name: "minVal",
      type: "float"
    }, {
      name: "maxVal",
      type: "float"
    }], this.outputShape = e, this.userCode = "\n\n      void main() {\n        float value = getAAtOutCoords();\n        if (isnan(value)) {\n          setOutput(value);\n          return;\n        }\n\n        setOutput(clamp(value, minVal, maxVal));\n      }\n    ";
  }

}

class ClipPackedProgram$1 {
  constructor(e) {
    this.variableNames = ["A"], this.packedInputs = !0, this.packedOutput = !0, this.customUniforms = [{
      name: "minVal",
      type: "float"
    }, {
      name: "maxVal",
      type: "float"
    }], this.outputShape = e, this.userCode = "\n      void main() {\n        vec4 value = getAAtOutCoords();\n\n        if (any(isnan(value))) {\n          setOutput(value);\n          return;\n        }\n\n        setOutput(clamp(value, vec4(minVal), vec4(maxVal)));\n      }\n    ";
  }

}

function clipByValue$2(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    clipValueMin: s,
    clipValueMax: o
  } = r;
  var i;
  return i = env$1().getBool("WEBGL_PACK_CLIP") ? new ClipPackedProgram$1(a.shape) : new ClipProgram$1(a.shape), n.runWebGLProgram(i, [a], a.dtype, [[s], [o]]);
}

var clipByValueConfig$1 = {
  kernelName: ClipByValue$1,
  backendName: "webgl",
  kernelFunc: clipByValue$2
};

class ComplexAbsProgram$1 {
  constructor(e) {
    this.variableNames = ["real", "imag"], this.outputShape = e, this.userCode = "\n      void main() {\n        float re = abs(getRealAtOutCoords());\n        float im = abs(getImagAtOutCoords());\n        float mx = max(re, im);\n\n        // sadly the length function in glsl is not underflow-safe\n        // (at least not on Intel GPUs). So the safe solution is\n        // to ensure underflow-safety in all cases.\n        setOutput(\n          mx == 0.0 ? 0.0 : mx * length(vec2(1, min(re, im)/mx))\n        );\n      }\n    ";
  }

}

function makeComplexComponentTensorInfo$1(e, t) {
  return {
    dataId: t.dataId,
    dtype: t.dtype,
    shape: e.shape
  };
}

function complexAbs$2(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    x: r
  } = t,
      a = n.texData.get(r.dataId),
      s = new ComplexAbsProgram$1(r.shape),
      o = [makeComplexComponentTensorInfo$1(r, a.complexTensorInfos.real), makeComplexComponentTensorInfo$1(r, a.complexTensorInfos.imag)];
  return n.runWebGLProgram(s, o, o[0].dtype);
}

var complexAbsConfig$2 = {
  kernelName: ComplexAbs$1,
  backendName: "webgl",
  kernelFunc: complexAbs$2
};

class ConcatProgram$1 {
  constructor(e) {
    this.outputShape = [], this.outputShape = computeOutShape$4(e, 1), this.variableNames = e.map((e, t) => "T".concat(t));
    var t = new Array(e.length - 1);
    t[0] = e[0][1];

    for (var _n210 = 1; _n210 < t.length; _n210++) {
      t[_n210] = t[_n210 - 1] + e[_n210][1];
    }

    var n = ["if (yC < ".concat(t[0], ") setOutput(getT0(yR, yC));")];

    for (var _e462 = 1; _e462 < t.length; _e462++) {
      n.push("else if (yC < ".concat(t[_e462], ") setOutput(getT").concat(_e462, "(yR, yC-").concat(t[_e462 - 1], "));"));
    }

    n.push("else setOutput(getT".concat(t.length, "(yR, yC-").concat(t[t.length - 1], "));")), this.userCode = "\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int yR = coords.x;\n        int yC = coords.y;\n\n        ".concat(n.join("\n        "), "\n      }\n    ");
  }

}

class ConcatPackedProgram$1 {
  constructor(e, t) {
    this.packedInputs = !0, this.packedOutput = !0, this.outputShape = [], this.outputShape = computeOutShape$4(e, t);
    var n = this.outputShape,
        r = n.length,
        a = getCoordsDataType$1(r),
        s = getChannels$1("coords", r),
        o = ["x", "y", "z", "w", "u", "v"].slice(0, r);
    this.variableNames = e.map((e, t) => "T".concat(t));
    var i = new Array(e.length - 1);
    i[0] = e[0][t];

    for (var _n211 = 1; _n211 < i.length; _n211++) {
      i[_n211] = i[_n211 - 1] + e[_n211][t];
    }

    var l = o[t],
        u = o.slice(-2),
        c = o.join();
    var p = "if (".concat(l, " < ").concat(i[0], ") {\n        return getChannel(\n            getT0(").concat(c, "), vec2(").concat(u.join(), "));\n        }");

    for (var _e463 = 1; _e463 < i.length; _e463++) {
      var _t332 = i[_e463 - 1];
      p += "\n        if (".concat(l, " < ").concat(i[_e463], "  && ").concat(l, " >= ").concat(i[_e463 - 1], ") {\n          return getChannel(\n            getT").concat(_e463, "(").concat(shiftedChannels$1(o, l, _t332), "),\n            vec2(").concat(shiftedChannels$1(u, l, _t332), "));\n        }");
    }

    var d = i[i.length - 1];
    p += "\n        return getChannel(\n          getT".concat(i.length, "(").concat(shiftedChannels$1(o, l, d), "),\n          vec2(").concat(shiftedChannels$1(u, l, d), "));"), this.userCode = "\n      float getValue(".concat(o.map(e => "int " + e), ") {\n        ").concat(p, "\n      }\n\n      void main() {\n        ").concat(a, " coords = getOutputCoords();\n        vec4 result = vec4(getValue(").concat(s, "), 0., 0., 0.);\n\n        ").concat(s[r - 1], " = ").concat(s[r - 1], " + 1;\n        if (").concat(s[r - 1], " < ").concat(n[r - 1], ") {\n          result.g = getValue(").concat(s, ");\n        }\n\n        ").concat(s[r - 2], " = ").concat(s[r - 2], " + 1;\n        if (").concat(s[r - 2], " < ").concat(n[r - 2], ") {\n          result.a = getValue(").concat(s, ");\n        }\n\n        ").concat(s[r - 1], " = ").concat(s[r - 1], " - 1;\n        if (").concat(s[r - 2], " < ").concat(n[r - 2], " &&\n            ").concat(s[r - 1], " < ").concat(n[r - 1], ") {\n          result.b = getValue(").concat(s, ");\n        }\n        setOutput(result);\n      }\n    ");
  }

}

function shiftedChannels$1(e, t, n) {
  var r = e.indexOf(t);
  return e.map((e, t) => t === r ? "".concat(e, " - ").concat(n) : e).join();
}

function imag$3(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    input: r
  } = t;
  return identity$3({
    inputs: {
      x: n.texData.get(r.dataId).complexTensorInfos.imag
    },
    backend: n
  });
}

var imagConfig$2 = {
  kernelName: Imag$1,
  backendName: "webgl",
  kernelFunc: imag$3
};

function concatImpl$2(e, t, n) {
  var r = e[0].dtype;

  if ("complex64" === r) {
    var _r158 = e.map(e => real$3({
      inputs: {
        input: e
      },
      backend: n
    })),
        _a110 = e.map(e => imag$3({
      inputs: {
        input: e
      },
      backend: n
    })),
        _s83 = concatImpl$2(_r158, t, n),
        _o59 = concatImpl$2(_a110, t, n),
        _i39 = complex$3({
      inputs: {
        real: _s83,
        imag: _o59
      },
      backend: n
    });

    return _r158.forEach(e => n.disposeIntermediateTensorInfo(e)), _a110.forEach(e => n.disposeIntermediateTensorInfo(e)), n.disposeIntermediateTensorInfo(_s83), n.disposeIntermediateTensorInfo(_o59), _i39;
  }

  var a = n.shouldExecuteOnCPU(e);

  if ("string" === r && (a = !0), a) {
    var _a111 = e.map(e => {
      var r = sizeFromShape$1(e.shape.slice(t));
      return reshape$4({
        inputs: {
          x: e
        },
        backend: n,
        attrs: {
          shape: [-1, r]
        }
      });
    }),
        _s84 = _a111.map(e => ({
      vals: n.readSync(e.dataId),
      shape: e.shape
    })),
        _o60 = computeOutShape$4(_a111.map(e => e.shape), 1),
        _i40 = concatImplCPU$1(_s84, _o60, r, 1 === _a111[0].shape[0]),
        _l31 = computeOutShape$4(e.map(e => e.shape), t),
        _u27 = n.makeTensorInfo(_l31, r, _i40);

    return _a111.forEach(e => n.disposeIntermediateTensorInfo(e)), _u27;
  }

  if (e.length > env$1().getNumber("WEBGL_MAX_TEXTURES_IN_SHADER")) {
    var _r159 = Math.floor(e.length / 2),
        _a112 = concatImpl$2(e.slice(0, _r159), t, n),
        _s85 = concatImpl$2(e.slice(_r159), t, n),
        _o61 = concatImpl$2([_a112, _s85], t, n);

    return n.disposeIntermediateTensorInfo(_a112), n.disposeIntermediateTensorInfo(_s85), _o61;
  }

  if (env$1().getBool("WEBGL_PACK_ARRAY_OPERATIONS") && e[0].shape.length > 1) {
    var _a113 = new ConcatPackedProgram$1(e.map(e => e.shape), t);

    return n.runWebGLProgram(_a113, e, r);
  }

  var {
    tensors2D: s,
    outShape: o
  } = computeTensors2D$1(e, t, n),
      i = new ConcatProgram$1(s.map(e => e.shape)),
      l = n.runWebGLProgram(i, s, r);
  s.forEach(e => n.disposeIntermediateTensorInfo(e));
  var u = reshape$4({
    inputs: {
      x: l
    },
    attrs: {
      shape: o
    },
    backend: n
  });
  return n.disposeIntermediateTensorInfo(l), u;
}

function computeTensors2D$1(e, t, n) {
  var r = computeOutShape$4(e.map(e => e.shape), t);
  return {
    tensors2D: e.map(e => reshape$4({
      inputs: {
        x: e
      },
      attrs: {
        shape: [-1, sizeFromShape$1(e.shape.slice(t))]
      },
      backend: n
    })),
    outShape: r
  };
}

function concat$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    axis: a
  } = r,
      s = parseAxisParam$1(a, t[0].shape)[0],
      o = computeOutShape$4(t.map(e => e.shape), s);
  if (0 === sizeFromShape$1(o)) return n.makeTensorInfo(o, t[0].dtype, []);
  var i = t.filter(e => sizeFromShape$1(e.shape) > 0);
  return 1 === i.length ? identity$3({
    inputs: {
      x: i[0]
    },
    backend: n
  }) : (assertParamsConsistent$1(i.map(e => e.shape), s), concatImpl$2(i, s, n));
}

var concatConfig$2 = {
  kernelName: Concat$1,
  backendName: "webgl",
  kernelFunc: concat$3
};

class Conv2DProgram$1 {
  constructor(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
    var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;
    this.variableNames = ["x", "W"], this.outputShape = e.outShape;
    var s = e.padInfo.top,
        o = e.padInfo.left,
        i = e.strideHeight,
        l = e.strideWidth,
        u = e.dilationHeight,
        c = e.dilationWidth,
        p = e.filterHeight,
        d = e.filterWidth,
        h = 4 * Math.floor(e.inChannels / 4),
        m = e.inChannels % 4,
        f = "channelsLast" === e.dataFormat,
        g = f ? 1 : 2,
        $ = f ? 2 : 3,
        y = f ? 3 : 1;
    var b = "",
        x = "";
    n && (b = r ? "float activation(float a) {\n          float b = getPreluActivationWeightsAtOutCoords();\n          ".concat(n, "\n        }") : a ? "float activation(float a) {\n          float b = getLeakyreluAlphaAtOutCoords();\n          ".concat(n, "\n        }") : "\n          float activation(float x) {\n            ".concat(n, "\n          }\n        "), x = "result = activation(result);");
    var v = t ? "result += getBiasAtOutCoords();" : "";
    t && this.variableNames.push("bias"), r && this.variableNames.push("preluActivationWeights"), a && this.variableNames.push("leakyreluAlpha"), this.userCode = "\n      ".concat(b, "\n\n      const ivec2 strides = ivec2(").concat(i, ", ").concat(l, ");\n      const ivec2 pads = ivec2(").concat(s, ", ").concat(o, ");\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d2 = coords[").concat(y, "];\n\n        ivec2 xRCCorner =\n            ivec2(coords[").concat(g, "], coords[").concat($, "]) * strides - pads;\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        // Convolve x(?, ?, d1) with w(:, :, d1, d2) to get y(yR, yC, d2).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ").concat(p, "; wR++) {\n          int xR = xRCorner + wR * ").concat(u, ";\n\n          if (xR < 0 || xR >= ").concat(e.inHeight, ") {\n            continue;\n          }\n\n          for (int wC = 0; wC < ").concat(d, "; wC++) {\n            int xC = xCCorner + wC * ").concat(c, ";\n\n            if (xC < 0 || xC >= ").concat(e.inWidth, ") {\n              continue;\n            }\n\n            for (int d1 = 0; d1 < ").concat(h, "; d1 += 4) {\n              vec4 wValues = vec4(\n                getW(wR, wC, d1, d2),\n                getW(wR, wC, d1 + 1, d2),\n                getW(wR, wC, d1 + 2, d2),\n                getW(wR, wC, d1 + 3, d2)\n              );\n\n              if (").concat(f, ") {\n                vec4 xValues = vec4(\n                  getX(batch, xR, xC, d1),\n                  getX(batch, xR, xC, d1 + 1),\n                  getX(batch, xR, xC, d1 + 2),\n                  getX(batch, xR, xC, d1 + 3)\n                );\n                dotProd += dot(xValues, wValues);\n              } else {\n                vec4 xValues = vec4(\n                  getX(batch, d1, xR, xC),\n                  getX(batch, d1 + 1, xR, xC),\n                  getX(batch, d1 + 2, xR, xC),\n                  getX(batch, d1 + 3, xR, xC)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n            }\n\n            if (").concat(1 === m, ") {\n\n              if (").concat(f, ") {\n                dotProd +=\n                    getX(batch, xR, xC, ").concat(h, ") *\n                    getW(wR, wC, ").concat(h, ", d2);\n              } else {\n                dotProd +=\n                    getX(batch, ").concat(h, ", xR, xC) *\n                    getW(wR, wC, ").concat(h, ", d2);\n              }\n\n            } else if (").concat(2 === m, ") {\n              vec2 wValues = vec2(\n                getW(wR, wC, ").concat(h, ", d2),\n                getW(wR, wC, ").concat(h, " + 1, d2)\n              );\n\n              if (").concat(f, ") {\n                vec2 xValues = vec2(\n                  getX(batch, xR, xC, ").concat(h, "),\n                  getX(batch, xR, xC, ").concat(h, " + 1)\n                );\n                dotProd += dot(xValues, wValues);\n              } else {\n                vec2 xValues = vec2(\n                  getX(batch, ").concat(h, ", xR, xC),\n                  getX(batch, ").concat(h, " + 1, xR, xC)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n\n            } else if (").concat(3 === m, ") {\n              vec3 wValues = vec3(\n                getW(wR, wC, ").concat(h, ", d2),\n                getW(wR, wC, ").concat(h, " + 1, d2),\n                getW(wR, wC, ").concat(h, " + 2, d2)\n              );\n\n              if (").concat(f, ") {\n                vec3 xValues = vec3(\n                  getX(batch, xR, xC, ").concat(h, "),\n                  getX(batch, xR, xC, ").concat(h, " + 1),\n                  getX(batch, xR, xC, ").concat(h, " + 2)\n                );\n                dotProd += dot(xValues, wValues);\n              } else {\n                vec3 xValues = vec3(\n                  getX(batch, ").concat(h, ", xR, xC),\n                  getX(batch, ").concat(h, " + 1, xR, xC),\n                  getX(batch, ").concat(h, " + 2, xR, xC)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n\n            }\n          }\n        }\n\n        float result = dotProd;\n        ").concat(v, "\n        ").concat(x, "\n        setOutput(result);\n      }\n    ");
  }

}

class Conv3DProgram$1 {
  constructor(e) {
    this.variableNames = ["x", "W"], this.outputShape = e.outShape;
    var t = e.padInfo.front,
        n = e.padInfo.top,
        r = e.padInfo.left,
        a = e.strideDepth,
        s = e.strideHeight,
        o = e.strideWidth,
        i = e.dilationDepth,
        l = e.dilationHeight,
        u = e.dilationWidth,
        c = e.filterDepth,
        p = e.filterHeight,
        d = e.filterWidth,
        h = 4 * Math.floor(e.inChannels / 4),
        m = e.inChannels % 4;
    this.userCode = "\n      const ivec3 strides = ivec3(".concat(a, ", ").concat(s, ", ").concat(o, ");\n      const ivec3 pads = ivec3(").concat(t, ", ").concat(n, ", ").concat(r, ");\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int d2 = coords.u;\n\n        ivec3 xFRCCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\n        int xFCorner = xFRCCorner.x;\n        int xRCorner = xFRCCorner.y;\n        int xCCorner = xFRCCorner.z;\n\n        // Convolve x(?, ?, ?, d1) with w(:, :, :, d1, d2) to get\n        // y(yF, yR, yC, d2). ? = to be determined. : = across all\n        // values in that axis.\n        float dotProd = 0.0;\n        for (int wF = 0; wF < ").concat(c, "; wF++) {\n          int xF = xFCorner + wF * ").concat(i, ";\n\n          if (xF < 0 || xF >= ").concat(e.inDepth, ") {\n            continue;\n          }\n\n          for (int wR = 0; wR < ").concat(p, "; wR++) {\n            int xR = xRCorner + wR * ").concat(l, ";\n\n            if (xR < 0 || xR >= ").concat(e.inHeight, ") {\n              continue;\n            }\n\n            for (int wC = 0; wC < ").concat(d, "; wC++) {\n              int xC = xCCorner + wC * ").concat(u, ";\n\n              if (xC < 0 || xC >= ").concat(e.inWidth, ") {\n                continue;\n              }\n\n              for (int d1 = 0; d1 < ").concat(h, "; d1 += 4) {\n                vec4 xValues = vec4(\n                  getX(batch, xF, xR, xC, d1),\n                  getX(batch, xF, xR, xC, d1 + 1),\n                  getX(batch, xF, xR, xC, d1 + 2),\n                  getX(batch, xF, xR, xC, d1 + 3)\n                );\n                vec4 wValues = vec4(\n                  getW(wF, wR, wC, d1, d2),\n                  getW(wF, wR, wC, d1 + 1, d2),\n                  getW(wF, wR, wC, d1 + 2, d2),\n                  getW(wF, wR, wC, d1 + 3, d2)\n                );\n\n                dotProd += dot(xValues, wValues);\n              }\n\n              if (").concat(1 === m, ") {\n                dotProd +=\n                  getX(batch, xF, xR, xC, ").concat(h, ") *\n                  getW(wF, wR, wC, ").concat(h, ", d2);\n              } else if (").concat(2 === m, ") {\n                vec2 xValues = vec2(\n                  getX(batch, xF, xR, xC, ").concat(h, "),\n                  getX(batch, xF, xR, xC, ").concat(h, " + 1)\n                );\n                vec2 wValues = vec2(\n                  getW(wF, wR, wC, ").concat(h, ", d2),\n                  getW(wF, wR, wC, ").concat(h, " + 1, d2)\n                );\n                dotProd += dot(xValues, wValues);\n              } else if (").concat(3 === m, ") {\n                vec3 xValues = vec3(\n                  getX(batch, xF, xR, xC, ").concat(h, "),\n                  getX(batch, xF, xR, xC, ").concat(h, " + 1),\n                  getX(batch, xF, xR, xC, ").concat(h, " + 2)\n                );\n                vec3 wValues = vec3(\n                  getW(wF, wR, wC, ").concat(h, ", d2),\n                  getW(wF, wR, wC, ").concat(h, " + 1, d2),\n                  getW(wF, wR, wC, ").concat(h, " + 2, d2)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    ");
  }

}

class Im2ColPackedProgram$1 {
  constructor(e, t, n) {
    this.variableNames = ["A"], this.packedInputs = !0, this.packedOutput = !0, this.outputShape = e;
    var {
      filterWidth: r,
      inChannels: a,
      strideWidth: s,
      strideHeight: o,
      padInfo: i,
      outWidth: l,
      dilationWidth: u,
      dilationHeight: c,
      dataFormat: p
    } = n,
        {
      left: d,
      top: h
    } = i,
        m = a * r,
        f = getGlslDifferences$1(),
        g = "channelsLast" === p,
        $ = g ? 0 : 1,
        y = g ? 1 : 2;
    var b = "";

    for (var _n212 = 0; _n212 <= 1; _n212++) {
      for (var _r160 = 0; _r160 <= 1; _r160++) {
        b += "\n          blockIndex = rc.y + ".concat(_r160, ";\n          pos = rc.x + ").concat(_n212, ";\n\n          if(blockIndex < ").concat(e[1], " && pos < ").concat(e[0], ") {\n            offsetY = int(blockIndex / (").concat(l, ")) * ").concat(o, " - ").concat(h, ";\n            d0 = offsetY + ").concat(c, " * (pos / ").concat(m, ");\n\n            if(d0 < ").concat(t[$], " && d0 >= 0) {\n\n              offsetX = int(mod(float(blockIndex), ").concat(l, ".) * ").concat(s, ". - ").concat(d, ".);\n              d1 = offsetX + ").concat(u, " * (int(mod(float(pos), ").concat(m, ".) / ").concat(a, ".));\n\n              if(d1 < ").concat(t[y], " && d1 >= 0) {\n\n                ch = int(mod(float(pos), ").concat(a, ".));\n\n                if (").concat(g, ") {\n                  innerDims = vec2(d1, ch);\n                  result[").concat(2 * _n212 + _r160, "] = getChannel(\n                    getA(d0, int(innerDims.x),\n                    int(innerDims.y)), innerDims);\n                } else {\n                  innerDims = vec2(d0, d1);\n                  result[").concat(2 * _n212 + _r160, "] = getChannel(\n                    getA(ch, int(innerDims.x),\n                    int(innerDims.y)), innerDims);\n                }\n              }\n            }\n          }\n        ");
      }
    }

    this.userCode = "\n      void main() {\n        ivec2 rc = getOutputCoords();\n\n        vec4 result = vec4(0);\n\n        int blockIndex, pos, offsetY, d0, offsetX, d1, ch;\n        vec2 innerDims;\n\n        ".concat(b, "\n\n        ").concat(f.output, " = result;\n      }\n    ");
  }

}

function conv2dByMatMul$1(_ref20) {
  var {
    x: e,
    filter: t,
    convInfo: n,
    backend: r,
    bias: a = null,
    preluActivationWeights: s = null,
    leakyreluAlpha: o = 0,
    activation: i = null
  } = _ref20;
  var l = e.shape,
      u = r.texData.get(e.dataId),
      c = "channelsLast" === n.dataFormat;
  var p;
  var d = [],
      h = l[2] % 2 != 0 && !!u.isPacked;

  if ((1 != l[0] * l[1] * l[2] && 1 !== n.outChannels || !(n.inChannels > MATMUL_SHARED_DIM_THRESHOLD$1)) && env$1().getBool("WEBGL_LAZILY_UNPACK") && env$1().getBool("WEBGL_PACK_BINARY_OPERATIONS") && h) {
    var _h11 = {
      dataId: e.dataId,
      shape: [1, c ? l[0] * l[1] * (l[2] + 1) : l[0] * l[2] * (l[3] + 1), n.inChannels],
      dtype: e.dtype
    },
        m = u.shape;
    u.shape = u.shape.slice(), u.shape[u.shape.length - 2]++, assert$6(isReshapeFree$1(u.shape, _h11.shape), () => "packed reshape ".concat(u.shape, " to ").concat(_h11.shape, " isn't free"));
    var f = reshape$4({
      inputs: {
        x: t
      },
      backend: r,
      attrs: {
        shape: [1, n.inChannels, n.outChannels]
      }
    });
    d.push(f);
    var g = batchMatMulImpl$1({
      a: _h11,
      b: f,
      backend: r,
      transposeA: !1,
      transposeB: !1,
      bias: a,
      activation: i,
      preluActivationWeights: s,
      leakyreluAlpha: o
    }),
        $ = r.texData.get(g.dataId);
    assert$6($.isPacked, () => "batchMatMul result is expected to be packed"), u.shape = m, $.shape = n.outShape, p = identity$3({
      inputs: {
        x: g
      },
      backend: r
    }), p.shape = n.outShape, d.push(g);
  } else {
    var _u28 = reshape$4({
      inputs: {
        x: e
      },
      backend: r,
      attrs: {
        shape: [1, c ? l[0] * l[1] * l[2] : l[0] * l[2] * l[3], n.inChannels]
      }
    }),
        _h12 = reshape$4({
      inputs: {
        x: t
      },
      backend: r,
      attrs: {
        shape: [1, n.inChannels, n.outChannels]
      }
    }),
        _m5 = batchMatMulImpl$1({
      a: _u28,
      b: _h12,
      transposeA: !1,
      transposeB: !1,
      backend: r,
      bias: a,
      activation: i,
      preluActivationWeights: s,
      leakyreluAlpha: o
    });

    p = reshape$4({
      inputs: {
        x: _m5
      },
      backend: r,
      attrs: {
        shape: n.outShape
      }
    }), d.push(_u28), d.push(_h12), d.push(_m5);
  }

  for (var _e464 of d) {
    r.disposeIntermediateTensorInfo(_e464);
  }

  return p;
}

function conv2dWithIm2Row$1(_ref21) {
  var {
    x: e,
    filter: t,
    convInfo: n,
    backend: r,
    bias: a = null,
    preluActivationWeights: s = null,
    leakyreluAlpha: o = 0,
    activation: i = null
  } = _ref21;
  var {
    filterWidth: l,
    filterHeight: u,
    inChannels: c,
    outWidth: p,
    outHeight: d,
    dataFormat: h
  } = n,
      m = "channelsLast" === h,
      f = l * u * c,
      g = d * p,
      $ = [f, g],
      y = [],
      b = reshape$4({
    inputs: {
      x: e
    },
    backend: r,
    attrs: {
      shape: e.shape.slice(1)
    }
  }),
      x = reshape$4({
    inputs: {
      x: t
    },
    backend: r,
    attrs: {
      shape: [1, f, sizeFromShape$1(t.shape) / f]
    }
  });
  y.push(b), y.push(x);
  var v = new Im2ColPackedProgram$1($, b.shape, n),
      I = r.runWebGLProgram(v, [b], "float32"),
      C = reshape$4({
    inputs: {
      x: I
    },
    backend: r,
    attrs: {
      shape: [1, $[0], $[1]]
    }
  });
  y.push(I), y.push(C);
  var S = null != a,
      k = null != s,
      T = "leakyrelu" === i,
      N = i ? mapActivationToShaderProgram$1(i, !0) : null,
      w = new MatMulPackedProgram$1(C.shape, x.shape, [1, g, n.outChannels], !0, !1, S, N, k, T),
      E = [C, x];

  if (a && E.push(a), k && E.push(s), T) {
    var _e465 = r.makeTensorInfo([], "float32", createScalarValue$1(o, "float32"));

    E.push(_e465), y.push(_e465);
  }

  var A = r.runWebGLProgram(w, E, "float32"),
      D = reshape$4({
    inputs: {
      x: A
    },
    backend: r,
    attrs: {
      shape: m ? [1, d, p, n.outChannels] : [1, n.outChannels, d, p]
    }
  });
  y.push(A);

  for (var _e466 of y) {
    r.disposeIntermediateTensorInfo(_e466);
  }

  return D;
}

function conv2d$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    filter: s
  } = t,
      {
    strides: o,
    pad: i,
    dataFormat: l,
    dilations: u,
    dimRoundingMode: c
  } = r,
      p = convertConv2DDataFormat$1(l),
      d = computeConv2DInfo$1(a.shape, s.shape, o, u, i, c, !1, p);
  var h;
  if (1 !== d.filterHeight || 1 !== d.filterWidth || 1 !== d.dilationHeight || 1 !== d.dilationWidth || 1 !== d.strideHeight || 1 !== d.strideWidth || "SAME" !== d.padInfo.type && "VALID" !== d.padInfo.type) {
    if (env$1().getBool("WEBGL_CONV_IM2COL") && 1 === a.shape[0]) h = conv2dWithIm2Row$1({
      x: a,
      filter: s,
      convInfo: d,
      backend: n
    });else {
      var _e467 = new Conv2DProgram$1(d);

      h = n.runWebGLProgram(_e467, [a, s], "float32");
    }
  } else h = conv2dByMatMul$1({
    x: a,
    filter: s,
    convInfo: d,
    backend: n
  });
  var m = reshape$4({
    inputs: {
      x: h
    },
    backend: n,
    attrs: {
      shape: d.outShape
    }
  });
  return n.disposeIntermediateTensorInfo(h), m;
}

var conv2DConfig$2 = {
  kernelName: Conv2D$3,
  backendName: "webgl",
  kernelFunc: conv2d$4
};

class Conv2DDerFilterProgram$1 {
  constructor(e) {
    this.variableNames = ["x", "dy"], this.outputShape = e.filterShape, this.userCode = "\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int wR = coords.x;\n        int wC = coords.y;\n        int d1 = coords.z;\n        int d2 = coords.w;\n\n        // Convolve x(?, ?, d1) with dy(:, :, d2) to get dw(wR, wC, d1, d2).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n\n        for (int b = 0; b < ".concat(e.batchSize, "; b++) {\n          for (int yR = 0; yR < ").concat(e.outHeight, "; yR++) {\n            int xR = wR + yR * ").concat(e.strideHeight, " - ").concat(e.padInfo.top, ";\n\n            if (xR < 0 || xR >= ").concat(e.inHeight, ") {\n              continue;\n            }\n\n            for (int yC = 0; yC < ").concat(e.outWidth, "; yC++) {\n              int xC = wC + yC * ").concat(e.strideWidth, " - ").concat(e.padInfo.left, ";\n\n              if (xC < 0 || xC >= ").concat(e.inWidth, ") {\n                continue;\n              }\n\n              if (").concat("channelsLast" === e.dataFormat, ") {\n                float dyValue = getDy(b, yR, yC, d2);\n                float xValue = getX(b, xR, xC, d1);\n                dotProd += (xValue * dyValue);\n              } else {\n                float dyValue = getDy(b, d2, yR, yC);\n                float xValue = getX(b, d1, xR, xC);\n                dotProd += (xValue * dyValue);\n              }\n\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    ");
  }

}

class Conv2DDerInputProgram$1 {
  constructor(e) {
    this.variableNames = ["dy", "W"], this.outputShape = e.inShape;
    var t = e.filterHeight,
        n = e.filterWidth,
        r = "channelsLast" === e.dataFormat;
    this.userCode = "\n      const ivec2 pads = ivec2(".concat(t - 1 - e.padInfo.top, ", ").concat(n - 1 - e.padInfo.left, ");\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d1 = coords[").concat(r ? 3 : 1, "];\n\n        ivec2 dyCorner = ivec2(coords[").concat(r ? 1 : 2, "], coords[").concat(r ? 2 : 3, "]) - pads;\n        int dyRCorner = dyCorner.x;\n        int dyCCorner = dyCorner.y;\n\n        // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ").concat(t, "; wR++) {\n          float dyR = float(dyRCorner + wR) / ").concat(e.strideHeight, ".0;\n\n          if (dyR < 0.0 || dyR >= ").concat(e.outHeight, ".0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          int wRPerm = ").concat(t, " - 1 - wR;\n\n          for (int wC = 0; wC < ").concat(n, "; wC++) {\n            float dyC = float(dyCCorner + wC) / ").concat(e.strideWidth, ".0;\n\n            if (dyC < 0.0 || dyC >= ").concat(e.outWidth, ".0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            int wCPerm = ").concat(n, " - 1 - wC;\n\n            for (int d2 = 0; d2 < ").concat(e.outChannels, "; d2++) {\n\n              if (").concat(r, ") {\n                float xValue = getDy(batch, idyR, idyC, d2);\n                float wValue = getW(wRPerm, wCPerm, d1, d2);\n                dotProd += xValue * wValue;\n              } else {\n                float xValue = getDy(batch, d2, idyR, idyC);\n                float wValue = getW(wRPerm, wCPerm, d1, d2);\n                dotProd += xValue * wValue;\n              }\n\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    ");
  }

}

class Conv3DDerFilterProgram$1 {
  constructor(e) {
    this.variableNames = ["x", "dy"], this.outputShape = e.filterShape, this.userCode = "\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int wF = coords.x;\n        int wR = coords.y;\n        int wC = coords.z;\n        int d1 = coords.w;\n        int d2 = coords.u;\n\n        float dotProd = 0.0;\n\n        for (int b = 0; b < ".concat(e.batchSize, "; b++) {\n          for (int yF = 0; yF < ").concat(e.outDepth, "; yF++) {\n            int xF = wF + yF * ").concat(e.strideDepth, " - ").concat(e.padInfo.front, ";\n\n            if (xF < 0 || xF >= ").concat(e.inDepth, ") {\n              continue;\n            }\n\n            for (int yR = 0; yR < ").concat(e.outHeight, "; yR++) {\n              int xR = wR + yR * ").concat(e.strideHeight, " - ").concat(e.padInfo.top, ";\n\n              if (xR < 0 || xR >= ").concat(e.inHeight, ") {\n                continue;\n              }\n\n              for (int yC = 0; yC < ").concat(e.outWidth, "; yC++) {\n                int xC = wC + yC * ").concat(e.strideWidth, " - ").concat(e.padInfo.left, ";\n\n                if (xC < 0 || xC >= ").concat(e.inWidth, ") {\n                  continue;\n                }\n\n                float dyValue = getDy(b, yF, yR, yC, d2);\n                float xValue = getX(b, xF, xR, xC, d1);\n                dotProd += (xValue * dyValue);\n              }\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    ");
  }

}

class Conv3DDerInputProgram$1 {
  constructor(e) {
    this.variableNames = ["dy", "W"], this.outputShape = e.inShape;
    var t = e.filterDepth,
        n = e.filterHeight,
        r = e.filterWidth;
    this.userCode = "\n      const ivec3 pads = ivec3(".concat(t - 1 - e.padInfo.front, ", ").concat(n - 1 - e.padInfo.top, ", ").concat(r - 1 - e.padInfo.left, ");\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int d1 = coords.u;\n\n\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\n        int dyFCorner = dyCorner.x;\n        int dyRCorner = dyCorner.y;\n        int dyCCorner = dyCorner.z;\n\n        float dotProd = 0.0;\n        for (int wF = 0; wF < ").concat(t, "; wF++) {\n          float dyF = float(dyFCorner + wF) / ").concat(e.strideDepth, ".0;\n\n          if (dyF < 0.0 || dyF >= ").concat(e.outDepth, ".0 || fract(dyF) > 0.0) {\n            continue;\n          }\n          int idyF = int(dyF);\n\n          int wFPerm = ").concat(t, " - 1 - wF;\n\n          for (int wR = 0; wR < ").concat(n, "; wR++) {\n            float dyR = float(dyRCorner + wR) / ").concat(e.strideHeight, ".0;\n\n            if (dyR < 0.0 || dyR >= ").concat(e.outHeight, ".0 ||\n              fract(dyR) > 0.0) {\n              continue;\n            }\n            int idyR = int(dyR);\n\n            int wRPerm = ").concat(n, " - 1 - wR;\n\n            for (int wC = 0; wC < ").concat(r, "; wC++) {\n              float dyC = float(dyCCorner + wC) / ").concat(e.strideWidth, ".0;\n\n              if (dyC < 0.0 || dyC >= ").concat(e.outWidth, ".0 ||\n                  fract(dyC) > 0.0) {\n                continue;\n              }\n              int idyC = int(dyC);\n\n              int wCPerm = ").concat(r, " - 1 - wC;\n\n              for (int d2 = 0; d2 < ").concat(e.outChannels, "; d2++) {\n                float xValue = getDy(batch, idyF, idyR, idyC, d2);\n                float wValue = getW(wFPerm, wRPerm, wCPerm, d1, d2);\n                dotProd += xValue * wValue;\n              }\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    ");
  }

}

function conv2DBackpropFilter$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    dy: s
  } = t,
      {
    strides: o,
    pad: i,
    dataFormat: l,
    dimRoundingMode: u,
    filterShape: c
  } = r,
      p = convertConv2DDataFormat$1(l),
      d = computeConv2DInfo$1(a.shape, c, o, 1, i, u, !1, p),
      h = new Conv2DDerFilterProgram$1(d);
  return n.runWebGLProgram(h, [a, s], "float32");
}

var conv2DBackpropFilterConfig$2 = {
  kernelName: Conv2DBackpropFilter$1,
  backendName: "webgl",
  kernelFunc: conv2DBackpropFilter$3
};

function conv2DBackpropInput$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    dy: a,
    filter: s
  } = t,
      {
    inputShape: o,
    strides: i,
    pad: l,
    dataFormat: u,
    dimRoundingMode: c
  } = r,
      p = convertConv2DDataFormat$1(u),
      d = computeConv2DInfo$1(o, s.shape, i, 1, l, c, !1, p),
      h = new Conv2DDerInputProgram$1(d);
  return n.runWebGLProgram(h, [a, s], "float32");
}

var conv2DBackpropInputConfig$2 = {
  kernelName: Conv2DBackpropInput$1,
  backendName: "webgl",
  kernelFunc: conv2DBackpropInput$3
};

function conv3D$2(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    filter: s
  } = t,
      {
    strides: o,
    pad: i,
    dilations: l
  } = r,
      u = computeConv3DInfo$1(a.shape, s.shape, o, l, i),
      c = new Conv3DProgram$1(u);
  return n.runWebGLProgram(c, [a, s], "float32");
}

var conv3DConfig$2 = {
  kernelName: Conv3D$3,
  backendName: "webgl",
  kernelFunc: conv3D$2
};

function conv3DBackpropFilterV2$2(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    dy: s
  } = t,
      {
    strides: o,
    pad: i,
    filterShape: l
  } = r,
      u = computeConv3DInfo$1(a.shape, l, o, 1, i),
      c = new Conv3DDerFilterProgram$1(u);
  return n.runWebGLProgram(c, [a, s], "float32");
}

var conv3DBackpropFilterV2Config$2 = {
  kernelName: Conv3DBackpropFilterV2$1,
  backendName: "webgl",
  kernelFunc: conv3DBackpropFilterV2$2
};

function conv3DBackpropInput$2(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    dy: a,
    filter: s
  } = t,
      {
    pad: o,
    strides: i,
    inputShape: l
  } = r,
      u = computeConv3DInfo$1(l, s.shape, i, 1, o),
      c = new Conv3DDerInputProgram$1(u);
  return n.runWebGLProgram(c, [a, s], "float32");
}

var conv3DBackpropInputConfig$1 = {
  kernelName: Conv3DBackpropInputV2$1,
  backendName: "webgl",
  kernelFunc: conv3DBackpropInput$2
},
    COS$1 = CHECK_NAN_SNIPPET_UNARY$1 + "\n  return cos(x);\n",
    cos$3 = unaryKernelFunc$2({
  opSnippet: COS$1
}),
    cosConfig$2 = {
  kernelName: Cos$1,
  backendName: "webgl",
  kernelFunc: cos$3
},
    COSH$1 = "\n  float e2x = exp(-x);\n  return (e2x + 1.0 / e2x) / 2.0;\n",
    cosh$3 = unaryKernelFunc$2({
  opSnippet: COSH$1
}),
    coshConfig$2 = {
  kernelName: Cosh$1,
  backendName: "webgl",
  kernelFunc: cosh$3
};

class CropAndResizeProgram$1 {
  constructor(e, t, n, r, a) {
    this.variableNames = ["Image", "Boxes", "BoxInd"], this.outputShape = [];
    var [s, o, i, l] = e,
        [u] = t,
        [c, p] = n;
    this.outputShape = [u, c, p, l];
    var d = "bilinear" === r ? 1 : 0,
        [h, m] = [o - 1 + ".0", i - 1 + ".0"],
        [f, g, $] = c > 1 ? ["" + (o - 1) / (c - 1), "(y2-y1) * height_ratio", "y1*".concat(h, " + float(y)*(height_scale)")] : ["0.0", "0.0", "0.5 * (y1+y2) * ".concat(h)],
        [y, b, x] = p > 1 ? ["" + (i - 1) / (p - 1), "(x2-x1) * width_ratio", "x1*".concat(m, " + float(x)*(width_scale)")] : ["0.0", "0.0", "0.5 * (x1+x2) * ".concat(m)];
    this.userCode = "\n      const float height_ratio = float(".concat(f, ");\n      const float width_ratio = float(").concat(y, ");\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int y = coords[1];\n        int x = coords[2];\n        int d = coords[3];\n\n        // get box vals\n        float y1 = getBoxes(b,0);\n        float x1 = getBoxes(b,1);\n        float y2 = getBoxes(b,2);\n        float x2 = getBoxes(b,3);\n\n        // get image in batch index\n        int bInd = round(getBoxInd(b));\n        if(bInd < 0 || bInd >= ").concat(s, ") {\n          return;\n        }\n\n        float height_scale = ").concat(g, ";\n        float width_scale = ").concat(b, ";\n\n        float in_y = ").concat($, ";\n        if( in_y < 0.0 || in_y > ").concat(h, " ) {\n          setOutput(float(").concat(a, "));\n          return;\n        }\n        float in_x = ").concat(x, ";\n        if( in_x < 0.0 || in_x > ").concat(m, " ) {\n          setOutput(float(").concat(a, "));\n          return;\n        }\n\n        vec2 sourceFracIndexCR = vec2(in_x,in_y);\n        if(").concat(d, " == 1) {\n          // Compute the four integer indices.\n          ivec2 sourceFloorCR = ivec2(sourceFracIndexCR);\n          ivec2 sourceCeilCR = ivec2(ceil(sourceFracIndexCR));\n\n          float topLeft = getImage(b, sourceFloorCR.y, sourceFloorCR.x, d);\n          float bottomLeft = getImage(b, sourceCeilCR.y, sourceFloorCR.x, d);\n          float topRight = getImage(b, sourceFloorCR.y, sourceCeilCR.x, d);\n          float bottomRight = getImage(b, sourceCeilCR.y, sourceCeilCR.x, d);\n\n          vec2 fracCR = sourceFracIndexCR - vec2(sourceFloorCR);\n\n          float top = topLeft + (topRight - topLeft) * fracCR.x;\n          float bottom = bottomLeft + (bottomRight - bottomLeft) * fracCR.x;\n          float newValue = top + (bottom - top) * fracCR.y;\n          setOutput(newValue);\n        } else {\n          // Compute the coordinators of nearest neighbor point.\n          ivec2 sourceNearestCR = ivec2(floor(\n            sourceFracIndexCR + vec2(0.5,0.5)));\n          float newValue = getImage(b, sourceNearestCR.y, sourceNearestCR.x, d);\n          setOutput(newValue);\n        }\n      }\n    ");
  }

}

var cropAndResize$3 = e => {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    image: a,
    boxes: s,
    boxInd: o
  } = t,
      {
    cropSize: i,
    method: l,
    extrapolationValue: u
  } = r,
      c = new CropAndResizeProgram$1(a.shape, s.shape, i, l, u);
  return n.runWebGLProgram(c, [a, s, o], "float32");
},
    cropAndResizeConfig$2 = {
  kernelName: CropAndResize$1,
  backendName: "webgl",
  kernelFunc: cropAndResize$3
};

class CumSumProgram$1 {
  constructor(e, t, n) {
    this.variableNames = ["x"], this.customUniforms = [{
      name: "index",
      type: "float"
    }], this.outputShape = e;
    var r = e.length,
        a = t ? "0.0" : "getX(".concat(getCoords$2(r, "coords"), ")"),
        s = e[e.length - 1];
    var o = "",
        i = "";
    t ? (o = n ? "end != " + (s - 1) : "end != 0", i = n ? "end + 1" : "end - 1") : (o = n ? "end + pow2 < ".concat(s) : "end >= pow2", i = n ? "end + pow2" : "end - pow2"), this.userCode = "\n      void main() {\n        ".concat(getCoordsDataType$1(r), " coords = getOutputCoords();\n        int end = ").concat(getFinalCoord$1(r, "coords"), ";\n        float val = ").concat(a, ";\n        int pow2 = int(pow(2.0, index));\n        if (").concat(o, ") {\n          int idx = ").concat(i, ";\n          ").concat(getFinalCoord$1(r, "coords"), " = idx;\n          val += getX(").concat(getCoords$2(r, "coords"), ");\n        }\n        setOutput(val);\n      }\n    ");
  }

}

function getCoords$2(e, t) {
  if (1 === e) return "".concat(t);
  if (2 === e) return "".concat(t, ".x, ").concat(t, ".y");
  if (3 === e) return "".concat(t, ".x, ").concat(t, ".y, ").concat(t, ".z");
  if (4 === e) return "".concat(t, ".x, ").concat(t, ".y, ").concat(t, ".z, ").concat(t, ".w");
  throw Error("Cumulative sum for rank ".concat(e, " is not yet supported"));
}

function getFinalCoord$1(e, t) {
  if (1 === e) return "".concat(t);
  if (2 === e) return "".concat(t, ".y");
  if (3 === e) return "".concat(t, ".z");
  if (4 === e) return "".concat(t, ".w");
  throw Error("Cumulative sum for rank ".concat(e, " is not yet supported"));
}

function cumsum$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    axis: s,
    exclusive: o,
    reverse: i
  } = r,
      l = a.shape.length,
      u = getAxesPermutation$1([s], l);
  var c = a;
  null != u && (c = transpose$3({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      perm: u
    }
  }));
  var p = getInnerMostAxes$1(1, l)[0];
  if (p !== l - 1) throw new Error("WebGL cumsum shader expects an inner-most axis=".concat(a.shape.length - 1, " but got axis=").concat(s));
  var d = c.shape[p];
  var h = identity$3({
    inputs: {
      x: c
    },
    backend: n
  });

  for (var _e468 = 0; _e468 <= Math.ceil(Math.log2(d)) - 1; _e468++) {
    var _t333 = new CumSumProgram$1(c.shape, !1, i),
        _r161 = h;

    h = n.runWebGLProgram(_t333, [h], h.dtype, [[_e468]]), n.disposeIntermediateTensorInfo(_r161);
  }

  if (o) {
    var _e469 = new CumSumProgram$1(c.shape, o, i),
        _t334 = h;

    h = n.runWebGLProgram(_e469, [h], h.dtype), n.disposeIntermediateTensorInfo(_t334);
  }

  if (null != u) {
    var _e470 = transpose$3({
      inputs: {
        x: h
      },
      backend: n,
      attrs: {
        perm: getUndoAxesPermutation$1(u)
      }
    });

    return n.disposeIntermediateTensorInfo(h), n.disposeIntermediateTensorInfo(c), _e470;
  }

  return h;
}

var cumsumConfig$2 = {
  kernelName: Cumsum$1,
  backendName: "webgl",
  kernelFunc: cumsum$3
};

function denseBincount$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    weights: s
  } = t,
      {
    size: o,
    binaryOutput: i
  } = r;

  if (1 === a.shape.length) {
    var _e471 = n.readSync(a.dataId),
        _t335 = n.readSync(s.dataId),
        _r162 = bincountImplCPU$1(_e471, _t335, s.dtype, s.shape, o);

    return n.makeTensorInfo([o], s.dtype, _r162);
  }

  if (2 === a.shape.length) {
    var _e472 = n.bufferSync(a),
        _t336 = n.bufferSync(s),
        _r163 = bincountReduceImplCPU$1(_e472, _t336, o, i);

    return n.makeTensorInfo(_r163.shape, s.dtype, _r163.values);
  }

  throw new Error("Error in denseBincount: input must be at most rank 2, but got rank".concat(a.shape.length, "."));
}

var denseBincountConfig$2 = {
  kernelName: DenseBincount$1,
  backendName: "webgl",
  kernelFunc: denseBincount$3
};

class DepthToSpaceProgram$1 {
  constructor(e, t, n) {
    this.variableNames = ["x"], this.outputShape = [], this.outputShape = e, this.blockSize = t, this.dataFormat = n, this.userCode = "\n    void main() {\n      ivec4 coords = getOutputCoords();\n      int b = coords[0];\n      int h = ".concat(this.getHeightCoordString(), ";\n      int w = ").concat(this.getWidthCoordString(), ";\n      int d = ").concat(this.getDepthCoordString(), ";\n\n      int in_h = h / ").concat(t, ";\n      int offset_h = imod(h, ").concat(t, ");\n      int in_w = w / ").concat(t, ";\n      int offset_w = imod(w, ").concat(t, ");\n      int offset_d = (offset_h * ").concat(t, " + offset_w) *\n        ").concat(this.getOutputDepthSize(), ";\n      int in_d = d + offset_d;\n\n      float result = ").concat(this.getInputSamplingString(), ";\n      setOutput(result);\n    }\n  ");
  }

  getHeightCoordString() {
    return "NHWC" === this.dataFormat ? "coords[1]" : "coords[2]";
  }

  getWidthCoordString() {
    return "NHWC" === this.dataFormat ? "coords[2]" : "coords[3]";
  }

  getDepthCoordString() {
    return "NHWC" === this.dataFormat ? "coords[3]" : "coords[1]";
  }

  getOutputDepthSize() {
    return "NHWC" === this.dataFormat ? this.outputShape[3] : this.outputShape[1];
  }

  getInputSamplingString() {
    return "NHWC" === this.dataFormat ? "getX(b, in_h, in_w, in_d)" : "getX(b, in_d, in_h, in_w)";
  }

}

function depthToSpace$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    blockSize: s,
    dataFormat: o
  } = r;
  assert$6(s > 1, () => "blockSize should be > 1 for depthToSpace, but was: ".concat(s));
  var i = a.shape[0],
      l = ("NHWC" === o ? a.shape[1] : a.shape[2]) * s,
      u = ("NHWC" === o ? a.shape[2] : a.shape[3]) * s,
      c = ("NHWC" === o ? a.shape[3] : a.shape[1]) / (s * s),
      p = new DepthToSpaceProgram$1("NHWC" === o ? [i, l, u, c] : [i, c, l, u], s, o);
  return n.runWebGLProgram(p, [a], a.dtype);
}

var depthToSpaceConfig$2 = {
  kernelName: DepthToSpace$1,
  backendName: "webgl",
  kernelFunc: depthToSpace$3
};

class DepthwiseConv2DProgram$1 {
  constructor(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
    var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;
    this.variableNames = ["x", "W"], this.outputShape = e.outShape;
    var s = e.inHeight,
        o = e.inWidth,
        i = e.padInfo.top,
        l = e.padInfo.left,
        u = e.strideHeight,
        c = e.strideWidth,
        p = e.dilationHeight,
        d = e.dilationWidth,
        h = e.filterHeight,
        m = e.filterWidth,
        f = e.outChannels / e.inChannels;
    var g = "",
        $ = "";
    n && (g = r ? "float activation(float a) {\n          float b = getPreluActivationWeightsAtOutCoords();\n          ".concat(n, "\n        }") : a ? "float activation(float a) {\n          float b = getLeakyreluAlphaAtOutCoords();\n          ".concat(n, "\n        }") : "\n          float activation(float x) {\n            ".concat(n, "\n          }\n        "), $ = "result = activation(result);");
    var y = t ? "result += getBiasAtOutCoords();" : "";
    t && this.variableNames.push("bias"), r && this.variableNames.push("preluActivationWeights"), a && this.variableNames.push("leakyreluAlpha"), this.userCode = "\n      ".concat(g, "\n\n      const ivec2 strides = ivec2(").concat(u, ", ").concat(c, ");\n      const ivec2 pads = ivec2(").concat(i, ", ").concat(l, ");\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords.x;\n        ivec2 xRCCorner = coords.yz * strides - pads;\n        int d2 = coords.w;\n        int d1 = d2 / ").concat(f, ";\n        int q = d2 - d1 * ").concat(f, ";\n\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        // Convolve x(?, ?, d1) with w(:, :, d1, q) to get y(yR, yC, d2).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        // TO DO(dsmilkov): Flatten the two for loops and vec4 the operations.\n        for (int wR = 0; wR < ").concat(h, "; wR++) {\n          int xR = xRCorner + wR * ").concat(p, ";\n\n          if (xR < 0 || xR >= ").concat(s, ") {\n            continue;\n          }\n\n          for (int wC = 0; wC < ").concat(m, "; wC++) {\n            int xC = xCCorner + wC * ").concat(d, ";\n\n            if (xC < 0 || xC >= ").concat(o, ") {\n              continue;\n            }\n\n            float xVal = getX(batch, xR, xC, d1);\n            float wVal = getW(wR, wC, d1, q);\n            dotProd += xVal * wVal;\n          }\n        }\n\n        float result = dotProd;\n        ").concat(y, "\n        ").concat($, "\n        setOutput(result);\n      }\n    ");
  }

}

class DepthwiseConvPacked2DProgram$1 {
  constructor(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
    var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;
    this.variableNames = ["x", "W"], this.packedInputs = !0, this.packedOutput = !0, this.outputShape = e.outShape;
    var s = e.outChannels / e.inChannels,
        o = e.inHeight,
        i = e.inWidth,
        l = e.padInfo.top,
        u = e.padInfo.left,
        c = e.strideHeight,
        p = e.strideWidth,
        d = e.dilationHeight,
        h = e.dilationWidth,
        m = e.filterHeight,
        f = e.filterWidth,
        g = f;
    var $ = "\n      int xR; int xC; int xCOffset;\n      vec4 wTexel; vec4 previous; vec4 final;";

    for (var _e473 = 0; _e473 < f; _e473++) {
      $ += "\n          vec4 xTexelC".concat(2 * _e473, ";\n          int xTexelC").concat(2 * _e473, "Ready;\n          vec4 xTexelC").concat(2 * _e473 + 1, ";\n          int xTexelC").concat(2 * _e473 + 1, "Ready;\n          vec4 xC").concat(_e473, ";");
    }

    for (var _e474 = 0; _e474 < m; _e474++) {
      for (var _e475 = 0; _e475 < f; _e475++) {
        $ += "\n          xTexelC".concat(2 * _e475, " = vec4(0.0);\n          xTexelC").concat(2 * _e475, "Ready = 0;\n          xTexelC").concat(2 * _e475 + 1, " = vec4(0.0);\n          xTexelC").concat(2 * _e475 + 1, "Ready = 0;\n          xC").concat(_e475, " = vec4(0.0);");
      }

      $ += "\n        xR = xRCorner + ".concat(_e474 * d, ";\n        if (xR >=0 && xR < ").concat(o, ") {\n      ");

      for (var _t337 = 0; _t337 < (g + 1) / 2; _t337++) {
        var _n213 = 2 * _t337,
            _r164 = _n213 * h;

        if ($ += "\n          xC = xCCorner + ".concat(_r164, ";\n          "), 1 === p) {
          if (_n213 < f && (u % 2 == 1 ? ($ += "\n                xCOffset = xC + 1;\n                if (xCOffset >= 0 && xCOffset < ".concat(i, " && xTexelC").concat(_n213, "Ready == 0) {\n                  xTexelC").concat(_n213, " = getX(batch, xR, xCOffset, d1);\n\n                  // Need to manually clear unused channels in case\n                  // we're reading from recycled texture.\n                  if (xCOffset + 1 >= ").concat(i, ") {\n                    xTexelC").concat(_n213, ".zw = vec2(0.0);\n                  }\n                  xTexelC").concat(_n213, "Ready = 1;\n                }\n              "), $ += 1 === h && _r164 > 0 ? "\n                xC".concat(_n213, " = vec4(xTexelC").concat(_n213 - 2, ".zw, xTexelC").concat(_n213, ".xy);\n                ") : "\n                  xCOffset = xC + 1 - 2;\n\n                  if (xCOffset >= 0 && xCOffset < ".concat(i, ") {\n                    previous = getX(batch, xR, xCOffset, d1);\n\n                    // Need to manually clear unused channels in case\n                    // we're reading from recycled texture.\n                    if (xCOffset + 1 >= ").concat(i, ") {\n                      previous.zw = vec2(0.0);\n                    }\n\n                    xC").concat(_n213, " = vec4(previous.zw, xTexelC").concat(_n213, ".xy);\n                  } else {\n                    xC").concat(_n213, " = vec4(0.0, 0.0, xTexelC").concat(_n213, ".xy);\n                  }\n                  ")) : $ += "\n                if (xC >= 0 && xC < ".concat(i, " && xTexelC").concat(_n213, "Ready == 0) {\n                  xTexelC").concat(_n213, " = getX(batch, xR, xC, d1);\n                  if (xC + 1 >= ").concat(i, ") {\n                    xTexelC").concat(_n213, ".zw = vec2(0.0);\n                  }\n                  xTexelC").concat(_n213, "Ready = 1;\n                }\n\n                xC").concat(_n213, " = xTexelC").concat(_n213, ";\n                "), _r164 + 1 < f)) {
            var _e476 = u % 2 == 0 ? nearestLargerEven$1(h) : h;

            h % 2 == 0 && u % 2 == 1 || h % 2 != 0 && u % 2 != 1 ? ($ += "\n                  xCOffset = xC + ".concat(u % 2, " + ").concat(_e476, ";\n\n                  if (xCOffset >= 0 && xCOffset < ").concat(i, " && xTexelC").concat(_n213 + 1, "Ready == 0) {\n                    xTexelC").concat(_n213 + 1, " = getX(batch, xR, xCOffset, d1);\n\n                    // Need to manually clear unused channels in case\n                    // we're reading from recycled texture.\n                    if (xCOffset + 1 >= ").concat(i, ") {\n                      xTexelC").concat(_n213 + 1, ".zw = vec2(0.0);\n                    }\n                    xTexelC").concat(_n213 + 1, "Ready = 1;\n                  }\n                  "), h > 1 && ($ += "\n                    xCOffset -= 2;\n                    if (xCOffset >= 0 && xCOffset < ".concat(i, " && xTexelC").concat(_n213, "Ready == 0) {\n                      xTexelC").concat(_n213, " = getX(batch, xR, xCOffset, d1);\n                      xTexelC").concat(_n213, "Ready = 1;\n                    }\n                    ")), $ += "\n                  xC".concat(_n213 + 1, " = vec4(xTexelC").concat(_n213, ".zw, xTexelC").concat(_n213 + 1, ".xy);\n                  ")) : $ += 1 === _e476 ? "\n                    xC".concat(_n213 + 1, " = xTexelC").concat(_n213, ";\n                    ") : "\n                    xCOffset = xC + ".concat(_e476, ";\n\n                    if (xCOffset >= 0 && xCOffset < ").concat(i, " && xTexelC").concat(_n213 + 1, "Ready == 0) {\n                      xTexelC").concat(_n213 + 1, " = getX(batch, xR, xCOffset, d1);\n                      if (xCOffset + 1 >= ").concat(i, ") {\n                        xTexelC").concat(_n213 + 1, ".zw = vec2(0.0);\n                      }\n                      xTexelC").concat(_n213 + 1, "Ready = 1;\n                    }\n\n                    xC").concat(_n213 + 1, " = xTexelC").concat(_n213 + 1, ";\n                    ");
          }
        } else _r164 < f && (u % 2 == 1 ? ($ += "\n                xCOffset = xC + 1 - ".concat(p, ";\n                if(xCOffset >= 0 && xCOffset < ").concat(i, " && xTexelC").concat(_n213, "Ready == 0) {\n                  xTexelC").concat(_n213, " = getX(batch, xR, xCOffset, d1);\n                  // Need to manually clear unused channels in case\n                  // we're reading from recycled texture.\n                  if (xCOffset + 1 >= ").concat(i, ") {\n                    xTexelC").concat(_n213, ".zw = vec2(0.0);\n                  }\n                  xTexelC").concat(_n213, "Ready = 1;\n                }\n\n                if(xC + 1 >= 0 && xC + 1 < ").concat(i, " && xTexelC").concat(_n213 + 1, "Ready == 0) {\n                  xTexelC").concat(_n213 + 1, " = getX(batch, xR, xC + 1, d1);\n                  // Need to manually clear unused channels in case\n                  // we're reading from recycled texture.\n                  if (xC + 2 >= ").concat(i, ") {\n                    xTexelC").concat(_n213 + 1, ".zw = vec2(0.0);\n                  }\n                  xTexelC").concat(_n213 + 1, "Ready = 1;\n                }\n\n                xC").concat(_n213, " = vec4(xTexelC").concat(_n213, ".zw, xTexelC").concat(_n213 + 1, ".zw);\n              "), _r164 + 1 < f && ($ += "\n                  final = vec4(0.0);\n                  xCOffset = xC + 1 + ".concat(p, ";\n                  if(xCOffset >= 0 && xCOffset < ").concat(i, ") {\n                    final = getX(batch, xR, xCOffset, d1);\n                  }\n                  xC").concat(_n213 + 1, " = vec4(xTexelC").concat(_n213 + 1, ".xy, final.xy);\n                "))) : ($ += "\n                if(xC >= 0 && xC < ".concat(i, " && xTexelC").concat(_n213, "Ready == 0) {\n                  xTexelC").concat(_n213, " = getX(batch, xR, xC, d1);\n                  if (xC + 1 >= ").concat(i, ") {\n                    xTexelC").concat(_n213, ".zw = vec2(0.0);\n                  }\n                  xTexelC").concat(_n213, "Ready = 1;\n                }\n\n                xCOffset = xC + ").concat(p, ";\n                if(xCOffset >= 0 && xCOffset < ").concat(i, " && xTexelC").concat(_n213 + 1, "Ready == 0) {\n                  xTexelC").concat(_n213 + 1, " = getX(batch, xR, xCOffset, d1);\n                  if (xCOffset + 1 >= ").concat(i, ") {\n                    xTexelC").concat(_n213 + 1, ".zw = vec2(0.);\n                  }\n                  xTexelC").concat(_n213 + 1, "Ready = 1;\n                }\n\n                xC").concat(_n213, " = vec4(\n                  xTexelC").concat(_n213, ".xy, xTexelC").concat(_n213 + 1, ".xy);\n              "), _r164 + 1 < f && ($ += "\n                  xC".concat(_n213 + 1, " = vec4(xTexelC").concat(_n213, ".zw, xTexelC").concat(_n213 + 1, ".zw);\n                "))));

        _n213 < f && ($ += "\n            wTexel = getW(".concat(_e474, ", ").concat(_r164, ", d1, q);\n            dotProd += xC").concat(_n213, " * vec4(wTexel.xz, wTexel.xz);\n          "), _r164 + 1 < f && ($ += "\n              wTexel = getW(".concat(_e474, ", ").concat(_r164 + 1, ", d1, q);\n              dotProd += xC").concat(_n213 + 1, " * vec4(wTexel.xz, wTexel.xz);\n            ")));
      }

      $ += "\n        }\n      ";
    }

    var y = "",
        b = "";
    n && (y = r ? "vec4 activation(vec4 a) {\n          vec4 b = getPreluActivationWeightsAtOutCoords();\n          ".concat(n, "\n        }") : a ? "vec4 activation(vec4 a) {\n          vec4 b = getLeakyreluAlphaAtOutCoords();\n          ".concat(n, "\n        }") : "vec4 activation(vec4 x) {\n          ".concat(n, "\n        }"), b = "result = activation(result);");
    var x = t ? "result += getBiasAtOutCoords();" : "";
    t && this.variableNames.push("bias"), r && this.variableNames.push("preluActivationWeights"), a && this.variableNames.push("leakyreluAlpha"), this.userCode = "\n      ".concat(y, "\n\n      const ivec2 strides = ivec2(").concat(c, ", ").concat(p, ");\n      const ivec2 pads = ivec2(").concat(l, ", ").concat(u, ");\n\n      void main() {\n\n        ivec4 coords = getOutputCoords();\n        int batch = coords.x;\n        ivec2 xRCCorner = coords.yz * strides - pads;\n        int d2 = coords.w;\n        int d1 = d2 / ").concat(s, ";\n        int q = d2 - d1 * ").concat(s, ";\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        //intialize dotProd with a small epsilon seems to reduce GPU accuracy loss.\n        vec4 dotProd = vec4(0.000000000000001);\n\n        ").concat($, "\n\n        vec4 result = dotProd - vec4(0.000000000000001);\n        ").concat(x, "\n        ").concat(b, "\n        setOutput(result);\n      }\n    ");
  }

}

function depthwiseConv2dNative$2(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    filter: s
  } = t,
      {
    strides: o,
    pad: i,
    dilations: l,
    dimRoundingMode: u
  } = r;
  var c = l;
  null == c && (c = [1, 1]), assert$6(eitherStridesOrDilationsAreOne$1(o, c), () => "Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ".concat(o, " and dilations '").concat(c, "'"));
  var p = computeConv2DInfo$1(a.shape, s.shape, o, c, i, u, !0);
  var d;
  return d = env$1().getBool("WEBGL_PACK_DEPTHWISECONV") && p.strideWidth <= 2 && p.outChannels / p.inChannels == 1 ? new DepthwiseConvPacked2DProgram$1(p) : new DepthwiseConv2DProgram$1(p), n.runWebGLProgram(d, [a, s], "float32");
}

var depthwiseConv2dNativeConfig$2 = {
  kernelName: DepthwiseConv2dNative$1,
  backendName: "webgl",
  kernelFunc: depthwiseConv2dNative$2
};

class DepthwiseConv2DDerFilterProgram$1 {
  constructor(e) {
    this.variableNames = ["x", "dy"], this.outputShape = e.filterShape, this.userCode = "\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int wR = coords.x;\n        int wC = coords.y;\n        int d1 = coords.z;\n        int dm = coords.w;\n        int d2 = d1 * ".concat(e.outChannels / e.inChannels, " + dm;\n\n        float dotProd = 0.0;\n\n        // TO DO: Vec4 over the batch size\n        for (int b = 0; b < ").concat(e.batchSize, "; b++) {\n          for (int yR = 0; yR < ").concat(e.outHeight, "; yR++) {\n            int xR = wR + yR * ").concat(e.strideHeight, " - ").concat(e.padInfo.top, ";\n\n            if (xR < 0 || xR >= ").concat(e.inHeight, ") {\n              continue;\n            }\n\n            for (int yC = 0; yC < ").concat(e.outWidth, "; yC++) {\n              int xC = wC + yC * ").concat(e.strideWidth, " - ").concat(e.padInfo.left, ";\n\n              if (xC < 0 || xC >= ").concat(e.inWidth, ") {\n                continue;\n              }\n\n              float dyValue = getDy(b, yR, yC, d2);\n              float xValue = getX(b, xR, xC, d1);\n              dotProd += (xValue * dyValue);\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    ");
  }

}

class DepthwiseConv2DDerInputProgram$1 {
  constructor(e) {
    this.variableNames = ["dy", "W"], this.outputShape = e.inShape;
    var t = e.filterHeight,
        n = e.filterWidth,
        r = e.outChannels / e.inChannels;
    this.userCode = "\n      const ivec2 pads = ivec2(".concat(t - 1 - e.padInfo.top, ", ").concat(n - 1 - e.padInfo.left, ");\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d1 = coords[3];\n        ivec2 dyCorner = coords.yz - pads;\n        int dyRCorner = dyCorner.x;\n        int dyCCorner = dyCorner.y;\n\n        float dotProd = 0.0;\n\n        for (int wR = 0; wR < ").concat(t, "; wR++) {\n          float dyR = float(dyRCorner + wR) / ").concat(e.strideHeight, ".0;\n\n          if (dyR < 0.0 || dyR >= ").concat(e.outHeight, ".0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          int wRPerm = ").concat(t, " - 1 - wR;\n\n          for (int wC = 0; wC < ").concat(n, "; wC++) {\n            float dyC = float(dyCCorner + wC) / ").concat(e.strideWidth, ".0;\n\n            if (dyC < 0.0 || dyC >= ").concat(e.outWidth, ".0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            int wCPerm = ").concat(n, " - 1 - wC;\n\n            // TO DO: Vec4 over the channelMul\n            for (int dm = 0; dm < ").concat(r, "; dm++) {\n              int d2 = d1 * ").concat(r, " + dm;\n              float xValue = getDy(batch, idyR, idyC, d2);\n              float wValue = getW(wRPerm, wCPerm, d1, dm);\n              dotProd += xValue * wValue;\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    ");
  }

}

function depthwiseConv2dNativeBackpropFilter$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    dy: s
  } = t,
      {
    strides: o,
    dilations: i,
    pad: l,
    dimRoundingMode: u,
    filterShape: c
  } = r,
      p = computeConv2DInfo$1(a.shape, c, o, i, l, u, !0),
      d = new DepthwiseConv2DDerFilterProgram$1(p);
  return n.runWebGLProgram(d, [a, s], "float32");
}

var depthwiseConv2dNativeBackpropFilterConfig$2 = {
  kernelName: DepthwiseConv2dNativeBackpropFilter$1,
  backendName: "webgl",
  kernelFunc: depthwiseConv2dNativeBackpropFilter$3
};

function depthwiseConv2dNativeBackpropInput$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    dy: a,
    filter: s
  } = t,
      {
    strides: o,
    dilations: i,
    pad: l,
    dimRoundingMode: u,
    inputShape: c
  } = r,
      p = computeConv2DInfo$1(c, s.shape, o, i, l, u, !0),
      d = new DepthwiseConv2DDerInputProgram$1(p);
  return n.runWebGLProgram(d, [a, s], "float32");
}

var depthwiseConv2dNativeBackpropInputConfig$2 = {
  kernelName: DepthwiseConv2dNativeBackpropInput$1,
  backendName: "webgl",
  kernelFunc: depthwiseConv2dNativeBackpropInput$3
};

class DiagProgram$1 {
  constructor(e) {
    this.variableNames = ["X"], this.outputShape = [e, e], this.userCode = "\n      void main() {\n          ivec2 coords = getOutputCoords();\n          float val = coords[0] == coords[1] ? getX(coords[0]) : 0.0;\n          setOutput(val);\n      }\n    ";
  }

}

function diag$3(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    x: r
  } = t,
      a = [...r.shape, ...r.shape],
      s = sizeFromShape$1(r.shape),
      o = reshape$4({
    inputs: {
      x: r
    },
    backend: n,
    attrs: {
      shape: [s]
    }
  }),
      i = new DiagProgram$1(s),
      l = n.runWebGLProgram(i, [o], o.dtype),
      u = reshape$4({
    inputs: {
      x: l
    },
    backend: n,
    attrs: {
      shape: a
    }
  });
  return n.disposeIntermediateTensorInfo(o), n.disposeIntermediateTensorInfo(l), u;
}

var diagConfig$2 = {
  kernelName: Diag$1,
  backendName: "webgl",
  kernelFunc: diag$3
};

class Dilation2DProgram$1 {
  constructor(e) {
    this.variableNames = ["x", "W"], this.outputShape = e.outShape;
    var {
      inHeight: t,
      inWidth: n,
      padInfo: r,
      strideHeight: a,
      strideWidth: s,
      filterHeight: o,
      filterWidth: i,
      dilationHeight: l,
      dilationWidth: u
    } = e,
        {
      top: c,
      left: p
    } = r;
    this.userCode = "\n      const ivec2 strides = ivec2(".concat(a, ", ").concat(s, ");\n      const ivec2 pads = ivec2(").concat(c, ", ").concat(p, ");\n      const float neg_infinity = -3.4e38;\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords.x;\n        int d1 = coords.w;\n        ivec2 outTopLeftCorner =\n            coords.yz * strides - pads;\n        int hBeg = outTopLeftCorner.x;\n        int wBeg = outTopLeftCorner.y;\n\n        float curVal = neg_infinity;\n        for (int h = 0; h < ").concat(o, "; h++) {\n          int hIn = hBeg + h * ").concat(l, ";\n\n          if (hIn >= 0 && hIn < ").concat(t, ") {\n            for (int w = 0; w < ").concat(i, "; w++) {\n              int wIn = wBeg + w * ").concat(u, ";\n\n              if (wIn >= 0 && wIn < ").concat(n, ") {\n                float xVal = getX(batch, hIn, wIn, d1);\n                float wVal = getW(h, w, d1);\n\n                float val = xVal + wVal;\n                if (val > curVal) {\n                  curVal = val;\n                }\n              }\n            }\n          }\n        }\n\n        float result = curVal;\n        setOutput(result);\n      }\n    ");
  }

}

function dilation2D$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    filter: s
  } = t,
      {
    strides: o,
    pad: i,
    dilations: l
  } = r,
      u = computeDilation2DInfo$1(a.shape, s.shape, o, i, "NHWC", l);
  var c;
  var p = new Dilation2DProgram$1(u);
  c = n.runWebGLProgram(p, [a, s], "float32");
  var d = reshape$4({
    inputs: {
      x: c
    },
    backend: n,
    attrs: {
      shape: u.outShape
    }
  });
  return n.disposeIntermediateTensorInfo(c), d;
}

var dilation2DConfig$1 = {
  kernelName: Dilation2D$1,
  backendName: "webgl",
  kernelFunc: dilation2D$1
};

function einsum$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    equation: a
  } = r,
      s = t,
      {
    allDims: o,
    summedDims: i,
    idDims: l
  } = decodeEinsumEquation$1(a, s.length);
  checkEinsumDimSizes$1(o.length, l, s);
  var {
    path: u,
    steps: c
  } = getEinsumComputePath$1(i, l),
      p = c.length;
  var d = null,
      h = o.length;
  var m = [];

  for (var _e477 = 0; _e477 < p; ++_e477) {
    for (var _t338 of c[_e477]) {
      var {
        permutationIndices: _e478,
        expandDims: _r165
      } = getEinsumPermutation$1(h, l[_t338]);

      var _a114 = void 0;

      isIdentityPermutation$1(_e478) ? _a114 = s[_t338] : (_a114 = transpose$3({
        inputs: {
          x: s[_t338]
        },
        backend: n,
        attrs: {
          perm: _e478
        }
      }), m.push(_a114));

      var _o62 = _a114.shape.slice();

      for (var _e479 = 0; _e479 < _r165.length; ++_e479) {
        _o62.splice(_r165[_e479], 0, 1);
      }

      arraysEqual$1(_a114.shape, _o62) || (_a114 = reshape$4({
        inputs: {
          x: _a114
        },
        backend: n,
        attrs: {
          shape: _o62
        }
      }), m.push(_a114)), null === d ? d = _a114 : (d = multiply$3({
        inputs: {
          a: _a114,
          b: d
        },
        backend: n
      }), m.push(d));
    }

    _e477 < p - 1 && (u[_e477] >= 0 && (d = sum$4({
      inputs: {
        x: d
      },
      backend: n,
      attrs: {
        axis: u[_e477] - (o.length - h),
        keepDims: !1
      }
    }), m.push(d)), h--);
  }

  for (var _e480 of m) {
    _e480 !== d && n.disposeIntermediateTensorInfo(_e480);
  }

  return d;
}

var einsumConfig$2 = {
  kernelName: Einsum$1,
  backendName: "webgl",
  kernelFunc: einsum$3
},
    ELU$4 = "return (x >= 0.0) ? x : (exp(x) - 1.0);",
    ELU_PACKED$1 = "\n  vec4 result;\n\n  result.r = (x.r >= 0.0) ? x.r : (exp(x.r) - 1.0);\n  result.g = (x.g >= 0.0) ? x.g : (exp(x.g) - 1.0);\n  result.b = (x.b >= 0.0) ? x.b : (exp(x.b) - 1.0);\n  result.a = (x.a >= 0.0) ? x.a : (exp(x.a) - 1.0);\n\n  return result;\n",
    elu$5 = unaryKernelFunc$2({
  opSnippet: ELU$4,
  packedOpSnippet: ELU_PACKED$1
}),
    eluConfig$2 = {
  kernelName: Elu$3,
  backendName: "webgl",
  kernelFunc: elu$5
},
    ELU_DER$1 = "return (b >= 1.0) ? a : a * (b + 1.0);",
    ELU_DER_PACKED$1 = "\n  vec4 bGTEZero = vec4(greaterThanEqual(b, vec4(0.)));\n  return (bGTEZero * a) + ((vec4(1.0) - bGTEZero) * (a * (b + vec4(1.0))));\n",
    eluGrad$2 = e => {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    dy: r,
    y: a
  } = t,
      s = env$1().getBool("WEBGL_PACK_BINARY_OPERATIONS") ? new BinaryOpPackedProgram$1(ELU_DER_PACKED$1, r.shape, a.shape) : new BinaryOpProgram$1(ELU_DER$1, r.shape, a.shape);
  return n.runWebGLProgram(s, [r, a], r.dtype);
},
    eluGradConfig$3 = {
  kernelName: EluGrad$1,
  backendName: "webgl",
  kernelFunc: eluGrad$2
},
    PACKED_EQUAL$1 = "\n  return vec4(equal(a, b));\n",
    EQUAL$1 = "return float(a == b);",
    equal$3 = binaryKernelFunc$2({
  opSnippet: EQUAL$1,
  packedOpSnippet: PACKED_EQUAL$1,
  dtype: "bool",
  cpuKernelImpl: equalImplCPU$1
}),
    equalConfig$2 = {
  kernelName: Equal$1,
  backendName: "webgl",
  kernelFunc: equal$3
},
    ERF$1 = "\n  // Error function is calculated approximately with elementary function.\n  // See \"Handbook of Mathematical Functions with Formulas,\n  // Graphs, and Mathematical Tables\", Abramowitz and Stegun.\n  float p = ".concat(ERF_P$1, ";\n  float a1 = ").concat(ERF_A1$1, ";\n  float a2 = ").concat(ERF_A2$1, ";\n  float a3 = ").concat(ERF_A3$1, ";\n  float a4 = ").concat(ERF_A4$1, ";\n  float a5 = ").concat(ERF_A5$1, ";\n\n  float sign = sign(x);\n  x = abs(x);\n  float t = 1.0 / (1.0 + p * x);\n  return sign * (1.0 - (((((a5*t + a4)*t) + a3)*t + a2)*t + a1)*t*exp(-x*x));\n"),
    erf$3 = unaryKernelFunc$2({
  opSnippet: ERF$1
}),
    erfConfig$2 = {
  kernelName: Erf$1,
  backendName: "webgl",
  kernelFunc: erf$3
},
    EXP$1 = "return exp(x);",
    exp$3 = unaryKernelFunc$2({
  opSnippet: EXP$1,
  packedOpSnippet: EXP$1,
  cpuKernelImpl: expImplCPU$1
}),
    expConfig$2 = {
  kernelName: Exp$1,
  backendName: "webgl",
  kernelFunc: exp$3
};

function expandDims$4(e) {
  var {
    inputs: t,
    attrs: n,
    backend: r
  } = e,
      {
    dim: a
  } = n,
      {
    input: s
  } = t,
      o = s.shape.length,
      i = s.shape.slice();
  var l = a;
  return a < 0 && (assert$6(-(o + 1) <= a, () => "Axis must be in the interval [".concat(-(o + 1), ", ").concat(o, "]")), l = o + a + 1), i.splice(l, 0, 1), reshape$4({
    inputs: {
      x: s
    },
    backend: r,
    attrs: {
      shape: i
    }
  });
}

var expandDimsConfig$2 = {
  kernelName: ExpandDims$1,
  backendName: "webgl",
  kernelFunc: expandDims$4
},
    EXPM1$1 = "return exp(x) - 1.0;",
    expm1$3 = unaryKernelFunc$2({
  opSnippet: EXPM1$1,
  packedOpSnippet: EXPM1$1,
  cpuKernelImpl: expm1ImplCPU$1
}),
    expm1Config$2 = {
  kernelName: Expm1$1,
  backendName: "webgl",
  kernelFunc: expm1$3
};

class FFTProgram$1 {
  constructor(e, t, n) {
    this.variableNames = ["real", "imag"];
    var r = t[1];
    this.outputShape = t;
    var a = n ? "2.0 * ".concat(Math.PI) : "-2.0 * ".concat(Math.PI),
        s = n ? "".concat(r, ".0") : "1.0";
    var o;
    if ("real" === e) o = "return real * expR - imag * expI;";else {
      if ("imag" !== e) throw new Error("FFT component must be either \"real\" or \"imag\", got ".concat(e, "."));
      o = "return real * expI + imag * expR;";
    }
    this.userCode = "\n      const float exponentMultiplier = ".concat(a, ";\n\n      float unaryOpComplex(float real, float expR, float imag, float expI) {\n        ").concat(o, "\n      }\n\n      float mulMatDFT(int batch, int index) {\n        float indexRatio = float(index) / float(").concat(r, ");\n        float exponentMultiplierTimesIndexRatio =\n            exponentMultiplier * indexRatio;\n\n        float result = 0.0;\n\n        for (int i = 0; i < ").concat(r, "; i++) {\n          // x = (-2|2 * PI / N) * index * i;\n          float x = exponentMultiplierTimesIndexRatio * float(i);\n          float expR = cos(x);\n          float expI = sin(x);\n          float real = getReal(batch, i);\n          float imag = getImag(batch, i);\n\n          result +=\n              unaryOpComplex(real, expR, imag, expI) / ").concat(s, ";\n        }\n\n        return result;\n      }\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        setOutput(mulMatDFT(coords[0], coords[1]));\n      }\n    ");
  }

}

function fftImpl$2(e, t, n) {
  var r = n.texData.get(e.dataId),
      a = sizeFromShape$1(e.shape),
      s = e.shape[e.shape.length - 1],
      o = reshape$4({
    inputs: {
      x: e
    },
    backend: n,
    attrs: {
      shape: [a / s, s]
    }
  }),
      i = o.shape,
      l = new FFTProgram$1("real", i, t),
      u = new FFTProgram$1("imag", i, t),
      c = [{
    dataId: r.complexTensorInfos.real.dataId,
    dtype: r.complexTensorInfos.real.dtype,
    shape: i
  }, {
    dataId: r.complexTensorInfos.imag.dataId,
    dtype: r.complexTensorInfos.imag.dtype,
    shape: i
  }],
      p = n.runWebGLProgram(l, c, "float32"),
      d = n.runWebGLProgram(u, c, "float32"),
      h = complex$3({
    inputs: {
      real: p,
      imag: d
    },
    backend: n
  });
  n.disposeIntermediateTensorInfo(p), n.disposeIntermediateTensorInfo(d);
  var m = reshape$4({
    inputs: {
      x: h
    },
    backend: n,
    attrs: {
      shape: e.shape
    }
  });
  return n.disposeIntermediateTensorInfo(o), n.disposeIntermediateTensorInfo(h), m;
}

function fft$3(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    input: r
  } = t;
  return fftImpl$2(r, !1, n);
}

var fftConfig$2 = {
  kernelName: FFT$1,
  backendName: "webgl",
  kernelFunc: fft$3
};

class FillProgram$1 {
  constructor(e, t) {
    this.outputShape = [], this.customUniforms = [{
      name: "value",
      type: "float"
    }], this.variableNames = ["x"], this.outputShape = e, this.userCode = "\n      void main() {\n        // Input can be obtained from uniform value.\n        setOutput(value);\n      }\n    ";
  }

}

function fill$3(e) {
  var {
    backend: t,
    attrs: n
  } = e,
      {
    shape: r,
    value: a
  } = n;
  var {
    dtype: s
  } = n;

  if (s = s || inferDtype$1(a), "string" === s) {
    var _e481 = getArrayFromDType$1(s, sizeFromShape$1(r));

    return _e481.fill(a), t.makeTensorInfo(r, s, _e481);
  }

  {
    var _e482 = new FillProgram$1(r, a);

    return t.runWebGLProgram(_e482, [], s, [[a]]);
  }
}

var fillConfig$2 = {
  kernelName: Fill$1,
  backendName: "webgl",
  kernelFunc: fill$3
};

class FlipLeftRightProgram$1 {
  constructor(e) {
    this.variableNames = ["Image"], this.outputShape = [];
    var t = e[2];
    this.outputShape = e, this.userCode = "\n        void main() {\n          ivec4 coords = getOutputCoords();\n          int x = coords[2];\n\n          int coordX = ".concat(t, " - x - 1;\n          float outputValue;\n          if(coordX >= 0 && coordX < ").concat(t, ") {\n            outputValue = getImage(coords[0], coords[1], coordX, coords[3]);\n          } else {\n            outputValue = getImage(coords[0], coords[1], coords[2], coords[3]);\n          }\n          setOutput(outputValue);\n        }\n    ");
  }

}

var flipLeftRightConfig$2 = {
  kernelName: FlipLeftRight$1,
  backendName: "webgl",
  kernelFunc: _ref22 => {
    var {
      inputs: e,
      backend: t
    } = _ref22;
    var {
      image: n
    } = e,
        r = t,
        a = new FlipLeftRightProgram$1(n.shape);
    return r.runWebGLProgram(a, [n], n.dtype);
  }
},
    FLOOR$1 = "return floor(x);",
    floor$3 = unaryKernelFunc$2({
  opSnippet: FLOOR$1,
  packedOpSnippet: FLOOR$1,
  cpuKernelImpl: floorImplCPU$1
}),
    floorConfig$2 = {
  kernelName: Floor$1,
  backendName: "webgl",
  kernelFunc: floor$3
},
    INT_DIV$1 = "\n  float s = sign(a) * sign(b);\n  int ia = round(a);\n  int ib = round(b);\n  if (ib != 0) {\n    // Windows (D3D) wants guaranteed non-zero int division at compile-time.\n    return float(idiv(ia, ib, s));\n  } else {\n    return NAN;\n  }\n",
    INT_DIV_PACKED$1 = "\n  ivec4 ia = round(a);\n  ivec4 ib = round(b);\n  bvec4 cond = notEqual(ib, ivec4(0));\n  ivec4 result = ivec4(0);\n  vec4 s = sign(a) * sign(b);\n\n  // Windows (D3D) wants guaranteed non-zero int division at compile-time.\n  if (cond[0]) {\n    result[0] = idiv(ia[0], ib[0], s[0]);\n  }\n  if (cond[1]) {\n    result[1] = idiv(ia[1], ib[1], s[1]);\n  }\n  if (cond[2]) {\n    result[2] = idiv(ia[2], ib[2], s[2]);\n  }\n  if (cond[3]) {\n    result[3] = idiv(ia[3], ib[3], s[3]);\n  }\n  return vec4(result);\n",
    floorDiv$3 = binaryKernelFunc$2({
  opSnippet: INT_DIV$1,
  packedOpSnippet: INT_DIV_PACKED$1,
  dtype: "int32"
}),
    floorDivConfig$2 = {
  kernelName: FloorDiv$1,
  backendName: "webgl",
  kernelFunc: floorDiv$3
};

class FromPixelsProgram$1 {
  constructor(e) {
    this.variableNames = ["A"];
    var t = getGlslDifferences$1(),
        [n, r] = e;
    this.outputShape = e, this.userCode = "\n      void main() {\n        ivec3 coords = getOutputCoords();\n        int texR = coords[0];\n        int texC = coords[1];\n        int depth = coords[2];\n        vec2 uv = (vec2(texC, texR) + halfCR) / vec2(".concat(r, ".0, ").concat(n, ".0);\n\n        vec4 values = ").concat(t.texture2D, "(A, uv);\n        float value;\n        if (depth == 0) {\n          value = values.r;\n        } else if (depth == 1) {\n          value = values.g;\n        } else if (depth == 2) {\n          value = values.b;\n        } else if (depth == 3) {\n          value = values.a;\n        }\n\n        setOutput(floor(value * 255.0 + 0.5));\n      }\n    ");
  }

}

class FromPixelsPackedProgram$1 {
  constructor(e) {
    this.variableNames = ["A"], this.packedInputs = !1, this.packedOutput = !0;
    var t = getGlslDifferences$1(),
        [n, r] = e;
    this.outputShape = e, this.userCode = "\n      void main() {\n        ivec3 coords = getOutputCoords();\n        int texR = coords[0];\n        int texC = coords[1];\n        int depth = coords[2];\n\n        vec4 result = vec4(0.);\n\n        for(int row=0; row<=1; row++) {\n          for(int col=0; col<=1; col++) {\n            texC = coords[1] + row;\n            depth = coords[2] + col;\n\n            vec2 uv = (vec2(texC, texR) + halfCR) /\n                       vec2(".concat(r, ".0, ").concat(n, ".0);\n            vec4 values = ").concat(t.texture2D, "(A, uv);\n            float value;\n            if (depth == 0) {\n              value = values.r;\n            } else if (depth == 1) {\n              value = values.g;\n            } else if (depth == 2) {\n              value = values.b;\n            } else if (depth == 3) {\n              value = values.a;\n            }\n\n            result[row * 2 + col] = floor(value * 255.0 + 0.5);\n          }\n        }\n\n        ").concat(t.output, " = result;\n      }\n    ");
  }

}

var fromPixelsConfig$1 = {
  kernelName: FromPixels$1,
  backendName: "webgl",
  kernelFunc: fromPixels$2
};
var fromPixels2DContext$2;

function fromPixels$2(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e;
  var {
    pixels: a
  } = t;
  var {
    numChannels: s
  } = r,
      o = "undefined" != typeof HTMLVideoElement && a instanceof HTMLVideoElement,
      i = "undefined" != typeof HTMLImageElement && a instanceof HTMLImageElement,
      [l, u] = o ? [a.videoWidth, a.videoHeight] : [a.width, a.height],
      c = [u, l],
      p = [u, l, s];
  (i || o) && (null == fromPixels2DContext$2 && (fromPixels2DContext$2 = document.createElement("canvas").getContext("2d")), fromPixels2DContext$2.canvas.width = l, fromPixels2DContext$2.canvas.height = u, fromPixels2DContext$2.drawImage(a, 0, 0, l, u), a = fromPixels2DContext$2.canvas);
  var d = n.makeTensorInfo(c, "int32");
  n.texData.get(d.dataId).usage = TextureUsage$1.PIXELS, n.gpgpu.uploadPixelDataToTexture(n.getTexture(d.dataId), a);
  var h = env$1().getBool("WEBGL_PACK") ? new FromPixelsPackedProgram$1(p) : new FromPixelsProgram$1(p),
      m = n.runWebGLProgram(h, [d], "int32");
  return n.disposeData(d.dataId), m;
}

function fusedConv2d$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    filter: s,
    bias: o,
    preluActivationWeights: i
  } = t,
      {
    strides: l,
    pad: u,
    dataFormat: c,
    dilations: p,
    dimRoundingMode: d,
    activation: h,
    leakyreluAlpha: m
  } = r,
      f = convertConv2DDataFormat$1(c),
      g = computeConv2DInfo$1(a.shape, s.shape, l, p, u, d, !1, f);
  var $;
  var y = [];
  if (1 !== g.filterHeight || 1 !== g.filterWidth || 1 !== g.dilationHeight || 1 !== g.dilationWidth || 1 !== g.strideHeight || 1 !== g.strideWidth || "SAME" !== g.padInfo.type && "VALID" !== g.padInfo.type) {
    if (env$1().getBool("WEBGL_CONV_IM2COL") && 1 === a.shape[0]) $ = conv2dWithIm2Row$1({
      x: a,
      filter: s,
      convInfo: g,
      backend: n,
      bias: o,
      activation: h,
      preluActivationWeights: i,
      leakyreluAlpha: m
    });else {
      var _e483 = null != o,
          _t339 = null != i,
          _r166 = "leakyrelu" === h,
          _l32 = h ? mapActivationToShaderProgram$1(h, !1) : null,
          _u29 = new Conv2DProgram$1(g, _e483, _l32, _t339, _r166),
          _c19 = [a, s];

      if (o && _c19.push(o), i && _c19.push(i), _r166) {
        var _e484 = n.makeTensorInfo([], "float32", createScalarValue$1(m, "float32"));

        _c19.push(_e484), y.push(_e484);
      }

      $ = n.runWebGLProgram(_u29, _c19, "float32");
    }
  } else $ = conv2dByMatMul$1({
    x: a,
    filter: s,
    convInfo: g,
    backend: n,
    bias: o,
    activation: h,
    preluActivationWeights: i,
    leakyreluAlpha: m
  });
  var b = reshape$4({
    inputs: {
      x: $
    },
    backend: n,
    attrs: {
      shape: g.outShape
    }
  });
  return y.push($), y.forEach(e => n.disposeIntermediateTensorInfo(e)), b;
}

var fusedConv2DConfig$2 = {
  kernelName: FusedConv2D$1,
  backendName: "webgl",
  kernelFunc: fusedConv2d$1
};

function fusedDepthwiseConv2D$2(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    filter: s,
    bias: o,
    preluActivationWeights: i
  } = t,
      {
    strides: l,
    pad: u,
    dilations: c,
    dimRoundingMode: p,
    activation: d,
    leakyreluAlpha: h
  } = r,
      m = [];
  var f = c;
  null == f && (f = [1, 1]), assert$6(eitherStridesOrDilationsAreOne$1(l, f), () => "Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ".concat(l, " and dilations '").concat(f, "'"));
  var g = computeConv2DInfo$1(a.shape, s.shape, l, f, u, p, !0),
      $ = env$1().getBool("WEBGL_PACK_DEPTHWISECONV") && g.strideWidth <= 2 && g.outChannels / g.inChannels == 1,
      y = d ? mapActivationToShaderProgram$1(d, $) : null,
      b = [a, s],
      x = null != o,
      v = null != i,
      I = "leakyrelu" === d;

  if (x && b.push(o), v && b.push(i), I) {
    var _e485 = n.makeTensorInfo([], "float32", createScalarValue$1(h, "float32"));

    b.push(_e485), m.push(_e485);
  }

  var C;
  C = $ ? new DepthwiseConvPacked2DProgram$1(g, x, y, v, I) : new DepthwiseConv2DProgram$1(g, x, y, v, I);
  var S = n.runWebGLProgram(C, b, "float32");
  return m.forEach(e => n.disposeIntermediateTensorInfo(e)), S;
}

var fusedDepthwiseConv2DConfig$2 = {
  kernelName: FusedDepthwiseConv2D$1,
  backendName: "webgl",
  kernelFunc: fusedDepthwiseConv2D$2
};

class GatherNDProgram$1 {
  constructor(e, t, n) {
    this.sliceDim = e, this.strides = t, this.variableNames = ["x", "indices"], this.outputShape = n;
    var r = getCoordsDataType$1(t.length),
        a = getCoordsDataType$1(n.length);
    this.userCode = "\n        ".concat(r, " strides = ").concat(r, "(").concat(this.strides, ");\n         void main() {\n          ").concat(a, " coords = getOutputCoords();\n          int flattenIndex = 0;\n          for (int j = 0; j < ").concat(this.sliceDim, "; j++) {\n            int index = round(getIndices(coords[0], j));\n            flattenIndex += index * ").concat(this.sliceDim > 1 ? "strides[j]" : "strides", ";\n          }\n          setOutput(getX(flattenIndex, coords[1]));\n        }\n      ");
  }

}

function gatherNd$2(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    params: r,
    indices: a
  } = t,
      s = a.shape,
      o = s[s.length - 1],
      i = sizeFromShape$1(r.shape),
      [l, u, c, p] = prepareAndValidate$1(r, a),
      d = reshape$4({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      shape: [u, o]
    }
  }),
      h = reshape$4({
    inputs: {
      x: r
    },
    backend: n,
    attrs: {
      shape: [sizeFromShape$1(r.shape) / c, c]
    }
  });

  if (n.shouldExecuteOnCPU([r, a]) || "string" === r.dtype) {
    var _e486 = n.readSync(a.dataId),
        _t340 = n.bufferSync(r),
        _s86 = gatherNdImplCPU$1(_e486, _t340, r.dtype, u, o, c, p, r.shape, i);

    return n.makeTensorInfo(l, r.dtype, _s86.values);
  }

  var m = new GatherNDProgram$1(o, p, [u, c]),
      f = n.runWebGLProgram(m, [h, d], h.dtype),
      g = reshape$4({
    inputs: {
      x: f
    },
    backend: n,
    attrs: {
      shape: l
    }
  });
  return n.disposeIntermediateTensorInfo(d), n.disposeIntermediateTensorInfo(h), n.disposeIntermediateTensorInfo(f), g;
}

var gatherNdConfig$2 = {
  kernelName: GatherNd$1,
  backendName: "webgl",
  kernelFunc: gatherNd$2
};

class GatherProgram$1 {
  constructor(e, t) {
    this.variableNames = ["A", "indices"], this.outputShape = t, this.rank = t.length;
    var n = getCoordsDataType$1(this.rank),
        r = getSourceCoords$4(e);
    this.userCode = "\n      void main() {\n        ".concat(n, " resRC = getOutputCoords();\n        setOutput(getA(").concat(r, "));\n      }\n    ");
  }

}

function getSourceCoords$4(e, t) {
  var n = ["resRC.x", "resRC.y", "resRC.z", "resRC.w"],
      r = [];

  for (var _t341 = 0; _t341 < e.length; _t341++) {
    r.push(2 === _t341 ? "int(getIndices(resRC.x, resRC.z))" : "".concat(n[_t341]));
  }

  return r.join();
}

function gatherV2$2(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    indices: s
  } = t,
      {
    axis: o,
    batchDims: i
  } = r,
      l = collectGatherOpShapeInfo$1(a, s, parseAxisParam$1(o, a.shape)[0], i),
      u = sizeFromShape$1(s.shape),
      c = [],
      p = reshape$4({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      shape: [l.batchSize, l.outerSize, l.dimSize, l.sliceSize]
    }
  }),
      d = reshape$4({
    inputs: {
      x: s
    },
    backend: n,
    attrs: {
      shape: [l.batchSize, u / l.batchSize]
    }
  });
  c.push(p), c.push(d);
  var h = [l.batchSize, l.outerSize, u / l.batchSize, l.sliceSize];

  if (n.shouldExecuteOnCPU([a, s]) || "string" === a.dtype) {
    var _e487 = n.bufferSync(d),
        _t342 = n.bufferSync(p),
        _r167 = gatherV2ImplCPU$1(_t342, _e487, h);

    return c.forEach(e => n.disposeIntermediateTensorInfo(e)), n.makeTensorInfo(l.outputShape, _r167.dtype, _r167.values);
  }

  var m = new GatherProgram$1(p.shape, h),
      f = n.runWebGLProgram(m, [p, d], p.dtype);
  c.push(f);
  var g = reshape$4({
    inputs: {
      x: f
    },
    backend: n,
    attrs: {
      shape: l.outputShape
    }
  });
  return c.forEach(e => n.disposeIntermediateTensorInfo(e)), g;
}

var gatherV2Config$2 = {
  kernelName: GatherV2$1,
  backendName: "webgl",
  kernelFunc: gatherV2$2
},
    GREATER$1 = "return float(a > b);",
    GREATER_PACKED$1 = "\n  return vec4(greaterThan(a, b));\n",
    greater$4 = binaryKernelFunc$2({
  opSnippet: GREATER$1,
  packedOpSnippet: GREATER_PACKED$1,
  cpuKernelImpl: greaterImplCPU$1,
  dtype: "bool"
}),
    greaterConfig$2 = {
  kernelName: Greater$1,
  backendName: "webgl",
  kernelFunc: greater$4
},
    GREATER_EQUAL$1 = "return float(a >= b);",
    GREATER_EQUAL_PACKED$1 = "\n  return vec4(greaterThanEqual(a, b));\n",
    greaterEqual$3 = binaryKernelFunc$2({
  opSnippet: GREATER_EQUAL$1,
  packedOpSnippet: GREATER_EQUAL_PACKED$1,
  dtype: "bool",
  cpuKernelImpl: greaterEqualImplCPU$1
}),
    greaterEqualConfig$2 = {
  kernelName: GreaterEqual$1,
  backendName: "webgl",
  kernelFunc: greaterEqual$3
};

function ifft$3(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    input: r
  } = t;
  return fftImpl$2(r, !0, n);
}

var ifftConfig$2 = {
  kernelName: IFFT$1,
  backendName: "webgl",
  kernelFunc: ifft$3
},
    IS_FINITE$1 = "return float(!isnan(x) && !isinf(x));",
    isFinite$4 = unaryKernelFunc$2({
  opSnippet: IS_FINITE$1,
  dtype: "bool"
}),
    isFiniteConfig$2 = {
  kernelName: IsFinite$1,
  backendName: "webgl",
  kernelFunc: isFinite$4
},
    IS_INF$1 = "return float(isinf(x));",
    isInf$3 = unaryKernelFunc$2({
  opSnippet: IS_INF$1,
  dtype: "bool"
}),
    isInfConfig$2 = {
  kernelName: IsInf$1,
  backendName: "webgl",
  kernelFunc: isInf$3
},
    IS_NAN$1 = "return float(isnan(x));",
    isNaN$4 = unaryKernelFunc$2({
  opSnippet: IS_NAN$1,
  dtype: "bool"
}),
    isNaNConfig$2 = {
  kernelName: IsNan$1,
  backendName: "webgl",
  kernelFunc: isNaN$4
},
    LESS$1 = "return float(a < b);",
    LESS_PACKED$1 = "\n  return vec4(lessThan(a, b));\n",
    less$4 = binaryKernelFunc$2({
  opSnippet: LESS$1,
  packedOpSnippet: LESS_PACKED$1,
  cpuKernelImpl: lessImplCPU$1,
  dtype: "bool"
}),
    lessConfig$2 = {
  kernelName: Less$1,
  backendName: "webgl",
  kernelFunc: less$4
},
    LESS_EQUAL$1 = "return float(a <= b);",
    LESS_EQUAL_PACKED$1 = "\n  return vec4(lessThanEqual(a, b));\n",
    lessEqual$3 = binaryKernelFunc$2({
  opSnippet: LESS_EQUAL$1,
  packedOpSnippet: LESS_EQUAL_PACKED$1,
  cpuKernelImpl: lessEqualImplCPU$1,
  dtype: "bool"
}),
    lessEqualConfig$2 = {
  kernelName: LessEqual$1,
  backendName: "webgl",
  kernelFunc: lessEqual$3
};

function linSpace$2(e) {
  var {
    backend: t,
    attrs: n
  } = e,
      {
    start: r,
    stop: a,
    num: s
  } = n,
      o = linSpaceImplCPU$1(r, a, s);
  return t.makeTensorInfo([o.length], "float32", o);
}

var linSpaceConfig$2 = {
  kernelName: LinSpace$1,
  backendName: "webgl",
  kernelFunc: linSpace$2
},
    LOG$1 = "if (x < 0.0) return NAN;\n  return log(x);",
    LOG_PACKED$1 = "\n  vec4 result = log(x);\n  vec4 isNaN = vec4(lessThan(x, vec4(0.0)));\n  result.r = isNaN.r == 1.0 ? NAN : result.r;\n  result.g = isNaN.g == 1.0 ? NAN : result.g;\n  result.b = isNaN.b == 1.0 ? NAN : result.b;\n  result.a = isNaN.a == 1.0 ? NAN : result.a;\n\n  return result;\n",
    log$4 = unaryKernelFunc$2({
  opSnippet: LOG$1,
  packedOpSnippet: LOG_PACKED$1,
  cpuKernelImpl: logImplCPU$1
}),
    logConfig$2 = {
  kernelName: Log$1,
  backendName: "webgl",
  kernelFunc: log$4
},
    LOG1P$1 = "return log(1.0 + x);",
    log1p$3 = unaryKernelFunc$2({
  opSnippet: LOG1P$1
}),
    log1pConfig$2 = {
  kernelName: Log1p$1,
  backendName: "webgl",
  kernelFunc: log1p$3
},
    LOGICAL_AND$1 = "return float(a >= 1.0 && b >= 1.0);",
    LOGICAL_AND_PACKED$1 = "\n  return vec4(\n    vec4(greaterThanEqual(a, vec4(1.0))) *\n    vec4(greaterThanEqual(b, vec4(1.0))));\n",
    logicalAnd$3 = binaryKernelFunc$2({
  opSnippet: LOGICAL_AND$1,
  packedOpSnippet: LOGICAL_AND_PACKED$1,
  dtype: "bool"
}),
    logicalAndConfig$2 = {
  kernelName: LogicalAnd$1,
  backendName: "webgl",
  kernelFunc: logicalAnd$3
},
    LOGICAL_NOT$1 = "return float(!(x >= 1.0));",
    logicalNot$3 = unaryKernelFunc$2({
  opSnippet: LOGICAL_NOT$1
}),
    logicalNotConfig$2 = {
  kernelName: LogicalNot$1,
  backendName: "webgl",
  kernelFunc: logicalNot$3
},
    LOGICAL_OR$1 = "return float(a >= 1.0 || b >= 1.0);",
    LOGICAL_OR_PACKED$1 = "\n  return min(\n    vec4(greaterThanEqual(a, vec4(1.0))) +\n    vec4(greaterThanEqual(b, vec4(1.0))),\n    vec4(1.0));\n",
    logicalOr$3 = binaryKernelFunc$2({
  opSnippet: LOGICAL_OR$1,
  packedOpSnippet: LOGICAL_OR_PACKED$1,
  dtype: "bool"
}),
    logicalOrConfig$2 = {
  kernelName: LogicalOr$1,
  backendName: "webgl",
  kernelFunc: logicalOr$3
};

class LRNProgram$1 {
  constructor(e, t, n, r, a) {
    this.variableNames = ["x"], this.outputShape = [];
    var s = t,
        o = e[3] - 1;
    var i;
    this.outputShape = e;
    var l = "float(".concat(n, ") + float(").concat(r, ") * sum");
    i = .5 === a ? "inversesqrt(".concat(l, ")") : 1 === a ? "1.0/(".concat(l, ")") : "exp(log(".concat(l, ") * float(-").concat(a, "));"), this.userCode = "\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int r = coords[1];\n        int c = coords[2];\n        int d = coords[3];\n        float x = getX(b, r, c, d);\n        float sum = 0.0;\n        for (int j = -".concat(s, "; j <= ").concat(s, "; j++) {\n          int idx = d + j;\n          if (idx >= 0 && idx <=  ").concat(o, ") {\n            float z = getX(b, r, c, idx);\n            sum += z * z;\n          }\n        }\n        float val = x * ").concat(i, ";\n        setOutput(val);\n      }\n    ");
  }

}

class LRNPackedProgram$1 {
  constructor(e, t, n, r, a) {
    this.variableNames = ["x"], this.outputShape = [], this.packedInputs = !0, this.packedOutput = !0;
    var s = t,
        o = e[3] - 1;
    var i;
    this.outputShape = e;
    var l = "float(".concat(n, ") + float(").concat(r, ") * sum");
    i = .5 === a ? "inversesqrt(".concat(l, ")") : 1 === a ? "1.0/(".concat(l, ")") : "exp(log(".concat(l, ") * float(-").concat(a, "));"), this.userCode = "\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords.x;\n        int r = coords.y;\n        int c = coords.z;\n        int d = coords.w;\n\n        bool hasNextCol = d < ".concat(this.outputShape[3], ";\n        bool hasNextRow = c < ").concat(this.outputShape[2], ";\n\n        vec4 sum = vec4(0.);\n        vec4 xFragAtOutputCoords = getX(b, r, c, d);\n\n        vec4 xAtOutputCoords = vec4(\n          getChannel(xFragAtOutputCoords, vec2(c, d)),\n          hasNextCol ?\n            getChannel(xFragAtOutputCoords, vec2(c, d + 1)) : 0.0,\n          hasNextRow ?\n            getChannel(xFragAtOutputCoords , vec2(c + 1, d)) : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getChannel(xFragAtOutputCoords, vec2(c + 1, d + 1)) : 0.0\n        );\n\n        int firstChannel = d - ").concat(s, ";\n        vec2 cache = vec2(0.);\n        if(firstChannel >= 0){\n          vec4 firstChannelFrag = getX(b, r, c, firstChannel);\n          cache.x = getChannel(firstChannelFrag, vec2(c, firstChannel));\n            if(hasNextRow){\n              cache.y = getChannel(firstChannelFrag, vec2(c + 1, firstChannel));\n            }\n        }\n\n        ivec2 depth = ivec2(d, d + 1);\n        for (int j = - ").concat(s, "; j <= ").concat(s, "; j++) {\n          ivec2 idx = depth + j;\n          bvec2 aboveLowerBound = greaterThanEqual(idx, ivec2(0));\n          bvec2 belowUpperBound = lessThanEqual(idx, ivec2(").concat(o, "));\n\n          bool depthInRange = aboveLowerBound.x && belowUpperBound.x;\n          bool depthPlusOneInRange = aboveLowerBound.y && belowUpperBound.y;\n\n          if(depthInRange || depthPlusOneInRange){\n            vec4 z = vec4(0.);\n            vec4 xFragAtCurrentDepth;\n            z.xz = cache.xy;\n            if(depthPlusOneInRange && hasNextCol){\n              xFragAtCurrentDepth = idx.y != d ?\n                getX(b, r, c, idx.y) : xFragAtOutputCoords;\n              z.y = getChannel(xFragAtCurrentDepth, vec2(c, idx.y));\n              if(hasNextRow){\n                z.w = getChannel(xFragAtCurrentDepth, vec2(c + 1, idx.y));\n              }\n            }\n            cache.xy = z.yw;\n            sum += z * z;\n          }\n        }\n        vec4 result = xAtOutputCoords * ").concat(i, ";\n        setOutput(result);\n      }\n    ");
  }

}

var lrn$1 = e => {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    depthRadius: s,
    bias: o,
    alpha: i,
    beta: l
  } = r,
      u = env$1().getBool("WEBGL_PACK_NORMALIZATION") ? new LRNPackedProgram$1(a.shape, s, o, i, l) : new LRNProgram$1(a.shape, s, o, i, l);
  return n.runWebGLProgram(u, [a], a.dtype);
},
    LRNConfig$1 = {
  kernelName: LRN$1,
  backendName: "webgl",
  kernelFunc: lrn$1
};

class LRNGradProgram$1 {
  constructor(e, t, n, r, a) {
    this.variableNames = ["inputImage", "outputImage", "dy"], this.outputShape = [], this.outputShape = e, this.depth = e[3], this.depthRadius = t, this.bias = n, this.alpha = r, this.beta = a, this.userCode = "\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int r = coords[1];\n        int c = coords[2];\n\n        float result = 0.0;\n        for (int d = 0; d < ".concat(this.depth, "; ++d) {\n          int depthBegin = int(max(0.0, float(d - ").concat(t, ")));\n          int depthEnd = int(min(float(").concat(this.depth, "),\n              float(d + ").concat(t, " + 1)));\n\n          const int MIN_DEPTH_BEGIN = 0;\n          const int MAX_DEPTH_END = ").concat(this.depth, ";\n\n          float norm = 0.0;\n          for (int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k) {\n            if (k < depthBegin){\n              continue;\n            }\n            else if (k >= depthBegin && k < depthEnd) {\n              norm += getInputImage(b, r, c, k) * getInputImage(b, r, c, k);\n            }\n            else {\n              break;\n            }\n          }\n\n          norm = float(").concat(r, ") * norm + float(").concat(n, ");\n\n          for(int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k){\n            if (k < depthBegin){\n              continue;\n            }\n            else if (k >= depthBegin && k < depthEnd){\n              float dyi = -2.0 * float(").concat(r, ")\n                * float(").concat(a, ")\n                * getInputImage(b ,r ,c, k) * getOutputImage(b, r, c, d)\n                / norm;\n              if (k == d) {\n                dyi += pow(norm, -1.0 * ").concat(a, ");\n              }\n              if (k == coords[3]) {\n                dyi *= getDy(b, r, c, d);\n                result += dyi;\n              }\n            }\n            else {\n              break;\n            }\n          }\n      }\n      setOutput(result);\n      }\n    ");
  }

}

var lrnGrad$1 = e => {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    y: s,
    dy: o
  } = t,
      {
    depthRadius: i,
    bias: l,
    alpha: u,
    beta: c
  } = r,
      p = new LRNGradProgram$1(a.shape, i, l, u, c);
  return n.runWebGLProgram(p, [a, s, o], a.dtype);
},
    LRNGradConfig$1 = {
  kernelName: LRNGrad$1,
  backendName: "webgl",
  kernelFunc: lrnGrad$1
};

function maxImpl$2(e, t, n, r) {
  var a = sizeFromShape$1(t),
      s = reshape$4({
    inputs: {
      x: e
    },
    attrs: {
      shape: [sizeFromShape$1(e.shape) / a, a]
    },
    backend: r
  }),
      o = reduce$1(s, e.dtype, "max", r),
      i = reshape$4({
    inputs: {
      x: o
    },
    attrs: {
      shape: n
    },
    backend: r
  });
  return r.disposeIntermediateTensorInfo(s), r.disposeIntermediateTensorInfo(o), i;
}

function max$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    reductionIndices: s,
    keepDims: o
  } = r,
      i = a.shape.length,
      l = parseAxisParam$1(s, a.shape);
  var u = l;
  var c = getAxesPermutation$1(u, i),
      p = null != c,
      d = n.shouldExecuteOnCPU([a]);
  var h = a;

  if (p) {
    if (d) {
      var _e488 = n.texData.get(h.dataId).values,
          _t343 = new Array(i);

      for (var _e489 = 0; _e489 < _t343.length; _e489++) {
        _t343[_e489] = a.shape[c[_e489]];
      }

      var _r168 = transposeImplCPU$1(_e488, a.shape, a.dtype, c, _t343);

      h = n.makeTensorInfo(_t343, a.dtype), n.texData.get(h.dataId).values = _r168;
    } else h = transposeImpl$2(a, c, n);

    u = getInnerMostAxes$1(u.length, i);
  }

  assertAxesAreInnerMostDims$1("max", u, i);
  var [m, f] = computeOutAndReduceShapes$1(h.shape, u);
  var g,
      $ = m;

  if (o && ($ = expandShapeToKeepDim$1(m, l)), d) {
    var _e490 = n.texData.get(h.dataId),
        _t344 = maxImplCPU$1(_e490.values, sizeFromShape$1(f), $, a.dtype);

    g = n.makeTensorInfo($, a.dtype), n.texData.get(g.dataId).values = _t344;
  } else g = maxImpl$2(h, f, $, n);

  return p && n.disposeIntermediateTensorInfo(h), g;
}

var maxConfig$2 = {
  kernelName: Max$1,
  backendName: "webgl",
  kernelFunc: max$4
},
    MAXIMUM$1 = CHECK_NAN_SNIPPET$4 + "\n  return max(a, b);\n",
    MAXIMUM_PACKED$1 = "\n  vec4 result = vec4(max(a, b));\n  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));\n  " + CHECK_NAN_SNIPPET$3 + "\n  return result;\n",
    maximum$4 = binaryKernelFunc$2({
  opSnippet: MAXIMUM$1,
  packedOpSnippet: MAXIMUM_PACKED$1,
  cpuKernelImpl: maximumImplCPU$1
}),
    maximumConfig$2 = {
  kernelName: Maximum$3,
  backendName: "webgl",
  kernelFunc: maximum$4
};

function maxPool$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t;
  assertNotComplex$2(a, "maxPool");
  var {
    filterSize: s,
    strides: o,
    pad: i,
    dimRoundingMode: l
  } = r;
  assert$6(eitherStridesOrDilationsAreOne$1(o, 1), () => "Error in maxPool: Either strides or dilations must be 1. Got strides ".concat(o, " and dilations '1'"));
  var u = computePool2DInfo$1(a.shape, s, o, 1, i, l);
  if (1 === u.filterWidth && 1 === u.filterHeight && arraysEqual$1(u.inShape, u.outShape)) return identity$3({
    inputs: {
      x: a
    },
    backend: n
  });
  var c = new Pool2DProgram$1(u, "max", !1);
  return n.runWebGLProgram(c, [a], a.dtype);
}

var maxPoolConfig$2 = {
  kernelName: MaxPool$1,
  backendName: "webgl",
  kernelFunc: maxPool$3
};

function maxPool3d$2(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    filterSize: s,
    strides: o,
    pad: i,
    dataFormat: l,
    dimRoundingMode: u
  } = r,
      c = computePool3DInfo$1(a.shape, s, o, [1, 1, 1], i, u, l),
      p = new Pool3DProgram$1(c, "max", !1);
  return n.runWebGLProgram(p, [a], a.dtype);
}

var maxPool3DConfig$2 = {
  kernelName: MaxPool3D$1,
  backendName: "webgl",
  kernelFunc: maxPool3d$2
};

class MaxPool2DBackpropProgram$1 {
  constructor(e) {
    this.variableNames = ["dy", "maxPos"], this.outputShape = e.inShape;
    var t = e.effectiveFilterHeight,
        n = e.effectiveFilterWidth;
    this.userCode = "\n      const ivec2 pads = ivec2(".concat(t - 1 - e.padInfo.top, ", ").concat(n - 1 - e.padInfo.left, ");\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n\n        ivec2 dyRCCorner = coords.yz - pads;\n        int dyRCorner = dyRCCorner.x;\n        int dyCCorner = dyRCCorner.y;\n\n        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ").concat(t, ";\n          wR += ").concat(e.dilationHeight, ") {\n          float dyR = float(dyRCorner + wR) / ").concat(e.strideHeight, ".0;\n\n          if (dyR < 0.0 || dyR >= ").concat(e.outHeight, ".0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          for (int wC = 0; wC < ").concat(n, "; wC++) {\n            float dyC = float(dyCCorner + wC) / ").concat(e.strideWidth, ".0;\n\n            if (dyC < 0.0 || dyC >= ").concat(e.outWidth, ".0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            float dyValue = getDy(b, idyR, idyC, d);\n            int maxPosValue = ").concat(t * n - 1, " - int(getMaxPos(b, idyR, idyC, d));\n\n            // Get the current value, check it against the value from the\n            // position matrix.\n            int curPosValue = wR * ").concat(n, " + wC;\n            float mask = float(maxPosValue == curPosValue ? 1.0 : 0.0);\n\n            dotProd += dyValue * mask;\n          }\n        }\n        setOutput(dotProd);\n      }\n    ");
  }

}

class MaxPool3DBackpropProgram$1 {
  constructor(e) {
    this.variableNames = ["dy", "maxPos"], this.outputShape = e.inShape;
    var t = e.effectiveFilterDepth,
        n = e.effectiveFilterHeight,
        r = e.effectiveFilterWidth;
    this.userCode = "\n      const ivec3 pads = ivec3(".concat(t - 1 - e.padInfo.front, ", ").concat(n - 1 - e.padInfo.top, ", ").concat(r - 1 - e.padInfo.left, ");\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int ch = coords.u;\n\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\n        int dyDCorner = dyCorner.x;\n        int dyRCorner = dyCorner.y;\n        int dyCCorner = dyCorner.z;\n\n        // Convolve dy(?, ?, ?, ch) with pos mask(:, :, :, d) to get\n        // dx(xD, xR, xC, ch).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n\n        for (int wD = 0; wD < ").concat(t, ";\n           wD += ").concat(e.dilationDepth, ") {\n          float dyD = float(dyDCorner + wD) / ").concat(e.strideDepth, ".0;\n\n          if (dyD < 0.0 || dyD >= ").concat(e.outDepth, ".0 || fract(dyD) > 0.0) {\n            continue;\n          }\n          int idyD = int(dyD);\n\n          for (int wR = 0; wR < ").concat(n, ";\n              wR += ").concat(e.dilationHeight, ") {\n            float dyR = float(dyRCorner + wR) / ").concat(e.strideHeight, ".0;\n\n            if (dyR < 0.0 || dyR >= ").concat(e.outHeight, ".0 ||\n                fract(dyR) > 0.0) {\n              continue;\n            }\n            int idyR = int(dyR);\n\n            for (int wC = 0; wC < ").concat(r, ";\n                wC += ").concat(e.dilationWidth, ") {\n              float dyC = float(dyCCorner + wC) / ").concat(e.strideWidth, ".0;\n\n              if (dyC < 0.0 || dyC >= ").concat(e.outWidth, ".0 ||\n                  fract(dyC) > 0.0) {\n                continue;\n              }\n              int idyC = int(dyC);\n\n              float dyValue = getDy(batch, idyD, idyR, idyC, ch);\n              int maxPosValue = ").concat(t * n * r - 1, " -\n                  int(getMaxPos(batch, idyD, idyR, idyC, ch));\n\n              // Get the current value, check it against the value from the\n              // position matrix.\n              int curPosValue =\n                  wD * ").concat(n, " * ").concat(r, " +\n                  wR * ").concat(r, " + wC;\n              float mask = float(maxPosValue == curPosValue ? 1.0 : 0.0);\n\n              dotProd += dyValue * mask;\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    ");
  }

}

function maxPool3DGrad$2(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    dy: a,
    input: s
  } = t,
      o = s,
      {
    filterSize: i,
    strides: l,
    pad: u,
    dimRoundingMode: c
  } = r,
      p = computePool3DInfo$1(o.shape, i, l, [1, 1, 1], u, c),
      d = new Pool3DProgram$1(p, "max", !0),
      h = n.runWebGLProgram(d, [o], o.dtype),
      m = new MaxPool3DBackpropProgram$1(p),
      f = n.runWebGLProgram(m, [a, h], o.dtype);
  return n.disposeIntermediateTensorInfo(h), f;
}

var maxPoolGrad3DConfig$1 = {
  kernelName: MaxPool3DGrad$1,
  backendName: "webgl",
  kernelFunc: maxPool3DGrad$2
};

function maxPoolGrad$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    dy: a,
    input: s,
    output: o
  } = t,
      i = s;
  assertNotComplex$2([s, o], "maxPoolGrad");
  var {
    filterSize: l,
    strides: u,
    pad: c,
    dimRoundingMode: p
  } = r,
      d = computePool2DInfo$1(i.shape, l, u, 1, c, p),
      h = new Pool2DProgram$1(d, "max", !0),
      m = n.runWebGLProgram(h, [i], i.dtype),
      f = new MaxPool2DBackpropProgram$1(d),
      g = n.runWebGLProgram(f, [a, m], i.dtype);
  return n.disposeIntermediateTensorInfo(m), g;
}

var maxPoolGradConfig$3 = {
  kernelName: MaxPoolGrad$1,
  backendName: "webgl",
  kernelFunc: maxPoolGrad$3
};

function maxPoolWithArgmaxImpl$2(e, t, n, r) {
  var a = new Pool2DProgram$1(n, "max", !1);
  var s = r.runWebGLProgram(a, [e], "float32");
  return a = new Pool2DProgram$1(n, "max", !0, !0, t), [s, r.runWebGLProgram(a, [e], "float32")];
}

var maxPoolWithArgmaxConfig$2 = {
  kernelName: MaxPoolWithArgmax$1,
  backendName: "webgl",
  kernelFunc: _ref23 => {
    var {
      inputs: e,
      attrs: t,
      backend: n
    } = _ref23;
    var {
      x: r
    } = e,
        {
      filterSize: a,
      strides: s,
      pad: o,
      includeBatchInIndex: i
    } = t,
        l = n;
    assert$6(4 === r.shape.length, () => "Error in maxPool: input must be rank 4 but got rank ".concat(r.shape.length, "."));
    var u = [1, 1];
    assert$6(eitherStridesOrDilationsAreOne$1(s, u), () => "Error in maxPool: Either strides or dilations must be 1. Got strides ".concat(s, " and dilations '").concat(u, "'"));
    var c = computePool2DInfo$1(r.shape, a, s, u, o),
        [p, d] = maxPoolWithArgmaxImpl$2(r, i, c, l);
    return [p, d];
  }
};

function meanImpl$1(e, t, n, r) {
  var a = sizeFromShape$1(t),
      s = reshape$4({
    inputs: {
      x: e
    },
    attrs: {
      shape: [sizeFromShape$1(e.shape) / a, a]
    },
    backend: r
  }),
      o = reduce$1(s, "float32", "mean", r),
      i = reshape$4({
    inputs: {
      x: o
    },
    attrs: {
      shape: n
    },
    backend: r
  });
  return r.disposeIntermediateTensorInfo(s), r.disposeIntermediateTensorInfo(o), i;
}

var meanConfig$2 = {
  kernelName: Mean$1,
  backendName: "webgl",
  kernelFunc: _ref24 => {
    var {
      inputs: e,
      attrs: t,
      backend: n
    } = _ref24;
    var {
      x: r
    } = e,
        {
      keepDims: a,
      axis: s
    } = t,
        o = n,
        i = r.shape.length,
        l = parseAxisParam$1(s, r.shape);
    var u = l;
    var c = getAxesPermutation$1(u, i),
        p = null != c,
        d = o.shouldExecuteOnCPU([r]),
        h = [];
    var m = r;

    if (p) {
      if (d) {
        var _e491 = o.texData.get(m.dataId).values,
            _t345 = new Array(i);

        for (var _e492 = 0; _e492 < _t345.length; _e492++) {
          _t345[_e492] = r.shape[c[_e492]];
        }

        var _n214 = transposeImplCPU$1(_e491, r.shape, r.dtype, c, _t345);

        m = o.makeTensorInfo(_t345, r.dtype), o.texData.get(m.dataId).values = _n214;
      } else m = transposeImpl$2(r, c, o);

      h.push(m), u = getInnerMostAxes$1(u.length, i);
    }

    assertAxesAreInnerMostDims$1("sum", u, i);
    var [f, g] = computeOutAndReduceShapes$1(m.shape, u);
    var $ = f;
    a && ($ = expandShapeToKeepDim$1(f, l));
    var y = meanImpl$1(m, g, $, o);

    for (var _e493 of h) {
      o.disposeIntermediateTensorInfo(_e493);
    }

    return y;
  }
};

function min$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    axis: s,
    keepDims: o
  } = r,
      i = a.shape.length,
      l = parseAxisParam$1(s, a.shape);
  var u = l;
  var c = getAxesPermutation$1(u, i);
  var p = a;
  null != c && (p = transpose$3({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      perm: c
    }
  }), u = getInnerMostAxes$1(u.length, a.shape.length)), assertAxesAreInnerMostDims$1("min", u, i);
  var [d, h] = computeOutAndReduceShapes$1(p.shape, u),
      m = reshape$4({
    inputs: {
      x: p
    },
    backend: n,
    attrs: {
      shape: [-1, sizeFromShape$1(h)]
    }
  }),
      f = reduce$1(m, m.dtype, "min", n);
  var g;
  return g = reshape$4(o ? {
    inputs: {
      x: f
    },
    backend: n,
    attrs: {
      shape: expandShapeToKeepDim$1(d, l)
    }
  } : {
    inputs: {
      x: f
    },
    backend: n,
    attrs: {
      shape: d
    }
  }), n.disposeIntermediateTensorInfo(m), n.disposeIntermediateTensorInfo(f), null != c && n.disposeIntermediateTensorInfo(p), g;
}

var minConfig$2 = {
  kernelName: Min$1,
  backendName: "webgl",
  kernelFunc: min$4
},
    MINIMUM$1 = CHECK_NAN_SNIPPET$4 + "\n  return min(a, b);\n",
    MINIMUM_PACKED$1 = "\n  vec4 result = vec4(min(a, b));\n  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));\n  " + CHECK_NAN_SNIPPET$3 + "\n  return result;\n",
    minimum$4 = binaryKernelFunc$2({
  opSnippet: MINIMUM$1,
  packedOpSnippet: MINIMUM_PACKED$1,
  cpuKernelImpl: minimumImplCPU$1
}),
    minimumConfig$2 = {
  kernelName: Minimum$3,
  backendName: "webgl",
  kernelFunc: minimum$4
};

class MirrorPadProgram$1 {
  constructor(e, t, n) {
    this.variableNames = ["x"], this.outputShape = t.map((t, n) => t[0] + e[n] + t[1]);
    var r = e.length,
        a = getCoordsDataType$1(r),
        s = t.map(e => e[0]).join(","),
        o = t.map((t, n) => t[0] + e[n]).join(","),
        i = ["coords[0]", "coords[1]", "coords[2]", "coords[3]"].slice(0, r),
        l = "reflect" === n ? 0 : 1;
    this.userCode = 1 !== r ? "\n      ".concat(a, " start = ").concat(a, "(").concat(s, ");\n      ").concat(a, " end = ").concat(a, "(").concat(o, ");\n\n      void main() {\n        ").concat(a, " outC = getOutputCoords();\n        for (int i = 0; i < ").concat(r, "; i++) {\n          if (outC[i] < start[i]) {\n            outC[i] = start[i] * 2 - outC[i] - ").concat(l, ";\n          } else if(outC[i] >= end[i]) {\n            outC[i] = (end[i] - 1) * 2 - outC[i] + ").concat(l, ";\n          }\n        }\n        ").concat(a, " coords = outC - start;\n        setOutput(getX(").concat(i, "));\n      }\n    ") : "\n        int start = ".concat(s, ";\n        int end = ").concat(o, ";\n\n        void main() {\n          int outC = getOutputCoords();\n          if (outC < start) {\n            outC = start * 2 - outC - ").concat(l, ";\n          } else if(outC >= end) {\n            outC = (end - 1) * 2 - outC + ").concat(l, ";\n          }\n          setOutput(getX(outC - start));\n        }\n      ");
  }

}

class MirrorPadPackedProgram$1 {
  constructor(e, t, n) {
    this.variableNames = ["x"], this.packedInputs = !0, this.packedOutput = !0, this.outputShape = t.map((t, n) => t[0] + e[n] + t[1]);
    var r = e.length,
        a = getCoordsDataType$1(r),
        s = t.map(e => e[0]).join(","),
        o = t.map((t, n) => t[0] + e[n]).join(","),
        i = getChannels$1("rc", r),
        l = getChannels$1("source", r),
        u = "".concat(i[r - 1], " < ").concat(this.outputShape[r - 1]),
        c = 1 === r ? "source" : "vec2(".concat(l.slice(-2).join(), ")"),
        p = "reflect" === n ? 0 : 1;
    var d = "";

    if (1 === r) {
      var _e494 = "\n        ".concat(a, " source = rc;\n        if (source < start) {\n          source = start * 2 - source - ").concat(p, ";\n        } else if (source >= end) {\n          source = (end - 1) * 2 - source + ").concat(p, ";\n        }\n        source -= start;\n      ");

      d = "\n        ".concat(a, " rc = outputLoc;\n        ").concat(_e494, "\n        result[0] = getChannel(getX(").concat(l.join(), "), ").concat(c, ");\n        ").concat(i[r - 1], " += 1;\n        if(").concat(u, ") {\n          ").concat(_e494, "\n          result[1] = getChannel(getX(").concat(l.join(), "), ").concat(c, ");\n        }\n      ");
    } else {
      var _e495 = "\n        ".concat(a, " source = rc;\n        ").concat(a, " lt = ").concat(a, "(lessThan(source, start));\n        ").concat(a, " gte = ").concat(a, "(greaterThanEqual(source, end));\n        ").concat(a, " orig = 1 - (lt + gte);\n        source = orig * source +\n                lt * (start * 2 - source - ").concat(p, ") +\n                gte * ((end - 1) * 2 - source + ").concat(p, ");\n        source -= start;\n      ");

      d = "\n        ".concat(a, " rc = outputLoc;\n        ").concat(_e495, "\n        result[0] = getChannel(getX(").concat(l.join(), "), ").concat(c, ");\n        ").concat(i[r - 1], " += 1;\n        if(").concat(u, ") {\n          ").concat(_e495, "\n          result[1] = getChannel(getX(").concat(l.join(), "), ").concat(c, ");\n        }\n        rc = outputLoc;\n        ").concat(i[r - 2], " += 1;\n        if(").concat(i[r - 2], " < ").concat(this.outputShape[r - 2], ") {\n          ").concat(_e495, "\n          result[2] = getChannel(getX(").concat(l.join(), "), ").concat(c, ");\n          ").concat(i[r - 1], " += 1;\n          if(").concat(u, ") {\n            ").concat(_e495, "\n            result[3] = getChannel(getX(").concat(l.join(), "), ").concat(c, ");\n          }\n        }\n      ");
    }

    this.userCode = "\n      const ".concat(a, " start = ").concat(a, "(").concat(s, ");\n      const ").concat(a, " end = ").concat(a, "(").concat(o, ");\n\n      void main() {\n        ").concat(a, " outputLoc = getOutputCoords();\n        vec4 result = vec4(0.);\n        ").concat(d, "\n        setOutput(result);\n      }\n    ");
  }

}

var mirrorPadKernelFunc$1 = _ref25 => {
  var {
    inputs: e,
    backend: t,
    attrs: n
  } = _ref25;
  var {
    x: r
  } = e,
      {
    paddings: a,
    mode: s
  } = n,
      o = env$1().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new MirrorPadPackedProgram$1(r.shape, a, s) : new MirrorPadProgram$1(r.shape, a, s);
  return t.runWebGLProgram(o, [r], r.dtype);
},
    mirrorPadConfig$2 = {
  kernelName: MirrorPad$1,
  backendName: "webgl",
  kernelFunc: mirrorPadKernelFunc$1
},
    MOD$1 = "if (b == 0.0) return NAN;\n  return mod(a, b);",
    MOD_PACKED$1 = "\n  vec4 result = mod(a, b);\n  vec4 isNaN = vec4(equal(b, vec4(0.0)));\n  " + CHECK_NAN_SNIPPET$3 + "\n  return result;\n",
    mod$3 = binaryKernelFunc$2({
  opSnippet: MOD$1,
  packedOpSnippet: MOD_PACKED$1
}),
    modConfig$2 = {
  kernelName: Mod$1,
  backendName: "webgl",
  kernelFunc: mod$3
};

class MultinomialProgram$1 {
  constructor(e, t, n) {
    this.variableNames = ["probs"], this.customUniforms = [{
      name: "seed",
      type: "float"
    }], this.outputShape = [e, n], this.userCode = "\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n\n        float r = random(seed);\n        float cdf = 0.0;\n\n        for (int i = 0; i < ".concat(t - 1, "; i++) {\n          cdf += getProbs(batch, i);\n\n          if (r < cdf) {\n            setOutput(float(i));\n            return;\n          }\n        }\n\n        // If no other event happened, last event happened.\n        setOutput(float(").concat(t - 1, "));\n      }\n    ");
  }

}

var DIV$1 = "\nif (a == b) {\n  return 1.0;\n};\nreturn a / b;",
    DIV_PACKED$1 = "\n  // vec4 one = vec4(equal(a, b));\n  // return one + (vec4(1.0) - one) * a / b;\n  vec4 result = a / b;\n  if(a.x == b.x) {\n    result.x = 1.;\n  }\n  if(a.y == b.y) {\n    result.y = 1.;\n  }\n  if(a.z == b.z) {\n    result.z = 1.;\n  }\n  if(a.w == b.w) {\n    result.w = 1.;\n  }\n\n  return result;\n",
    realDiv$1 = binaryKernelFunc$2({
  opSnippet: DIV$1,
  packedOpSnippet: DIV_PACKED$1,
  checkOutOfBounds: !0
}),
    realDivConfig$2 = {
  kernelName: RealDiv$1,
  backendName: "webgl",
  kernelFunc: realDiv$1
},
    SUB$1 = "return a - b;",
    sub$3 = binaryKernelFunc$2({
  opSnippet: SUB$1,
  packedOpSnippet: SUB$1,
  supportsComplex: !0,
  cpuKernelImpl: subImplCPU$1
}),
    subConfig$2 = {
  kernelName: Sub$1,
  backendName: "webgl",
  kernelFunc: sub$3
};

function softmax$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    logits: a
  } = t,
      {
    dim: s
  } = r,
      o = parseAxisParam$1([s], a.shape),
      i = max$4({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      reductionIndices: o,
      keepDims: !1
    }
  }),
      l = expandShapeToKeepDim$1(i.shape, o),
      u = reshape$4({
    inputs: {
      x: i
    },
    backend: n,
    attrs: {
      shape: l
    }
  }),
      c = sub$3({
    inputs: {
      a,
      b: u
    },
    backend: n
  }),
      p = exp$3({
    inputs: {
      x: c
    },
    backend: n
  }),
      d = sum$4({
    inputs: {
      x: p
    },
    backend: n,
    attrs: {
      axis: o,
      keepDims: !1
    }
  }),
      h = reshape$4({
    inputs: {
      x: d
    },
    backend: n,
    attrs: {
      shape: l
    }
  }),
      m = realDiv$1({
    inputs: {
      a: p,
      b: h
    },
    backend: n
  });
  return n.disposeIntermediateTensorInfo(i), n.disposeIntermediateTensorInfo(u), n.disposeIntermediateTensorInfo(c), n.disposeIntermediateTensorInfo(p), n.disposeIntermediateTensorInfo(d), n.disposeIntermediateTensorInfo(h), m;
}

var softmaxConfig$2 = {
  kernelName: Softmax$5,
  backendName: "webgl",
  kernelFunc: softmax$4
};

function multinomial$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    logits: a
  } = t,
      {
    numSamples: s,
    seed: o,
    normalized: i
  } = r,
      l = i ? a : softmax$4({
    inputs: {
      logits: a
    },
    backend: n,
    attrs: {
      dim: a.shape.length - 1
    }
  }),
      u = new MultinomialProgram$1(l.shape[0], l.shape[1], s),
      c = n.runWebGLProgram(u, [l], "int32", [[o]]);
  return i || n.disposeIntermediateTensorInfo(l), c;
}

var multinomialConfig$2 = {
  kernelName: Multinomial$1,
  backendName: "webgl",
  kernelFunc: multinomial$3
},
    NEG$1 = "return -x;";

function neg$3(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    x: r
  } = t;

  if (n.shouldExecuteOnCPU([r])) {
    var _e496 = n.texData.get(r.dataId),
        [_t346, _a115] = negImplCPU$1(_e496.values, r.shape, r.dtype);

    return n.makeTensorInfo(_a115, r.dtype, _t346);
  }

  var a;
  return a = env$1().getBool("WEBGL_PACK_UNARY_OPERATIONS") ? new UnaryOpPackedProgram$1(r.shape, NEG$1) : new UnaryOpProgram$1(r.shape, NEG$1), n.runWebGLProgram(a, [r], r.dtype);
}

var negConfig$2 = {
  kernelName: Neg$1,
  backendName: "webgl",
  kernelFunc: neg$3
},
    nonMaxSuppressionV3Impl$3 = nonMaxSuppressionV3Impl$5;

function nonMaxSuppressionV3$2(e) {
  warn$1("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    boxes: a,
    scores: s
  } = t,
      {
    maxOutputSize: o,
    iouThreshold: i,
    scoreThreshold: l
  } = r,
      u = n.readSync(a.dataId),
      c = n.readSync(s.dataId),
      {
    selectedIndices: p
  } = nonMaxSuppressionV3Impl$3(u, c, o, i, l);
  return n.makeTensorInfo([p.length], "int32", new Int32Array(p));
}

var nonMaxSuppressionV3Config$2 = {
  kernelName: NonMaxSuppressionV3$1,
  backendName: "webgl",
  kernelFunc: nonMaxSuppressionV3$2
},
    nonMaxSuppressionV4Impl$3 = nonMaxSuppressionV4Impl$5;

function nonMaxSuppressionV4$2(e) {
  warn$1("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    boxes: a,
    scores: s
  } = t,
      {
    maxOutputSize: o,
    iouThreshold: i,
    scoreThreshold: l,
    padToMaxOutputSize: u
  } = r,
      c = n.readSync(a.dataId),
      p = n.readSync(s.dataId),
      {
    selectedIndices: d,
    validOutputs: h
  } = nonMaxSuppressionV4Impl$3(c, p, o, i, l, u);
  return [n.makeTensorInfo([d.length], "int32", new Int32Array(d)), n.makeTensorInfo([], "int32", new Int32Array([h]))];
}

var nonMaxSuppressionV4Config$2 = {
  kernelName: NonMaxSuppressionV4$1,
  backendName: "webgl",
  kernelFunc: nonMaxSuppressionV4$2
},
    nonMaxSuppressionV5Impl$3 = nonMaxSuppressionV5Impl$5;

function nonMaxSuppressionV5$2(e) {
  warn$1("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    boxes: a,
    scores: s
  } = t,
      {
    maxOutputSize: o,
    iouThreshold: i,
    scoreThreshold: l,
    softNmsSigma: u
  } = r,
      c = n.readSync(a.dataId),
      p = n.readSync(s.dataId),
      d = o,
      h = i,
      m = l,
      f = u,
      {
    selectedIndices: g,
    selectedScores: $
  } = nonMaxSuppressionV5Impl$3(c, p, d, h, m, f);
  return [n.makeTensorInfo([g.length], "int32", new Int32Array(g)), n.makeTensorInfo([$.length], "float32", new Float32Array($))];
}

var nonMaxSuppressionV5Config$2 = {
  kernelName: NonMaxSuppressionV5$1,
  backendName: "webgl",
  kernelFunc: nonMaxSuppressionV5$2
};

class OneHotProgram$1 {
  constructor(e, t, n, r) {
    this.variableNames = ["indices"], this.outputShape = [e, t], this.userCode = "\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int index = round(getIndices(coords.x));\n        setOutput(mix(float(".concat(r, "), float(").concat(n, "),\n                      float(index == coords.y)));\n      }\n    ");
  }

}

var oneHot$3 = e => {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    indices: a
  } = t,
      {
    depth: s,
    onValue: o,
    offValue: i
  } = r,
      l = sizeFromShape$1(a.shape),
      u = new OneHotProgram$1(l, s, o, i),
      c = reshape$4({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      shape: [l]
    }
  }),
      p = n.runWebGLProgram(u, [c], a.dtype);
  n.disposeIntermediateTensorInfo(c);
  var d = reshape$4({
    inputs: {
      x: p
    },
    backend: n,
    attrs: {
      shape: [...a.shape, s]
    }
  });
  return n.disposeIntermediateTensorInfo(p), d;
},
    oneHotConfig$2 = {
  kernelName: OneHot$1,
  backendName: "webgl",
  kernelFunc: oneHot$3
};

function zerosLike$3(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    x: r
  } = t;

  if ("complex64" === r.dtype) {
    var _e497 = real$3({
      inputs: {
        input: r
      },
      backend: n
    }),
        _t347 = zerosLike$3({
      inputs: {
        x: _e497
      },
      backend: n
    }),
        a = imag$3({
      inputs: {
        input: r
      },
      backend: n
    }),
        s = zerosLike$3({
      inputs: {
        x: a
      },
      backend: n
    }),
        o = complex$3({
      inputs: {
        real: _t347,
        imag: s
      },
      backend: n
    });

    return n.disposeIntermediateTensorInfo(_e497), n.disposeIntermediateTensorInfo(_t347), n.disposeIntermediateTensorInfo(a), n.disposeIntermediateTensorInfo(s), o;
  }

  return fill$3({
    attrs: {
      shape: r.shape,
      dtype: r.dtype,
      value: "string" === r.dtype ? "" : 0
    },
    backend: n
  });
}

var zerosLikeConfig$2 = {
  kernelName: ZerosLike$1,
  backendName: "webgl",
  kernelFunc: zerosLike$3
};

function onesLike$3(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    x: r
  } = t;
  if ("string" === r.dtype) throw new Error("onesLike is not supported under string dtype");

  if ("complex64" === r.dtype) {
    var _e498 = real$3({
      inputs: {
        input: r
      },
      backend: n
    }),
        _t348 = onesLike$3({
      inputs: {
        x: _e498
      },
      backend: n
    }),
        a = imag$3({
      inputs: {
        input: r
      },
      backend: n
    }),
        s = zerosLike$3({
      inputs: {
        x: a
      },
      backend: n
    }),
        o = complex$3({
      inputs: {
        real: _t348,
        imag: s
      },
      backend: n
    });

    return n.disposeIntermediateTensorInfo(_e498), n.disposeIntermediateTensorInfo(_t348), n.disposeIntermediateTensorInfo(a), n.disposeIntermediateTensorInfo(s), o;
  }

  return fill$3({
    attrs: {
      shape: r.shape,
      dtype: r.dtype,
      value: 1
    },
    backend: n
  });
}

var onesLikeConfig$2 = {
  kernelName: OnesLike$1,
  backendName: "webgl",
  kernelFunc: onesLike$3
};

function pack$2(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    axis: a
  } = r;
  if (1 === t.length) return expandDims$4({
    inputs: {
      input: t[0]
    },
    backend: n,
    attrs: {
      dim: a
    }
  });
  var s = t[0].shape,
      o = t[0].dtype;
  t.forEach(e => {
    assertShapesMatch$1(s, e.shape, "All tensors passed to stack must have matching shapes"), assert$6(o === e.dtype, () => "All tensors passed to stack must have matching dtypes");
  });
  var i = [],
      l = concat$3({
    inputs: t.map(e => {
      var t = expandDims$4({
        inputs: {
          input: e
        },
        backend: n,
        attrs: {
          dim: a
        }
      });
      return i.push(t), t;
    }),
    backend: n,
    attrs: {
      axis: a
    }
  });
  return i.forEach(e => n.disposeIntermediateTensorInfo(e)), l;
}

var packConfig$2 = {
  kernelName: Pack$1,
  backendName: "webgl",
  kernelFunc: pack$2
};

class PadProgram$1 {
  constructor(e, t, n) {
    this.variableNames = ["x"], this.customUniforms = [{
      name: "value",
      type: "float"
    }], this.outputShape = t.map((t, n) => t[0] + e[n] + t[1]);
    var r = e.length,
        a = getCoordsDataType$1(r),
        s = t.map(e => e[0]).join(","),
        o = t.map((t, n) => t[0] + e[n]).join(","),
        i = ["coords[0]", "coords[1]", "coords[2]", "coords[3]"].slice(0, r);
    this.userCode = 1 !== r ? "\n      ".concat(a, " start = ").concat(a, "(").concat(s, ");\n      ").concat(a, " end = ").concat(a, "(").concat(o, ");\n\n      void main() {\n        ").concat(a, " outC = getOutputCoords();\n        if (any(lessThan(outC, start)) || any(greaterThanEqual(outC, end))) {\n          setOutput(value);\n        } else {\n          ").concat(a, " coords = outC - start;\n          setOutput(getX(").concat(i, "));\n        }\n      }\n    ") : "\n        int start = ".concat(s, ";\n        int end = ").concat(o, ";\n\n        void main() {\n          int outC = getOutputCoords();\n          if (outC < start || outC >= end) {\n            setOutput(value);\n          } else {\n            setOutput(getX(outC - start));\n          }\n        }\n      ");
  }

}

class PadPackedProgram$1 {
  constructor(e, t, n) {
    this.variableNames = ["x"], this.packedInputs = !0, this.packedOutput = !0, this.customUniforms = [{
      name: "value",
      type: "float"
    }], this.outputShape = t.map((t, n) => t[0] + e[n] + t[1]);
    var r = e.length,
        a = getCoordsDataType$1(r),
        s = t.map(e => e[0]).join(","),
        o = t.map((t, n) => t[0] + e[n]).join(","),
        i = getChannels$1("rc", r),
        l = getChannels$1("source", r),
        u = "".concat(i[r - 1], " < ").concat(this.outputShape[r - 1]),
        c = 1 === r ? "source" : "vec2(".concat(l.slice(-2).join(), ")"),
        p = ["".concat(a, " rc = outputLoc;"), "".concat(i[r - 1], " += 1;\n       if(").concat(u, ") {\n      "), 1 === r ? "" : "}\n       rc = outputLoc;\n       ".concat(i[r - 2], " += 1;\n       if(").concat(i[r - 2], " < ").concat(this.outputShape[r - 2], ") {"), 1 === r ? "" : "  ".concat(i[r - 1], " += 1;\n         if(").concat(u, ") {")],
        d = 1 === r ? "rc < start || rc >= end" : "any(lessThan(rc, start)) || any(greaterThanEqual(rc, end))";
    var h = "";

    for (var _e499 = 0, _t349 = 1 === r ? 2 : 4; _e499 < _t349; _e499++) {
      h += "\n        ".concat(p[_e499], "\n        if (").concat(d, ") {\n          result[").concat(_e499, "] = float(value);\n        } else {\n          ").concat(a, " source = rc - start;\n          result[").concat(_e499, "] = getChannel(getX(").concat(l.join(), "), ").concat(c, ");\n        }\n      ");
    }

    h += 1 === r ? "} " : "}}", this.userCode = "\n      const ".concat(a, " start = ").concat(a, "(").concat(s, ");\n      const ").concat(a, " end = ").concat(a, "(").concat(o, ");\n\n      void main() {\n        ").concat(a, " outputLoc = getOutputCoords();\n        vec4 result = vec4(0.);\n        ").concat(h, "\n        setOutput(result);\n      }\n    ");
  }

}

var padV2$2 = e => {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    paddings: s,
    constantValue: o
  } = r,
      i = env$1().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new PadPackedProgram$1(a.shape, s, o) : new PadProgram$1(a.shape, s, o);
  return n.runWebGLProgram(i, [a], a.dtype, [[o]]);
},
    padV2Config$2 = {
  kernelName: PadV2$1,
  backendName: "webgl",
  kernelFunc: padV2$2
},
    POW$1 = "\n  if(a < 0.0 && floor(b) < b){\n    return NAN;\n  }\n  if (b == 0.0) {\n    return 1.0;\n  }\n  return (round(mod(b, 2.0)) != 1) ?\n      pow(abs(a), b) : sign(a) * pow(abs(a), b);\n",
    POW_PACKED$1 = "\n  // isModRound1 has 1 for components with round(mod(b, 2.0)) == 1, 0 otherwise.\n  vec4 isModRound1 = vec4(equal(round(mod(b, 2.0)), ivec4(1)));\n  vec4 multiplier = sign(a) * isModRound1 + (vec4(1.0) - isModRound1);\n  vec4 result = multiplier * pow(abs(a), b);\n\n  // Ensure that a^0 = 1, including 0^0 = 1 as this correspond to TF and JS\n  bvec4 isExpZero = equal(b, vec4(0.0));\n  result.r = isExpZero.r ? 1.0 : result.r;\n  result.g = isExpZero.g ? 1.0 : result.g;\n  result.b = isExpZero.b ? 1.0 : result.b;\n  result.a = isExpZero.a ? 1.0 : result.a;\n\n  vec4 isNaN = vec4(lessThan(a, vec4(0.0))) * vec4(lessThan(floor(b), b));\n  " + CHECK_NAN_SNIPPET$3 + "\n  return result;\n",
    pow$3 = binaryKernelFunc$2({
  opSnippet: POW$1,
  packedOpSnippet: POW_PACKED$1
}),
    powConfig$2 = {
  kernelName: Pow$1,
  backendName: "webgl",
  kernelFunc: pow$3
};

function prod$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    axis: s,
    keepDims: o
  } = r,
      i = a.shape.length,
      l = [],
      u = parseAxisParam$1(s, a.shape);
  var c = u;
  var p = getAxesPermutation$1(c, i);
  var d,
      h = a;

  if (null != p && (h = transpose$3({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      perm: p
    }
  }), c = getInnerMostAxes$1(c.length, i), l.push(h)), assertAxesAreInnerMostDims$1("prod", c, i), n.shouldExecuteOnCPU([h])) {
    var _e500 = n.texData.get(h.dataId).values,
        {
      outVals: _t350,
      outShape: _r169,
      outDtype: _a116
    } = prodImplCPU$1(h.shape, h.dtype, _e500, c);
    d = n.makeTensorInfo(_r169, _a116, _t350);
  } else {
    var [_e501, _t351] = computeOutAndReduceShapes$1(h.shape, c),
        _r170 = sizeFromShape$1(_t351),
        _s87 = reshape$4({
      inputs: {
        x: h
      },
      backend: n,
      attrs: {
        shape: [-1, _r170]
      }
    }),
        _o63 = reduce$1(_s87, sumOutType$1(a.dtype), "prod", n);

    d = reshape$4({
      inputs: {
        x: _o63
      },
      backend: n,
      attrs: {
        shape: _e501
      }
    }), l.push(_s87), l.push(_o63);
  }

  if (o) {
    l.push(d);

    var _e502 = expandShapeToKeepDim$1(d.shape, u);

    d = reshape$4({
      inputs: {
        x: d
      },
      backend: n,
      attrs: {
        shape: _e502
      }
    });
  }

  return l.forEach(e => n.disposeIntermediateTensorInfo(e)), d;
}

var prodConfig$2 = {
  kernelName: Prod$1,
  backendName: "webgl",
  kernelFunc: prod$3
},
    range$5 = e => {
  var {
    backend: t,
    attrs: n
  } = e,
      {
    start: r,
    stop: a,
    step: s,
    dtype: o
  } = n,
      i = rangeImplCPU$1(r, a, s, o);
  return t.makeTensorInfo([i.length], o, i);
},
    rangeConfig$2 = {
  kernelName: Range$1,
  backendName: "webgl",
  kernelFunc: range$5
},
    RECIPROCAL$1 = "return 1.0 / x;",
    reciprocal$3 = unaryKernelFunc$2({
  opSnippet: RECIPROCAL$1
}),
    reciprocalConfig$2 = {
  kernelName: Reciprocal$1,
  backendName: "webgl",
  kernelFunc: reciprocal$3
},
    RELU$3 = CHECK_NAN_SNIPPET$5 + "\n  return (x < 0.0) ? 0.0 : x;\n",
    RELU_PACKED$1 = "\n  vec4 result = x * vec4(greaterThanEqual(x, vec4(0.0)));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n",
    relu$4 = unaryKernelFunc$2({
  opSnippet: RELU$3,
  packedOpSnippet: RELU_PACKED$1
}),
    reluConfig$2 = {
  kernelName: Relu$3,
  backendName: "webgl",
  kernelFunc: relu$4
},
    RELU6$3 = CHECK_NAN_SNIPPET$5 + "\n  return (x < 0.0) ? 0.0 : min(6.0, x);\n",
    RELU6_PACKED$1 = "\n  vec4 result = min(x, vec4(6.)) * vec4(greaterThanEqual(x, vec4(0.0)));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n",
    relu6$3 = unaryKernelFunc$2({
  opSnippet: RELU6$3,
  packedOpSnippet: RELU6_PACKED$1
}),
    relu6Config$2 = {
  kernelName: Relu6$3,
  backendName: "webgl",
  kernelFunc: relu6$3
};

class ResizeBilinearProgram$1 {
  constructor(e, t, n, r, a) {
    this.variableNames = ["A"], this.outputShape = [];
    var [s, o, i, l] = e;
    this.outputShape = [s, t, n, l];
    var u = [r && t > 1 ? o - 1 : o, r && n > 1 ? i - 1 : i],
        c = [r && t > 1 ? t - 1 : t, r && n > 1 ? n - 1 : n];
    var p;
    p = a ? "(vec2(yRC) + vec2(0.5)) * effectiveInputOverOutputRatioRC - vec2(0.5)" : "vec2(yRC) * effectiveInputOverOutputRatioRC", this.userCode = "\n      const vec2 effectiveInputOverOutputRatioRC = vec2(\n          ".concat(u[0] / c[0], ",\n          ").concat(u[1] / c[1], ");\n      const vec2 inputShapeRC = vec2(").concat(o, ".0, ").concat(i, ".0);\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        ivec2 yRC = coords.yz;\n\n        // Fractional source index.\n        vec2 sourceFracIndexRC = ").concat(p, ";\n\n        // Compute the four integer indices.\n        ivec2 sourceFloorRC = ivec2(max(sourceFracIndexRC, vec2(0.0)));\n        ivec2 sourceCeilRC = ivec2(\n          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));\n\n        float topLeft = getA(b, sourceFloorRC.x, sourceFloorRC.y, d);\n        float bottomLeft = getA(b, sourceCeilRC.x, sourceFloorRC.y, d);\n        float topRight = getA(b, sourceFloorRC.x, sourceCeilRC.y, d);\n        float bottomRight = getA(b, sourceCeilRC.x, sourceCeilRC.y, d);\n\n        vec2 fracRC = sourceFracIndexRC - vec2(sourceFloorRC);\n\n        float top = topLeft + (topRight - topLeft) * fracRC.y;\n        float bottom = bottomLeft + (bottomRight - bottomLeft) * fracRC.y;\n        float newValue = top + (bottom - top) * fracRC.x;\n\n        setOutput(newValue);\n      }\n    ");
  }

}

class ResizeBilinearPackedProgram$1 {
  constructor(e, t, n, r, a) {
    this.variableNames = ["A"], this.packedInputs = !0, this.packedOutput = !0, this.outputShape = [];
    var [s, o, i, l] = e;
    this.outputShape = [s, t, n, l];
    var u = [r && t > 1 ? o - 1 : o, r && n > 1 ? i - 1 : i],
        c = [r && t > 1 ? t - 1 : t, r && n > 1 ? n - 1 : n];
    var p;
    p = a ? "(vec3(yRC) + vec3(0.5)) * effectiveInputOverOutputRatioRC - vec3(0.5)" : "vec3(yRC) * effectiveInputOverOutputRatioRC", this.userCode = "\n      const vec3 effectiveInputOverOutputRatioRC = vec3(\n          ".concat(u[0] / c[0], ",\n          ").concat(u[1] / c[1], ",\n          ").concat(u[1] / c[1], ");\n      const vec3 inputShapeRC = vec3(").concat(o, ".0, ").concat(i, ".0,\n                                     ").concat(i, ".0);\n\n      float getAValue(int b, int r, int c, int d) {\n        return getChannel(getA(b, r, c, d), vec2(c, d));\n      }\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        // Calculate values for next column in yRC.z.\n        ivec3 yRC = coords.yzz + ivec3(0, 0, 1);\n\n        // Fractional source index.\n        vec3 sourceFracIndexRC = ").concat(p, ";\n\n        // Compute the four integer indices.\n        ivec3 sourceFloorRC = ivec3(max(sourceFracIndexRC, vec3(0.0)));\n        ivec3 sourceCeilRC = ivec3(\n          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));\n\n        // Should we calculate next column and row elements in 2x2 packed cell.\n        bool hasNextCol = d < ").concat(l - 1, ";\n        bool hasNextRow = coords.z < ").concat(n - 1, ";\n\n        // In parallel, construct four corners for all four components in\n        // packed 2x2 cell.\n        vec4 topLeft = vec4(\n          getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d),\n          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d + 1) : 0.0);\n\n        vec4 bottomLeft = vec4(\n          getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d),\n          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d + 1) : 0.0);\n\n        vec4 topRight = vec4(\n          getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d),\n          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d + 1) : 0.0);\n\n        vec4 bottomRight = vec4(\n          getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d),\n          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d + 1) : 0.0);\n\n        vec3 fracRC = sourceFracIndexRC - vec3(sourceFloorRC);\n\n        vec4 top = mix(topLeft, topRight, fracRC.yyzz);\n        vec4 bottom = mix(bottomLeft, bottomRight, fracRC.yyzz);\n        vec4 newValue = mix(top, bottom, fracRC.x);\n\n        setOutput(newValue);\n      }\n    ");
  }

}

function resizeBilinear$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    images: a
  } = t,
      {
    alignCorners: s,
    halfPixelCenters: o,
    size: i
  } = r,
      [l, u] = i,
      c = env$1().getBool("WEBGL_PACK_IMAGE_OPERATIONS") ? new ResizeBilinearPackedProgram$1(a.shape, l, u, s, o) : new ResizeBilinearProgram$1(a.shape, l, u, s, o);
  return n.runWebGLProgram(c, [a], "float32");
}

var resizeBilinearConfig$2 = {
  kernelName: ResizeBilinear$1,
  backendName: "webgl",
  kernelFunc: resizeBilinear$3
};

class ResizeBilinearBackpropProgram$1 {
  constructor(e, t, n) {
    this.variableNames = ["dy"], this.outputShape = [], this.outputShape = t;
    var [, r, a] = t,
        [, s, o] = e,
        i = [n && s > 1 ? r - 1 : r, n && o > 1 ? a - 1 : a],
        l = [n && s > 1 ? s - 1 : s, n && o > 1 ? o - 1 : o],
        u = i[0] / l[0],
        c = i[1] / l[1],
        p = 1 / u,
        d = 1 / c,
        h = 2 * Math.ceil(p) + 2,
        m = 2 * Math.ceil(d) + 2;
    this.userCode = "\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        int r = coords[1];\n        int c = coords[2];\n\n        float accumulator = 0.0;\n\n        const float heightScale = float(".concat(u, ");\n        const float widthScale = float(").concat(c, ");\n\n        const float invHeightScale = float(").concat(p, ");\n        const float invWidthScale = float(").concat(d, ");\n\n        const int winHeight = int(").concat(h, ");\n        const int winWidth = int(").concat(m, ");\n\n        // Compute bounds for where in dy we will look\n        float startRLerp = floor(float(r) * invHeightScale);\n        int startDyR = int(startRLerp - float(winHeight / 2));\n\n        float startCLerp = floor(float(c) * invWidthScale);\n        int startDyC = int(startCLerp - float(winWidth / 2));\n\n        // Loop over dy\n        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {\n          int dyR = dyROffset + startDyR;\n\n          // Guard against the window exceeding the bounds of dy\n          if (dyR < 0 || dyR >= ").concat(s, ") {\n            continue;\n          }\n\n          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {\n            int dyC = dyCOffset + startDyC;\n\n            // Guard against the window exceeding the bounds of dy\n            if (dyC < 0 || dyC >= ").concat(o, ") {\n              continue;\n            }\n\n            float dxR = float(dyR) * heightScale;\n            int topDxRIndex = int(floor(dxR));\n            int bottomDxRIndex = int(min(ceil(dxR), ").concat(r - 1, ".0));\n            float dxRLerp = dxR - float(topDxRIndex);\n            float inverseDxRLerp = 1.0 - dxRLerp;\n\n            float dxC = float(dyC) * widthScale;\n            int leftDxCIndex = int(floor(dxC));\n            int rightDxCIndex = int(min(ceil(dxC), ").concat(a - 1, ".0));\n            float dxCLerp = dxC - float(leftDxCIndex);\n            float inverseDxCLerp = 1.0 - dxCLerp;\n\n            if (r == topDxRIndex && c == leftDxCIndex) {\n              // topLeft\n              accumulator +=\n                getDy(b, dyR, dyC, d) * inverseDxRLerp * inverseDxCLerp;\n            }\n\n            if (r == topDxRIndex && c == rightDxCIndex) {\n              // topRight\n              accumulator += getDy(b, dyR, dyC, d) * inverseDxRLerp * dxCLerp;\n            }\n\n            if (r == bottomDxRIndex && c == leftDxCIndex) {\n              // bottomLeft\n              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * inverseDxCLerp;\n            }\n\n            if (r == bottomDxRIndex && c == rightDxCIndex) {\n              // bottomRight\n              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * dxCLerp;\n            }\n          }\n        }\n        // End loop over dy\n\n        setOutput(accumulator);\n      }\n    ");
  }

}

function resizeBilinearGrad$2(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    images: a,
    dy: s
  } = t,
      {
    alignCorners: o
  } = r,
      i = new ResizeBilinearBackpropProgram$1(s.shape, a.shape, o);
  return n.runWebGLProgram(i, [s], s.dtype);
}

var resizeBilinearGradConfig$3 = {
  kernelName: ResizeBilinearGrad$1,
  backendName: "webgl",
  kernelFunc: resizeBilinearGrad$2
};

class ResizeNearestNeighborProgram$1 {
  constructor(e, t, n, r, a) {
    this.variableNames = ["A"], this.outputShape = [];
    var [s, o, i, l] = e;
    this.outputShape = [s, t, n, l];
    var u = [r && t > 1 ? o - 1 : o, r && n > 1 ? i - 1 : i],
        c = [r && t > 1 ? t - 1 : t, r && n > 1 ? n - 1 : n];
    var p;
    p = a ? "max((vec2(yRC) + vec2(0.5)) * effectiveInputOverOutputRatioRC, vec2(0.0))" : "vec2(yRC) * effectiveInputOverOutputRatioRC", this.userCode = "\n      const vec2 effectiveInputOverOutputRatioRC = vec2(\n          ".concat(u[0] / c[0], ",\n          ").concat(u[1] / c[1], ");\n      const vec2 inputShapeRC = vec2(").concat(o, ".0, ").concat(i, ".0);\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        ivec2 yRC = coords.yz;\n\n        // Fractional source index.\n        vec2 sourceFracIndexRC = ").concat(p, ";\n\n        // Compute the coordinators of nearest neighbor point.\n        ivec2 sourceNearestRC = ivec2(\n          min(inputShapeRC - 1.0, floor(sourceFracIndexRC + ").concat(r ? "0.5" : "0.0", ")));\n        float newValue = getA(b, sourceNearestRC.x, sourceNearestRC.y, d);\n\n        setOutput(newValue);\n      }\n    ");
  }

}

class ResizeNearestNeighborPackedProgram$1 {
  constructor(e, t, n, r, a) {
    this.variableNames = ["A"], this.packedInputs = !0, this.packedOutput = !0, this.outputShape = [];
    var [s, o, i, l] = e;
    this.outputShape = [s, t, n, l];
    var u = [r && t > 1 ? o - 1 : o, r && n > 1 ? i - 1 : i],
        c = [r && t > 1 ? t - 1 : t, r && n > 1 ? n - 1 : n];
    var p;
    p = a ? "max((vec3(yRC) + vec3(0.5)) * effectiveInputOverOutputRatioRC, vec3(0.0))" : "vec3(yRC) * effectiveInputOverOutputRatioRC", this.userCode = "\n      const vec3 effectiveInputOverOutputRatioRC = vec3(\n          ".concat(u[0] / c[0], ",\n          ").concat(u[1] / c[1], ",\n          ").concat(u[1] / c[1], ");\n      const vec3 inputShapeRC = vec3(").concat(o, ".0, ").concat(i, ".0,\n                                     ").concat(i, ".0);\n\n      float getAValue(int b, int r, int c, int d) {\n        return getChannel(getA(b, r, c, d), vec2(c, d));\n      }\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        // Calculate values for next column in yRC.z.\n        ivec3 yRC = coords.yzz + ivec3(0, 0, 1);\n\n        // Fractional source index.\n        vec3 sourceFracIndexRC = ").concat(p, ";\n\n        // Compute the coordinators of nearest neighbor point.\n        ivec3 sourceNearestRC = ivec3(\n          min(inputShapeRC - 1.0, floor(sourceFracIndexRC + ").concat(r ? "0.5" : "0.0", ")));\n\n        // Should we calculate next column and row elements in 2x2 packed cell.\n        bool hasNextCol = d < ").concat(l - 1, ";\n        bool hasNextRow = coords.z < ").concat(n - 1, ";\n\n        vec4 newValue = vec4(\n          getAValue(b, sourceNearestRC.x, sourceNearestRC.y, d),\n          hasNextCol ? getAValue(b, sourceNearestRC.x, sourceNearestRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceNearestRC.x, sourceNearestRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceNearestRC.x, sourceNearestRC.z, d + 1) : 0.0);\n\n        setOutput(newValue);\n      }\n    ");
  }

}

function resizeNearestNeighbor$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    images: a
  } = t,
      {
    alignCorners: s,
    halfPixelCenters: o,
    size: i
  } = r,
      [l, u] = i,
      c = env$1().getBool("WEBGL_PACK_IMAGE_OPERATIONS") ? new ResizeNearestNeighborPackedProgram$1(a.shape, l, u, s, o) : new ResizeNearestNeighborProgram$1(a.shape, l, u, s, o);
  return n.runWebGLProgram(c, [a], a.dtype);
}

var resizeNearestNeighborConfig$2 = {
  kernelName: ResizeNearestNeighbor$1,
  backendName: "webgl",
  kernelFunc: resizeNearestNeighbor$3
};

class ResizeNearestNeigborBackpropProgram$1 {
  constructor(e, t, n) {
    this.variableNames = ["dy"], this.outputShape = [], this.outputShape = t;
    var [, r, a] = t,
        [, s, o] = e,
        i = [n && s > 1 ? r - 1 : r, n && o > 1 ? a - 1 : a],
        l = [n && s > 1 ? s - 1 : s, n && o > 1 ? o - 1 : o],
        u = i[0] / l[0],
        c = i[1] / l[1],
        p = 1 / u,
        d = 1 / c,
        h = 2 * Math.ceil(p) + 2,
        m = 2 * Math.ceil(d) + 2;
    this.userCode = "\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        int r = coords[1];\n        int c = coords[2];\n\n        float accumulator = 0.0;\n\n        const float heightScale = float(".concat(u, ");\n        const float widthScale = float(").concat(c, ");\n\n        const float invHeightScale = float(").concat(p, ");\n        const float invWidthScale = float(").concat(d, ");\n\n        const int winHeight = int(").concat(h, ");\n        const int winWidth = int(").concat(m, ");\n\n        // Compute bounds for where in dy we will look\n        float startRLerp = floor(float(r) * invHeightScale);\n        int startDyR = int(floor(startRLerp - float(winHeight / 2)));\n\n        float startCLerp = floor(float(c) * invWidthScale);\n        int startDyC = int(floor(startCLerp - float(winWidth / 2)));\n\n        // Loop over dy\n        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {\n          int dyR = dyROffset + startDyR;\n\n          // Guard against the window exceeding the bounds of dy\n          if (dyR < 0 || dyR >= ").concat(s, ") {\n            continue;\n          }\n\n          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {\n            int dyC = dyCOffset + startDyC;\n\n            // Guard against the window exceeding the bounds of dy\n            if (dyC < 0 || dyC >= ").concat(o, ") {\n              continue;\n            }\n\n            float sourceFracRow =\n              float(").concat(i[0], ") *\n                (float(dyR) / float(").concat(l[0], "));\n\n            float sourceFracCol =\n                float(").concat(i[1], ") *\n                  (float(dyC) / float(").concat(l[1], "));\n\n            int sourceNearestRow = int(min(\n                float(int(").concat(r, ") - 1),\n                ").concat(n, " ? float(round(sourceFracRow)) :\n                                  float(floor(sourceFracRow))));\n\n            int sourceNearestCol = int(min(\n                float(int(").concat(a, ") - 1),\n                ").concat(n, " ? float(round(sourceFracCol)) :\n                                  float(floor(sourceFracCol))));\n\n            if (r == sourceNearestRow && c == sourceNearestCol) {\n              accumulator += getDy(b, dyR, dyC, d);\n            }\n          }\n        }\n        // End loop over dy\n\n        setOutput(accumulator);\n      }\n    ");
  }

}

function resizeNearestNeighborGrad$2(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    images: a,
    dy: s
  } = t,
      {
    alignCorners: o
  } = r,
      i = new ResizeNearestNeigborBackpropProgram$1(s.shape, a.shape, o);
  return n.runWebGLProgram(i, [s], s.dtype);
}

var resizeNearestNeighborGradConfig$3 = {
  kernelName: ResizeNearestNeighborGrad$1,
  backendName: "webgl",
  kernelFunc: resizeNearestNeighborGrad$2
};

class ReverseProgram$1 {
  constructor(e, t) {
    this.variableNames = ["x"];
    var n = e.length;
    if (n > 4) throw new Error("WebGL backend: Reverse of rank-".concat(n, " tensor is not yet supported"));
    if (this.outputShape = e, 1 === n) return void (this.userCode = "\n        void main() {\n          int coord = getOutputCoords();\n          setOutput(getX(".concat(e[0], " - coord - 1));\n        }\n      "));
    var r = e.map((n, r) => (n => -1 !== t.indexOf(n) && 1 !== e[n] ? "".concat(e[n], " - coords[").concat(n, "] - 1") : "coords[".concat(n, "]"))(r)).join(","),
        a = getCoordsDataType$1(n);
    this.userCode = "\n      void main() {\n        ".concat(a, " coords = getOutputCoords();\n        setOutput(getX(").concat(r, "));\n      }\n    ");
  }

}

class ReversePackedProgram$1 {
  constructor(e, t) {
    this.variableNames = ["x"], this.packedInputs = !0, this.packedOutput = !0;
    var n = e.length;
    if (n > 4) throw new Error("WebGL backend: Reverse of rank-".concat(n, " tensor is not yet supported"));
    this.outputShape = e;
    var r = getChannels$1("rc", n),
        a = "".concat(r[n - 1], " + 1 < ").concat(this.outputShape[n - 1]),
        s = "".concat(r[n - 2], " + 1 < ").concat(this.outputShape[n - 2]),
        o = getCoordsDataType$1(n);

    function i(n) {
      var r = e.map((r, a) => function (n, r) {
        return -1 !== t.indexOf(n) && 1 !== e[n] ? "".concat(e[n], " - ").concat(r[n], " - 1") : "".concat(r[n]);
      }(a, n));
      return "getChannel(getX(".concat(r.join(","), "), vec2(").concat(r.slice(-2).join(","), "))");
    }

    this.userCode = 1 === n ? "\n        void main(){\n          int rc = getOutputCoords();\n          vec4 result = vec4(0.);\n          result.r = getChannel(getX(".concat(e[0], " - rc - 1),\n            ").concat(e[0], " - rc - 1);\n          if(").concat(a, "){\n              result.g = getChannel(getX(").concat(e[0], " - (rc  + 1) - 1),\n                ").concat(e[0], " - (rc  + 1) - 1);\n          }\n          setOutput(result);\n        }\n      ") : "\n        void main() {\n          ".concat(o, " rc = getOutputCoords();\n          vec4 result = vec4(0.);\n          result.r = ").concat(function (e) {
      return i(e);
    }(r.slice()), ";\n          if(").concat(a, "){\n            result.g = ").concat(function (e) {
      return e[n - 1] = "(" + e[n - 1] + " + 1)", i(e);
    }(r.slice()), ";\n          }\n          if(").concat(s, ") {\n            result.b = ").concat(function (e) {
      return e[n - 2] = "(" + e[n - 2] + " + 1)", i(e);
    }(r.slice()), ";\n            if(").concat(a, ") {\n              result.a = ").concat(function (e) {
      return e[n - 1] = "(" + e[n - 1] + " + 1)", e[n - 2] = "(" + e[n - 2] + " + 1)", i(e);
    }(r.slice()), ";\n            }\n          }\n          setOutput(result);\n        }\n    ");
  }

}

function reverse$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    dims: s
  } = r,
      o = a.shape.length,
      i = parseAxisParam$1(s, a.shape);
  if (0 === o) return identity$3({
    inputs: {
      x: a
    },
    backend: n
  });
  var l = env$1().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new ReversePackedProgram$1(a.shape, i) : new ReverseProgram$1(a.shape, i);
  return n.runWebGLProgram(l, [a], a.dtype);
}

var reverseConfig$2 = {
  kernelName: Reverse$1,
  backendName: "webgl",
  kernelFunc: reverse$3
};

class RotateProgram$1 {
  constructor(e, t) {
    this.variableNames = ["Image"], this.outputShape = [], this.customUniforms = [{
      name: "params",
      type: "vec4"
    }];
    var n = e[1],
        r = e[2];
    this.outputShape = e;
    var a = "";
    a = "number" == typeof t ? "float outputValue = ".concat(t.toFixed(2), ";") : "\n        vec3 fill = vec3(".concat(t.join(","), ");\n        float outputValue = fill[coords[3]];"), this.userCode = "\n        void main() {\n          ivec4 coords = getOutputCoords();\n          int x = coords[2];\n          int y = coords[1];\n          float coordXFloat = (float(x) - params[0]) * params[3] -\n            (float(y) - params[1]) * params[2];\n          float coordYFloat = (float(x) - params[0]) * params[2] +\n            (float(y) - params[1]) * params[3];\n          int coordX = int(round(coordXFloat + params[0]));\n          int coordY = int(round(coordYFloat + params[1]));\n          ".concat(a, "\n          if(coordX >= 0 && coordX < ").concat(r, " && coordY >= 0 && coordY < ").concat(n, ") {\n            outputValue = getImage(coords[0], coordY, coordX, coords[3]);\n          }\n          setOutput(outputValue);\n        }\n    ");
  }

}

var rotateWithOffsetConfig$2 = {
  kernelName: RotateWithOffset$1,
  backendName: "webgl",
  kernelFunc: _ref26 => {
    var {
      inputs: e,
      attrs: t,
      backend: n
    } = _ref26;
    var {
      image: r
    } = e,
        {
      radians: a,
      fillValue: s,
      center: o
    } = t,
        i = n,
        l = new RotateProgram$1(r.shape, s),
        [u, c] = getImageCenter$1(o, r.shape[1], r.shape[2]),
        p = [[u, c, Math.sin(a), Math.cos(a)]];
    return i.runWebGLProgram(l, [r], r.dtype, p);
  }
},
    ROUND$1 = "\n  // OpenGL ES does not support round function.\n  // The algorithm is based on banker's rounding.\n  float base = floor(x);\n  if ((x - base) < 0.5) {\n    return floor(x);\n  } else if ((x - base) > 0.5) {\n    return ceil(x);\n  } else {\n    if (mod(base, 2.0) == 0.0) {\n      return base;\n    } else {\n      return base + 1.0;\n    }\n  }\n",
    round$4 = unaryKernelFunc$2({
  opSnippet: ROUND$1
}),
    roundConfig$2 = {
  kernelName: Round$1,
  backendName: "webgl",
  kernelFunc: round$4
},
    RSQRT$1 = "return inversesqrt(x);",
    rsqrt$3 = unaryKernelFunc$2({
  opSnippet: RSQRT$1,
  cpuKernelImpl: rsqrtImplCPU$1
}),
    rsqrtConfig$2 = {
  kernelName: Rsqrt$1,
  backendName: "webgl",
  kernelFunc: rsqrt$3
};

class ScatterProgram$1 {
  constructor(e, t, n, r, a, s) {
    var o = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : !0;
    this.variableNames = ["updates", "indices", "defaultValue"], this.outputShape = s;
    var i = getCoordsDataType$1(a.length),
        l = getCoordsDataType$1(s.length);
    var u = "";
    1 === n ? u = "i" : 2 === n && (u = "i, j");
    var c = "";
    1 === r ? c = "i" : 2 === r && (c = "i, coords[1]"), this.userCode = "\n        ".concat(i, " strides = ").concat(i, "(").concat(a, ");\n\n        void main() {\n          ").concat(l, " coords = getOutputCoords();\n          float sum = 0.0;\n          bool found = false;\n          for (int i = 0; i < ").concat(e, "; i++) {\n            int flattenedIndex = 0;\n            for (int j = 0; j < ").concat(t, "; j++) {\n              int index = round(getIndices(").concat(u, "));\n              flattenedIndex += index * ").concat(t > 1 ? "strides[j]" : "strides", ";\n            }\n            if (flattenedIndex == coords[0]) {\n              sum += getUpdates(").concat(c, ");\n              found = true;\n            }\n          }\n          setOutput(mix(getDefaultValue(), sum, float(found)));\n        }\n      ");
  }

}

function scatterNd$2(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    indices: a,
    updates: s
  } = t,
      {
    shape: o
  } = r,
      {
    sliceRank: i,
    numUpdates: l,
    sliceSize: u,
    strides: c,
    outputSize: p
  } = calculateShapes$1(s, a, o),
      d = [p / u, u];
  if (0 === p) return n.makeTensorInfo(o, a.dtype);
  var h = reshape$4({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      shape: [l, i]
    }
  }),
      m = reshape$4({
    inputs: {
      x: s
    },
    backend: n,
    attrs: {
      shape: [l, u]
    }
  }),
      f = n.makeTensorInfo([], "float32", new Float32Array([0])),
      g = new ScatterProgram$1(l, i, h.shape.length, m.shape.length, c, d),
      $ = n.runWebGLProgram(g, [m, h, f], m.dtype),
      y = reshape$4({
    inputs: {
      x: $
    },
    backend: n,
    attrs: {
      shape: o
    }
  });
  return n.disposeIntermediateTensorInfo(h), n.disposeIntermediateTensorInfo(m), n.disposeIntermediateTensorInfo($), n.disposeIntermediateTensorInfo(f), y;
}

var scatterNdConfig$2 = {
  kernelName: ScatterNd$1,
  backendName: "webgl",
  kernelFunc: scatterNd$2
};

class SelectProgram$1 {
  constructor(e, t, n) {
    var r, a;
    if (this.variableNames = ["c", "a", "b"], this.outputShape = t, n > 4) throw Error("Where for rank ".concat(n, " is not yet supported"));
    if (1 === n) a = "resRC", r = "resRC";else {
      var _n215 = ["resRC.x", "resRC.y", "resRC.z", "resRC.w"],
          _s88 = [],
          o = [];

      for (var _r171 = 0; _r171 < t.length; _r171++) {
        o.push("".concat(_n215[_r171])), _r171 < e && _s88.push("".concat(_n215[_r171]));
      }

      r = _s88.join(), a = o.join();
    }
    var s = getCoordsDataType$1(n);
    this.userCode = "\n      void main() {\n        ".concat(s, " resRC = getOutputCoords();\n        float cVal = getC(").concat(r, ");\n        if (cVal >= 1.0) {\n          setOutput(getA(").concat(a, "));\n        } else {\n          setOutput(getB(").concat(a, "));\n        }\n      }\n    ");
  }

}

function select$3(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    condition: r,
    t: a,
    e: s
  } = t,
      o = new SelectProgram$1(r.shape.length, a.shape, a.shape.length);
  return n.runWebGLProgram(o, [r, a, s], upcastType$1(a.dtype, s.dtype));
}

var selectConfig$2 = {
  kernelName: Select$1,
  backendName: "webgl",
  kernelFunc: select$3
},
    SELU$1 = "\n  // Stable and Attracting Fixed Point (0, 1) for Normalized Weights.\n  // see: https://arxiv.org/abs/1706.02515\n  float scaleAlpha = ".concat(SELU_SCALEALPHA$1, ";\n  float scale = ").concat(SELU_SCALE$1, ";\n  return (x >= 0.0) ? scale * x : scaleAlpha * (exp(x) - 1.0);\n"),
    selu$3 = unaryKernelFunc$2({
  opSnippet: SELU$1
}),
    seluConfig$2 = {
  kernelName: Selu$3,
  backendName: "webgl",
  kernelFunc: selu$3
},
    SIGMOID$3 = "return 1.0 / (1.0 + exp(-1.0 * x));",
    sigmoid$3 = unaryKernelFunc$2({
  opSnippet: SIGMOID$3
}),
    sigmoidConfig$2 = {
  kernelName: Sigmoid$3,
  backendName: "webgl",
  kernelFunc: sigmoid$3
},
    SIGN$1 = "\n  if (isnan(x)) { return 0.0; }\n  return sign(x);\n",
    sign$3 = unaryKernelFunc$2({
  opSnippet: SIGN$1
}),
    signConfig$2 = {
  kernelName: Sign$1,
  backendName: "webgl",
  kernelFunc: sign$3
},
    SIN$1 = CHECK_NAN_SNIPPET_UNARY$1 + "\n  return sin(x);\n",
    sin$3 = unaryKernelFunc$2({
  opSnippet: SIN$1
}),
    sinConfig$2 = {
  kernelName: Sin$1,
  backendName: "webgl",
  kernelFunc: sin$3
},
    SINH$1 = "\n  float e2x = exp(x);\n  return (e2x - 1.0 / e2x) / 2.0;\n",
    sinh$3 = unaryKernelFunc$2({
  opSnippet: SINH$1
}),
    sinhConfig$2 = {
  kernelName: Sinh$1,
  backendName: "webgl",
  kernelFunc: sinh$3
},
    SOFTPLUS$1 = "\n  float epsilon = 1.1920928955078125e-7;\n  float threshold = log(epsilon) + 2.0;\n\n  bool too_large = x > -threshold;\n  bool too_small = x < threshold;\n\n  float result;\n  float exp_x = exp(x);\n\n  if (too_large){\n    result = x;\n  }\n  else if (too_small){\n    result = exp_x;\n  }\n  else{\n    result = log(exp_x + 1.0);\n  }\n  return result;\n",
    softplus$3 = unaryKernelFunc$2({
  opSnippet: SOFTPLUS$1
}),
    softplusConfig$2 = {
  kernelName: Softplus$3,
  backendName: "webgl",
  kernelFunc: softplus$3
},
    spaceToBatchND$3 = e => {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    blockShape: s,
    paddings: o
  } = r;
  assert$6(a.shape.length <= 4, () => "spaceToBatchND for rank > 4 with a WebGL backend not implemented yet");
  var i = s.reduce((e, t) => e * t),
      l = [[0, 0]];
  l.push(...o);

  for (var _e503 = 1 + s.length; _e503 < a.shape.length; ++_e503) {
    l.push([0, 0]);
  }

  var u = [],
      c = padV2$2({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      paddings: l,
      constantValue: 0
    }
  }),
      p = getReshaped$1(c.shape, s, i, !1),
      d = getPermuted$1(p.length, s.length, !1),
      h = getReshapedPermuted$1(c.shape, s, i, !1),
      m = reshape$4({
    inputs: {
      x: c
    },
    backend: n,
    attrs: {
      shape: p
    }
  }),
      f = transpose$3({
    inputs: {
      x: m
    },
    backend: n,
    attrs: {
      perm: d
    }
  }),
      g = reshape$4({
    inputs: {
      x: f
    },
    backend: n,
    attrs: {
      shape: h
    }
  });
  return u.push(c), u.push(m), u.push(f), u.forEach(e => n.disposeIntermediateTensorInfo(e)), g;
},
    spaceToBatchNDConfig$2 = {
  kernelName: SpaceToBatchND$1,
  backendName: "webgl",
  kernelFunc: spaceToBatchND$3
};

function sparseFillEmptyRows$3(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    indices: r,
    values: a,
    denseShape: s,
    defaultValue: o
  } = t;
  if (1 !== s.shape.length) throw new Error("Dense shape must be a vector, saw:\n         ".concat(s.shape));
  if (2 !== r.shape.length) throw new Error("Indices must be a matrix, saw:\n         ".concat(r.shape));
  if (1 !== a.shape.length) throw new Error("Values must be a vector, saw:\n         ".concat(a.shape));
  if (0 !== o.shape.length) throw new Error("Default value must be a scalar, saw:\n        ".concat(o.shape));
  var i = n.readSync(r.dataId),
      l = n.readSync(a.dataId),
      u = n.readSync(s.dataId),
      c = n.readSync(o.dataId)[0],
      [p, d, h, m, f] = sparseFillEmptyRowsImplCPU$1(i, r.shape, r.dtype, l, a.dtype, u, c);
  return [n.makeTensorInfo(d, r.dtype, p), n.makeTensorInfo([d[0]], a.dtype, h), n.makeTensorInfo([m.length], "bool", new Uint8Array(m.map(e => Number(e)))), n.makeTensorInfo([f.length], r.dtype, new Int32Array(f))];
}

var sparseFillEmptyRowsConfig$2 = {
  kernelName: SparseFillEmptyRows$1,
  backendName: "webgl",
  kernelFunc: sparseFillEmptyRows$3
};

function sparseReshape$3(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    inputIndices: r,
    inputShape: a,
    newShape: s
  } = t;
  if (2 !== r.shape.length) throw new Error("Input indices should be a matrix but received shape ".concat(r.shape));
  if (1 !== a.shape.length) throw new Error("Input shape should be a vector but received shape ".concat(a.shape));
  if (1 !== s.shape.length) throw new Error("Target shape should be a vector but received shape ".concat(s.shape));
  var o = Array.from(n.readSync(a.dataId)),
      i = n.readSync(r.dataId),
      l = Array.from(n.readSync(s.dataId)),
      [u, c, p] = sparseReshapeImplCPU$1(i, r.shape, r.dtype, o, l);
  return [n.makeTensorInfo(c, r.dtype, u), n.makeTensorInfo([p.length], s.dtype, new Int32Array(p))];
}

var sparseReshapeConfig$2 = {
  kernelName: SparseReshape$1,
  backendName: "webgl",
  kernelFunc: sparseReshape$3
};

function sparseSegmentMean$3(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    data: r,
    indices: a,
    segmentIds: s
  } = t;
  if (r.shape.length < 1) throw new Error("Data should be at least 1 dimensional but received scalar");
  if (1 !== a.shape.length) throw new Error("Indices should be a vector but received shape\n              ".concat(a.shape));
  if (1 !== s.shape.length) throw new Error("Segment ids should be a vector but received shape\n              ".concat(s.shape));
  var o = n.readSync(r.dataId),
      i = n.readSync(a.dataId),
      l = n.readSync(s.dataId),
      [u, c] = sparseSegmentReductionImplCPU$1(o, r.shape, r.dtype, i, l, !0);
  return n.makeTensorInfo(c, r.dtype, u);
}

var sparseSegmentMeanConfig$2 = {
  kernelName: SparseSegmentMean$1,
  backendName: "webgl",
  kernelFunc: sparseSegmentMean$3
};

function sparseSegmentSum$3(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    data: r,
    indices: a,
    segmentIds: s
  } = t;
  if (r.shape.length < 1) throw new Error("Data should be at least 1 dimensional but received scalar");
  if (1 !== a.shape.length) throw new Error("Indices should be a vector but received shape\n             ".concat(a.shape));
  if (1 !== s.shape.length) throw new Error("Segment ids should be a vector but received shape\n             ".concat(s.shape));
  var o = n.readSync(r.dataId),
      i = n.readSync(a.dataId),
      l = n.readSync(s.dataId),
      [u, c] = sparseSegmentReductionImplCPU$1(o, r.shape, r.dtype, i, l);
  return n.makeTensorInfo(c, r.dtype, u);
}

var sparseSegmentSumConfig$2 = {
  kernelName: SparseSegmentSum$1,
  backendName: "webgl",
  kernelFunc: sparseSegmentSum$3
};

function sparseToDense$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    sparseIndices: a,
    sparseValues: s,
    defaultValue: o
  } = t,
      {
    outputShape: i
  } = r,
      {
    sliceRank: l,
    numUpdates: u,
    strides: c,
    outputSize: p
  } = calculateShapes$1(s, a, i),
      d = new ScatterProgram$1(u, l, a.shape.length, s.shape.length, c, [p, 1], !1),
      h = n.runWebGLProgram(d, [s, a, o], s.dtype),
      m = reshape$4({
    inputs: {
      x: h
    },
    backend: n,
    attrs: {
      shape: i
    }
  });
  return n.disposeIntermediateTensorInfo(h), m;
}

var sparseToDenseConfig$2 = {
  kernelName: SparseToDense$1,
  backendName: "webgl",
  kernelFunc: sparseToDense$3
};

function splitV$2(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    numOrSizeSplits: s,
    axis: o
  } = r,
      i = parseAxisParam$1(o, a.shape)[0],
      l = prepareSplitSize$1(a, s, i),
      u = new Array(a.shape.length).fill(0),
      c = a.shape.slice();
  return l.map(e => {
    var t = [...c];
    t[i] = e;
    var r = slice$3({
      inputs: {
        x: a
      },
      backend: n,
      attrs: {
        begin: u,
        size: t
      }
    });
    return u[i] += e, r;
  });
}

var splitVConfig$2 = {
  kernelName: SplitV$1,
  backendName: "webgl",
  kernelFunc: splitV$2
},
    SQRT$1 = "return sqrt(x);",
    sqrt$3 = unaryKernelFunc$2({
  opSnippet: SQRT$1
}),
    sqrtConfig$2 = {
  kernelName: Sqrt$1,
  backendName: "webgl",
  kernelFunc: sqrt$3
},
    SQUARE$1 = "return x * x;",
    square$3 = unaryKernelFunc$2({
  opSnippet: SQUARE$1
}),
    squareConfig$2 = {
  kernelName: Square$1,
  backendName: "webgl",
  kernelFunc: square$3
},
    SQUARED_DIFFERENCE$1 = "return (a - b) * (a - b);",
    squaredDifference$3 = binaryKernelFunc$2({
  opSnippet: SQUARED_DIFFERENCE$1,
  packedOpSnippet: SQUARED_DIFFERENCE$1
}),
    squaredDifferenceConfig$2 = {
  kernelName: SquaredDifference$1,
  backendName: "webgl",
  kernelFunc: squaredDifference$3
};

function step$3(_ref27) {
  var {
    inputs: e,
    attrs: t,
    backend: n
  } = _ref27;
  var {
    x: r
  } = e,
      a = new UnaryOpProgram$1(r.shape, CHECK_NAN_SNIPPET$5 + "\n    return x > 0.0 ? 1.0 : float(".concat(t.alpha, ");\n  "));
  return n.runWebGLProgram(a, [r], r.dtype);
}

var stepConfig$2 = {
  kernelName: Step$1,
  backendName: "webgl",
  kernelFunc: step$3
};

class StridedSliceProgram$1 {
  constructor(e, t, n) {
    this.variableNames = ["x"], this.outputShape = n;
    var r = n.length,
        a = getCoordsDataType$1(n.length),
        s = getCoordsDataType$1(n.length);
    var o = "";
    if (1 === r) o = "coords * strides + begin";else {
      var _e504 = 0;
      o = n.map((t, r) => (_e504++, 1 === n.length ? "coords * strides[".concat(r, "] + begin[").concat(r, "]") : "coords[".concat(_e504 - 1, "] * strides[").concat(r, "] + begin[").concat(r, "]"))).join(",");
    }
    this.userCode = "\n      ".concat(a, " begin = ").concat(a, "(").concat(e, ");\n      ").concat(a, " strides = ").concat(a, "(").concat(t, ");\n\n      void main() {\n        ").concat(s, " coords = getOutputCoords();\n        setOutput(getX(").concat(o, "));\n      }\n    ");
  }

}

function stridedSlice$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    begin: s,
    end: o,
    strides: i,
    beginMask: l,
    endMask: u,
    ellipsisMask: c,
    newAxisMask: p,
    shrinkAxisMask: d
  } = r,
      {
    nonStrided: h,
    $begin: m,
    $strides: f,
    size: g,
    newShape: $,
    outShape: y
  } = sliceInfo$1(a.shape, s, o, i, l, u, c, p, d),
      b = reshape$4({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      shape: $
    }
  });
  var x;

  if (h) {
    var _e505 = slice$3({
      inputs: {
        x: b
      },
      backend: n,
      attrs: {
        begin: m,
        size: g
      }
    });

    x = reshape$4({
      inputs: {
        x: _e505
      },
      backend: n,
      attrs: {
        shape: y
      }
    }), n.disposeIntermediateTensorInfo(_e505);
  } else if (y.some(e => 0 === e)) x = n.makeTensorInfo(y, a.dtype, []);else if (n.shouldExecuteOnCPU([b])) {
    var _e506 = n.texData.get(b.dataId),
        _t352 = buffer$1(b.shape, b.dtype, _e506.values),
        _r172 = stridedSliceImplCPU$1(y, _t352, f, m);

    x = n.makeTensorInfo(y, b.dtype, _r172.values);
  } else {
    var _e507 = new StridedSliceProgram$1(m, f, y);

    x = n.runWebGLProgram(_e507, [b], b.dtype);
  }

  var v = reshape$4({
    inputs: {
      x
    },
    backend: n,
    attrs: {
      shape: y
    }
  });
  return n.disposeIntermediateTensorInfo(b), n.disposeIntermediateTensorInfo(x), v;
}

var stridedSliceConfig$2 = {
  kernelName: StridedSlice$1,
  backendName: "webgl",
  kernelFunc: stridedSlice$3
};

function stringNGrams$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    separator: a,
    nGramWidths: s,
    leftPad: o,
    rightPad: i,
    padWidth: l,
    preserveShortSequences: u
  } = r,
      {
    data: c,
    dataSplits: p
  } = t,
      d = n.readSync(c.dataId),
      h = n.readSync(p.dataId),
      [m, f] = stringNGramsImplCPU$1(d, h, a, s, o, i, l, u);
  return [n.makeTensorInfo([m.length], "string", m), n.makeTensorInfo(p.shape, "int32", f)];
}

var stringNGramsConfig$2 = {
  kernelName: StringNGrams$1,
  backendName: "webgl",
  kernelFunc: stringNGrams$3
};

function stringSplit$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    skipEmpty: a
  } = r,
      {
    input: s,
    delimiter: o
  } = t;
  if ("string" !== s.dtype) throw new Error("Input must be of datatype string");
  if (1 !== s.shape.length) throw new Error("Input must be a vector, got shape: ".concat(s.shape));
  if (0 !== o.shape.length) throw new Error("Delimiter must be a scalar, got shape: ".concat(o.shape));
  var i = n.readSync(s.dataId),
      l = n.readSync(o.dataId)[0],
      [u, c, p] = stringSplitImplCPU$1(i, l, a),
      d = c.length;
  return [n.makeTensorInfo([d, 2], "int32", u), n.makeTensorInfo([d], "string", c), n.makeTensorInfo([2], "int32", new Int32Array(p))];
}

var stringSplitConfig$2 = {
  kernelName: StringSplit$1,
  backendName: "webgl",
  kernelFunc: stringSplit$3
};

function stringToHashBucketFast$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    numBuckets: a
  } = r,
      {
    input: s
  } = t;
  if ("string" !== s.dtype) throw new Error("Input must be of datatype string");
  if (a <= 0) throw new Error("Number of buckets must be at least 1");
  var o = n.readSync(s.dataId),
      i = stringToHashBucketFastImplCPU$1(o, a);
  return n.makeTensorInfo(s.shape, "int32", i);
}

var stringToHashBucketFastConfig$2 = {
  kernelName: StringToHashBucketFast$1,
  backendName: "webgl",
  kernelFunc: stringToHashBucketFast$3
},
    TAN$1 = "return tan(x);",
    tan$3 = unaryKernelFunc$2({
  opSnippet: TAN$1
}),
    tanConfig$2 = {
  kernelName: Tan$1,
  backendName: "webgl",
  kernelFunc: tan$3
},
    TANH$1 = "\n  float e2x = exp(-2.0 * abs(x));\n  return sign(x) * (1.0 - e2x) / (1.0 + e2x);\n",
    tanh$4 = unaryKernelFunc$2({
  opSnippet: TANH$1
}),
    tanhConfig$2 = {
  kernelName: Tanh$3,
  backendName: "webgl",
  kernelFunc: tanh$4
};

class TileProgram$1 {
  constructor(e, t) {
    this.variableNames = ["A"];
    var n = new Array(e.length);

    for (var _r173 = 0; _r173 < n.length; _r173++) {
      n[_r173] = e[_r173] * t[_r173];
    }

    this.outputShape = n, this.rank = n.length;
    var r = getCoordsDataType$1(this.rank),
        a = getSourceCoords$3(e);
    this.userCode = "\n      void main() {\n        ".concat(r, " resRC = getOutputCoords();\n        setOutput(getA(").concat(a, "));\n      }\n    ");
  }

}

function getSourceCoords$3(e) {
  var t = e.length;
  if (t > 5) throw Error("Tile for rank ".concat(t, " is not yet supported"));
  if (1 === t) return "imod(resRC, ".concat(e[0], ")");
  var n = ["resRC.x", "resRC.y", "resRC.z", "resRC.w", "resRC.u"],
      r = [];

  for (var _t353 = 0; _t353 < e.length; _t353++) {
    r.push("imod(".concat(n[_t353], ", ").concat(e[_t353], ")"));
  }

  return r.join();
}

function tile$4(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    reps: s
  } = r;

  if ("string" === a.dtype || a.shape.length > 5) {
    var _e508 = n.readSync(a.dataId),
        _t354 = "string" === a.dtype ? _e508.map(e => decodeString$1(e)) : _e508,
        _r174 = buffer$1(a.shape, a.dtype, _t354),
        _o64 = tileImplCPU$1(_r174, s);

    return n.makeTensorInfo(_o64.shape, _o64.dtype, _o64.values);
  }

  var o = new TileProgram$1(a.shape, s);
  return n.runWebGLProgram(o, [a], a.dtype);
}

var tileConfig$2 = {
  kernelName: Tile$1,
  backendName: "webgl",
  kernelFunc: tile$4
};

class SwapProgram$1 {
  constructor(e) {
    this.variableNames = ["x", "indices"], this.customUniforms = [{
      name: "n",
      type: "int"
    }, {
      name: "firstPass",
      type: "int"
    }, {
      name: "negativeInf",
      type: "float"
    }, {
      name: "dir",
      type: "int"
    }, {
      name: "inc",
      type: "int"
    }], this.outputShape = e, this.userCode = "\n       void main() {\n         ivec2 coords = getOutputCoords();\n         int batch = coords[0];\n         int elemIdx = coords[1];\n\n         // We compare elements pair-wise within a group of size 2 * inc.\n         // The comparing rule for each group alternates between ascending\n         // and descending. Within each group, we compare each pair at\n         // positions i and i+inc. To decide whether an element at position i\n         // is x0 or x1, we mod it by 2 * inc, if the result is smaller than\n         // inc, it is in the first half of the group, we denote it as x0,\n         // otherwise we denote it as x1.\n         // For example, as shown in the Bitonic top K paper referenced above,\n         // Figure5(a) shows that element[1] is in the\n         // second half of the group when group size is 2, but it is in the\n         // first half of the group when group size is 4.\n\n         bool isFirstInPair = imod(elemIdx, 2 * inc) < inc;\n         int i = isFirstInPair ? elemIdx : elemIdx - inc;\n\n         int i0 = firstPass == 1 ? i : int(getIndices(batch, i));\n         int i1 = firstPass == 1 ? i + inc : int(getIndices(batch, i + inc));\n         float x0 = i0 < n ? getX(batch, i0) : negativeInf;\n         float x1 = i1 < n ? getX(batch, i1) : negativeInf;\n\n         // Denotes which direction indices are in (ascending or descending).\n         bool reverse = imod(elemIdx, 2 * dir) >= dir;\n         bool isGreater = x0 > x1 || (x0 == x1 && i1 > i0);\n         if (reverse == isGreater) { // Elements in opposite order of direction\n           int iTemp = i0;\n           i0 = i1;\n           i1 = iTemp;\n         }\n         if (isFirstInPair) {\n            setOutput(float(i0));\n         } else {\n            setOutput(float(i1));\n         }\n       }\n     ";
  }

}

class MergeProgram$1 {
  constructor(e) {
    this.variableNames = ["x", "indices"], this.customUniforms = [{
      name: "n",
      type: "int"
    }, {
      name: "firstPass",
      type: "int"
    }, {
      name: "k",
      type: "int"
    }], this.outputShape = e, this.userCode = "\n    void main() {\n         // Takes max of indices (0, k), (1, k + 1), (2, k + 2) ...\n         ivec2 coords = getOutputCoords();\n         int batch = coords[0];\n         int elemIdx = coords[1];\n\n         // The output size is half of the previous size.\n         // If the previous sequence is | | | | _ _ _ _  | | | |  _ _ _ _ (k=4),\n         // we only need to output the indices at positions |, the indices at\n         // positions _ can be thrown away, see Figure5(b) After Phase 2\n         // (Merge phase) in the Bitonic Top K paper referenced above.\n         // For example, the paper shows we only need to output the orange bars.\n         // The output sequence should look like this | | | | | | | |.\n         // Because the sequence is halved, to map the output index back\n         // to the previous sequence to find the corresponding value,\n         // we need to double the index. When we double the index,\n         // we basically interpolate a position, so 2i looks like\n         // | _ | _ | _ | _ | _ | _ | _. We move the | to the first k position\n         // of each 2k positions by - elemIdx % k. E.g. for output at\n         // index 4,5,6,7, we want to get the corresponding element at\n         // original index 8,9,10,11, for output at index 8,9,10,11,\n         // we want to get the corresponding element at original index\n         // 16,17,18,19, so on and so forth.\n\n         int i = elemIdx < k ? elemIdx : (elemIdx * 2 - imod(elemIdx, k));\n         int i0 = firstPass == 1 ? i : int(getIndices(batch, i));\n         int i1 = firstPass == 1 ? i + k : int(getIndices(batch, i + k));\n\n         float x0 = getX(batch, i0);\n         float x1 = i1 < n ? getX(batch, i1) : x0;\n\n         setOutput(x0 >= x1 ? float(i0) : float(i1));\n       }\n     ";
  }

}

function disposeIntermediateTensorInfoOrNull$1(e, t) {
  null !== t && e.disposeIntermediateTensorInfo(t);
}

function roundUpToPow2$1(e) {
  var t = 1;

  for (; t < e;) {
    t *= 2;
  }

  return t;
}

function topK$2(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    k: s,
    sorted: o
  } = r,
      i = env$1().getNumber("TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD"),
      l = env$1().getNumber("TOPK_K_CPU_HANDOFF_THRESHOLD"),
      u = a.shape,
      c = u[u.length - 1];

  if (n.shouldExecuteOnCPU([a]) || c < i || s > l) {
    var _e509 = n.readSync(a.dataId),
        [_t355, _r175] = topKImplCPU$1(_e509, u, a.dtype, s, o);

    return [n.makeTensorInfo(_t355.shape, _t355.dtype, _t355.values), n.makeTensorInfo(_r175.shape, _r175.dtype, _r175.values)];
  }

  if (0 === s) return u[u.length - 1] = 0, [n.makeTensorInfo(u, a.dtype, []), n.makeTensorInfo(u, "int32", [])];
  if (1 === c) return [a, fill$3({
    attrs: {
      shape: u,
      dtype: "int32",
      value: 0
    },
    backend: n
  })];
  var p = n.texData.get(a.dataId),
      d = null !== p && p.isPacked,
      h = d ? n.unpackTensor(a) : a,
      m = sizeFromShape$1(u) / c,
      f = reshape$4({
    inputs: {
      x: h
    },
    attrs: {
      shape: [m, c]
    },
    backend: n
  });
  d && disposeIntermediateTensorInfoOrNull$1(n, h);
  var g = roundUpToPow2$1(s),
      $ = roundUpToPow2$1(c);
  var y = null;

  var b = () => null === y ? [f, f] : [f, y],
      x = (e, t, r) => {
    var a = b(),
        s = new SwapProgram$1(r),
        o = y;
    y = n.runWebGLProgram(s, a, "int32", [[c], [null === y ? 1 : 0], [Number.NEGATIVE_INFINITY], [e], [t]]), disposeIntermediateTensorInfoOrNull$1(n, o);
  };

  for (var _e510 = 1; _e510 < g; _e510 *= 2) {
    var _t356 = 2 * _e510;

    for (var _n216 = _e510; _n216 >= 1; _n216 /= 2) {
      x(_t356, _n216, [m, $]);
    }
  }

  for (var _e511 = $; _e511 > g; _e511 /= 2) {
    var _t357 = b(),
        _r176 = new MergeProgram$1([m, _e511 / 2]),
        _a117 = y;

    y = n.runWebGLProgram(_r176, _t357, "int32", [[c], [null === y ? 1 : 0], [g]]), disposeIntermediateTensorInfoOrNull$1(n, _a117);

    var _s89 = g / 2,
        _o65 = 2 * _s89;

    for (var _e512 = _s89; _e512 >= 1; _e512 /= 2) {
      x(_o65, _e512, y.shape);
    }
  }

  var v = y;
  y = slice$3({
    inputs: {
      x: y
    },
    backend: n,
    attrs: {
      begin: 0,
      size: [m, s]
    }
  }), disposeIntermediateTensorInfoOrNull$1(n, v);
  var I = gatherV2$2({
    inputs: {
      x: f,
      indices: y
    },
    backend: n,
    attrs: {
      axis: 1,
      batchDims: 1
    }
  });
  disposeIntermediateTensorInfoOrNull$1(n, f);
  var C = u.slice(0, -1);
  C.push(s), v = y, y = reshape$4({
    inputs: {
      x: y
    },
    attrs: {
      shape: C
    },
    backend: n
  }), disposeIntermediateTensorInfoOrNull$1(n, v);
  var S = I;
  return I = reshape$4({
    inputs: {
      x: I
    },
    attrs: {
      shape: C
    },
    backend: n
  }), disposeIntermediateTensorInfoOrNull$1(n, S), [I, y];
}

var topKConfig$2 = {
  kernelName: TopK$1,
  backendName: "webgl",
  kernelFunc: topK$2
};

class TransformProgram$1 {
  constructor(e, t, n, r, a, s) {
    this.variableNames = ["Image", "Transforms"], this.outputShape = s;
    var o = "nearest" === n ? 1 : 2;
    var i;

    switch (r) {
      case "constant":
      default:
        i = 1;
        break;

      case "reflect":
        i = 2;
        break;

      case "wrap":
        i = 3;
        break;

      case "nearest":
        i = 4;
    }

    this.userCode = "\n            float mapCoord(float outCoord, float len) {\n              float inCoord = outCoord;\n              if(".concat(i, " == 2) {\n                if (inCoord < 0.0) {\n                  if (len <= 1.0) {\n                    inCoord = 0.0;\n                  } else {\n                    float sz2 = 2.0 * len;\n                    if (inCoord < sz2) {\n                      inCoord = sz2 * float(int(float(-inCoord / sz2))) +\n                      inCoord;\n                    }\n                    inCoord = inCoord < -len ? inCoord + sz2 : -inCoord - 1.0;\n                  }\n                } else if (inCoord > len - 1.0) {\n                  if (len <= 1.0) {\n                    inCoord = 0.0;\n                  } else {\n                    float sz2 = 2.0 * len;\n                    inCoord -= sz2 * float(int(float(inCoord / sz2)));\n                    if (inCoord >= len) {\n                      inCoord = sz2 - inCoord - 1.0;\n                    }\n                  }\n                }\n                return clamp(inCoord, 0.0, len - 1.0);\n              } else if (").concat(i, " == 3) {\n                if (inCoord < 0.0) {\n                  if (len <= 1.0) {\n                    inCoord = 0.0;\n                  } else {\n                    float sz = len - 1.0;\n                    inCoord += len * (float(int(float(-inCoord / sz))) + 1.0);\n                  }\n                } else if (inCoord > len - 1.0) {\n                  if (len <= 1.0) {\n                    inCoord = 0.0;\n                  } else {\n                    float sz = len - 1.0;\n                    inCoord -= len * float(int(float(inCoord / sz)));\n                  }\n                }\n                return clamp(inCoord, 0.0, len - 1.0);\n              } else if (").concat(i, " == 4) {\n                return clamp(outCoord, 0.0, len - 1.0);\n              } else {\n                return outCoord;\n              }\n            }\n\n            float readWithFillValue(int batch, int coordY, int coordX,\n              int channel) {\n              float outputValue;\n              if (0 <= coordY && coordY < ").concat(e, " && 0 <= coordX && coordX < ").concat(t, ") {\n                  outputValue = getImage(batch, coordY, coordX, channel);\n              } else {\n                outputValue = float(").concat(a, ");\n              }\n              return outputValue;\n            }\n\n            void main() {\n              ivec4 coords = getOutputCoords();\n              float outputValue;\n              int batch = coords[0];\n              int x = coords[2];\n              int y = coords[1];\n              int channel = coords[3];\n              float xf = float(x);\n              float yf = float(y);\n              float a1 = getTransforms(batch, 0);\n              float a2 = getTransforms(batch, 1);\n              float a3 = getTransforms(batch, 2);\n              float b1 = getTransforms(batch, 3);\n              float b2 = getTransforms(batch, 4);\n              float b3 = getTransforms(batch, 5);\n              float c1 = getTransforms(batch, 6);\n              float c2 = getTransforms(batch, 7);\n              float projection = c1 * xf + c2 * yf + 1.0;\n              if (projection == 0.0) {\n                outputValue = float(").concat(a, ");\n              } else {\n                float inX = (a1 * xf + a2 * yf + a3) / projection;\n                float inY = (b1 * xf + b2 * yf + b3) / projection;\n                float mapX = mapCoord(inX, float(").concat(t, "));\n                float mapY = mapCoord(inY, float(").concat(e, "));\n\n                if (").concat(o, " == 1) {\n                  int coordY = int(round(mapY));\n                  int coordX = int(round(mapX));\n                  outputValue = readWithFillValue(batch, coordY, coordX,\n                    channel);\n                } else {\n                  float yFloor = floor(mapY);\n                  float xFloor = floor(mapX);\n                  float yCeil = yFloor + 1.0;\n                  float xCeil = xFloor + 1.0;\n                  float valueYFloor = (xCeil - mapX) *\n                  readWithFillValue(batch, int(yFloor), int(xFloor), channel) +\n                  (mapX - xFloor) *\n                  readWithFillValue(batch, int(yFloor), int(xCeil), channel);\n                  float valueYCeil = (xCeil - mapX) *\n                  readWithFillValue(batch, int(yCeil), int(xFloor), channel) +\n                  (mapX - xFloor) *\n                  readWithFillValue(batch, int(yCeil), int(xCeil), channel);\n                  outputValue = (yCeil - mapY) * valueYFloor +\n                  (mapY - yFloor) * valueYCeil;\n                }\n              }\n              setOutput(outputValue);\n            }\n        ");
  }

}

function transform$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    image: a,
    transforms: s
  } = t,
      {
    interpolation: o,
    fillMode: i,
    fillValue: l,
    outputShape: u
  } = r,
      [c, p, d, h] = a.shape,
      [m, f] = null != u ? u : [p, d],
      g = new TransformProgram$1(p, d, o, i, l, [c, m, f, h]);
  return n.runWebGLProgram(g, [a, s], "float32");
}

var transformConfig$2 = {
  kernelName: Transform$1,
  backendName: "webgl",
  kernelFunc: transform$3
};

function unique$4(e) {
  var {
    inputs: t,
    attrs: n,
    backend: r
  } = e,
      {
    axis: a
  } = n,
      {
    x: s
  } = t;
  assertNotComplex$2(s, "unique"), console.warn("WARNING: ", "UI might be locked temporarily as data is being downloaded");
  var o = r.readSync(s.dataId),
      {
    outputValues: i,
    outputShape: l,
    indices: u
  } = uniqueImplCPU$1(o, a, s.shape, s.dtype);
  return [r.makeTensorInfo(l, s.dtype, i), r.makeTensorInfo([u.length], "int32", u)];
}

var uniqueConfig$2 = {
  kernelName: Unique$1,
  backendName: "webgl",
  kernelFunc: unique$4
};

function unpack$2(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    value: a
  } = t;
  var {
    axis: s
  } = r;
  s < 0 && (s += a.shape.length);
  var o = a,
      i = o.shape.length,
      l = a.shape[s],
      u = new Array(i - 1);
  var c = 0;

  for (var _e513 = 0; _e513 < i; _e513++) {
    _e513 !== s && (u[c++] = o.shape[_e513]);
  }

  var p = [],
      d = new Array(i).fill(0),
      h = o.shape.slice();
  h[s] = 1;
  var m = new Array(l);

  for (var _e514 = 0; _e514 < m.length; _e514++) {
    d[s] = _e514;

    var _t358 = slice$3({
      inputs: {
        x: o
      },
      backend: n,
      attrs: {
        begin: d,
        size: h
      }
    }),
        _r177 = reshape$4({
      inputs: {
        x: _t358
      },
      backend: n,
      attrs: {
        shape: u
      }
    });

    m[_e514] = _r177, p.push(_t358);
  }

  return p.forEach(e => n.disposeIntermediateTensorInfo(e)), m;
}

var unpackConfig$2 = {
  kernelName: Unpack$1,
  backendName: "webgl",
  kernelFunc: unpack$2
};

class SegmentOpProgram$1 {
  constructor(e, t) {
    this.variableNames = ["x", "segmentIds"];
    var n = e.windowSize,
        r = e.batchSize,
        a = e.inSize,
        s = e.numSegments,
        o = s * Math.ceil(a / n);
    this.outputShape = [r, o];
    var i = 4 * Math.floor(n / 4),
        l = n % 4,
        u = "\n        sumValue += dot(values, segFilter);\n    ";
    var c = "";
    a % n > 0 && (c = "\n        if (inIdx < 0 || inIdx >= ".concat(a, ") {\n          return initializationValue;\n        }\n      "));
    var p = "";
    a % n > 0 && (p = "\n        if (inIdx < 0 || inIdx >= ".concat(a, ") {\n          return -1.0;\n        }\n      ")), this.userCode = "\n      const float initializationValue = 0.0;\n\n      float getValue(int batch, int inIdx) {\n        ".concat(c, "\n        return getX(batch, inIdx);\n      }\n\n      float getSegmentIdAtIndex(int inIdx) {\n        ").concat(p, "\n        return getSegmentIds(inIdx);\n      }\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n        int outIdx = coords[1];\n        int inOffset = int(floor(float(outIdx) / float(\n          ").concat(s, ")) * float(").concat(n, "));\n        int currentSeg = int(mod(float(outIdx), float(").concat(s, ")));\n\n        float sumValue = 0.0;\n\n        for (int i = 0; i < ").concat(i, "; i += 4) {\n          int inIdx = inOffset + i;\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            getValue(batch, inIdx + 3)\n          );\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 3)) == currentSeg ? 1 : 0\n          );\n\n          ").concat(u, "\n        }\n\n        int inIdx = inOffset + ").concat(i, ";\n        if (").concat(1 === l, ") {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            initializationValue,\n            initializationValue,\n            initializationValue\n          );\n\n          int inIdxSeg = int(getSegmentIdAtIndex(inIdx));\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            0,\n            0,\n            0\n          );\n\n          ").concat(u, "\n        } else if (").concat(2 === l, ") {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            initializationValue,\n            initializationValue\n          );\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\n              0,\n              0\n          );\n\n          ").concat(u, "\n        } else if (").concat(3 === l, ") {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            initializationValue\n          );\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,\n            0\n          );\n\n          ").concat(u, "\n        }\n        setOutput(sumValue);\n      }\n    ");
  }

}

function unsortedSegmentSum$3(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    segmentIds: s
  } = t,
      {
    numSegments: o
  } = r,
      i = a.shape.length,
      l = [];
  var u = 0;
  var c = getAxesPermutation$1([u], i);
  var p = a;
  null != c && (p = transpose$3({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      perm: c
    }
  }), l.push(p), u = getInnerMostAxes$1(1, i)[0]);
  var d = computeOutShape$3(p.shape, u, o),
      h = sizeFromShape$1([p.shape[u]]),
      m = reshape$4({
    inputs: {
      x: p
    },
    backend: n,
    attrs: {
      shape: [-1, h]
    }
  });
  l.push(m);

  var f = sumOutType$1(a.dtype),
      g = (e, t, r, a, s) => {
    var o = e.shape[0],
        i = e.shape[1],
        u = segOpComputeOptimalWindowSize$1(i, s),
        c = new SegmentOpProgram$1({
      windowSize: u,
      inSize: i,
      batchSize: o,
      numSegments: s
    }, t),
        p = n.compileAndRun(c, [e, r], a);
    if (l.push(p), p.shape[1] === s) return p;
    var d = range$5({
      backend: n,
      attrs: {
        start: 0,
        stop: s,
        step: 1,
        dtype: "float32"
      }
    }),
        h = tile$4({
      inputs: {
        x: d
      },
      backend: n,
      attrs: {
        reps: [i / u]
      }
    });
    return l.push(d), l.push(h), g(p, t, h, a, s);
  },
      $ = reshape$4({
    inputs: {
      x: g(m, "unsortedSegmentSum", s, f, o)
    },
    backend: n,
    attrs: {
      shape: d
    }
  });

  var y = $;

  if (null != c) {
    l.push($);

    var _e515 = getUndoAxesPermutation$1(c);

    y = transpose$3({
      inputs: {
        x: y
      },
      backend: n,
      attrs: {
        perm: _e515
      }
    });
  }

  return l.forEach(e => n.disposeIntermediateTensorInfo(e)), y;
}

var unsortedSegmentSumConfig$2 = {
  kernelName: UnsortedSegmentSum$1,
  backendName: "webgl",
  kernelFunc: unsortedSegmentSum$3
},
    kernelConfigs$2 = [LRNConfig$1, LRNGradConfig$1, _fusedMatMulConfig$2, absConfig$2, acosConfig$2, acoshConfig$2, addConfig$2, addNConfig$2, allConfig$2, anyConfig$2, argMaxConfig$2, argMinConfig$2, asinConfig$2, asinhConfig$2, atan2Config$2, atanConfig$2, atanhConfig$2, avgPool3DConfig$2, avgPoolConfig$2, avgPoolGrad3DConfig$1, avgPoolGradConfig$3, batchMatMulConfig$2, batchNormConfig$2, batchToSpaceNDConfig$2, bincountConfig$2, castConfig$2, ceilConfig$2, clipByValueConfig$1, complexAbsConfig$2, complexConfig$2, concatConfig$2, conv2DBackpropFilterConfig$2, conv2DBackpropInputConfig$2, conv2DConfig$2, conv3DBackpropFilterV2Config$2, conv3DBackpropInputConfig$1, conv3DConfig$2, cosConfig$2, coshConfig$2, cropAndResizeConfig$2, cumsumConfig$2, denseBincountConfig$2, depthToSpaceConfig$2, depthwiseConv2dNativeBackpropFilterConfig$2, depthwiseConv2dNativeBackpropInputConfig$2, depthwiseConv2dNativeConfig$2, diagConfig$2, dilation2DConfig$1, einsumConfig$2, eluConfig$2, eluGradConfig$3, equalConfig$2, erfConfig$2, expConfig$2, expandDimsConfig$2, expm1Config$2, fftConfig$2, fillConfig$2, flipLeftRightConfig$2, floorConfig$2, floorDivConfig$2, fromPixelsConfig$1, fusedConv2DConfig$2, fusedDepthwiseConv2DConfig$2, gatherNdConfig$2, gatherV2Config$2, greaterConfig$2, greaterEqualConfig$2, identityConfig$2, ifftConfig$2, imagConfig$2, isFiniteConfig$2, isInfConfig$2, isNaNConfig$2, leakyReluConfig$2, lessConfig$2, lessEqualConfig$2, linSpaceConfig$2, log1pConfig$2, logConfig$2, logicalAndConfig$2, logicalNotConfig$2, logicalOrConfig$2, maxConfig$2, maxPool3DConfig$2, maxPoolConfig$2, maxPoolGrad3DConfig$1, maxPoolGradConfig$3, maxPoolWithArgmaxConfig$2, maximumConfig$2, meanConfig$2, minConfig$2, minimumConfig$2, mirrorPadConfig$2, modConfig$2, multinomialConfig$2, multiplyConfig$2, negConfig$2, nonMaxSuppressionV3Config$2, nonMaxSuppressionV4Config$2, nonMaxSuppressionV5Config$2, notEqualConfig$2, oneHotConfig$2, onesLikeConfig$2, packConfig$2, padV2Config$2, powConfig$2, preluConfig$2, prodConfig$2, rangeConfig$2, realConfig$2, realDivConfig$2, reciprocalConfig$2, relu6Config$2, reluConfig$2, reshapeConfig$2, resizeBilinearConfig$2, resizeBilinearGradConfig$3, resizeNearestNeighborConfig$2, resizeNearestNeighborGradConfig$3, reverseConfig$2, rotateWithOffsetConfig$2, roundConfig$2, rsqrtConfig$2, scatterNdConfig$2, selectConfig$2, seluConfig$2, sigmoidConfig$2, signConfig$2, sinConfig$2, sinhConfig$2, sliceConfig$2, softmaxConfig$2, softplusConfig$2, spaceToBatchNDConfig$2, sparseFillEmptyRowsConfig$2, sparseReshapeConfig$2, sparseSegmentMeanConfig$2, sparseSegmentSumConfig$2, sparseToDenseConfig$2, splitVConfig$2, sqrtConfig$2, squareConfig$2, squaredDifferenceConfig$2, stepConfig$2, stridedSliceConfig$2, stringNGramsConfig$2, stringSplitConfig$2, stringToHashBucketFastConfig$2, subConfig$2, sumConfig$2, tanConfig$2, tanhConfig$2, tileConfig$2, topKConfig$2, transformConfig$2, transposeConfig$2, uniqueConfig$2, unpackConfig$2, unsortedSegmentSumConfig$2, zerosLikeConfig$2];

for (var _e516 of kernelConfigs$2) {
  registerKernel$1(_e516);
}

var version$8 = "3.8.0",
    EPSILON_FLOAT32$1 = 1e-7,
    EPSILON_FLOAT16$1 = 1e-4;

class DataStorage {
  constructor(e, t) {
    this.backend = e, this.dataMover = t, this.data = new WeakMap(), this.dataIdsCount = 0;
  }

  get(e) {
    return this.data.has(e) || this.dataMover.moveData(this.backend, e), this.data.get(e);
  }

  set(e, t) {
    this.dataIdsCount++, this.data.set(e, t);
  }

  has(e) {
    return this.data.has(e);
  }

  delete(e) {
    return this.dataIdsCount--, this.data.delete(e);
  }

  numDataIds() {
    return this.dataIdsCount;
  }

}

class KernelBackend {
  refCount(e) {
    return notYetImplemented("refCount");
  }

  incRef(e) {
    return notYetImplemented("incRef");
  }

  timerAvailable() {
    return !0;
  }

  time(e) {
    return notYetImplemented("time");
  }

  read(e) {
    return notYetImplemented("read");
  }

  readSync(e) {
    return notYetImplemented("readSync");
  }

  numDataIds() {
    return notYetImplemented("numDataIds");
  }

  disposeData(e, t) {
    return notYetImplemented("disposeData");
  }

  write(e, t, n) {
    return notYetImplemented("write");
  }

  move(e, t, n, r, a) {
    return notYetImplemented("move");
  }

  memory() {
    return notYetImplemented("memory");
  }

  floatPrecision() {
    return notYetImplemented("floatPrecision");
  }

  epsilon() {
    return 32 === this.floatPrecision() ? EPSILON_FLOAT32$1 : EPSILON_FLOAT16$1;
  }

  dispose() {
    return notYetImplemented("dispose");
  }

}

function notYetImplemented(e) {
  throw new Error("'".concat(e, "' not yet implemented or not found in the registry. This kernel may not be supported by the tfjs backend you have chosen"));
}

function shuffle(e) {
  var t = e.length,
      n = 0;

  for (; t > 0;) {
    n = Math.random() * t | 0, t--, swap(e, t, n);
  }
}

function shuffleCombo(e, t) {
  if (e.length !== t.length) throw new Error("Array sizes must match to be shuffled together First array length was ".concat(e.length, "Second array length was ").concat(t.length));
  var n = e.length,
      r = 0;

  for (; n > 0;) {
    r = Math.random() * n | 0, n--, swap(e, n, r), swap(t, n, r);
  }
}

function clamp(e, t, n) {
  return Math.max(e, Math.min(t, n));
}

function nearestLargerEven(e) {
  return e % 2 == 0 ? e : e + 1;
}

function swap(e, t, n) {
  var r = e[t];
  e[t] = e[n], e[n] = r;
}

function sum$3(e) {
  var t = 0;

  for (var n = 0; n < e.length; n++) {
    t += e[n];
  }

  return t;
}

function randUniform(e, t) {
  var n = Math.random();
  return t * n + (1 - n) * e;
}

function distSquared(e, t) {
  var n = 0;

  for (var r = 0; r < e.length; r++) {
    var a = Number(e[r]) - Number(t[r]);
    n += a * a;
  }

  return n;
}

function assert$4(e, t) {
  if (!e) throw new Error("string" == typeof t ? t : t());
}

function assertShapesMatch(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : "";
  assert$4(arraysEqual(e, t), () => n + " Shapes ".concat(e, " and ").concat(t, " must match"));
}

function assertNonNull(e) {
  assert$4(null != e, () => "The input to the tensor constructor must be a non-null value.");
}

function flatten$3(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : [];
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  if (null == t && (t = []), Array.isArray(e) || isTypedArray(e) && !n) for (var r = 0; r < e.length; ++r) {
    flatten$3(e[r], t, n);
  } else t.push(e);
  return t;
}

function sizeFromShape(e) {
  if (0 === e.length) return 1;
  var t = e[0];

  for (var n = 1; n < e.length; n++) {
    t *= e[n];
  }

  return t;
}

function isScalarShape(e) {
  return 0 === e.length;
}

function arraysEqual(e, t) {
  if (e === t) return !0;
  if (null == e || null == t) return !1;
  if (e.length !== t.length) return !1;

  for (var n = 0; n < e.length; n++) {
    if (e[n] !== t[n]) return !1;
  }

  return !0;
}

function isInt(e) {
  return e % 1 == 0;
}

function tanh$3(e) {
  if (null != Math.tanh) return Math.tanh(e);
  if (Infinity === e) return 1;
  if (-Infinity === e) return -1;
  {
    var t = Math.exp(2 * e);
    return (t - 1) / (t + 1);
  }
}

function sizeToSquarishShape(e) {
  var t = Math.ceil(Math.sqrt(e));
  return [t, Math.ceil(e / t)];
}

function createShuffledIndices(e) {
  var t = new Uint32Array(e);

  for (var n = 0; n < e; ++n) {
    t[n] = n;
  }

  return shuffle(t), t;
}

function rightPad(e, t) {
  return t <= e.length ? e : e + " ".repeat(t - e.length);
}

function repeatedTry(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : e => 0;
  var n = arguments.length > 2 ? arguments[2] : undefined;
  return new Promise((r, a) => {
    var s = 0;

    var o = () => {
      if (e()) return void r();
      s++;
      var i = t(s);
      null != n && s >= n ? a() : setTimeout(o, i);
    };

    o();
  });
}

function inferFromImplicitShape(e, t) {
  var n = 1,
      r = -1;

  for (var _t359 = 0; _t359 < e.length; ++_t359) {
    if (e[_t359] >= 0) n *= e[_t359];else if (-1 === e[_t359]) {
      if (-1 !== r) throw Error("Shapes can only have 1 implicit size. Found -1 at dim ".concat(r, " and dim ").concat(_t359));
      r = _t359;
    } else if (e[_t359] < 0) throw Error("Shapes can not be < 0. Found ".concat(e[_t359], " at dim ").concat(_t359));
  }

  if (-1 === r) {
    if (t > 0 && t !== n) throw Error("Size(".concat(t, ") must match the product of shape ").concat(e));
    return e;
  }

  if (0 === n) throw Error("Cannot infer the missing size in [".concat(e, "] when there are 0 elements"));
  if (t % n != 0) throw Error("The implicit shape can't be a fractional number. Got ".concat(t, " / ").concat(n));
  var a = e.slice();
  return a[r] = t / n, a;
}

function parseAxisParam(e, t) {
  var n = t.length;
  return assert$4((e = null == e ? t.map((e, t) => t) : [].concat(e)).every(e => e >= -n && e < n), () => "All values in axis param must be in range [-".concat(n, ", ").concat(n, ") but got axis ").concat(e)), assert$4(e.every(e => isInt(e)), () => "All values in axis param must be integers but got axis ".concat(e)), e.map(e => e < 0 ? n + e : e);
}

function squeezeShape(e, t) {
  var n = [],
      r = [],
      a = null != t && Array.isArray(t) && 0 === t.length,
      s = null == t || a ? null : parseAxisParam(t, e).sort();
  var o = 0;

  for (var _t360 = 0; _t360 < e.length; ++_t360) {
    if (null != s) {
      if (s[o] === _t360 && 1 !== e[_t360]) throw new Error("Can't squeeze axis ".concat(_t360, " since its dim '").concat(e[_t360], "' is not 1"));
      (null == s[o] || s[o] > _t360) && 1 === e[_t360] && (n.push(e[_t360]), r.push(_t360)), s[o] <= _t360 && o++;
    }

    1 !== e[_t360] && (n.push(e[_t360]), r.push(_t360));
  }

  return {
    newShape: n,
    keptDims: r
  };
}

function getTypedArrayFromDType(e, t) {
  var n = null;
  if (null == e || "float32" === e) n = new Float32Array(t);else if ("int32" === e) n = new Int32Array(t);else {
    if ("bool" !== e) throw new Error("Unknown data type ".concat(e));
    n = new Uint8Array(t);
  }
  return n;
}

function getArrayFromDType(e, t) {
  var n = null;
  if (null == e || "float32" === e) n = new Float32Array(t);else if ("int32" === e) n = new Int32Array(t);else if ("bool" === e) n = new Uint8Array(t);else {
    if ("string" !== e) throw new Error("Unknown data type ".concat(e));
    n = new Array(t);
  }
  return n;
}

function checkConversionForErrors(e, t) {
  for (var n = 0; n < e.length; n++) {
    var r = e[n];
    if (isNaN(r) || !isFinite(r)) throw Error("A tensor of type ".concat(t, " being uploaded contains ").concat(r, "."));
  }
}

function isValidDtype(e) {
  return "bool" === e || "complex64" === e || "float32" === e || "int32" === e || "string" === e;
}

function hasEncodingLoss(e, t) {
  return !("complex64" === t || "float32" === t && "complex64" !== e || "int32" === t && "float32" !== e && "complex64" !== e || "bool" === t && "bool" === e);
}

function isTypedArray(e) {
  return e instanceof Float32Array || e instanceof Int32Array || e instanceof Uint8Array;
}

function bytesPerElement(e) {
  if ("float32" === e || "int32" === e) return 4;
  if ("complex64" === e) return 8;
  if ("bool" === e) return 1;
  throw new Error("Unknown dtype ".concat(e));
}

function bytesFromStringArray(e) {
  if (null == e) return 0;
  var t = 0;
  return e.forEach(e => t += e.length), t;
}

function isString(e) {
  return "string" == typeof e || e instanceof String;
}

function isBoolean(e) {
  return "boolean" == typeof e;
}

function isNumber(e) {
  return "number" == typeof e;
}

function inferDtype(e) {
  return Array.isArray(e) ? inferDtype(e[0]) : e instanceof Float32Array ? "float32" : e instanceof Int32Array || e instanceof Uint8Array ? "int32" : isNumber(e) ? "float32" : isString(e) ? "string" : isBoolean(e) ? "bool" : "float32";
}

function isFunction(e) {
  return !!(e && e.constructor && e.call && e.apply);
}

function nearestDivisor(e, t) {
  for (var n = t; n < e; ++n) {
    if (e % n == 0) return n;
  }

  return e;
}

function computeStrides(e) {
  var t = e.length;
  if (t < 2) return [];
  var n = new Array(t - 1);
  n[t - 2] = e[t - 1];

  for (var r = t - 3; r >= 0; --r) {
    n[r] = n[r + 1] * e[r + 1];
  }

  return n;
}

function createNestedArray(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
  var a = new Array();

  if (1 === t.length) {
    var s = t[0] * (r ? 2 : 1);

    for (var _t361 = 0; _t361 < s; _t361++) {
      a[_t361] = n[e + _t361];
    }
  } else {
    var _s90 = t[0],
        o = t.slice(1),
        i = o.reduce((e, t) => e * t) * (r ? 2 : 1);

    for (var _t362 = 0; _t362 < _s90; _t362++) {
      a[_t362] = createNestedArray(e + _t362 * i, o, n, r);
    }
  }

  return a;
}

function toNestedArray(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  if (0 === e.length) return t[0];
  var r = e.reduce((e, t) => e * t) * (n ? 2 : 1);
  if (0 === r) return [];
  if (r !== t.length) throw new Error("[".concat(e, "] does not match the input size ").concat(t.length).concat(n ? " for a complex tensor" : "", "."));
  return createNestedArray(0, e, t, n);
}

function makeOnesTypedArray(e, t) {
  var n = makeZerosTypedArray(e, t);

  for (var _e517 = 0; _e517 < n.length; _e517++) {
    n[_e517] = 1;
  }

  return n;
}

function makeZerosTypedArray(e, t) {
  if (null == t || "float32" === t || "complex64" === t) return new Float32Array(e);
  if ("int32" === t) return new Int32Array(e);
  if ("bool" === t) return new Uint8Array(e);
  throw new Error("Unknown data type ".concat(t));
}

function makeZerosNestedTypedArray(e, t) {
  var n = e.reduce((e, t) => e * t, 1);
  if (null == t || "float32" === t) return toNestedArray(e, new Float32Array(n));
  if ("int32" === t) return toNestedArray(e, new Int32Array(n));
  if ("bool" === t) return toNestedArray(e, new Uint8Array(n));
  throw new Error("Unknown data type ".concat(t));
}

function assertNonNegativeIntegerDimensions(e) {
  e.forEach(t => {
    assert$4(Number.isInteger(t) && t >= 0, () => "Tensor must have a shape comprised of positive integers but got shape [".concat(e, "]."));
  });
}

function locToIndex(e, t, n) {
  if (0 === t) return 0;
  if (1 === t) return e[0];
  var r = e[e.length - 1];

  for (var _t363 = 0; _t363 < e.length - 1; ++_t363) {
    r += n[_t363] * e[_t363];
  }

  return r;
}

function indexToLoc(e, t, n) {
  if (0 === t) return [];
  if (1 === t) return [e];
  var r = new Array(t);

  for (var _t364 = 0; _t364 < r.length - 1; ++_t364) {
    r[_t364] = Math.floor(e / n[_t364]), e -= r[_t364] * n[_t364];
  }

  return r[r.length - 1] = e, r;
}

function isPromise(e) {
  return e && e.then && "function" == typeof e.then;
}

var TENSORFLOWJS_FLAGS_PREFIX = "tfjsflags";

class Environment {
  constructor(e) {
    this.global = e, this.flags = {}, this.flagRegistry = {}, this.urlFlags = {}, this.getQueryParams = getQueryParams, this.populateURLFlags();
  }

  setPlatform(e, t) {
    null != this.platform && console.warn("Platform ".concat(this.platformName, " has already been set. Overwriting the platform with ").concat(t, ".")), this.platformName = e, this.platform = t;
  }

  registerFlag(e, t, n) {
    if (this.flagRegistry[e] = {
      evaluationFn: t,
      setHook: n
    }, null != this.urlFlags[e]) {
      var _t365 = this.urlFlags[e];
      console.warn("Setting feature override from URL ".concat(e, ": ").concat(_t365, ".")), this.set(e, _t365);
    }
  }

  getAsync(e) {
    var _this76 = this;

    return _asyncToGenerator(function* () {
      return e in _this76.flags || (_this76.flags[e] = yield _this76.evaluateFlag(e)), _this76.flags[e];
    })();
  }

  get(e) {
    if (e in this.flags) return this.flags[e];
    var t = this.evaluateFlag(e);
    if (isPromise(t)) throw new Error("Flag ".concat(e, " cannot be synchronously evaluated. Please use getAsync() instead."));
    return this.flags[e] = t, this.flags[e];
  }

  getNumber(e) {
    return this.get(e);
  }

  getBool(e) {
    return this.get(e);
  }

  getFlags() {
    return this.flags;
  }

  get features() {
    return this.flags;
  }

  set(e, t) {
    if (null == this.flagRegistry[e]) throw new Error("Cannot set flag ".concat(e, " as it has not been registered."));
    this.flags[e] = t, null != this.flagRegistry[e].setHook && this.flagRegistry[e].setHook(t);
  }

  evaluateFlag(e) {
    if (null == this.flagRegistry[e]) throw new Error("Cannot evaluate flag '".concat(e, "': no evaluation function found."));
    return this.flagRegistry[e].evaluationFn();
  }

  setFlags(e) {
    this.flags = Object.assign({}, e);
  }

  reset() {
    this.flags = {}, this.urlFlags = {}, this.populateURLFlags();
  }

  populateURLFlags() {
    if (void 0 === this.global || void 0 === this.global.location || void 0 === this.global.location.search) return;
    var e = this.getQueryParams(this.global.location.search);
    TENSORFLOWJS_FLAGS_PREFIX in e && e[TENSORFLOWJS_FLAGS_PREFIX].split(",").forEach(e => {
      var [t, n] = e.split(":");
      this.urlFlags[t] = parseValue(t, n);
    });
  }

}

function getQueryParams(e) {
  var t = {};
  return e.replace(/[?&]([^=?&]+)(?:=([^&]*))?/g, function (e) {
    for (var _len5 = arguments.length, n = new Array(_len5 > 1 ? _len5 - 1 : 0), _key5 = 1; _key5 < _len5; _key5++) {
      n[_key5 - 1] = arguments[_key5];
    }

    return decodeParam(t, n[0], n[1]), n.join("=");
  }), t;
}

function decodeParam(e, t, n) {
  e[decodeURIComponent(t)] = decodeURIComponent(n || "");
}

function parseValue(e, t) {
  if ("true" === (t = t.toLowerCase()) || "false" === t) return "true" === t;
  if ("" + +t === t) return +t;
  throw new Error("Could not parse value flag value ".concat(t, " for flag ").concat(e, "."));
}

function env() {
  return ENV$2;
}

var ENV$2 = null,
    globalNameSpace;

function setEnvironmentGlobal(e) {
  ENV$2 = e;
}

function getGlobalNamespace() {
  if (null == globalNameSpace) {
    var _e518;

    if ("undefined" != typeof window) _e518 = window;else if ("undefined" != typeof __webpack_require__.g) _e518 = __webpack_require__.g;else if ("undefined" != typeof process) _e518 = process;else {
      if ("undefined" == typeof self) throw new Error("Could not find a global object");
      _e518 = self;
    }
    globalNameSpace = _e518;
  }

  return globalNameSpace;
}

function getGlobalMap() {
  var e = getGlobalNamespace();
  return null == e._tfGlobals && (e._tfGlobals = new Map()), e._tfGlobals;
}

function getGlobal(e, t) {
  var n = getGlobalMap();
  if (n.has(e)) return n.get(e);
  {
    var r = t();
    return n.set(e, r), n.get(e);
  }
}

var Abs = "Abs",
    Acos = "Acos",
    Acosh = "Acosh",
    Add$1 = "Add",
    AddN = "AddN",
    All = "All",
    Any = "Any",
    ArgMax = "ArgMax",
    ArgMin = "ArgMin",
    Asin = "Asin",
    Asinh = "Asinh",
    Atan = "Atan",
    Atanh = "Atanh",
    Atan2 = "Atan2",
    AvgPool = "AvgPool",
    AvgPoolGrad = "AvgPoolGrad",
    AvgPool3D = "AvgPool3D",
    AvgPool3DGrad = "AvgPool3DGrad",
    BatchMatMul = "BatchMatMul",
    BatchToSpaceND = "BatchToSpaceND",
    Bincount = "Bincount",
    BroadcastTo = "BroadcastTo",
    Cast = "Cast",
    Ceil = "Ceil",
    ClipByValue = "ClipByValue",
    Complex = "Complex",
    ComplexAbs = "ComplexAbs",
    Concat = "Concat",
    Conv2D$1 = "Conv2D",
    Conv2DBackpropFilter = "Conv2DBackpropFilter",
    Conv2DBackpropInput = "Conv2DBackpropInput",
    Conv3D$1 = "Conv3D",
    Conv3DBackpropFilterV2 = "Conv3DBackpropFilterV2",
    Conv3DBackpropInputV2 = "Conv3DBackpropInputV2",
    Cos = "Cos",
    Cosh = "Cosh",
    Cumsum = "Cumsum",
    CropAndResize = "CropAndResize",
    DenseBincount = "DenseBincount",
    DepthToSpace = "DepthToSpace",
    DepthwiseConv2dNative = "DepthwiseConv2dNative",
    DepthwiseConv2dNativeBackpropFilter = "DepthwiseConv2dNativeBackpropFilter",
    DepthwiseConv2dNativeBackpropInput = "DepthwiseConv2dNativeBackpropInput",
    Diag = "Diag",
    Dilation2D = "Dilation2D",
    Dilation2DBackpropInput = "Dilation2DBackpropInput",
    Dilation2DBackpropFilter = "Dilation2DBackpropFilter",
    RealDiv = "RealDiv",
    Einsum = "Einsum",
    Elu$1 = "Elu",
    EluGrad = "EluGrad",
    Erf = "Erf",
    Equal = "Equal",
    Exp = "Exp",
    ExpandDims = "ExpandDims",
    Expm1 = "Expm1",
    FFT = "FFT",
    Fill = "Fill",
    FlipLeftRight = "FlipLeftRight",
    Floor = "Floor",
    FloorDiv = "FloorDiv",
    FusedBatchNorm = "FusedBatchNorm",
    GatherV2 = "GatherV2",
    GatherNd = "GatherNd",
    Greater = "Greater",
    GreaterEqual = "GreaterEqual",
    Identity$1 = "Identity",
    IFFT = "IFFT",
    Imag = "Imag",
    IsFinite = "IsFinite",
    IsInf = "IsInf",
    IsNan = "IsNan",
    LeakyRelu = "LeakyRelu",
    Less = "Less",
    LessEqual = "LessEqual",
    LinSpace = "LinSpace",
    Log = "Log",
    Log1p = "Log1p",
    LogicalAnd = "LogicalAnd",
    LogicalNot = "LogicalNot",
    LogicalOr = "LogicalOr",
    LogSoftmax$1 = "LogSoftmax",
    LRN = "LRN",
    LRNGrad = "LRNGrad",
    Max = "Max",
    Maximum$1 = "Maximum",
    MaxPool = "MaxPool",
    MaxPoolGrad = "MaxPoolGrad",
    MaxPool3D = "MaxPool3D",
    MaxPool3DGrad = "MaxPool3DGrad",
    MaxPoolWithArgmax = "MaxPoolWithArgmax",
    Mean = "Mean",
    Min = "Min",
    Minimum$1 = "Minimum",
    MirrorPad = "MirrorPad",
    Mod = "Mod",
    Multinomial = "Multinomial",
    Multiply$1 = "Multiply",
    Neg = "Neg",
    NotEqual = "NotEqual",
    NonMaxSuppressionV3 = "NonMaxSuppressionV3",
    NonMaxSuppressionV4 = "NonMaxSuppressionV4",
    NonMaxSuppressionV5 = "NonMaxSuppressionV5",
    OnesLike = "OnesLike",
    OneHot = "OneHot",
    Pack = "Pack",
    PadV2 = "PadV2",
    Pool = "Pool",
    Pow = "Pow",
    Prelu = "Prelu",
    Prod = "Prod",
    Range = "Range",
    Real = "Real",
    Reciprocal = "Reciprocal",
    Relu$1 = "Relu",
    Reshape$1 = "Reshape",
    ResizeNearestNeighbor = "ResizeNearestNeighbor",
    ResizeNearestNeighborGrad = "ResizeNearestNeighborGrad",
    ResizeBilinear = "ResizeBilinear",
    ResizeBilinearGrad = "ResizeBilinearGrad",
    Relu6$1 = "Relu6",
    Reverse = "Reverse",
    Round = "Round",
    Rsqrt = "Rsqrt",
    ScatterNd = "ScatterNd",
    Select = "Select",
    Selu$1 = "Selu",
    Slice = "Slice",
    Sin = "Sin",
    Sinh = "Sinh",
    Sign = "Sign",
    Sigmoid$1 = "Sigmoid",
    Softplus$1 = "Softplus",
    Sqrt = "Sqrt",
    Sum = "Sum",
    SpaceToBatchND = "SpaceToBatchND",
    SplitV = "SplitV",
    Softmax$2 = "Softmax",
    SparseFillEmptyRows = "SparseFillEmptyRows",
    SparseReshape = "SparseReshape",
    SparseSegmentMean = "SparseSegmentMean",
    SparseSegmentSum = "SparseSegmentSum",
    SparseToDense = "SparseToDense",
    SquaredDifference = "SquaredDifference",
    Square = "Square",
    StridedSlice = "StridedSlice",
    StringNGrams = "StringNGrams",
    StringSplit = "StringSplit",
    StringToHashBucketFast = "StringToHashBucketFast",
    Sub = "Sub",
    Tan = "Tan",
    Tanh$1 = "Tanh",
    Tile = "Tile",
    TopK = "TopK",
    Transform = "Transform",
    Transpose = "Transpose",
    Unique = "Unique",
    Unpack = "Unpack",
    UnsortedSegmentSum = "UnsortedSegmentSum",
    ZerosLike = "ZerosLike",
    Step = "Step",
    FromPixels = "FromPixels",
    RotateWithOffset = "RotateWithOffset",
    _FusedMatMul = "_FusedMatMul",
    FusedConv2D = "FusedConv2D",
    FusedDepthwiseConv2D = "FusedDepthwiseConv2D",
    kernelRegistry = getGlobal("kernelRegistry", () => new Map()),
    gradRegistry = getGlobal("gradRegistry", () => new Map());

function getKernel(e, t) {
  var n = makeKey(e, t);
  return kernelRegistry.get(n);
}

function getGradient(e) {
  return gradRegistry.get(e);
}

function getKernelsForBackend(e) {
  var t = kernelRegistry.entries(),
      n = [];

  for (;;) {
    var {
      done: r,
      value: a
    } = t.next();
    if (r) break;
    var [s, o] = a,
        [i] = s.split("_");
    i === e && n.push(o);
  }

  return n;
}

function registerKernel(e) {
  var {
    kernelName: t,
    backendName: n
  } = e,
      r = makeKey(t, n);
  kernelRegistry.has(r) && console.warn("The kernel '".concat(t, "' for backend '").concat(n, "' is already registered")), kernelRegistry.set(r, e);
}

function registerGradient(e) {
  var {
    kernelName: t
  } = e;
  gradRegistry.has(t) && env().getBool("DEBUG") && console.warn("Overriding the gradient for '".concat(t, "'")), gradRegistry.set(t, e);
}

function unregisterKernel(e, t) {
  var n = makeKey(e, t);
  if (!kernelRegistry.has(n)) throw new Error("The kernel '".concat(e, "' for backend '").concat(t, "' is not registered"));
  kernelRegistry.delete(n);
}

function unregisterGradient(e) {
  if (!gradRegistry.has(e)) throw new Error("The gradient '".concat(e, "' for backend is not registered"));
  gradRegistry.delete(e);
}

function copyRegisteredKernels(e, t) {
  getKernelsForBackend(e).forEach(e => {
    registerKernel(Object.assign({}, e, {
      backendName: t
    }));
  });
}

function makeKey(e, t) {
  return "".concat(t, "_").concat(e);
}

var long = Long$1,
    wasm = null;

try {
  wasm = new WebAssembly.Instance(new WebAssembly.Module(new Uint8Array([0, 97, 115, 109, 1, 0, 0, 0, 1, 13, 2, 96, 0, 1, 127, 96, 4, 127, 127, 127, 127, 1, 127, 3, 7, 6, 0, 1, 1, 1, 1, 1, 6, 6, 1, 127, 1, 65, 0, 11, 7, 50, 6, 3, 109, 117, 108, 0, 1, 5, 100, 105, 118, 95, 115, 0, 2, 5, 100, 105, 118, 95, 117, 0, 3, 5, 114, 101, 109, 95, 115, 0, 4, 5, 114, 101, 109, 95, 117, 0, 5, 8, 103, 101, 116, 95, 104, 105, 103, 104, 0, 0, 10, 191, 1, 6, 4, 0, 35, 0, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 126, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 127, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 128, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 129, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11, 36, 1, 1, 126, 32, 0, 173, 32, 1, 173, 66, 32, 134, 132, 32, 2, 173, 32, 3, 173, 66, 32, 134, 132, 130, 34, 4, 66, 32, 135, 167, 36, 0, 32, 4, 167, 11])), {}).exports;
} catch (e) {}

function Long$1(e, t, n) {
  this.low = 0 | e, this.high = 0 | t, this.unsigned = !!n;
}

function isLong(e) {
  return !0 === (e && e.__isLong__);
}

Object.defineProperty(Long$1.prototype, "__isLong__", {
  value: !0
}), Long$1.isLong = isLong;
var INT_CACHE = {},
    UINT_CACHE = {};

function fromInt(e, t) {
  var n, r, a;
  return t ? (a = 0 <= (e >>>= 0) && e < 256) && (r = UINT_CACHE[e]) ? r : (n = fromBits(e, (0 | e) < 0 ? -1 : 0, !0), a && (UINT_CACHE[e] = n), n) : (a = -128 <= (e |= 0) && e < 128) && (r = INT_CACHE[e]) ? r : (n = fromBits(e, e < 0 ? -1 : 0, !1), a && (INT_CACHE[e] = n), n);
}

function fromNumber(e, t) {
  if (isNaN(e)) return t ? UZERO : ZERO;

  if (t) {
    if (e < 0) return UZERO;
    if (e >= TWO_PWR_64_DBL) return MAX_UNSIGNED_VALUE;
  } else {
    if (e <= -TWO_PWR_63_DBL) return MIN_VALUE;
    if (e + 1 >= TWO_PWR_63_DBL) return MAX_VALUE;
  }

  return e < 0 ? fromNumber(-e, t).neg() : fromBits(e % TWO_PWR_32_DBL | 0, e / TWO_PWR_32_DBL | 0, t);
}

function fromBits(e, t, n) {
  return new Long$1(e, t, n);
}

Long$1.fromInt = fromInt, Long$1.fromNumber = fromNumber, Long$1.fromBits = fromBits;
var pow_dbl = Math.pow;

function fromString(e, t, n) {
  if (0 === e.length) throw Error("empty string");
  if ("NaN" === e || "Infinity" === e || "+Infinity" === e || "-Infinity" === e) return ZERO;
  if ("number" == typeof t ? (n = t, t = !1) : t = !!t, (n = n || 10) < 2 || 36 < n) throw RangeError("radix");
  var r;
  if ((r = e.indexOf("-")) > 0) throw Error("interior hyphen");
  if (0 === r) return fromString(e.substring(1), t, n).neg();

  for (var a = fromNumber(pow_dbl(n, 8)), s = ZERO, o = 0; o < e.length; o += 8) {
    var i = Math.min(8, e.length - o),
        l = parseInt(e.substring(o, o + i), n);

    if (i < 8) {
      var u = fromNumber(pow_dbl(n, i));
      s = s.mul(u).add(fromNumber(l));
    } else s = (s = s.mul(a)).add(fromNumber(l));
  }

  return s.unsigned = t, s;
}

function fromValue(e, t) {
  return "number" == typeof e ? fromNumber(e, t) : "string" == typeof e ? fromString(e, t) : fromBits(e.low, e.high, "boolean" == typeof t ? t : e.unsigned);
}

Long$1.fromString = fromString, Long$1.fromValue = fromValue;
var TWO_PWR_16_DBL = 65536,
    TWO_PWR_24_DBL = 1 << 24,
    TWO_PWR_32_DBL = TWO_PWR_16_DBL * TWO_PWR_16_DBL,
    TWO_PWR_64_DBL = TWO_PWR_32_DBL * TWO_PWR_32_DBL,
    TWO_PWR_63_DBL = TWO_PWR_64_DBL / 2,
    TWO_PWR_24 = fromInt(TWO_PWR_24_DBL),
    ZERO = fromInt(0);
Long$1.ZERO = ZERO;
var UZERO = fromInt(0, !0);
Long$1.UZERO = UZERO;
var ONE = fromInt(1);
Long$1.ONE = ONE;
var UONE = fromInt(1, !0);
Long$1.UONE = UONE;
var NEG_ONE = fromInt(-1);
Long$1.NEG_ONE = NEG_ONE;
var MAX_VALUE = fromBits(-1, 2147483647, !1);
Long$1.MAX_VALUE = MAX_VALUE;
var MAX_UNSIGNED_VALUE = fromBits(-1, -1, !0);
Long$1.MAX_UNSIGNED_VALUE = MAX_UNSIGNED_VALUE;
var MIN_VALUE = fromBits(0, -2147483648, !1);
Long$1.MIN_VALUE = MIN_VALUE;
var LongPrototype = Long$1.prototype;
LongPrototype.toInt = function () {
  return this.unsigned ? this.low >>> 0 : this.low;
}, LongPrototype.toNumber = function () {
  return this.unsigned ? (this.high >>> 0) * TWO_PWR_32_DBL + (this.low >>> 0) : this.high * TWO_PWR_32_DBL + (this.low >>> 0);
}, LongPrototype.toString = function (e) {
  if ((e = e || 10) < 2 || 36 < e) throw RangeError("radix");
  if (this.isZero()) return "0";

  if (this.isNegative()) {
    if (this.eq(MIN_VALUE)) {
      var t = fromNumber(e),
          n = this.div(t),
          r = n.mul(t).sub(this);
      return n.toString(e) + r.toInt().toString(e);
    }

    return "-" + this.neg().toString(e);
  }

  for (var a = fromNumber(pow_dbl(e, 6), this.unsigned), s = this, o = "";;) {
    var i = s.div(a),
        l = (s.sub(i.mul(a)).toInt() >>> 0).toString(e);
    if ((s = i).isZero()) return l + o;

    for (; l.length < 6;) {
      l = "0" + l;
    }

    o = "" + l + o;
  }
}, LongPrototype.getHighBits = function () {
  return this.high;
}, LongPrototype.getHighBitsUnsigned = function () {
  return this.high >>> 0;
}, LongPrototype.getLowBits = function () {
  return this.low;
}, LongPrototype.getLowBitsUnsigned = function () {
  return this.low >>> 0;
}, LongPrototype.getNumBitsAbs = function () {
  if (this.isNegative()) return this.eq(MIN_VALUE) ? 64 : this.neg().getNumBitsAbs();

  for (var e = 0 != this.high ? this.high : this.low, t = 31; t > 0 && 0 == (e & 1 << t); t--) {
    ;
  }

  return 0 != this.high ? t + 33 : t + 1;
}, LongPrototype.isZero = function () {
  return 0 === this.high && 0 === this.low;
}, LongPrototype.eqz = LongPrototype.isZero, LongPrototype.isNegative = function () {
  return !this.unsigned && this.high < 0;
}, LongPrototype.isPositive = function () {
  return this.unsigned || this.high >= 0;
}, LongPrototype.isOdd = function () {
  return 1 == (1 & this.low);
}, LongPrototype.isEven = function () {
  return 0 == (1 & this.low);
}, LongPrototype.equals = function (e) {
  return isLong(e) || (e = fromValue(e)), (this.unsigned === e.unsigned || this.high >>> 31 != 1 || e.high >>> 31 != 1) && this.high === e.high && this.low === e.low;
}, LongPrototype.eq = LongPrototype.equals, LongPrototype.notEquals = function (e) {
  return !this.eq(e);
}, LongPrototype.neq = LongPrototype.notEquals, LongPrototype.ne = LongPrototype.notEquals, LongPrototype.lessThan = function (e) {
  return this.comp(e) < 0;
}, LongPrototype.lt = LongPrototype.lessThan, LongPrototype.lessThanOrEqual = function (e) {
  return this.comp(e) <= 0;
}, LongPrototype.lte = LongPrototype.lessThanOrEqual, LongPrototype.le = LongPrototype.lessThanOrEqual, LongPrototype.greaterThan = function (e) {
  return this.comp(e) > 0;
}, LongPrototype.gt = LongPrototype.greaterThan, LongPrototype.greaterThanOrEqual = function (e) {
  return this.comp(e) >= 0;
}, LongPrototype.gte = LongPrototype.greaterThanOrEqual, LongPrototype.ge = LongPrototype.greaterThanOrEqual, LongPrototype.compare = function (e) {
  if (isLong(e) || (e = fromValue(e)), this.eq(e)) return 0;
  var t = this.isNegative(),
      n = e.isNegative();
  return t && !n ? -1 : !t && n ? 1 : this.unsigned ? e.high >>> 0 > this.high >>> 0 || e.high === this.high && e.low >>> 0 > this.low >>> 0 ? -1 : 1 : this.sub(e).isNegative() ? -1 : 1;
}, LongPrototype.comp = LongPrototype.compare, LongPrototype.negate = function () {
  return !this.unsigned && this.eq(MIN_VALUE) ? MIN_VALUE : this.not().add(ONE);
}, LongPrototype.neg = LongPrototype.negate, LongPrototype.add = function (e) {
  isLong(e) || (e = fromValue(e));
  var t = 0,
      n = 0,
      r = 0,
      a = 0;
  return r += (a += (65535 & this.low) + (65535 & e.low)) >>> 16, n += (r += (this.low >>> 16) + (e.low >>> 16)) >>> 16, t += (n += (65535 & this.high) + (65535 & e.high)) >>> 16, t += (this.high >>> 16) + (e.high >>> 16), fromBits((r &= 65535) << 16 | (a &= 65535), (t &= 65535) << 16 | (n &= 65535), this.unsigned);
}, LongPrototype.subtract = function (e) {
  return isLong(e) || (e = fromValue(e)), this.add(e.neg());
}, LongPrototype.sub = LongPrototype.subtract, LongPrototype.multiply = function (e) {
  if (this.isZero()) return ZERO;
  if (isLong(e) || (e = fromValue(e)), wasm) return fromBits(wasm.mul(this.low, this.high, e.low, e.high), wasm.get_high(), this.unsigned);
  if (e.isZero()) return ZERO;
  if (this.eq(MIN_VALUE)) return e.isOdd() ? MIN_VALUE : ZERO;
  if (e.eq(MIN_VALUE)) return this.isOdd() ? MIN_VALUE : ZERO;
  if (this.isNegative()) return e.isNegative() ? this.neg().mul(e.neg()) : this.neg().mul(e).neg();
  if (e.isNegative()) return this.mul(e.neg()).neg();
  if (this.lt(TWO_PWR_24) && e.lt(TWO_PWR_24)) return fromNumber(this.toNumber() * e.toNumber(), this.unsigned);
  var t = 65535 & this.high,
      n = this.low >>> 16,
      r = 65535 & this.low,
      a = 65535 & e.high,
      s = e.low >>> 16,
      o = 65535 & e.low,
      i = 0,
      l = 0,
      u = 0,
      c = 0;
  return u += (c += r * o) >>> 16, l += (u += n * o) >>> 16, u &= 65535, l += (u += r * s) >>> 16, i += (l += t * o) >>> 16, l &= 65535, i += (l += n * s) >>> 16, l &= 65535, i += (l += r * a) >>> 16, i += (this.high >>> 16) * o + t * s + n * a + r * (e.high >>> 16), fromBits((u &= 65535) << 16 | (c &= 65535), (i &= 65535) << 16 | (l &= 65535), this.unsigned);
}, LongPrototype.mul = LongPrototype.multiply, LongPrototype.divide = function (e) {
  if (isLong(e) || (e = fromValue(e)), e.isZero()) throw Error("division by zero");
  var t, n, r;
  if (wasm) return this.unsigned || -2147483648 !== this.high || -1 !== e.low || -1 !== e.high ? fromBits((this.unsigned ? wasm.div_u : wasm.div_s)(this.low, this.high, e.low, e.high), wasm.get_high(), this.unsigned) : this;
  if (this.isZero()) return this.unsigned ? UZERO : ZERO;

  if (this.unsigned) {
    if (e.unsigned || (e = e.toUnsigned()), e.gt(this)) return UZERO;
    if (e.gt(this.shru(1))) return UONE;
    r = UZERO;
  } else {
    if (this.eq(MIN_VALUE)) return e.eq(ONE) || e.eq(NEG_ONE) ? MIN_VALUE : e.eq(MIN_VALUE) ? ONE : (t = this.shr(1).div(e).shl(1)).eq(ZERO) ? e.isNegative() ? ONE : NEG_ONE : (n = this.sub(e.mul(t)), r = t.add(n.div(e)));
    if (e.eq(MIN_VALUE)) return this.unsigned ? UZERO : ZERO;
    if (this.isNegative()) return e.isNegative() ? this.neg().div(e.neg()) : this.neg().div(e).neg();
    if (e.isNegative()) return this.div(e.neg()).neg();
    r = ZERO;
  }

  for (n = this; n.gte(e);) {
    t = Math.max(1, Math.floor(n.toNumber() / e.toNumber()));

    for (var a = Math.ceil(Math.log(t) / Math.LN2), s = a <= 48 ? 1 : pow_dbl(2, a - 48), o = fromNumber(t), i = o.mul(e); i.isNegative() || i.gt(n);) {
      i = (o = fromNumber(t -= s, this.unsigned)).mul(e);
    }

    o.isZero() && (o = ONE), r = r.add(o), n = n.sub(i);
  }

  return r;
}, LongPrototype.div = LongPrototype.divide, LongPrototype.modulo = function (e) {
  return isLong(e) || (e = fromValue(e)), wasm ? fromBits((this.unsigned ? wasm.rem_u : wasm.rem_s)(this.low, this.high, e.low, e.high), wasm.get_high(), this.unsigned) : this.sub(this.div(e).mul(e));
}, LongPrototype.mod = LongPrototype.modulo, LongPrototype.rem = LongPrototype.modulo, LongPrototype.not = function () {
  return fromBits(~this.low, ~this.high, this.unsigned);
}, LongPrototype.and = function (e) {
  return isLong(e) || (e = fromValue(e)), fromBits(this.low & e.low, this.high & e.high, this.unsigned);
}, LongPrototype.or = function (e) {
  return isLong(e) || (e = fromValue(e)), fromBits(this.low | e.low, this.high | e.high, this.unsigned);
}, LongPrototype.xor = function (e) {
  return isLong(e) || (e = fromValue(e)), fromBits(this.low ^ e.low, this.high ^ e.high, this.unsigned);
}, LongPrototype.shiftLeft = function (e) {
  return isLong(e) && (e = e.toInt()), 0 == (e &= 63) ? this : e < 32 ? fromBits(this.low << e, this.high << e | this.low >>> 32 - e, this.unsigned) : fromBits(0, this.low << e - 32, this.unsigned);
}, LongPrototype.shl = LongPrototype.shiftLeft, LongPrototype.shiftRight = function (e) {
  return isLong(e) && (e = e.toInt()), 0 == (e &= 63) ? this : e < 32 ? fromBits(this.low >>> e | this.high << 32 - e, this.high >> e, this.unsigned) : fromBits(this.high >> e - 32, this.high >= 0 ? 0 : -1, this.unsigned);
}, LongPrototype.shr = LongPrototype.shiftRight, LongPrototype.shiftRightUnsigned = function (e) {
  if (isLong(e) && (e = e.toInt()), 0 == (e &= 63)) return this;
  var t = this.high;
  return e < 32 ? fromBits(this.low >>> e | t << 32 - e, t >>> e, this.unsigned) : fromBits(32 === e ? t : t >>> e - 32, 0, this.unsigned);
}, LongPrototype.shru = LongPrototype.shiftRightUnsigned, LongPrototype.shr_u = LongPrototype.shiftRightUnsigned, LongPrototype.toSigned = function () {
  return this.unsigned ? fromBits(this.low, this.high, !1) : this;
}, LongPrototype.toUnsigned = function () {
  return this.unsigned ? this : fromBits(this.low, this.high, !0);
}, LongPrototype.toBytes = function (e) {
  return e ? this.toBytesLE() : this.toBytesBE();
}, LongPrototype.toBytesLE = function () {
  var e = this.high,
      t = this.low;
  return [255 & t, t >>> 8 & 255, t >>> 16 & 255, t >>> 24, 255 & e, e >>> 8 & 255, e >>> 16 & 255, e >>> 24];
}, LongPrototype.toBytesBE = function () {
  var e = this.high,
      t = this.low;
  return [e >>> 24, e >>> 16 & 255, e >>> 8 & 255, 255 & e, t >>> 24, t >>> 16 & 255, t >>> 8 & 255, 255 & t];
}, Long$1.fromBytes = function (e, t, n) {
  return n ? Long$1.fromBytesLE(e, t) : Long$1.fromBytesBE(e, t);
}, Long$1.fromBytesLE = function (e, t) {
  return new Long$1(e[0] | e[1] << 8 | e[2] << 16 | e[3] << 24, e[4] | e[5] << 8 | e[6] << 16 | e[7] << 24, t);
}, Long$1.fromBytesBE = function (e, t) {
  return new Long$1(e[4] << 24 | e[5] << 16 | e[6] << 8 | e[7], e[0] << 24 | e[1] << 16 | e[2] << 8 | e[3], t);
};

var long$1 = long,
    LongExports = /*#__PURE__*/_mergeNamespaces({
  __proto__: null,
  default: long$1
}, [long]);

var Long = long$1 || LongExports;

function hexToLong(e) {
  return Long.fromString(e, !0, 16);
}

var k0 = hexToLong("c3a5c85c97cb3127"),
    k1 = hexToLong("b492b66fbe98f273"),
    k2 = hexToLong("9ae16a3b2f90404f");

function shiftMix(e) {
  return e.xor(e.shru(47));
}

function fetch$2(e, t, n) {
  var r = e.slice(t, t + n);
  return Long.fromBytes(Array.from(r), !0, !0);
}

function fetch64(e, t) {
  return fetch$2(e, t, 8);
}

function fetch32(e, t) {
  return fetch$2(e, t, 4);
}

function rotate64(e, t) {
  return 0 === t ? e : e.shru(t).or(e.shl(64 - t));
}

function hashLen16(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : hexToLong("9ddfea08eb382d69");
  var r = e.xor(t).mul(n);
  r = r.xor(r.shru(47));
  var a = t.xor(r).mul(n);
  return a = a.xor(a.shru(47)), a = a.mul(n), a;
}

function weakHashLen32WithSeeds(e, t, n, r, a, s) {
  a = a.add(e), s = rotate64(s.add(a).add(r), 21);
  var o = a;
  return a = (a = a.add(t)).add(n), s = s.add(rotate64(a, 44)), [a.add(r), s.add(o)];
}

function weakHashLen32WithSeedsStr(e, t, n, r) {
  return weakHashLen32WithSeeds(fetch64(e, t), fetch64(e, t + 8), fetch64(e, t + 16), fetch64(e, t + 24), n, r);
}

function hashLen0to16(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : e.length;

  if (t >= 8) {
    var n = k2.add(2 * t),
        r = fetch64(e, 0).add(k2),
        a = fetch64(e, t - 8);
    return hashLen16(rotate64(a, 37).mul(n).add(r), rotate64(r, 25).add(a).mul(n), n);
  }

  if (t >= 4) {
    var _n217 = k2.add(2 * t);

    return hashLen16(fetch32(e, 0).shl(3).add(t), fetch32(e, t - 4), _n217);
  }

  if (t > 0) {
    var _n218 = t + (e[t - 1] << 2);

    return shiftMix(k2.mul(e[0] + (e[t >> 1] << 8)).xor(k0.mul(_n218))).mul(k2);
  }

  return k2;
}

function hashLen17to32(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : e.length;
  var n = k2.add(2 * t),
      r = fetch64(e, 0).mul(k1),
      a = fetch64(e, 8),
      s = fetch64(e, t - 8).mul(n),
      o = fetch64(e, t - 16).mul(k2);
  return hashLen16(rotate64(r.add(a), 43).add(rotate64(s, 30)).add(o), r.add(rotate64(a.add(k2), 18)).add(s), n);
}

function hashLen33to64(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : e.length;
  var n = k2.add(2 * t),
      r = fetch64(e, 0).mul(k2),
      a = fetch64(e, 8),
      s = fetch64(e, t - 8).mul(n),
      o = fetch64(e, t - 16).mul(k2),
      i = rotate64(r.add(a), 43).add(rotate64(s, 30)).add(o),
      l = hashLen16(i, r.add(rotate64(a.add(k2), 18)).add(s), n),
      u = fetch64(e, 16).mul(n),
      c = fetch64(e, 24),
      p = i.add(fetch64(e, t - 32)).mul(n),
      d = l.add(fetch64(e, t - 24)).mul(n);
  return hashLen16(rotate64(u.add(c), 43).add(rotate64(p, 30)).add(d), u.add(rotate64(c.add(r), 18)).add(p), n);
}

function fingerPrint64(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : e.length;
  var n = Long.fromNumber(81, !0);
  if (t <= 32) return t <= 16 ? hashLen0to16(e, t) : hashLen17to32(e, t);
  if (t <= 64) return hashLen33to64(e, t);
  var r = n,
      a = n.mul(k1).add(113),
      s = shiftMix(a.mul(k2).add(113)).mul(k2),
      o = [Long.UZERO, Long.UZERO],
      i = [Long.UZERO, Long.UZERO];
  r = r.mul(k2).add(fetch64(e, 0));
  var l = 0;
  var u = 64 * (t - 1 >> 6),
      c = u + (t - 1 & 63) - 63;

  do {
    r = rotate64(r.add(a).add(o[0]).add(fetch64(e, l + 8)), 37).mul(k1), a = rotate64(a.add(o[1]).add(fetch64(e, l + 48)), 42).mul(k1), r = r.xor(i[1]), a = a.add(o[0]).add(fetch64(e, l + 40)), s = rotate64(s.add(i[0]), 33).mul(k1), o = weakHashLen32WithSeedsStr(e, l, o[1].mul(k1), r.add(i[0])), i = weakHashLen32WithSeedsStr(e, l + 32, s.add(i[1]), a.add(fetch64(e, l + 16))), [s, r] = [r, s], l += 64;
  } while (l !== u);

  var p = k1.add(s.and(255).shl(1));
  return l = c, i[0] = i[0].add(t - 1 & 63), o[0] = o[0].add(i[0]), i[0] = i[0].add(o[0]), r = rotate64(r.add(a).add(o[0]).add(fetch64(e, l + 8)), 37).mul(p), a = rotate64(a.add(o[1]).add(fetch64(e, l + 48)), 42).mul(p), r = r.xor(i[1].mul(9)), a = a.add(o[0].mul(9).add(fetch64(e, l + 40))), s = rotate64(s.add(i[0]), 33).mul(p), o = weakHashLen32WithSeedsStr(e, l, o[1].mul(p), r.add(i[0])), i = weakHashLen32WithSeedsStr(e, l + 32, s.add(i[1]), a.add(fetch64(e, l + 16))), [s, r] = [r, s], hashLen16(hashLen16(o[0], i[0], p).add(shiftMix(a).mul(k0)).add(s), hashLen16(o[1], i[1], p).add(r), p);
}

function createScalarValue(e, t) {
  return "string" === t ? encodeString(e) : toTypedArray([e], t);
}

function noConversionNeeded(e, t) {
  return e instanceof Float32Array && "float32" === t || e instanceof Int32Array && "int32" === t || e instanceof Uint8Array && "bool" === t;
}

function toTypedArray(e, t) {
  if ("string" === t) throw new Error("Cannot convert a string[] to a TypedArray");
  if (Array.isArray(e) && (e = flatten$3(e)), env().getBool("DEBUG") && checkConversionForErrors(e, t), noConversionNeeded(e, t)) return e;
  if (null == t || "float32" === t || "complex64" === t) return new Float32Array(e);
  if ("int32" === t) return new Int32Array(e);

  if ("bool" === t) {
    var _t366 = new Uint8Array(e.length);

    for (var n = 0; n < _t366.length; ++n) {
      0 !== Math.round(e[n]) && (_t366[n] = 1);
    }

    return _t366;
  }

  throw new Error("Unknown data type ".concat(t));
}

function now() {
  return env().platform.now();
}

function fetch$1(e, t) {
  return env().platform.fetch(e, t);
}

function encodeString(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : "utf-8";
  return t = t || "utf-8", env().platform.encode(e, t);
}

function decodeString(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : "utf-8";
  return t = t || "utf-8", env().platform.decode(e, t);
}

var util = {
  __proto__: null,
  createScalarValue,
  toTypedArray,
  now,
  fetch: fetch$1,
  encodeString,
  decodeString,
  shuffle,
  shuffleCombo,
  clamp,
  nearestLargerEven,
  swap,
  sum: sum$3,
  randUniform,
  distSquared,
  assert: assert$4,
  assertShapesMatch,
  assertNonNull,
  flatten: flatten$3,
  sizeFromShape,
  isScalarShape,
  arraysEqual,
  isInt,
  tanh: tanh$3,
  sizeToSquarishShape,
  createShuffledIndices,
  rightPad,
  repeatedTry,
  inferFromImplicitShape,
  parseAxisParam,
  squeezeShape,
  getTypedArrayFromDType,
  getArrayFromDType,
  checkConversionForErrors,
  isValidDtype,
  hasEncodingLoss,
  isTypedArray,
  bytesPerElement,
  bytesFromStringArray,
  isString,
  isBoolean,
  isNumber,
  inferDtype,
  isFunction,
  nearestDivisor,
  computeStrides,
  toNestedArray,
  makeOnesTypedArray,
  makeZerosTypedArray,
  makeZerosNestedTypedArray,
  assertNonNegativeIntegerDimensions,
  locToIndex,
  indexToLoc,
  isPromise,
  hexToLong,
  fingerPrint64
};

class Profiler {
  constructor(e, t) {
    this.backendTimer = e, this.logger = t, null == t && (this.logger = new Logger());
  }

  profileKernel(e, t, n) {
    var r;

    var a = () => {
      r = n();
    };

    var s;
    var o = now();
    if (this.backendTimer.timerAvailable()) s = this.backendTimer.time(a);else {
      a();

      for (var _e519 of r) {
        _e519.dataSync();
      }

      s = Promise.resolve({
        kernelMs: now() - o
      });
    }

    if (env().getBool("CHECK_COMPUTATION_FOR_ERRORS")) {
      var _loop28 = function _loop28(_t367) {
        var n = r[_t367];
        n.data().then(t => {
          checkComputationForErrors(t, n.dtype, e);
        });
      };

      for (var _t367 = 0; _t367 < r.length; _t367++) {
        _loop28(_t367);
      }
    }

    return {
      kernelName: e,
      outputs: r,
      inputs: t,
      timeMs: s.then(e => e.kernelMs),
      extraInfo: s.then(e => null != e.getExtraProfileInfo ? e.getExtraProfileInfo() : "")
    };
  }

  logKernelProfile(e) {
    var {
      kernelName: t,
      outputs: n,
      timeMs: r,
      inputs: a,
      extraInfo: s
    } = e;
    n.forEach(e => {
      Promise.all([e.data(), r, s]).then(n => {
        this.logger.logKernelProfile(t, e, n[0], n[1], a, n[2]);
      });
    });
  }

}

function checkComputationForErrors(e, t, n) {
  if ("float32" !== t) return !1;

  for (var _t368 = 0; _t368 < e.length; _t368++) {
    var r = e[_t368];
    if (isNaN(r) || !isFinite(r)) return console.warn("Found ".concat(r, " in the result of '").concat(n, "'")), !0;
  }

  return !1;
}

class Logger {
  logKernelProfile(e, t, n, r, a, s) {
    var o = "number" == typeof r ? rightPad("".concat(r, "ms"), 9) : r.error,
        i = rightPad(e, 25),
        l = t.rank,
        u = t.size,
        c = rightPad(t.shape.toString(), 14);
    var p = "";

    for (var _e520 in a) {
      var _n219 = a[_e520];

      if (null != _n219) {
        var _r178 = _n219.shape || t.shape,
            _a118 = _r178.length;

        p += "".concat(_e520, ": ").concat(_a118, "D ").concat(_a118 > 0 ? _r178 : "", " ");
      }
    }

    console.log("%c".concat(i, "\t%c").concat(o, "\t%c").concat(l, "D ").concat(c, "\t%c").concat(u, "\t%c").concat(p, "\t%c").concat(s), "font-weight:bold", "color:red", "color:blue", "color: orange", "color: green", "color: steelblue");
  }

}

function getFilteredNodesXToY(e, t, n) {
  var r = {},
      a = {};

  for (var _e521 = 0; _e521 < t.length; _e521++) {
    r[t[_e521].id] = !0;
  }

  for (var _n220 = 0; _n220 < e.length; _n220++) {
    var _s91 = e[_n220],
        _o66 = _s91.inputs;

    for (var _e522 in _o66) {
      var _n221 = _o66[_e522];

      var _i41 = !1;

      for (var _e523 = 0; _e523 < t.length; _e523++) {
        if (r[_n221.id]) {
          _s91.outputs.forEach(e => r[e.id] = !0), _i41 = !0, a[_s91.id] = !0;
          break;
        }
      }

      if (_i41) break;
    }
  }

  var s = {};
  s[n.id] = !0;
  var o = {};

  for (var _t369 = e.length - 1; _t369 >= 0; _t369--) {
    var _n222 = e[_t369],
        _r179 = _n222.inputs;

    for (var _e524 = 0; _e524 < _n222.outputs.length; _e524++) {
      if (s[_n222.outputs[_e524].id]) {
        for (var _e525 in _r179) {
          s[_r179[_e525].id] = !0, o[_n222.id] = !0;
        }

        break;
      }
    }
  }

  var i = [];

  for (var _t370 = 0; _t370 < e.length; _t370++) {
    var _n223 = e[_t370];

    if (a[_n223.id] && o[_n223.id]) {
      var _e526 = {};

      for (var _t372 in _n223.inputs) {
        var _a119 = _n223.inputs[_t372];
        r[_a119.id] && (_e526[_t372] = _a119);
      }

      var _t371 = Object.assign({}, _n223);

      _t371.inputs = _e526, _t371.outputs = _n223.outputs, i.push(_t371);
    }
  }

  return i;
}

function backpropagateGradients(e, t, n, r) {
  var _loop29 = function _loop29(a) {
    var s = t[a],
        o = [];
    if (s.outputs.forEach(t => {
      var n = e[t.id];
      o.push(null != n ? n : null);
    }), null == s.gradient) throw new Error("Cannot compute gradient: gradient function not found for ".concat(s.kernelName, "."));
    var i = s.gradient(o);

    var _loop30 = function _loop30(_t373) {
      if (!(_t373 in i)) throw new Error("Cannot backprop through input ".concat(_t373, ". Available gradients found: ").concat(Object.keys(i), "."));
      var a = n(() => i[_t373]());
      if ("float32" !== a.dtype) throw new Error("Error in gradient for op ".concat(s.kernelName, ". The gradient of input ").concat(_t373, " must have 'float32' dtype, but has '").concat(a.dtype, "'"));
      var o = s.inputs[_t373];
      if (!arraysEqual(a.shape, o.shape)) throw new Error("Error in gradient for op ".concat(s.kernelName, ". The gradient of input '").concat(_t373, "' has shape '").concat(a.shape, "', which does not match the shape of the input '").concat(o.shape, "'"));
      if (null == e[o.id]) e[o.id] = a;else {
        var _t374 = e[o.id];
        e[o.id] = r(_t374, a), _t374.dispose();
      }
    };

    for (var _t373 in s.inputs) {
      _loop30(_t373);
    }
  };

  for (var a = t.length - 1; a >= 0; a--) {
    _loop29(a);
  }
}

var FORMAT_LIMIT_NUM_VALS = 20,
    FORMAT_NUM_FIRST_LAST_VALS = 3,
    FORMAT_NUM_SIG_DIGITS = 7;

function tensorToString(e, t, n, r) {
  var a = computeStrides(t),
      s = computeMaxSizePerColumn(e, t, n, a),
      o = t.length,
      i = subTensorToString(e, t, n, a, s),
      l = ["Tensor"];
  return r && (l.push("  dtype: ".concat(n)), l.push("  rank: ".concat(o)), l.push("  shape: [".concat(t, "]")), l.push("  values:")), l.push(i.map(e => "    " + e).join("\n")), l.join("\n");
}

function computeMaxSizePerColumn(e, t, n, r) {
  var a = sizeFromShape(t),
      s = r[r.length - 1],
      o = new Array(s).fill(0),
      i = t.length,
      l = "complex64" === n ? createComplexTuples(e) : e;
  if (i > 1) for (var _e527 = 0; _e527 < a / s; _e527++) {
    var _t375 = _e527 * s;

    for (var _e528 = 0; _e528 < s; _e528++) {
      o[_e528] = Math.max(o[_e528], valToString(l[_t375 + _e528], 0, n).length);
    }
  }
  return o;
}

function valToString(e, t, n) {
  var r;
  return r = Array.isArray(e) ? "".concat(parseFloat(e[0].toFixed(FORMAT_NUM_SIG_DIGITS)), " + ").concat(parseFloat(e[1].toFixed(FORMAT_NUM_SIG_DIGITS)), "j") : isString(e) ? "'".concat(e, "'") : "bool" === n ? boolNumToString(e) : parseFloat(e.toFixed(FORMAT_NUM_SIG_DIGITS)).toString(), rightPad(r, t);
}

function boolNumToString(e) {
  return 0 === e ? "false" : "true";
}

function subTensorToString(e, t, n, r, a) {
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : !0;
  var o = "complex64" === n ? 2 : 1,
      i = t[0],
      l = t.length;
  if (0 === l) return "complex64" === n ? [valToString(createComplexTuples(e)[0], 0, n)] : "bool" === n ? [boolNumToString(e[0])] : [e[0].toString()];

  if (1 === l) {
    if (i > FORMAT_LIMIT_NUM_VALS) {
      var _t376 = Array.from(e.slice(0, FORMAT_NUM_FIRST_LAST_VALS * o)),
          _r180 = Array.from(e.slice((i - FORMAT_NUM_FIRST_LAST_VALS) * o, i * o));

      return "complex64" === n && (_t376 = createComplexTuples(_t376), _r180 = createComplexTuples(_r180)), ["[" + _t376.map((e, t) => valToString(e, a[t], n)).join(", ") + ", ..., " + _r180.map((e, t) => valToString(e, a[i - FORMAT_NUM_FIRST_LAST_VALS + t], n)).join(", ") + "]"];
    }

    return ["[" + ("complex64" === n ? createComplexTuples(e) : Array.from(e)).map((e, t) => valToString(e, a[t], n)).join(", ") + "]"];
  }

  var u = t.slice(1),
      c = r.slice(1),
      p = r[0] * o,
      d = [];

  if (i > FORMAT_LIMIT_NUM_VALS) {
    for (var _t377 = 0; _t377 < FORMAT_NUM_FIRST_LAST_VALS; _t377++) {
      var _r181 = _t377 * p;

      d.push(...subTensorToString(e.slice(_r181, _r181 + p), u, n, c, a, !1));
    }

    d.push("...");

    for (var _t378 = i - FORMAT_NUM_FIRST_LAST_VALS; _t378 < i; _t378++) {
      var _r182 = _t378 * p;

      d.push(...subTensorToString(e.slice(_r182, _r182 + p), u, n, c, a, _t378 === i - 1));
    }
  } else for (var _t379 = 0; _t379 < i; _t379++) {
    var _r183 = _t379 * p;

    d.push(...subTensorToString(e.slice(_r183, _r183 + p), u, n, c, a, _t379 === i - 1));
  }

  var h = 2 === l ? "," : "";
  d[0] = "[" + d[0] + h;

  for (var _e529 = 1; _e529 < d.length - 1; _e529++) {
    d[_e529] = " " + d[_e529] + h;
  }

  var m = ",\n";

  for (var _e530 = 2; _e530 < l; _e530++) {
    m += "\n";
  }

  return d[d.length - 1] = " " + d[d.length - 1] + "]" + (s ? "" : m), d;
}

function createComplexTuples(e) {
  var t = [];

  for (var n = 0; n < e.length; n += 2) {
    t.push([e[n], e[n + 1]]);
  }

  return t;
}

class TensorBuffer {
  constructor(e, t, n) {
    if (this.dtype = t, this.shape = e.slice(), this.size = sizeFromShape(e), null != n) {
      var _e531 = n.length;
      assert$4(_e531 === this.size, () => "Length of values '".concat(_e531, "' does not match the size inferred by the shape '").concat(this.size, "'."));
    }

    if ("complex64" === t) throw new Error("complex64 dtype TensorBuffers are not supported. Please create a TensorBuffer for the real and imaginary parts separately and call tf.complex(real, imag).");
    this.values = n || getArrayFromDType(t, this.size), this.strides = computeStrides(e);
  }

  set(e) {
    for (var _len6 = arguments.length, t = new Array(_len6 > 1 ? _len6 - 1 : 0), _key6 = 1; _key6 < _len6; _key6++) {
      t[_key6 - 1] = arguments[_key6];
    }

    0 === t.length && (t = [0]), assert$4(t.length === this.rank, () => "The number of provided coordinates (".concat(t.length, ") must match the rank (").concat(this.rank, ")"));
    var n = this.locToIndex(t);
    this.values[n] = e;
  }

  get() {
    for (var _len7 = arguments.length, e = new Array(_len7), _key7 = 0; _key7 < _len7; _key7++) {
      e[_key7] = arguments[_key7];
    }

    0 === e.length && (e = [0]);
    var t = 0;

    for (var _n224 of e) {
      if (_n224 < 0 || _n224 >= this.shape[t]) throw new Error("Requested out of range element at ".concat(e, ".   Buffer shape=").concat(this.shape));
      t++;
    }

    var n = e[e.length - 1];

    for (var _t380 = 0; _t380 < e.length - 1; ++_t380) {
      n += this.strides[_t380] * e[_t380];
    }

    return this.values[n];
  }

  locToIndex(e) {
    if (0 === this.rank) return 0;
    if (1 === this.rank) return e[0];
    var t = e[e.length - 1];

    for (var n = 0; n < e.length - 1; ++n) {
      t += this.strides[n] * e[n];
    }

    return t;
  }

  indexToLoc(e) {
    if (0 === this.rank) return [];
    if (1 === this.rank) return [e];
    var t = new Array(this.shape.length);

    for (var n = 0; n < t.length - 1; ++n) {
      t[n] = Math.floor(e / this.strides[n]), e -= t[n] * this.strides[n];
    }

    return t[t.length - 1] = e, t;
  }

  get rank() {
    return this.shape.length;
  }

  toTensor() {
    return trackerFn().makeTensor(this.values, this.shape, this.dtype);
  }

}

var trackerFn = null,
    opHandler$1 = null;

function setTensorTracker(e) {
  trackerFn = e;
}

function setOpHandler(e) {
  opHandler$1 = e;
}

class Tensor {
  constructor(e, t, n, r) {
    this.kept = !1, this.isDisposedInternal = !1, this.shape = e.slice(), this.dtype = t || "float32", this.size = sizeFromShape(e), this.strides = computeStrides(e), this.dataId = n, this.id = r, this.rankType = this.rank < 5 ? this.rank.toString() : "higher";
  }

  get rank() {
    return this.shape.length;
  }

  buffer() {
    var _this77 = this;

    return _asyncToGenerator(function* () {
      var e = yield _this77.data();
      return opHandler$1.buffer(_this77.shape, _this77.dtype, e);
    })();
  }

  bufferSync() {
    return opHandler$1.buffer(this.shape, this.dtype, this.dataSync());
  }

  array() {
    var _this78 = this;

    return _asyncToGenerator(function* () {
      var e = yield _this78.data();
      return toNestedArray(_this78.shape, e, "complex64" === _this78.dtype);
    })();
  }

  arraySync() {
    return toNestedArray(this.shape, this.dataSync(), "complex64" === this.dtype);
  }

  data() {
    var _this79 = this;

    return _asyncToGenerator(function* () {
      _this79.throwIfDisposed();

      var e = trackerFn().read(_this79.dataId);

      if ("string" === _this79.dtype) {
        var t = yield e;

        try {
          return t.map(e => decodeString(e));
        } catch (e) {
          throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().");
        }
      }

      return e;
    })();
  }

  dataSync() {
    this.throwIfDisposed();
    var e = trackerFn().readSync(this.dataId);
    if ("string" === this.dtype) try {
      return e.map(e => decodeString(e));
    } catch (e) {
      throw new Error("Failed to decode the string bytes into utf-8. To get the original bytes, call tensor.bytes().");
    }
    return e;
  }

  bytes() {
    var _this80 = this;

    return _asyncToGenerator(function* () {
      _this80.throwIfDisposed();

      var e = yield trackerFn().read(_this80.dataId);
      return "string" === _this80.dtype ? e : new Uint8Array(e.buffer);
    })();
  }

  dispose() {
    this.isDisposed || (trackerFn().disposeTensor(this), this.isDisposedInternal = !0);
  }

  get isDisposed() {
    return this.isDisposedInternal;
  }

  throwIfDisposed() {
    if (this.isDisposed) throw new Error("Tensor is disposed.");
  }

  print() {
    var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : !1;
    return opHandler$1.print(this, e);
  }

  clone() {
    return this.throwIfDisposed(), opHandler$1.clone(this);
  }

  toString() {
    var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : !1;
    return tensorToString(this.dataSync(), this.shape, this.dtype, e);
  }

  cast(e) {
    return this.throwIfDisposed(), opHandler$1.cast(this, e);
  }

  variable() {
    var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : !0;
    var t = arguments.length > 1 ? arguments[1] : undefined;
    var n = arguments.length > 2 ? arguments[2] : undefined;
    return this.throwIfDisposed(), trackerFn().makeVariable(this, e, t, n);
  }

}

function getGlobalTensorClass() {
  return getGlobal("Tensor", () => Tensor);
}

Object.defineProperty(Tensor, Symbol.hasInstance, {
  value: e => !!e && null != e.data && null != e.dataSync && null != e.throwIfDisposed
}), getGlobalTensorClass();

class Variable extends Tensor {
  constructor(e, t, n, r) {
    super(e.shape, e.dtype, e.dataId, r), this.trainable = t, this.name = n;
  }

  assign(e) {
    if (e.dtype !== this.dtype) throw new Error("dtype of the new value (".concat(e.dtype, ") and previous value (").concat(this.dtype, ") must match"));
    if (!arraysEqual(e.shape, this.shape)) throw new Error("shape of the new value (".concat(e.shape, ") and previous value (").concat(this.shape, ") must match"));
    trackerFn().disposeTensor(this), this.dataId = e.dataId, trackerFn().incRef(this, null);
  }

  dispose() {
    trackerFn().disposeVariable(this), this.isDisposedInternal = !0;
  }

}

var Rank, UpcastInt32AndMap, UpcastBoolAndMap, UpcastFloat32AndMap, UpcastComplex64AndMap;
Object.defineProperty(Variable, Symbol.hasInstance, {
  value: e => e instanceof Tensor && null != e.assign && e.assign instanceof Function
}), function (e) {
  e.R0 = "R0", e.R1 = "R1", e.R2 = "R2", e.R3 = "R3", e.R4 = "R4", e.R5 = "R5", e.R6 = "R6";
}(Rank || (Rank = {})), function (e) {
  e.float32 = "float32", e.int32 = "int32", e.bool = "int32", e.complex64 = "complex64";
}(UpcastInt32AndMap || (UpcastInt32AndMap = {})), function (e) {
  e.float32 = "float32", e.int32 = "int32", e.bool = "bool", e.complex64 = "complex64";
}(UpcastBoolAndMap || (UpcastBoolAndMap = {})), function (e) {
  e.float32 = "float32", e.int32 = "float32", e.bool = "float32", e.complex64 = "complex64";
}(UpcastFloat32AndMap || (UpcastFloat32AndMap = {})), function (e) {
  e.float32 = "complex64", e.int32 = "complex64", e.bool = "complex64", e.complex64 = "complex64";
}(UpcastComplex64AndMap || (UpcastComplex64AndMap = {}));
var upcastTypeMap = {
  float32: UpcastFloat32AndMap,
  int32: UpcastInt32AndMap,
  bool: UpcastBoolAndMap,
  complex64: UpcastComplex64AndMap
};

function upcastType(e, t) {
  if ("string" === e || "string" === t) {
    if ("string" === e && "string" === t) return "string";
    throw new Error("Can not upcast ".concat(e, " with ").concat(t));
  }

  return upcastTypeMap[e][t];
}

function sumOutType(e) {
  return upcastType(e, "int32");
}

function makeTypesMatch(e, t) {
  if (e.dtype === t.dtype) return [e, t];
  var n = upcastType(e.dtype, t.dtype);
  return [e.cast(n), t.cast(n)];
}

function assertTypesMatch(e, t) {
  assert$4(e.dtype === t.dtype, () => "The dtypes of the first(".concat(e.dtype, ") and second(").concat(t.dtype, ") input must match"));
}

function isTensorInList(e, t) {
  return t.some(t => t.id === e.id);
}

function getTensorsInContainer(e) {
  var t = [];
  return walkTensorContainer(e, t, new Set()), t;
}

function walkTensorContainer(e, t, n) {
  if (null == e) return;
  if (e instanceof Tensor) return void t.push(e);
  if (!isIterable$1(e)) return;
  var r = e;

  for (var _e532 in r) {
    var a = r[_e532];
    n.has(a) || (n.add(a), walkTensorContainer(a, t, n));
  }
}

function isIterable$1(e) {
  return Array.isArray(e) || "object" == typeof e;
}

var tensor_util = {
  __proto__: null,
  makeTypesMatch,
  assertTypesMatch,
  isTensorInList,
  getTensorsInContainer
};

function isRegisteredKernelInvocation(e) {
  return null != e.kernelName;
}

class EngineState {
  constructor() {
    this.registeredVariables = {}, this.nextTapeNodeId = 0, this.numBytes = 0, this.numTensors = 0, this.numStringTensors = 0, this.numDataBuffers = 0, this.gradientDepth = 0, this.kernelDepth = 0, this.scopeStack = [], this.numDataMovesStack = [], this.nextScopeId = 0, this.tensorInfo = new WeakMap(), this.profiling = !1, this.activeProfile = {
      newBytes: 0,
      newTensors: 0,
      peakBytes: 0,
      kernels: [],
      result: null,

      get kernelNames() {
        return Array.from(new Set(this.kernels.map(e => e.name)));
      }

    };
  }

  dispose() {
    for (var _e533 in this.registeredVariables) {
      this.registeredVariables[_e533].dispose();
    }
  }

}

class Engine {
  constructor(e) {
    this.ENV = e, this.registry = {}, this.registryFactory = {}, this.pendingBackendInitId = 0, this.state = new EngineState();
  }

  ready() {
    var _this81 = this;

    return _asyncToGenerator(function* () {
      if (null != _this81.pendingBackendInit) return _this81.pendingBackendInit.then(() => {});
      if (null != _this81.backendInstance) return;

      var e = _this81.getSortedBackends();

      for (var t = 0; t < e.length; t++) {
        var n = e[t];
        if (yield _this81.initializeBackend(n).success) return void (yield _this81.setBackend(n));
      }

      throw new Error("Could not initialize any backends, all backend initializations failed.");
    })();
  }

  get backend() {
    if (null != this.pendingBackendInit) throw new Error("Backend '".concat(this.backendName, "' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods"));

    if (null == this.backendInstance) {
      var {
        name: _e534,
        asyncInit: t
      } = this.initializeBackendsAndReturnBest();
      if (t) throw new Error("The highest priority backend '".concat(_e534, "' has not yet been initialized. Make sure to await tf.ready() or await tf.setBackend() before calling other methods"));
      this.setBackend(_e534);
    }

    return this.backendInstance;
  }

  backendNames() {
    return Object.keys(this.registryFactory);
  }

  findBackend(e) {
    if (!(e in this.registry)) {
      if (!(e in this.registryFactory)) return null;
      {
        var {
          asyncInit: t
        } = this.initializeBackend(e);
        if (t) return null;
      }
    }

    return this.registry[e];
  }

  findBackendFactory(e) {
    return e in this.registryFactory ? this.registryFactory[e].factory : null;
  }

  registerBackend(e, t) {
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 1;
    return e in this.registryFactory ? (console.warn("".concat(e, " backend was already registered. Reusing existing backend factory.")), !1) : (this.registryFactory[e] = {
      factory: t,
      priority: n
    }, !0);
  }

  setBackend(e) {
    var _this82 = this;

    return _asyncToGenerator(function* () {
      if (null == _this82.registryFactory[e]) throw new Error("Backend name '".concat(e, "' not found in registry"));

      if (_this82.backendName = e, null == _this82.registry[e]) {
        _this82.backendInstance = null;

        var {
          success: t,
          asyncInit: n
        } = _this82.initializeBackend(e);

        if (!(n ? yield t : t)) return !1;
      }

      return _this82.backendInstance = _this82.registry[e], _this82.setupRegisteredKernels(), _this82.profiler = new Profiler(_this82.backendInstance), !0;
    })();
  }

  setupRegisteredKernels() {
    getKernelsForBackend(this.backendName).forEach(e => {
      null != e.setupFunc && e.setupFunc(this.backendInstance);
    });
  }

  disposeRegisteredKernels(e) {
    getKernelsForBackend(e).forEach(t => {
      null != t.disposeFunc && t.disposeFunc(this.registry[e]);
    });
  }

  initializeBackend(e) {
    var t = this.registryFactory[e];
    if (null == t) throw new Error("Cannot initialize backend ".concat(e, ", no registration found."));

    try {
      var n = t.factory();
      if (!n || n instanceof KernelBackend || "function" != typeof n.then) return this.registry[e] = n, {
        success: !0,
        asyncInit: !1
      };
      {
        var _t381 = ++this.pendingBackendInitId,
            r = n.then(n => !(_t381 < this.pendingBackendInitId || (this.registry[e] = n, this.pendingBackendInit = null, 0))).catch(n => (_t381 < this.pendingBackendInitId || (this.pendingBackendInit = null, console.warn("Initialization of backend ".concat(e, " failed")), console.warn(n.stack || n.message)), !1));

        return this.pendingBackendInit = r, {
          success: r,
          asyncInit: !0
        };
      }
    } catch (t) {
      return console.warn("Initialization of backend ".concat(e, " failed")), console.warn(t.stack || t.message), {
        success: !1,
        asyncInit: !1
      };
    }
  }

  removeBackend(e) {
    if (!(e in this.registryFactory)) throw new Error("".concat(e, " backend not found in registry"));
    this.backendName === e && null != this.pendingBackendInit && this.pendingBackendInitId++, e in this.registry && (this.disposeRegisteredKernels(e), this.registry[e].dispose(), delete this.registry[e]), delete this.registryFactory[e], this.backendName === e && (this.pendingBackendInit = null, this.backendName = null, this.backendInstance = null);
  }

  getSortedBackends() {
    if (0 === Object.keys(this.registryFactory).length) throw new Error("No backend found in registry.");
    return Object.keys(this.registryFactory).sort((e, t) => this.registryFactory[t].priority - this.registryFactory[e].priority);
  }

  initializeBackendsAndReturnBest() {
    var e = this.getSortedBackends();

    for (var t = 0; t < e.length; t++) {
      var n = e[t],
          {
        success: r,
        asyncInit: a
      } = this.initializeBackend(n);
      if (a || r) return {
        name: n,
        asyncInit: a
      };
    }

    throw new Error("Could not initialize any backends, all backend initializations failed.");
  }

  moveData(e, t) {
    var n = this.state.tensorInfo.get(t),
        r = n.backend,
        a = this.readSync(t),
        s = r.refCount(t);
    r.disposeData(t, !0), n.backend = e, e.move(t, a, n.shape, n.dtype, s), this.shouldCheckForMemLeaks() && this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1]++;
  }

  tidy(e, t) {
    var n,
        r = null;

    if (null == t) {
      if ("function" != typeof e) throw new Error("Please provide a function to tidy()");
      t = e;
    } else {
      if ("string" != typeof e && !(e instanceof String)) throw new Error("When calling with two arguments, the first argument to tidy() must be a string");
      if ("function" != typeof t) throw new Error("When calling with two arguments, the 2nd argument to tidy() must be a function");
      r = e;
    }

    return this.scopedRun(() => this.startScope(r), () => this.endScope(n), () => (n = t(), n instanceof Promise && console.error("Cannot return a Promise inside of tidy."), n));
  }

  scopedRun(e, t, n) {
    e();

    try {
      var _e535 = n();

      return t(), _e535;
    } catch (e) {
      throw t(), e;
    }
  }

  nextTensorId() {
    return Engine.nextTensorId++;
  }

  nextVariableId() {
    return Engine.nextVariableId++;
  }

  clone(e) {
    var t = ENGINE.runKernel(Identity$1, {
      x: e
    });
    return this.addTapeNode(this.state.activeScope.name, {
      x: e
    }, [t], e => ({
      x: () => ENGINE.runKernel(Cast, {
        x: e
      }, {
        dtype: "float32"
      })
    }), [], {}), t;
  }

  runKernel(e, t, n) {
    if (null == getKernel(e, this.backendName)) throw new Error("Kernel '".concat(e, "' not registered for backend '").concat(this.backendName, "'"));
    return this.runKernelFunc({
      kernelName: e,
      inputs: t,
      attrs: n
    });
  }

  shouldCheckForMemLeaks() {
    return this.ENV.getBool("IS_TEST");
  }

  checkKernelForMemLeak(e, t, n) {
    var r = this.backend.numDataIds();
    var a = 0;
    n.forEach(e => {
      a += "complex64" === e.dtype ? 3 : 1;
    });
    var s = r - t - a - this.state.numDataMovesStack[this.state.numDataMovesStack.length - 1];
    if (s > 0) throw new Error("Backend '".concat(this.backendName, "' has an internal memory leak (").concat(s, " data ids) after running '").concat(e, "'"));
  }

  runKernelFunc(e) {
    var t,
        n = [];
    var r = this.isTapeOn(),
        a = this.state.numBytes,
        s = this.state.numTensors;
    var o, i;
    this.shouldCheckForMemLeaks() && this.state.numDataMovesStack.push(0);
    var l = isRegisteredKernelInvocation(e) ? e.kernelName : null != this.state.activeScope ? this.state.activeScope.name : "";

    if (isRegisteredKernelInvocation(e)) {
      var {
        kernelName: _t382,
        inputs: _a120,
        attrs: _s92
      } = e,
          _l33 = getKernel(_t382, this.backendName);

      assert$4(null != _l33, () => "Cannot find registered kernel '".concat(_t382, "' for backend '").concat(this.backendName, "'")), o = () => {
        var e = this.backend.numDataIds();
        i = _l33.kernelFunc({
          inputs: _a120,
          attrs: _s92,
          backend: this.backend
        });
        var o = Array.isArray(i) ? i : [i];
        this.shouldCheckForMemLeaks() && this.checkKernelForMemLeak(_t382, e, o);
        var u = o.map(e => {
          if (null != e.rank) return e;
          var {
            dataId: t,
            shape: n,
            dtype: r
          } = e;
          return this.makeTensorFromDataId(t, n, r);
        });

        if (r) {
          var _e536 = this.getTensorsForGradient(_t382, _a120, u);

          n = this.saveTensorsForBackwardMode(_e536);
        }

        return u;
      };
    } else {
      var {
        forwardFunc: _t383
      } = e,
          _a121 = e => {
        r && (n = e.map(e => this.keep(this.clone(e))));
      };

      o = () => {
        var e = this.backend.numDataIds();
        i = this.tidy(() => _t383(this.backend, _a121));
        var n = Array.isArray(i) ? i : [i];
        return this.shouldCheckForMemLeaks() && this.checkKernelForMemLeak(l, e, n), n;
      };
    }

    var {
      inputs: u,
      attrs: c
    } = e,
        p = isRegisteredKernelInvocation(e) ? null : e.backwardsFunc;
    var d;
    return this.scopedRun(() => this.state.kernelDepth++, () => this.state.kernelDepth--, () => {
      this.ENV.getBool("DEBUG") || this.state.profiling ? (d = this.profiler.profileKernel(l, u, () => o()), this.ENV.getBool("DEBUG") && this.profiler.logKernelProfile(d), t = d.outputs) : t = o();
    }), r && this.addTapeNode(l, u, t, p, n, c), this.state.profiling && this.state.activeProfile.kernels.push({
      name: l,
      bytesAdded: this.state.numBytes - a,
      totalBytesSnapshot: this.state.numBytes,
      tensorsAdded: this.state.numTensors - s,
      totalTensorsSnapshot: this.state.numTensors,
      inputShapes: Object.keys(u).map(e => null != u[e] ? u[e].shape : null),
      outputShapes: t.map(e => e.shape),
      kernelTimeMs: d.timeMs,
      extraInfo: d.extraInfo
    }), Array.isArray(i) ? t : t[0];
  }

  saveTensorsForBackwardMode(e) {
    var t = e.map(e => this.keep(this.clone(e)));
    return t;
  }

  getTensorsForGradient(e, t, n) {
    var r = getGradient(e);

    if (null != r) {
      var _e537 = r.inputsToSave || [],
          a = r.outputsToSave || [];

      var s;
      r.saveAllInputs ? (assert$4(Array.isArray(t), () => "saveAllInputs is true, expected inputs to be an array."), s = Object.keys(t).map(e => t[e])) : s = _e537.map(e => t[e]);
      var o = n.filter((e, t) => a[t]);
      return s.concat(o);
    }

    return [];
  }

  makeTensor(e, t, n, r) {
    if (null == e) throw new Error("Values passed to engine.makeTensor() are null");
    r = r || this.backend;
    var a = e;
    "string" === (n = n || "float32") && isString(e[0]) && (a = e.map(e => encodeString(e)));
    var s = r.write(a, t, n),
        o = new Tensor(t, n, s, this.nextTensorId());

    if (this.trackTensor(o, r), "string" === n) {
      var _e538 = this.state.tensorInfo.get(s),
          _t384 = bytesFromStringArray(a);

      this.state.numBytes += _t384 - _e538.bytes, _e538.bytes = _t384;
    }

    return o;
  }

  makeTensorFromDataId(e, t, n, r) {
    var a = new Tensor(t, n = n || "float32", e, this.nextTensorId());
    return this.trackTensor(a, r), a;
  }

  makeVariable(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !0;
    var n = arguments.length > 2 ? arguments[2] : undefined;
    var r = arguments.length > 3 ? arguments[3] : undefined;
    n = n || this.nextVariableId().toString(), null != r && r !== e.dtype && (e = e.cast(r));
    var a = new Variable(e, t, n, this.nextTensorId());
    if (null != this.state.registeredVariables[a.name]) throw new Error("Variable with name ".concat(a.name, " was already registered"));
    return this.state.registeredVariables[a.name] = a, this.incRef(a, this.backend), a;
  }

  trackTensor(e, t) {
    this.state.numTensors++, "string" === e.dtype && this.state.numStringTensors++;
    var n = 0;
    "complex64" !== e.dtype && "string" !== e.dtype && (n = e.size * bytesPerElement(e.dtype)), this.state.numBytes += n, this.state.tensorInfo.has(e.dataId) || (this.state.numDataBuffers++, this.state.tensorInfo.set(e.dataId, {
      backend: t || this.backend,
      dtype: e.dtype,
      shape: e.shape,
      bytes: n
    })), e instanceof Variable || this.track(e);
  }

  incRef(e, t) {
    this.trackTensor(e, t), this.backend.incRef(e.dataId);
  }

  removeDataId(e, t) {
    this.state.tensorInfo.has(e) && this.state.tensorInfo.get(e).backend === t && (this.state.tensorInfo.delete(e), this.state.numDataBuffers--);
  }

  disposeTensor(e) {
    if (!this.state.tensorInfo.has(e.dataId)) return;
    var t = this.state.tensorInfo.get(e.dataId);

    if (this.state.numTensors--, "string" === e.dtype && (this.state.numStringTensors--, this.state.numBytes -= t.bytes), "complex64" !== e.dtype && "string" !== e.dtype) {
      var _t385 = e.size * bytesPerElement(e.dtype);

      this.state.numBytes -= _t385;
    }

    t.backend.disposeData(e.dataId) && this.removeDataId(e.dataId, t.backend);
  }

  disposeVariables() {
    for (var _e539 in this.state.registeredVariables) {
      this.disposeVariable(this.state.registeredVariables[_e539]);
    }
  }

  disposeVariable(e) {
    this.disposeTensor(e), null != this.state.registeredVariables[e.name] && delete this.state.registeredVariables[e.name];
  }

  memory() {
    var e = this.backend.memory();
    return e.numTensors = this.state.numTensors, e.numDataBuffers = this.state.numDataBuffers, e.numBytes = this.state.numBytes, this.state.numStringTensors > 0 && (e.unreliable = !0, null == e.reasons && (e.reasons = []), e.reasons.push("Memory usage by string tensors is approximate (2 bytes per character)")), e;
  }

  profile(e) {
    var _this83 = this;

    return _asyncToGenerator(function* () {
      _this83.state.profiling = !0;
      var t = _this83.state.numBytes,
          n = _this83.state.numTensors;
      _this83.state.activeProfile.kernels = [], _this83.state.activeProfile.result = yield e(), _this83.state.profiling = !1, _this83.state.activeProfile.peakBytes = Math.max(..._this83.state.activeProfile.kernels.map(e => e.totalBytesSnapshot)), _this83.state.activeProfile.newBytes = _this83.state.numBytes - t, _this83.state.activeProfile.newTensors = _this83.state.numTensors - n;

      for (var _e540 of _this83.state.activeProfile.kernels) {
        _e540.kernelTimeMs = yield _e540.kernelTimeMs, _e540.extraInfo = yield _e540.extraInfo;
      }

      return _this83.state.activeProfile;
    })();
  }

  isTapeOn() {
    return this.state.gradientDepth > 0 && 0 === this.state.kernelDepth;
  }

  addTapeNode(e, t, n, r, a, s) {
    var o = {
      id: this.state.nextTapeNodeId++,
      kernelName: e,
      inputs: t,
      outputs: n,
      saved: a
    },
        i = getGradient(e);
    null != i && (r = i.gradFunc), null != r && (o.gradient = e => (e = e.map((e, t) => {
      if (null == e) {
        var _e541 = n[t],
            _r184 = makeZerosTypedArray(_e541.size, _e541.dtype);

        return this.makeTensor(_r184, _e541.shape, _e541.dtype);
      }

      return e;
    }), r(e.length > 1 ? e : e[0], a, s))), this.state.activeTape.push(o);
  }

  keep(e) {
    return e.kept = !0, e;
  }

  startTape() {
    0 === this.state.gradientDepth && (this.state.activeTape = []), this.state.gradientDepth++;
  }

  endTape() {
    this.state.gradientDepth--;
  }

  startScope(e) {
    var t = {
      track: [],
      name: "unnamed scope",
      id: this.state.nextScopeId++
    };
    e && (t.name = e), this.state.scopeStack.push(t), this.state.activeScope = t;
  }

  endScope(e) {
    var t = getTensorsInContainer(e),
        n = new Set(t.map(e => e.id));

    for (var _e542 = 0; _e542 < this.state.activeScope.track.length; _e542++) {
      var _t386 = this.state.activeScope.track[_e542];
      _t386.kept || n.has(_t386.id) || _t386.dispose();
    }

    var r = this.state.scopeStack.pop();
    this.state.activeScope = 0 === this.state.scopeStack.length ? null : this.state.scopeStack[this.state.scopeStack.length - 1], t.forEach(e => {
      e.kept || e.scopeId !== r.id || this.track(e);
    });
  }

  gradients(e, t, n) {
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
    if (assert$4(t.length > 0, () => "gradients() received an empty list of xs."), null != n && "float32" !== n.dtype) throw new Error("dy must have 'float32' dtype, but has '".concat(n.dtype, "'"));
    var a = this.scopedRun(() => this.startTape(), () => this.endTape(), () => this.tidy("forward", e));
    assert$4(a instanceof Tensor, () => "The result y returned by f() must be a tensor.");
    var s = getFilteredNodesXToY(this.state.activeTape, t, a);
    if (!r && 0 === s.length && t.length > 0) throw new Error("Cannot compute gradient of y=f(x) with respect to x. Make sure that the f you passed encloses all operations that lead from x to y.");
    return this.tidy("backward", () => {
      var e = {};
      e[a.id] = null == n ? ones$2(a.shape) : n, backpropagateGradients(e, s, e => this.tidy(e), add$3);
      var r = t.map(t => e[t.id]);
      return 0 === this.state.gradientDepth && (this.state.activeTape.forEach(e => {
        for (var _t387 of e.saved) {
          _t387.dispose();
        }
      }), this.state.activeTape = null), {
        value: a,
        grads: r
      };
    });
  }

  customGrad(e) {
    var _this84 = this;

    return assert$4(isFunction(e), () => "The f passed in customGrad(f) must be a function."), function () {
      for (var _len8 = arguments.length, t = new Array(_len8), _key8 = 0; _key8 < _len8; _key8++) {
        t[_key8] = arguments[_key8];
      }

      var n;
      assert$4(t.every(e => e instanceof Tensor), () => "The args passed in customGrad(f)(x1, x2,...) must all be tensors");
      var r = {};
      return t.forEach((e, t) => {
        r[t] = e;
      }), _this84.runKernelFunc({
        forwardFunc: (r, a) => (n = e(...t, a), assert$4(n.value instanceof Tensor, () => "The function f passed in customGrad(f) must return an object where `obj.value` is a tensor"), assert$4(isFunction(n.gradFunc), () => "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function."), n.value),
        backwardsFunc: (e, r) => {
          var a = n.gradFunc(e, r),
              s = Array.isArray(a) ? a : [a];
          assert$4(s.length === t.length, () => "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns the same number of tensors as inputs passed to f(...)."), assert$4(s.every(e => e instanceof Tensor), () => "The function f passed in customGrad(f) must return an object where `obj.gradFunc` is a function that returns a list of only tensors.");
          var o = {};
          return s.forEach((e, t) => {
            o[t] = () => e;
          }), o;
        },
        inputs: r
      });
    };
  }

  readSync(e) {
    return this.state.tensorInfo.get(e).backend.readSync(e);
  }

  read(e) {
    return this.state.tensorInfo.get(e).backend.read(e);
  }

  time(e) {
    var _this85 = this;

    return _asyncToGenerator(function* () {
      var t = now(),
          n = yield _this85.backend.time(e);
      return n.wallMs = now() - t, n;
    })();
  }

  track(e) {
    return null != this.state.activeScope && (e.scopeId = this.state.activeScope.id, this.state.activeScope.track.push(e)), e;
  }

  get registeredVariables() {
    return this.state.registeredVariables;
  }

  reset() {
    this.pendingBackendInitId++, this.state.dispose(), this.ENV.reset(), this.state = new EngineState();

    for (var _e543 in this.registry) {
      this.disposeRegisteredKernels(_e543), this.registry[_e543].dispose(), delete this.registry[_e543];
    }

    this.backendName = null, this.backendInstance = null, this.pendingBackendInit = null;
  }

}

function ones$2(e) {
  var t = makeOnesTypedArray(sizeFromShape(e), "float32");
  return ENGINE.makeTensor(t, e, "float32");
}

function getOrMakeEngine() {
  var e = getGlobalNamespace();

  if (null == e._tfengine) {
    var t = new Environment(e);
    e._tfengine = new Engine(t);
  }

  return setEnvironmentGlobal(e._tfengine.ENV), setTensorTracker(() => e._tfengine), e._tfengine;
}

Engine.nextTensorId = 0, Engine.nextVariableId = 0;
var ENGINE = getOrMakeEngine();

function add$3(e, t) {
  return ENGINE.runKernel(Add$1, {
    a: e,
    b: t
  });
}

function _isNavigatorDefined() {
  return "undefined" != typeof navigator && null != navigator;
}

function isMobile(e) {
  if (e || _isNavigatorDefined()) {
    if (e || (e = navigator), "ReactNative" === e.product) return !0;
    var t = e.userAgent || e.vendor || window.opera;
    return /(android|bb\d+|meego).+mobile|avantgo|bada\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\.(browser|link)|vodafone|wap|windows ce|xda|xiino/i.test(t) || /1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\-(n|u)|c55\/|capi|ccwa|cdm\-|cell|chtm|cldc|cmd\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\-s|devi|dica|dmob|do(c|p)o|ds(12|\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\-|_)|g1 u|g560|gene|gf\-5|g\-mo|go(\.w|od)|gr(ad|un)|haie|hcit|hd\-(m|p|t)|hei\-|hi(pt|ta)|hp( i|ip)|hs\-c|ht(c(\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\-(20|go|ma)|i230|iac( |\-|\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\/)|klon|kpt |kwc\-|kyo(c|k)|le(no|xi)|lg( g|\/(k|l|u)|50|54|\-[a-w])|libw|lynx|m1\-w|m3ga|m50\/|ma(te|ui|xo)|mc(01|21|ca)|m\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\-2|po(ck|rt|se)|prox|psio|pt\-g|qa\-a|qc(07|12|21|32|60|\-[2-7]|i\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\-|oo|p\-)|sdk\/|se(c(\-|0|1)|47|mc|nd|ri)|sgh\-|shar|sie(\-|m)|sk\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\-|v\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\-|tdg\-|tel(i|m)|tim\-|t\-mo|to(pl|sh)|ts(70|m\-|m3|m5)|tx\-9|up(\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\-|your|zeto|zte\-/i.test(t.substr(0, 4));
  }

  return !1;
}

function isBrowser() {
  return "undefined" != typeof window && null != window.document || "undefined" != typeof WorkerGlobalScope;
}

var device_util = {
  __proto__: null,
  isMobile,
  isBrowser
};
var ENV$1 = env();

function inferShape(e, t) {
  var n = e;
  if (isTypedArray(e)) return "string" === t ? [] : [e.length];
  if (!Array.isArray(e)) return [];
  var r = [];

  for (; Array.isArray(n) || isTypedArray(n) && "string" !== t;) {
    r.push(n.length), n = n[0];
  }

  return Array.isArray(e) && env().getBool("TENSORLIKE_CHECK_SHAPE_CONSISTENCY") && deepAssertShapeConsistency(e, r, []), r;
}

function deepAssertShapeConsistency(e, t, n) {
  if (n = n || [], !Array.isArray(e) && !isTypedArray(e)) return void assert$4(0 === t.length, () => "Element arr[".concat(n.join("]["), "] is a primitive, but should be an array/TypedArray of ").concat(t[0], " elements"));
  assert$4(t.length > 0, () => "Element arr[".concat(n.join("]["), "] should be a primitive, but is an array of ").concat(e.length, " elements")), assert$4(e.length === t[0], () => "Element arr[".concat(n.join("]["), "] should have ").concat(t[0], " elements, but has ").concat(e.length, " elements"));
  var r = t.slice(1);

  for (var _t388 = 0; _t388 < e.length; ++_t388) {
    deepAssertShapeConsistency(e[_t388], r, n.concat(_t388));
  }
}

function assertDtype(e, t, n, r) {
  if ("string_or_numeric" !== e) {
    if (null == e) throw new Error("Expected dtype cannot be null.");
    if ("numeric" !== e && e !== t || "numeric" === e && "string" === t) throw new Error("Argument '".concat(n, "' passed to '").concat(r, "' must be ").concat(e, " tensor, but got ").concat(t, " tensor"));
  }
}

function convertToTensor(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : "numeric";
  if (e instanceof Tensor) return assertDtype(r, e.dtype, t, n), e;
  var a = inferDtype(e);
  if ("string" !== a && ["bool", "int32", "float32"].indexOf(r) >= 0 && (a = r), assertDtype(r, a, t, n), null == e || !isTypedArray(e) && !Array.isArray(e) && "number" != typeof e && "boolean" != typeof e && "string" != typeof e) throw new Error("Argument '".concat(t, "' passed to '").concat(n, "' must be a Tensor or TensorLike, but got '").concat(null == e ? "null" : e.constructor.name, "'"));
  var s = inferShape(e, a);
  isTypedArray(e) || Array.isArray(e) || (e = [e]);
  var o = "string" !== a ? toTypedArray(e, a) : flatten$3(e, [], !0);
  return ENGINE.makeTensor(o, s, a);
}

function convertToTensorArray(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : "numeric";
  if (!Array.isArray(e)) throw new Error("Argument ".concat(t, " passed to ").concat(n, " must be a `Tensor[]` or `TensorLike[]`"));
  return e.map((e, a) => convertToTensor(e, "".concat(t, "[").concat(a, "]"), n, r));
}

ENV$1.registerFlag("DEBUG", () => !1, e => {
  e && console.warn("Debugging mode is ON. The output of every math call will be downloaded to CPU and checked for NaNs. This significantly impacts performance.");
}), ENV$1.registerFlag("IS_BROWSER", () => isBrowser()), ENV$1.registerFlag("IS_NODE", () => "undefined" != typeof process && void 0 !== process.versions && void 0 !== process.versions.node), ENV$1.registerFlag("IS_CHROME", () => "undefined" != typeof navigator && null != navigator && null != navigator.userAgent && /Chrome/.test(navigator.userAgent) && /Google Inc/.test(navigator.vendor)), ENV$1.registerFlag("PROD", () => !1), ENV$1.registerFlag("TENSORLIKE_CHECK_SHAPE_CONSISTENCY", () => ENV$1.getBool("DEBUG")), ENV$1.registerFlag("DEPRECATION_WARNINGS_ENABLED", () => !0), ENV$1.registerFlag("IS_TEST", () => !1), ENV$1.registerFlag("CHECK_COMPUTATION_FOR_ERRORS", () => !0), ENV$1.registerFlag("WRAP_TO_IMAGEBITMAP", () => !1);
var OP_SCOPE_SUFFIX = "__op";

function op(e) {
  var t = Object.keys(e);
  if (1 !== t.length) throw new Error("Please provide an object with a single key (operation name) mapping to a function. Got an object with ".concat(t.length, " keys."));
  var n = t[0];
  var r = e[n];
  n.endsWith("_") && (n = n.substring(0, n.length - 1)), n += OP_SCOPE_SUFFIX;

  var a = function a() {
    ENGINE.startScope(n);

    try {
      var _t389 = r(...arguments);

      return isPromise(_t389) && console.error("Cannot return a Promise inside of tidy."), ENGINE.endScope(_t389), _t389;
    } catch (e) {
      throw ENGINE.endScope(null), e;
    }
  };

  return Object.defineProperty(a, "name", {
    value: n,
    configurable: !0
  }), a;
}

function complex_(e, t) {
  var n = convertToTensor(e, "real", "complex"),
      r = convertToTensor(t, "imag", "complex");
  return assertShapesMatch(n.shape, r.shape, "real and imag shapes, ".concat(n.shape, " and ").concat(r.shape, ", must match in call to tf.complex().")), ENGINE.runKernel(Complex, {
    real: n,
    imag: r
  });
}

var complex$2 = op({
  complex_
});

function makeTensor(e, t, n, r) {
  if (null == r && (r = inferDtype(e)), "complex64" === r) throw new Error("Cannot construct a complex64 tensor directly. Please use tf.complex(real, imag).");
  if (!isTypedArray(e) && !Array.isArray(e) && "number" != typeof e && "boolean" != typeof e && "string" != typeof e) throw new Error("values passed to tensor(values) must be a number/boolean/string or an array of numbers/booleans/strings, or a TypedArray");

  if (null != t) {
    assertNonNegativeIntegerDimensions(t);

    var _e544 = sizeFromShape(t),
        _r185 = sizeFromShape(n);

    assert$4(_e544 === _r185, () => "Based on the provided shape, [".concat(t, "], the tensor should have ").concat(_e544, " values but has ").concat(_r185));

    for (var _e545 = 0; _e545 < n.length; ++_e545) {
      var _r186 = n[_e545],
          a = _e545 !== n.length - 1 || _r186 !== sizeFromShape(t.slice(_e545));

      assert$4(n[_e545] === t[_e545] || !a, () => "Error creating a new Tensor. Inferred shape (".concat(n, ") does not match the provided shape (").concat(t, "). "));
    }
  }

  return isTypedArray(e) || Array.isArray(e) || (e = [e]), t = t || n, e = "string" !== r ? toTypedArray(e, r) : flatten$3(e, [], !0), ENGINE.makeTensor(e, t, r);
}

function tensor(e, t, n) {
  return makeTensor(e, t, inferShape(e, n), n);
}

var DTYPE_VALUE_SIZE_MAP = {
  float32: 4,
  float16: 2,
  int32: 4,
  uint16: 2,
  uint8: 1,
  bool: 1,
  complex64: 8
},
    NUM_BYTES_STRING_LENGTH = 4;

function encodeWeights(_x51, _x52) {
  return _encodeWeights.apply(this, arguments);
}

function _encodeWeights() {
  _encodeWeights = _asyncToGenerator(function* (e, t) {
    var n = [],
        r = [],
        a = Array.isArray(e) ? e.map(e => e.name) : Object.keys(e);

    var _loop65 = function _loop65(s) {
      var o = a[s],
          i = Array.isArray(e) ? e[s].tensor : e[o];
      if ("float32" !== i.dtype && "int32" !== i.dtype && "bool" !== i.dtype && "string" !== i.dtype && "complex64" !== i.dtype) throw new Error("Unsupported dtype in weight '".concat(o, "': ").concat(i.dtype));
      var l = {
        name: o,
        shape: i.shape,
        dtype: i.dtype
      };

      if ("string" === i.dtype) {
        var _e1150 = new Promise( /*#__PURE__*/function () {
          var _ref76 = _asyncToGenerator(function* (e) {
            var t = yield i.bytes(),
                n = t.reduce((e, t) => e + t.length, 0) + NUM_BYTES_STRING_LENGTH * t.length,
                r = new Uint8Array(n);
            var a = 0;

            for (var _e1151 = 0; _e1151 < t.length; _e1151++) {
              var _n454 = t[_e1151],
                  _s225 = new Uint8Array(new Uint32Array([_n454.length]).buffer);

              r.set(_s225, a), a += NUM_BYTES_STRING_LENGTH, r.set(_n454, a), a += _n454.length;
            }

            e(r);
          });

          return function (_x146) {
            return _ref76.apply(this, arguments);
          };
        }());

        r.push(_e1150);
      } else r.push(i.data());

      null != t && (l.group = t), n.push(l);
    };

    for (var s = 0; s < a.length; ++s) {
      _loop65(s);
    }

    return {
      data: concatenateTypedArrays(yield Promise.all(r)),
      specs: n
    };
  });
  return _encodeWeights.apply(this, arguments);
}

function decodeWeights(e, t) {
  var n = {};
  var r,
      a = 0;

  for (var s of t) {
    var _t390 = s.name,
        o = s.dtype,
        i = s.shape,
        l = sizeFromShape(i);
    var u = void 0;

    if ("quantization" in s) {
      var _n225 = s.quantization;

      if ("uint8" === _n225.dtype || "uint16" === _n225.dtype) {
        if (!("min" in _n225) || !("scale" in _n225)) throw new Error("Weight ".concat(s.name, " with quantization ").concat(_n225.dtype, " doesn't have corresponding metadata min and scale."));
      } else {
        if ("float16" !== _n225.dtype) throw new Error("Weight ".concat(s.name, " has unknown quantization dtype ").concat(_n225.dtype, ". Supported quantization dtypes are: 'uint8', 'uint16', and 'float16'."));
        if ("float32" !== o) throw new Error("Weight ".concat(s.name, " is quantized with ").concat(_n225.dtype, " which only supports weights of type float32 not ").concat(o, "."));
      }

      var _i42 = DTYPE_VALUE_SIZE_MAP[_n225.dtype],
          c = e.slice(a, a + l * _i42),
          _p18 = "uint8" === _n225.dtype ? new Uint8Array(c) : new Uint16Array(c);

      if ("float32" === o) {
        if ("uint8" === _n225.dtype || "uint16" === _n225.dtype) {
          u = new Float32Array(_p18.length);

          for (var _e546 = 0; _e546 < _p18.length; _e546++) {
            u[_e546] = _p18[_e546] * _n225.scale + _n225.min;
          }
        } else {
          if ("float16" !== _n225.dtype) throw new Error("Unsupported quantization type ".concat(_n225.dtype, " for weight type float32."));
          void 0 === r && (r = getFloat16Decoder()), u = r(_p18);
        }
      } else {
        if ("int32" !== o) throw new Error("Unsupported dtype in weight '".concat(_t390, "': ").concat(o));
        if ("uint8" !== _n225.dtype && "uint16" !== _n225.dtype) throw new Error("Unsupported quantization type ".concat(_n225.dtype, " for weight type int32."));
        u = new Int32Array(_p18.length);

        for (var _e547 = 0; _e547 < _p18.length; _e547++) {
          u[_e547] = Math.round(_p18[_e547] * _n225.scale + _n225.min);
        }
      }
      a += l * _i42;
    } else if ("string" === o) {
      var _t391 = sizeFromShape(s.shape);

      u = [];

      for (var _n226 = 0; _n226 < _t391; _n226++) {
        var _t392 = new Uint32Array(e.slice(a, a + NUM_BYTES_STRING_LENGTH))[0];
        a += NUM_BYTES_STRING_LENGTH;

        var _n227 = new Uint8Array(e.slice(a, a + _t392));

        u.push(_n227), a += _t392;
      }
    } else {
      var _r187 = DTYPE_VALUE_SIZE_MAP[o],
          _s93 = e.slice(a, a + l * _r187);

      if ("float32" === o) u = new Float32Array(_s93);else if ("int32" === o) u = new Int32Array(_s93);else if ("bool" === o) u = new Uint8Array(_s93);else {
        if ("complex64" !== o) throw new Error("Unsupported dtype in weight '".concat(_t390, "': ").concat(o));
        {
          u = new Float32Array(_s93);

          var _e548 = new Float32Array(u.length / 2),
              _r188 = new Float32Array(u.length / 2);

          for (var _t393 = 0; _t393 < _e548.length; _t393++) {
            _e548[_t393] = u[2 * _t393], _r188[_t393] = u[2 * _t393 + 1];
          }

          var _a122 = tensor(_e548, i, "float32"),
              _o67 = tensor(_r188, i, "float32");

          n[_t390] = complex$2(_a122, _o67), _a122.dispose(), _o67.dispose();
        }
      }
      a += l * _r187;
    }

    "complex64" !== o && (n[_t390] = tensor(u, i, o));
  }

  return n;
}

function concatenateTypedArrays(e) {
  if (null === e) throw new Error("Invalid input value: ".concat(JSON.stringify(e)));
  var t = 0;
  var n = [];
  e.forEach(e => {
    if (t += e.byteLength, n.push(e.byteLength === e.buffer.byteLength ? e : new e.constructor(e)), !(e instanceof Float32Array || e instanceof Int32Array || e instanceof Uint8Array)) throw new Error("Unsupported TypedArray subtype: ".concat(e.constructor.name));
  });
  var r = new Uint8Array(t);
  var a = 0;
  return n.forEach(e => {
    r.set(new Uint8Array(e.buffer), a), a += e.byteLength;
  }), r.buffer;
}

var useNodeBuffer = "undefined" != typeof Buffer && ("undefined" == typeof Blob || "undefined" == typeof atob || "undefined" == typeof btoa);

function stringByteLength(e) {
  return useNodeBuffer ? Buffer.byteLength(e) : new Blob([e]).size;
}

function arrayBufferToBase64String(e) {
  if (useNodeBuffer) return Buffer.from(e).toString("base64");
  var t = new Uint8Array(e);
  var n = "";

  for (var _e549 = 0, r = t.length; _e549 < r; _e549++) {
    n += String.fromCharCode(t[_e549]);
  }

  return btoa(n);
}

function base64StringToArrayBuffer(e) {
  if (useNodeBuffer) {
    var _t394 = Buffer.from(e, "base64");

    return _t394.buffer.slice(_t394.byteOffset, _t394.byteOffset + _t394.byteLength);
  }

  var t = atob(e),
      n = new Uint8Array(t.length);

  for (var _e550 = 0; _e550 < t.length; ++_e550) {
    n.set([t.charCodeAt(_e550)], _e550);
  }

  return n.buffer;
}

function concatenateArrayBuffers(e) {
  if (1 === e.length) return e[0];
  var t = 0;
  e.forEach(e => {
    t += e.byteLength;
  });
  var n = new Uint8Array(t);
  var r = 0;
  return e.forEach(e => {
    n.set(new Uint8Array(e), r), r += e.byteLength;
  }), n.buffer;
}

function basename(e) {
  for (e = e.trim(); e.endsWith("/");) {
    e = e.slice(0, e.length - 1);
  }

  var t = e.split("/");
  return t[t.length - 1];
}

function getModelJSONForModelArtifacts(e, t) {
  var n = {
    modelTopology: e.modelTopology,
    format: e.format,
    generatedBy: e.generatedBy,
    convertedBy: e.convertedBy,
    weightsManifest: t
  };
  return null != e.signature && (n.signature = e.signature), null != e.userDefinedMetadata && (n.userDefinedMetadata = e.userDefinedMetadata), null != e.modelInitializer && (n.modelInitializer = e.modelInitializer), null != e.trainingConfig && (n.trainingConfig = e.trainingConfig), n;
}

function getModelArtifactsForJSON(_x53, _x54) {
  return _getModelArtifactsForJSON.apply(this, arguments);
}

function _getModelArtifactsForJSON() {
  _getModelArtifactsForJSON = _asyncToGenerator(function* (e, t) {
    var n = {
      modelTopology: e.modelTopology,
      format: e.format,
      generatedBy: e.generatedBy,
      convertedBy: e.convertedBy
    };

    if (null != e.trainingConfig && (n.trainingConfig = e.trainingConfig), null != e.weightsManifest) {
      var [r, a] = yield t(e.weightsManifest);
      n.weightSpecs = r, n.weightData = a;
    }

    return null != e.signature && (n.signature = e.signature), null != e.userDefinedMetadata && (n.userDefinedMetadata = e.userDefinedMetadata), null != e.modelInitializer && (n.modelInitializer = e.modelInitializer), n;
  });
  return _getModelArtifactsForJSON.apply(this, arguments);
}

function getModelArtifactsInfoForJSON(e) {
  if (e.modelTopology instanceof ArrayBuffer) throw new Error("Expected JSON model topology, received ArrayBuffer.");
  return {
    dateSaved: new Date(),
    modelTopologyType: "JSON",
    modelTopologyBytes: null == e.modelTopology ? 0 : stringByteLength(JSON.stringify(e.modelTopology)),
    weightSpecsBytes: null == e.weightSpecs ? 0 : stringByteLength(JSON.stringify(e.weightSpecs)),
    weightDataBytes: null == e.weightData ? 0 : e.weightData.byteLength
  };
}

function computeFloat16MantisaTable() {
  var e = e => {
    var t = e << 13,
        n = 0;

    for (; 0 == (8388608 & t);) {
      n -= 8388608, t <<= 1;
    }

    return t &= -8388609, n += 947912704, t | n;
  },
      t = new Uint32Array(2048);

  t[0] = 0;

  for (var n = 1; n < 1024; n++) {
    t[n] = e(n);
  }

  for (var _e551 = 1024; _e551 < 2048; _e551++) {
    t[_e551] = 939524096 + (_e551 - 1024 << 13);
  }

  return t;
}

function computeFloat16ExponentTable() {
  var e = new Uint32Array(64);
  e[0] = 0, e[31] = 1199570944, e[32] = 2147483648, e[63] = 3347054592;

  for (var t = 1; t < 31; t++) {
    e[t] = t << 23;
  }

  for (var _t395 = 33; _t395 < 63; _t395++) {
    e[_t395] = 2147483648 + (_t395 - 32 << 23);
  }

  return e;
}

function computeFloat16OffsetTable() {
  var e = new Uint32Array(64);

  for (var t = 0; t < 64; t++) {
    e[t] = 1024;
  }

  return e[0] = e[32] = 0, e;
}

function getFloat16Decoder() {
  var e = computeFloat16MantisaTable(),
      t = computeFloat16ExponentTable(),
      n = computeFloat16OffsetTable();
  return r => {
    var a = new ArrayBuffer(4 * r.length),
        s = new Uint32Array(a);

    for (var _a123 = 0; _a123 < r.length; _a123++) {
      var o = r[_a123];
      s[_a123] = e[n[o >> 10] + (1023 & o)] + t[o >> 10];
    }

    return new Float32Array(a);
  };
}

class IORouterRegistry {
  constructor() {
    this.saveRouters = [], this.loadRouters = [];
  }

  static getInstance() {
    return null == IORouterRegistry.instance && (IORouterRegistry.instance = new IORouterRegistry()), IORouterRegistry.instance;
  }

  static registerSaveRouter(e) {
    IORouterRegistry.getInstance().saveRouters.push(e);
  }

  static registerLoadRouter(e) {
    IORouterRegistry.getInstance().loadRouters.push(e);
  }

  static getSaveHandlers(e) {
    return IORouterRegistry.getHandlers(e, "save");
  }

  static getLoadHandlers(e, t) {
    return IORouterRegistry.getHandlers(e, "load", t);
  }

  static getHandlers(e, t, n) {
    var r = [];
    return ("load" === t ? IORouterRegistry.getInstance().loadRouters : IORouterRegistry.getInstance().saveRouters).forEach(t => {
      var a = t(e, n);
      null !== a && r.push(a);
    }), r;
  }

}

var registerSaveRouter = e => IORouterRegistry.registerSaveRouter(e),
    registerLoadRouter = e => IORouterRegistry.registerLoadRouter(e),
    getSaveHandlers = e => IORouterRegistry.getSaveHandlers(e),
    getLoadHandlers = (e, t) => IORouterRegistry.getLoadHandlers(e, t),
    DATABASE_NAME = "tensorflowjs",
    DATABASE_VERSION = 1,
    MODEL_STORE_NAME = "models_store",
    INFO_STORE_NAME = "model_info_store";

function getIndexedDBFactory() {
  if (!env().getBool("IS_BROWSER")) throw new Error("Failed to obtain IndexedDB factory because the current environmentis not a web browser.");
  var e = "undefined" == typeof window ? self : window,
      t = e.indexedDB || e.mozIndexedDB || e.webkitIndexedDB || e.msIndexedDB || e.shimIndexedDB;
  if (null == t) throw new Error("The current browser does not appear to support IndexedDB.");
  return t;
}

function setUpDatabase(e) {
  var t = e.result;
  t.createObjectStore(MODEL_STORE_NAME, {
    keyPath: "modelPath"
  }), t.createObjectStore(INFO_STORE_NAME, {
    keyPath: "modelPath"
  });
}

class BrowserIndexedDB {
  constructor(e) {
    if (this.indexedDB = getIndexedDBFactory(), null == e || !e) throw new Error("For IndexedDB, modelPath must not be null, undefined or empty.");
    this.modelPath = e;
  }

  save(e) {
    var _this86 = this;

    return _asyncToGenerator(function* () {
      if (e.modelTopology instanceof ArrayBuffer) throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");
      return _this86.databaseAction(_this86.modelPath, e);
    })();
  }

  load() {
    var _this87 = this;

    return _asyncToGenerator(function* () {
      return _this87.databaseAction(_this87.modelPath);
    })();
  }

  databaseAction(e, t) {
    return new Promise((e, n) => {
      var r = this.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);
      r.onupgradeneeded = () => setUpDatabase(r), r.onsuccess = () => {
        var a = r.result;

        if (null == t) {
          var _t396 = a.transaction(MODEL_STORE_NAME, "readonly"),
              _r189 = _t396.objectStore(MODEL_STORE_NAME).get(this.modelPath);

          _r189.onsuccess = () => {
            if (null == _r189.result) return a.close(), n(new Error("Cannot find model with path '".concat(this.modelPath, "' in IndexedDB.")));
            e(_r189.result.modelArtifacts);
          }, _r189.onerror = e => (a.close(), n(_r189.error)), _t396.oncomplete = () => a.close();
        } else {
          var _r190 = getModelArtifactsInfoForJSON(t),
              s = a.transaction(INFO_STORE_NAME, "readwrite");

          var o = s.objectStore(INFO_STORE_NAME);
          var i = o.put({
            modelPath: this.modelPath,
            modelArtifactsInfo: _r190
          });
          var l;
          i.onsuccess = () => {
            l = a.transaction(MODEL_STORE_NAME, "readwrite");
            var i = l.objectStore(MODEL_STORE_NAME).put({
              modelPath: this.modelPath,
              modelArtifacts: t,
              modelArtifactsInfo: _r190
            });
            i.onsuccess = () => e({
              modelArtifactsInfo: _r190
            }), i.onerror = e => {
              o = s.objectStore(INFO_STORE_NAME);
              var t = o.delete(this.modelPath);
              t.onsuccess = () => (a.close(), n(i.error)), t.onerror = e => (a.close(), n(i.error));
            };
          }, i.onerror = e => (a.close(), n(i.error)), s.oncomplete = () => {
            null == l ? a.close() : l.oncomplete = () => a.close();
          };
        }
      }, r.onerror = e => n(r.error);
    });
  }

}

BrowserIndexedDB.URL_SCHEME = "indexeddb://";

var indexedDBRouter = e => env().getBool("IS_BROWSER") && !Array.isArray(e) && e.startsWith(BrowserIndexedDB.URL_SCHEME) ? browserIndexedDB(e.slice(BrowserIndexedDB.URL_SCHEME.length)) : null;

function browserIndexedDB(e) {
  return new BrowserIndexedDB(e);
}

function maybeStripScheme$1(e) {
  return e.startsWith(BrowserIndexedDB.URL_SCHEME) ? e.slice(BrowserIndexedDB.URL_SCHEME.length) : e;
}

IORouterRegistry.registerSaveRouter(indexedDBRouter), IORouterRegistry.registerLoadRouter(indexedDBRouter);

class BrowserIndexedDBManager {
  constructor() {
    this.indexedDB = getIndexedDBFactory();
  }

  listModels() {
    var _this88 = this;

    return _asyncToGenerator(function* () {
      return new Promise((e, t) => {
        var n = _this88.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);

        n.onupgradeneeded = () => setUpDatabase(n), n.onsuccess = () => {
          var r = n.result,
              a = r.transaction(INFO_STORE_NAME, "readonly"),
              s = a.objectStore(INFO_STORE_NAME).getAll();
          s.onsuccess = () => {
            var t = {};

            for (var _e552 of s.result) {
              t[_e552.modelPath] = _e552.modelArtifactsInfo;
            }

            e(t);
          }, s.onerror = e => (r.close(), t(s.error)), a.oncomplete = () => r.close();
        }, n.onerror = e => t(n.error);
      });
    })();
  }

  removeModel(e) {
    var _this89 = this;

    return _asyncToGenerator(function* () {
      return e = maybeStripScheme$1(e), new Promise((t, n) => {
        var r = _this89.indexedDB.open(DATABASE_NAME, DATABASE_VERSION);

        r.onupgradeneeded = () => setUpDatabase(r), r.onsuccess = () => {
          var a = r.result,
              s = a.transaction(INFO_STORE_NAME, "readwrite"),
              o = s.objectStore(INFO_STORE_NAME),
              i = o.get(e);
          var l;
          i.onsuccess = () => {
            if (null == i.result) return a.close(), n(new Error("Cannot find model with path '".concat(e, "' in IndexedDB.")));
            {
              var _r191 = o.delete(e),
                  _s94 = () => {
                l = a.transaction(MODEL_STORE_NAME, "readwrite");
                var r = l.objectStore(MODEL_STORE_NAME).delete(e);
                r.onsuccess = () => t(i.result.modelArtifactsInfo), r.onerror = e => n(i.error);
              };

              _r191.onsuccess = _s94, _r191.onerror = e => (_s94(), a.close(), n(i.error));
            }
          }, i.onerror = e => (a.close(), n(i.error)), s.oncomplete = () => {
            null == l ? a.close() : l.oncomplete = () => a.close();
          };
        }, r.onerror = e => n(r.error);
      });
    })();
  }

}

var PATH_SEPARATOR = "/",
    PATH_PREFIX = "tensorflowjs_models",
    INFO_SUFFIX = "info",
    MODEL_TOPOLOGY_SUFFIX = "model_topology",
    WEIGHT_SPECS_SUFFIX = "weight_specs",
    WEIGHT_DATA_SUFFIX = "weight_data",
    MODEL_METADATA_SUFFIX = "model_metadata";

function getModelKeys(e) {
  return {
    info: [PATH_PREFIX, e, INFO_SUFFIX].join(PATH_SEPARATOR),
    topology: [PATH_PREFIX, e, MODEL_TOPOLOGY_SUFFIX].join(PATH_SEPARATOR),
    weightSpecs: [PATH_PREFIX, e, WEIGHT_SPECS_SUFFIX].join(PATH_SEPARATOR),
    weightData: [PATH_PREFIX, e, WEIGHT_DATA_SUFFIX].join(PATH_SEPARATOR),
    modelMetadata: [PATH_PREFIX, e, MODEL_METADATA_SUFFIX].join(PATH_SEPARATOR)
  };
}

function removeItems(e) {
  for (var t of Object.values(e)) {
    window.localStorage.removeItem(t);
  }
}

function getModelPathFromKey(e) {
  var t = e.split(PATH_SEPARATOR);
  if (t.length < 3) throw new Error("Invalid key format: ".concat(e));
  return t.slice(1, t.length - 1).join(PATH_SEPARATOR);
}

function maybeStripScheme(e) {
  return e.startsWith(BrowserLocalStorage.URL_SCHEME) ? e.slice(BrowserLocalStorage.URL_SCHEME.length) : e;
}

class BrowserLocalStorage {
  constructor(e) {
    if (!env().getBool("IS_BROWSER") || "undefined" == typeof window || void 0 === window.localStorage) throw new Error("The current environment does not support local storage.");
    if (this.LS = window.localStorage, null == e || !e) throw new Error("For local storage, modelPath must not be null, undefined or empty.");
    this.modelPath = e, this.keys = getModelKeys(this.modelPath);
  }

  save(e) {
    var _this90 = this;

    return _asyncToGenerator(function* () {
      if (e.modelTopology instanceof ArrayBuffer) throw new Error("BrowserLocalStorage.save() does not support saving model topology in binary formats yet.");
      {
        var t = JSON.stringify(e.modelTopology),
            n = JSON.stringify(e.weightSpecs),
            r = getModelArtifactsInfoForJSON(e);

        try {
          return _this90.LS.setItem(_this90.keys.info, JSON.stringify(r)), _this90.LS.setItem(_this90.keys.topology, t), _this90.LS.setItem(_this90.keys.weightSpecs, n), _this90.LS.setItem(_this90.keys.weightData, arrayBufferToBase64String(e.weightData)), _this90.LS.setItem(_this90.keys.modelMetadata, JSON.stringify({
            format: e.format,
            generatedBy: e.generatedBy,
            convertedBy: e.convertedBy,
            signature: null != e.signature ? e.signature : void 0,
            userDefinedMetadata: null != e.userDefinedMetadata ? e.userDefinedMetadata : void 0,
            modelInitializer: null != e.modelInitializer ? e.modelInitializer : void 0,
            trainingConfig: null != e.trainingConfig ? e.trainingConfig : void 0
          })), {
            modelArtifactsInfo: r
          };
        } catch (e) {
          throw removeItems(_this90.keys), new Error("Failed to save model '".concat(_this90.modelPath, "' to local storage: size quota being exceeded is a possible cause of this failure: modelTopologyBytes=").concat(r.modelTopologyBytes, ", weightSpecsBytes=").concat(r.weightSpecsBytes, ", weightDataBytes=").concat(r.weightDataBytes, "."));
        }
      }
    })();
  }

  load() {
    var _this91 = this;

    return _asyncToGenerator(function* () {
      var e = JSON.parse(_this91.LS.getItem(_this91.keys.info));
      if (null == e) throw new Error("In local storage, there is no model with name '".concat(_this91.modelPath, "'"));
      if ("JSON" !== e.modelTopologyType) throw new Error("BrowserLocalStorage does not support loading non-JSON model topology yet.");
      var t = {},
          n = JSON.parse(_this91.LS.getItem(_this91.keys.topology));
      if (null == n) throw new Error("In local storage, the topology of model '".concat(_this91.modelPath, "' is missing."));
      t.modelTopology = n;
      var r = JSON.parse(_this91.LS.getItem(_this91.keys.weightSpecs));
      if (null == r) throw new Error("In local storage, the weight specs of model '".concat(_this91.modelPath, "' are missing."));
      t.weightSpecs = r;

      var a = _this91.LS.getItem(_this91.keys.modelMetadata);

      if (null != a) {
        var _e553 = JSON.parse(a);

        t.format = _e553.format, t.generatedBy = _e553.generatedBy, t.convertedBy = _e553.convertedBy, null != _e553.signature && (t.signature = _e553.signature), null != _e553.userDefinedMetadata && (t.userDefinedMetadata = _e553.userDefinedMetadata), null != _e553.modelInitializer && (t.modelInitializer = _e553.modelInitializer), null != _e553.trainingConfig && (t.trainingConfig = _e553.trainingConfig);
      }

      var s = _this91.LS.getItem(_this91.keys.weightData);

      if (null == s) throw new Error("In local storage, the binary weight values of model '".concat(_this91.modelPath, "' are missing."));
      return t.weightData = base64StringToArrayBuffer(s), t;
    })();
  }

}

BrowserLocalStorage.URL_SCHEME = "localstorage://";

var localStorageRouter = e => env().getBool("IS_BROWSER") && !Array.isArray(e) && e.startsWith(BrowserLocalStorage.URL_SCHEME) ? browserLocalStorage(e.slice(BrowserLocalStorage.URL_SCHEME.length)) : null;

function browserLocalStorage(e) {
  return new BrowserLocalStorage(e);
}

IORouterRegistry.registerSaveRouter(localStorageRouter), IORouterRegistry.registerLoadRouter(localStorageRouter);

class BrowserLocalStorageManager {
  constructor() {
    assert$4(env().getBool("IS_BROWSER"), () => "Current environment is not a web browser"), assert$4("undefined" == typeof window || void 0 !== window.localStorage, () => "Current browser does not appear to support localStorage"), this.LS = window.localStorage;
  }

  listModels() {
    var _this92 = this;

    return _asyncToGenerator(function* () {
      var e = {},
          t = PATH_PREFIX + PATH_SEPARATOR,
          n = PATH_SEPARATOR + INFO_SUFFIX;

      for (var r = 0; r < _this92.LS.length; ++r) {
        var a = _this92.LS.key(r);

        a.startsWith(t) && a.endsWith(n) && (e[getModelPathFromKey(a)] = JSON.parse(_this92.LS.getItem(a)));
      }

      return e;
    })();
  }

  removeModel(e) {
    var _this93 = this;

    return _asyncToGenerator(function* () {
      var t = getModelKeys(e = maybeStripScheme(e));
      if (null == _this93.LS.getItem(t.info)) throw new Error("Cannot find model at path '".concat(e, "'"));
      var n = JSON.parse(_this93.LS.getItem(t.info));
      return removeItems(t), n;
    })();
  }

}

var URL_SCHEME_SUFFIX = "://";

class ModelStoreManagerRegistry {
  constructor() {
    this.managers = {};
  }

  static getInstance() {
    return null == ModelStoreManagerRegistry.instance && (ModelStoreManagerRegistry.instance = new ModelStoreManagerRegistry()), ModelStoreManagerRegistry.instance;
  }

  static registerManager(e, t) {
    assert$4(null != e, () => "scheme must not be undefined or null."), e.endsWith(URL_SCHEME_SUFFIX) && (e = e.slice(0, e.indexOf(URL_SCHEME_SUFFIX))), assert$4(e.length > 0, () => "scheme must not be an empty string.");
    var n = ModelStoreManagerRegistry.getInstance();
    assert$4(null == n.managers[e], () => "A model store manager is already registered for scheme '".concat(e, "'.")), n.managers[e] = t;
  }

  static getManager(e) {
    var t = this.getInstance().managers[e];
    if (null == t) throw new Error("Cannot find model manager for scheme '".concat(e, "'"));
    return t;
  }

  static getSchemes() {
    return Object.keys(this.getInstance().managers);
  }

}

function parseURL(e) {
  if (-1 === e.indexOf(URL_SCHEME_SUFFIX)) throw new Error("The url string provided does not contain a scheme. Supported schemes are: ".concat(ModelStoreManagerRegistry.getSchemes().join(",")));
  return {
    scheme: e.split(URL_SCHEME_SUFFIX)[0],
    path: e.split(URL_SCHEME_SUFFIX)[1]
  };
}

function cloneModelInternal(_x55, _x56) {
  return _cloneModelInternal.apply(this, arguments);
}

function _cloneModelInternal() {
  _cloneModelInternal = _asyncToGenerator(function* (e, t) {
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
    assert$4(e !== t, () => "Old path and new path are the same: '".concat(e, "'"));
    var r = IORouterRegistry.getLoadHandlers(e);
    assert$4(r.length > 0, () => "Copying failed because no load handler is found for source URL ".concat(e, ".")), assert$4(r.length < 2, () => "Copying failed because more than one (".concat(r.length, ") load handlers for source URL ").concat(e, "."));
    var a = r[0],
        s = IORouterRegistry.getSaveHandlers(t);
    assert$4(s.length > 0, () => "Copying failed because no save handler is found for destination URL ".concat(t, ".")), assert$4(s.length < 2, () => "Copying failed because more than one (".concat(r.length, ") save handlers for destination URL ").concat(t, "."));
    var o = s[0],
        i = parseURL(e).scheme,
        l = parseURL(e).path,
        u = i === parseURL(e).scheme,
        c = yield a.load();
    n && u && (yield ModelStoreManagerRegistry.getManager(i).removeModel(l));
    var p = yield o.save(c);
    return n && !u && (yield ModelStoreManagerRegistry.getManager(i).removeModel(l)), p.modelArtifactsInfo;
  });
  return _cloneModelInternal.apply(this, arguments);
}

function listModels() {
  return _listModels.apply(this, arguments);
}

function _listModels() {
  _listModels = _asyncToGenerator(function* () {
    var e = ModelStoreManagerRegistry.getSchemes(),
        t = {};

    for (var n of e) {
      var _e1152 = yield ModelStoreManagerRegistry.getManager(n).listModels();

      for (var r in _e1152) {
        t[n + URL_SCHEME_SUFFIX + r] = _e1152[r];
      }
    }

    return t;
  });
  return _listModels.apply(this, arguments);
}

function removeModel(_x57) {
  return _removeModel.apply(this, arguments);
}

function _removeModel() {
  _removeModel = _asyncToGenerator(function* (e) {
    var t = parseURL(e);
    return ModelStoreManagerRegistry.getManager(t.scheme).removeModel(t.path);
  });
  return _removeModel.apply(this, arguments);
}

function copyModel(_x58, _x59) {
  return _copyModel.apply(this, arguments);
}

function _copyModel() {
  _copyModel = _asyncToGenerator(function* (e, t) {
    return cloneModelInternal(e, t, !1);
  });
  return _copyModel.apply(this, arguments);
}

function moveModel(_x60, _x61) {
  return _moveModel.apply(this, arguments);
}

function _moveModel() {
  _moveModel = _asyncToGenerator(function* (e, t) {
    return cloneModelInternal(e, t, !0);
  });
  return _moveModel.apply(this, arguments);
}

class PlatformBrowser {
  fetch(e, t) {
    return fetch(e, t);
  }

  now() {
    return performance.now();
  }

  encode(e, t) {
    if ("utf-8" !== t && "utf8" !== t) throw new Error("Browser's encoder only supports utf-8, but got ".concat(t));
    return null == this.textEncoder && (this.textEncoder = new TextEncoder()), this.textEncoder.encode(e);
  }

  decode(e, t) {
    return new TextDecoder(t).decode(e);
  }

}

if (env().get("IS_BROWSER")) {
  env().setPlatform("browser", new PlatformBrowser());

  try {
    ModelStoreManagerRegistry.registerManager(BrowserLocalStorage.URL_SCHEME, new BrowserLocalStorageManager());
  } catch (e) {}

  try {
    ModelStoreManagerRegistry.registerManager(BrowserIndexedDB.URL_SCHEME, new BrowserIndexedDBManager());
  } catch (e) {}
}

var getNodeFetch = {
  importFetch: () => __webpack_require__(76474)
};
var systemFetch;

class PlatformNode {
  constructor() {
    this.util = __webpack_require__(15895), this.textEncoder = new this.util.TextEncoder();
  }

  fetch(e, t) {
    return null != env().global.fetch ? env().global.fetch(e, t) : (null == systemFetch && (systemFetch = getNodeFetch.importFetch()), systemFetch(e, t));
  }

  now() {
    var e = process.hrtime();
    return 1e3 * e[0] + e[1] / 1e6;
  }

  encode(e, t) {
    if ("utf-8" !== t && "utf8" !== t) throw new Error("Node built-in encoder only supports utf-8, but got ".concat(t));
    return this.textEncoder.encode(e);
  }

  decode(e, t) {
    return 0 === e.length ? "" : new this.util.TextDecoder(t).decode(e);
  }

}

function buffer(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : "float32";
  var n = arguments.length > 2 ? arguments[2] : undefined;
  return t = t || "float32", assertNonNegativeIntegerDimensions(e), new TensorBuffer(e, t, n);
}

function cast_(e, t) {
  var n = convertToTensor(e, "x", "cast");
  if (!isValidDtype(t)) throw new Error("Failed to cast to unknown dtype ".concat(t));
  if ("string" === t && "string" !== n.dtype || "string" !== t && "string" === n.dtype) throw new Error("Only strings can be casted to strings");
  return ENGINE.runKernel(Cast, {
    x: n
  }, {
    dtype: t
  });
}

env().get("IS_NODE") && env().setPlatform("node", new PlatformNode());
var cast$3 = op({
  cast_
});

function clone_(e) {
  var t = convertToTensor(e, "x", "clone", "string_or_numeric");
  return ENGINE.runKernel(Identity$1, {
    x: t
  });
}

var clone = op({
  clone_
});

function print(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;
  console.log(e.toString(t));
}

getOrMakeEngine();
var opHandler = {
  buffer,
  cast: cast$3,
  clone,
  print
};
setOpHandler(opHandler);
var DEFAULT_FILE_NAME_PREFIX = "model",
    DEFAULT_JSON_EXTENSION_NAME = ".json",
    DEFAULT_WEIGHT_DATA_EXTENSION_NAME = ".weights.bin";

function defer(e) {
  return new Promise(e => setTimeout(e)).then(e);
}

class BrowserDownloads {
  constructor(e) {
    if (!env().getBool("IS_BROWSER")) throw new Error("browserDownloads() cannot proceed because the current environment is not a browser.");
    e.startsWith(BrowserDownloads.URL_SCHEME) && (e = e.slice(BrowserDownloads.URL_SCHEME.length)), null != e && 0 !== e.length || (e = DEFAULT_FILE_NAME_PREFIX), this.modelJsonFileName = e + DEFAULT_JSON_EXTENSION_NAME, this.weightDataFileName = e + DEFAULT_WEIGHT_DATA_EXTENSION_NAME;
  }

  save(e) {
    var _this94 = this;

    return _asyncToGenerator(function* () {
      if ("undefined" == typeof document) throw new Error("Browser downloads are not supported in this environment since `document` is not present");
      var t = window.URL.createObjectURL(new Blob([e.weightData], {
        type: "application/octet-stream"
      }));
      if (e.modelTopology instanceof ArrayBuffer) throw new Error("BrowserDownloads.save() does not support saving model topology in binary formats yet.");
      {
        var n = getModelJSONForModelArtifacts(e, [{
          paths: ["./" + _this94.weightDataFileName],
          weights: e.weightSpecs
        }]),
            r = window.URL.createObjectURL(new Blob([JSON.stringify(n)], {
          type: "application/json"
        })),
            a = null == _this94.modelJsonAnchor ? document.createElement("a") : _this94.modelJsonAnchor;

        if (a.download = _this94.modelJsonFileName, a.href = r, yield defer(() => a.dispatchEvent(new MouseEvent("click"))), null != e.weightData) {
          var _e554 = null == _this94.weightDataAnchor ? document.createElement("a") : _this94.weightDataAnchor;

          _e554.download = _this94.weightDataFileName, _e554.href = t, yield defer(() => _e554.dispatchEvent(new MouseEvent("click")));
        }

        return {
          modelArtifactsInfo: getModelArtifactsInfoForJSON(e)
        };
      }
    })();
  }

}

BrowserDownloads.URL_SCHEME = "downloads://";

class BrowserFiles {
  constructor(e) {
    if (null == e || e.length < 1) throw new Error("When calling browserFiles, at least 1 file is required, but received ".concat(e));
    this.jsonFile = e[0], this.weightsFiles = e.slice(1);
  }

  load() {
    var _this95 = this;

    return _asyncToGenerator(function* () {
      return new Promise((e, t) => {
        var n = new FileReader();
        n.onload = n => {
          var r = JSON.parse(n.target.result),
              a = r.modelTopology;
          if (null == a) return void t(new Error("modelTopology field is missing from file ".concat(_this95.jsonFile.name)));
          if (null == r.weightsManifest) return void t(new Error("weightManifest field is missing from file ".concat(_this95.jsonFile.name)));
          if (0 === _this95.weightsFiles.length) return void e({
            modelTopology: a
          });
          var s = getModelArtifactsForJSON(r, e => _this95.loadWeights(e));
          e(s);
        }, n.onerror = e => t("Failed to read model topology and weights manifest JSON from file '".concat(_this95.jsonFile.name, "'. BrowserFiles supports loading Keras-style tf.Model artifacts only.")), n.readAsText(_this95.jsonFile);
      });
    })();
  }

  loadWeights(e) {
    var t = [],
        n = [];

    for (var _r192 of e) {
      t.push(..._r192.weights), n.push(..._r192.paths);
    }

    var r = this.checkManifestAndWeightFiles(e),
        a = n.map(e => this.loadWeightsFile(e, r[e]));
    return Promise.all(a).then(e => [t, concatenateArrayBuffers(e)]);
  }

  loadWeightsFile(e, t) {
    return new Promise((n, r) => {
      var a = new FileReader();
      a.onload = e => {
        n(e.target.result);
      }, a.onerror = t => r("Failed to weights data from file of path '".concat(e, "'.")), a.readAsArrayBuffer(t);
    });
  }

  checkManifestAndWeightFiles(e) {
    var t = [],
        n = this.weightsFiles.map(e => basename(e.name)),
        r = {};

    for (var a of e) {
      a.paths.forEach(e => {
        var a = basename(e);
        if (-1 !== t.indexOf(a)) throw new Error("Duplicate file basename found in weights manifest: '".concat(a, "'"));
        if (t.push(a), -1 === n.indexOf(a)) throw new Error("Weight file with basename '".concat(a, "' is not provided."));
        r[e] = this.weightsFiles[n.indexOf(a)];
      });
    }

    if (t.length !== this.weightsFiles.length) throw new Error("Mismatch in the number of files in weights manifest (".concat(t.length, ") and the number of weight files provided (").concat(this.weightsFiles.length, ")."));
    return r;
  }

}

var browserDownloadsRouter = e => env().getBool("IS_BROWSER") && !Array.isArray(e) && e.startsWith(BrowserDownloads.URL_SCHEME) ? browserDownloads(e.slice(BrowserDownloads.URL_SCHEME.length)) : null;

function browserDownloads() {
  var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : "model";
  return new BrowserDownloads(e);
}

function browserFiles(e) {
  return new BrowserFiles(e);
}

function monitorPromisesProgress(e, t, n, r) {
  !function (e) {
    assert$4(null != e && Array.isArray(e) && e.length > 0, () => "promises must be a none empty array");
  }(e), function (e, t) {
    assert$4(e >= 0 && e <= 1, () => "Progress fraction must be in range [0, 1], but got startFraction ".concat(e)), assert$4(t >= 0 && t <= 1, () => "Progress fraction must be in range [0, 1], but got endFraction ".concat(t)), assert$4(t >= e, () => "startFraction must be no more than endFraction, but got startFraction ".concat(e, " and endFraction ").concat(t));
  }(n = null == n ? 0 : n, r = null == r ? 1 : r);
  var a = 0;
  return Promise.all(e.map(s => (s.then(s => {
    var o = n + ++a / e.length * (r - n);
    return t(o), s;
  }), s)));
}

function loadWeightsAsArrayBuffer(_x62, _x63) {
  return _loadWeightsAsArrayBuffer.apply(this, arguments);
}

function _loadWeightsAsArrayBuffer() {
  _loadWeightsAsArrayBuffer = _asyncToGenerator(function* (e, t) {
    null == t && (t = {});
    var n = null == t.fetchFunc ? env().platform.fetch : t.fetchFunc,
        r = e.map(e => n(e, t.requestInit, {
      isBinary: !0
    })),
        a = (null == t.onProgress ? yield Promise.all(r) : yield monitorPromisesProgress(r, t.onProgress, 0, .5)).map(e => e.arrayBuffer());
    return null == t.onProgress ? yield Promise.all(a) : yield monitorPromisesProgress(a, t.onProgress, .5, 1);
  });
  return _loadWeightsAsArrayBuffer.apply(this, arguments);
}

function loadWeights(_x64) {
  return _loadWeights.apply(this, arguments);
}

function _loadWeights() {
  _loadWeights = _asyncToGenerator(function* (e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : "";
    var n = arguments.length > 2 ? arguments[2] : undefined;
    var r = arguments.length > 3 ? arguments[3] : undefined;
    return weightsLoaderFactory(e => loadWeightsAsArrayBuffer(e, {
      requestInit: r
    }))(e, t, n);
  });
  return _loadWeights.apply(this, arguments);
}

function weightsLoaderFactory(e) {
  return /*#__PURE__*/function () {
    var _ref28 = _asyncToGenerator(function* (t) {
      var n = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : "";
      var r = arguments.length > 2 ? arguments[2] : undefined;
      var a = t.map(() => !1),
          s = {},
          o = null != r ? r.map(() => !1) : [],
          i = [];

      if (t.forEach((e, t) => {
        var n = 0;
        e.weights.forEach(e => {
          var l = DTYPE_VALUE_SIZE_MAP["quantization" in e ? e.quantization.dtype : e.dtype] * sizeFromShape(e.shape),
              u = () => {
            a[t] = !0, null == s[t] && (s[t] = []), s[t].push({
              manifestEntry: e,
              groupOffset: n,
              sizeBytes: l
            });
          };

          null != r ? r.forEach((t, n) => {
            t === e.name && (u(), o[n] = !0);
          }) : u(), i.push(e.name), n += l;
        });
      }), !o.every(e => e)) {
        var _e555 = r.filter((e, t) => !o[t]);

        throw new Error("Could not find weights in manifest with names: ".concat(_e555.join(", "), ". \nManifest JSON has weights with names: ").concat(i.join(", "), "."));
      }

      var l = a.reduce((e, t, n) => (t && e.push(n), e), []),
          u = [];
      l.forEach(e => {
        t[e].paths.forEach(e => {
          var t = n + (n.endsWith("/") ? "" : "/") + e;
          u.push(t);
        });
      });
      var c = yield e(u),
          p = {};
      var d = 0;
      return l.forEach(e => {
        var n = t[e].paths.length;
        var r = 0;

        for (var _e556 = 0; _e556 < n; _e556++) {
          r += c[d + _e556].byteLength;
        }

        var a = new ArrayBuffer(r),
            o = new Uint8Array(a);
        var i = 0;

        for (var _e557 = 0; _e557 < n; _e557++) {
          var _t397 = new Uint8Array(c[d + _e557]);

          o.set(_t397, i), i += _t397.byteLength;
        }

        s[e].forEach(e => {
          var t = decodeWeights(a.slice(e.groupOffset, e.groupOffset + e.sizeBytes), [e.manifestEntry]);

          for (var _e558 in t) {
            p[_e558] = t[_e558];
          }
        }), d += n;
      }), p;
    });

    return function (_x65) {
      return _ref28.apply(this, arguments);
    };
  }();
}

IORouterRegistry.registerSaveRouter(browserDownloadsRouter);
var OCTET_STREAM_MIME_TYPE = "application/octet-stream",
    JSON_TYPE = "application/json";

class HTTPRequest {
  constructor(e, t) {
    if (this.DEFAULT_METHOD = "POST", null == t && (t = {}), this.weightPathPrefix = t.weightPathPrefix, this.onProgress = t.onProgress, this.weightUrlConverter = t.weightUrlConverter, null != t.fetchFunc ? (assert$4("function" == typeof t.fetchFunc, () => "Must pass a function that matches the signature of `fetch` (see https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API)"), this.fetch = t.fetchFunc) : this.fetch = env().platform.fetch, assert$4(null != e && e.length > 0, () => "URL path for http must not be null, undefined or empty."), Array.isArray(e) && assert$4(2 === e.length, () => "URL paths for http must have a length of 2, (actual length is ".concat(e.length, ").")), this.path = e, null != t.requestInit && null != t.requestInit.body) throw new Error("requestInit is expected to have no pre-existing body, but has one.");
    this.requestInit = t.requestInit || {};
  }

  save(e) {
    var _this96 = this;

    return _asyncToGenerator(function* () {
      if (e.modelTopology instanceof ArrayBuffer) throw new Error("BrowserHTTPRequest.save() does not support saving model topology in binary formats yet.");
      var t = Object.assign({
        method: _this96.DEFAULT_METHOD
      }, _this96.requestInit);
      t.body = new FormData();
      var n = getModelJSONForModelArtifacts(e, [{
        paths: ["./model.weights.bin"],
        weights: e.weightSpecs
      }]);
      t.body.append("model.json", new Blob([JSON.stringify(n)], {
        type: JSON_TYPE
      }), "model.json"), null != e.weightData && t.body.append("model.weights.bin", new Blob([e.weightData], {
        type: OCTET_STREAM_MIME_TYPE
      }), "model.weights.bin");
      var r = yield _this96.fetch(_this96.path, t);
      if (r.ok) return {
        modelArtifactsInfo: getModelArtifactsInfoForJSON(e),
        responses: [r]
      };
      throw new Error("BrowserHTTPRequest.save() failed due to HTTP response status ".concat(r.status, "."));
    })();
  }

  load() {
    var _this97 = this;

    return _asyncToGenerator(function* () {
      var e = yield _this97.fetch(_this97.path, _this97.requestInit);
      if (!e.ok) throw new Error("Request to ".concat(_this97.path, " failed with status code ").concat(e.status, ". Please verify this URL points to the model JSON of the model to load."));
      var t;

      try {
        t = yield e.json();
      } catch (e) {
        var _t398 = "Failed to parse model JSON of response from ".concat(_this97.path, ".");

        throw _this97.path.endsWith(".pb") ? _t398 += " Your path contains a .pb file extension. Support for .pb models have been removed in TensorFlow.js 1.0 in favor of .json models. You can re-convert your Python TensorFlow model using the TensorFlow.js 1.0 conversion scripts or you can convert your.pb models with the 'pb2json'NPM script in the tensorflow/tfjs-converter repository." : _t398 += " Please make sure the server is serving valid JSON for this request.", new Error(_t398);
      }

      if (null == t.modelTopology && null == t.weightsManifest) throw new Error("The JSON from HTTP path ".concat(_this97.path, " contains neither model topology or manifest for weights."));
      return getModelArtifactsForJSON(t, e => _this97.loadWeights(e));
    })();
  }

  loadWeights(e) {
    var _this98 = this;

    return _asyncToGenerator(function* () {
      var t = Array.isArray(_this98.path) ? _this98.path[1] : _this98.path,
          [n, r] = parseUrl(t),
          a = _this98.weightPathPrefix || n,
          s = [];

      for (var _t399 of e) {
        s.push(..._t399.weights);
      }

      var o = [],
          i = [];

      for (var _t400 of e) {
        for (var _e559 of _t400.paths) {
          null != _this98.weightUrlConverter ? i.push(_this98.weightUrlConverter(_e559)) : o.push(a + _e559 + r);
        }
      }

      return _this98.weightUrlConverter && o.push(...(yield Promise.all(i))), [s, concatenateArrayBuffers(yield loadWeightsAsArrayBuffer(o, {
        requestInit: _this98.requestInit,
        fetchFunc: _this98.fetch,
        onProgress: _this98.onProgress
      }))];
    })();
  }

}

function parseUrl(e) {
  var t = e.lastIndexOf("/"),
      n = e.lastIndexOf("?");
  return [e.substring(0, t) + "/", n > t ? e.substring(n) : ""];
}

function isHTTPScheme(e) {
  return null != e.match(HTTPRequest.URL_SCHEME_REGEX);
}

HTTPRequest.URL_SCHEME_REGEX = /^https?:\/\//;

var httpRouter = (e, t) => {
  if ("undefined" == typeof fetch && (null == t || null == t.fetchFunc)) return null;
  {
    var n = !0;
    if (n = Array.isArray(e) ? e.every(e => isHTTPScheme(e)) : isHTTPScheme(e), n) return http(e, t);
  }
  return null;
};

function http(e, t) {
  return new HTTPRequest(e, t);
}

function browserHTTPRequest(e, t) {
  return http(e, t);
}

IORouterRegistry.registerSaveRouter(httpRouter), IORouterRegistry.registerLoadRouter(httpRouter);

class PassthroughLoader {
  constructor(e) {
    this.modelArtifacts = e;
  }

  load() {
    var _this99 = this;

    return _asyncToGenerator(function* () {
      return _this99.modelArtifacts;
    })();
  }

}

class PassthroughSaver {
  constructor(e) {
    this.saveHandler = e;
  }

  save(e) {
    var _this100 = this;

    return _asyncToGenerator(function* () {
      return _this100.saveHandler(e);
    })();
  }

}

function fromMemory(e, t, n, r) {
  return 1 === arguments.length ? null != e.modelTopology || null != e.weightSpecs ? new PassthroughLoader(e) : (console.warn("Please call tf.io.fromMemory() with only one argument. The argument should be of type ModelArtifacts. The multi-argument signature of tf.io.fromMemory() has been deprecated and will be removed in a future release."), new PassthroughLoader({
    modelTopology: e
  })) : (console.warn("Please call tf.io.fromMemory() with only one argument. The argument should be of type ModelArtifacts. The multi-argument signature of tf.io.fromMemory() has been deprecated and will be removed in a future release."), new PassthroughLoader({
    modelTopology: e,
    weightSpecs: t,
    weightData: n,
    trainingConfig: r
  }));
}

function withSaveHandler(e) {
  return new PassthroughSaver(e);
}

var io = {
  __proto__: null,
  browserFiles,
  browserHTTPRequest,
  concatenateArrayBuffers,
  decodeWeights,
  encodeWeights,
  fromMemory,
  getLoadHandlers,
  getModelArtifactsForJSON,
  getModelArtifactsInfoForJSON,
  getSaveHandlers,
  http,
  isHTTPScheme,
  loadWeights,
  registerLoadRouter,
  registerSaveRouter,
  weightsLoaderFactory,
  withSaveHandler,
  copyModel,
  listModels,
  moveModel,
  removeModel
};

function matMul_(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
  var a = convertToTensor(e, "a", "matMul"),
      s = convertToTensor(t, "b", "matMul");
  return [a, s] = makeTypesMatch(a, s), ENGINE.runKernel(BatchMatMul, {
    a,
    b: s
  }, {
    transposeA: n,
    transposeB: r
  });
}

var matMul$1 = op({
  matMul_
});

function oneHot_(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 1;
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 0;
  if (t < 2) throw new Error("Error in oneHot: depth must be >=2, but it is ".concat(t));
  var a = convertToTensor(e, "indices", "oneHot", "int32");
  return ENGINE.runKernel(OneHot, {
    indices: a
  }, {
    depth: t,
    onValue: n,
    offValue: r
  });
}

var oneHot$2 = op({
  oneHot_
});

function transpose_(e, t) {
  var n = convertToTensor(e, "x", "transpose");
  return null == t && (t = n.shape.map((e, t) => t).reverse()), assert$4(n.rank === t.length, () => "Error in transpose: rank of input ".concat(n.rank, " must match length of perm ").concat(t, ".")), t.forEach(e => {
    assert$4(e >= 0 && e < n.rank, () => "All entries in 'perm' must be between 0 and " + (n.rank - 1) + " but got ".concat(t));
  }), n.rank <= 1 ? n.clone() : ENGINE.runKernel(Transpose, {
    x: n
  }, {
    perm: t
  });
}

var transpose$2 = op({
  transpose_
});

function confusionMatrix_(e, t, n) {
  var r = convertToTensor(e, "labels", "confusionMatrix"),
      a = convertToTensor(t, "predictions", "confusionMatrix");
  assert$4(null == n || n > 0 && Number.isInteger(n), () => "If provided, numClasses must be a positive integer, but got ".concat(n)), assert$4(1 === r.rank, () => "Expected the rank of labels to be 1, but got ".concat(r.rank)), assert$4(1 === a.rank, () => "Expected the rank of predictions to be 1, but got ".concat(a.rank)), assert$4(r.shape[0] === a.shape[0], () => "Mismatch in the number of examples: ".concat(r.shape[0], " vs. ").concat(a.shape[0], ". Labels and predictions should have the same number of elements.")), assert$4(n > 0 && Number.isInteger(n), () => "numClasses is required to be a positive integer, but got ".concat(n));
  var s = oneHot$2(cast$3(r, "int32"), n),
      o = oneHot$2(cast$3(a, "int32"), n),
      i = transpose$2(s),
      l = matMul$1(i, o);
  return cast$3(l, "int32");
}

var confusionMatrix = op({
  confusionMatrix_
});
var math = {
  __proto__: null,
  confusionMatrix
};

function tensor3d(e, t, n) {
  if (assertNonNull(e), null != t && 3 !== t.length) throw new Error("tensor3d() requires shape to have three numbers");
  var r = inferShape(e, n);
  if (3 !== r.length && 1 !== r.length) throw new Error("tensor3d() requires values to be number[][][] or flat/TypedArray");
  if (1 === r.length && null == t) throw new Error("tensor3d() requires shape to be provided when `values` are a flat array");
  return makeTensor(e, t, r, n);
}

var fromPixels2DContext$1;

function fromPixels_(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 3;
  if (t > 4) throw new Error("Cannot construct Tensor with more than 4 channels from pixels.");
  if (null == e) throw new Error("pixels passed to tf.browser.fromPixels() can not be null");
  var n = !1,
      r = !1,
      a = !1,
      s = !1,
      o = !1,
      i = !1;
  if (e.data instanceof Uint8Array) n = !0;else if ("undefined" != typeof ImageData && e instanceof ImageData) r = !0;else if ("undefined" != typeof HTMLVideoElement && e instanceof HTMLVideoElement) a = !0;else if ("undefined" != typeof HTMLImageElement && e instanceof HTMLImageElement) s = !0;else if (null != e.getContext) o = !0;else {
    if (!("undefined" != typeof ImageBitmap && e instanceof ImageBitmap)) throw new Error("pixels passed to tf.browser.fromPixels() must be either an HTMLVideoElement, HTMLImageElement, HTMLCanvasElement, ImageData in browser, or OffscreenCanvas, ImageData in webworker or {data: Uint32Array, width: number, height: number}, but was ".concat(e.constructor.name));
    i = !0;
  }

  if (a) {
    var _t401 = 2;
    if (a && e.readyState < _t401) throw new Error("The video element has not loaded data yet. Please wait for `loadeddata` event on the <video> element.");
  }

  if (null != getKernel(FromPixels, ENGINE.backendName)) return ENGINE.runKernel(FromPixels, {
    pixels: e
  }, {
    numChannels: t
  });
  var [l, u] = a ? [e.videoWidth, e.videoHeight] : [e.width, e.height];
  var c, p;
  if (o ? c = e.getContext("2d").getImageData(0, 0, l, u).data : r || n ? c = e.data : (s || a || i) && (null == fromPixels2DContext$1 && (fromPixels2DContext$1 = document.createElement("canvas").getContext("2d")), fromPixels2DContext$1.canvas.width = l, fromPixels2DContext$1.canvas.height = u, fromPixels2DContext$1.drawImage(e, 0, 0, l, u), c = fromPixels2DContext$1.getImageData(0, 0, l, u).data), 4 === t) p = new Int32Array(c);else {
    var _e560 = l * u;

    p = new Int32Array(_e560 * t);

    for (var _n228 = 0; _n228 < _e560; _n228++) {
      for (var _e561 = 0; _e561 < t; ++_e561) {
        p[_n228 * t + _e561] = c[4 * _n228 + _e561];
      }
    }
  }
  return tensor3d(p, [u, l, t], "int32");
}

function isPixelData(e) {
  return null != e && e.data instanceof Uint8Array;
}

function isImageBitmapFullySupported() {
  return "undefined" != typeof window && "undefined" != typeof ImageBitmap && window.hasOwnProperty("createImageBitmap");
}

function isNonEmptyPixels(e) {
  return null != e && 0 !== e.width && 0 !== e.height;
}

function canWrapPixelsToImageBitmap(e) {
  return isImageBitmapFullySupported() && !(e instanceof ImageBitmap) && isNonEmptyPixels(e) && !isPixelData(e);
}

function fromPixelsAsync(_x66) {
  return _fromPixelsAsync.apply(this, arguments);
}

function _fromPixelsAsync() {
  _fromPixelsAsync = _asyncToGenerator(function* (e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 3;
    var n = null;

    if (env().getBool("WRAP_TO_IMAGEBITMAP") && canWrapPixelsToImageBitmap(e)) {
      var _t773;

      try {
        _t773 = yield createImageBitmap(e, {
          premultiplyAlpha: "none"
        });
      } catch (e) {
        _t773 = null;
      }

      n = null != _t773 && _t773.width === e.width && _t773.height === e.height ? _t773 : e;
    } else n = e;

    return fromPixels_(n, t);
  });
  return _fromPixelsAsync.apply(this, arguments);
}

function toPixels(_x67, _x68) {
  return _toPixels.apply(this, arguments);
}

function _toPixels() {
  _toPixels = _asyncToGenerator(function* (e, t) {
    var n = convertToTensor(e, "img", "toPixels");

    if (!(e instanceof Tensor)) {
      var _e1153 = n;
      n = cast$3(_e1153, "int32"), _e1153.dispose();
    }

    if (2 !== n.rank && 3 !== n.rank) throw new Error("toPixels only supports rank 2 or 3 tensors, got rank ".concat(n.rank, "."));
    var [r, a] = n.shape.slice(0, 2),
        s = 2 === n.rank ? 1 : n.shape[2];
    if (s > 4 || 2 === s) throw new Error("toPixels only supports depth of size 1, 3 or 4 but got ".concat(s));
    if ("float32" !== n.dtype && "int32" !== n.dtype) throw new Error("Unsupported type for toPixels: ".concat(n.dtype, ". Please use float32 or int32 tensors."));
    var o = yield n.data(),
        i = "float32" === n.dtype ? 255 : 1,
        l = new Uint8ClampedArray(a * r * 4);

    for (var _e1154 = 0; _e1154 < r * a; ++_e1154) {
      var _t774 = [0, 0, 0, 255];

      for (var _r448 = 0; _r448 < s; _r448++) {
        var _a319 = o[_e1154 * s + _r448];

        if ("float32" === n.dtype) {
          if (_a319 < 0 || _a319 > 1) throw new Error("Tensor values for a float32 Tensor must be in the range [0 - 1] but encountered ".concat(_a319, "."));
        } else if ("int32" === n.dtype && (_a319 < 0 || _a319 > 255)) throw new Error("Tensor values for a int32 Tensor must be in the range [0 - 255] but encountered ".concat(_a319, "."));

        1 === s ? (_t774[0] = _a319 * i, _t774[1] = _a319 * i, _t774[2] = _a319 * i) : _t774[_r448] = _a319 * i;
      }

      var _r447 = 4 * _e1154;

      l[_r447 + 0] = Math.round(_t774[0]), l[_r447 + 1] = Math.round(_t774[1]), l[_r447 + 2] = Math.round(_t774[2]), l[_r447 + 3] = Math.round(_t774[3]);
    }

    if (null != t) {
      t.width = a, t.height = r;

      var _e1155 = t.getContext("2d"),
          _n455 = new ImageData(l, a, r);

      _e1155.putImageData(_n455, 0, 0);
    }

    return n !== e && n.dispose(), l;
  });
  return _toPixels.apply(this, arguments);
}

var fromPixels$1 = op({
  fromPixels_
});
var browser = {
  __proto__: null,
  fromPixelsAsync,
  toPixels,
  fromPixels: fromPixels$1
};

function prepareAndValidate(e, t) {
  var n = e.shape.length,
      r = t.shape.length;
  if (n < 1) throw new Error("tf.gatherND() expects the input to be rank 1 or higher, but the rank was ".concat(n, "."));
  if (r < 1) throw new Error("tf.gatherND() expects the indices to be rank 1 or higher, but the rank was ".concat(r, "."));
  if ("int32" !== t.dtype) throw new Error("tf.gatherND() expects the indices to be int32 type, but the dtype was ".concat(t.dtype, "."));
  if (t.shape[r - 1] > n) throw new Error("index innermost dimension length must be <= tensor rank; saw: ".concat(t.shape[r - 1], " vs. ").concat(n));
  if (0 === sizeFromShape(e.shape)) throw new Error("Requested more than 0 entries, but input is empty. Input shape: ".concat(e.shape, "."));
  var a = t.shape,
      s = a[a.length - 1];
  var o = 1;

  for (var _e562 = 0; _e562 < a.length - 1; ++_e562) {
    o *= a[_e562];
  }

  var i = e.shape,
      l = a.slice();
  l.pop();
  var u = 1;

  for (var _e563 = s; _e563 < n; ++_e563) {
    u *= i[_e563], l.push(i[_e563]);
  }

  var c = [...computeStrides(e.shape).map(e => e / u), 1].slice(0, s);
  return [l, o, u, c];
}

var gather_nd_util = {
  __proto__: null,
  prepareAndValidate
};

function validateUpdateShape(e, t, n) {
  var r = t.rank > 1 ? t.shape[t.rank - 1] : 1,
      a = t.rank > 1 ? t.rank - 1 : 1,
      s = "Must have updates.shape = indices.shape[:batchDim] + shape[sliceDim:], got updates.shape: ".concat(n.shape, ", indices.shape: ").concat(t.shape, ", shape: ").concat(e, ", sliceDim: ").concat(r, ", and batchDim: ").concat(a, ".");
  if (n.rank < a) throw new Error(s + " update.rank < ".concat(a, ". "));
  if (e.length < r + (n.rank - a)) throw new Error(s + " Output shape length < ".concat(r + (n.rank - a)));
  if (n.rank !== a + e.length - r) throw new Error(s + " update.rank != " + (a + e.length - r));

  for (var _e564 = 0; _e564 < a; ++_e564) {
    if (n.shape[_e564] !== t.shape[_e564]) throw new Error(s + " updates.shape[".concat(_e564, "] (").concat(n.shape[_e564], ") != indices.shape[").concat(_e564, "] (").concat(t.shape[_e564], ")."));
  }

  for (var _t402 = 0; _t402 < n.rank - a; ++_t402) {
    if (n.shape[_t402 + a] !== e[_t402 + r]) throw new Error(s + " updates.shape[".concat(_t402 + a, "] (").concat(n.shape[_t402 + a], ") != shape[").concat(_t402 + a, "] (").concat(e[_t402 + a], ")"));
  }
}

function validateInput$1(e, t, n) {
  if (t.rank < 1) throw new Error("tf.scatterND() expects the indices to be rank 1 or higher, but the rank was ".concat(t.rank, "."));
  if (e.rank < 1) throw new Error("tf.scatterND() expects the updates to be rank 1 or higher, but the rank was ".concat(e.rank, "."));
  if ("int32" !== t.dtype) throw new Error("The dtype of 'indices' should be int32, but got dtype: ".concat(t.dtype));
  if (n.length < 1) throw new Error("Output rank must be greater or equal to 1, but got shape: ".concat(n));

  if (0 === n.length) {
    if (0 === t.size) throw new Error("Indices specified for empty output. indices shape: ".concat(t.shape));
    if (0 === e.size) throw new Error("Updates specified for empty output. updates shape: ".concat(e.shape));
  }

  validateUpdateShape(n, t, e);
}

function calculateShapes(e, t, n) {
  var r = t.shape.length,
      a = r > 1 ? t.shape[r - 1] : 1,
      s = n.length;
  var o = 1;

  for (var _e565 = a; _e565 < s; ++_e565) {
    o *= n[_e565];
  }

  var i = a < 1 ? 1 : a;
  return {
    sliceRank: a,
    numUpdates: sizeFromShape(t.shape) / i,
    sliceSize: o,
    strides: [...computeStrides(n.slice(0, a)), 1],
    outputSize: sizeFromShape(n)
  };
}

var scatter_nd_util = {
  __proto__: null,
  validateUpdateShape,
  validateInput: validateInput$1,
  calculateShapes
};

function assertParamsValid(e, t, n) {
  var r = e.shape.length;
  assert$4(r === t.length, () => "Error in slice".concat(r, "D: Length of begin ").concat(t, " must match the rank of the array (").concat(r, ").")), assert$4(r === n.length, () => "Error in slice".concat(r, "D: Length of size ").concat(n, " must match the rank of the array (").concat(r, ")."));

  var _loop31 = function _loop31(a) {
    assert$4(t[a] + n[a] <= e.shape[a], () => "Error in slice".concat(r, "D: begin[").concat(a, "] + size[").concat(a, "] (").concat(t[a] + n[a], ") would overflow input.shape[").concat(a, "] (").concat(e.shape[a], ")"));
  };

  for (var a = 0; a < r; ++a) {
    _loop31(a);
  }
}

function maskToAxes(e) {
  var t = [];
  var n = 0;

  for (; e > 0;) {
    1 & e && t.push(n), e /= 2, n++;
  }

  return t;
}

function computeOutShape$2(e, t, n) {
  var r = [];

  for (var a = 0; a < e.length; a++) {
    r[a] = Math.ceil((t[a] - e[a]) / n[a]);
  }

  return r;
}

function stridesWithElidedDims(e, t, n, r) {
  var a = [...e];

  for (var _e566 = a.length; _e566 < r.length; _e566++) {
    a.push(1);
  }

  for (var _e567 = 0; _e567 < n; _e567++) {
    0 === _e567 ? a[t] = 1 : (a.splice(t, 0, 1), a.pop());
  }

  return a;
}

function unnormalizeAxis(e, t, n) {
  return n <= e ? n : n - (t - 1);
}

function getElidedAxes(e, t) {
  var n = [];

  for (var r = 0; r < e; r++) {
    n.push(t + r);
  }

  return n;
}

function getNormalizedAxes(e, t, n, r, a, s, o, i, l) {
  var u = e.length;
  var c = new Array(u),
      p = new Array(u),
      d = new Array(u);

  if (t.length && n > 0) {
    var _l34 = t[0],
        _u30 = n + 1;

    c = startIndicesWithElidedDims(o, _l34, _u30, r, e), p = stopIndicesWithElidedDims(i, _l34, _u30, a, e), d = stridesWithElidedDims(s, _l34, _u30, e);
  } else for (var _t403 = 0; _t403 < u; _t403++) {
    c[_t403] = startForAxis(o, r, s, e, _t403, l), p[_t403] = stopForAxis(i, a, s, e, _t403, l), d[_t403] = stridesForAxis(s, _t403, l);
  }

  return {
    begin: c,
    end: p,
    strides: d
  };
}

function startIndicesWithElidedDims(e, t, n, r, a) {
  var s = [...a],
      o = getElidedAxes(n, t);

  for (var _a124 = 0; _a124 < s.length; _a124++) {
    if (o.indexOf(_a124) > -1) s[_a124] = 0;else {
      var _o68 = unnormalizeAxis(t, n, _a124);

      var i = r[_o68];
      e & 1 << _o68 && (i = 0), s[_a124] = i;
    }
  }

  return s;
}

function stopIndicesWithElidedDims(e, t, n, r, a) {
  var s = [...a],
      o = getElidedAxes(n, t);

  for (var _a125 = 0; _a125 < s.length; _a125++) {
    if (o.indexOf(_a125) > -1) s[_a125] = Number.MAX_SAFE_INTEGER;else {
      var _o69 = unnormalizeAxis(t, n, _a125);

      var i = r[_o69];
      e & 1 << _o69 && (i = Number.MAX_SAFE_INTEGER), s[_a125] = i;
    }
  }

  for (var _e568 = 0; _e568 < s.length; _e568++) {
    var _t404 = a[_e568];
    s[_e568] < 0 && (s[_e568] += _t404), s[_e568] = clamp(0, s[_e568], a[_e568]);
  }

  return s;
}

function stridesForAxis(e, t, n) {
  var r = e[t];
  return (n & 1 << t || null == r) && (r = 1), r;
}

function startForAxis(e, t, n, r, a, s) {
  var o = t[a];
  (e & 1 << a || s & 1 << a || null == o) && (o = (n[a] || 1) > 0 ? Number.MIN_SAFE_INTEGER : Number.MAX_SAFE_INTEGER);
  var i = r[a];
  return o < 0 && (o += i), o = clamp(0, o, i - 1), o;
}

function stopForAxis(e, t, n, r, a, s) {
  var o = t[a];
  var i = n[a] || 1;
  (e & 1 << a || s & 1 << a || null == o) && (o = i > 0 ? Number.MAX_SAFE_INTEGER : Number.MIN_SAFE_INTEGER);
  var l = r[a];
  return o < 0 && (o += l), o = i > 0 ? clamp(0, o, l) : clamp(-1, o, l - 1), o;
}

function isSliceContinous(e, t, n) {
  var r = n.length;

  for (var _e569 = 0; _e569 < n.length; _e569++) {
    if (n[_e569] > 1) {
      r = _e569;
      break;
    }
  }

  for (var a = r + 1; a < n.length; a++) {
    if (t[a] > 0 || n[a] !== e[a]) return !1;
  }

  return !0;
}

function computeFlatOffset(e, t) {
  var n = e.length > 0 ? e[e.length - 1] : 1;

  for (var r = 0; r < e.length - 1; r++) {
    n += e[r] * t[r];
  }

  return n;
}

function parseSliceParams(e, t, n) {
  var r;
  var a = e.shape.length;
  var s;
  return r = "number" == typeof t ? [t, ...new Array(a - 1).fill(0)] : t.length < a ? t.concat(new Array(a - t.length).fill(0)) : t.slice(), r.forEach(e => {
    assert$4(-1 !== e, () => "slice() does not support negative begin indexing.");
  }), s = null == n ? new Array(a).fill(-1) : "number" == typeof n ? [n, ...new Array(a - 1).fill(-1)] : n.length < a ? n.concat(new Array(a - n.length).fill(-1)) : n, s = s.map((t, n) => t >= 0 ? t : (assert$4(-1 === t, () => "Negative size values should be exactly -1 but got ".concat(t, " for the slice() size at index ").concat(n, ".")), e.shape[n] - r[n])), [r, s];
}

function sliceInfo(e, t, n, r, a, s, o, i, l) {
  var u = t.slice(),
      c = n.slice(),
      p = r;
  null == r && (p = new Array(u.length));
  var d = maskToAxes(o);
  if (d.length > 1) throw new Error("Multiple ellipses in slice is not allowed.");
  if (0 !== o && 0 !== i) throw new Error("Using both ellipsisMask and newAxisMask is not yet supported.");
  if (0 !== o && 0 !== l) throw new Error("Using both ellipsisMask and shrinkAxisMask is not yet supported.");
  var h = e.length - u.length,
      m = maskToAxes(i),
      f = e.slice();
  m.forEach(e => {
    u[e] = 0, c[e] = 1, f.splice(e, 0, 1);
  });
  var {
    begin: g,
    end: $,
    strides: y
  } = getNormalizedAxes(f, d, h, u, c, p, a, s, o);
  u = g, c = $, p = y;
  var b = maskToAxes(l);
  b.forEach(e => {
    c[e] = u[e] + 1, p[e] = 1;
  });
  var x = computeOutShape$2(u, c, p),
      v = x.filter((e, t) => -1 === b.indexOf(t));
  return {
    nonStrided: p.every(e => 1 === e),
    $begin: u,
    $end: c,
    $strides: p,
    size: x,
    newShape: f,
    outShape: v
  };
}

var slice_util = {
  __proto__: null,
  assertParamsValid,
  maskToAxes,
  computeOutShape: computeOutShape$2,
  stridesWithElidedDims,
  getNormalizedAxes,
  startIndicesWithElidedDims,
  stopIndicesWithElidedDims,
  stridesForAxis,
  startForAxis,
  stopForAxis,
  isSliceContinous,
  computeFlatOffset,
  parseSliceParams,
  sliceInfo
};

class Serializable {
  getClassName() {
    return this.constructor.className;
  }

  static fromConfig(e, t) {
    return new e(t);
  }

}

class SerializationMap {
  constructor() {
    this.classNameMap = {};
  }

  static getMap() {
    return null == SerializationMap.instance && (SerializationMap.instance = new SerializationMap()), SerializationMap.instance;
  }

  static register(e) {
    SerializationMap.getMap().classNameMap[e.className] = [e, e.fromConfig];
  }

}

function registerClass(e) {
  assert$4(null != e.className, () => "Class being registered does not have the static className property defined."), assert$4("string" == typeof e.className, () => "className is required to be a string, but got type " + typeof e.className), assert$4(e.className.length > 0, () => "Class being registered has an empty-string as its className, which is disallowed."), SerializationMap.register(e);
}

var serialization = {
  __proto__: null,
  Serializable,
  SerializationMap,
  registerClass
};
var TEST_EPSILON_FLOAT32 = .001,
    TEST_EPSILON_FLOAT16 = .1;

function expectArraysClose(e, t, n) {
  return null == n && (n = testEpsilon()), expectArraysPredicate(e, t, (e, t) => areClose(e, t, n));
}

function testEpsilon() {
  return 32 === ENGINE.backend.floatPrecision() ? TEST_EPSILON_FLOAT32 : TEST_EPSILON_FLOAT16;
}

function expectArraysPredicate(e, t, n) {
  var r = !0;

  if ((isTypedArray(e) || isTypedArray(t)) && (r = !1), isTypedArray(e) && isTypedArray(t) && (r = !0), r) {
    var _n229 = e.constructor.name,
        _r193 = t.constructor.name;
    if (_n229 !== _r193) throw new Error("Arrays are of different type. Actual: ".concat(_n229, ". Expected: ").concat(_r193));
  }

  if (Array.isArray(e) && Array.isArray(t)) {
    var _n230 = inferShape(e),
        _r194 = inferShape(t);

    if (!arraysEqual(_n230, _r194)) throw new Error("Arrays have different shapes. Actual: [".concat(_n230, "]. Expected: [").concat(_r194, "]"));
  }

  var a = isTypedArray(e) ? e : flatten$3(e),
      s = isTypedArray(t) ? t : flatten$3(t);
  if (a.length !== s.length) throw new Error("Arrays have different lengths actual: ".concat(a.length, " vs expected: ").concat(s.length, ".\nActual:   ").concat(a, ".\nExpected: ").concat(s, "."));

  for (var _e570 = 0; _e570 < s.length; ++_e570) {
    var _t405 = a[_e570],
        _r195 = s[_e570];
    if (!n(_t405, _r195)) throw new Error("Arrays differ: actual[".concat(_e570, "] = ").concat(_t405, ", expected[").concat(_e570, "] = ").concat(_r195, ".\nActual:   ").concat(a, ".\nExpected: ").concat(s, "."));
  }
}

function expectPromiseToFail(e, t) {
  e().then(() => t.fail(), () => t());
}

function expectArraysEqual(e, t) {
  var n = "string" == typeof t || "number" == typeof t || "boolean" == typeof t ? [t] : t;
  return isString(e) || isString(e[0]) || isString(t) || isString(t[0]) ? expectArraysPredicate(e, n, (e, t) => e == t) : expectArraysPredicate(e, t, (e, t) => areClose(e, t, 0));
}

function expectNumbersClose(e, t, n) {
  if (null == n && (n = testEpsilon()), !areClose(e, t, n)) throw new Error("Numbers differ: actual === ".concat(e, ", expected === ").concat(t));
}

function areClose(e, t, n) {
  return !isFinite(e) && !isFinite(t) || !(isNaN(e) || isNaN(t) || Math.abs(e - t) > n);
}

function expectValuesInRange(e, t, n) {
  for (var r = 0; r < e.length; r++) {
    if (e[r] < t || e[r] > n) throw new Error("Value out of range:".concat(e[r], " low: ").concat(t, ", high: ").concat(n));
  }
}

function expectArrayBuffersEqual(e, t) {
  expect(new Float32Array(e)).toEqual(new Float32Array(t));
}

function encodeStrings(e) {
  for (var t = 0; t < e.length; t++) {
    var n = e[t];
    Array.isArray(n) ? encodeStrings(n) : e[t] = encodeString(n);
  }

  return e;
}

var test_util = {
  __proto__: null,
  TEST_EPSILON_FLOAT16,
  expectArraysClose,
  testEpsilon,
  expectPromiseToFail,
  expectArraysEqual,
  expectNumbersClose,
  expectValuesInRange,
  expectArrayBuffersEqual,
  encodeStrings
};
var version$7 = "3.8.0";

function enableProdMode() {
  env().set("PROD", !0);
}

function enableDebugMode() {
  env().set("DEBUG", !0);
}

function disableDeprecationWarnings() {
  env().set("DEPRECATION_WARNINGS_ENABLED", !1), console.warn("TensorFlow.js deprecation warnings have been disabled.");
}

function deprecationWarn(e) {
  env().getBool("DEPRECATION_WARNINGS_ENABLED") && console.warn(e + " You can disable deprecation warnings with tf.disableDeprecationWarnings().");
}

function disposeVariables() {
  ENGINE.disposeVariables();
}

function engine() {
  return ENGINE;
}

function memory() {
  return ENGINE.memory();
}

function profile(e) {
  return ENGINE.profile(e);
}

function tidy(e, t) {
  return ENGINE.tidy(e, t);
}

function dispose(e) {
  getTensorsInContainer(e).forEach(e => e.dispose());
}

function keep(e) {
  return ENGINE.keep(e);
}

function time(e) {
  return ENGINE.time(e);
}

function setBackend(e) {
  return ENGINE.setBackend(e);
}

function ready() {
  return ENGINE.ready();
}

function getBackend() {
  return ENGINE.backendName;
}

function removeBackend(e) {
  ENGINE.removeBackend(e);
}

function findBackend(e) {
  return ENGINE.findBackend(e);
}

function findBackendFactory(e) {
  return ENGINE.findBackendFactory(e);
}

function registerBackend(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 1;
  return ENGINE.registerBackend(e, t, n);
}

function backend() {
  return ENGINE.backend;
}

function setPlatform(e, t) {
  env().setPlatform(e, t);
}

function add_(e, t) {
  var n = convertToTensor(e, "a", "add"),
      r = convertToTensor(t, "b", "add");
  return [n, r] = makeTypesMatch(n, r), ENGINE.runKernel(Add$1, {
    a: n,
    b: r
  });
}

var add$2 = op({
  add_
});

function floorDiv_(e, t) {
  var n = convertToTensor(e, "a", "floorDiv"),
      r = convertToTensor(t, "b", "floorDiv");
  return [n, r] = makeTypesMatch(n, r), ENGINE.runKernel(FloorDiv, {
    a: n,
    b: r
  });
}

var floorDiv$2 = op({
  floorDiv_
});

function div_(e, t) {
  var n = convertToTensor(e, "a", "div"),
      r = convertToTensor(t, "b", "div");
  return [n, r] = makeTypesMatch(n, r), "int32" === n.dtype && "int32" === r.dtype ? floorDiv$2(n, r) : ENGINE.runKernel(RealDiv, {
    a: n,
    b: r
  }, {});
}

var div$1 = op({
  div_
});

function mul_(e, t) {
  var n = convertToTensor(e, "a", "mul"),
      r = convertToTensor(t, "b", "mul");
  return [n, r] = makeTypesMatch(n, r), ENGINE.runKernel(Multiply$1, {
    a: n,
    b: r
  });
}

var mul = op({
  mul_
});

function abs_(e) {
  var t = convertToTensor(e, "x", "abs");
  return ENGINE.runKernel("complex64" === t.dtype ? ComplexAbs : Abs, {
    x: t
  });
}

var abs$2 = op({
  abs_
});

function acos_(e) {
  var t = convertToTensor(e, "x", "acos");
  return ENGINE.runKernel(Acos, {
    x: t
  });
}

var acos$2 = op({
  acos_
});

function acosh_(e) {
  var t = convertToTensor(e, "x", "acosh");
  return ENGINE.runKernel(Acosh, {
    x: t
  });
}

var acosh$2 = op({
  acosh_
});

function addN_(e) {
  assert$4(Array.isArray(e), () => "The argument passed to tf.addN() must be a list of tensors"), assert$4(e.length >= 1, () => "Must pass at least one tensor to tf.addN(), but got ".concat(e.length));
  var t = e.map((e, t) => convertToTensor(e, "tensors".concat(t), "addN")),
      n = t[0];
  return t.forEach(e => {
    if (e.dtype !== n.dtype) throw new Error("All tensors passed to tf.addN() must have the same dtype");
  }), t.forEach(e => {
    if (!arraysEqual(e.shape, n.shape)) throw new Error("All tensors passed to tf.addN() must have the same shape");
  }), ENGINE.runKernel(AddN, t);
}

var addN$2 = op({
  addN_
});

function all_(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  var r = convertToTensor(e, "x", "all", "bool");
  return ENGINE.runKernel(All, {
    x: r
  }, {
    axis: t,
    keepDims: n
  });
}

var all$2 = op({
  all_
});

function any_(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  var r = convertToTensor(e, "x", "any", "bool");
  return ENGINE.runKernel(Any, {
    x: r
  }, {
    axis: t,
    keepDims: n
  });
}

var any$2 = op({
  any_
});

function argMax_(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;
  var n = convertToTensor(e, "x", "argMax");
  return ENGINE.runKernel(ArgMax, {
    x: n
  }, {
    axis: t
  });
}

var argMax$2 = op({
  argMax_
});

function argMin_(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;
  var n = convertToTensor(e, "x", "argMin");
  return ENGINE.runKernel(ArgMin, {
    x: n
  }, {
    axis: t
  });
}

var argMin$2 = op({
  argMin_
});

function asin_(e) {
  var t = convertToTensor(e, "x", "asin");
  return ENGINE.runKernel(Asin, {
    x: t
  });
}

var asin$2 = op({
  asin_
});

function asinh_(e) {
  var t = convertToTensor(e, "x", "asinh");
  return ENGINE.runKernel(Asinh, {
    x: t
  });
}

var asinh$2 = op({
  asinh_
});

function atan_(e) {
  var t = convertToTensor(e, "x", "atan");
  return ENGINE.runKernel(Atan, {
    x: t
  });
}

var atan$2 = op({
  atan_
});

function atan2_(e, t) {
  var n = convertToTensor(e, "a", "atan2"),
      r = convertToTensor(t, "b", "atan2");
  return [n, r] = makeTypesMatch(n, r), ENGINE.runKernel(Atan2, {
    a: n,
    b: r
  });
}

var atan2$2 = op({
  atan2_
});

function atanh_(e) {
  var t = convertToTensor(e, "x", "atanh");
  return ENGINE.runKernel(Atanh, {
    x: t
  });
}

var atanh$2 = op({
  atanh_
});

function computeDilation2DInfo(e, t, n, r) {
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : "NHWC";
  var s = arguments.length > 5 ? arguments[5] : undefined;
  return computeConv2DInfo(e, [...t, e[3]], n, s, r, null, null, convertConv2DDataFormat(a));
}

function computePool2DInfo(e, t, n, r, a, s) {
  var o = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : "channelsLast";
  var [i, l] = parseTupleParam(t);
  var u;
  if ("channelsLast" === o) u = [i, l, e[3], e[3]];else {
    if ("channelsFirst" !== o) throw new Error("Unknown dataFormat ".concat(o));
    u = [i, l, e[1], e[1]];
  }
  return computeConv2DInfo(e, u, n, r, a, s, !1, o);
}

function computePool3DInfo(e, t, n, r, a, s) {
  var o = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : "NDHWC";
  var [i, l, u] = parse3TupleParam(t);
  var c, p;
  if ("NDHWC" === o) p = "channelsLast", c = [i, l, u, e[4], e[4]];else {
    if ("NCDHW" !== o) throw new Error("Unknown dataFormat ".concat(o));
    p = "channelsFirst", c = [i, l, u, e[1], e[1]];
  }
  return computeConv3DInfo(e, c, n, r, a, !1, p, s);
}

function computeConv2DInfo(e, t, n, r, a, s) {
  var o = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : !1;
  var i = arguments.length > 7 && arguments[7] !== undefined ? arguments[7] : "channelsLast";
  var [l, u, c, p] = [-1, -1, -1, -1];
  if ("channelsLast" === i) [l, u, c, p] = e;else {
    if ("channelsFirst" !== i) throw new Error("Unknown dataFormat ".concat(i));
    [l, p, u, c] = e;
  }
  var [d, h,, m] = t,
      [f, g] = parseTupleParam(n),
      [$, y] = parseTupleParam(r),
      b = getEffectiveFilterSize(d, $),
      x = getEffectiveFilterSize(h, y),
      {
    padInfo: v,
    outHeight: I,
    outWidth: C
  } = getPadAndOutInfo(a, u, c, f, g, b, x, s, i),
      S = o ? m * p : m;
  var k;
  return "channelsFirst" === i ? k = [l, S, I, C] : "channelsLast" === i && (k = [l, I, C, S]), {
    batchSize: l,
    dataFormat: i,
    inHeight: u,
    inWidth: c,
    inChannels: p,
    outHeight: I,
    outWidth: C,
    outChannels: S,
    padInfo: v,
    strideHeight: f,
    strideWidth: g,
    filterHeight: d,
    filterWidth: h,
    effectiveFilterHeight: b,
    effectiveFilterWidth: x,
    dilationHeight: $,
    dilationWidth: y,
    inShape: e,
    outShape: k,
    filterShape: t
  };
}

function computeConv3DInfo(e, t, n, r, a) {
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : !1;
  var o = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : "channelsLast";
  var i = arguments.length > 7 ? arguments[7] : undefined;
  var [l, u, c, p, d] = [-1, -1, -1, -1, -1];
  if ("channelsLast" === o) [l, u, c, p, d] = e;else {
    if ("channelsFirst" !== o) throw new Error("Unknown dataFormat ".concat(o));
    [l, d, u, c, p] = e;
  }
  var [h, m, f,, g] = t,
      [$, y, b] = parse3TupleParam(n),
      [x, v, I] = parse3TupleParam(r),
      C = getEffectiveFilterSize(h, x),
      S = getEffectiveFilterSize(m, v),
      k = getEffectiveFilterSize(f, I),
      {
    padInfo: T,
    outDepth: N,
    outHeight: w,
    outWidth: E
  } = get3DPadAndOutInfo(a, u, c, p, $, y, b, C, S, k, i),
      A = s ? g * d : g;
  var D;
  return "channelsFirst" === o ? D = [l, A, N, w, E] : "channelsLast" === o && (D = [l, N, w, E, A]), {
    batchSize: l,
    dataFormat: o,
    inDepth: u,
    inHeight: c,
    inWidth: p,
    inChannels: d,
    outDepth: N,
    outHeight: w,
    outWidth: E,
    outChannels: A,
    padInfo: T,
    strideDepth: $,
    strideHeight: y,
    strideWidth: b,
    filterDepth: h,
    filterHeight: m,
    filterWidth: f,
    effectiveFilterDepth: C,
    effectiveFilterHeight: S,
    effectiveFilterWidth: k,
    dilationDepth: x,
    dilationHeight: v,
    dilationWidth: I,
    inShape: e,
    outShape: D,
    filterShape: t
  };
}

function computeOutputShape2D(e, t, n, r, a) {
  null == r && (r = computeDefaultPad(e, t, n));
  var s = e[1];
  return [round$3((e[0] - t + 2 * r) / n + 1, a), round$3((s - t + 2 * r) / n + 1, a)];
}

function computeOutputShape4D(e, t, n, r, a, s) {
  null == a && (a = computeDefaultPad(e, t, r));
  var o = e[1],
      i = e[2];
  return [round$3((e[0] - t + 2 * a) / r + 1, s), round$3((o - t + 2 * a) / r + 1, s), round$3((i - t + 2 * a) / r + 1, s), n];
}

function computeDefaultPad(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 1;
  var a = getEffectiveFilterSize(t, r);
  return Math.floor((e[0] * (n - 1) - n + a) / 2);
}

function parseTupleParam(e) {
  return "number" == typeof e ? [e, e, e] : 2 === e.length ? [e[0], e[1], 1] : e;
}

function parse3TupleParam(e) {
  return "number" == typeof e ? [e, e, e] : e;
}

function getEffectiveFilterSize(e, t) {
  return t <= 1 ? e : e + (e - 1) * (t - 1);
}

function getPadAndOutInfo(e, t, n, r, a, s, o, i, l) {
  var u, c, p;

  if ("number" == typeof e) {
    u = {
      top: e,
      bottom: e,
      left: e,
      right: e,
      type: 0 === e ? "VALID" : "NUMBER"
    };

    var _a126 = computeOutputShape2D([t, n], s, r, e, i);

    c = _a126[0], p = _a126[1];
  } else if ("same" === e) {
    c = Math.ceil(t / r), p = Math.ceil(n / a);

    var _e571 = Math.max(0, (c - 1) * r + s - t),
        _i43 = Math.max(0, (p - 1) * a + o - n),
        _l35 = Math.floor(_e571 / 2),
        d = _e571 - _l35,
        h = Math.floor(_i43 / 2);

    u = {
      top: _l35,
      bottom: d,
      left: h,
      right: _i43 - h,
      type: "SAME"
    };
  } else if ("valid" === e) u = {
    top: 0,
    bottom: 0,
    left: 0,
    right: 0,
    type: "VALID"
  }, c = Math.ceil((t - s + 1) / r), p = Math.ceil((n - o + 1) / a);else {
    if ("object" != typeof e) throw Error("Unknown padding parameter: ".concat(e));
    {
      var _d12 = "channelsLast" === l ? e[1][0] : e[2][0],
          _h13 = "channelsLast" === l ? e[1][1] : e[2][1],
          m = "channelsLast" === l ? e[2][0] : e[3][0],
          f = "channelsLast" === l ? e[2][1] : e[3][1];

      u = {
        top: _d12,
        bottom: _h13,
        left: m,
        right: f,
        type: 0 === _d12 && 0 === _h13 && 0 === m && 0 === f ? "VALID" : "EXPLICIT"
      }, c = round$3((t - s + _d12 + _h13) / r + 1, i), p = round$3((n - o + m + f) / a + 1, i);
    }
  }

  return {
    padInfo: u,
    outHeight: c,
    outWidth: p
  };
}

function get3DPadAndOutInfo(e, t, n, r, a, s, o, i, l, u, c) {
  var p, d, h, m;

  if ("number" == typeof e) {
    p = {
      top: e,
      bottom: e,
      left: e,
      right: e,
      front: e,
      back: e,
      type: 0 === e ? "VALID" : "NUMBER"
    };

    var _s95 = computeOutputShape4D([t, n, r, 1], i, 1, a, e, c);

    d = _s95[0], h = _s95[1], m = _s95[2];
  } else if ("same" === e) {
    d = Math.ceil(t / a), h = Math.ceil(n / s), m = Math.ceil(r / o);

    var _e572 = (d - 1) * a + i - t,
        _c20 = (h - 1) * s + l - n,
        f = (m - 1) * o + u - r,
        g = Math.floor(_e572 / 2),
        $ = _e572 - g,
        y = Math.floor(_c20 / 2),
        b = _c20 - y,
        x = Math.floor(f / 2);

    p = {
      top: y,
      bottom: b,
      left: x,
      right: f - x,
      front: g,
      back: $,
      type: "SAME"
    };
  } else {
    if ("valid" !== e) throw Error("Unknown padding parameter: ".concat(e));
    p = {
      top: 0,
      bottom: 0,
      left: 0,
      right: 0,
      front: 0,
      back: 0,
      type: "VALID"
    }, d = Math.ceil((t - i + 1) / a), h = Math.ceil((n - l + 1) / s), m = Math.ceil((r - u + 1) / o);
  }

  return {
    padInfo: p,
    outDepth: d,
    outHeight: h,
    outWidth: m
  };
}

function round$3(e, t) {
  if (!t) return Math.trunc(e);

  switch (t) {
    case "round":
      return Math.round(e);

    case "ceil":
      return Math.ceil(e);

    case "floor":
      return Math.floor(e);

    default:
      throw new Error("Unknown roundingMode ".concat(t));
  }
}

function tupleValuesAreOne(e) {
  var [t, n, r] = parseTupleParam(e);
  return 1 === t && 1 === n && 1 === r;
}

function eitherStridesOrDilationsAreOne(e, t) {
  return tupleValuesAreOne(e) || tupleValuesAreOne(t);
}

function convertConv2DDataFormat(e) {
  if ("NHWC" === e) return "channelsLast";
  if ("NCHW" === e) return "channelsFirst";
  throw new Error("Unknown dataFormat ".concat(e));
}

function reshape_(e, t) {
  var n = convertToTensor(e, "x", "reshape", "string_or_numeric");
  return ENGINE.runKernel(Reshape$1, {
    x: n
  }, {
    shape: t
  });
}

var reshape$3 = op({
  reshape_
});

function avgPool_(e, t, n, r, a) {
  var s = convertToTensor(e, "x", "avgPool", "float32");
  assert$4(eitherStridesOrDilationsAreOne(n, 1), () => "Error in avgPool: Either strides or dilations must be 1. Got strides ".concat(n, " and dilations '1'"));
  var o = s,
      i = !1;
  3 === s.rank && (i = !0, o = reshape$3(s, [1, s.shape[0], s.shape[1], s.shape[2]])), assert$4(4 === o.rank, () => "Error in avgPool: x must be rank 4 but got rank ".concat(o.rank, ".")), null != a && assert$4(isInt(r), () => "Error in avgPool: pad must be an integer when using, dimRoundingMode ".concat(a, " but got pad ").concat(r, "."));
  var l = ENGINE.runKernel(AvgPool, {
    x: o
  }, {
    filterSize: t,
    strides: n,
    pad: r,
    dimRoundingMode: a
  });
  return l = cast$3(l, s.dtype), i ? reshape$3(l, [l.shape[1], l.shape[2], l.shape[3]]) : l;
}

var avgPool$2 = op({
  avgPool_
});

function avgPool3d_(e, t, n, r, a) {
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : "NDHWC";
  var o = convertToTensor(e, "x", "avgPool3d", "float32");
  var i = o,
      l = !1;
  4 === o.rank && (l = !0, i = reshape$3(o, [1, o.shape[0], o.shape[1], o.shape[2], o.shape[3]])), assert$4(5 === i.rank, () => "Error in avgPool3d: x must be rank 5 but got rank ".concat(i.rank, ".")), assert$4("NDHWC" === s, () => "Error in avgPool3d: Only NDHWC is currently supported, but got dataFormat of ".concat(s)), null != a && assert$4(isInt(r), () => "Error in avgPool3d: pad must be an integer when using, dimRoundingMode ".concat(a, " but got pad ").concat(r, "."));
  var u = ENGINE.runKernel(AvgPool3D, {
    x: i
  }, {
    filterSize: t,
    strides: n,
    pad: r,
    dimRoundingMode: a,
    dataFormat: s
  });
  return u = cast$3(u, i.dtype), l ? reshape$3(u, [u.shape[1], u.shape[2], u.shape[3], u.shape[4]]) : u;
}

var avgPool3d$1 = op({
  avgPool3d_
});

function concat_(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;
  assert$4(e.length >= 1, () => "Pass at least one tensor to concat");
  var n = convertToTensorArray(e, "tensors", "concat", "string_or_numeric");
  return "complex64" === n[0].dtype && n.forEach(e => {
    if ("complex64" !== e.dtype) throw new Error("Cannot concatenate complex64 tensors with a tensor\n          with dtype ".concat(e.dtype, ". "));
  }), 1 === n.length ? clone(n[0]) : ENGINE.runKernel(Concat, n, {
    axis: t
  });
}

var concat$2 = op({
  concat_
});

function sigmoid_(e) {
  var t = convertToTensor(e, "x", "sigmoid");
  return ENGINE.runKernel(Sigmoid$1, {
    x: t
  });
}

var sigmoid$2 = op({
  sigmoid_
});

function slice_(e, t, n) {
  var r = convertToTensor(e, "x", "slice", "string_or_numeric");
  if (0 === r.rank) throw new Error("Slicing scalar is not possible");
  return ENGINE.runKernel(Slice, {
    x: r
  }, {
    begin: t,
    size: n
  });
}

var slice$2 = op({
  slice_
});

function tanh_(e) {
  var t = convertToTensor(e, "x", "tanh");
  return ENGINE.runKernel(Tanh$1, {
    x: t
  });
}

var tanh$2 = op({
  tanh_
});

function basicLSTMCell_(e, t, n, r, a, s) {
  var o = convertToTensor(e, "forgetBias", "basicLSTMCell"),
      i = convertToTensor(t, "lstmKernel", "basicLSTMCell"),
      l = convertToTensor(n, "lstmBias", "basicLSTMCell"),
      u = convertToTensor(r, "data", "basicLSTMCell"),
      c = convertToTensor(a, "c", "basicLSTMCell"),
      p = convertToTensor(s, "h", "basicLSTMCell"),
      d = concat$2([u, p], 1),
      h = matMul$1(d, i),
      m = add$2(h, l),
      f = m.shape[1] / 4,
      g = [m.shape[0], f],
      $ = slice$2(m, [0, 0], g),
      y = slice$2(m, [0, f], g),
      b = slice$2(m, [0, 2 * f], g),
      x = slice$2(m, [0, 3 * f], g),
      v = add$2(mul(sigmoid$2($), tanh$2(y)), mul(c, sigmoid$2(add$2(o, b))));
  return [v, mul(tanh$2(v), sigmoid$2(x))];
}

var basicLSTMCell = op({
  basicLSTMCell_
});

function batchToSpaceND_(e, t, n) {
  var r = convertToTensor(e, "x", "batchToSpaceND"),
      a = t.reduce((e, t) => e * t);
  return assert$4(r.rank >= 1 + t.length, () => "input rank is ".concat(r.rank, " but should be > than blockShape.length ").concat(t.length)), assert$4(n.length === t.length, () => "crops.length is ".concat(n.length, " but should be equal to blockShape.length  ").concat(t.length)), assert$4(r.shape[0] % a == 0, () => "input tensor batch is ".concat(r.shape[0], " but is not divisible by the product of the elements of blockShape ").concat(t.join(" * "), " === ").concat(a)), ENGINE.runKernel(BatchToSpaceND, {
    x: r
  }, {
    blockShape: t,
    crops: n
  });
}

var batchToSpaceND$2 = op({
  batchToSpaceND_
});

function xAs4D(e) {
  var t;
  return t = 0 === e.rank || 1 === e.rank ? reshape$3(e, [1, 1, 1, e.size]) : 2 === e.rank ? reshape$3(e, [1, 1, e.shape[0], e.shape[1]]) : 3 === e.rank ? reshape$3(e, [1, e.shape[0], e.shape[1], e.shape[2]]) : e, t;
}

function batchNorm_(e, t, n, r, a, s) {
  null == s && (s = .001);
  var o = convertToTensor(e, "x", "batchNorm"),
      i = convertToTensor(t, "mean", "batchNorm"),
      l = convertToTensor(n, "variance", "batchNorm");
  var u, c;
  null != a && (u = convertToTensor(a, "scale", "batchNorm")), null != r && (c = convertToTensor(r, "offset", "batchNorm")), assert$4(i.rank === l.rank, () => "Batch normalization gradient requires mean and variance to have equal ranks."), assert$4(null == c || i.rank === c.rank, () => "Batch normalization gradient requires mean and offset to have equal ranks."), assert$4(null == u || i.rank === u.rank, () => "Batch normalization gradient requires mean and scale to have equal ranks.");
  var p = xAs4D(o),
      d = ENGINE.runKernel(FusedBatchNorm, {
    x: p,
    scale: u,
    offset: c,
    mean: i,
    variance: l
  }, {
    varianceEpsilon: s
  });
  return reshape$3(d, o.shape);
}

var batchNorm$2 = op({
  batchNorm_
});

function batchNorm2d_(e, t, n, r, a, s) {
  var o = convertToTensor(e, "x", "batchNorm"),
      i = convertToTensor(t, "mean", "batchNorm"),
      l = convertToTensor(n, "variance", "batchNorm");
  var u, c;
  return null != a && (u = convertToTensor(a, "scale", "batchNorm")), null != r && (c = convertToTensor(r, "offset", "batchNorm")), assert$4(2 === o.rank, () => "Error in batchNorm2D: x must be rank 2 but got rank ".concat(o.rank, ".")), assert$4(2 === i.rank || 1 === i.rank, () => "Error in batchNorm2D: mean must be rank 2 or rank 1 but got rank ".concat(i.rank, ".")), assert$4(2 === l.rank || 1 === l.rank, () => "Error in batchNorm2D: variance must be rank 2 or rank 1 but got rank ".concat(l.rank, ".")), null != u && assert$4(2 === u.rank || 1 === u.rank, () => "Error in batchNorm2D: scale must be rank 2 or rank 1 but got rank ".concat(u.rank, ".")), null != c && assert$4(2 === c.rank || 1 === c.rank, () => "Error in batchNorm2D: offset must be rank 2 or rank 1 but got rank ".concat(c.rank, ".")), batchNorm$2(o, i, l, c, u, s);
}

var batchNorm2d = op({
  batchNorm2d_
});

function batchNorm3d_(e, t, n, r, a, s) {
  var o = convertToTensor(e, "x", "batchNorm"),
      i = convertToTensor(t, "mean", "batchNorm"),
      l = convertToTensor(n, "variance", "batchNorm");
  var u, c;
  return null != a && (u = convertToTensor(a, "scale", "batchNorm")), null != r && (c = convertToTensor(r, "offset", "batchNorm")), assert$4(3 === o.rank, () => "Error in batchNorm3D: x must be rank 3 but got rank ".concat(o.rank, ".")), assert$4(3 === i.rank || 1 === i.rank, () => "Error in batchNorm3D: mean must be rank 3 or rank 1 but got rank ".concat(i.rank, ".")), assert$4(3 === l.rank || 1 === l.rank, () => "Error in batchNorm3D: variance must be rank 3 or rank 1 but got rank ".concat(l.rank, ".")), null != u && assert$4(3 === u.rank || 1 === u.rank, () => "Error in batchNorm3D: scale must be rank 3 or rank 1 but got rank ".concat(u.rank, ".")), null != c && assert$4(3 === c.rank || 1 === c.rank, () => "Error in batchNorm3D: offset must be rank 3 or rank 1 but got rank ".concat(c.rank, ".")), batchNorm$2(o, i, l, c, u, s);
}

var batchNorm3d = op({
  batchNorm3d_
});

function batchNorm4d_(e, t, n, r, a, s) {
  var o = convertToTensor(e, "x", "batchNorm"),
      i = convertToTensor(t, "mean", "batchNorm"),
      l = convertToTensor(n, "variance", "batchNorm");
  var u, c;
  return null != a && (u = convertToTensor(a, "scale", "batchNorm")), null != r && (c = convertToTensor(r, "offset", "batchNorm")), assert$4(4 === o.rank, () => "Error in batchNorm4D: x must be rank 4 but got rank ".concat(o.rank, ".")), assert$4(4 === i.rank || 1 === i.rank, () => "Error in batchNorm4D: mean must be rank 4 or rank 1 but got rank ".concat(i.rank, ".")), assert$4(4 === l.rank || 1 === l.rank, () => "Error in batchNorm4D: variance must be rank 4 or rank 1 but got rank ".concat(l.rank, ".")), null != u && assert$4(4 === u.rank || 1 === u.rank, () => "Error in batchNorm4D: scale must be rank 4 or rank 1 but got rank ".concat(u.rank, ".")), null != c && assert$4(4 === c.rank || 1 === c.rank, () => "Error in batchNorm4D: offset must be rank 4 or rank 1 but got rank ".concat(c.rank, ".")), batchNorm$2(o, i, l, c, u, s);
}

var batchNorm4d = op({
  batchNorm4d_
});

function bincount_(e, t, n) {
  var r = convertToTensor(e, "x", "bincount"),
      a = convertToTensor(t, "weights", "bincount");
  return assert$4("int32" === r.dtype, () => "Error in bincount: input dtype must be int32, but got ".concat(r.dtype)), assert$4(n >= 0, () => "size must be non-negative, but got ".concat(n, ".")), assert$4(a.size === r.size || 0 === a.size, () => "Error in bincount: weights must have the same size as input or0-length, but got input shape: ".concat(r.shape, ", weights shape: ").concat(a.shape, ".")), ENGINE.runKernel(Bincount, {
    x: r,
    weights: a
  }, {
    size: n
  });
}

var bincount$2 = op({
  bincount_
});

function broadcastTo_(e, t) {
  var n = convertToTensor(e, "broadcastTo", "x");
  var r = n.shape;
  if (t.some(e => !(e > 0) || e % 1 != 0)) throw new Error("broadcastTo(): Invalid broadcast shape [".concat(t, "]."));
  if (t.length < n.rank) throw new Error("broadcastTo(): shape.length=".concat(t.length, " < input.rank=").concat(n.rank, "."));

  if (t.length > n.rank) {
    var _e573 = n.shape.slice();

    for (; _e573.length < t.length;) {
      _e573.unshift(1);
    }

    n = reshape$3(n, _e573);
  }

  var a = n.shape,
      s = Array.from(t);

  for (var _e574 = t.length - 1; _e574 >= 0; _e574--) {
    if (a[_e574] === t[_e574]) s[_e574] = 1;else if (1 !== n.shape[_e574]) throw new Error("broadcastTo(): [".concat(r, "] cannot be broadcast to [").concat(t, "]."));
  }

  return 0 === s.map((e, t) => e > 1 ? t : -1).filter(e => e >= 0).length ? clone(n) : ENGINE.runKernel(Tile, {
    x: n
  }, {
    reps: s
  });
}

var broadcastTo = op({
  broadcastTo_
});

function ceil_(e) {
  var t = convertToTensor(e, "x", "ceil");
  return ENGINE.runKernel(Ceil, {
    x: t
  });
}

var ceil$2 = op({
  ceil_
});

function clipByValue_(e, t, n) {
  var r = convertToTensor(e, "x", "clipByValue");
  return assert$4(t <= n, () => "Error in clip: min (".concat(t, ") must be less than or equal to max (").concat(n, ").")), ENGINE.runKernel(ClipByValue, {
    x: r
  }, {
    clipValueMin: t,
    clipValueMax: n
  });
}

var clipByValue$1 = op({
  clipByValue_
});

function concat1d_(e) {
  return concat$2(e, 0);
}

var concat1d = op({
  concat1d_
});

function concat2d_(e, t) {
  return concat$2(e, t);
}

var concat2d = op({
  concat2d_
});

function concat3d_(e, t) {
  return concat$2(e, t);
}

var concat3d = op({
  concat3d_
});

function concat4d_(e, t) {
  return concat$2(e, t);
}

var concat4d = op({
  concat4d_
});

function conv2d_(e, t, n, r) {
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : "NHWC";
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : [1, 1];
  var o = arguments.length > 6 ? arguments[6] : undefined;
  var i = convertToTensor(e, "x", "conv2d"),
      l = convertToTensor(t, "filter", "conv2d");
  var u = i,
      c = !1;
  3 === i.rank && (c = !0, u = reshape$3(i, [1, i.shape[0], i.shape[1], i.shape[2]])), assert$4(4 === u.rank, () => "Error in conv2d: input must be rank 4, but got rank ".concat(u.rank, ".")), assert$4(4 === l.rank, () => "Error in conv2d: filter must be rank 4, but got rank ".concat(l.rank, ".")), null != o && assert$4(isInt(r), () => "Error in conv2d: pad must be an integer when using, dimRoundingMode ".concat(o, " but got pad ").concat(r, "."));
  var p = "NHWC" === a ? u.shape[3] : u.shape[1];
  assert$4(p === l.shape[2], () => "Error in conv2d: depth of input (".concat(p, ") must match input depth for filter ").concat(l.shape[2], ".")), assert$4(eitherStridesOrDilationsAreOne(n, s), () => "Error in conv2D: Either strides or dilations must be 1. Got strides ".concat(n, " and dilations '").concat(s, "'"));
  var d = ENGINE.runKernel(Conv2D$1, {
    x: u,
    filter: l
  }, {
    strides: n,
    pad: r,
    dataFormat: a,
    dilations: s,
    dimRoundingMode: o
  });
  return c ? reshape$3(d, [d.shape[1], d.shape[2], d.shape[3]]) : d;
}

var conv2d$3 = op({
  conv2d_
});

function conv1d_(e, t, n, r) {
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : "NWC";
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : 1;
  var o = arguments.length > 6 ? arguments[6] : undefined;
  var i = convertToTensor(e, "x", "conv1d"),
      l = convertToTensor(t, "filter", "conv1d");
  var u = i,
      c = !1;
  2 === i.rank && (c = !0, u = reshape$3(i, [1, i.shape[0], i.shape[1]])), assert$4(3 === u.rank, () => "Error in conv1d: input must be rank 3, but got rank ".concat(u.rank, ".")), assert$4(3 === l.rank, () => "Error in conv1d: filter must be rank 3, but got rank ".concat(l.rank, ".")), null != o && assert$4(isInt(r), () => "Error in conv1d: pad must be an integer when using, dimRoundingMode ".concat(o, " but got pad ").concat(r, ".")), assert$4(u.shape[2] === l.shape[1], () => "Error in conv1d: depth of input (".concat(u.shape[2], ") must match input depth for filter ").concat(l.shape[1], ".")), assert$4(eitherStridesOrDilationsAreOne(n, s), () => "Error in conv1D: Either stride or dilation must be 1. Got stride ".concat(n, " and dilation '").concat(s, "'")), assert$4("NWC" === a, () => "Error in conv1d: got dataFormat of ".concat(a, " but only NWC is currently supported."));
  var p = reshape$3(l, [1, l.shape[0], l.shape[1], l.shape[2]]),
      d = reshape$3(u, [u.shape[0], 1, u.shape[1], u.shape[2]]),
      h = conv2d$3(d, p, [1, n], r, "NHWC", [1, s], o);
  return reshape$3(h, c ? [h.shape[2], h.shape[3]] : [h.shape[0], h.shape[2], h.shape[3]]);
}

var conv1d$1 = op({
  conv1d_
});

function conv2DBackpropInput_(e, t, n, r, a) {
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : "NHWC";
  var o = arguments.length > 6 ? arguments[6] : undefined;
  assert$4(e.length === t.rank, () => "Length of inShape (".concat(e.length, ") and rank of dy (").concat(t.rank, ") must match"));
  var i = e,
      l = t,
      u = !1;
  3 === t.rank && (u = !0, l = reshape$3(t, [1, t.shape[0], t.shape[1], t.shape[2]]), i = [1, e[0], e[1], e[2]]), assert$4(4 === i.length, () => "Error in conv2dDerInput: inShape must be length 4, but got length ".concat(i.length, ".")), assert$4(4 === l.rank, () => "Error in conv2dDerInput: dy must be rank 4, but got rank ".concat(l.rank)), assert$4(4 === n.rank, () => "Error in conv2dDerInput: filter must be rank 4, but got rank ".concat(n.rank));
  var c = "NHWC" === s ? i[3] : i[1],
      p = "NHWC" === s ? l.shape[3] : l.shape[1];
  assert$4(c === n.shape[2], () => "Error in conv2dDerInput: depth of input (".concat(c, ") must match input depth for filter ").concat(n.shape[2], ".")), assert$4(p === n.shape[3], () => "Error in conv2dDerInput: depth of output (".concat(p, ") must match output depth for filter ").concat(n.shape[3], ".")), null != o && assert$4(isInt(a), () => "Error in conv2dDerInput: pad must be an integer when using, dimRoundingMode ".concat(o, " but got pad ").concat(a, "."));
  var d = ENGINE.runKernel(Conv2DBackpropInput, {
    dy: l,
    filter: n
  }, {
    strides: r,
    pad: a,
    dataFormat: s,
    dimRoundingMode: o,
    inputShape: i
  });
  return u ? reshape$3(d, [d.shape[1], d.shape[2], d.shape[3]]) : d;
}

var conv2DBackpropInput$2 = op({
  conv2DBackpropInput_
});

function conv2dTranspose_(e, t, n, r, a, s) {
  var o = convertToTensor(e, "x", "conv2dTranspose"),
      i = convertToTensor(t, "filter", "conv2dTranspose");
  return conv2DBackpropInput$2(n, o, i, r, a, "NHWC", s);
}

var conv2dTranspose$1 = op({
  conv2dTranspose_
});

function conv3d_(e, t, n, r) {
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : "NDHWC";
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : [1, 1, 1];
  var o = convertToTensor(e, "x", "conv3d"),
      i = convertToTensor(t, "filter", "conv3d");
  var l = o,
      u = !1;
  4 === o.rank && (u = !0, l = reshape$3(o, [1, o.shape[0], o.shape[1], o.shape[2], o.shape[3]])), assert$4(5 === l.rank, () => "Error in conv3d: input must be rank 5, but got rank ".concat(l.rank, ".")), assert$4(5 === i.rank, () => "Error in conv3d: filter must be rank 5, but got rank ".concat(i.rank, ".")), assert$4(l.shape[4] === i.shape[3], () => "Error in conv3d: depth of input (".concat(l.shape[4], ") must match input depth for filter ").concat(i.shape[3], ".")), assert$4(eitherStridesOrDilationsAreOne(n, s), () => "Error in conv3D: Either strides or dilations must be 1. Got strides ".concat(n, " and dilations '").concat(s, "'")), assert$4("NDHWC" === a, () => "Error in conv3d: got dataFormat of ".concat(a, " but only NDHWC is currently supported."));
  var c = ENGINE.runKernel(Conv3D$1, {
    x: l,
    filter: i
  }, {
    strides: n,
    pad: r,
    dataFormat: a,
    dilations: s
  });
  return u ? reshape$3(c, [c.shape[1], c.shape[2], c.shape[3], c.shape[4]]) : c;
}

var conv3d$1 = op({
  conv3d_
});

function conv3DBackpropInput_(e, t, n, r, a) {
  assert$4(e.length === t.rank, () => "Length of inShape (".concat(e.length, ") and rank of dy (").concat(t.rank, ") must match"));
  var s = e,
      o = t,
      i = !1;
  4 === t.rank && (i = !0, o = reshape$3(t, [1, t.shape[0], t.shape[1], t.shape[2], t.shape[3]]), s = [1, e[0], e[1], e[2], e[3]]);
  var l = s[4],
      u = o.shape[4];
  assert$4(5 === s.length, () => "Error in conv3dDerInput: inShape must be length 5, but got length ".concat(s.length, ".")), assert$4(5 === o.rank, () => "Error in conv3dDerInput: dy must be rank 5, but got rank ".concat(o.rank)), assert$4(5 === n.rank, () => "Error in conv3dDerInput: filter must be rank 5, but got rank ".concat(n.rank)), assert$4(l === n.shape[3], () => "Error in conv3dDerInput: depth of input (".concat(l, ") must match input depth for filter ").concat(n.shape[3], ".")), assert$4(u === n.shape[4], () => "Error in conv3dDerInput: depth of output (".concat(u, ") must match output depth for filter ").concat(n.shape[4], "."));
  var c = ENGINE.runKernel(Conv3DBackpropInputV2, {
    dy: o,
    filter: n
  }, {
    pad: a,
    strides: r,
    inputShape: s
  });
  return i ? reshape$3(c, [c.shape[1], c.shape[2], c.shape[3], c.shape[4]]) : c;
}

var conv3DBackpropInput$1 = op({
  conv3DBackpropInput_
});

function conv3dTranspose_(e, t, n, r, a) {
  var s = convertToTensor(e, "x", "conv3dTranspose"),
      o = convertToTensor(t, "filter", "conv3dTranspose");
  return conv3DBackpropInput$1(n, s, o, r, a);
}

var conv3dTranspose$1 = op({
  conv3dTranspose_
});

function cos_(e) {
  var t = convertToTensor(e, "x", "cos");
  return ENGINE.runKernel(Cos, {
    x: t
  });
}

var cos$2 = op({
  cos_
});

function cosh_(e) {
  var t = convertToTensor(e, "x", "cosh");
  return ENGINE.runKernel(Cosh, {
    x: t
  });
}

var cosh$2 = op({
  cosh_
});

function cumsum_(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
  var a = convertToTensor(e, "x", "cumsum");
  return ENGINE.runKernel(Cumsum, {
    x: a
  }, {
    axis: t,
    exclusive: n,
    reverse: r
  });
}

var cumsum$2 = op({
  cumsum_
});

function denseBincount_(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
  var a = convertToTensor(e, "x", "denseBincount"),
      s = convertToTensor(t, "weights", "denseBincount");
  return assert$4("int32" === a.dtype, () => "Error in denseBincount: input dtype must be int32, but got ".concat(a.dtype)), assert$4(a.rank <= 2, () => "Error in denseBincount: input must be at most rank 2, but got rank ".concat(a.rank, ".")), assert$4(n >= 0, () => "size must be non-negative, but got ".concat(n, ".")), assert$4(s.size === a.size || 0 === s.size, () => "Error in denseBincount: weights must have the same shape as x or 0-length, but got x shape: ".concat(a.shape, ", weights shape: ").concat(s.shape, ".")), ENGINE.runKernel(DenseBincount, {
    x: a,
    weights: s
  }, {
    size: n,
    binaryOutput: r
  });
}

var denseBincount$2 = op({
  denseBincount_
});

function depthToSpace_(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : "NHWC";
  var r = convertToTensor(e, "x", "depthToSpace"),
      a = "NHWC" === n ? r.shape[1] : r.shape[2],
      s = "NHWC" === n ? r.shape[2] : r.shape[3],
      o = "NHWC" === n ? r.shape[3] : r.shape[1];
  return assert$4(a * t >= 0, () => "Negative dimension size caused by overflow when multiplying\n    ".concat(a, " and ").concat(t, "  for depthToSpace with input shape\n    ").concat(r.shape)), assert$4(s * t >= 0, () => "Negative dimension size caused by overflow when multiplying\n    ".concat(s, " and ").concat(t, " for depthToSpace with input shape\n        ").concat(r.shape)), assert$4(o % (t * t) == 0, () => "Dimension size must be evenly divisible by ".concat(t * t, " but is ").concat(o, " for depthToSpace with input shape ").concat(r.shape)), ENGINE.runKernel(DepthToSpace, {
    x: r
  }, {
    blockSize: t,
    dataFormat: n
  });
}

var depthToSpace$2 = op({
  depthToSpace_
});

function depthwiseConv2d_(e, t, n, r) {
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : "NHWC";
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : [1, 1];
  var o = arguments.length > 6 ? arguments[6] : undefined;
  var i = convertToTensor(e, "x", "depthwiseConv2d"),
      l = convertToTensor(t, "filter", "depthwiseConv2d");
  var u = i,
      c = !1;
  3 === i.rank && (c = !0, u = reshape$3(i, [1, i.shape[0], i.shape[1], i.shape[2]])), assert$4(4 === u.rank, () => "Error in depthwiseConv2d: input must be rank 4, but got rank ".concat(u.rank, ".")), assert$4(4 === l.rank, () => "Error in depthwiseConv2d: filter must be rank 4, but got rank ".concat(l.rank, ".")), assert$4(u.shape[3] === l.shape[2], () => "Error in depthwiseConv2d: number of input channels (".concat(u.shape[3], ") must match the inChannels dimension in filter ").concat(l.shape[2], ".")), null != o && assert$4(isInt(r), () => "Error in depthwiseConv2d: pad must be an integer when using, dimRoundingMode ".concat(o, " but got pad ").concat(r, "."));
  var p = ENGINE.runKernel(DepthwiseConv2dNative, {
    x: u,
    filter: l
  }, {
    strides: n,
    pad: r,
    dataFormat: a,
    dilations: s,
    dimRoundingMode: o
  });
  return c ? reshape$3(p, [p.shape[1], p.shape[2], p.shape[3]]) : p;
}

var depthwiseConv2d$3 = op({
  depthwiseConv2d_
});

function diag_(e) {
  var t = convertToTensor(e, "x", "diag");
  return ENGINE.runKernel(Diag, {
    x: t
  });
}

var diag$2 = op({
  diag_
});

function dilation2d_(e, t, n, r) {
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : [1, 1];
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : "NHWC";
  var o = convertToTensor(e, "x", "dilation2d"),
      i = convertToTensor(t, "filter", "dilation2d");
  assert$4(3 === o.rank || 4 === o.rank, () => "Error in dilation2d: input must be rank 3 or 4, but got rank ".concat(o.rank, ".")), assert$4(3 === i.rank, () => "Error in dilation2d: filter must be rank 3, but got rank ".concat(i.rank, ".")), assert$4("NHWC" === s, () => "Error in dilation2d: Only NHWC is currently supported, but got dataFormat of ".concat(s));
  var l = o,
      u = !1;
  3 === o.rank && (l = reshape$3(o, [1, o.shape[0], o.shape[1], o.shape[2]]), u = !0);
  var c = ENGINE.runKernel(Dilation2D, {
    x: l,
    filter: i
  }, {
    strides: n,
    pad: r,
    dilations: a
  });
  return u ? reshape$3(c, [c.shape[1], c.shape[2], c.shape[3]]) : c;
}

var dilation2d = op({
  dilation2d_
});

function getBroadcastDims$1(e, t) {
  var n = e.length,
      r = [];

  for (var a = 0; a < n; a++) {
    var s = n - 1 - a,
        o = e[s] || 1;
    (t[t.length - 1 - a] || 1) > 1 && 1 === o && r.unshift(s);
  }

  return r;
}

function getReductionAxes(e, t) {
  var n = [];

  for (var r = 0; r < t.length; r++) {
    var a = e[e.length - r - 1],
        s = t.length - r - 1,
        o = t[s];
    (null == a || 1 === a && o > 1) && n.unshift(s);
  }

  return n;
}

function assertAndGetBroadcastShape(e, t) {
  var n = [],
      r = Math.max(e.length, t.length);

  for (var a = 0; a < r; a++) {
    var _r196 = e[e.length - a - 1];
    null == _r196 && (_r196 = 1);
    var s = t[t.length - a - 1];
    if (null == s && (s = 1), 1 === _r196) n.unshift(s);else if (1 === s) n.unshift(_r196);else {
      if (_r196 !== s) throw Error("Operands could not be broadcast together with shapes ".concat(e, " and ").concat(t, "."));
      n.unshift(_r196);
    }
  }

  return n;
}

function equal_(e, t) {
  var n = convertToTensor(e, "a", "equal", "string_or_numeric"),
      r = convertToTensor(t, "b", "equal", "string_or_numeric");
  return [n, r] = makeTypesMatch(n, r), assertAndGetBroadcastShape(n.shape, r.shape), ENGINE.runKernel(Equal, {
    a: n,
    b: r
  });
}

var equal$2 = op({
  equal_
});

function where_(e, t, n) {
  var r = convertToTensor(t, "a", "where"),
      a = convertToTensor(n, "b", "where"),
      s = convertToTensor(e, "condition", "where", "bool"),
      o = assertAndGetBroadcastShape(assertAndGetBroadcastShape(s.shape, r.shape), a.shape),
      i = broadcastTo(s, o),
      l = broadcastTo(r, o),
      u = broadcastTo(a, o);
  return ENGINE.runKernel(Select, {
    condition: i,
    t: l,
    e: u
  });
}

var where = op({
  where_
});

function zerosLike_(e) {
  var t = convertToTensor(e, "x", "zerosLike");
  return ENGINE.runKernel(ZerosLike, {
    x: t
  });
}

var zerosLike$2 = op({
  zerosLike_
});

function divNoNan_(e, t) {
  var n = convertToTensor(e, "a", "div"),
      r = convertToTensor(t, "b", "div");
  [n, r] = makeTypesMatch(n, r);
  var a = div$1(n, r),
      s = zerosLike$2(a),
      o = equal$2(r, s);
  return where(o, s, a);
}

var divNoNan = op({
  divNoNan_
});

function dot_(e, t) {
  var n = convertToTensor(e, "t1", "dot"),
      r = convertToTensor(t, "t2", "dot");
  assert$4(!(1 !== n.rank && 2 !== n.rank || 1 !== r.rank && 2 !== r.rank), () => "Error in dot: inputs must all be rank 1 or 2, but got ranks ".concat(n.rank, " and ").concat(r.rank, "."));
  var a = 1 === n.rank ? n.size : n.shape[1],
      s = 1 === r.rank ? r.size : r.shape[0];

  if (assert$4(a === s, () => "Error in dot: inner dimensions of inputs must match, but got ".concat(a, " and ").concat(s, ".")), 1 === n.rank && 1 === r.rank) {
    var _e575 = reshape$3(n, [1, -1]),
        _t406 = reshape$3(r, [-1, 1]),
        _a127 = matMul$1(_e575, _t406);

    return reshape$3(_a127, []);
  }

  if (1 === n.rank && 2 === r.rank) {
    var _e576 = reshape$3(n, [1, -1]),
        _t407 = reshape$3(r, [r.shape[0], r.shape[1]]),
        _a128 = matMul$1(_e576, _t407);

    return reshape$3(_a128, [_a128.size]);
  }

  if (2 === n.rank && 1 === r.rank) {
    var _e577 = reshape$3(r, [-1, 1]),
        _t408 = matMul$1(n, _e577);

    return reshape$3(_t408, [_t408.size]);
  }

  {
    var _e578 = reshape$3(r, [r.shape[0], r.shape[1]]);

    return matMul$1(n, _e578);
  }
}

var dot$2 = op({
  dot_
});

function einsum_(e) {
  for (var _len9 = arguments.length, t = new Array(_len9 > 1 ? _len9 - 1 : 0), _key9 = 1; _key9 < _len9; _key9++) {
    t[_key9 - 1] = arguments[_key9];
  }

  var n = t.map((e, t) => convertToTensor(e, "tensors".concat(t), "einsum"));
  return ENGINE.runKernel(Einsum, n, {
    equation: e
  });
}

var einsum$2 = op({
  einsum_
});

function elu_(e) {
  var t = convertToTensor(e, "x", "elu");
  return ENGINE.runKernel(Elu$1, {
    x: t
  });
}

var elu$4 = op({
  elu_
});

function erf_(e) {
  var t = convertToTensor(e, "x", "erf");
  return assert$4("int32" === t.dtype || "float32" === t.dtype, () => "Input dtype must be `int32` or `float32`."), "int32" === t.dtype && (t = cast$3(t, "float32")), ENGINE.runKernel(Erf, {
    x: t
  });
}

var erf$2 = op({
  erf_
});

function exp_(e) {
  var t = convertToTensor(e, "x", "exp");
  return ENGINE.runKernel(Exp, {
    x: t
  });
}

var exp$2 = op({
  exp_
});

function expandDims_(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;
  var n = convertToTensor(e, "x", "expandDims", "string_or_numeric");
  return assert$4(t <= n.rank, () => "Axis must be <= rank of the tensor"), ENGINE.runKernel(ExpandDims, {
    input: n
  }, {
    dim: t
  });
}

var expandDims$3 = op({
  expandDims_
});

function expm1_(e) {
  var t = convertToTensor(e, "x", "expm1");
  return ENGINE.runKernel(Expm1, {
    x: t
  });
}

var expm1$2 = op({
  expm1_
});

function tile_(e, t) {
  var n = convertToTensor(e, "x", "tile", "string_or_numeric");
  return assert$4(n.rank === t.length, () => "Error in transpose: rank of input ".concat(n.rank, " must match length of reps ").concat(t, ".")), ENGINE.runKernel(Tile, {
    x: n
  }, {
    reps: t
  });
}

var tile$3 = op({
  tile_
});

function eye_(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : "float32";
  null == t && (t = e);
  var a = buffer([e, t], r),
      s = e <= t ? e : t;

  for (var _e579 = 0; _e579 < s; ++_e579) {
    a.set(1, _e579, _e579);
  }

  var o = reshape$3(a.toTensor(), [e, t]);
  if (null == n) return o;
  if (1 === n.length) return tile$3(expandDims$3(o, 0), [n[0], 1, 1]);
  if (2 === n.length) return tile$3(expandDims$3(expandDims$3(o, 0), 0), [n[0], n[1], 1, 1]);
  if (3 === n.length) return tile$3(expandDims$3(expandDims$3(expandDims$3(o, 0), 0), 0), [n[0], n[1], n[2], 1, 1]);
  throw new Error("eye() currently supports only 1D and 2D batchShapes, but received ".concat(n.length, "D."));
}

var eye = op({
  eye_
});

function fill$2(e, t, n) {
  return ENGINE.runKernel(Fill, {}, {
    shape: e,
    value: t,
    dtype: n
  });
}

function floor_(e) {
  var t = convertToTensor(e, "x", "floor");
  return ENGINE.runKernel(Floor, {
    x: t
  });
}

var floor$2 = op({
  floor_
});

function gather_(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 0;
  var a = convertToTensor(e, "x", "gather"),
      s = convertToTensor(t, "indices", "gather", "int32");
  return ENGINE.runKernel(GatherV2, {
    x: a,
    indices: s
  }, {
    axis: n,
    batchDims: r
  });
}

var gather$1 = op({
  gather_
});

function greater_(e, t) {
  var n = convertToTensor(e, "a", "greater", "string_or_numeric"),
      r = convertToTensor(t, "b", "greater", "string_or_numeric");
  return [n, r] = makeTypesMatch(n, r), assertAndGetBroadcastShape(n.shape, r.shape), ENGINE.runKernel(Greater, {
    a: n,
    b: r
  });
}

var greater$3 = op({
  greater_
});

function greaterEqual_(e, t) {
  var n = convertToTensor(e, "a", "greaterEqual", "string_or_numeric"),
      r = convertToTensor(t, "b", "greaterEqual", "string_or_numeric");
  return [n, r] = makeTypesMatch(n, r), assertAndGetBroadcastShape(n.shape, r.shape), ENGINE.runKernel(GreaterEqual, {
    a: n,
    b: r
  });
}

var greaterEqual$2 = op({
  greaterEqual_
});

function imag_(e) {
  var t = convertToTensor(e, "input", "imag");
  return ENGINE.runKernel(Imag, {
    input: t
  });
}

var imag$2 = op({
  imag_
});

function isFinite_(e) {
  var t = convertToTensor(e, "x", "isFinite");
  return ENGINE.runKernel(IsFinite, {
    x: t
  });
}

var isFinite$3 = op({
  isFinite_
});

function isInf_(e) {
  var t = convertToTensor(e, "x", "isInf");
  return ENGINE.runKernel(IsInf, {
    x: t
  });
}

var isInf$2 = op({
  isInf_
});

function isNaN_(e) {
  var t = convertToTensor(e, "x", "isNaN");
  return ENGINE.runKernel(IsNan, {
    x: t
  });
}

var isNaN$3 = op({
  isNaN_
});

function leakyRelu_(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : .2;
  var n = convertToTensor(e, "x", "leakyRelu");
  return ENGINE.runKernel(LeakyRelu, {
    x: n
  }, {
    alpha: t
  });
}

var leakyRelu$2 = op({
  leakyRelu_
});

function less_(e, t) {
  var n = convertToTensor(e, "a", "less", "string_or_numeric"),
      r = convertToTensor(t, "b", "less", "string_or_numeric");
  return [n, r] = makeTypesMatch(n, r), assertAndGetBroadcastShape(n.shape, r.shape), ENGINE.runKernel(Less, {
    a: n,
    b: r
  });
}

var less$3 = op({
  less_
});

function lessEqual_(e, t) {
  var n = convertToTensor(e, "a", "lessEqual", "string_or_numeric"),
      r = convertToTensor(t, "b", "lessEqual", "string_or_numeric");
  return [n, r] = makeTypesMatch(n, r), assertAndGetBroadcastShape(n.shape, r.shape), ENGINE.runKernel(LessEqual, {
    a: n,
    b: r
  });
}

var lessEqual$2 = op({
  lessEqual_
});

function linspace(e, t, n) {
  if (n <= 0) throw new Error("The number of values should be positive.");
  return ENGINE.runKernel(LinSpace, {}, {
    start: e,
    stop: t,
    num: n
  });
}

function localResponseNormalization_(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 5;
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 1;
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 1;
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : .5;
  var s = convertToTensor(e, "x", "localResponseNormalization");
  assert$4(4 === s.rank || 3 === s.rank, () => "Error in localResponseNormalization: x must be rank 3 or 4 but got\n               rank ".concat(s.rank, ".")), assert$4(isInt(t), () => "Error in localResponseNormalization: depthRadius must be an integer but got depthRadius ".concat(t, "."));
  var o = s,
      i = !1;
  3 === s.rank && (i = !0, o = reshape$3(s, [1, s.shape[0], s.shape[1], s.shape[2]]));
  var l = ENGINE.runKernel(LRN, {
    x: o
  }, {
    depthRadius: t,
    bias: n,
    alpha: r,
    beta: a
  });
  return i ? reshape$3(l, [l.shape[1], l.shape[2], l.shape[3]]) : l;
}

var localResponseNormalization = op({
  localResponseNormalization_
});

function log_(e) {
  var t = convertToTensor(e, "x", "log");
  return ENGINE.runKernel(Log, {
    x: t
  });
}

var log$3 = op({
  log_
});

function log1p_(e) {
  var t = convertToTensor(e, "x", "log1p");
  return ENGINE.runKernel(Log1p, {
    x: t
  });
}

var log1p$2 = op({
  log1p_
});

function grad(e) {
  return assert$4(isFunction(e), () => "The f passed in grad(f) must be a function"), (t, n) => {
    var r = convertToTensor(t, "x", "tf.grad", "string_or_numeric"),
        a = null != n ? convertToTensor(n, "dy", "tf.grad") : null;
    return ENGINE.tidy(() => {
      var {
        value: t,
        grads: n
      } = ENGINE.gradients(() => e(r), [r], a);
      return null != a && assertShapesMatch(t.shape, a.shape, "The shape of dy passed in grad(f)(x, dy) must match the shape returned by f(x)"), checkGrads(n), n[0];
    });
  };
}

function grads(e) {
  return assert$4(isFunction(e), () => "The f passed in grads(f) must be a function"), (t, n) => {
    assert$4(Array.isArray(t), () => "The args passed in grads(f)(args) must be an array of `Tensor`s or `TensorLike`s");
    var r = convertToTensorArray(t, "args", "tf.grads", "string_or_numeric"),
        a = null != n ? convertToTensor(n, "dy", "tf.grads") : null;
    return ENGINE.tidy(() => {
      var {
        value: t,
        grads: n
      } = ENGINE.gradients(() => e(...r), r, a);
      return null != a && assertShapesMatch(t.shape, a.shape, "The shape of dy passed in grads(f)([x1,...], dy) must match the shape returned by f([x1,...])"), checkGrads(n), n;
    });
  };
}

function valueAndGrad(e) {
  return assert$4(isFunction(e), () => "The f passed in valueAndGrad(f) must be a function"), (t, n) => {
    assert$4(t instanceof Tensor, () => "The x passed in valueAndGrad(f)(x) must be a tensor"), assert$4(null == n || n instanceof Tensor, () => "The dy passed in valueAndGrad(f)(x, dy) must be a tensor");
    var {
      grads: r,
      value: a
    } = ENGINE.gradients(() => e(t), [t], n);
    return checkGrads(r), {
      grad: r[0],
      value: a
    };
  };
}

function valueAndGrads(e) {
  return assert$4(isFunction(e), () => "The f passed in valueAndGrads(f) must be a function"), (t, n) => {
    assert$4(Array.isArray(t) && t.every(e => e instanceof Tensor), () => "The args passed in valueAndGrads(f)(args) must be array of tensors"), assert$4(null == n || n instanceof Tensor, () => "The dy passed in valueAndGrads(f)(args, dy) must be a tensor");
    var r = ENGINE.gradients(() => e(...t), t, n);
    return null != n && assertShapesMatch(r.value.shape, n.shape, "The shape of dy passed in valueAndGrads(f)([x1,...], dy) must match the shape returned by f([x1,...])"), checkGrads(r.grads), r;
  };
}

function variableGrads(e, t) {
  assert$4(isFunction(e), () => "The f passed in variableGrads(f) must be a function"), assert$4(null == t || Array.isArray(t) && t.every(e => e instanceof Variable), () => "The varList passed in variableGrads(f, varList) must be an array of variables");
  var n = null != t;

  if (!n) {
    t = [];

    for (var _e580 in ENGINE.registeredVariables) {
      t.push(ENGINE.registeredVariables[_e580]);
    }
  }

  var r = n ? t.filter(e => !e.trainable) : null,
      a = t.length;
  t = t.filter(e => e.trainable), assert$4(t.length > 0, () => "variableGrads() expects at least one of the input variables to be trainable, but none of the ".concat(a, " variables is trainable."));
  var {
    value: s,
    grads: o
  } = ENGINE.gradients(e, t, null, !0);
  assert$4(o.some(e => null != e), () => "Cannot find a connection between any variable and the result of the loss function y=f(x). Please make sure the operations that use variables are inside the function f passed to minimize()."), assert$4(0 === s.rank, () => "The f passed in variableGrads(f) must return a scalar, but it returned a rank-".concat(s.rank, " tensor"));
  var i = {};
  return t.forEach((e, t) => {
    null != o[t] && (i[e.name] = o[t]);
  }), null != r && r.forEach(e => i[e.name] = null), {
    value: s,
    grads: i
  };
}

function customGrad(e) {
  return ENGINE.customGrad(e);
}

function checkGrads(e) {
  if (e.filter(e => null == e).length > 0) throw new Error("Cannot compute gradient of y=f(x) with respect to x. Make sure that\n    the f you passed encloses all operations that lead from x to y.");
}

function neg_(e) {
  var t = convertToTensor(e, "x", "neg");
  return ENGINE.runKernel(Neg, {
    x: t
  });
}

var neg$2 = op({
  neg_
});

function softplus_(e) {
  var t = convertToTensor(e, "x", "softplus");
  return ENGINE.runKernel(Softplus$1, {
    x: t
  });
}

var softplus$2 = op({
  softplus_
});

function logSigmoid_(e) {
  var t = convertToTensor(e, "x", "logSigmoid"),
      n = customGrad(e => ({
    value: neg$2(softplus$2(neg$2(e))),
    gradFunc: t => mul(t, sigmoid$2(neg$2(e)))
  }));
  return n(t);
}

var logSigmoid = op({
  logSigmoid_
});

function max_(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  var r = convertToTensor(e, "x", "max");
  return ENGINE.runKernel(Max, {
    x: r
  }, {
    reductionIndices: t,
    keepDims: n
  });
}

var max$3 = op({
  max_
});

function sub_(e, t) {
  var n = convertToTensor(e, "a", "sub"),
      r = convertToTensor(t, "b", "sub");
  return [n, r] = makeTypesMatch(n, r), ENGINE.runKernel(Sub, {
    a: n,
    b: r
  });
}

var sub$2 = op({
  sub_
});

function sum_(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  var r = convertToTensor(e, "x", "sum");
  return "bool" === r.dtype && (r = cast$3(r, "int32")), ENGINE.runKernel(Sum, {
    x: r
  }, {
    axis: t,
    keepDims: n
  });
}

var sum$2 = op({
  sum_
});

function logSoftmax_(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : -1;
  var n = convertToTensor(e, "logits", "logSoftmax");
  if (-1 === t && (t = n.rank - 1), t !== n.rank - 1) throw Error("Log Softmax along a non-last dimension is not yet supported. Logits was rank ".concat(n.rank, " and axis was ").concat(t));
  var r = customGrad((e, n) => {
    var r = max$3(e, t, !0),
        a = sub$2(e, r),
        s = sub$2(cast$3(a, "float32"), log$3(sum$2(exp$2(a), t, !0)));
    return n([s]), {
      value: s,
      gradFunc: (e, n) => {
        var [r] = n,
            a = exp$2(r);
        return sub$2(e, mul(sum$2(e, t, !0), a));
      }
    };
  });
  return r(n);
}

var logSoftmax = op({
  logSoftmax_
});

function axesAreInnerMostDims(e, t) {
  for (var n = 0; n < e.length; ++n) {
    if (e[e.length - n - 1] !== t - 1 - n) return !1;
  }

  return !0;
}

function combineLocations(e, t, n) {
  var r = e.length + t.length,
      a = [];
  var s = 0,
      o = 0;

  for (var i = 0; i < r; i++) {
    -1 === n.indexOf(i) ? a.push(e[s++]) : a.push(t[o++]);
  }

  return a;
}

function computeOutAndReduceShapes(e, t) {
  var n = [],
      r = e.length;

  for (var a = 0; a < r; a++) {
    -1 === t.indexOf(a) && n.push(e[a]);
  }

  return [n, t.map(t => e[t])];
}

function expandShapeToKeepDim(e, t) {
  return combineLocations(e, t.map(e => 1), t);
}

function assertAxesAreInnerMostDims(e, t, n) {
  assert$4(axesAreInnerMostDims(t, n), () => "".concat(e, " supports only inner-most axes for now. Got axes ").concat(t, " and rank-").concat(n, " input."));
}

function getAxesPermutation(e, t) {
  if (axesAreInnerMostDims(e, t)) return null;
  var n = [];

  for (var r = 0; r < t; ++r) {
    -1 === e.indexOf(r) && n.push(r);
  }

  return e.forEach(e => n.push(e)), n;
}

function getUndoAxesPermutation(e) {
  return e.map((e, t) => [t, e]).sort((e, t) => e[1] - t[1]).map(e => e[0]);
}

function getInnerMostAxes(e, t) {
  var n = [];

  for (var r = t - e; r < t; ++r) {
    n.push(r);
  }

  return n;
}

function logSumExp_(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  var r = convertToTensor(e, "x", "logSumExp"),
      a = parseAxisParam(t, r.shape),
      s = max$3(r, a, !0),
      o = sub$2(r, s),
      i = exp$2(o),
      l = sum$2(i, a),
      u = log$3(l),
      c = add$2(reshape$3(s, u.shape), u);

  if (n) {
    var _e581 = expandShapeToKeepDim(c.shape, a);

    return reshape$3(c, _e581);
  }

  return c;
}

var logSumExp = op({
  logSumExp_
});

function logicalAnd_(e, t) {
  var n = convertToTensor(e, "a", "logicalAnd", "bool"),
      r = convertToTensor(t, "b", "logicalAnd", "bool");
  return assertAndGetBroadcastShape(n.shape, r.shape), ENGINE.runKernel(LogicalAnd, {
    a: n,
    b: r
  });
}

var logicalAnd$2 = op({
  logicalAnd_
});

function logicalNot_(e) {
  var t = convertToTensor(e, "x", "logicalNot", "bool");
  return ENGINE.runKernel(LogicalNot, {
    x: t
  });
}

var logicalNot$2 = op({
  logicalNot_
});

function logicalOr_(e, t) {
  var n = convertToTensor(e, "a", "logicalOr", "bool"),
      r = convertToTensor(t, "b", "logicalOr", "bool");
  return assertAndGetBroadcastShape(n.shape, r.shape), ENGINE.runKernel(LogicalOr, {
    a: n,
    b: r
  });
}

var logicalOr$2 = op({
  logicalOr_
});

function logicalXor_(e, t) {
  var n = convertToTensor(e, "a", "logicalXor", "bool"),
      r = convertToTensor(t, "b", "logicalXor", "bool");
  return assertAndGetBroadcastShape(n.shape, r.shape), logicalAnd$2(logicalOr$2(e, t), logicalNot$2(logicalAnd$2(e, t)));
}

var logicalXor = op({
  logicalXor_
});

function maxPool_(e, t, n, r, a) {
  var s = convertToTensor(e, "x", "maxPool");
  var o = s,
      i = !1;
  3 === s.rank && (i = !0, o = reshape$3(s, [1, s.shape[0], s.shape[1], s.shape[2]])), assert$4(4 === o.rank, () => "Error in maxPool: input must be rank 4 but got rank ".concat(o.rank, ".")), assert$4(eitherStridesOrDilationsAreOne(n, 1), () => "Error in maxPool: Either strides or dilations must be 1. Got strides ".concat(n, " and dilations '1'")), null != a && assert$4(isInt(r), () => "Error in maxPool: pad must be an integer when using, dimRoundingMode ".concat(a, " but got pad ").concat(r, "."));
  var l = ENGINE.runKernel(MaxPool, {
    x: o
  }, {
    filterSize: t,
    strides: n,
    pad: r,
    dimRoundingMode: a
  });
  return i ? reshape$3(l, [l.shape[1], l.shape[2], l.shape[3]]) : l;
}

var maxPool$2 = op({
  maxPool_
});

function maxPool3d_(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : [1, 1, 1];
  var n = arguments.length > 2 ? arguments[2] : undefined;
  var r = arguments.length > 3 ? arguments[3] : undefined;
  var a = arguments.length > 4 ? arguments[4] : undefined;
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : "NDHWC";
  var o = convertToTensor(e, "x", "maxPool3d");
  var i = o,
      l = !1;
  4 === o.rank && (l = !0, i = reshape$3(o, [1, o.shape[0], o.shape[1], o.shape[2], o.shape[3]])), assert$4(5 === i.rank, () => "Error in maxPool3d: x must be rank 5 but got rank ".concat(i.rank, ".")), assert$4("NDHWC" === s, () => "Error in maxPool3d: Only NDHWC is currently supported, but got dataFormat of ".concat(s)), null != a && assert$4(isInt(r), () => "Error in maxPool3d: pad must be an integer when using, dimRoundingMode ".concat(a, " but got pad ").concat(r, "."));
  var u = ENGINE.runKernel(MaxPool3D, {
    x: i
  }, {
    filterSize: t,
    strides: n,
    pad: r,
    dimRoundingMode: a,
    dataFormat: s
  });
  return l ? reshape$3(u, [u.shape[1], u.shape[2], u.shape[3], u.shape[4]]) : u;
}

var maxPool3d$1 = op({
  maxPool3d_
});

function maxPoolWithArgmax_(e, t, n, r) {
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;
  var s = convertToTensor(e, "x", "maxPoolWithArgmax"),
      o = ENGINE.runKernel(MaxPoolWithArgmax, {
    x: s
  }, {
    filterSize: t,
    strides: n,
    pad: r,
    includeBatchInIndex: a
  });
  return {
    result: o[0],
    indexes: o[1]
  };
}

var maxPoolWithArgmax = op({
  maxPoolWithArgmax_
});

function maximum_(e, t) {
  var n = convertToTensor(e, "a", "maximum"),
      r = convertToTensor(t, "b", "maximum");
  return [n, r] = makeTypesMatch(n, r), "bool" === n.dtype && (n = cast$3(n, "int32"), r = cast$3(r, "int32")), assertAndGetBroadcastShape(n.shape, r.shape), ENGINE.runKernel(Maximum$1, {
    a: n,
    b: r
  });
}

var maximum$3 = op({
  maximum_
});

function mean_(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  var r = convertToTensor(e, "x", "mean");
  return ENGINE.runKernel(Mean, {
    x: r
  }, {
    axis: t,
    keepDims: n
  });
}

var mean$1 = op({
  mean_
});

function zeros$2(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : "float32";

  if ("complex64" === t) {
    var _t409 = zeros$2(e, "float32"),
        _n231 = zeros$2(e, "float32");

    return complex$2(_t409, _n231);
  }

  var n = makeZerosTypedArray(sizeFromShape(e), t);
  return ENGINE.makeTensor(n, e, t);
}

function ones$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : "float32";

  if ("complex64" === t) {
    var _t410 = ones$1(e, "float32"),
        _n232 = zeros$2(e, "float32");

    return complex$2(_t410, _n232);
  }

  var n = makeOnesTypedArray(sizeFromShape(e), t);
  return ENGINE.makeTensor(n, e, t);
}

function meshgrid(e, t) {
  var {
    indexing: n = "xy"
  } = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};
  if ("xy" !== n && "ij" !== n) throw new TypeError("".concat(n, " is not a valid third argument to meshgrid"));
  if (void 0 === e) return [];
  var r = convertToTensor(e, "x", "meshgrid", e instanceof Tensor ? e.dtype : "float32");
  if (void 0 === t) return [r];
  var a = convertToTensor(t, "y", "meshgrid", t instanceof Tensor ? t.dtype : "float32");
  var s = sizeFromShape(r.shape),
      o = sizeFromShape(a.shape);
  return "xy" === n ? (r = reshape$3(r, [1, -1]), a = reshape$3(a, [-1, 1]), [matMul$1(ones$1([o, 1], r.dtype), r), matMul$1(a, ones$1([1, s], a.dtype))]) : (r = reshape$3(r, [-1, 1]), a = reshape$3(a, [1, -1]), [matMul$1(r, ones$1([1, o], r.dtype)), matMul$1(ones$1([s, 1], a.dtype), a)]);
}

function min_(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  var r = convertToTensor(e, "x", "min");
  return ENGINE.runKernel(Min, {
    x: r
  }, {
    axis: t,
    keepDims: n
  });
}

var min$3 = op({
  min_
});

function minimum_(e, t) {
  var n = convertToTensor(e, "a", "minimum"),
      r = convertToTensor(t, "b", "minimum");
  return [n, r] = makeTypesMatch(n, r), "bool" === n.dtype && (n = cast$3(n, "int32"), r = cast$3(r, "int32")), assertAndGetBroadcastShape(n.shape, r.shape), ENGINE.runKernel(Minimum$1, {
    a: n,
    b: r
  });
}

var minimum$3 = op({
  minimum_
});

function mirrorPad_(e, t, n) {
  assert$4("reflect" === n || "symmetric" === n, () => "Invalid mode. Mode must be either reflect or symmetric. Got ".concat(n, "."));
  var r = convertToTensor(e, "x", "mirrorPad");
  if (0 === r.rank) throw new Error("mirrorPad(scalar) is not defined. Pass non-scalar to mirrorPad");
  assert$4(t.length === r.rank, () => "Padding doesn't match input. Must be ".concat(r.rank, ". Got ").concat(t.length, "."));
  var a = "reflect" === n ? 1 : 0;

  var _loop32 = function _loop32(_e582) {
    assert$4(2 === t[_e582].length, () => "Invalid number of paddings. Must be length of 2 each."), assert$4(t[_e582][0] >= 0 && t[_e582][0] <= r.shape[_e582] - a && t[_e582][1] >= 0 && t[_e582][1] <= r.shape[_e582] - a, () => "Padding in dimension ".concat(_e582, " cannot be greater than or equal to ").concat(r.shape[_e582] - a, " or less than 0 for input of shape ").concat(r.shape));
  };

  for (var _e582 = 0; _e582 < r.rank; _e582++) {
    _loop32(_e582);
  }

  return ENGINE.runKernel(MirrorPad, {
    x: r
  }, {
    paddings: t,
    mode: n
  });
}

var mirrorPad$1 = op({
  mirrorPad_
});

function mod_(e, t) {
  var n = convertToTensor(e, "a", "mod"),
      r = convertToTensor(t, "b", "mod");
  return [n, r] = makeTypesMatch(n, r), ENGINE.runKernel(Mod, {
    a: n,
    b: r
  });
}

var mod$2 = op({
  mod_
});

function square_(e) {
  var t = convertToTensor(e, "x", "square");
  return ENGINE.runKernel("Square", {
    x: t
  }, {});
}

var square$2 = op({
  square_
});

function moments_(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  var r = parseAxisParam(t, (e = convertToTensor(e, "x", "moments")).shape),
      a = mean$1(e, r, n);
  var s = a.shape;
  n || (s = expandShapeToKeepDim(a.shape, r));
  var o = square$2(sub$2(cast$3(e, "float32"), reshape$3(a, s)));
  return {
    mean: a,
    variance: mean$1(o, r, n)
  };
}

var moments = op({
  moments_
});

function multiRNNCell_(e, t, n, r) {
  var a = convertToTensor(t, "data", "multiRNNCell"),
      s = convertToTensorArray(n, "c", "multiRNNCell"),
      o = convertToTensorArray(r, "h", "multiRNNCell");
  var i = a;
  var l = [];

  for (var _t411 = 0; _t411 < e.length; _t411++) {
    var _n233 = e[_t411](i, s[_t411], o[_t411]);

    l.push(_n233[0]), l.push(_n233[1]), i = _n233[1];
  }

  var u = [],
      c = [];

  for (var _e583 = 0; _e583 < l.length; _e583 += 2) {
    u.push(l[_e583]), c.push(l[_e583 + 1]);
  }

  return [u, c];
}

var multiRNNCell = op({
  multiRNNCell_
});

function multinomial_(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
  var a = convertToTensor(e, "logits", "multinomial"),
      s = a.size,
      o = a.rank;
  if (s < 2) throw new Error("Error in multinomial: you need at least 2 outcomes, but got ".concat(s, "."));
  if (o > 2) throw new Error("Rank of probabilities must be 1 or 2, but is ".concat(o));
  n = n || Math.random();
  var i = 1 === o ? reshape$3(a, [1, -1]) : a,
      l = ENGINE.runKernel(Multinomial, {
    logits: i
  }, {
    numSamples: t,
    seed: n,
    normalized: r
  });
  return 1 === o ? reshape$3(l, [l.size]) : l;
}

var multinomial$2 = op({
  multinomial_
});

function notEqual_(e, t) {
  var n = convertToTensor(e, "a", "notEqual", "string_or_numeric"),
      r = convertToTensor(t, "b", "notEqual", "string_or_numeric");
  return [n, r] = makeTypesMatch(n, r), assertAndGetBroadcastShape(n.shape, r.shape), ENGINE.runKernel(NotEqual, {
    a: n,
    b: r
  });
}

var notEqual$2 = op({
  notEqual_
});

function onesLike_(e) {
  var t = convertToTensor(e, "x", "onesLike");
  return ENGINE.runKernel(OnesLike, {
    x: t
  });
}

var onesLike$2 = op({
  onesLike_
});

function outerProduct_(e, t) {
  var n = convertToTensor(e, "v1", "outerProduct"),
      r = convertToTensor(t, "v2", "outerProduct");
  assert$4(1 === n.rank && 1 === r.rank, () => "Error in outerProduct: inputs must be rank 1, but got ranks ".concat(n.rank, " and ").concat(r.rank, "."));
  var a = reshape$3(n, [-1, 1]),
      s = reshape$3(r, [1, -1]);
  return matMul$1(a, s);
}

var outerProduct = op({
  outerProduct_
});

function pad_(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;
  var r = convertToTensor(e, "x", "pad");
  if (0 === r.rank) throw new Error("pad(scalar) is not defined. Pass non-scalar to pad");
  return ENGINE.runKernel(PadV2, {
    x: r
  }, {
    paddings: t,
    constantValue: n
  });
}

var pad = op({
  pad_
});

function pad1d_(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;
  return assert$4(2 === t.length, () => "Invalid number of paddings. Must be length of 2."), pad(e, [t], n);
}

var pad1d = op({
  pad1d_
});

function pad2d_(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;
  return assert$4(2 === t.length && 2 === t[0].length && 2 === t[1].length, () => "Invalid number of paddings. Must be length of 2 each."), pad(e, t, n);
}

var pad2d = op({
  pad2d_
});

function pad3d_(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;
  return assert$4(3 === t.length && 2 === t[0].length && 2 === t[1].length && 2 === t[2].length, () => "Invalid number of paddings. Must be length of 2 each."), pad(e, t, n);
}

var pad3d = op({
  pad3d_
});

function pad4d_(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;
  return assert$4(4 === t.length && 2 === t[0].length && 2 === t[1].length && 2 === t[2].length && 2 === t[3].length, () => "Invalid number of paddings. Must be length of 2 each."), pad(e, t, n);
}

var pad4d = op({
  pad4d_
});

function spaceToBatchND_(e, t, n) {
  var r = convertToTensor(e, "x", "spaceToBatchND");
  return assert$4(r.rank >= 1 + t.length, () => "input rank ".concat(r.rank, " should be > than [blockShape] ").concat(t.length)), assert$4(n.length === t.length, () => "paddings.shape[0] ".concat(n.length, " must be equal to [blockShape] ").concat(t.length)), assert$4(r.shape.reduce((e, r, a) => a > 0 && a <= t.length ? e && (r + n[a - 1][0] + n[a - 1][1]) % t[a - 1] == 0 : e, !0), () => "input spatial dimensions ".concat(r.shape.slice(1), " with paddings ").concat(n.toString(), " must be divisible by blockShapes ").concat(t.toString())), ENGINE.runKernel(SpaceToBatchND, {
    x: r
  }, {
    blockShape: t,
    paddings: n
  });
}

var spaceToBatchND$2 = op({
  spaceToBatchND_
});

function pool_(e, t, n, r, a, s) {
  null == a && (a = [1, 1]), null == s && (s = 1), 0 === r && (r = "valid");
  var o = convertToTensor(e, "x", "maxPool");
  var i = o,
      l = !1;
  3 === o.rank && (l = !0, i = reshape$3(o, [1, o.shape[0], o.shape[1], o.shape[2]])), assert$4(eitherStridesOrDilationsAreOne(s, a), () => "Error in pool: Either strides or dilations must be 1. Got strides ".concat(s, " and dilations '").concat(a, "'"));
  var u = computePool2DInfo(i.shape, t, s, a, r),
      c = [u.dilationHeight, u.dilationWidth];
  var p;
  p = "same" === r ? withSpaceToBatchBasePaddings([u.filterHeight, u.filterWidth], c) : [[0, 0], [0, 0]];
  var d = 1 === c[0] && 1 === c[1],
      [h, m] = requiredSpaceToBatchPaddings([u.inHeight, u.inWidth], c, p),
      f = d ? r : "valid",
      g = d ? i : spaceToBatchND$2(i, c, h),
      $ = ("avg" === n ? () => avgPool$2(g, t, s, f) : () => maxPool$2(g, t, s, f))(),
      y = d ? $ : batchToSpaceND$2($, c, m);
  return l ? reshape$3(y, [y.shape[1], y.shape[2], y.shape[3]]) : y;
}

function requiredSpaceToBatchPaddings(e, t, n) {
  var r = n.map(e => e[0]),
      a = n.map(e => e[1]),
      s = e.concat(r, a),
      o = t.map((e, t) => (e - s[t] % e) % e),
      i = a.map((e, t) => e + o[t]);
  return [t.map((e, t) => [r[t], i[t]]), t.map((e, t) => [0, o[t]])];
}

function withSpaceToBatchBasePaddings(e, t) {
  var n = e.map((e, n) => e + (e - 1) * (t[n] - 1)).map(e => e - 1),
      r = n.map(e => Math.floor(e / 2)),
      a = n.map((e, t) => e - r[t]);
  return n.map((e, t) => [r[t], a[t]]);
}

var pool$1 = op({
  pool_
});

function pow_(e, t) {
  var n = convertToTensor(e, "base", "pow"),
      r = convertToTensor(t, "exp", "pow");
  return [n, r] = makeTypesMatch(n, r), ENGINE.runKernel(Pow, {
    a: n,
    b: r
  });
}

var pow$2 = op({
  pow_
});

function prelu_(e, t) {
  var n = convertToTensor(e, "x", "prelu"),
      r = convertToTensor(t, "alpha", "prelu");
  return ENGINE.runKernel(Prelu, {
    x: n,
    alpha: r
  });
}

var prelu$3 = op({
  prelu_
});

function prod_(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  var r = convertToTensor(e, "x", "prod");
  return "bool" === r.dtype && (r = cast$3(r, "int32")), ENGINE.runKernel(Prod, {
    x: r
  }, {
    axis: t,
    keepDims: n
  });
}

var prod$2 = op({
  prod_
});

function rand_(e, t, n) {
  var r = sizeFromShape(e);
  var a = null;
  if (null == n || "float32" === n) a = new Float32Array(r);else if ("int32" === n) a = new Int32Array(r);else {
    if ("bool" !== n) throw new Error("Unknown data type ".concat(n));
    a = new Uint8Array(r);
  }

  for (var _e584 = 0; _e584 < r; _e584++) {
    a[_e584] = t();
  }

  return ENGINE.makeTensor(a, e, n);
}

var rand = op({
  rand_
});
var alea = createCommonjsModule(function (e) {
  !function (e, t, n) {
    function r(e) {
      var t,
          n = this,
          r = (t = 4022871197, function (e) {
        e = e.toString();

        for (var n = 0; n < e.length; n++) {
          var r = .02519603282416938 * (t += e.charCodeAt(n));
          r -= t = r >>> 0, t = (r *= t) >>> 0, t += 4294967296 * (r -= t);
        }

        return 2.3283064365386963e-10 * (t >>> 0);
      });
      n.next = function () {
        var e = 2091639 * n.s0 + 2.3283064365386963e-10 * n.c;
        return n.s0 = n.s1, n.s1 = n.s2, n.s2 = e - (n.c = 0 | e);
      }, n.c = 1, n.s0 = r(" "), n.s1 = r(" "), n.s2 = r(" "), n.s0 -= r(e), n.s0 < 0 && (n.s0 += 1), n.s1 -= r(e), n.s1 < 0 && (n.s1 += 1), n.s2 -= r(e), n.s2 < 0 && (n.s2 += 1), r = null;
    }

    function a(e, t) {
      return t.c = e.c, t.s0 = e.s0, t.s1 = e.s1, t.s2 = e.s2, t;
    }

    function s(e, t) {
      var n = new r(e),
          s = t && t.state,
          o = n.next;
      return o.int32 = function () {
        return 4294967296 * n.next() | 0;
      }, o.double = function () {
        return o() + 11102230246251565e-32 * (2097152 * o() | 0);
      }, o.quick = o, s && ("object" == typeof s && a(s, n), o.state = function () {
        return a(n, {});
      }), o;
    }

    t && t.exports ? t.exports = s : this.alea = s;
  }(0, e);
}),
    xor128 = createCommonjsModule(function (e) {
  !function (e, t, n) {
    function r(e) {
      var t = this,
          n = "";
      t.x = 0, t.y = 0, t.z = 0, t.w = 0, t.next = function () {
        var e = t.x ^ t.x << 11;
        return t.x = t.y, t.y = t.z, t.z = t.w, t.w ^= t.w >>> 19 ^ e ^ e >>> 8;
      }, e === (0 | e) ? t.x = e : n += e;

      for (var r = 0; r < n.length + 64; r++) {
        t.x ^= 0 | n.charCodeAt(r), t.next();
      }
    }

    function a(e, t) {
      return t.x = e.x, t.y = e.y, t.z = e.z, t.w = e.w, t;
    }

    function s(e, t) {
      var n = new r(e),
          s = t && t.state,
          o = function o() {
        return (n.next() >>> 0) / 4294967296;
      };

      return o.double = function () {
        do {
          var e = ((n.next() >>> 11) + (n.next() >>> 0) / 4294967296) / (1 << 21);
        } while (0 === e);

        return e;
      }, o.int32 = n.next, o.quick = o, s && ("object" == typeof s && a(s, n), o.state = function () {
        return a(n, {});
      }), o;
    }

    t && t.exports ? t.exports = s : this.xor128 = s;
  }(0, e);
}),
    xorwow = createCommonjsModule(function (e) {
  !function (e, t, n) {
    function r(e) {
      var t = this,
          n = "";
      t.next = function () {
        var e = t.x ^ t.x >>> 2;
        return t.x = t.y, t.y = t.z, t.z = t.w, t.w = t.v, (t.d = t.d + 362437 | 0) + (t.v = t.v ^ t.v << 4 ^ e ^ e << 1) | 0;
      }, t.x = 0, t.y = 0, t.z = 0, t.w = 0, t.v = 0, e === (0 | e) ? t.x = e : n += e;

      for (var r = 0; r < n.length + 64; r++) {
        t.x ^= 0 | n.charCodeAt(r), r == n.length && (t.d = t.x << 10 ^ t.x >>> 4), t.next();
      }
    }

    function a(e, t) {
      return t.x = e.x, t.y = e.y, t.z = e.z, t.w = e.w, t.v = e.v, t.d = e.d, t;
    }

    function s(e, t) {
      var n = new r(e),
          s = t && t.state,
          o = function o() {
        return (n.next() >>> 0) / 4294967296;
      };

      return o.double = function () {
        do {
          var e = ((n.next() >>> 11) + (n.next() >>> 0) / 4294967296) / (1 << 21);
        } while (0 === e);

        return e;
      }, o.int32 = n.next, o.quick = o, s && ("object" == typeof s && a(s, n), o.state = function () {
        return a(n, {});
      }), o;
    }

    t && t.exports ? t.exports = s : this.xorwow = s;
  }(0, e);
}),
    xorshift7 = createCommonjsModule(function (e) {
  !function (e, t, n) {
    function r(e) {
      var t = this;
      t.next = function () {
        var e,
            n,
            r = t.x,
            a = t.i;
        return e = r[a], n = (e ^= e >>> 7) ^ e << 24, n ^= (e = r[a + 1 & 7]) ^ e >>> 10, n ^= (e = r[a + 3 & 7]) ^ e >>> 3, n ^= (e = r[a + 4 & 7]) ^ e << 7, e = r[a + 7 & 7], r[a] = n ^= (e ^= e << 13) ^ e << 9, t.i = a + 1 & 7, n;
      }, function (e, t) {
        var n,
            r = [];
        if (t === (0 | t)) r[0] = t;else for (t = "" + t, n = 0; n < t.length; ++n) {
          r[7 & n] = r[7 & n] << 15 ^ t.charCodeAt(n) + r[n + 1 & 7] << 13;
        }

        for (; r.length < 8;) {
          r.push(0);
        }

        for (n = 0; n < 8 && 0 === r[n]; ++n) {
          ;
        }

        for (8 == n && (r[7] = -1), e.x = r, e.i = 0, n = 256; n > 0; --n) {
          e.next();
        }
      }(t, e);
    }

    function a(e, t) {
      return t.x = e.x.slice(), t.i = e.i, t;
    }

    function s(e, t) {
      null == e && (e = +new Date());

      var n = new r(e),
          s = t && t.state,
          o = function o() {
        return (n.next() >>> 0) / 4294967296;
      };

      return o.double = function () {
        do {
          var e = ((n.next() >>> 11) + (n.next() >>> 0) / 4294967296) / (1 << 21);
        } while (0 === e);

        return e;
      }, o.int32 = n.next, o.quick = o, s && (s.x && a(s, n), o.state = function () {
        return a(n, {});
      }), o;
    }

    t && t.exports ? t.exports = s : this.xorshift7 = s;
  }(0, e);
}),
    xor4096 = createCommonjsModule(function (e) {
  !function (e, t, n) {
    function r(e) {
      var t = this;
      t.next = function () {
        var e,
            n,
            r = t.w,
            a = t.X,
            s = t.i;
        return t.w = r = r + 1640531527 | 0, n = a[s + 34 & 127], e = a[s = s + 1 & 127], n ^= n << 13, e ^= e << 17, n = a[s] = (n ^= n >>> 15) ^ (e ^= e >>> 12), t.i = s, n + (r ^ r >>> 16) | 0;
      }, function (e, t) {
        var n,
            r,
            a,
            s,
            o,
            i = [],
            l = 128;

        for (t === (0 | t) ? (r = t, t = null) : (t += "\0", r = 0, l = Math.max(l, t.length)), a = 0, s = -32; s < l; ++s) {
          t && (r ^= t.charCodeAt((s + 32) % t.length)), 0 === s && (o = r), r ^= r << 10, r ^= r >>> 15, r ^= r << 4, r ^= r >>> 13, s >= 0 && (a = 0 == (n = i[127 & s] ^= r + (o = o + 1640531527 | 0)) ? a + 1 : 0);
        }

        for (a >= 128 && (i[127 & (t && t.length || 0)] = -1), a = 127, s = 512; s > 0; --s) {
          r = i[a + 34 & 127], n = i[a = a + 1 & 127], r ^= r << 13, n ^= n << 17, i[a] = (r ^= r >>> 15) ^ (n ^= n >>> 12);
        }

        e.w = o, e.X = i, e.i = a;
      }(t, e);
    }

    function a(e, t) {
      return t.i = e.i, t.w = e.w, t.X = e.X.slice(), t;
    }

    function s(e, t) {
      null == e && (e = +new Date());

      var n = new r(e),
          s = t && t.state,
          o = function o() {
        return (n.next() >>> 0) / 4294967296;
      };

      return o.double = function () {
        do {
          var e = ((n.next() >>> 11) + (n.next() >>> 0) / 4294967296) / (1 << 21);
        } while (0 === e);

        return e;
      }, o.int32 = n.next, o.quick = o, s && (s.X && a(s, n), o.state = function () {
        return a(n, {});
      }), o;
    }

    t && t.exports ? t.exports = s : this.xor4096 = s;
  }(0, e);
}),
    tychei = createCommonjsModule(function (e) {
  !function (e, t, n) {
    function r(e) {
      var t = this,
          n = "";
      t.next = function () {
        var e = t.b,
            n = t.c,
            r = t.d,
            a = t.a;
        return e = e << 25 ^ e >>> 7 ^ n, n = n - r | 0, r = r << 24 ^ r >>> 8 ^ a, a = a - e | 0, t.b = e = e << 20 ^ e >>> 12 ^ n, t.c = n = n - r | 0, t.d = r << 16 ^ n >>> 16 ^ a, t.a = a - e | 0;
      }, t.a = 0, t.b = 0, t.c = -1640531527, t.d = 1367130551, e === Math.floor(e) ? (t.a = e / 4294967296 | 0, t.b = 0 | e) : n += e;

      for (var r = 0; r < n.length + 20; r++) {
        t.b ^= 0 | n.charCodeAt(r), t.next();
      }
    }

    function a(e, t) {
      return t.a = e.a, t.b = e.b, t.c = e.c, t.d = e.d, t;
    }

    function s(e, t) {
      var n = new r(e),
          s = t && t.state,
          o = function o() {
        return (n.next() >>> 0) / 4294967296;
      };

      return o.double = function () {
        do {
          var e = ((n.next() >>> 11) + (n.next() >>> 0) / 4294967296) / (1 << 21);
        } while (0 === e);

        return e;
      }, o.int32 = n.next, o.quick = o, s && ("object" == typeof s && a(s, n), o.state = function () {
        return a(n, {});
      }), o;
    }

    t && t.exports ? t.exports = s : this.tychei = s;
  }(0, e);
}),
    seedrandom$1 = createCommonjsModule(function (e) {
  !function (t, n) {
    var r,
        a = this,
        s = 256,
        o = n.pow(s, 6),
        i = n.pow(2, 52),
        l = 2 * i,
        u = 255;

    function c(e, u, c) {
      var g = [],
          $ = m(h((u = 1 == u ? {
        entropy: !0
      } : u || {}).entropy ? [e, f(t)] : null == e ? function () {
        try {
          var e;
          return r && (e = r.randomBytes) ? e = e(s) : (e = new Uint8Array(s), (a.crypto || a.msCrypto).getRandomValues(e)), f(e);
        } catch (e) {
          var n = a.navigator,
              o = n && n.plugins;
          return [+new Date(), a, o, a.screen, f(t)];
        }
      }() : e, 3), g),
          y = new p(g),
          b = function b() {
        for (var e = y.g(6), t = o, n = 0; e < i;) {
          e = (e + n) * s, t *= s, n = y.g(1);
        }

        for (; e >= l;) {
          e /= 2, t /= 2, n >>>= 1;
        }

        return (e + n) / t;
      };

      return b.int32 = function () {
        return 0 | y.g(4);
      }, b.quick = function () {
        return y.g(4) / 4294967296;
      }, b.double = b, m(f(y.S), t), (u.pass || c || function (e, t, r, a) {
        return a && (a.S && d(a, y), e.state = function () {
          return d(y, {});
        }), r ? (n.random = e, t) : e;
      })(b, $, "global" in u ? u.global : this == n, u.state);
    }

    function p(e) {
      var t,
          n = e.length,
          r = this,
          a = 0,
          o = r.i = r.j = 0,
          i = r.S = [];

      for (n || (e = [n++]); a < s;) {
        i[a] = a++;
      }

      for (a = 0; a < s; a++) {
        i[a] = i[o = u & o + e[a % n] + (t = i[a])], i[o] = t;
      }

      (r.g = function (e) {
        for (var t, n = 0, a = r.i, o = r.j, i = r.S; e--;) {
          t = i[a = u & a + 1], n = n * s + i[u & (i[a] = i[o = u & o + t]) + (i[o] = t)];
        }

        return r.i = a, r.j = o, n;
      })(s);
    }

    function d(e, t) {
      return t.i = e.i, t.j = e.j, t.S = e.S.slice(), t;
    }

    function h(e, t) {
      var n,
          r = [],
          a = typeof e;
      if (t && "object" == a) for (n in e) {
        try {
          r.push(h(e[n], t - 1));
        } catch (e) {}
      }
      return r.length ? r : "string" == a ? e : e + "\0";
    }

    function m(e, t) {
      for (var n, r = e + "", a = 0; a < r.length;) {
        t[u & a] = u & (n ^= 19 * t[u & a]) + r.charCodeAt(a++);
      }

      return f(t);
    }

    function f(e) {
      return String.fromCharCode.apply(0, e);
    }

    if (n.seedrandom = c, m(n.random(), t), e.exports) {
      e.exports = c;

      try {
        r = _nodeResolve_empty$1;
      } catch (e) {}
    }
  }([], Math);
});
seedrandom$1.alea = alea, seedrandom$1.xor128 = xor128, seedrandom$1.xorwow = xorwow, seedrandom$1.xorshift7 = xorshift7, seedrandom$1.xor4096 = xor4096, seedrandom$1.tychei = tychei;
var seedrandom = seedrandom$1;

class MPRandGauss {
  constructor(e, t, n, r, a) {
    this.mean = e, this.stdDev = t, this.dtype = n, this.nextVal = NaN, this.truncated = r, this.truncated && (this.upper = this.mean + 2 * this.stdDev, this.lower = this.mean - 2 * this.stdDev);
    var s = a || Math.random();
    this.random = seedrandom.alea(s.toString());
  }

  nextValue() {
    if (!isNaN(this.nextVal)) {
      var _e585 = this.nextVal;
      return this.nextVal = NaN, _e585;
    }

    var e,
        t,
        n = !1;

    for (; !n;) {
      var r = void 0,
          a = void 0,
          s = void 0;

      do {
        r = 2 * this.random() - 1, a = 2 * this.random() - 1, s = r * r + a * a;
      } while (s >= 1 || 0 === s);

      var o = Math.sqrt(-2 * Math.log(s) / s);
      e = this.mean + this.stdDev * r * o, t = this.mean + this.stdDev * a * o, this.truncated && !this.isValidTruncated(e) || (n = !0);
    }

    return this.truncated && !this.isValidTruncated(t) || (this.nextVal = this.convertValue(t)), this.convertValue(e);
  }

  convertValue(e) {
    return null == this.dtype || "float32" === this.dtype ? e : Math.round(e);
  }

  isValidTruncated(e) {
    return e <= this.upper && e >= this.lower;
  }

}

class RandGamma {
  constructor(e, t, n, r) {
    this.alpha = e, this.beta = 1 / t, this.dtype = n;
    var a = r || Math.random();
    this.randu = seedrandom.alea(a.toString()), this.randn = new MPRandGauss(0, 1, n, !1, this.randu()), this.d = e < 1 ? e + 2 / 3 : e - 1 / 3, this.c = 1 / Math.sqrt(9 * this.d);
  }

  nextValue() {
    var e, t, n, r, a, s;

    for (;;) {
      do {
        r = this.randn.nextValue(), s = 1 + this.c * r;
      } while (s <= 0);

      if (s *= s * s, e = r * r, t = 1 - .331 * e * e, n = .5 * e + this.d * (1 - s + Math.log(s)), a = this.randu(), a < t || Math.log(a) < n) break;
    }

    return s *= 1 / this.beta * this.d, this.alpha < 1 && (s *= Math.pow(this.randu(), 1 / this.alpha)), this.convertValue(s);
  }

  convertValue(e) {
    return "float32" === this.dtype ? e : Math.round(e);
  }

}

class UniformRandom {
  constructor() {
    var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : 0;
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 1;
    var n = arguments.length > 2 ? arguments[2] : undefined;
    var r = arguments.length > 3 ? arguments[3] : undefined;
    if (this.canReturnFloat = () => null == this.dtype || "float32" === this.dtype, this.min = e, this.range = t - e, this.dtype = n, null == r && (r = Math.random()), "number" == typeof r && (r = r.toString()), !this.canReturnFloat() && this.range <= 1) throw new Error("The difference between ".concat(e, " - ").concat(t, " <= 1 and dtype is not float"));
    this.random = seedrandom.alea(r);
  }

  convertValue(e) {
    return this.canReturnFloat() ? e : Math.round(e);
  }

  nextValue() {
    return this.convertValue(this.min + this.range * this.random());
  }

}

function randomGamma_(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 1;
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : "float32";
  var a = arguments.length > 4 ? arguments[4] : undefined;
  if (null == n && (n = 1), null == r && (r = "float32"), "float32" !== r && "int32" !== r) throw new Error("Unsupported data type ".concat(r));
  var s = new RandGamma(t, n, r, a),
      o = buffer(e, r);

  for (var _e586 = 0; _e586 < o.values.length; _e586++) {
    o.values[_e586] = s.nextValue();
  }

  return o.toTensor();
}

var randomGamma = op({
  randomGamma_
});

function randomNormal_(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 1;
  var r = arguments.length > 3 ? arguments[3] : undefined;
  var a = arguments.length > 4 ? arguments[4] : undefined;
  if (null != r && "bool" === r) throw new Error("Unsupported data type ".concat(r));
  var s = new MPRandGauss(t, n, r, !1, a),
      o = buffer(e, r);

  for (var _e587 = 0; _e587 < o.values.length; _e587++) {
    o.values[_e587] = s.nextValue();
  }

  return o.toTensor();
}

var randomNormal$2 = op({
  randomNormal_
});

function randomUniform_(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 1;
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : "float32";
  var a = arguments.length > 4 ? arguments[4] : undefined;
  var s = buffer(e, r),
      o = new UniformRandom(t, n, null, a);

  for (var _e588 = 0; _e588 < s.values.length; _e588++) {
    s.values[_e588] = o.nextValue();
  }

  return s.toTensor();
}

var randomUniform$1 = op({
  randomUniform_
});

function range$4(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 1;
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : "float32";
  if (0 === n) throw new Error("Cannot have a step of zero");
  return ENGINE.runKernel(Range, {}, {
    start: e,
    stop: t,
    step: n,
    dtype: r
  });
}

function real_(e) {
  var t = convertToTensor(e, "input", "real");
  return ENGINE.runKernel(Real, {
    input: t
  });
}

var real$2 = op({
  real_
});

function reciprocal_(e) {
  var t = convertToTensor(e, "x", "reciprocal");
  return ENGINE.runKernel(Reciprocal, {
    x: t
  });
}

var reciprocal$2 = op({
  reciprocal_
});

function relu_(e) {
  var t = convertToTensor(e, "x", "relu");
  return ENGINE.runKernel(Relu$1, {
    x: t
  });
}

var relu$3 = op({
  relu_
});

function relu6_(e) {
  var t = convertToTensor(e, "x", "relu6");
  return ENGINE.runKernel(Relu6$1, {
    x: t
  });
}

var relu6$2 = op({
  relu6_
});

function reverse_(e, t) {
  var n = convertToTensor(e, "x", "reverse");
  return ENGINE.runKernel(Reverse, {
    x: n
  }, {
    dims: t
  });
}

var reverse$2 = op({
  reverse_
});

function reverse1d_(e) {
  var t = convertToTensor(e, "x", "reverse");
  return assert$4(1 === t.rank, () => "Error in reverse1D: x must be rank 1 but got rank ".concat(t.rank, ".")), reverse$2(t, 0);
}

var reverse1d = op({
  reverse1d_
});

function reverse2d_(e, t) {
  var n = convertToTensor(e, "x", "reverse");
  return assert$4(2 === n.rank, () => "Error in reverse2D: x must be rank 2 but got rank ".concat(n.rank, ".")), reverse$2(n, t);
}

var reverse2d = op({
  reverse2d_
});

function reverse3d_(e, t) {
  var n = convertToTensor(e, "x", "reverse");
  return assert$4(3 === n.rank, () => "Error in reverse3D: x must be rank 3 but got rank ".concat(n.rank, ".")), reverse$2(n, t);
}

var reverse3d = op({
  reverse3d_
});

function reverse4d_(e, t) {
  var n = convertToTensor(e, "x", "reverse");
  return assert$4(4 === n.rank, () => "Error in reverse4D: x must be rank 4 but got rank ".concat(n.rank, ".")), reverse$2(n, t);
}

var reverse4d = op({
  reverse4d_
});

function round_(e) {
  var t = convertToTensor(e, "x", "round");
  return ENGINE.runKernel(Round, {
    x: t
  });
}

var round$2 = op({
  round_
});

function rsqrt_(e) {
  var t = convertToTensor(e, "x", "rsqrt");
  return ENGINE.runKernel(Rsqrt, {
    x: t
  });
}

var rsqrt$2 = op({
  rsqrt_
});

function scalar(e, t) {
  if ((isTypedArray(e) && "string" !== t || Array.isArray(e)) && "complex64" !== t) throw new Error("Error creating a new Scalar: value must be a primitive (number|boolean|string)");
  if ("string" === t && isTypedArray(e) && !(e instanceof Uint8Array)) throw new Error("When making a scalar from encoded string, the value must be `Uint8Array`.");
  return makeTensor(e, [], [], t);
}

function selu_(e) {
  var t = convertToTensor(e, "x", "selu");
  return ENGINE.runKernel(Selu$1, {
    x: t
  });
}

var selu$2 = op({
  selu_
});

function separableConv2d_(e, t, n, r, a) {
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : [1, 1];
  var o = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : "NHWC";
  var i = convertToTensor(e, "x", "separableConv2d"),
      l = convertToTensor(t, "depthwiseFilter", "separableConv2d"),
      u = convertToTensor(n, "pointwiseFilter", "separableConv2d");
  var c = i,
      p = !1;
  if (3 === i.rank && (p = !0, c = reshape$3(i, [1, i.shape[0], i.shape[1], i.shape[2]])), "NCHW" === o) throw new Error("separableConv2d currently does not support dataFormat NCHW; only NHWC is supported");
  assert$4(4 === c.rank, () => "Error in separableConv2d: input must be rank 4, but got rank ".concat(c.rank, ".")), assert$4(4 === l.rank, () => "Error in separableConv2d: depthwise filter must be rank 4, but got rank ".concat(l.rank, ".")), assert$4(4 === u.rank, () => "Error in separableConv2d: pointwise filter must be rank 4, but got rank ".concat(l.rank, ".")), assert$4(1 === u.shape[0], () => "Error in separableConv2d: the first dimension of pointwise filter  must be 1, but got ".concat(u.shape[0], ".")), assert$4(1 === u.shape[1], () => "Error in separableConv2d: the second dimension of pointwise filter must be 1, but got ".concat(u.shape[1], "."));
  var d = l.shape[2],
      h = l.shape[3];
  assert$4(u.shape[2] === d * h, () => "Error in separableConv2d: the third dimension of pointwise filter must be ".concat(d * h, ", but got ").concat(u.shape[2], "."));
  var m = depthwiseConv2d$3(c, l, r, a, o, s),
      f = conv2d$3(m, u, 1, "valid", o);
  return p ? reshape$3(f, [f.shape[1], f.shape[2], f.shape[3]]) : f;
}

var separableConv2d$1 = op({
  separableConv2d_
});

function setdiff1dAsync_(_x69, _x70) {
  return _setdiff1dAsync_.apply(this, arguments);
}

function _setdiff1dAsync_() {
  _setdiff1dAsync_ = _asyncToGenerator(function* (e, t) {
    var n = convertToTensor(e, "x", "setdiff1d"),
        r = convertToTensor(t, "y", "setdiff1d");
    assert$4(n.dtype === r.dtype, () => "x and y should have the same dtype, but got x (".concat(n.dtype, ") and y (").concat(r.dtype, ").")), assert$4(1 === n.rank, () => "x should be 1D tensor, but got x (".concat(n.shape, ").")), assert$4(1 === r.rank, () => "y should be 1D tensor, but got y (".concat(r.shape, ")."));
    var a = yield n.data(),
        s = yield r.data(),
        o = new Set(s);
    var i = 0;

    for (var _e1156 = 0; _e1156 < a.length; _e1156++) {
      o.has(a[_e1156]) || i++;
    }

    var l = new TensorBuffer([i], n.dtype),
        u = new TensorBuffer([i], "int32");

    for (var _e1157 = 0, _t775 = 0; _e1157 < a.length; _e1157++) {
      o.has(a[_e1157]) || (l.values[_t775] = a[_e1157], u.values[_t775] = _e1157, _t775++);
    }

    return [l.toTensor(), u.toTensor()];
  });
  return _setdiff1dAsync_.apply(this, arguments);
}

var setdiff1dAsync = setdiff1dAsync_;

function sign_(e) {
  var t = convertToTensor(e, "x", "sign");
  return ENGINE.runKernel(Sign, {
    x: t
  });
}

var sign$2 = op({
  sign_
});

function sin_(e) {
  var t = convertToTensor(e, "x", "sin");
  return ENGINE.runKernel(Sin, {
    x: t
  });
}

var sin$2 = op({
  sin_
});

function sinh_(e) {
  var t = convertToTensor(e, "x", "sinh");
  return ENGINE.runKernel(Sinh, {
    x: t
  });
}

var sinh$2 = op({
  sinh_
});

function slice1d_(e, t, n) {
  var r = convertToTensor(e, "x", "slice1d");
  return assert$4(1 === r.rank, () => "slice1d expects a rank-1 tensor, but got a rank-".concat(r.rank, " tensor")), slice$2(r, [t], [n]);
}

var slice1d = op({
  slice1d_
});

function slice2d_(e, t, n) {
  var r = convertToTensor(e, "x", "slice2d");
  return assert$4(2 === r.rank, () => "slice2d expects a rank-2 tensor, but got a rank-".concat(r.rank, " tensor")), slice$2(r, t, n);
}

var slice2d = op({
  slice2d_
});

function slice3d_(e, t, n) {
  var r = convertToTensor(e, "x", "slice3d");
  return assert$4(3 === r.rank, () => "slice3d expects a rank-3 tensor, but got a rank-".concat(r.rank, " tensor")), slice$2(r, t, n);
}

var slice3d = op({
  slice3d_
});

function slice4d_(e, t, n) {
  var r = convertToTensor(e, "x", "slice4d");
  return assert$4(4 === r.rank, () => "slice4d expects a rank-4 tensor, but got a rank-".concat(r.rank, " tensor")), slice$2(r, t, n);
}

var slice4d = op({
  slice4d_
});

function softmax_(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : -1;
  var n = convertToTensor(e, "logits", "softmax", "float32");
  if (-1 === t && (t = n.rank - 1), t !== n.rank - 1) throw Error("Softmax along a non-last dimension is not yet supported. Logits was rank ".concat(n.rank, " and dim was ").concat(t));
  return ENGINE.runKernel(Softmax$2, {
    logits: n
  }, {
    dim: t
  });
}

var softmax$3 = op({
  softmax_
});

function fft_(e) {
  return assert$4("complex64" === e.dtype, () => "The dtype for tf.spectral.fft() must be complex64 but got ".concat(e.dtype, ".")), ENGINE.runKernel(FFT, {
    input: e
  });
}

var fft$2 = op({
  fft_
});

function ifft_(e) {
  return assert$4("complex64" === e.dtype, () => "The dtype for tf.spectral.ifft() must be complex64 but got ".concat(e.dtype, ".")), ENGINE.runKernel(IFFT, {
    input: e
  });
}

var ifft$2 = op({
  ifft_
});

function irfft_(e) {
  var t = e.shape[e.shape.length - 1],
      n = e.size / t;
  var r;

  if (t <= 2) {
    var a = reshape$3(e, [n, t]);
    r = ifft$2(a);
  } else {
    var _a129 = [n, 2 * (t - 1)],
        s = reshape$3(real$2(e), [n, t]),
        o = reshape$3(imag$2(e), [n, t]),
        i = reverse$2(slice$2(s, [0, 1], [n, t - 2]), 1),
        l = mul(reverse$2(slice$2(o, [0, 1], [n, t - 2]), 1), scalar(-1)),
        u = concat$2([s, i], 1),
        c = concat$2([o, l], 1),
        _p19 = reshape$3(complex$2(u, c), [_a129[0], _a129[1]]);

    r = ifft$2(_p19);
  }

  if (r = real$2(r), 3 === e.rank && 0 !== e.shape[0]) {
    var _t412 = r,
        _n234 = e.shape[0];
    r = reshape$3(r, [_n234, r.shape[0] / _n234, r.shape[1]]), _t412.dispose();
  }

  return r;
}

var irfft = op({
  irfft_
});

function split_(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;
  var r = convertToTensor(e, "x", "split");
  return ENGINE.runKernel(SplitV, {
    x: r
  }, {
    numOrSizeSplits: t,
    axis: n
  });
}

var split$2 = op({
  split_
});

function rfft_(e, t) {
  assert$4("float32" === e.dtype, () => "The dtype for rfft() must be real value but got ".concat(e.dtype));
  var n = e.shape[e.shape.length - 1];
  var r = e.size / n;
  var a;

  if (null != t && t < n) {
    var _r197 = e.shape.map(e => 0),
        _s96 = e.shape.map(e => e);

    _s96[e.shape.length - 1] = t, a = slice$2(e, _r197, _s96), n = t;
  } else if (null != t && t > n) {
    var _r198 = e.shape.map(e => e);

    _r198[e.shape.length - 1] = t - n, a = concat$2([e, zeros$2(_r198)], e.shape.length - 1), n = t;
  } else a = e;

  var s = zerosLike$2(a),
      o = reshape$3(complex$2(a, s), [r, n]),
      i = fft$2(o),
      l = Math.floor(n / 2) + 1,
      u = real$2(i),
      c = imag$2(i),
      p = split$2(u, [l, n - l], u.shape.length - 1),
      d = split$2(c, [l, n - l], c.shape.length - 1),
      h = a.shape.slice();
  return h[a.shape.length - 1] = l, reshape$3(complex$2(p[0], d[0]), h);
}

var rfft = op({
  rfft_
});

function sqrt_(e) {
  var t = convertToTensor(e, "x", "sqrt");
  return ENGINE.runKernel(Sqrt, {
    x: t
  });
}

var sqrt$2 = op({
  sqrt_
});

function squaredDifference_(e, t) {
  var n = convertToTensor(e, "a", "squaredDifference"),
      r = convertToTensor(t, "b", "squaredDifference");
  return [n, r] = makeTypesMatch(n, r), assertAndGetBroadcastShape(n.shape, r.shape), ENGINE.runKernel(SquaredDifference, {
    a: n,
    b: r
  }, {});
}

var squaredDifference$2 = op({
  squaredDifference_
});

function squeeze_(e, t) {
  var n = convertToTensor(e, "x", "squeeze");
  return reshape$3(n, squeezeShape(n.shape, t).newShape);
}

var squeeze = op({
  squeeze_
});

function stack_(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;
  var n = convertToTensorArray(e, "tensors", "stack", "string_or_numeric");
  return assert$4(n.length >= 1, () => "Pass at least one tensor to tf.stack"), n.length > 0 && assert$4(t <= n[0].rank, () => "Axis must be <= rank of the tensor"), ENGINE.runKernel(Pack, n, {
    axis: t
  });
}

var stack = op({
  stack_
});

function step_(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;
  var n = convertToTensor(e, "x", "step");
  return ENGINE.runKernel(Step, {
    x: n
  }, {
    alpha: t
  });
}

var step$2 = op({
  step_
});

function stridedSlice_(e, t, n, r) {
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : 0;
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : 0;
  var o = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : 0;
  var i = arguments.length > 7 && arguments[7] !== undefined ? arguments[7] : 0;
  var l = arguments.length > 8 && arguments[8] !== undefined ? arguments[8] : 0;
  var u = convertToTensor(e, "x", "stridedSlice", "string_or_numeric");
  return ENGINE.runKernel(StridedSlice, {
    x: u
  }, {
    begin: t,
    end: n,
    strides: r,
    beginMask: a,
    endMask: s,
    ellipsisMask: o,
    newAxisMask: i,
    shrinkAxisMask: l
  });
}

var stridedSlice$2 = op({
  stridedSlice_
});

function tan_(e) {
  var t = convertToTensor(e, "x", "tan");
  return ENGINE.runKernel(Tan, {
    x: t
  });
}

var tan$2 = op({
  tan_
});

function tensor1d(e, t) {
  assertNonNull(e);
  var n = inferShape(e, t);
  if (1 !== n.length) throw new Error("tensor1d() requires values to be a flat/TypedArray");
  return makeTensor(e, null, n, t);
}

function tensor2d(e, t, n) {
  if (assertNonNull(e), null != t && 2 !== t.length) throw new Error("tensor2d() requires shape to have two numbers");
  var r = inferShape(e, n);
  if (2 !== r.length && 1 !== r.length) throw new Error("tensor2d() requires values to be number[][] or flat/TypedArray");
  if (1 === r.length && null == t) throw new Error("tensor2d() requires shape to be provided when `values` are a flat/TypedArray");
  return makeTensor(e, t, r, n);
}

function tensor4d(e, t, n) {
  if (assertNonNull(e), null != t && 4 !== t.length) throw new Error("tensor4d() requires shape to have four numbers");
  var r = inferShape(e, n);
  if (4 !== r.length && 1 !== r.length) throw new Error("tensor4d() requires values to be number[][][][] or flat/TypedArray");
  if (1 === r.length && null == t) throw new Error("tensor4d() requires shape to be provided when `values` are a flat array");
  return makeTensor(e, t, r, n);
}

function tensor5d(e, t, n) {
  if (assertNonNull(e), null != t && 5 !== t.length) throw new Error("tensor5d() requires shape to have five numbers");
  var r = inferShape(e, n);
  if (5 !== r.length && 1 !== r.length) throw new Error("tensor5d() requires values to be number[][][][][] or flat/TypedArray");
  if (1 === r.length && null == t) throw new Error("tensor5d() requires shape to be provided when `values` are a flat array");
  return makeTensor(e, t, r, n);
}

function tensor6d(e, t, n) {
  if (assertNonNull(e), null != t && 6 !== t.length) throw new Error("tensor6d() requires shape to have six numbers");
  var r = inferShape(e, n);
  if (6 !== r.length && 1 !== r.length) throw new Error("tensor6d() requires values to be number[][][][][][] or flat/TypedArray");
  if (1 === r.length && null == t) throw new Error("tensor6d() requires shape to be provided when `values` are a flat array");
  return makeTensor(e, t = t || r, r, n);
}

function topk_(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 1;
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !0;
  var r = convertToTensor(e, "x", "topk");
  if (0 === r.rank) throw new Error("topk() expects the input to be of rank 1 or higher");
  var a = r.shape[r.shape.length - 1];
  if (t < 0) throw new Error("'k' passed to topk() must be >= 0 but got ".concat(t));
  if (t > a) throw new Error("'k' passed to topk() must be <= the last dimension (".concat(a, ") but got ").concat(t));
  var s = {
    x: r
  },
      o = {
    k: t,
    sorted: n
  },
      [i, l] = ENGINE.runKernel(TopK, s, o);
  return {
    values: i,
    indices: l
  };
}

var topk = op({
  topk_
});

function truncatedNormal_(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 1;
  var r = arguments.length > 3 ? arguments[3] : undefined;
  var a = arguments.length > 4 ? arguments[4] : undefined;
  if (null != r && "bool" === r) throw new Error("Unsupported data type $ { dtype }");
  var s = new MPRandGauss(t, n, r, !0, a),
      o = buffer(e, r);

  for (var _e589 = 0; _e589 < o.values.length; _e589++) {
    o.values[_e589] = s.nextValue();
  }

  return o.toTensor();
}

var truncatedNormal$1 = op({
  truncatedNormal_
});

function unique_(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;
  var n = convertToTensor(e, "x", "unique", "string_or_numeric");
  assert$4(n.rank > 0, () => "The input tensor must be at least 1D");
  var r = {
    x: n
  },
      a = {
    axis: t
  },
      [s, o] = ENGINE.runKernel(Unique, r, a);
  return {
    values: s,
    indices: o
  };
}

var unique$3 = op({
  unique_
});

function unsortedSegmentSum_(e, t, n) {
  var r = convertToTensor(e, "x", "unsortedSegmentSum"),
      a = convertToTensor(t, "segmentIds", "unsortedSegmentSum", "int32");
  return assert$4(isInt(n), () => "numSegments must be of dtype int"), ENGINE.runKernel(UnsortedSegmentSum, {
    x: r,
    segmentIds: a
  }, {
    numSegments: n
  });
}

var unsortedSegmentSum$2 = op({
  unsortedSegmentSum_
});

function unstack_(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;
  var n = convertToTensor(e, "x", "unstack", "string_or_numeric");
  return assert$4(t >= -n.shape.length && t < n.shape.length, () => "Axis = ".concat(t, " is not in [-").concat(n.shape.length, ", ").concat(n.shape.length, ")")), ENGINE.runKernel(Unpack, {
    value: n
  }, {
    axis: t
  });
}

var unstack = op({
  unstack_
});

function variable(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !0;
  var n = arguments.length > 2 ? arguments[2] : undefined;
  var r = arguments.length > 3 ? arguments[3] : undefined;
  return ENGINE.makeVariable(e, t, n, r);
}

function whereImpl$2(e, t) {
  var n = [];

  for (var _e590 = 0; _e590 < t.length; _e590++) {
    t[_e590] && n.push(_e590);
  }

  var r = buffer(e, "int32"),
      a = buffer([n.length, e.length], "int32");

  for (var _t413 = 0; _t413 < n.length; _t413++) {
    var s = r.indexToLoc(n[_t413]);
    a.values.set(s, _t413 * e.length);
  }

  return a.toTensor();
}

function whereAsync_(_x71) {
  return _whereAsync_.apply(this, arguments);
}

function _whereAsync_() {
  _whereAsync_ = _asyncToGenerator(function* (e) {
    var t = convertToTensor(e, "condition", "whereAsync", "bool"),
        n = yield t.data(),
        r = whereImpl$2(t.shape, n);
    return e !== t && t.dispose(), r;
  });
  return _whereAsync_.apply(this, arguments);
}

var whereAsync = whereAsync_;

function booleanMaskAsync_(_x72, _x73, _x74) {
  return _booleanMaskAsync_.apply(this, arguments);
}

function _booleanMaskAsync_() {
  _booleanMaskAsync_ = _asyncToGenerator(function* (e, t, n) {
    var r = convertToTensor(e, "tensor", "boolMask"),
        a = convertToTensor(t, "mask", "boolMask", "bool"),
        s = null == n ? 0 : n,
        o = a.rank,
        i = r.shape;
    assert$4(o > 0, () => "mask cannot be scalar"), assertShapesMatch(i.slice(s, s + o), a.shape, "mask's shape must match the first K dimensions of tensor's shape,");
    var l = 1;

    for (var _e1158 = s; _e1158 < s + o; _e1158++) {
      l *= i[_e1158];
    }

    var u = i.slice(0, s).concat([l], i.slice(s + o)),
        c = reshape$3(r, u),
        p = reshape$3(a, [-1]),
        d = yield whereAsync(p),
        h = squeeze(d, [1]),
        m = gather$1(c, h, s);
    return e !== r && r.dispose(), t !== a && a.dispose(), h.dispose(), c.dispose(), p.dispose(), d.dispose(), m;
  });
  return _booleanMaskAsync_.apply(this, arguments);
}

var booleanMaskAsync = booleanMaskAsync_;

function norm_(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : "euclidean";
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
  var a = normImpl(e = convertToTensor(e, "x", "norm"), t, n);
  var s = a.shape;

  if (r) {
    var _t414 = parseAxisParam(n, e.shape);

    s = expandShapeToKeepDim(a.shape, _t414);
  }

  return reshape$3(a, s);
}

function normImpl(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;
  if (0 === e.rank) return abs$2(e);
  if (1 !== e.rank && null === n) return normImpl(reshape$3(e, [-1]), t, n);

  if (1 === e.rank || "number" == typeof n || Array.isArray(n) && 1 === n.length) {
    if (1 === t) return sum$2(abs$2(e), n);
    if (Infinity === t) return max$3(abs$2(e), n);
    if (-Infinity === t) return min$3(abs$2(e), n);
    if ("euclidean" === t || 2 === t) return sqrt$2(sum$2(pow$2(abs$2(e), scalar(2, "int32")), n));
    throw new Error("Error in norm: invalid ord value: ".concat(t));
  }

  if (Array.isArray(n) && 2 === n.length) {
    if (1 === t) return max$3(sum$2(abs$2(e), n[0]), n[1] - 1);
    if (Infinity === t) return max$3(sum$2(abs$2(e), n[1]), n[0]);
    if (-Infinity === t) return min$3(sum$2(abs$2(e), n[1]), n[0]);
    if ("fro" === t || "euclidean" === t) return sqrt$2(sum$2(square$2(e), n));
    throw new Error("Error in norm: invalid ord value: ".concat(t));
  }

  throw new Error("Error in norm: invalid axis: ".concat(n));
}

var norm = op({
  norm_
});

function movingAverage_(e, t, n, r) {
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !0;
  var s = convertToTensor(e, "v", "movingAverage"),
      o = convertToTensor(t, "x", "movingAverage"),
      i = convertToTensor(n, "decay", "movingAverage");
  assertTypesMatch(s, o), assert$4(arraysEqual(s.shape, o.shape), () => "Shape mismatch in v and x");
  var l = scalar(1),
      u = sub$2(l, i);
  var c = mul(sub$2(o, s), u);

  if (a) {
    assert$4(null != r, () => "When using zeroDebias: true, step is required.");

    var _e591 = convertToTensor(r, "step", "movingAverage");

    c = div$1(c, sub$2(l, pow$2(i, _e591)));
  }

  return add$2(s, c);
}

var movingAverage = op({
  movingAverage_
});

function scatterND_(e, t, n) {
  var r = convertToTensor(e, "indices", "scatterND", "int32"),
      a = convertToTensor(t, "updates", "scatterND");
  return validateInput$1(a, r, n), ENGINE.runKernel(ScatterNd, {
    indices: r,
    updates: a
  }, {
    shape: n
  });
}

var scatterND = op({
  scatterND_
});

function validateInput(e, t, n, r) {
  if ("int32" !== e.dtype) throw new Error("tf.sparseToDense() expects the indices to be int32 type, but the dtype was ".concat(e.dtype, "."));
  if (e.rank > 2) throw new Error("sparseIndices should be a scalar, vector, or matrix, but got shape ".concat(e.shape, "."));
  var a = e.rank > 0 ? e.shape[0] : 1,
      s = e.rank > 1 ? e.shape[1] : 1;
  if (n.length !== s) throw new Error("outputShape has incorrect number of elements:, ".concat(n.length, ", should be: ").concat(s, "."));
  if (0 !== t.rank && (1 !== t.rank || t.size !== a)) throw new Error("sparseValues has incorrect shape ".concat(t.shape, ", should be [] or [").concat(a, "]"));
  if (t.dtype !== r.dtype) throw new Error("sparseValues.dtype must match defaultValues.dtype");
}

function sparseToDense_(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 0;
  var a = convertToTensor(e, "sparseIndices", "sparseToDense", "int32"),
      s = convertToTensor(t, "sparseValues", "sparseToDense"),
      o = convertToTensor(r, "defaultValue", "sparseToDense", s.dtype);
  return validateInput(a, s, n, o), ENGINE.runKernel(SparseToDense, {
    sparseIndices: a,
    sparseValues: s,
    defaultValue: o
  }, {
    outputShape: n
  });
}

var sparseToDense$2 = op({
  sparseToDense_
});

function gatherND_(e, t) {
  var n = convertToTensor(t, "indices", "gatherND", "int32"),
      r = convertToTensor(e, "x", "gatherND", "string_or_numeric");
  return ENGINE.runKernel(GatherNd, {
    params: r,
    indices: n
  });
}

var gatherND = op({
  gatherND_
});

function getNoiseShape(e, t) {
  if (null == t) return e.shape.slice();
  if (arraysEqual(e.shape, t)) return t;

  if (e.shape.length === t.length) {
    var n = [];

    for (var r = 0; r < e.shape.length; r++) {
      n.push(null == t[r] && null != e.shape[r] ? e.shape[r] : t[r]);
    }

    return n;
  }

  return t;
}

function dropout_(e, t, n, r) {
  var a = convertToTensor(e, "x", "dropout");
  if (assert$4("float32" === a.dtype, () => "x has to be a floating point tensor since it's going to be scaled, but got a ".concat(a.dtype, " tensor instead.")), assert$4(t >= 0 && t < 1, () => "rate must be a float in the range [0, 1), but got ".concat(t, ".")), 0 === t) return e instanceof Tensor ? a.clone() : a;
  var s = getNoiseShape(a, n),
      o = 1 - t,
      i = div$1(floor$2(add$2(randomUniform$1(s, 0, 1, "float32", r), o)), o);
  return mul(a, i);
}

var dropout$2 = op({
  dropout_
});

function enclosingPowerOfTwo(e) {
  return Math.floor(Math.pow(2, Math.ceil(Math.log(e) / Math.log(2))));
}

function cosineWindow(e, t, n) {
  var r = 1 - e % 2,
      a = new Float32Array(e);

  for (var s = 0; s < e; ++s) {
    var o = 2 * Math.PI * s / (e + r - 1);
    a[s] = t - n * Math.cos(o);
  }

  return tensor1d(a, "float32");
}

function inTopKAsync_(_x75, _x76) {
  return _inTopKAsync_.apply(this, arguments);
}

function _inTopKAsync_() {
  _inTopKAsync_ = _asyncToGenerator(function* (e, t) {
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 1;
    var r = convertToTensor(e, "predictions", "inTopK"),
        a = convertToTensor(t, "targets", "inTopK");
    assert$4(r.rank > 1, () => "inTopK() expects the predictions to be of rank 2 or higher, but got ".concat(r.rank)), assert$4(r.rank - 1 === a.rank, () => "predictions rank should be 1 larger than targets rank, but got predictions rank ".concat(r.rank, " and targets rank ").concat(a.rank)), assertShapesMatch(r.shape.slice(0, r.shape.length - 1), a.shape, "predictions's shape should be align with the targets' shape, except the last dimension.");
    var s = r.shape[r.shape.length - 1];
    assert$4(n > 0 && n <= s, () => "'k' passed to inTopK() must be > 0 && <= the predictions last dimension (".concat(s, "), but got ").concat(n));
    var o = yield r.data(),
        i = yield a.data(),
        [l, u] = [o.length / s, s],
        c = getTypedArrayFromDType("bool", l);

    for (var _e1159 = 0; _e1159 < l; _e1159++) {
      var _t776 = _e1159 * u,
          _r449 = o.subarray(_t776, _t776 + u),
          _a320 = [];

      for (var _e1160 = 0; _e1160 < _r449.length; _e1160++) {
        _a320.push({
          value: _r449[_e1160],
          index: _e1160
        });
      }

      _a320.sort((e, t) => t.value - e.value), c[_e1159] = 0;

      for (var _t777 = 0; _t777 < n; _t777++) {
        if (_a320[_t777].index === i[_e1159]) {
          c[_e1159] = 1;
          break;
        }
      }
    }

    return e !== r && r.dispose(), t !== a && a.dispose(), tensor(c, a.shape, "bool");
  });
  return _inTopKAsync_.apply(this, arguments);
}

var inTopKAsync = inTopKAsync_;

function conv2DBackpropFilter_(e, t, n, r, a) {
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : "NHWC";
  var o = arguments.length > 6 ? arguments[6] : undefined;
  var i = e;
  3 === e.rank && (i = reshape$3(e, [1, e.shape[0], e.shape[1], e.shape[2]]));
  var l = t;
  3 === l.rank && (l = reshape$3(t, [1, t.shape[0], t.shape[1], t.shape[2]])), assert$4(4 === i.rank, () => "Error in conv2dDerFilter: input must be rank 4, but got shape ".concat(i.shape, ".")), assert$4(4 === l.rank, () => "Error in conv2dDerFilter: dy must be rank 4, but got shape ".concat(l.shape, ".")), assert$4(4 === n.length, () => "Error in conv2dDerFilter: filterShape must be length 4, but got ".concat(n, "."));
  var u = "NHWC" === s ? i.shape[3] : i.shape[1],
      c = "NHWC" === s ? l.shape[3] : l.shape[1];
  return assert$4(u === n[2], () => "Error in conv2dDerFilter: depth of input ".concat(u, ") must match input depth in filter (").concat(n[2], ".")), assert$4(c === n[3], () => "Error in conv2dDerFilter: depth of dy (".concat(c, ") must match output depth for filter (").concat(n[3], ").")), null != o && assert$4(isInt(a), () => "Error in conv2dDerFilter: pad must be an integer when using, dimRoundingMode ".concat(o, " but got pad ").concat(a, ".")), ENGINE.runKernel(Conv2DBackpropFilter, {
    x: i,
    dy: l
  }, {
    strides: r,
    pad: a,
    dataFormat: s,
    dimRoundingMode: o,
    filterShape: n
  });
}

var conv2DBackpropFilter$2 = op({
  conv2DBackpropFilter_
});

function getFusedDyActivation(e, t, n) {
  if (null == n || "linear" === n) return e;
  if ("relu" === n) return mul(e, step$2(t));
  throw new Error("Cannot compute gradient for fused activation ".concat(n, "."));
}

function getFusedBiasGradient(e, t) {
  var n = t;
  var r = getReductionAxes(e.shape, t.shape);
  return r.length > 0 && (n = sum$2(n, r)), reshape$3(n, e.shape);
}

function applyActivation$1(e, t, n, r) {
  if ("linear" === t) return e;
  if ("relu" === t) return relu$3(e);
  if ("elu" === t) return elu$4(e);
  if ("relu6" === t) return relu6$2(e);
  if ("prelu" === t) return prelu$3(e, n);
  if ("leakyrelu" === t) return leakyRelu$2(e, r);
  if ("sigmoid" === t) return sigmoid$2(e);
  throw new Error("Unknown fused activation ".concat(t, "."));
}

var shouldFuse = (e, t) => !(e > 0) || "linear" === t;

function fusedConv2d_(_ref29) {
  var {
    x: e,
    filter: t,
    strides: n,
    pad: r,
    dataFormat: a = "NHWC",
    dilations: s = [1, 1],
    dimRoundingMode: o,
    bias: i,
    activation: l = "linear",
    preluActivationWeights: u,
    leakyreluAlpha: c
  } = _ref29;

  if (!1 === shouldFuse(ENGINE.state.gradientDepth, l = l || "linear")) {
    var _p20 = conv2d$3(e, t, n, r, a, s, o);

    return null != i && (_p20 = add$2(_p20, i)), applyActivation$1(_p20, l, u, c);
  }

  var p = convertToTensor(e, "x", "conv2d"),
      d = convertToTensor(t, "filter", "conv2d");
  var h = p,
      m = !1;
  3 === p.rank && (m = !0, h = reshape$3(p, [1, p.shape[0], p.shape[1], p.shape[2]])), assert$4(4 === h.rank, () => "Error in fused conv2d: input must be rank 4, but got rank ".concat(h.rank, ".")), assert$4(4 === d.rank, () => "Error in fused conv2d: filter must be rank 4, but got rank ".concat(d.rank, ".")), null != o && assert$4(isInt(r), () => "Error in fused conv2d: pad must be an integer when using, dimRoundingMode ".concat(o, " but got pad ").concat(r, ".")), assert$4(h.shape[3] === d.shape[2], () => "Error in conv2d: depth of input (".concat(h.shape[3], ") must match input depth for filter ").concat(d.shape[2], ".")), assert$4(eitherStridesOrDilationsAreOne(n, s), () => "Error in conv2D: Either strides or dilations must be 1. Got strides ".concat(n, " and dilations '").concat(s, "'")), assert$4("NHWC" === a, () => "Error in conv2d: got dataFormat of ".concat(a, " but only NHWC is currently supported."));
  var f = computeConv2DInfo(h.shape, d.shape, n, s, r, o);
  var g, $;
  null != i && (g = convertToTensor(i, "bias", "fused conv2d"), [g] = makeTypesMatch(g, p), assertAndGetBroadcastShape(f.outShape, g.shape)), null != u && ($ = convertToTensor(u, "prelu weights", "fused conv2d"));

  var y = (e, t) => {
    var [a, o, i, u] = t,
        c = getFusedDyActivation(e, i, l);
    assert$4(tupleValuesAreOne(s), () => "Error in gradient of fused conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '".concat(s, "'"));
    var p = [conv2DBackpropInput$2(o.shape, c, a, n, r), conv2DBackpropFilter$2(o, c, a.shape, n, r)];

    if (null != u) {
      var _e592 = getFusedBiasGradient(u, c);

      p.push(_e592);
    }

    return p;
  },
      b = {
    x: h,
    filter: d,
    bias: g,
    preluActivationWeights: $
  },
      x = {
    strides: n,
    pad: r,
    dataFormat: a,
    dilations: s,
    dimRoundingMode: o,
    activation: l,
    leakyreluAlpha: c
  };

  if (null == i) {
    var _e593 = customGrad((e, t, n) => {
      var r = ENGINE.runKernel(FusedConv2D, b, x);
      return n([t, e, r]), m && (r = reshape$3(r, [r.shape[1], r.shape[2], r.shape[3]])), {
        value: r,
        gradFunc: y
      };
    });

    return _e593(h, d);
  }

  {
    var _e594 = customGrad((e, t, n, r) => {
      var a = ENGINE.runKernel(FusedConv2D, b, x);
      return r([t, e, a, n]), m && (a = reshape$3(a, [a.shape[1], a.shape[2], a.shape[3]])), {
        value: a,
        gradFunc: y
      };
    });

    return _e594(h, d, g);
  }
}

var conv2d$2 = op({
  fusedConv2d_
});

function depthwiseConv2dNativeBackpropFilter_(e, t, n, r, a) {
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : [1, 1];
  var o = arguments.length > 6 ? arguments[6] : undefined;
  var i = e;
  3 === e.rank && (i = reshape$3(e, [1, e.shape[0], e.shape[1], e.shape[2]]));
  var l = t;
  return 3 === l.rank && (l = reshape$3(t, [1, t.shape[0], t.shape[1], t.shape[2]])), ENGINE.runKernel(DepthwiseConv2dNativeBackpropFilter, {
    x: i,
    dy: l
  }, {
    strides: r,
    pad: a,
    dimRoundingMode: o,
    dilations: s,
    filterShape: n
  });
}

var depthwiseConv2dNativeBackpropFilter$2 = op({
  depthwiseConv2dNativeBackpropFilter_
});

function depthwiseConv2dNativeBackpropInput_(e, t, n, r, a) {
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : [1, 1];
  var o = arguments.length > 6 ? arguments[6] : undefined;
  var i = t,
      l = !1;
  3 === t.rank && (l = !0, i = reshape$3(t, [1, t.shape[0], t.shape[1], t.shape[2]]));
  var u = ENGINE.runKernel(DepthwiseConv2dNativeBackpropInput, {
    dy: i,
    filter: n
  }, {
    strides: r,
    pad: a,
    dimRoundingMode: o,
    dilations: s,
    inputShape: e
  });
  return l ? reshape$3(u, [u.shape[1], u.shape[2], u.shape[3]]) : u;
}

var depthwiseConv2dNativeBackpropInput$2 = op({
  depthwiseConv2dNativeBackpropInput_
});

function fusedDepthwiseConv2d_(_ref30) {
  var {
    x: e,
    filter: t,
    strides: n,
    pad: r,
    dataFormat: a = "NHWC",
    dilations: s = [1, 1],
    dimRoundingMode: o,
    bias: i,
    activation: l = "linear",
    preluActivationWeights: u,
    leakyreluAlpha: c
  } = _ref30;

  if (!1 === shouldFuse(ENGINE.state.gradientDepth, l)) {
    var _p21 = depthwiseConv2d$3(e, t, n, r, a, s, o);

    return null != i && (_p21 = add$2(_p21, i)), applyActivation$1(_p21, l, u, c);
  }

  var p = convertToTensor(e, "x", "depthwiseConv2d"),
      d = convertToTensor(t, "filter", "depthwiseConv2d");
  var h = p,
      m = !1;
  3 === p.rank && (m = !0, h = reshape$3(p, [1, p.shape[0], p.shape[1], p.shape[2]])), assert$4(4 === h.rank, () => "Error in fused depthwiseConv2d: input must be rank 4, but got rank ".concat(h.rank, ".")), assert$4(4 === d.rank, () => "Error in fused depthwiseConv2d: filter must be rank 4, but got rank ".concat(d.rank, ".")), assert$4(h.shape[3] === d.shape[2], () => "Error in fused depthwiseConv2d: number of input channels (".concat(h.shape[3], ") must match the inChannels dimension in filter ").concat(d.shape[2], ".")), null == s && (s = [1, 1]), assert$4(eitherStridesOrDilationsAreOne(n, s), () => "Error in fused depthwiseConv2d: Either strides or dilations must be 1. Got strides ".concat(n, " and dilations '").concat(s, "'")), null != o && assert$4(isInt(r), () => "Error in fused depthwiseConv2d: pad must be an integer when using dimRoundingMode ".concat(o, " but got pad ").concat(r, "."));
  var f = computeConv2DInfo(h.shape, d.shape, n, s, r, o, !0);
  var g, $;
  null != i && (g = convertToTensor(i, "bias", "fused conv2d"), [g] = makeTypesMatch(g, p), assertAndGetBroadcastShape(f.outShape, g.shape)), null != u && ($ = convertToTensor(u, "prelu weights", "fused depthwiseConv2d"));

  var y = (e, t) => {
    assert$4(tupleValuesAreOne(s), () => "Error in gradient of fused depthwiseConv2d: dilation rates greater than 1 are not yet supported. Got dilations '".concat(s, "'"));
    var [a, i, u, c] = t,
        p = getFusedDyActivation(e, u, l),
        d = depthwiseConv2dNativeBackpropInput$2(i.shape, p, a, n, r, s, o),
        h = depthwiseConv2dNativeBackpropFilter$2(i, p, a.shape, n, r, s, o);
    return null != c ? [d, h, getFusedBiasGradient(g, p)] : [d, h];
  },
      b = {
    x: h,
    filter: d,
    bias: g,
    preluActivationWeights: $
  },
      x = {
    strides: n,
    pad: r,
    dataFormat: a,
    dilations: s,
    dimRoundingMode: o,
    activation: l,
    leakyreluAlpha: c
  };

  if (null == i) {
    var _e595 = customGrad((e, t, n) => {
      var r = ENGINE.runKernel(FusedDepthwiseConv2D, b, x);
      return n([t, e, r]), m && (r = reshape$3(r, [r.shape[1], r.shape[2], r.shape[3]])), {
        value: r,
        gradFunc: y
      };
    });

    return _e595(h, d);
  }

  {
    var _e596 = customGrad((e, t, n, r) => {
      var a = ENGINE.runKernel(FusedDepthwiseConv2D, b, x);
      return r([t, e, a, n]), m && (a = reshape$3(a, [a.shape[1], a.shape[2], a.shape[3]])), {
        value: a,
        gradFunc: y
      };
    });

    return _e596(h, d, g);
  }
}

var depthwiseConv2d$2 = op({
  fusedDepthwiseConv2d_
});

function fusedMatMul_(_ref31) {
  var {
    a: e,
    b: t,
    transposeA: n = !1,
    transposeB: r = !1,
    bias: a,
    activation: s = "linear",
    preluActivationWeights: o,
    leakyreluAlpha: i
  } = _ref31;

  if (!1 === shouldFuse(ENGINE.state.gradientDepth, s)) {
    var _l36 = matMul$1(e, t, n, r);

    return null != a && (_l36 = add$2(_l36, a)), applyActivation$1(_l36, s, o, i);
  }

  var l = convertToTensor(e, "a", "fused matMul"),
      u = convertToTensor(t, "b", "fused matMul");
  [l, u] = makeTypesMatch(l, u);
  var c = n ? l.shape[l.rank - 2] : l.shape[l.rank - 1],
      p = r ? u.shape[u.rank - 1] : u.shape[u.rank - 2],
      d = n ? l.shape[l.rank - 1] : l.shape[l.rank - 2],
      h = r ? u.shape[u.rank - 2] : u.shape[u.rank - 1],
      m = l.shape.slice(0, -2),
      f = u.shape.slice(0, -2),
      g = sizeFromShape(m),
      $ = sizeFromShape(f);
  assert$4(l.rank >= 2 && u.rank >= 2 && l.rank === u.rank, () => "Error in fused matMul: inputs must have the same rank of at least 2, got ranks ".concat(l.rank, " and ").concat(u.rank, ".")), assert$4(arraysEqual(m, f), () => "Error in fused matMul: outer dimensions (".concat(m, ") and (").concat(f, ") of Tensors with shapes ").concat(l.shape, " and ").concat(u.shape, " must match.")), assert$4(c === p, () => "Error in fused matMul: inner shapes (".concat(c, ") and (").concat(p, ") of Tensors with shapes ").concat(l.shape, " and ").concat(u.shape, " and transposeA=").concat(n, " and transposeB=").concat(r, " must match."));
  var y = l.shape.slice(0, -2).concat([d, h]),
      b = reshape$3(l, n ? [g, c, d] : [g, d, c]),
      x = reshape$3(u, r ? [$, h, p] : [$, p, h]);
  var v, I;
  null != a && (v = convertToTensor(a, "bias", "fused matMul"), [v] = makeTypesMatch(v, l), assertAndGetBroadcastShape(y, v.shape)), null != o && (I = convertToTensor(o, "prelu weights", "fused matMul"));

  var C = (e, t) => {
    var [o, i, l, u] = t,
        c = getFusedDyActivation(reshape$3(e, l.shape), l, s);
    var p, d;
    return n || r ? !n && r ? (p = matMul$1(c, i, !1, !1), d = matMul$1(c, o, !0, !1)) : n && !r ? (p = matMul$1(i, c, !1, !0), d = matMul$1(o, c, !1, !1)) : (p = matMul$1(i, c, !0, !0), d = matMul$1(c, o, !0, !0)) : (p = matMul$1(c, i, !1, !0), d = matMul$1(o, c, !0, !1)), null != a ? [p, d, getFusedBiasGradient(u, c)] : [p, d];
  },
      S = {
    a: b,
    b: x,
    bias: v,
    preluActivationWeights: I
  },
      k = {
    transposeA: n,
    transposeB: r,
    activation: s,
    leakyreluAlpha: i
  };

  if (null == a) {
    var _e597 = customGrad((e, t, n) => {
      var r = ENGINE.runKernel(_FusedMatMul, S, k);
      return n([e, t, r]), {
        value: reshape$3(r, y),
        gradFunc: C
      };
    });

    return _e597(b, x);
  }

  {
    var _e598 = customGrad((e, t, n, r) => {
      var a = ENGINE.runKernel(_FusedMatMul, S, k);
      return r([e, t, a, n]), {
        value: reshape$3(a, y),
        gradFunc: C
      };
    });

    return _e598(b, x, v);
  }
}

var matMul = op({
  fusedMatMul_
});
var fused_ops = {
  __proto__: null,
  conv2d: conv2d$2,
  depthwiseConv2d: depthwiseConv2d$2,
  matMul
};

function hammingWindow_(e) {
  return cosineWindow(e, .54, .46);
}

var hammingWindow = op({
  hammingWindow_
});

function hannWindow_(e) {
  return cosineWindow(e, .5, .5);
}

var hannWindow = op({
  hannWindow_
});

function frame_(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : 0;
  var s = 0;
  var o = [];

  for (; s + t <= e.size;) {
    o.push(slice$2(e, s, t)), s += n;
  }

  if (r) for (; s < e.size;) {
    var _r199 = s + t - e.size,
        i = concat$2([slice$2(e, s, t - _r199), fill$2([_r199], a)]);

    o.push(i), s += n;
  }
  return 0 === o.length ? tensor2d([], [0, t]) : reshape$3(concat$2(o), [o.length, t]);
}

var frame = op({
  frame_
});

function stft_(e, t, n, r) {
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : hannWindow;
  null == r && (r = enclosingPowerOfTwo(t));
  var s = frame(e, t, n),
      o = mul(s, a(t));
  return rfft(o, r);
}

var stft = op({
  stft_
});

function cropAndResize_(e, t, n, r) {
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : "bilinear";
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : 0;
  var o = convertToTensor(e, "image", "cropAndResize"),
      i = convertToTensor(t, "boxes", "cropAndResize", "float32"),
      l = convertToTensor(n, "boxInd", "cropAndResize", "int32"),
      u = i.shape[0];
  return assert$4(4 === o.rank, () => "Error in cropAndResize: image must be rank 4,but got rank ".concat(o.rank, ".")), assert$4(2 === i.rank && 4 === i.shape[1], () => "Error in cropAndResize: boxes must be have size [".concat(u, ",4] but had shape ").concat(i.shape, ".")), assert$4(1 === l.rank && l.shape[0] === u, () => "Error in cropAndResize: boxInd must be have size [".concat(u, "] but had shape ").concat(i.shape, ".")), assert$4(2 === r.length, () => "Error in cropAndResize: cropSize must be of length 2, but got length ".concat(r.length, ".")), assert$4(r[0] >= 1 && r[1] >= 1, () => "cropSize must be atleast [1,1], but was ".concat(r)), assert$4("bilinear" === a || "nearest" === a, () => "method must be bilinear or nearest, but was ".concat(a)), ENGINE.runKernel(CropAndResize, {
    image: o,
    boxes: i,
    boxInd: l
  }, {
    method: a,
    extrapolationValue: s,
    cropSize: r
  });
}

var cropAndResize$2 = op({
  cropAndResize_
});

function flipLeftRight_(e) {
  var t = convertToTensor(e, "image", "flipLeftRight", "float32");
  return assert$4(4 === t.rank, () => "Error in flipLeftRight: image must be rank 4,but got rank ".concat(t.rank, ".")), ENGINE.runKernel(FlipLeftRight, {
    image: t
  }, {});
}

var flipLeftRight = op({
  flipLeftRight_
});

function rotateWithOffset_(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : .5;
  var a = convertToTensor(e, "image", "rotateWithOffset", "float32");
  return assert$4(4 === a.rank, () => "Error in rotateWithOffset: image must be rank 4,but got rank ".concat(a.rank, ".")), ENGINE.runKernel(RotateWithOffset, {
    image: a
  }, {
    radians: t,
    fillValue: n,
    center: r
  });
}

var rotateWithOffset = op({
  rotateWithOffset_
});

function nonMaxSuppSanityCheck(e, t, n, r, a, s) {
  null == r && (r = .5), null == a && (a = Number.NEGATIVE_INFINITY), null == s && (s = 0);
  var o = e.shape[0];
  return n = Math.min(n, o), assert$4(0 <= r && r <= 1, () => "iouThreshold must be in [0, 1], but was '".concat(r, "'")), assert$4(2 === e.rank, () => "boxes must be a 2D tensor, but was of rank '".concat(e.rank, "'")), assert$4(4 === e.shape[1], () => "boxes must have 4 columns, but 2nd dimension was ".concat(e.shape[1])), assert$4(1 === t.rank, () => "scores must be a 1D tensor"), assert$4(t.shape[0] === o, () => "scores has incompatible shape with boxes. Expected ".concat(o, ", but was ").concat(t.shape[0])), assert$4(0 <= s && s <= 1, () => "softNmsSigma must be in [0, 1], but was '".concat(s, "'")), {
    maxOutputSize: n,
    iouThreshold: r,
    scoreThreshold: a,
    softNmsSigma: s
  };
}

function nonMaxSuppression_(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : .5;
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : Number.NEGATIVE_INFINITY;
  var s = convertToTensor(e, "boxes", "nonMaxSuppression"),
      o = convertToTensor(t, "scores", "nonMaxSuppression"),
      i = nonMaxSuppSanityCheck(s, o, n, r, a);
  return ENGINE.runKernel(NonMaxSuppressionV3, {
    boxes: s,
    scores: o
  }, {
    maxOutputSize: n = i.maxOutputSize,
    iouThreshold: r = i.iouThreshold,
    scoreThreshold: a = i.scoreThreshold
  });
}

var nonMaxSuppression = op({
  nonMaxSuppression_
});

function binaryInsert(e, t, n) {
  var r = binarySearch(e, t, n);
  e.splice(r < 0 ? -(r + 1) : r, 0, t);
}

function binarySearch(e, t, n) {
  return binarySearch_(e, t, n || defaultComparator);
}

function defaultComparator(e, t) {
  return e > t ? 1 : e < t ? -1 : 0;
}

function binarySearch_(e, t, n) {
  var r = 0,
      a = e.length,
      s = 0,
      o = !1;

  for (; r < a;) {
    s = r + (a - r >>> 1);
    var i = n(t, e[s]);
    i > 0 ? r = s + 1 : (a = s, o = !i);
  }

  return o ? r : -r - 1;
}

function nonMaxSuppressionV3Impl$2(e, t, n, r, a) {
  return nonMaxSuppressionImpl_(e, t, n, r, a, 0);
}

function nonMaxSuppressionV4Impl$2(e, t, n, r, a, s) {
  return nonMaxSuppressionImpl_(e, t, n, r, a, 0, !1, s, !0);
}

function nonMaxSuppressionV5Impl$2(e, t, n, r, a, s) {
  return nonMaxSuppressionImpl_(e, t, n, r, a, s, !0);
}

function nonMaxSuppressionImpl_(e, t, n, r, a, s) {
  var o = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : !1;
  var i = arguments.length > 7 && arguments[7] !== undefined ? arguments[7] : !1;
  var l = arguments.length > 8 && arguments[8] !== undefined ? arguments[8] : !1;
  var u = [];

  for (var _e599 = 0; _e599 < t.length; _e599++) {
    t[_e599] > a && u.push({
      score: t[_e599],
      boxIndex: _e599,
      suppressBeginIndex: 0
    });
  }

  u.sort(ascendingComparator);
  var c = s > 0 ? -.5 / s : 0,
      p = [],
      d = [];

  for (; p.length < n && u.length > 0;) {
    var _t415 = u.pop(),
        {
      score: _n235,
      boxIndex: _s97,
      suppressBeginIndex: _o70
    } = _t415;

    if (_n235 < a) break;

    var _i44 = !1;

    for (var _n236 = p.length - 1; _n236 >= _o70; --_n236) {
      var _o71 = intersectionOverUnion(e, _s97, p[_n236]);

      if (_o71 >= r) {
        _i44 = !0;
        break;
      }

      if (_t415.score = _t415.score * suppressWeight(r, c, _o71), _t415.score <= a) break;
    }

    _t415.suppressBeginIndex = p.length, _i44 || (_t415.score === _n235 ? (p.push(_s97), d.push(_t415.score)) : _t415.score > a && binaryInsert(u, _t415, ascendingComparator));
  }

  var h = p.length,
      m = n - h;
  i && m > 0 && (p.push(...new Array(m).fill(0)), d.push(...new Array(m).fill(0)));
  var f = {
    selectedIndices: p
  };
  return o && (f.selectedScores = d), l && (f.validOutputs = h), f;
}

function intersectionOverUnion(e, t, n) {
  var r = e.subarray(4 * t, 4 * t + 4),
      a = e.subarray(4 * n, 4 * n + 4),
      s = Math.min(r[0], r[2]),
      o = Math.min(r[1], r[3]),
      i = Math.max(r[0], r[2]),
      l = Math.max(r[1], r[3]),
      u = Math.min(a[0], a[2]),
      c = Math.min(a[1], a[3]),
      p = Math.max(a[0], a[2]),
      d = Math.max(a[1], a[3]),
      h = (i - s) * (l - o),
      m = (p - u) * (d - c);
  if (h <= 0 || m <= 0) return 0;
  var f = Math.max(s, u),
      g = Math.max(o, c),
      $ = Math.min(i, p),
      y = Math.min(l, d),
      b = Math.max($ - f, 0) * Math.max(y - g, 0);
  return b / (h + m - b);
}

function suppressWeight(e, t, n) {
  var r = Math.exp(t * n * n);
  return n <= e ? r : 0;
}

function ascendingComparator(e, t) {
  return e.score - t.score || e.score === t.score && t.boxIndex - e.boxIndex;
}

function nonMaxSuppressionAsync_(_x77, _x78, _x79) {
  return _nonMaxSuppressionAsync_.apply(this, arguments);
}

function _nonMaxSuppressionAsync_() {
  _nonMaxSuppressionAsync_ = _asyncToGenerator(function* (e, t, n) {
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : .5;
    var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : Number.NEGATIVE_INFINITY;
    var s = convertToTensor(e, "boxes", "nonMaxSuppressionAsync"),
        o = convertToTensor(t, "scores", "nonMaxSuppressionAsync"),
        i = nonMaxSuppSanityCheck(s, o, n, r, a);
    n = i.maxOutputSize, r = i.iouThreshold, a = i.scoreThreshold;
    var l = yield Promise.all([s.data(), o.data()]),
        u = l[0],
        c = l[1],
        {
      selectedIndices: p
    } = nonMaxSuppressionV3Impl$2(u, c, n, r, a);
    return s !== e && s.dispose(), o !== t && o.dispose(), tensor1d(p, "int32");
  });
  return _nonMaxSuppressionAsync_.apply(this, arguments);
}

var nonMaxSuppressionAsync = nonMaxSuppressionAsync_;

function nonMaxSuppressionWithScore_(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : .5;
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : Number.NEGATIVE_INFINITY;
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : 0;
  var o = convertToTensor(e, "boxes", "nonMaxSuppression"),
      i = convertToTensor(t, "scores", "nonMaxSuppression"),
      l = nonMaxSuppSanityCheck(o, i, n, r, a, s),
      u = ENGINE.runKernel(NonMaxSuppressionV5, {
    boxes: o,
    scores: i
  }, {
    maxOutputSize: n = l.maxOutputSize,
    iouThreshold: r = l.iouThreshold,
    scoreThreshold: a = l.scoreThreshold,
    softNmsSigma: s = l.softNmsSigma
  });
  return {
    selectedIndices: u[0],
    selectedScores: u[1]
  };
}

var nonMaxSuppressionWithScore = op({
  nonMaxSuppressionWithScore_
});

function nonMaxSuppressionWithScoreAsync_(_x80, _x81, _x82) {
  return _nonMaxSuppressionWithScoreAsync_.apply(this, arguments);
}

function _nonMaxSuppressionWithScoreAsync_() {
  _nonMaxSuppressionWithScoreAsync_ = _asyncToGenerator(function* (e, t, n) {
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : .5;
    var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : Number.NEGATIVE_INFINITY;
    var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : 0;
    var o = convertToTensor(e, "boxes", "nonMaxSuppressionAsync"),
        i = convertToTensor(t, "scores", "nonMaxSuppressionAsync"),
        l = nonMaxSuppSanityCheck(o, i, n, r, a, s);
    n = l.maxOutputSize, r = l.iouThreshold, a = l.scoreThreshold, s = l.softNmsSigma;
    var u = yield Promise.all([o.data(), i.data()]),
        c = u[0],
        p = u[1],
        {
      selectedIndices: d,
      selectedScores: h
    } = nonMaxSuppressionV5Impl$2(c, p, n, r, a, s);
    return o !== e && o.dispose(), i !== t && i.dispose(), {
      selectedIndices: tensor1d(d, "int32"),
      selectedScores: tensor1d(h)
    };
  });
  return _nonMaxSuppressionWithScoreAsync_.apply(this, arguments);
}

var nonMaxSuppressionWithScoreAsync = nonMaxSuppressionWithScoreAsync_;

function nonMaxSuppressionPadded_(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : .5;
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : Number.NEGATIVE_INFINITY;
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : !1;
  var o = convertToTensor(e, "boxes", "nonMaxSuppression"),
      i = convertToTensor(t, "scores", "nonMaxSuppression"),
      l = nonMaxSuppSanityCheck(o, i, n, r, a, null),
      u = ENGINE.runKernel(NonMaxSuppressionV4, {
    boxes: o,
    scores: i
  }, {
    maxOutputSize: l.maxOutputSize,
    iouThreshold: l.iouThreshold,
    scoreThreshold: l.scoreThreshold,
    padToMaxOutputSize: s
  });
  return {
    selectedIndices: u[0],
    validOutputs: u[1]
  };
}

var nonMaxSuppressionPadded = op({
  nonMaxSuppressionPadded_
});

function nonMaxSuppressionPaddedAsync_(_x83, _x84, _x85) {
  return _nonMaxSuppressionPaddedAsync_.apply(this, arguments);
}

function _nonMaxSuppressionPaddedAsync_() {
  _nonMaxSuppressionPaddedAsync_ = _asyncToGenerator(function* (e, t, n) {
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : .5;
    var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : Number.NEGATIVE_INFINITY;
    var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : !1;
    var o = convertToTensor(e, "boxes", "nonMaxSuppressionAsync"),
        i = convertToTensor(t, "scores", "nonMaxSuppressionAsync"),
        l = nonMaxSuppSanityCheck(o, i, n, r, a, null),
        u = l.maxOutputSize,
        c = l.iouThreshold,
        p = l.scoreThreshold,
        [d, h] = yield Promise.all([o.data(), i.data()]),
        {
      selectedIndices: m,
      validOutputs: f
    } = nonMaxSuppressionV4Impl$2(d, h, u, c, p, s);
    return o !== e && o.dispose(), i !== t && i.dispose(), {
      selectedIndices: tensor1d(m, "int32"),
      validOutputs: scalar(f, "int32")
    };
  });
  return _nonMaxSuppressionPaddedAsync_.apply(this, arguments);
}

var nonMaxSuppressionPaddedAsync = nonMaxSuppressionPaddedAsync_;

function resizeBilinear_(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
  var a = convertToTensor(e, "images", "resizeBilinear");
  assert$4(3 === a.rank || 4 === a.rank, () => "Error in resizeBilinear: x must be rank 3 or 4, but got rank ".concat(a.rank, ".")), assert$4(2 === t.length, () => "Error in resizeBilinear: new shape must 2D, but got shape ".concat(t, ".")), assert$4(!1 === r || !1 === n, () => "Error in resizeBilinear: If halfPixelCenters is true, alignCorners must be false.");
  var s = a,
      o = !1;
  3 === a.rank && (o = !0, s = reshape$3(a, [1, a.shape[0], a.shape[1], a.shape[2]]));
  var i = ENGINE.runKernel(ResizeBilinear, {
    images: s
  }, {
    alignCorners: n,
    halfPixelCenters: r,
    size: t
  });
  return o ? reshape$3(i, [i.shape[1], i.shape[2], i.shape[3]]) : i;
}

var resizeBilinear$2 = op({
  resizeBilinear_
});

function resizeNearestNeighbor_(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
  var a = convertToTensor(e, "images", "resizeNearestNeighbor");
  assert$4(3 === a.rank || 4 === a.rank, () => "Error in resizeNearestNeighbor: x must be rank 3 or 4, but got rank ".concat(a.rank, ".")), assert$4(2 === t.length, () => "Error in resizeNearestNeighbor: new shape must 2D, but got shape ".concat(t, ".")), assert$4("float32" === a.dtype || "int32" === a.dtype, () => "`images` must have `int32` or `float32` as dtype"), assert$4(!1 === r || !1 === n, () => "Error in resizeNearestNeighbor: If halfPixelCenters is true, alignCorners must be false.");
  var s = a,
      o = !1;
  3 === a.rank && (o = !0, s = reshape$3(a, [1, a.shape[0], a.shape[1], a.shape[2]]));
  var i = ENGINE.runKernel(ResizeNearestNeighbor, {
    images: s
  }, {
    alignCorners: n,
    halfPixelCenters: r,
    size: t
  });
  return o ? reshape$3(i, [i.shape[1], i.shape[2], i.shape[3]]) : i;
}

var resizeNearestNeighbor$2 = op({
  resizeNearestNeighbor_
});

function threshold_(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : "binary";
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : .5;
  var a = convertToTensor(e, "image", "threshold"),
      s = a.shape[0] * a.shape[1];
  var o,
      i,
      l,
      u,
      c = mul(tensor1d([r]), 255);

  if (assert$4(3 === a.rank, () => "Error in threshold: image must be rank 3,but got rank ".concat(a.rank, ".")), assert$4(3 === a.shape[2] || 1 === a.shape[2], () => "Error in threshold: image color channel must be equal to 3 or 1but got ".concat(a.shape[2], ".")), assert$4("int32" === a.dtype || "float32" === a.dtype, () => "Error in dtype: image dtype must be int32 or float32,but got dtype ".concat(a.dtype, ".")), assert$4("otsu" === t || "binary" === t, () => "Method must be binary or otsu, but was ".concat(t)), 3 === a.shape[2]) {
    [o, i, l] = split$2(a, [1, 1, 1], -1);

    var _e600 = mul(o, .2989),
        _t416 = mul(i, .587),
        _n237 = mul(l, .114);

    u = add$2(add$2(_e600, _t416), _n237);
  } else u = e;

  "otsu" === t && (c = otsu(bincount$2(cast$3(round$2(u), "int32"), tensor([]), 256), s));
  var p = n ? lessEqual$2(u, c) : greater$3(u, c);
  return cast$3(mul(p, 255), "int32");
}

function otsu(e, t) {
  var n,
      r,
      a,
      s,
      o,
      i,
      l = tensor1d([-1]),
      u = tensor1d([0]),
      c = tensor1d([0]);

  for (var _p22 = 0; _p22 < e.size - 1; _p22++) {
    n = slice$2(e, 0, _p22 + 1), r = slice$2(e, _p22 + 1), o = div$1(sum$2(n), t), i = div$1(sum$2(r), t);
    var d = sum$2(mul(n, range$4(0, n.size)));
    a = div$1(d, sum$2(n));
    var h = fill$2(r.shape, n.size),
        m = add$2(range$4(0, r.size), h),
        f = mul(r, m);
    s = div$1(sum$2(f), sum$2(r));
    var g = sub$2(a, s),
        $ = sub$2(a, s),
        y = mul(o, i);
    c = mul(mul(y, g), $);
    var b = greater$3(c, u);
    u = where(b, c, u), l = where(b, tensor1d([_p22]), l);
  }

  return l;
}

var threshold$1 = op({
  threshold_
});

function transform_(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : "nearest";
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : "constant";
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : 0;
  var s = arguments.length > 5 ? arguments[5] : undefined;
  var o = convertToTensor(e, "image", "transform", "float32"),
      i = convertToTensor(t, "transforms", "transform", "float32");
  return assert$4(4 === o.rank, () => "Error in transform: image must be rank 4,but got rank ".concat(o.rank, ".")), assert$4(2 === i.rank && (i.shape[0] === o.shape[0] || 1 === i.shape[0]) && 8 === i.shape[1], () => "Error in transform: Input transform should be batch x 8 or 1 x 8"), assert$4(null == s || 2 === s.length, () => "Error in transform: outputShape must be [height, width] or null, but got ".concat(s, ".")), ENGINE.runKernel(Transform, {
    image: o,
    transforms: i
  }, {
    interpolation: n,
    fillMode: r,
    fillValue: a,
    outputShape: s
  });
}

var transform$2 = op({
  transform_
});

function bandPart_(e, t, n) {
  assert$4(t % 1 == 0, () => "bandPart(): numLower must be an integer, got ".concat(t, ".")), assert$4(n % 1 == 0, () => "bandPart(): numUpper must be an integer, got ".concat(n, "."));
  var r = convertToTensor(e, "a", "bandPart");
  assert$4(r.rank >= 2, () => "bandPart(): Rank must be at least 2, got ".concat(r.rank, "."));
  var a = r.shape,
      [s, o] = r.shape.slice(-2);
  if (!(t <= s)) throw new Error("bandPart(): numLower (".concat(t, ") must not be greater than the number of rows (").concat(s, ")."));
  if (!(n <= o)) throw new Error("bandPart(): numUpper (".concat(n, ") must not be greater than the number of columns (").concat(o, ")."));
  t < 0 && (t = s), n < 0 && (n = o);
  var i = reshape$3(range$4(0, s, 1, "int32"), [-1, 1]),
      l = range$4(0, o, 1, "int32"),
      u = sub$2(i, l),
      c = logicalAnd$2(lessEqual$2(u, scalar(+t, "int32")), greaterEqual$2(u, scalar(-n, "int32"))),
      p = zeros$2([s, o], r.dtype);
  return reshape$3(stack(unstack(reshape$3(r, [-1, s, o])).map(e => where(c, e, p))), a);
}

var bandPart = op({
  bandPart_
});

function gramSchmidt_(e) {
  var t;

  if (Array.isArray(e)) {
    (function () {
      t = !1, assert$4(null != e && e.length > 0, () => "Gram-Schmidt process: input must not be null, undefined, or empty");
      var n = e[0].shape[0];

      var _loop33 = function _loop33(_t417) {
        assert$4(e[_t417].shape[0] === n, () => "Gram-Schmidt: Non-unique lengths found in the input vectors: (".concat(e[_t417].shape[0], " vs. ").concat(n, ")"));
      };

      for (var _t417 = 1; _t417 < e.length; ++_t417) {
        _loop33(_t417);
      }
    })();
  } else t = !0, e = split$2(e, e.shape[0], 0).map(e => squeeze(e, [0]));

  assert$4(e.length <= e[0].shape[0], () => "Gram-Schmidt: Number of vectors (".concat(e.length, ") exceeds number of dimensions (").concat(e[0].shape[0], ")."));
  var n = [],
      r = e;

  var _loop34 = function _loop34(_t418) {
    n.push(ENGINE.tidy(() => {
      var e = r[_t418];
      if (_t418 > 0) for (var _r200 = 0; _r200 < _t418; ++_r200) {
        var _t419 = mul(sum$2(mul(n[_r200], e)), n[_r200]);

        e = sub$2(e, _t419);
      }
      return div$1(e, norm(e, "euclidean"));
    }));
  };

  for (var _t418 = 0; _t418 < e.length; ++_t418) {
    _loop34(_t418);
  }

  return t ? stack(n, 0) : n;
}

var gramSchmidt = op({
  gramSchmidt_
});

function qr_(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;
  if (assert$4(e.rank >= 2, () => "qr() requires input tensor to have a rank >= 2, but got rank ".concat(e.rank)), 2 === e.rank) return qr2d(e, t);
  {
    var n = e.shape.slice(0, e.shape.length - 2).reduce((e, t) => e * t),
        r = unstack(reshape$3(e, [n, e.shape[e.shape.length - 2], e.shape[e.shape.length - 1]]), 0),
        a = [],
        s = [];
    return r.forEach(e => {
      var [n, r] = qr2d(e, t);
      a.push(n), s.push(r);
    }), [reshape$3(stack(a, 0), e.shape), reshape$3(stack(s, 0), e.shape)];
  }
}

function qr2d(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;
  return ENGINE.tidy(() => {
    assert$4(2 === e.shape.length, () => "qr2d() requires a 2D Tensor, but got a ".concat(e.shape.length, "D Tensor."));
    var n = e.shape[0],
        r = e.shape[1];
    var a = eye(n),
        s = clone(e);
    var o = tensor2d([[1]], [1, 1]);
    var i = clone(o);
    var l = n >= r ? r : n;

    var _loop35 = function _loop35(_e601) {
      var t = s,
          l = i,
          u = a;
      [i, s, a] = ENGINE.tidy(() => {
        var t = slice$2(s, [_e601, _e601], [n - _e601, 1]),
            l = norm(t),
            u = slice$2(s, [_e601, _e601], [1, 1]),
            c = where(greater$3(u, 0), tensor2d([[-1]]), tensor2d([[1]])),
            p = sub$2(u, mul(c, l)),
            d = div$1(t, p);
        i = 1 === d.shape[0] ? clone(o) : concat$2([o, slice$2(d, [1, 0], [d.shape[0] - 1, d.shape[1]])], 0);
        var h = neg$2(div$1(matMul$1(c, p), l)),
            m = slice$2(s, [_e601, 0], [n - _e601, r]),
            f = mul(h, i),
            g = transpose$2(i);
        if (0 === _e601) s = sub$2(m, matMul$1(f, matMul$1(g, m)));else {
          var _t420 = sub$2(m, matMul$1(f, matMul$1(g, m)));

          s = concat$2([slice$2(s, [0, 0], [_e601, r]), _t420], 0);
        }
        var $ = transpose$2(f),
            y = slice$2(a, [0, _e601], [n, a.shape[1] - _e601]);
        if (0 === _e601) a = sub$2(y, matMul$1(matMul$1(y, i), $));else {
          var _t421 = sub$2(y, matMul$1(matMul$1(y, i), $));

          a = concat$2([slice$2(a, [0, 0], [n, _e601]), _t421], 1);
        }
        return [i, s, a];
      }), dispose([t, l, u]);
    };

    for (var _e601 = 0; _e601 < l; ++_e601) {
      _loop35(_e601);
    }

    return !t && n > r && (a = slice$2(a, [0, 0], [n, r]), s = slice$2(s, [0, 0], [r, r])), [a, s];
  });
}

var qr = op({
  qr_
});
var Reduction;

function computeWeightedLoss_(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : Reduction.SUM_BY_NONZERO_WEIGHTS;
  var r = convertToTensor(e, "losses", "computeWeightedLoss");
  var a = null;
  null != t && (a = convertToTensor(t, "weights", "computeWeightedLoss"));
  var s = null == a ? r : mul(r, a);
  if (n === Reduction.NONE) return s;
  if (n === Reduction.SUM) return sum$2(s);

  if (n === Reduction.MEAN) {
    if (null == a) return mean$1(s);
    {
      var _e602 = r.size / a.size,
          _t422 = div$1(sum$2(s), sum$2(a));

      return _e602 > 1 ? div$1(_t422, scalar(_e602)) : _t422;
    }
  }

  if (n === Reduction.SUM_BY_NONZERO_WEIGHTS) {
    if (null == a) return div$1(sum$2(s), scalar(r.size));
    {
      var _e603 = mul(a, ones$1(r.shape)),
          _t423 = cast$3(sum$2(notEqual$2(_e603, scalar(0))), "float32");

      return div$1(sum$2(s), _t423);
    }
  }

  throw Error("Unknown reduction: ".concat(n));
}

!function (e) {
  e[e.NONE = 0] = "NONE", e[e.MEAN = 1] = "MEAN", e[e.SUM = 2] = "SUM", e[e.SUM_BY_NONZERO_WEIGHTS = 3] = "SUM_BY_NONZERO_WEIGHTS";
}(Reduction || (Reduction = {}));
var computeWeightedLoss$1 = op({
  computeWeightedLoss_
});

function absoluteDifference_(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : Reduction.SUM_BY_NONZERO_WEIGHTS;
  var a = convertToTensor(e, "labels", "absoluteDifference"),
      s = convertToTensor(t, "predictions", "absoluteDifference");
  var o = null;
  null != n && (o = convertToTensor(n, "weights", "absoluteDifference")), assertShapesMatch(a.shape, s.shape, "Error in absoluteDifference: ");
  var i = abs$2(sub$2(a, s));
  return computeWeightedLoss$1(i, o, r);
}

var absoluteDifference = op({
  absoluteDifference_
});

function cosineDistance_(e, t, n, r) {
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : Reduction.SUM_BY_NONZERO_WEIGHTS;
  var s = convertToTensor(e, "labels", "cosineDistance"),
      o = convertToTensor(t, "predictions", "cosineDistance");
  var i = null;
  null != r && (i = convertToTensor(r, "weights", "cosineDistance")), assertShapesMatch(s.shape, o.shape, "Error in cosineDistance: ");
  var l = scalar(1),
      u = sub$2(l, sum$2(mul(s, o), n, !0));
  return computeWeightedLoss$1(u, i, a);
}

var cosineDistance = op({
  cosineDistance_
});

function hingeLoss_(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : Reduction.SUM_BY_NONZERO_WEIGHTS;
  var a = convertToTensor(e, "labels", "hingeLoss");
  var s = convertToTensor(t, "predictions", "hingeLoss");
  var o = null;
  null != n && (o = convertToTensor(n, "weights", "hingeLoss")), assertShapesMatch(a.shape, s.shape, "Error in hingeLoss: ");
  var i = scalar(1);
  a = sub$2(mul(scalar(2), a), i);
  var l = relu$3(sub$2(i, mul(a, s)));
  return computeWeightedLoss$1(l, o, r);
}

var hingeLoss = op({
  hingeLoss_
});

function huberLoss_(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 1;
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : Reduction.SUM_BY_NONZERO_WEIGHTS;
  var s = convertToTensor(e, "labels", "huberLoss"),
      o = convertToTensor(t, "predictions", "huberLoss");
  var i = null;
  null != n && (i = convertToTensor(n, "weights", "huberLoss")), assertShapesMatch(s.shape, o.shape, "Error in huberLoss: ");
  var l = scalar(r),
      u = abs$2(sub$2(o, s)),
      c = minimum$3(u, l),
      p = sub$2(u, c),
      d = add$2(mul(scalar(.5), square$2(c)), mul(l, p));
  return computeWeightedLoss$1(d, i, a);
}

var huberLoss = op({
  huberLoss_
});

function logLoss_(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 1e-7;
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : Reduction.SUM_BY_NONZERO_WEIGHTS;
  var s = convertToTensor(e, "labels", "logLoss"),
      o = convertToTensor(t, "predictions", "logLoss");
  var i = null;
  null != n && (i = convertToTensor(n, "weights", "logLoss")), assertShapesMatch(s.shape, o.shape, "Error in logLoss: ");
  var l = scalar(1),
      u = scalar(r),
      c = neg$2(mul(s, log$3(add$2(o, u)))),
      p = mul(sub$2(l, s), log$3(add$2(sub$2(l, o), u))),
      d = sub$2(c, p);
  return computeWeightedLoss$1(d, i, a);
}

var logLoss = op({
  logLoss_
});

function meanSquaredError_(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : Reduction.SUM_BY_NONZERO_WEIGHTS;
  var a = convertToTensor(e, "labels", "meanSquaredError"),
      s = convertToTensor(t, "predictions", "meanSquaredError");
  var o = null;
  null != n && (o = convertToTensor(n, "weights", "meanSquaredError")), assertShapesMatch(a.shape, s.shape, "Error in meanSquaredError: ");
  var i = squaredDifference$2(a, s);
  return computeWeightedLoss$1(i, o, r);
}

var meanSquaredError$2 = op({
  meanSquaredError_
});

function sigmoidCrossEntropyWithLogits_(e, t) {
  var n = convertToTensor(e, "labels", "sigmoidCrossEntropyWithLogits"),
      r = convertToTensor(t, "logits", "sigmoidCrossEntropyWithLogits");
  assertShapesMatch(n.shape, r.shape, "Error in sigmoidCrossEntropyWithLogits: ");
  var a = relu$3(r),
      s = mul(r, n),
      o = log1p$2(exp$2(neg$2(abs$2(r))));
  return add$2(sub$2(a, s), o);
}

function sigmoidCrossEntropy_(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 0;
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : Reduction.SUM_BY_NONZERO_WEIGHTS;
  var s = convertToTensor(e, "multiClassLabels", "sigmoidCrossEntropy");
  var o = convertToTensor(t, "logits", "sigmoidCrossEntropy");
  var i = null;

  if (null != n && (i = convertToTensor(n, "weights", "sigmoidCrossEntropy")), assertShapesMatch(s.shape, o.shape, "Error in sigmoidCrossEntropy: "), r > 0) {
    var _e604 = scalar(r),
        _t424 = scalar(1),
        _n238 = scalar(.5);

    s = add$2(mul(s, sub$2(_t424, _e604)), mul(_n238, _e604));
  }

  var l = sigmoidCrossEntropyWithLogits_(s, o);
  return computeWeightedLoss$1(l, i, a);
}

var sigmoidCrossEntropy = op({
  sigmoidCrossEntropy_
});

function softmaxCrossEntropyWithLogits_(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : -1;
  if (-1 === n && (n = t.rank - 1), n !== t.rank - 1) throw Error("Softmax cross entropy along a non-last dimension is not yet supported. Labels / logits was rank ".concat(t.rank, " and dim was ").concat(n));
  var r = customGrad((e, t, r) => {
    var a = logSumExp(t, [n], !0),
        s = sub$2(cast$3(t, "float32"), a);
    r([e, s]);
    var o = neg$2(mul(s, e));
    return {
      value: sum$2(o, [n]),
      gradFunc: (e, t) => {
        var [r, a] = t,
            s = expandShapeToKeepDim(e.shape, [n]);
        return [mul(reshape$3(e, s), sub$2(cast$3(r, "float32"), exp$2(a))), mul(reshape$3(e, s), sub$2(exp$2(a), cast$3(r, "float32")))];
      }
    };
  });
  return r(e, t);
}

function softmaxCrossEntropy_(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 0;
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : Reduction.SUM_BY_NONZERO_WEIGHTS;
  var s = convertToTensor(e, "onehotLabels", "softmaxCrossEntropy");
  var o = convertToTensor(t, "logits", "softmaxCrossEntropy");
  var i = null;

  if (null != n && (i = convertToTensor(n, "weights", "softmaxCrossEntropy")), assertShapesMatch(s.shape, o.shape, "Error in softmaxCrossEntropy: "), r > 0) {
    var _e605 = scalar(r),
        _t425 = scalar(1),
        _n239 = scalar(s.shape[1]);

    s = add$2(mul(s, sub$2(_t425, _e605)), div$1(_e605, _n239));
  }

  var l = softmaxCrossEntropyWithLogits_(s, o);
  return computeWeightedLoss$1(l, i, a);
}

var softmaxCrossEntropy = op({
  softmaxCrossEntropy_
});

function sparseFillEmptyRows_(e, t, n, r) {
  var a = convertToTensor(e, "indices", "sparseFillEmptyRows"),
      s = convertToTensor(t, "values", "sparseFillEmptyRows"),
      o = convertToTensor(n, "denseShape", "sparseFillEmptyRows"),
      i = convertToTensor(r, "defaultValue", "sparseFillEmptyRows", s.dtype);
  if (2 !== a.rank) throw new Error("Indices should be Tensor2D but received shape\n        ".concat(a.shape));
  if (1 !== s.rank) throw new Error("Values should be Tensor1D but received shape ".concat(s.shape));
  if (1 !== o.rank) throw new Error("Dense shape should be Tensor1D but received shape ".concat(o.shape));
  if (0 !== i.rank) throw new Error("Default value should be a scalar but received shape ".concat(i.shape));
  var l = ENGINE.runKernel(SparseFillEmptyRows, {
    indices: a,
    values: s,
    denseShape: o,
    defaultValue: i
  });
  return {
    outputIndices: l[0],
    outputValues: l[1],
    emptyRowIndicator: l[2],
    reverseIndexMap: l[3]
  };
}

var sparseFillEmptyRows$2 = op({
  sparseFillEmptyRows_
});

function sparseReshape_(e, t, n) {
  var r = convertToTensor(e, "inputIndices", "sparseReshape"),
      a = convertToTensor(t, "inputShape", "sparseReshape"),
      s = convertToTensor(n, "newShape", "sparseReshape");
  if (2 !== r.rank) throw new Error("Input indices should be Tensor2D but received shape\n        ".concat(r.shape));
  if (1 !== a.rank) throw new Error("Input shape should be Tensor1D but received shape ".concat(a.shape));
  if (1 !== s.rank) throw new Error("New shape should be Tensor1D but received shape ".concat(s.shape));
  var o = ENGINE.runKernel(SparseReshape, {
    inputIndices: r,
    inputShape: a,
    newShape: s
  });
  return {
    outputIndices: o[0],
    outputShape: o[1]
  };
}

var sparseReshape$2 = op({
  sparseReshape_
});

function sparseSegmentMean_(e, t, n) {
  var r = convertToTensor(e, "data", "sparseSegmentMean"),
      a = convertToTensor(t, "indices", "sparseSegmentMean"),
      s = convertToTensor(n, "segmentIds", "sparseSegmentMean");
  if (r.rank < 1) throw new Error("Data should be at least 1 dimensional but received scalar");
  if (1 !== a.rank) throw new Error("Indices should be Tensor1D but received shape\n          ".concat(a.shape));
  if (1 !== s.rank) throw new Error("Segment ids should be Tensor1D but received shape\n          ".concat(s.shape));
  return ENGINE.runKernel(SparseSegmentMean, {
    data: r,
    indices: a,
    segmentIds: s
  });
}

var sparseSegmentMean$2 = op({
  sparseSegmentMean_
});

function sparseSegmentSum_(e, t, n) {
  var r = convertToTensor(e, "data", "sparseSegmentSum"),
      a = convertToTensor(t, "indices", "sparseSegmentSum"),
      s = convertToTensor(n, "segmentIds", "sparseSegmentSum");
  if (r.rank < 1) throw new Error("Data should be at least 1 dimensional but received scalar");
  if (1 !== a.rank) throw new Error("Indices should be Tensor1D but received shape\n         ".concat(a.shape));
  if (1 !== s.rank) throw new Error("Segment ids should be Tensor1D but received shape\n         ".concat(s.shape));
  return ENGINE.runKernel(SparseSegmentSum, {
    data: r,
    indices: a,
    segmentIds: s
  });
}

var sparseSegmentSum$2 = op({
  sparseSegmentSum_
});

function stringNGrams_(e, t, n, r, a, s, o, i) {
  var l = convertToTensor(e, "data", "stringNGrams", "string");
  if ("string" !== l.dtype) throw new Error("Data must be of datatype string");
  if (1 !== l.shape.length) throw new Error("Data must be a vector, saw: ".concat(l.shape));
  var u = convertToTensor(t, "dataSplits", "stringNGrams");
  if ("int32" !== u.dtype) throw new Error("Data splits must be of datatype int32");
  var c = ENGINE.runKernel(StringNGrams, {
    data: l,
    dataSplits: u
  }, {
    separator: n,
    nGramWidths: r,
    leftPad: a,
    rightPad: s,
    padWidth: o,
    preserveShortSequences: i
  });
  return {
    nGrams: c[0],
    nGramsSplits: c[1]
  };
}

var stringNGrams$2 = op({
  stringNGrams_
});

function stringSplit_(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !0;
  var r = convertToTensor(e, "input", "stringSplit", "string"),
      a = convertToTensor(t, "delimiter", "stringSplit", "string");
  if (1 !== r.rank) throw new Error("Input should be Tensor1D but received shape ".concat(r.shape));
  if (0 !== a.rank) throw new Error("Delimiter should be a scalar but received shape ".concat(a.shape));
  var s = ENGINE.runKernel(StringSplit, {
    input: r,
    delimiter: a
  }, {
    skipEmpty: n
  });
  return {
    indices: s[0],
    values: s[1],
    shape: s[2]
  };
}

var stringSplit$2 = op({
  stringSplit_
});

function stringToHashBucketFast_(e, t) {
  var n = convertToTensor(e, "input", "stringToHashBucketFast", "string"),
      r = {
    numBuckets: t
  };
  if (t <= 0) throw new Error("Number of buckets must be at least 1");
  return ENGINE.runKernel(StringToHashBucketFast, {
    input: n
  }, r);
}

var stringToHashBucketFast$2 = op({
  stringToHashBucketFast_
}),
    spectral$1 = {
  fft: fft$2,
  ifft: ifft$2,
  rfft,
  irfft
},
    signal = {
  hammingWindow,
  hannWindow,
  frame,
  stft
},
    image$1 = {
  flipLeftRight,
  resizeNearestNeighbor: resizeNearestNeighbor$2,
  resizeBilinear: resizeBilinear$2,
  rotateWithOffset,
  cropAndResize: cropAndResize$2,
  nonMaxSuppression,
  nonMaxSuppressionAsync,
  nonMaxSuppressionWithScore,
  nonMaxSuppressionWithScoreAsync,
  nonMaxSuppressionPadded,
  nonMaxSuppressionPaddedAsync,
  threshold: threshold$1,
  transform: transform$2
},
    linalg = {
  bandPart,
  gramSchmidt,
  qr
},
    losses = {
  absoluteDifference,
  computeWeightedLoss: computeWeightedLoss$1,
  cosineDistance,
  hingeLoss,
  huberLoss,
  logLoss,
  meanSquaredError: meanSquaredError$2,
  sigmoidCrossEntropy,
  softmaxCrossEntropy
},
    sparse$1 = {
  sparseFillEmptyRows: sparseFillEmptyRows$2,
  sparseReshape: sparseReshape$2,
  sparseSegmentMean: sparseSegmentMean$2,
  sparseSegmentSum: sparseSegmentSum$2
},
    string$1 = {
  stringNGrams: stringNGrams$2,
  stringSplit: stringSplit$2,
  stringToHashBucketFast: stringToHashBucketFast$2
};

class Optimizer extends Serializable {
  minimize(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;
    var n = arguments.length > 2 ? arguments[2] : undefined;
    var {
      value: r,
      grads: a
    } = this.computeGradients(e, n);

    if (null != n) {
      var _e606 = n.map(e => ({
        name: e.name,
        tensor: a[e.name]
      }));

      this.applyGradients(_e606);
    } else this.applyGradients(a);

    return dispose(a), t ? r : (r.dispose(), null);
  }

  get iterations() {
    return null == this.iterations_ && (this.iterations_ = 0), this.iterations_;
  }

  incrementIterations() {
    this.iterations_ = this.iterations + 1;
  }

  computeGradients(e, t) {
    return variableGrads(e, t);
  }

  dispose() {
    null != this.iterations_ && dispose(this.iterations_);
  }

  saveIterations() {
    var _this101 = this;

    return _asyncToGenerator(function* () {
      return null == _this101.iterations_ && (_this101.iterations_ = 0), {
        name: "iter",
        tensor: scalar(_this101.iterations_, "int32")
      };
    })();
  }

  getWeights() {
    return _asyncToGenerator(function* () {
      throw new Error("getWeights() is not implemented for this optimizer yet.");
    })();
  }

  setWeights(e) {
    var _this102 = this;

    return _asyncToGenerator(function* () {
      throw new Error("setWeights() is not implemented for this optimizer class ".concat(_this102.getClassName()));
    })();
  }

  extractIterations(e) {
    var _this103 = this;

    return _asyncToGenerator(function* () {
      return _this103.iterations_ = (yield e[0].tensor.data())[0], e.slice(1);
    })();
  }

}

Object.defineProperty(Optimizer, Symbol.hasInstance, {
  value: e => null != e.minimize && null != e.computeGradients && null != e.applyGradients
});

class AdadeltaOptimizer extends Optimizer {
  constructor(e, t) {
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;
    super(), this.learningRate = e, this.rho = t, this.epsilon = n, this.accumulatedGrads = [], this.accumulatedUpdates = [], null == n && (this.epsilon = ENGINE.backend.epsilon());
  }

  applyGradients(e) {
    (Array.isArray(e) ? e.map(e => e.name) : Object.keys(e)).forEach((t, n) => {
      var r = ENGINE.registeredVariables[t];
      null == this.accumulatedGrads[n] && (this.accumulatedGrads[n] = {
        originalName: "".concat(t, "/accum_grad"),
        variable: tidy(() => zerosLike$2(r).variable(!1))
      }), null == this.accumulatedUpdates[n] && (this.accumulatedUpdates[n] = {
        originalName: "".concat(t, "/accum_var"),
        variable: tidy(() => zerosLike$2(r).variable(!1))
      });
      var a = Array.isArray(e) ? e[n].tensor : e[t];
      if (null == a) return;
      var s = this.accumulatedGrads[n].variable,
          o = this.accumulatedUpdates[n].variable;
      tidy(() => {
        var e = add$2(mul(s, this.rho), mul(square$2(a), 1 - this.rho)),
            t = mul(div$1(sqrt$2(add$2(o, this.epsilon)), sqrt$2(add$2(s, this.epsilon))), a),
            n = add$2(mul(o, this.rho), mul(square$2(t), 1 - this.rho));
        s.assign(e), o.assign(n);
        var i = add$2(mul(t, -this.learningRate), r);
        r.assign(i);
      });
    }), this.incrementIterations();
  }

  dispose() {
    null != this.accumulatedUpdates && (dispose(this.accumulatedGrads.map(e => e.variable)), dispose(this.accumulatedUpdates.map(e => e.variable)));
  }

  getWeights() {
    var _this104 = this;

    return _asyncToGenerator(function* () {
      var e = [..._this104.accumulatedGrads, ..._this104.accumulatedUpdates];
      return [yield _this104.saveIterations()].concat(e.map(e => ({
        name: e.originalName,
        tensor: e.variable
      })));
    })();
  }

  setWeights(e) {
    var _this105 = this;

    return _asyncToGenerator(function* () {
      var t = (e = yield _this105.extractIterations(e)).length / 2;
      _this105.accumulatedGrads = e.slice(0, t).map(e => ({
        originalName: e.name,
        variable: e.tensor.variable(!1)
      })), _this105.accumulatedUpdates = e.slice(t, 2 * t).map(e => ({
        originalName: e.name,
        variable: e.tensor.variable(!1)
      }));
    })();
  }

  getConfig() {
    return {
      learningRate: this.learningRate,
      rho: this.rho,
      epsilon: this.epsilon
    };
  }

  static fromConfig(e, t) {
    return new e(t.learningRate, t.rho, t.epsilon);
  }

}

AdadeltaOptimizer.className = "Adadelta", registerClass(AdadeltaOptimizer);

class AdagradOptimizer extends Optimizer {
  constructor(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : .1;
    super(), this.learningRate = e, this.initialAccumulatorValue = t, this.accumulatedGrads = [];
  }

  applyGradients(e) {
    (Array.isArray(e) ? e.map(e => e.name) : Object.keys(e)).forEach((t, n) => {
      var r = ENGINE.registeredVariables[t];

      if (null == this.accumulatedGrads[n]) {
        var _e607 = !1;

        this.accumulatedGrads[n] = {
          originalName: "".concat(t, "/accumulator"),
          variable: tidy(() => fill$2(r.shape, this.initialAccumulatorValue).variable(_e607))
        };
      }

      var a = Array.isArray(e) ? e[n].tensor : e[t];
      if (null == a) return;
      var s = this.accumulatedGrads[n].variable;
      tidy(() => {
        var e = add$2(s, square$2(a));
        s.assign(e);
        var t = add$2(mul(div$1(a, sqrt$2(add$2(e, ENGINE.backend.epsilon()))), -this.learningRate), r);
        r.assign(t);
      });
    }), this.incrementIterations();
  }

  dispose() {
    null != this.accumulatedGrads && dispose(this.accumulatedGrads.map(e => e.variable));
  }

  getWeights() {
    var _this106 = this;

    return _asyncToGenerator(function* () {
      return [yield _this106.saveIterations()].concat(_this106.accumulatedGrads.map(e => ({
        name: e.originalName,
        tensor: e.variable
      })));
    })();
  }

  setWeights(e) {
    var _this107 = this;

    return _asyncToGenerator(function* () {
      e = yield _this107.extractIterations(e), _this107.accumulatedGrads = e.map(e => ({
        originalName: e.name,
        variable: e.tensor.variable(!1)
      }));
    })();
  }

  getConfig() {
    return {
      learningRate: this.learningRate,
      initialAccumulatorValue: this.initialAccumulatorValue
    };
  }

  static fromConfig(e, t) {
    return new e(t.learningRate, t.initialAccumulatorValue);
  }

}

AdagradOptimizer.className = "Adagrad", registerClass(AdagradOptimizer);

class AdamOptimizer extends Optimizer {
  constructor(e, t, n) {
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : null;
    super(), this.learningRate = e, this.beta1 = t, this.beta2 = n, this.epsilon = r, this.accumulatedFirstMoment = [], this.accumulatedSecondMoment = [], tidy(() => {
      this.accBeta1 = scalar(t).variable(), this.accBeta2 = scalar(n).variable();
    }), null == r && (this.epsilon = ENGINE.backend.epsilon());
  }

  applyGradients(e) {
    var t = Array.isArray(e) ? e.map(e => e.name) : Object.keys(e);
    tidy(() => {
      var n = sub$2(1, this.accBeta1),
          r = sub$2(1, this.accBeta2);
      t.forEach((t, a) => {
        var s = ENGINE.registeredVariables[t];
        null == this.accumulatedFirstMoment[a] && (this.accumulatedFirstMoment[a] = {
          originalName: "".concat(t, "/m"),
          variable: tidy(() => zerosLike$2(s).variable(!1))
        }), null == this.accumulatedSecondMoment[a] && (this.accumulatedSecondMoment[a] = {
          originalName: "".concat(t, "/v"),
          variable: tidy(() => zerosLike$2(s).variable(!1))
        });
        var o = Array.isArray(e) ? e[a].tensor : e[t];
        if (null == o) return;
        var i = this.accumulatedFirstMoment[a].variable,
            l = this.accumulatedSecondMoment[a].variable,
            u = add$2(mul(i, this.beta1), mul(o, 1 - this.beta1)),
            c = add$2(mul(l, this.beta2), mul(square$2(o), 1 - this.beta2)),
            p = div$1(u, n),
            d = div$1(c, r);
        i.assign(u), l.assign(c);
        var h = add$2(mul(div$1(p, add$2(sqrt$2(d), this.epsilon)), -this.learningRate), s);
        s.assign(h);
      }), this.accBeta1.assign(mul(this.accBeta1, this.beta1)), this.accBeta2.assign(mul(this.accBeta2, this.beta2));
    }), this.incrementIterations();
  }

  dispose() {
    this.accBeta1.dispose(), this.accBeta2.dispose(), null != this.accumulatedFirstMoment && dispose(this.accumulatedFirstMoment.map(e => e.variable)), null != this.accumulatedSecondMoment && dispose(this.accumulatedSecondMoment.map(e => e.variable));
  }

  getWeights() {
    var _this108 = this;

    return _asyncToGenerator(function* () {
      var e = [..._this108.accumulatedFirstMoment, ..._this108.accumulatedSecondMoment];
      return [yield _this108.saveIterations()].concat(e.map(e => ({
        name: e.originalName,
        tensor: e.variable
      })));
    })();
  }

  setWeights(e) {
    var _this109 = this;

    return _asyncToGenerator(function* () {
      e = yield _this109.extractIterations(e), tidy(() => {
        _this109.accBeta1.assign(pow$2(_this109.beta1, _this109.iterations_ + 1)), _this109.accBeta2.assign(pow$2(_this109.beta2, _this109.iterations_ + 1));
      });
      var t = e.length / 2;
      _this109.accumulatedFirstMoment = e.slice(0, t).map(e => ({
        originalName: e.name,
        variable: e.tensor.variable(!1)
      })), _this109.accumulatedSecondMoment = e.slice(t, 2 * t).map(e => ({
        originalName: e.name,
        variable: e.tensor.variable(!1)
      }));
    })();
  }

  getConfig() {
    return {
      learningRate: this.learningRate,
      beta1: this.beta1,
      beta2: this.beta2,
      epsilon: this.epsilon
    };
  }

  static fromConfig(e, t) {
    return new e(t.learningRate, t.beta1, t.beta2, t.epsilon);
  }

}

AdamOptimizer.className = "Adam", registerClass(AdamOptimizer);

class AdamaxOptimizer extends Optimizer {
  constructor(e, t, n) {
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : null;
    var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : 0;
    super(), this.learningRate = e, this.beta1 = t, this.beta2 = n, this.epsilon = r, this.decay = a, this.accumulatedFirstMoment = [], this.accumulatedWeightedInfNorm = [], tidy(() => {
      this.iteration = scalar(0).variable(), this.accBeta1 = scalar(t).variable();
    }), null == r && (this.epsilon = ENGINE.backend.epsilon());
  }

  applyGradients(e) {
    var t = Array.isArray(e) ? e.map(e => e.name) : Object.keys(e);
    tidy(() => {
      var n = sub$2(1, this.accBeta1),
          r = div$1(-this.learningRate, add$2(mul(this.iteration, this.decay), 1));
      t.forEach((t, a) => {
        var s = ENGINE.registeredVariables[t];
        null == this.accumulatedFirstMoment[a] && (this.accumulatedFirstMoment[a] = {
          originalName: "".concat(t, "/m"),
          variable: zerosLike$2(s).variable(!1)
        }), null == this.accumulatedWeightedInfNorm[a] && (this.accumulatedWeightedInfNorm[a] = {
          originalName: "".concat(t, "/v"),
          variable: zerosLike$2(s).variable(!1)
        });
        var o = Array.isArray(e) ? e[a].tensor : e[t];
        if (null == o) return;
        var i = this.accumulatedFirstMoment[a].variable,
            l = this.accumulatedWeightedInfNorm[a].variable,
            u = add$2(mul(i, this.beta1), mul(o, 1 - this.beta1)),
            c = mul(l, this.beta2),
            p = abs$2(o),
            d = maximum$3(c, p);
        i.assign(u), l.assign(d);
        var h = add$2(mul(div$1(r, n), div$1(u, add$2(d, this.epsilon))), s);
        s.assign(h);
      }), this.iteration.assign(add$2(this.iteration, 1)), this.accBeta1.assign(mul(this.accBeta1, this.beta1));
    }), this.incrementIterations();
  }

  dispose() {
    this.accBeta1.dispose(), this.iteration.dispose(), null != this.accumulatedFirstMoment && dispose(this.accumulatedFirstMoment.map(e => e.variable)), null != this.accumulatedWeightedInfNorm && dispose(this.accumulatedWeightedInfNorm.map(e => e.variable));
  }

  getWeights() {
    return _asyncToGenerator(function* () {
      throw new Error("getWeights() is not implemented for Adamax yet.");
    })();
  }

  setWeights(e) {
    return _asyncToGenerator(function* () {
      throw new Error("setWeights() is not implemented for Adamax yet.");
    })();
  }

  getConfig() {
    return {
      learningRate: this.learningRate,
      beta1: this.beta1,
      beta2: this.beta2,
      epsilon: this.epsilon,
      decay: this.decay
    };
  }

  static fromConfig(e, t) {
    return new e(t.learningRate, t.beta1, t.beta2, t.epsilon, t.decay);
  }

}

AdamaxOptimizer.className = "Adamax", registerClass(AdamaxOptimizer);

class SGDOptimizer extends Optimizer {
  constructor(e) {
    super(), this.learningRate = e, this.setLearningRate(e);
  }

  applyGradients(e) {
    (Array.isArray(e) ? e.map(e => e.name) : Object.keys(e)).forEach((t, n) => {
      var r = Array.isArray(e) ? e[n].tensor : e[t];
      if (null == r) return;
      var a = ENGINE.registeredVariables[t];
      tidy(() => {
        var e = add$2(mul(this.c, r), a);
        a.assign(e);
      });
    }), this.incrementIterations();
  }

  setLearningRate(e) {
    this.learningRate = e, null != this.c && this.c.dispose(), this.c = keep(scalar(-e));
  }

  dispose() {
    this.c.dispose();
  }

  getWeights() {
    var _this110 = this;

    return _asyncToGenerator(function* () {
      return [yield _this110.saveIterations()];
    })();
  }

  setWeights(e) {
    var _this111 = this;

    return _asyncToGenerator(function* () {
      if (0 !== (e = yield _this111.extractIterations(e)).length) throw new Error("SGD optimizer does not have settable weights.");
    })();
  }

  getConfig() {
    return {
      learningRate: this.learningRate
    };
  }

  static fromConfig(e, t) {
    return new e(t.learningRate);
  }

}

SGDOptimizer.className = "SGD", registerClass(SGDOptimizer);

class MomentumOptimizer extends SGDOptimizer {
  constructor(e, t) {
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
    super(e), this.learningRate = e, this.momentum = t, this.useNesterov = n, this.accumulations = [], this.m = scalar(this.momentum);
  }

  applyGradients(e) {
    (Array.isArray(e) ? e.map(e => e.name) : Object.keys(e)).forEach((t, n) => {
      var r = ENGINE.registeredVariables[t];

      if (null == this.accumulations[n]) {
        var _e608 = !1;

        this.accumulations[n] = {
          originalName: "".concat(t, "/momentum"),
          variable: tidy(() => zerosLike$2(r).variable(_e608))
        };
      }

      var a = this.accumulations[n].variable,
          s = Array.isArray(e) ? e[n].tensor : e[t];
      null != s && tidy(() => {
        var e;
        var t = add$2(mul(this.m, a), s);
        e = add$2(mul(this.c, this.useNesterov ? add$2(s, mul(t, this.m)) : t), r), a.assign(t), r.assign(e);
      });
    }), this.incrementIterations();
  }

  dispose() {
    this.m.dispose(), null != this.accumulations && dispose(this.accumulations.map(e => e.variable));
  }

  setMomentum(e) {
    this.momentum = e;
  }

  getWeights() {
    var _this112 = this;

    return _asyncToGenerator(function* () {
      return [yield _this112.saveIterations()].concat(_this112.accumulations.map(e => ({
        name: e.originalName,
        tensor: e.variable
      })));
    })();
  }

  setWeights(e) {
    var _this113 = this;

    return _asyncToGenerator(function* () {
      e = yield _this113.extractIterations(e), _this113.accumulations = e.map(e => ({
        originalName: e.name,
        variable: e.tensor.variable(!1)
      }));
    })();
  }

  getConfig() {
    return {
      learningRate: this.learningRate,
      momentum: this.momentum,
      useNesterov: this.useNesterov
    };
  }

  static fromConfig(e, t) {
    return new e(t.learningRate, t.momentum, t.useNesterov);
  }

}

MomentumOptimizer.className = "Momentum", registerClass(MomentumOptimizer);

class RMSPropOptimizer extends Optimizer {
  constructor(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : .9;
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : null;
    var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;
    if (super(), this.learningRate = e, this.decay = t, this.momentum = n, this.epsilon = r, this.accumulatedMeanSquares = [], this.accumulatedMoments = [], this.accumulatedMeanGrads = [], this.centered = a, null == r && (this.epsilon = ENGINE.backend.epsilon()), null == e) throw new Error("learningRate for RMSPropOptimizer must be defined.");
  }

  applyGradients(e) {
    (Array.isArray(e) ? e.map(e => e.name) : Object.keys(e)).forEach((t, n) => {
      var r = ENGINE.registeredVariables[t],
          a = !1;
      null == this.accumulatedMeanSquares[n] && (this.accumulatedMeanSquares[n] = {
        originalName: "".concat(t, "/rms"),
        variable: tidy(() => zerosLike$2(r).variable(a))
      }), null == this.accumulatedMoments[n] && (this.accumulatedMoments[n] = {
        originalName: "".concat(t, "/momentum"),
        variable: tidy(() => zerosLike$2(r).variable(a))
      }), null == this.accumulatedMeanGrads[n] && this.centered && (this.accumulatedMeanGrads[n] = {
        originalName: "".concat(t, "/mg"),
        variable: tidy(() => zerosLike$2(r).variable(a))
      });
      var s = Array.isArray(e) ? e[n].tensor : e[t];
      if (null == s) return;
      var o = this.accumulatedMeanSquares[n].variable,
          i = this.accumulatedMoments[n].variable;
      tidy(() => {
        var e = add$2(mul(o, this.decay), mul(square$2(s), 1 - this.decay));

        if (this.centered) {
          var _t426 = this.accumulatedMeanGrads[n].variable,
              _a130 = add$2(mul(_t426, this.decay), mul(s, 1 - this.decay)),
              l = div$1(mul(s, this.learningRate), sqrt$2(sub$2(e, add$2(square$2(_a130), this.epsilon)))),
              u = add$2(mul(i, this.momentum), l);

          o.assign(e), _t426.assign(_a130), i.assign(u);
          var c = sub$2(r, u);
          r.assign(c);
        } else {
          var _e609 = add$2(mul(o, this.decay), mul(square$2(s), 1 - this.decay)),
              _t427 = add$2(mul(i, this.momentum), div$1(mul(s, this.learningRate), sqrt$2(add$2(_e609, this.epsilon))));

          o.assign(_e609), i.assign(_t427);

          var _n240 = sub$2(r, _t427);

          r.assign(_n240);
        }
      });
    }), this.incrementIterations();
  }

  dispose() {
    null != this.accumulatedMeanSquares && dispose(this.accumulatedMeanSquares.map(e => e.variable)), null != this.accumulatedMeanGrads && this.centered && dispose(this.accumulatedMeanGrads.map(e => e.variable)), null != this.accumulatedMoments && dispose(this.accumulatedMoments.map(e => e.variable));
  }

  getWeights() {
    var _this114 = this;

    return _asyncToGenerator(function* () {
      var e = [..._this114.accumulatedMeanSquares, ..._this114.accumulatedMoments];
      return _this114.centered && e.push(..._this114.accumulatedMeanGrads), [yield _this114.saveIterations()].concat(e.map(e => ({
        name: e.originalName,
        tensor: e.variable
      })));
    })();
  }

  setWeights(e) {
    var _this115 = this;

    return _asyncToGenerator(function* () {
      e = yield _this115.extractIterations(e);
      var t = _this115.centered ? e.length / 3 : e.length / 2,
          n = !1;
      _this115.accumulatedMeanSquares = e.slice(0, t).map(e => ({
        originalName: e.name,
        variable: e.tensor.variable(n)
      })), _this115.accumulatedMoments = e.slice(t, 2 * t).map(e => ({
        originalName: e.name,
        variable: e.tensor.variable(n)
      })), _this115.centered && (_this115.accumulatedMeanGrads = e.slice(2 * t, 3 * t).map(e => ({
        originalName: e.name,
        variable: e.tensor.variable(n)
      })));
    })();
  }

  getConfig() {
    return {
      learningRate: this.learningRate,
      decay: this.decay,
      momentum: this.momentum,
      epsilon: this.epsilon,
      centered: this.centered
    };
  }

  static fromConfig(e, t) {
    return new e(t.learningRate, t.decay, t.momentum, t.epsilon, t.centered);
  }

}

RMSPropOptimizer.className = "RMSProp", registerClass(RMSPropOptimizer);

class OptimizerConstructors {
  static sgd(e) {
    return new SGDOptimizer(e);
  }

  static momentum(e, t) {
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
    return new MomentumOptimizer(e, t, n);
  }

  static rmsprop(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : .9;
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : null;
    var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;
    return new RMSPropOptimizer(e, t, n, r, a);
  }

  static adam() {
    var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : .001;
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : .9;
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : .999;
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : null;
    return new AdamOptimizer(e, t, n, r);
  }

  static adadelta() {
    var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : .001;
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : .95;
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;
    return new AdadeltaOptimizer(e, t, n);
  }

  static adamax() {
    var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : .002;
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : .9;
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : .999;
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : null;
    var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : 0;
    return new AdamaxOptimizer(e, t, n, r, a);
  }

  static adagrad(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : .1;
    return new AdagradOptimizer(e, t);
  }

}

var train = {
  sgd: OptimizerConstructors.sgd,
  momentum: OptimizerConstructors.momentum,
  adadelta: OptimizerConstructors.adadelta,
  adagrad: OptimizerConstructors.adagrad,
  rmsprop: OptimizerConstructors.rmsprop,
  adamax: OptimizerConstructors.adamax,
  adam: OptimizerConstructors.adam
},
    delayCallback = "undefined" != typeof requestAnimationFrame ? requestAnimationFrame : "undefined" != typeof setImmediate ? setImmediate : e => e();

function nextFrame() {
  return new Promise(e => delayCallback(() => e()));
}

function assertParamsConsistent(e, t) {
  var n = e[0].length;
  e.forEach((e, t) => {
    assert$4(e.length === n, () => "Error in concat".concat(n, "D: rank of tensors[").concat(t, "] must be the same as the rank of the rest (").concat(n, ")"));
  }), assert$4(t >= 0 && t < n, () => "Error in concat".concat(n, "D: axis must be between 0 and ").concat(n - 1, "."));
  var r = e[0];
  e.forEach((e, a) => {
    for (var s = 0; s < n; s++) {
      assert$4(s === t || e[s] === r[s], () => "Error in concat".concat(n, "D: Shape of tensors[").concat(a, "] (").concat(e, ") does not match the shape of the rest (").concat(r, ") along the non-concatenated axis ").concat(a, "."));
    }
  });
}

function computeOutShape$1(e, t) {
  var n = e[0].slice();

  for (var r = 1; r < e.length; r++) {
    n[t] += e[r][t];
  }

  return n;
}

var PARALLELIZE_THRESHOLD = 30;

function computeOptimalWindowSize(e) {
  return e <= PARALLELIZE_THRESHOLD ? e : nearestDivisor(e, Math.floor(Math.sqrt(e)));
}

function getImageCenter(e, t, n) {
  return [n * ("number" == typeof e ? e : e[0]), t * ("number" == typeof e ? e : e[1])];
}

function getReshaped(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !0;
  var a = [];
  if (r) a = a.concat(t.slice(0)), a.push(e[0] / n), a = a.concat(e.slice(1));else {
    a = a.concat(e[0]);
    var _n241 = t.length;

    for (var _r201 = 0; _r201 < _n241; ++_r201) {
      a = a.concat([e[_r201 + 1] / t[_r201], t[_r201]]);
    }

    a = a.concat(e.slice(_n241 + 1));
  }
  return a;
}

function getPermuted(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !0;
  var r = [];

  if (n) {
    r.push(t);

    for (var _n242 = t + 1; _n242 < e; ++_n242) {
      _n242 <= 2 * t ? (r.push(_n242), r.push(_n242 - (t + 1))) : r.push(_n242);
    }
  } else {
    var _n243 = [],
        a = [];

    for (var _r202 = 1; _r202 < e; ++_r202) {
      _r202 >= 2 * t + 1 || _r202 % 2 == 1 ? a.push(_r202) : _n243.push(_r202);
    }

    r.push(..._n243), r.push(0), r.push(...a);
  }

  return r;
}

function getReshapedPermuted(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !0;
  var a = [];
  a.push(r ? e[0] / n : e[0] * n);

  for (var _n244 = 1; _n244 < e.length; ++_n244) {
    a.push(_n244 <= t.length ? r ? t[_n244 - 1] * e[_n244] : e[_n244] / t[_n244 - 1] : e[_n244]);
  }

  return a;
}

function getSliceBeginCoords(e, t) {
  var n = [0];

  for (var r = 0; r < t; ++r) {
    n.push(e[r][0]);
  }

  return n;
}

function getSliceSize(e, t, n) {
  var r = e.slice(0, 1);

  for (var a = 0; a < n; ++a) {
    r.push(e[a + 1] - t[a][0] - t[a][1]);
  }

  return r;
}

var SELU_SCALEALPHA = 1.7580993408473768,
    SELU_SCALE = 1.0507009873554805,
    ERF_P = .3275911,
    ERF_A1 = .254829592,
    ERF_A2 = -.284496736,
    ERF_A3 = 1.421413741,
    ERF_A4 = -1.453152027,
    ERF_A5 = 1.061405429;

function warn() {
  env().getBool("IS_TEST") || console.warn(...arguments);
}

function log$2() {
  env().getBool("IS_TEST") || console.log(...arguments);
}

function mergeRealAndImagArrays(e, t) {
  if (e.length !== t.length) throw new Error("Cannot merge real and imag arrays of different lengths. real:".concat(e.length, ", imag: ").concat(t.length, "."));
  var n = new Float32Array(2 * e.length);

  for (var r = 0; r < n.length; r += 2) {
    n[r] = e[r / 2], n[r + 1] = t[r / 2];
  }

  return n;
}

function splitRealAndImagArrays(e) {
  var t = new Float32Array(e.length / 2),
      n = new Float32Array(e.length / 2);

  for (var r = 0; r < e.length; r += 2) {
    t[r / 2] = e[r], n[r / 2] = e[r + 1];
  }

  return {
    real: t,
    imag: n
  };
}

function complexWithEvenIndex(e) {
  var t = Math.ceil(e.length / 4),
      n = new Float32Array(t),
      r = new Float32Array(t);

  for (var _t428 = 0; _t428 < e.length; _t428 += 4) {
    n[Math.floor(_t428 / 4)] = e[_t428], r[Math.floor(_t428 / 4)] = e[_t428 + 1];
  }

  return {
    real: n,
    imag: r
  };
}

function complexWithOddIndex(e) {
  var t = Math.floor(e.length / 4),
      n = new Float32Array(t),
      r = new Float32Array(t);

  for (var _t429 = 2; _t429 < e.length; _t429 += 4) {
    n[Math.floor(_t429 / 4)] = e[_t429], r[Math.floor(_t429 / 4)] = e[_t429 + 1];
  }

  return {
    real: n,
    imag: r
  };
}

function getComplexWithIndex(e, t) {
  return {
    real: e[2 * t],
    imag: e[2 * t + 1]
  };
}

function assignToTypedArray(e, t, n, r) {
  e[2 * r] = t, e[2 * r + 1] = n;
}

function exponents(e, t) {
  var n = new Float32Array(e / 2),
      r = new Float32Array(e / 2);

  for (var a = 0; a < Math.ceil(e / 2); a++) {
    var s = (t ? 2 : -2) * Math.PI * (a / e);
    n[a] = Math.cos(s), r[a] = Math.sin(s);
  }

  return {
    real: n,
    imag: r
  };
}

function exponent(e, t, n) {
  var r = (n ? 2 : -2) * Math.PI * (e / t);
  return {
    real: Math.cos(r),
    imag: Math.sin(r)
  };
}

var ARROW = "->",
    ARROW_REGEX = /->/g,
    COMMA = ",",
    ELLIPSIS = "...";

function decodeEinsumEquation(e, t) {
  var n = ((e = e.replace(/\s/g, "")).length - e.replace(ARROW_REGEX, "").length) / ARROW.length;
  if (n < 1) throw new Error("Equations without an arrow are not supported.");
  if (n > 1) throw new Error("Equation must contain exactly one arrow (\"".concat(ARROW, "\")."));
  var [r, a] = e.split(ARROW);
  assert$4(-1 === r.indexOf(ELLIPSIS), () => "The ellipsis notation (\"".concat(ELLIPSIS, "\") is not supported yet."));
  var s = r.split(COMMA),
      o = s.length;
  if (t !== o) throw new Error("Expected ".concat(o, " input tensors, received ").concat(t));
  if (o > 2) throw new Error("Support for more than 2 input tensors is not implemented yet.");
  var i = [];

  var _loop36 = function _loop36(_e610) {
    var t = a[_e610];
    if (!s.some(e => -1 !== e.indexOf(t))) throw new Error("Output subscripts contain the label ".concat(t, " not present in the input subscripts."));
    -1 === i.indexOf(t) && i.push(t);
  };

  for (var _e610 = 0; _e610 < a.length; ++_e610) {
    _loop36(_e610);
  }

  for (var _e611 = 0; _e611 < r.length; ++_e611) {
    var _t430 = r[_e611];
    -1 === i.indexOf(_t430) && _t430 !== COMMA && i.push(_t430);
  }

  var l = new Array(s.length);

  for (var _e612 = 0; _e612 < o; ++_e612) {
    if (new Set(s[_e612].split("")).size !== s[_e612].length) throw new Error("Found duplicate axes in input component ".concat(s[_e612], ". Support for duplicate axes in input is not implemented yet."));
    l[_e612] = [];

    for (var _t431 = 0; _t431 < s[_e612].length; ++_t431) {
      l[_e612].push(i.indexOf(s[_e612][_t431]));
    }
  }

  var u = i.length,
      c = [];

  for (var _e613 = a.length; _e613 < u; ++_e613) {
    c.push(_e613);
  }

  return {
    allDims: i,
    summedDims: c,
    idDims: l
  };
}

function getEinsumPermutation(e, t) {
  var n = new Array(e);
  n.fill(-1);

  for (var _e614 = 0; _e614 < t.length; ++_e614) {
    n[t[_e614]] = _e614;
  }

  var r = [];

  for (var _t432 = 0; _t432 < e; ++_t432) {
    -1 === n[_t432] && r.push(_t432);
  }

  return n = n.filter(e => -1 !== e), {
    permutationIndices: n,
    expandDims: r
  };
}

function checkEinsumDimSizes(e, t, n) {
  var r = new Array(e);

  var _loop37 = function _loop37(_e615) {
    var a = n[_e615].shape;

    var _loop38 = function _loop38(_n245) {
      void 0 === r[t[_e615][_n245]] ? r[t[_e615][_n245]] = a[_n245] : assert$4(r[t[_e615][_n245]] === a[_n245], () => "Expected dimension ".concat(r[t[_e615][_n245]], " at axis ").concat(_n245, " of input shaped ").concat(JSON.stringify(a), ", but got dimension ").concat(a[_n245]));
    };

    for (var _n245 = 0; _n245 < t[_e615].length; ++_n245) {
      _loop38(_n245);
    }
  };

  for (var _e615 = 0; _e615 < n.length; ++_e615) {
    _loop37(_e615);
  }
}

function getEinsumComputePath(e, t) {
  var n = e,
      r = [];
  var a = 0;
  0 === e.length && n.push(-1), a = e.length + 1;

  for (var _e616 = 0; _e616 < a; ++_e616) {
    r.push([]);
  }

  var s = [];

  for (var _e617 = 0; _e617 < n.length; ++_e617) {
    var _a131 = findTermsWithDim(t, n[_e617]);

    for (var _t433 of _a131) {
      -1 === s.indexOf(_t433) && (r[_e617].push(_t433), s.push(_t433));
    }
  }

  return {
    path: n,
    steps: r
  };
}

function isIdentityPermutation(e) {
  return e.every((e, t) => e === t);
}

function findTermsWithDim(e, t) {
  var n = [];

  for (var r = 0; r < e.length; ++r) {
    0 !== e[r].length && -1 === e[r].indexOf(t) && -1 !== t || n.push(r);
  }

  return n;
}

function prepareSplitSize(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;
  var r = [];
  if ("number" == typeof t) assert$4(e.shape[n] % t == 0, () => "Number of splits must evenly divide the axis."), r = new Array(t).fill(e.shape[n] / t);else {
    var a = t.reduce((e, t) => (-1 === t && (e += 1), e), 0);
    assert$4(a <= 1, () => "There should be only one negative value in split array.");
    var s = t.indexOf(-1);

    if (-1 !== s) {
      var _r203 = t.reduce((e, t) => t > 0 ? e + t : e);

      t[s] = e.shape[n] - _r203;
    }

    assert$4(e.shape[n] === t.reduce((e, t) => e + t), () => "The sum of sizes must match the size of the axis dimension."), r = t;
  }
  return r;
}

function segOpComputeOptimalWindowSize(e, t) {
  var n,
      r = !1;

  for (e <= PARALLELIZE_THRESHOLD ? (n = e, r = !0) : n = nearestDivisor(e, Math.floor(Math.sqrt(e))); !r;) {
    n > t || n === e ? r = !0 : n = nearestDivisor(e, n + 1);
  }

  return n;
}

function computeOutShape(e, t, n) {
  var r = [],
      a = e.length;

  for (var s = 0; s < a; s++) {
    r.push(s !== t ? e[s] : n);
  }

  return r;
}

function collectGatherOpShapeInfo(e, t, n, r) {
  var a = t.shape.length,
      s = e.shape.length;
  if (0 !== r && (r < -a || r > a)) throw new Error("Expect batchDims in the range of [-".concat(a, ", ").concat(a, "], but got ").concat(r));
  if (r < 0 && (r += a), r > s) throw new Error("batchDims (".concat(r, ") must be less than rank(x) (\n    ").concat(s, ")."));
  if (n < r) throw new Error("batchDims (".concat(r, ") must be less than or equal to axis (").concat(n, ")."));

  for (var _n246 = 0; _n246 < r; ++_n246) {
    if (e.shape[_n246] !== t.shape[_n246]) throw new Error("x.shape[".concat(_n246, "]: ").concat(e.shape[_n246], " should be equal to indices.shape[").concat(_n246, "]: ").concat(t.shape[_n246], "."));
  }

  var o = e.shape[n],
      i = [];
  var l = 1,
      u = 1,
      c = 1;

  for (var _t434 = 0; _t434 < r; ++_t434) {
    i.push(e.shape[_t434]), l *= e.shape[_t434];
  }

  for (var _t435 = r; _t435 < n; _t435++) {
    i.push(e.shape[_t435]), u *= e.shape[_t435];
  }

  for (var _e618 = r; _e618 < a; _e618++) {
    i.push(t.shape[_e618]);
  }

  for (var _t436 = n + 1; _t436 < s; _t436++) {
    i.push(e.shape[_t436]), c *= e.shape[_t436];
  }

  return {
    batchSize: l,
    sliceSize: c,
    outerSize: u,
    dimSize: o,
    outputShape: i
  };
}

var segment_util = {
  __proto__: null,
  segOpComputeOptimalWindowSize,
  computeOutShape,
  collectGatherOpShapeInfo
};

function fromUint8ToStringArray(e) {
  try {
    return e.map(e => decodeString(e));
  } catch (e) {
    throw new Error("Failed to decode encoded string bytes into utf-8, error: ".concat(e));
  }
}

function fromStringArrayToUint8(e) {
  return e.map(e => encodeString(e));
}

var backend_util = {
  __proto__: null,
  slice_util,
  segment_util,
  fromUint8ToStringArray,
  fromStringArrayToUint8,
  upcastType,
  axesAreInnerMostDims,
  combineLocations,
  computeOutAndReduceShapes,
  expandShapeToKeepDim,
  assertAxesAreInnerMostDims,
  getAxesPermutation,
  getUndoAxesPermutation,
  getInnerMostAxes,
  getBroadcastDims: getBroadcastDims$1,
  getReductionAxes,
  assertAndGetBroadcastShape,
  assertParamsConsistent,
  computeOutShape: computeOutShape$1,
  computeDilation2DInfo,
  computePool2DInfo,
  computePool3DInfo,
  computeConv2DInfo,
  computeConv3DInfo,
  computeDefaultPad,
  tupleValuesAreOne,
  eitherStridesOrDilationsAreOne,
  convertConv2DDataFormat,
  getFusedDyActivation,
  getFusedBiasGradient,
  applyActivation: applyActivation$1,
  shouldFuse,
  PARALLELIZE_THRESHOLD,
  computeOptimalWindowSize,
  getImageCenter,
  getReshaped,
  getPermuted,
  getReshapedPermuted,
  getSliceBeginCoords,
  getSliceSize,
  prepareAndValidate,
  validateUpdateShape,
  validateInput: validateInput$1,
  calculateShapes,
  SELU_SCALEALPHA,
  SELU_SCALE,
  ERF_P,
  ERF_A1,
  ERF_A2,
  ERF_A3,
  ERF_A4,
  ERF_A5,
  warn,
  log: log$2,
  mergeRealAndImagArrays,
  splitRealAndImagArrays,
  complexWithEvenIndex,
  complexWithOddIndex,
  getComplexWithIndex,
  assignToTypedArray,
  exponents,
  exponent,
  decodeEinsumEquation,
  getEinsumPermutation,
  checkEinsumDimSizes,
  getEinsumComputePath,
  isIdentityPermutation,
  prepareSplitSize
},
    kernel_impls = {
  __proto__: null,
  nonMaxSuppressionV3Impl: nonMaxSuppressionV3Impl$2,
  nonMaxSuppressionV4Impl: nonMaxSuppressionV4Impl$2,
  nonMaxSuppressionV5Impl: nonMaxSuppressionV5Impl$2,
  whereImpl: whereImpl$2
};
var absGradConfig = {
  kernelName: Abs,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => mul(e, step$2(cast$3(n, "float32"), -1))
    };
  }
},
    acosGradConfig = {
  kernelName: Acos,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => {
        var t = square$2(cast$3(n, "float32")),
            r = sqrt$2(sub$2(scalar(1), t));
        return neg$2(div$1(e, r));
      }
    };
  }
},
    acoshGradConfig = {
  kernelName: Acosh,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => {
        var t = sqrt$2(sub$2(square$2(cast$3(n, "float32")), 1));
        return div$1(e, t);
      }
    };
  }
},
    addGradConfig = {
  kernelName: Add$1,
  inputsToSave: ["a", "b"],
  gradFunc: (e, t) => {
    var [n, r] = t,
        _a132 = assertAndGetBroadcastShape(n.shape, r.shape);

    return {
      a: () => {
        var t = e;
        var r = getReductionAxes(n.shape, _a132);
        return r.length > 0 && (t = sum$2(t, r)), reshape$3(t, n.shape);
      },
      b: () => {
        var t = e;
        var n = getReductionAxes(r.shape, _a132);
        return n.length > 0 && (t = sum$2(t, n)), reshape$3(t, r.shape);
      }
    };
  }
},
    addNGradConfig = {
  kernelName: AddN,
  saveAllInputs: !0,
  gradFunc: (e, t) => {
    var n = {};
    return t.forEach((t, r) => {
      n[r] = () => e.clone();
    }), n;
  }
},
    argMaxGradConfig = {
  kernelName: ArgMax,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => zerosLike$2(n)
    };
  }
},
    argMinGradConfig = {
  kernelName: ArgMin,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => zerosLike$2(n)
    };
  }
},
    asinGradConfig = {
  kernelName: Asin,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => div$1(e, sqrt$2(sub$2(scalar(1), square$2(cast$3(n, "float32")))))
    };
  }
},
    asinhGradConfig = {
  kernelName: Asinh,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => {
        var t = sqrt$2(add$2(scalar(1), square$2(cast$3(n, "float32"))));
        return div$1(e, t);
      }
    };
  }
},
    atan2GradConfig = {
  kernelName: Atan2,
  inputsToSave: ["a", "b"],
  gradFunc: (e, t) => {
    var [n, r] = t,
        _a133 = assertAndGetBroadcastShape(n.shape, r.shape);

    return {
      a: () => {
        var t = add$2(square$2(n), square$2(r));
        var s = mul(e, div$1(r, t));
        var o = getReductionAxes(n.shape, _a133);
        return o.length > 0 && (s = sum$2(s, o)), reshape$3(s, n.shape);
      },
      b: () => {
        var t = add$2(square$2(n), square$2(r));
        var s = neg$2(mul(e, div$1(n, t)));
        var o = getReductionAxes(r.shape, _a133);
        return o.length > 0 && (s = sum$2(s, o)), reshape$3(s, r.shape);
      }
    };
  }
},
    atanGradConfig = {
  kernelName: Atan,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => div$1(e, add$2(square$2(cast$3(n, "float32")), 1))
    };
  }
},
    atanhGradConfig = {
  kernelName: Atanh,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => div$1(e, sub$2(scalar(1), square$2(cast$3(n, "float32"))))
    };
  }
};

function avgPool3dGrad_(e, t, n, r, a, s) {
  var o = convertToTensor(e, "dy", "avgPool3dGrad"),
      i = convertToTensor(t, "input", "avgPool3dGrad");
  var l = o,
      u = i,
      c = !1;
  4 === i.rank && (c = !0, l = reshape$3(o, [1, o.shape[0], o.shape[1], o.shape[2], o.shape[3]]), u = reshape$3(i, [1, i.shape[0], i.shape[1], i.shape[2], i.shape[3]])), assert$4(5 === l.rank, () => "Error in avgPool3dGrad: dy must be rank 5 but got rank ".concat(l.rank, ".")), assert$4(5 === u.rank, () => "Error in avgPool3dGrad: input must be rank 5 but got rank ".concat(u.rank, ".")), null != s && assert$4(isInt(a), () => "Error in avgPool3dGrad: pad must be an integer when using, dimRoundingMode ".concat(s, " but got pad ").concat(a, "."));
  var p = ENGINE.runKernel(AvgPool3DGrad, {
    dy: l,
    input: u
  }, {
    filterSize: n,
    strides: r,
    pad: a,
    dimRoundingMode: s
  });
  return c ? reshape$3(p, [p.shape[1], p.shape[2], p.shape[3], p.shape[4]]) : p;
}

var avgPool3dGrad = op({
  avgPool3dGrad_
}),
    avgPool3DGradConfig$1 = {
  kernelName: AvgPool3D,
  inputsToSave: ["x"],
  gradFunc: (e, t, n) => {
    var [r] = t,
        {
      filterSize: a,
      strides: s,
      pad: o,
      dimRoundingMode: i
    } = n;
    return {
      x: () => avgPool3dGrad(e, r, a, s, o, i)
    };
  }
};

function avgPoolGrad_(e, t, n, r, a) {
  var s = convertToTensor(e, "dy", "avgPoolGrad"),
      o = convertToTensor(t, "input", "avgPoolGrad");
  assert$4(o.rank === s.rank, () => "Rank of input (".concat(o.rank, ") does not match rank of dy (").concat(s.rank, ")"));
  var i = o,
      l = s,
      u = !1;
  3 === o.rank && (u = !0, i = reshape$3(o, [1, o.shape[0], o.shape[1], o.shape[2]]), l = reshape$3(s, [1, s.shape[0], s.shape[1], s.shape[2]])), assert$4(4 === l.rank, () => "Error in avgPoolGrad: dy must be rank 4 but got rank ".concat(l.rank, ".")), assert$4(4 === i.rank, () => "Error in avgPoolGrad: input must be rank 4 but got rank ".concat(i.rank, "."));
  var c = ENGINE.runKernel(AvgPoolGrad, {
    dy: l,
    input: i
  }, {
    filterSize: n,
    strides: r,
    pad: a
  });
  return u ? reshape$3(c, [c.shape[1], c.shape[2], c.shape[3]]) : c;
}

var avgPoolGrad$2 = op({
  avgPoolGrad_
}),
    avgPoolGradConfig$2 = {
  kernelName: AvgPool,
  inputsToSave: ["x"],
  gradFunc: (e, t, n) => {
    var [r] = t,
        {
      filterSize: a,
      strides: s,
      pad: o
    } = n;
    return {
      x: () => avgPoolGrad$2(e, r, a, s, o)
    };
  }
},
    batchMatMulGradConfig = {
  kernelName: BatchMatMul,
  inputsToSave: ["a", "b"],
  gradFunc: (e, t, n) => {
    var [r, _a134] = t,
        {
      transposeA: s,
      transposeB: o
    } = n;
    return s || o ? !s && o ? {
      a: () => matMul$1(e, _a134, !1, !1),
      b: () => matMul$1(e, r, !0, !1)
    } : s && !o ? {
      a: () => matMul$1(_a134, e, !1, !0),
      b: () => matMul$1(r, e, !1, !1)
    } : {
      a: () => matMul$1(_a134, e, !0, !0),
      b: () => matMul$1(e, r, !0, !0)
    } : {
      a: () => matMul$1(e, _a134, !1, !0),
      b: () => matMul$1(r, e, !0, !1)
    };
  }
},
    batchToSpaceNDGradConfig = {
  kernelName: BatchToSpaceND,
  gradFunc: (e, t, n) => {
    var {
      blockShape: r,
      crops: a
    } = n;
    return {
      x: () => spaceToBatchND$2(e, r, a)
    };
  }
},
    broadcastToGradConfig = {
  kernelName: BroadcastTo,
  gradFunc: (e, t, n) => {
    var r = n.inputShape,
        a = n.shape,
        s = Array.from(a);

    for (var _e619 = r.length - 1; _e619 >= 0; _e619--) {
      if (r[_e619] === a[_e619]) s[_e619] = 1;else if (1 !== r[_e619]) throw new Error("broadcastTo(): [".concat(r, "] cannot be broadcast to [").concat(a, "]."));
    }

    var o = [];

    for (var _e620 = 0; _e620 < s.length; _e620++) {
      s[_e620] > 1 && o.push(_e620);
    }

    return {
      x: () => sum$2(e, o, !0)
    };
  }
},
    castGradConfig = {
  kernelName: Cast,
  gradFunc: e => ({
    x: () => e.clone()
  })
},
    ceilGradConfig = {
  kernelName: Ceil,
  gradFunc: e => ({
    x: () => zerosLike$2(e)
  })
},
    clipByValueGradConfig = {
  kernelName: ClipByValue,
  inputsToSave: ["x"],
  gradFunc: (e, t, n) => {
    var [r] = t,
        {
      clipValueMin: a,
      clipValueMax: s
    } = n;
    return {
      x: () => where(logicalAnd$2(greaterEqual$2(r, a), lessEqual$2(r, s)), e, zerosLike$2(e))
    };
  }
},
    complexAbsGradConfig = {
  kernelName: ComplexAbs,
  inputsToSave: ["x"],
  gradFunc: absGradConfig.gradFunc
},
    concatGradConfig = {
  kernelName: Concat,
  saveAllInputs: !0,
  gradFunc: (e, t, n) => {
    var r = t.map(e => e.shape),
        {
      axis: a
    } = n,
        s = parseAxisParam(a, t[0].shape)[0],
        o = r.map(e => e[s]);
    return split$2(e, o, s).map(e => () => e);
  }
},
    conv2DGradConfig = {
  kernelName: Conv2D$1,
  inputsToSave: ["x", "filter"],
  gradFunc: (e, t, n) => {
    var [r, a] = t,
        {
      dilations: s,
      strides: o,
      pad: i,
      dataFormat: l
    } = n;
    return assert$4(tupleValuesAreOne(s), () => "Error in gradient of conv2D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '".concat(s, "'")), {
      x: () => conv2DBackpropInput$2(r.shape, e, a, o, i, l),
      filter: () => conv2DBackpropFilter$2(r, e, a.shape, o, i, l)
    };
  }
},
    conv2DBackpropInputGradConfig = {
  kernelName: Conv2DBackpropInput,
  inputsToSave: ["dy", "filter"],
  gradFunc: (e, t, n) => {
    var [r, a] = t,
        {
      strides: s,
      pad: o,
      dataFormat: i,
      dimRoundingMode: l
    } = n;
    return {
      dy: () => conv2d$3(e, a, s, o, i, 1, l),
      filter: () => conv2DBackpropFilter$2(e, r, a.shape, s, o, i, l)
    };
  }
};

function conv3DBackpropFilter_(e, t, n, r, a) {
  var s = e;
  4 === e.rank && (s = reshape$3(e, [1, e.shape[0], e.shape[1], e.shape[2], e.shape[3]]));
  var o = t;
  return 4 === o.rank && (o = reshape$3(t, [1, t.shape[0], t.shape[1], t.shape[2], t.shape[3]])), assert$4(5 === s.rank, () => "Error in conv3dDerFilter: input must be rank 5, but got shape ".concat(s.shape, ".")), assert$4(5 === o.rank, () => "Error in conv3dDerFilter: dy must be rank 5, but got shape ".concat(o.shape, ".")), assert$4(5 === n.length, () => "Error in conv3dDerFilter: filterShape must be length 5, but got ".concat(n, ".")), assert$4(s.shape[4] === n[3], () => "Error in conv3dDerFilter: depth of input ".concat(s.shape[4], ") must match input depth in filter (").concat(n[3], ".")), assert$4(o.shape[4] === n[4], () => "Error in conv3dDerFilter: depth of dy (".concat(o.shape[4], ") must match output depth for filter (").concat(n[4], ").")), ENGINE.runKernel(Conv3DBackpropFilterV2, {
    x: s,
    dy: o
  }, {
    strides: r,
    pad: a,
    filterShape: n
  });
}

var conv3DBackpropFilter = op({
  conv3DBackpropFilter_
}),
    conv3DGradConfig = {
  kernelName: Conv3D$1,
  inputsToSave: ["x", "filter"],
  gradFunc: (e, t, n) => {
    var {
      dilations: r,
      strides: a,
      pad: s
    } = n;
    assert$4(tupleValuesAreOne(r), () => "Error in gradient of conv3D: dilation rates greater than 1 are not yet supported in gradients. Got dilations '".concat(r, "'"));
    var [o, i] = t;
    return {
      x: () => conv3DBackpropInput$1(o.shape, e, i, a, s),
      filter: () => conv3DBackpropFilter(o, e, i.shape, a, s)
    };
  }
},
    cosGradConfig = {
  kernelName: Cos,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => mul(neg$2(sin$2(cast$3(n, "float32"))), e)
    };
  }
},
    coshGradConfig = {
  kernelName: Cosh,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => mul(sinh$2(cast$3(n, "float32")), e)
    };
  }
},
    cumsumGradConfig = {
  kernelName: Cumsum,
  inputsToSave: ["x"],
  gradFunc: (e, t, n) => {
    var [r] = t,
        {
      axis: a,
      exclusive: s,
      reverse: o
    } = n;
    return {
      x: () => {
        var t = getAxesPermutation([a], r.rank);
        var n = cumsum$2(e, a, s, !o);
        return null != t && (n = transpose$2(n, t)), n;
      }
    };
  }
},
    depthwiseConv2dNativeGradConfig = {
  kernelName: DepthwiseConv2dNative,
  inputsToSave: ["x", "filter"],
  gradFunc: (e, t, n) => {
    var {
      dilations: r,
      strides: a,
      pad: s,
      dimRoundingMode: o
    } = n,
        i = null == r ? [1, 1] : r;
    assert$4(tupleValuesAreOne(i), () => "Error in gradient of depthwiseConv2dNative: dilation rates greater than 1 are not yet supported. Got dilations '".concat(i, "'"));
    var [l, u] = t;
    return assert$4(4 === l.rank, () => "Error in gradient of depthwiseConv2dNative: input must be rank 4, but got rank ".concat(l.rank, ".")), assert$4(4 === u.rank, () => "Error in gradient of depthwiseConv2dNative: filter must be rank 4, but got rank ".concat(u.rank, ".")), assert$4(l.shape[3] === u.shape[2], () => "Error in gradient of depthwiseConv2d: number of input channels (".concat(l.shape[3], ") must match the inChannels dimension in filter ").concat(u.shape[2], ".")), assert$4(eitherStridesOrDilationsAreOne(a, i), () => "Error in gradient of depthwiseConv2d: Either strides or dilations must be  1. Got strides ".concat(a, " and dilations '").concat(i, "'.")), null != o && assert$4(isInt(s), () => "Error in depthwiseConv2d: pad must be an integer when using, dimRoundingMode ".concat(o, " but got pad ").concat(s, ".")), {
      x: () => depthwiseConv2dNativeBackpropInput$2(l.shape, e, u, a, s, r, o),
      filter: () => depthwiseConv2dNativeBackpropFilter$2(l, e, u.shape, a, s, r, o)
    };
  }
},
    dilation2dGradConfig = {
  kernelName: Dilation2D,
  inputsToSave: ["x", "filter"],
  gradFunc: (e, t, n) => {
    var [r, a] = t,
        s = {
      x: r,
      filter: a,
      dy: e
    },
        o = {
      x: r,
      filter: a,
      dy: e
    };
    return {
      x: () => ENGINE.runKernel(Dilation2DBackpropInput, s, n),
      filter: () => ENGINE.runKernel(Dilation2DBackpropFilter, o, n)
    };
  }
},
    eluGradConfig$2 = {
  kernelName: Elu$1,
  outputsToSave: [!0],
  gradFunc: (e, t) => {
    var [n] = t,
        r = {
      dy: e,
      y: n
    };
    return {
      x: () => ENGINE.runKernel(EluGrad, r)
    };
  }
},
    erfGradConfig = {
  kernelName: Erf,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t,
        r = mul(exp$2(neg$2(square$2(n))), 2 / Math.sqrt(Math.PI));
    return {
      x: () => mul(e, r)
    };
  }
},
    expGradConfig = {
  kernelName: Exp,
  outputsToSave: [!0],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => mul(e, n)
    };
  }
},
    expandDimsGradConfig = {
  kernelName: ExpandDims,
  inputsToSave: ["input"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      input: () => reshape$3(e, n.shape)
    };
  }
},
    expm1GradConfig = {
  kernelName: Expm1,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => mul(e, exp$2(n))
    };
  }
},
    floorGradConfig = {
  kernelName: Floor,
  gradFunc: e => ({
    x: () => zerosLike$2(e)
  })
},
    floorDivGradConfig = {
  kernelName: FloorDiv,
  inputsToSave: ["a", "b"],
  gradFunc: (e, t) => {
    var [n, r] = t,
        _a135 = assertAndGetBroadcastShape(n.shape, r.shape);

    return {
      a: () => {
        var t = div$1(e, cast$3(r, "float32")),
            s = getReductionAxes(n.shape, _a135);
        return s.length > 0 ? reshape$3(sum$2(t, s), n.shape) : t;
      },
      b: () => {
        var t = mul(e, cast$3(n, "float32"));
        var s = getReductionAxes(r.shape, _a135);
        s.length > 0 && (t = reshape$3(sum$2(t, s), r.shape));
        var o = square$2(r);
        return neg$2(div$1(t, cast$3(o, "float32")));
      }
    };
  }
},
    fusedBatchNormGradConfig = {
  kernelName: FusedBatchNorm,
  inputsToSave: ["x", "mean", "variance", "scale"],
  gradFunc: (e, t, n) => {
    var {
      varianceEpsilon: r
    } = n,
        [a, s, o, i] = t,
        l = null == i ? scalar(1) : i,
        u = getReductionAxes(s.shape, a.shape),
        c = [];

    if (1 === s.rank) {
      for (var _e621 = 0; _e621 < a.shape.length - 1; ++_e621) {
        c.push(a.shape[_e621]);
      }

      c.push(1);
    }

    var p = sub$2(a, s),
        d = mul(e, l),
        h = rsqrt$2(add$2(o, scalar(r))),
        m = mul(mul(mul(h, h), h), scalar(-.5));
    return {
      x: () => reshape$3(mul(mul(e, 1 === s.rank ? tile$3(reshape$3(h, [1, 1, 1, s.shape[0]]), c) : h), l), a.shape),
      mean: () => {
        var e = mul(mul(h, scalar(-1)), d);
        return 1 === s.rank && (e = sum$2(e, u)), reshape$3(e, s.shape);
      },
      variance: () => {
        var e = mul(mul(m, p), d);
        return 1 === s.rank && (e = sum$2(e, u)), reshape$3(e, s.shape);
      },
      scale: () => {
        var t = mul(p, h);
        var n = mul(e, t);
        return 1 === s.rank && (n = sum$2(n, u)), reshape$3(n, s.shape);
      },
      offset: () => {
        var t = e;
        return 1 === s.rank && (t = sum$2(t, u)), reshape$3(t, s.shape);
      }
    };
  }
},
    gatherGradConfig = {
  kernelName: GatherV2,
  inputsToSave: ["x", "indices"],
  gradFunc: (e, t, n) => {
    var [r, a] = t,
        {
      axis: s
    } = n,
        o = parseAxisParam(s, r.shape)[0];
    return {
      x: () => {
        var t = r.shape,
            n = a.size,
            i = t.slice(0, o),
            l = i.length,
            u = t.slice(s, t.length).slice(1),
            c = u.length,
            p = arrayRange(0, l),
            d = arrayRange(l + 1, l + 1 + c),
            h = arrayConcat([i, [n], u]),
            m = reshape$3(e, h),
            f = reshape$3(a, [n]),
            g = arrayConcat([[l], p, d]),
            $ = transpose$2(m, g);
        var y = unsortedSegmentSum$2($, f, r.shape[o]);
        var b = getUndoAxesPermutation(g);
        return y = transpose$2(y, b), y;
      },
      indices: () => a
    };
  }
};

function arrayRange(e, t) {
  var n = [];

  for (var r = e; r < t; ++r) {
    n.push(r);
  }

  return n;
}

function arrayConcat(e) {
  var t = [];

  for (var n = 0; n < e.length; ++n) {
    for (var r = 0; r < e[n].length; ++r) {
      t.push(e[n][r]);
    }
  }

  return t;
}

var greaterEqualGradConfig = {
  kernelName: GreaterEqual,
  inputsToSave: ["a", "b"],
  gradFunc: (e, t) => {
    var [n, r] = t;
    return {
      a: () => zerosLike$2(n),
      b: () => zerosLike$2(r)
    };
  }
},
    identityGradConfig = {
  kernelName: Identity$1,
  gradFunc: e => ({
    x: () => cast$3(e, "float32")
  })
},
    isFiniteGradConfig = {
  kernelName: IsFinite,
  gradFunc: e => ({
    x: () => zerosLike$2(e)
  })
},
    isInfGradConfig = {
  kernelName: IsInf,
  gradFunc: e => ({
    x: () => zerosLike$2(e)
  })
},
    isNanGradConfig = {
  kernelName: IsNan,
  gradFunc: e => ({
    x: () => zerosLike$2(e)
  })
},
    leakyReluGradConfig = {
  kernelName: LeakyRelu,
  inputsToSave: ["x"],
  gradFunc: (e, t, n) => {
    var [r] = t,
        {
      alpha: a
    } = n,
        s = greater$3(r, 0);
    return {
      x: () => where(s, e, mul(e, a))
    };
  }
},
    log1pGradConfig = {
  kernelName: Log1p,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => div$1(e, add$2(n, 1))
    };
  }
},
    logGradConfig = {
  kernelName: Log,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => div$1(e, cast$3(n, "float32"))
    };
  }
},
    logSoftmaxGradConfig = {
  kernelName: LogSoftmax$1,
  inputsToSave: [],
  outputsToSave: [!0],
  gradFunc: (e, t, n) => {
    var [r] = t,
        {
      axis: a
    } = n;
    return {
      logits: () => {
        var t = exp$2(r);
        return sub$2(e, mul(sum$2(e, a, !0), t));
      }
    };
  }
};

function localResponseNormalizationBackprop_(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 5;
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : 1;
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : 1;
  var o = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : .5;
  return ENGINE.runKernel(LRNGrad, {
    x: e,
    y: t,
    dy: n
  }, {
    depthRadius: r,
    bias: a,
    alpha: s,
    beta: o
  });
}

var localResponseNormalizationBackprop = op({
  localResponseNormalizationBackprop_
}),
    lrnGradConfig = {
  kernelName: LRN,
  inputsToSave: ["x"],
  outputsToSave: [!0],
  gradFunc: (e, t, n) => {
    var [r, a] = t,
        {
      depthRadius: s,
      bias: o,
      alpha: i,
      beta: l
    } = n;
    return {
      x: () => localResponseNormalizationBackprop(r, a, e, s, o, i, l)
    };
  }
};

function gradForMinAndMax(e, t, n, r) {
  return t.rank < n.rank && (t = reshape$3(t, expandShapeToKeepDim(t.shape, r))), e.rank < n.rank && (e = reshape$3(e, expandShapeToKeepDim(e.shape, r))), {
    x: () => mul(e, cast$3(equal$2(n, t), e.dtype))
  };
}

var maxGradConfig = {
  kernelName: Max,
  inputsToSave: ["x"],
  outputsToSave: [!0],
  gradFunc: (e, t, n) => {
    var r = n,
        {
      reductionIndices: a
    } = r,
        s = t[0],
        o = gradForMinAndMax(e, t[1], s, parseAxisParam(a, s.shape));
    return {
      x: () => o.x()
    };
  }
},
    maximumGradConfig = {
  kernelName: Maximum$1,
  inputsToSave: ["a", "b"],
  gradFunc: (e, t) => {
    var [n, r] = t;
    return {
      a: () => mul(e, cast$3(greaterEqual$2(n, r), "float32")),
      b: () => mul(e, cast$3(less$3(n, r), "float32"))
    };
  }
};

function maxPool3dGrad_(e, t, n, r, a, s, o) {
  var i = convertToTensor(e, "dy", "maxPool3dGrad"),
      l = convertToTensor(t, "input", "maxPool3dGrad"),
      u = convertToTensor(n, "output", "maxPool3dGrad");
  var c = i,
      p = l,
      d = u,
      h = !1;
  4 === l.rank && (h = !0, c = reshape$3(i, [1, i.shape[0], i.shape[1], i.shape[2], i.shape[3]]), p = reshape$3(l, [1, l.shape[0], l.shape[1], l.shape[2], l.shape[3]]), d = reshape$3(u, [1, u.shape[0], u.shape[1], u.shape[2], u.shape[3]])), assert$4(5 === c.rank, () => "Error in maxPool3dGrad: dy must be rank 5 but got rank ".concat(c.rank, ".")), assert$4(5 === p.rank, () => "Error in maxPool3dGrad: input must be rank 5 but got rank ".concat(p.rank, ".")), assert$4(5 === d.rank, () => "Error in maxPool3dGrad: output must be rank 5 but got rank ".concat(d.rank, ".")), null != o && assert$4(isInt(s), () => "Error in maxPool3dGrad: pad must be an integer when using, dimRoundingMode ".concat(o, " but got pad ").concat(s, "."));
  var m = ENGINE.runKernel(MaxPool3DGrad, {
    dy: c,
    input: p,
    output: d
  }, {
    filterSize: r,
    strides: a,
    pad: s,
    dimRoundingMode: o
  });
  return h ? reshape$3(m, [m.shape[1], m.shape[2], m.shape[3], m.shape[4]]) : m;
}

var maxPool3dGrad = op({
  maxPool3dGrad_
}),
    maxPool3DGradConfig$1 = {
  kernelName: MaxPool3D,
  inputsToSave: ["x"],
  outputsToSave: [!0],
  gradFunc: (e, t, n) => {
    var [r, a] = t,
        {
      filterSize: s,
      strides: o,
      pad: i,
      dimRoundingMode: l
    } = n;
    return {
      x: () => maxPool3dGrad(e, r, a, s, o, i, l)
    };
  }
};

function maxPoolGrad_(e, t, n, r, a, s, o) {
  var i = convertToTensor(e, "dy", "maxPoolGrad"),
      l = convertToTensor(t, "input", "maxPoolGrad"),
      u = convertToTensor(n, "output", "maxPoolGrad");
  return assert$4(l.rank === i.rank, () => "Rank of input (".concat(l.rank, ") does not match rank of dy (").concat(i.rank, ")")), assert$4(4 === i.rank, () => "Error in maxPoolGrad: dy must be rank 4 but got rank ".concat(i.rank, ".")), assert$4(4 === l.rank, () => "Error in maxPoolGrad: input must be rank 4 but got rank ".concat(l.rank, ".")), null != o && assert$4(isInt(s), () => "Error in maxPoolGrad: pad must be an integer when using, dimRoundingMode ".concat(o, " but got pad ").concat(s, ".")), ENGINE.runKernel(MaxPoolGrad, {
    dy: i,
    input: l,
    output: u
  }, {
    filterSize: r,
    strides: a,
    pad: s,
    dimRoundingMode: o
  });
}

var maxPoolGrad$2 = op({
  maxPoolGrad_
}),
    maxPoolGradConfig$2 = {
  kernelName: MaxPool,
  inputsToSave: ["x"],
  outputsToSave: [!0],
  gradFunc: (e, t, n) => {
    var [r, a] = t,
        {
      filterSize: s,
      strides: o,
      pad: i
    } = n;
    return {
      x: () => maxPoolGrad$2(e, r, a, s, o, i)
    };
  }
},
    meanGradConfig = {
  kernelName: Mean,
  inputsToSave: ["x"],
  gradFunc: (e, t, n) => {
    var [r] = t,
        {
      axis: a
    } = n,
        s = parseAxisParam(a, r.shape),
        o = sizeFromShape(computeOutAndReduceShapes(r.shape, s)[1]);
    return {
      x: () => {
        var t = r.shape.slice();
        s.forEach(e => {
          t[e] = 1;
        });
        var n = reshape$3(e, t);
        return div$1(mul(n, ones$1(r.shape, "float32")), o);
      }
    };
  }
},
    minGradConfig = {
  kernelName: Min,
  inputsToSave: ["x"],
  outputsToSave: [!0],
  gradFunc: (e, t, n) => {
    var r = n,
        {
      axis: a
    } = r,
        [s, o] = t,
        i = gradForMinAndMax(e, o, s, parseAxisParam(a, s.shape));
    return {
      x: () => i.x()
    };
  }
},
    minimumGradConfig = {
  kernelName: Minimum$1,
  inputsToSave: ["a", "b"],
  gradFunc: (e, t) => {
    var [n, r] = t;
    return {
      a: () => mul(e, cast$3(lessEqual$2(n, r), "float32")),
      b: () => mul(e, cast$3(greater$3(n, r), "float32"))
    };
  }
},
    mirrorPadGradConfig = {
  kernelName: MirrorPad,
  inputsToSave: ["x"],
  gradFunc: (e, t, n) => {
    var r = t[0],
        {
      paddings: a
    } = n,
        s = a.map(e => e[0]);
    return {
      x: () => slice$2(e, s, r.shape)
    };
  }
},
    modGradConfig = {
  kernelName: Mod,
  inputsToSave: ["a", "b"],
  gradFunc: (e, t) => {
    var [n, r] = t,
        _a136 = assertAndGetBroadcastShape(n.shape, r.shape);

    return {
      a: () => {
        var t = getReductionAxes(n.shape, _a136);
        return t.length > 0 ? reshape$3(sum$2(e, t), n.shape) : e;
      },
      b: () => {
        var t = mul(e, neg$2(floor$2(div$1(n, r)))),
            s = getReductionAxes(r.shape, _a136);
        return s.length > 0 ? reshape$3(sum$2(t, s), r.shape) : t;
      }
    };
  }
},
    multiplyGradConfig = {
  kernelName: Multiply$1,
  inputsToSave: ["a", "b"],
  gradFunc: (e, t) => {
    var [n, r] = t,
        _a137 = assertAndGetBroadcastShape(n.shape, r.shape);

    return {
      a: () => {
        var t = mul(e, cast$3(r, "float32")),
            s = getReductionAxes(n.shape, _a137);
        return s.length > 0 ? reshape$3(sum$2(t, s), n.shape) : t;
      },
      b: () => {
        var t = mul(e, cast$3(n, "float32")),
            s = getReductionAxes(r.shape, _a137);
        return s.length > 0 ? reshape$3(sum$2(t, s), r.shape) : t;
      }
    };
  }
},
    negGradConfig = {
  kernelName: Neg,
  gradFunc: e => ({
    x: () => neg$2(e)
  })
},
    oneHotGradConfig = {
  kernelName: OneHot,
  inputsToSave: ["indices"],
  gradFunc: (e, t) => {
    var n = t[0];
    return {
      indices: () => zeros$2(n.shape, "float32")
    };
  }
},
    onesLikeGradConfig = {
  kernelName: OnesLike,
  gradFunc: e => ({
    x: () => zerosLike$2(e)
  })
},
    packGradConfig = {
  kernelName: Pack,
  saveAllInputs: !0,
  gradFunc: (e, t, n) => {
    var {
      axis: r
    } = n;
    return unstack(e, r).map(e => () => e);
  }
},
    padV2GradConfig = {
  kernelName: PadV2,
  inputsToSave: ["x"],
  gradFunc: (e, t, n) => {
    var r = t[0],
        {
      paddings: a
    } = n,
        s = a.map(e => e[0]);
    return {
      x: () => slice$2(e, s, r.shape)
    };
  }
},
    powGradConfig = {
  kernelName: Pow,
  inputsToSave: ["a", "b"],
  outputsToSave: [!0],
  gradFunc: (e, t) => {
    var [n, r, a] = t,
        s = n,
        o = r,
        i = assertAndGetBroadcastShape(s.shape, o.shape);
    return {
      a: () => {
        var t = cast$3(o, "float32");
        var n = mul(e, mul(t, pow$2(s, sub$2(t, scalar(1)))));
        var r = getReductionAxes(s.shape, i);
        return r.length > 0 && (n = sum$2(n, r)), reshape$3(n, s.shape);
      },
      b: () => {
        var t = greater$3(s, 0),
            n = where(t, log$3(s), zerosLike$2(s));
        var r = mul(e, mul(a, n));
        var l = getReductionAxes(o.shape, i);
        return l.length > 0 && (r = sum$2(r, l)), reshape$3(r, o.shape);
      }
    };
  }
},
    preluGradConfig = {
  kernelName: Prelu,
  inputsToSave: ["x", "alpha"],
  gradFunc: (e, t) => {
    var [n, r] = t,
        a = greater$3(n, 0);
    return {
      x: () => where(a, e, mul(e, r)),
      alpha: () => {
        var t = where(a, zerosLike$2(e), mul(e, n));
        var s = getReductionAxes(r.shape, e.shape);
        return s.length > 0 && (t = sum$2(t, s)), reshape$3(t, r.shape);
      }
    };
  }
},
    divGradConfig = {
  kernelName: RealDiv,
  inputsToSave: ["a", "b"],
  gradFunc: (e, t) => {
    var [n, r] = t,
        _a138 = assertAndGetBroadcastShape(n.shape, r.shape);

    return {
      a: () => {
        var t = div$1(e, cast$3(r, "float32")),
            s = getReductionAxes(n.shape, _a138);
        return s.length > 0 ? reshape$3(sum$2(t, s), n.shape) : t;
      },
      b: () => {
        var t = mul(e, cast$3(n, "float32"));
        var s = getReductionAxes(r.shape, _a138);
        s.length > 0 && (t = reshape$3(sum$2(t, s), r.shape));
        var o = square$2(r);
        return neg$2(div$1(t, cast$3(o, "float32")));
      }
    };
  }
},
    reciprocalGradConfig = {
  kernelName: Reciprocal,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => div$1(e, neg$2(square$2(n)))
    };
  }
},
    relu6GradConfig = {
  kernelName: Relu6$1,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t,
        r = mul(lessEqual$2(n, 6), step$2(n));
    return {
      x: () => mul(e, cast$3(r, "float32"))
    };
  }
},
    reluGradConfig = {
  kernelName: Relu$1,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => mul(e, cast$3(step$2(n), "float32"))
    };
  }
},
    reshapeGradConfig = {
  kernelName: Reshape$1,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => reshape$3(e, n.shape)
    };
  }
},
    resizeBilinearGradConfig$2 = {
  kernelName: ResizeBilinear,
  inputsToSave: ["images"],
  gradFunc: (e, t, n) => {
    var [r] = t,
        a = {
      dy: e,
      images: r
    };
    return {
      images: () => ENGINE.runKernel(ResizeBilinearGrad, a, n)
    };
  }
},
    resizeNearestNeighborGradConfig$2 = {
  kernelName: ResizeNearestNeighbor,
  inputsToSave: ["images"],
  gradFunc: (e, t, n) => {
    var [r] = t,
        a = {
      dy: e,
      images: r
    };
    return {
      images: () => ENGINE.runKernel(ResizeNearestNeighborGrad, a, n)
    };
  }
},
    reverseGradConfig = {
  kernelName: Reverse,
  gradFunc: (e, t, n) => {
    var {
      dims: r
    } = n,
        a = parseAxisParam(r, e.shape);
    return {
      x: () => reverse$2(e, a)
    };
  }
},
    roundGradConfig = {
  kernelName: Round,
  gradFunc: e => ({
    x: () => zerosLike$2(e)
  })
},
    rsqrtGradConfig = {
  kernelName: Rsqrt,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => neg$2(div$1(e, mul(pow$2(n, 1.5), 2)))
    };
  }
},
    selectGradConfig = {
  kernelName: Select,
  inputsToSave: ["condition"],
  gradFunc: (_e622, t) => {
    var [n] = t;
    return {
      condition: () => cast$3(zerosLike$2(n), "float32"),
      t: () => mul(_e622, cast$3(n, _e622.dtype)),
      e: () => mul(_e622, cast$3(logicalNot$2(n), _e622.dtype))
    };
  }
},
    seluGradConfig = {
  kernelName: Selu$1,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => {
        var t = greater$3(n, scalar(0)),
            r = scalar(SELU_SCALEALPHA),
            a = scalar(SELU_SCALE),
            s = mul(e, a),
            o = mul(mul(e, r), exp$2(cast$3(n, "float32")));
        return where(t, s, o);
      }
    };
  }
},
    sigmoidGradConfig = {
  kernelName: Sigmoid$1,
  outputsToSave: [!0],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => mul(e, mul(n, sub$2(scalar(1), n)))
    };
  }
},
    signGradConfig = {
  kernelName: Sign,
  gradFunc: e => ({
    x: () => zerosLike$2(e)
  })
},
    sinGradConfig = {
  kernelName: Sin,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => mul(cos$2(cast$3(n, "float32")), e)
    };
  }
},
    sinhGradConfig = {
  kernelName: Sinh,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => mul(cosh$2(cast$3(n, "float32")), e)
    };
  }
},
    sliceGradConfig = {
  kernelName: Slice,
  inputsToSave: ["x"],
  gradFunc: (e, t, n) => {
    var [r] = t,
        {
      begin: a,
      size: s
    } = n,
        o = r.shape,
        [i, l] = parseSliceParams(r, a, s),
        u = [];

    for (var _t437 = 0; _t437 < e.rank; _t437++) {
      u.push([i[_t437], o[_t437] - i[_t437] - l[_t437]]);
    }

    return {
      x: () => pad(e, u)
    };
  }
},
    softmaxGradConfig = {
  kernelName: Softmax$2,
  outputsToSave: [!0],
  gradFunc: (e, t, n) => {
    var [r] = t,
        {
      dim: a
    } = n,
        s = mul(e, r);
    return {
      logits: () => sub$2(s, mul(sum$2(s, [a], !0), r))
    };
  }
},
    softplusGradConfig = {
  kernelName: Softplus$1,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => mul(e, sigmoid$2(n))
    };
  }
},
    spaceToBatchNDGradConfig = {
  kernelName: SpaceToBatchND,
  gradFunc: (e, t, n) => {
    var {
      blockShape: r,
      paddings: a
    } = n;
    return {
      x: () => batchToSpaceND$2(e, r, a)
    };
  }
},
    splitVGradConfig = {
  kernelName: SplitV,
  gradFunc: (e, t, n) => {
    var {
      axis: r
    } = n;
    return {
      x: () => concat$2(e, r)
    };
  }
},
    sqrtGradConfig = {
  kernelName: Sqrt,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => div$1(e, mul(sqrt$2(cast$3(n, "float32")), 2))
    };
  }
},
    squareGradConfig = {
  kernelName: Square,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => mul(e, mul(cast$3(n, "float32"), 2))
    };
  }
},
    squaredDifferenceGradConfig = {
  kernelName: SquaredDifference,
  inputsToSave: ["a", "b"],
  gradFunc: (e, t) => {
    var [n, r] = t,
        _a139 = scalar(2);

    return {
      a: () => mul(e, mul(_a139, sub$2(n, r))),
      b: () => mul(e, mul(_a139, sub$2(r, n)))
    };
  }
},
    stepGradConfig = {
  kernelName: Step,
  gradFunc: e => ({
    x: () => zerosLike$2(e)
  })
},
    subGradConfig = {
  kernelName: Sub,
  inputsToSave: ["a", "b"],
  gradFunc: (e, t) => {
    var [n, r] = t,
        _a140 = assertAndGetBroadcastShape(n.shape, r.shape);

    return {
      a: () => {
        var t = e;
        var r = getReductionAxes(n.shape, _a140);
        return r.length > 0 && (t = sum$2(t, r)), reshape$3(t, n.shape);
      },
      b: () => {
        var t = e;
        var n = getReductionAxes(r.shape, _a140);
        return n.length > 0 && (t = sum$2(t, n)), reshape$3(neg$2(t), r.shape);
      }
    };
  }
},
    sumGradConfig = {
  kernelName: Sum,
  inputsToSave: ["x"],
  gradFunc: (e, t, n) => {
    var [r] = t,
        a = r.shape.slice(),
        {
      axis: s
    } = n;
    parseAxisParam(s, r.shape).forEach(e => {
      a[e] = 1;
    });
    var o = reshape$3(e, a),
        i = mul(o, ones$1(r.shape, "float32"));
    return {
      x: () => i
    };
  }
},
    tanGradConfig = {
  kernelName: Tan,
  inputsToSave: ["x"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => div$1(e, square$2(cos$2(n)))
    };
  }
},
    tanhGradConfig = {
  kernelName: Tanh$1,
  outputsToSave: [!0],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => mul(sub$2(scalar(1), square$2(n)), e)
    };
  }
},
    tileGradConfig = {
  kernelName: Tile,
  inputsToSave: ["x"],
  gradFunc: (e, t, n) => {
    var [r] = t,
        {
      reps: a
    } = n;
    return {
      x: () => {
        var t = zerosLike$2(r);
        if (1 === r.rank) for (var _n247 = 0; _n247 < a[0]; ++_n247) {
          t = add$2(t, slice$2(e, [_n247 * r.shape[0]], [r.shape[0]]));
        } else if (2 === r.rank) for (var _n248 = 0; _n248 < a[0]; ++_n248) {
          for (var s = 0; s < a[1]; ++s) {
            t = add$2(t, slice$2(e, [_n248 * r.shape[0], s * r.shape[1]], [r.shape[0], r.shape[1]]));
          }
        } else if (3 === r.rank) for (var _n249 = 0; _n249 < a[0]; ++_n249) {
          for (var _s98 = 0; _s98 < a[1]; ++_s98) {
            for (var o = 0; o < a[2]; ++o) {
              t = add$2(t, slice$2(e, [_n249 * r.shape[0], _s98 * r.shape[1], o * r.shape[2]], [r.shape[0], r.shape[1], r.shape[2]]));
            }
          }
        } else {
          if (4 !== r.rank) throw new Error("Gradient for tile operation is not implemented for rank-".concat(r.rank, " tensors yet."));

          for (var _n250 = 0; _n250 < a[0]; ++_n250) {
            for (var _s99 = 0; _s99 < a[1]; ++_s99) {
              for (var _o72 = 0; _o72 < a[2]; ++_o72) {
                for (var i = 0; i < a[3]; ++i) {
                  t = add$2(t, slice$2(e, [_n250 * r.shape[0], _s99 * r.shape[1], _o72 * r.shape[2], i * r.shape[3]], [r.shape[0], r.shape[1], r.shape[2], r.shape[3]]));
                }
              }
            }
          }
        }
        return t;
      }
    };
  }
},
    transposeGradConfig = {
  kernelName: Transpose,
  gradFunc: (e, t, n) => {
    var r = n,
        {
      perm: a
    } = r,
        s = getUndoAxesPermutation(a);
    return {
      x: () => transpose$2(e, s)
    };
  }
},
    unpackGradConfig = {
  kernelName: Unpack,
  gradFunc: (e, t, n) => {
    var r = n,
        {
      axis: a
    } = r;
    return {
      value: () => stack(e, a)
    };
  }
},
    unsortedSegmentSumGradConfig = {
  kernelName: UnsortedSegmentSum,
  inputsToSave: ["segmentIds"],
  gradFunc: (e, t) => {
    var [n] = t;
    return {
      x: () => gatherDropNegatives(e, n)
    };
  }
};

function gatherDropNegatives(e, t) {
  var n = maximum$3(t, zerosLike$2(t)),
      r = gather$1(e, n);
  var a = greaterEqual$2(t, scalar(0, "int32"));
  var s = r.rank - a.rank;

  for (var _e623 = 0; _e623 < s; ++_e623) {
    a = expandDims$3(a, _e623 + 1);
  }

  a = logicalAnd$2(a, ones$1(r.shape, "bool"));
  var o = zerosLike$2(r);
  return where(a, r, o);
}

var zerosLikeGradConfig = {
  kernelName: ZerosLike,
  gradFunc: e => ({
    x: () => zerosLike$2(e)
  })
},
    gradConfigs = [absGradConfig, acosGradConfig, acoshGradConfig, addGradConfig, addNGradConfig, argMaxGradConfig, argMinGradConfig, asinGradConfig, asinhGradConfig, atan2GradConfig, atanGradConfig, atanhGradConfig, avgPool3DGradConfig$1, avgPoolGradConfig$2, batchMatMulGradConfig, batchToSpaceNDGradConfig, broadcastToGradConfig, castGradConfig, ceilGradConfig, clipByValueGradConfig, complexAbsGradConfig, concatGradConfig, conv2DBackpropInputGradConfig, conv2DGradConfig, conv3DGradConfig, cosGradConfig, coshGradConfig, cumsumGradConfig, depthwiseConv2dNativeGradConfig, dilation2dGradConfig, divGradConfig, eluGradConfig$2, erfGradConfig, expGradConfig, expandDimsGradConfig, expm1GradConfig, floorDivGradConfig, floorGradConfig, fusedBatchNormGradConfig, gatherGradConfig, greaterEqualGradConfig, identityGradConfig, isFiniteGradConfig, isInfGradConfig, isNanGradConfig, leakyReluGradConfig, log1pGradConfig, logGradConfig, logSoftmaxGradConfig, lrnGradConfig, maxGradConfig, maxGradConfig, maximumGradConfig, maxPool3DGradConfig$1, maxPoolGradConfig$2, meanGradConfig, minGradConfig, minimumGradConfig, mirrorPadGradConfig, modGradConfig, multiplyGradConfig, negGradConfig, oneHotGradConfig, onesLikeGradConfig, packGradConfig, padV2GradConfig, padV2GradConfig, powGradConfig, preluGradConfig, reciprocalGradConfig, relu6GradConfig, reluGradConfig, reshapeGradConfig, resizeBilinearGradConfig$2, resizeNearestNeighborGradConfig$2, reverseGradConfig, roundGradConfig, rsqrtGradConfig, selectGradConfig, seluGradConfig, sigmoidGradConfig, signGradConfig, sinGradConfig, sinhGradConfig, sliceGradConfig, softmaxGradConfig, softplusGradConfig, spaceToBatchNDGradConfig, spaceToBatchNDGradConfig, splitVGradConfig, splitVGradConfig, sqrtGradConfig, squaredDifferenceGradConfig, squareGradConfig, stepGradConfig, subGradConfig, sumGradConfig, tanGradConfig, tanhGradConfig, tileGradConfig, transposeGradConfig, unpackGradConfig, unsortedSegmentSumGradConfig, zerosLikeGradConfig];

for (var _e624 of gradConfigs) {
  registerGradient(_e624);
}

var _epsilon;

function epsilon$1() {
  return null == _epsilon && (_epsilon = backend().epsilon()), _epsilon;
}

function imageDataFormat() {
  return "channelsLast";
}

getGlobalTensorClass().prototype.abs = function () {
  return this.throwIfDisposed(), abs$2(this);
}, getGlobalTensorClass().prototype.acos = function () {
  return this.throwIfDisposed(), acos$2(this);
}, getGlobalTensorClass().prototype.acosh = function () {
  return this.throwIfDisposed(), acosh$2(this);
}, getGlobalTensorClass().prototype.add = function (e) {
  return this.throwIfDisposed(), add$2(this, e);
}, getGlobalTensorClass().prototype.all = function (e, t) {
  return this.throwIfDisposed(), all$2(this, e, t);
}, getGlobalTensorClass().prototype.any = function (e, t) {
  return this.throwIfDisposed(), any$2(this, e, t);
}, getGlobalTensorClass().prototype.argMax = function (e) {
  return this.throwIfDisposed(), argMax$2(this, e);
}, getGlobalTensorClass().prototype.argMin = function (e) {
  return this.throwIfDisposed(), argMin$2(this, e);
}, getGlobalTensorClass().prototype.asScalar = function () {
  return this.throwIfDisposed(), assert$4(1 === this.size, () => "The array must have only 1 element."), reshape$3(this, []);
}, getGlobalTensorClass().prototype.asType = function (e) {
  return this.throwIfDisposed(), cast$3(this, e);
}, getGlobalTensorClass().prototype.as1D = function () {
  return this.throwIfDisposed(), reshape$3(this, [this.size]);
}, getGlobalTensorClass().prototype.as2D = function (e, t) {
  return this.throwIfDisposed(), reshape$3(this, [e, t]);
}, getGlobalTensorClass().prototype.as3D = function (e, t, n) {
  return this.throwIfDisposed(), reshape$3(this, [e, t, n]);
}, getGlobalTensorClass().prototype.as4D = function (e, t, n, r) {
  return this.throwIfDisposed(), reshape$3(this, [e, t, n, r]);
}, getGlobalTensorClass().prototype.as5D = function (e, t, n, r, a) {
  return this.throwIfDisposed(), reshape$3(this, [e, t, n, r, a]);
}, getGlobalTensorClass().prototype.asin = function () {
  return this.throwIfDisposed(), asin$2(this);
}, getGlobalTensorClass().prototype.asinh = function () {
  return this.throwIfDisposed(), asinh$2(this);
}, getGlobalTensorClass().prototype.atan = function () {
  return this.throwIfDisposed(), atan$2(this);
}, getGlobalTensorClass().prototype.atan2 = function (e) {
  return this.throwIfDisposed(), atan2$2(this, e);
}, getGlobalTensorClass().prototype.atanh = function () {
  return this.throwIfDisposed(), atanh$2(this);
}, getGlobalTensorClass().prototype.avgPool = function (e, t, n, r) {
  return this.throwIfDisposed(), avgPool$2(this, e, t, n, r);
}, getGlobalTensorClass().prototype.batchToSpaceND = function (e, t) {
  return this.throwIfDisposed(), batchToSpaceND$2(this, e, t);
}, getGlobalTensorClass().prototype.batchNorm = function (e, t, n, r, a) {
  return this.throwIfDisposed(), batchNorm$2(this, e, t, n, r, a);
}, getGlobalTensorClass().prototype.broadcastTo = function (e) {
  return this.throwIfDisposed(), broadcastTo(this, e);
}, getGlobalTensorClass().prototype.cast = function (e) {
  return this.throwIfDisposed(), cast$3(this, e);
}, getGlobalTensorClass().prototype.ceil = function () {
  return this.throwIfDisposed(), ceil$2(this);
}, getGlobalTensorClass().prototype.clipByValue = function (e, t) {
  return this.throwIfDisposed(), clipByValue$1(this, e, t);
}, getGlobalTensorClass().prototype.concat = function (e, t) {
  return this.throwIfDisposed(), e instanceof Tensor && (e = [e]), concat$2([this, ...e], t);
}, getGlobalTensorClass().prototype.conv1d = function (e, t, n, r, a, s) {
  return this.throwIfDisposed(), conv1d$1(this, e, t, n, r, a, s);
}, getGlobalTensorClass().prototype.conv2dTranspose = function (e, t, n, r, a) {
  return this.throwIfDisposed(), conv2dTranspose$1(this, e, t, n, r, a);
}, getGlobalTensorClass().prototype.conv2d = function (e, t, n, r, a, s) {
  return this.throwIfDisposed(), conv2d$3(this, e, t, n, r, a, s);
}, getGlobalTensorClass().prototype.cos = function () {
  return this.throwIfDisposed(), cos$2(this);
}, getGlobalTensorClass().prototype.cosh = function () {
  return this.throwIfDisposed(), cosh$2(this);
}, getGlobalTensorClass().prototype.cumsum = function (e, t, n) {
  return this.throwIfDisposed(), cumsum$2(this, e, t, n);
}, getGlobalTensorClass().prototype.depthToSpace = function (e, t) {
  return this.throwIfDisposed(), depthToSpace$2(this, e, t);
}, getGlobalTensorClass().prototype.depthwiseConv2d = function (e, t, n, r, a, s) {
  return this.throwIfDisposed(), depthwiseConv2d$3(this, e, t, n, r, a, s);
}, getGlobalTensorClass().prototype.dilation2d = function (e, t, n, r, a) {
  return this.throwIfDisposed(), dilation2d(this, e, t, n, r, a);
}, getGlobalTensorClass().prototype.divNoNan = function (e) {
  return this.throwIfDisposed(), divNoNan(this, e);
}, getGlobalTensorClass().prototype.div = function (e) {
  return this.throwIfDisposed(), div$1(this, e);
}, getGlobalTensorClass().prototype.dot = function (e) {
  return this.throwIfDisposed(), dot$2(this, e);
}, getGlobalTensorClass().prototype.elu = function () {
  return this.throwIfDisposed(), elu$4(this);
}, getGlobalTensorClass().prototype.equal = function (e) {
  return this.throwIfDisposed(), equal$2(this, e);
}, getGlobalTensorClass().prototype.erf = function () {
  return this.throwIfDisposed(), erf$2(this);
}, getGlobalTensorClass().prototype.exp = function () {
  return this.throwIfDisposed(), exp$2(this);
}, getGlobalTensorClass().prototype.expandDims = function (e) {
  return this.throwIfDisposed(), expandDims$3(this, e);
}, getGlobalTensorClass().prototype.expm1 = function () {
  return this.throwIfDisposed(), expm1$2(this);
}, getGlobalTensorClass().prototype.fft = function () {
  return this.throwIfDisposed(), fft$2(this);
}, getGlobalTensorClass().prototype.flatten = function () {
  return this.throwIfDisposed(), reshape$3(this, [this.size]);
}, getGlobalTensorClass().prototype.floor = function () {
  return this.throwIfDisposed(), floor$2(this);
}, getGlobalTensorClass().prototype.floorDiv = function (e) {
  return this.throwIfDisposed(), floorDiv$2(this, e);
}, getGlobalTensorClass().prototype.gather = function (e, t) {
  return this.throwIfDisposed(), gather$1(this, e, t);
}, getGlobalTensorClass().prototype.greaterEqual = function (e) {
  return this.throwIfDisposed(), greaterEqual$2(this, e);
}, getGlobalTensorClass().prototype.greater = function (e) {
  return this.throwIfDisposed(), greater$3(this, e);
}, getGlobalTensorClass().prototype.ifft = function () {
  return this.throwIfDisposed(), ifft$2(this);
}, getGlobalTensorClass().prototype.irfft = function () {
  return this.throwIfDisposed(), irfft(this);
}, getGlobalTensorClass().prototype.isFinite = function () {
  return this.throwIfDisposed(), isFinite$3(this);
}, getGlobalTensorClass().prototype.isInf = function () {
  return this.throwIfDisposed(), isInf$2(this);
}, getGlobalTensorClass().prototype.isNaN = function () {
  return this.throwIfDisposed(), isNaN$3(this);
}, getGlobalTensorClass().prototype.leakyRelu = function (e) {
  return this.throwIfDisposed(), leakyRelu$2(this, e);
}, getGlobalTensorClass().prototype.lessEqual = function (e) {
  return this.throwIfDisposed(), lessEqual$2(this, e);
}, getGlobalTensorClass().prototype.less = function (e) {
  return this.throwIfDisposed(), less$3(this, e);
}, getGlobalTensorClass().prototype.localResponseNormalization = function (e, t, n, r) {
  return this.throwIfDisposed(), localResponseNormalization(this, e, t, n, r);
}, getGlobalTensorClass().prototype.logSigmoid = function () {
  return this.throwIfDisposed(), logSigmoid(this);
}, getGlobalTensorClass().prototype.logSoftmax = function (e) {
  return this.throwIfDisposed(), logSoftmax(this, e);
}, getGlobalTensorClass().prototype.logSumExp = function (e, t) {
  return this.throwIfDisposed(), logSumExp(this, e, t);
}, getGlobalTensorClass().prototype.log = function () {
  return this.throwIfDisposed(), log$3(this);
}, getGlobalTensorClass().prototype.log1p = function () {
  return this.throwIfDisposed(), log1p$2(this);
}, getGlobalTensorClass().prototype.logicalAnd = function (e) {
  return this.throwIfDisposed(), logicalAnd$2(this, e);
}, getGlobalTensorClass().prototype.logicalNot = function () {
  return this.throwIfDisposed(), logicalNot$2(this);
}, getGlobalTensorClass().prototype.logicalOr = function (e) {
  return this.throwIfDisposed(), logicalOr$2(this, e);
}, getGlobalTensorClass().prototype.logicalXor = function (e) {
  return this.throwIfDisposed(), logicalXor(this, e);
}, getGlobalTensorClass().prototype.matMul = function (e, t, n) {
  return this.throwIfDisposed(), matMul$1(this, e, t, n);
}, getGlobalTensorClass().prototype.maxPool = function (e, t, n, r) {
  return this.throwIfDisposed(), maxPool$2(this, e, t, n, r);
}, getGlobalTensorClass().prototype.max = function (e, t) {
  return this.throwIfDisposed(), max$3(this, e, t);
}, getGlobalTensorClass().prototype.maximum = function (e) {
  return this.throwIfDisposed(), maximum$3(this, e);
}, getGlobalTensorClass().prototype.mean = function (e, t) {
  return this.throwIfDisposed(), mean$1(this, e, t);
}, getGlobalTensorClass().prototype.min = function (e, t) {
  return this.throwIfDisposed(), min$3(this, e, t);
}, getGlobalTensorClass().prototype.minimum = function (e) {
  return this.throwIfDisposed(), minimum$3(this, e);
}, getGlobalTensorClass().prototype.mirrorPad = function (e, t) {
  return this.throwIfDisposed(), mirrorPad$1(this, e, t);
}, getGlobalTensorClass().prototype.mod = function (e) {
  return this.throwIfDisposed(), mod$2(this, e);
}, getGlobalTensorClass().prototype.mul = function (e) {
  return this.throwIfDisposed(), mul(this, e);
}, getGlobalTensorClass().prototype.neg = function () {
  return this.throwIfDisposed(), neg$2(this);
}, getGlobalTensorClass().prototype.norm = function (e, t, n) {
  return this.throwIfDisposed(), norm(this, e, t, n);
}, getGlobalTensorClass().prototype.notEqual = function (e) {
  return this.throwIfDisposed(), notEqual$2(this, e);
}, getGlobalTensorClass().prototype.oneHot = function (e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 1;
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;
  return this.throwIfDisposed(), oneHot$2(this, e, t, n);
}, getGlobalTensorClass().prototype.onesLike = function () {
  return this.throwIfDisposed(), onesLike$2(this);
}, getGlobalTensorClass().prototype.pad = function (e, t) {
  return this.throwIfDisposed(), pad(this, e, t);
}, getGlobalTensorClass().prototype.pool = function (e, t, n, r, a) {
  return this.throwIfDisposed(), pool$1(this, e, t, n, r, a);
}, getGlobalTensorClass().prototype.pow = function (e) {
  return this.throwIfDisposed(), pow$2(this, e);
}, getGlobalTensorClass().prototype.prelu = function (e) {
  return this.throwIfDisposed(), prelu$3(this, e);
}, getGlobalTensorClass().prototype.prod = function (e, t) {
  return this.throwIfDisposed(), prod$2(this, e, t);
}, getGlobalTensorClass().prototype.reciprocal = function () {
  return this.throwIfDisposed(), reciprocal$2(this);
}, getGlobalTensorClass().prototype.relu = function () {
  return this.throwIfDisposed(), relu$3(this);
}, getGlobalTensorClass().prototype.relu6 = function () {
  return this.throwIfDisposed(), relu6$2(this);
}, getGlobalTensorClass().prototype.reshapeAs = function (e) {
  return this.throwIfDisposed(), reshape$3(this, e.shape);
}, getGlobalTensorClass().prototype.reshape = function (e) {
  return this.throwIfDisposed(), reshape$3(this, e);
}, getGlobalTensorClass().prototype.resizeBilinear = function (e, t, n) {
  return this.throwIfDisposed(), resizeBilinear$2(this, e, t, n);
}, getGlobalTensorClass().prototype.resizeNearestNeighbor = function (e, t, n) {
  return this.throwIfDisposed(), resizeNearestNeighbor$2(this, e, t, n);
}, getGlobalTensorClass().prototype.reverse = function (e) {
  return this.throwIfDisposed(), reverse$2(this, e);
}, getGlobalTensorClass().prototype.rfft = function () {
  return this.throwIfDisposed(), rfft(this);
}, getGlobalTensorClass().prototype.round = function () {
  return this.throwIfDisposed(), round$2(this);
}, getGlobalTensorClass().prototype.rsqrt = function () {
  return this.throwIfDisposed(), rsqrt$2(this);
}, getGlobalTensorClass().prototype.selu = function () {
  return this.throwIfDisposed(), selu$2(this);
}, getGlobalTensorClass().prototype.separableConv2d = function (e, t, n, r, a, s) {
  return this.throwIfDisposed(), separableConv2d$1(this, e, t, n, r, a, s);
}, getGlobalTensorClass().prototype.sigmoid = function () {
  return this.throwIfDisposed(), sigmoid$2(this);
}, getGlobalTensorClass().prototype.sign = function () {
  return this.throwIfDisposed(), sign$2(this);
}, getGlobalTensorClass().prototype.sin = function () {
  return this.throwIfDisposed(), sin$2(this);
}, getGlobalTensorClass().prototype.sinh = function () {
  return this.throwIfDisposed(), sinh$2(this);
}, getGlobalTensorClass().prototype.slice = function (e, t) {
  return this.throwIfDisposed(), slice$2(this, e, t);
}, getGlobalTensorClass().prototype.softmax = function (e) {
  return this.throwIfDisposed(), softmax$3(this, e);
}, getGlobalTensorClass().prototype.softplus = function () {
  return this.throwIfDisposed(), softplus$2(this);
}, getGlobalTensorClass().prototype.spaceToBatchND = function (e, t) {
  return this.throwIfDisposed(), spaceToBatchND$2(this, e, t);
}, getGlobalTensorClass().prototype.split = function (e, t) {
  return this.throwIfDisposed(), split$2(this, e, t);
}, getGlobalTensorClass().prototype.sqrt = function () {
  return this.throwIfDisposed(), sqrt$2(this);
}, getGlobalTensorClass().prototype.square = function () {
  return this.throwIfDisposed(), square$2(this);
}, getGlobalTensorClass().prototype.squaredDifference = function (e) {
  return this.throwIfDisposed(), squaredDifference$2(this, e);
}, getGlobalTensorClass().prototype.squeeze = function (e) {
  return this.throwIfDisposed(), squeeze(this, e);
}, getGlobalTensorClass().prototype.stack = function (e, t) {
  this.throwIfDisposed();
  var n = e instanceof Tensor ? [this, e] : [this, ...e];
  return stack(n, t);
}, getGlobalTensorClass().prototype.step = function (e) {
  return this.throwIfDisposed(), step$2(this, e);
}, getGlobalTensorClass().prototype.stridedSlice = function (e, t, n, r, a, s, o, i) {
  return this.throwIfDisposed(), stridedSlice$2(this, e, t, n, r, a, s, o, i);
}, getGlobalTensorClass().prototype.sub = function (e) {
  return this.throwIfDisposed(), sub$2(this, e);
}, getGlobalTensorClass().prototype.sum = function (e, t) {
  return this.throwIfDisposed(), sum$2(this, e, t);
}, getGlobalTensorClass().prototype.tan = function () {
  return this.throwIfDisposed(), tan$2(this);
}, getGlobalTensorClass().prototype.tanh = function () {
  return this.throwIfDisposed(), tanh$2(this);
}, getGlobalTensorClass().prototype.tile = function (e) {
  return this.throwIfDisposed(), tile$3(this, e);
}, getGlobalTensorClass().prototype.toBool = function () {
  return this.throwIfDisposed(), cast$3(this, "bool");
}, getGlobalTensorClass().prototype.toFloat = function () {
  return this.throwIfDisposed(), cast$3(this, "float32");
}, getGlobalTensorClass().prototype.toInt = function () {
  return this.throwIfDisposed(), cast$3(this, "int32");
}, getGlobalTensorClass().prototype.topk = function (e, t) {
  return this.throwIfDisposed(), topk(this, e, t);
}, getGlobalTensorClass().prototype.transpose = function (e) {
  return this.throwIfDisposed(), transpose$2(this, e);
}, getGlobalTensorClass().prototype.unique = function (e) {
  return this.throwIfDisposed(), unique$3(this, e);
}, getGlobalTensorClass().prototype.unsortedSegmentSum = function (e, t) {
  return this.throwIfDisposed(), unsortedSegmentSum$2(this, e, t);
}, getGlobalTensorClass().prototype.unstack = function (e) {
  return this.throwIfDisposed(), unstack(this, e);
}, getGlobalTensorClass().prototype.where = function (e, t) {
  return this.throwIfDisposed(), where(e, this, t);
}, getGlobalTensorClass().prototype.zerosLike = function () {
  return this.throwIfDisposed(), zerosLike$2(this);
};

class AttributeError extends Error {
  constructor(e) {
    super(e), Object.setPrototypeOf(this, AttributeError.prototype);
  }

}

class RuntimeError extends Error {
  constructor(e) {
    super(e), Object.setPrototypeOf(this, RuntimeError.prototype);
  }

}

class ValueError extends Error {
  constructor(e) {
    super(e), Object.setPrototypeOf(this, ValueError.prototype);
  }

}

class NotImplementedError extends Error {
  constructor(e) {
    super(e), Object.setPrototypeOf(this, NotImplementedError.prototype);
  }

}

class AssertionError extends Error {
  constructor(e) {
    super(e), Object.setPrototypeOf(this, AssertionError.prototype);
  }

}

function pyListRepeat(e, t) {
  if (Array.isArray(e)) {
    var n = [];

    for (var r = 0; r < t; r++) {
      n = n.concat(e);
    }

    return n;
  }

  {
    var _n251 = new Array(t);

    return _n251.fill(e), _n251;
  }
}

function assert$3(e, t) {
  if (!e) throw new AssertionError(t);
}

function count(e, t) {
  var n = 0;

  for (var r of e) {
    r === t && n++;
  }

  return n;
}

function singletonOrArray(e) {
  return 1 === e.length ? e[0] : e;
}

function toList(e) {
  return Array.isArray(e) ? e : [e];
}

function toSnakeCase(e) {
  var t = e.replace(/(.)([A-Z][a-z0-9]+)/g, "$1_$2").replace(/([a-z])([A-Z])/g, "$1_$2").toLowerCase();
  return "_" !== t[0] ? t : "private" + t;
}

function toCamelCase(e) {
  return e.length <= 1 || -1 === e.indexOf("_") ? e : e.replace(/[_]+(\w|$)/g, (e, t) => t.toUpperCase());
}

var _GLOBAL_CUSTOM_OBJECTS = {};

function serializeKerasObject(e) {
  if (null == e) return null;
  var t = {};
  return t.className = e.getClassName(), t.config = e.getConfig(), t;
}

function convertNDArrayScalarsInConfig(e) {
  if (null != e && "object" == typeof e) if (Array.isArray(e)) e.forEach(e => convertNDArrayScalarsInConfig(e));else {
    var t = Object.keys(e);

    for (var n of t) {
      var _t438 = e[n];
      null != _t438 && "object" == typeof _t438 && (Array.isArray(_t438) || "ndarray" !== _t438.type || "number" != typeof _t438.value ? convertNDArrayScalarsInConfig(_t438) : e[n] = _t438.value);
    }
  }
}

function deserializeKerasObject(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : "object";
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;

  if ("string" == typeof e) {
    var _a141 = e;
    var s;
    if (_a141 in n) s = n[_a141];else if (_a141 in _GLOBAL_CUSTOM_OBJECTS) s = _GLOBAL_CUSTOM_OBJECTS[_a141];else if (s = t[_a141], null == s) throw new ValueError("Unknown ".concat(r, ": ").concat(e, ". This may be due to one of the following reasons:\n1. The ").concat(r, " is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.\n2. The custom ").concat(r, " is defined in JavaScript, but is not registered properly with tf.serialization.registerClass()."));
    return s;
  }

  {
    var _s100 = e;
    if (null == _s100.className || null == _s100.config) throw new ValueError("".concat(r, ": Improper config format: ").concat(JSON.stringify(_s100), ".\n'className' and 'config' must set."));
    var o = _s100.className;
    var i, l;
    if (o in n ? [i, l] = n[o] : o in _GLOBAL_CUSTOM_OBJECTS ? [i, l] = _GLOBAL_CUSTOM_OBJECTS.className : o in t && ([i, l] = t[o]), null == i) throw new ValueError("Unknown ".concat(r, ": ").concat(o, ". This may be due to one of the following reasons:\n1. The ").concat(r, " is defined in Python, in which case it needs to be ported to TensorFlow.js or your JavaScript code.\n2. The custom ").concat(r, " is defined in JavaScript, but is not registered properly with tf.serialization.registerClass()."));

    if (null != l) {
      var _e625 = {};

      for (var _t440 of Object.keys(_GLOBAL_CUSTOM_OBJECTS)) {
        _e625[_t440] = _GLOBAL_CUSTOM_OBJECTS[_t440];
      }

      for (var _t441 of Object.keys(n)) {
        _e625[_t441] = n[_t441];
      }

      _s100.config.customObjects = _e625;

      var _t439 = Object.assign({}, _GLOBAL_CUSTOM_OBJECTS);

      for (var _e626 of Object.keys(n)) {
        _GLOBAL_CUSTOM_OBJECTS[_e626] = n[_e626];
      }

      convertNDArrayScalarsInConfig(_s100.config);

      var _r204 = l(i, _s100.config, n, a);

      return _GLOBAL_CUSTOM_OBJECTS = Object.assign({}, _t439), _r204;
    }

    {
      var _e627 = Object.assign({}, _GLOBAL_CUSTOM_OBJECTS);

      for (var _e628 of Object.keys(n)) {
        _GLOBAL_CUSTOM_OBJECTS[_e628] = n[_e628];
      }

      var _t442 = new i(_s100.config);

      return _GLOBAL_CUSTOM_OBJECTS = Object.assign({}, _e627), _t442;
    }
  }
}

function numberCompare(e, t) {
  return e < t ? -1 : e > t ? 1 : 0;
}

function reverseNumberCompare(e, t) {
  return -1 * numberCompare(e, t);
}

function unique$2(e) {
  if (null == e) return e;
  var t = [];

  for (var n of e) {
    -1 === t.indexOf(n) && t.push(n);
  }

  return t;
}

function isObjectEmpty(e) {
  if (null == e) throw new ValueError("Invalid value in obj: ".concat(JSON.stringify(e)));

  for (var t in e) {
    if (e.hasOwnProperty(t)) return !1;
  }

  return !0;
}

function checkStringTypeUnionValue(e, t, n) {
  if (null != n && e.indexOf(n) < 0) throw new ValueError("".concat(n, " is not a valid ").concat(t, ".  Valid values are ").concat(e, " or null/undefined."));
}

function checkArrayTypeAndLength(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : Infinity;
  return assert$3(n >= 0), assert$3(r >= n), Array.isArray(e) && e.length >= n && e.length <= r && e.every(e => typeof e === t);
}

function assertPositiveInteger(e, t) {
  Array.isArray(e) ? (assert$4(e.length > 0, () => "".concat(t, " is unexpectedly an empty array.")), e.forEach((e, n) => assertPositiveInteger(e, "element ".concat(n + 1, " of ").concat(t)))) : assert$4(Number.isInteger(e) && e > 0, () => "Expected ".concat(t, " to be a positive integer, but got ").concat(formatAsFriendlyString(e), "."));
}

function formatAsFriendlyString(e) {
  return null === e ? "null" : Array.isArray(e) ? "[" + e.map(e => formatAsFriendlyString(e)).join(",") + "]" : "string" == typeof e ? "\"".concat(e, "\"") : "".concat(e);
}

function debounce(e, t) {
  var n,
      r = now();
  return function () {
    var s = now();
    return s - r < t || (r = s, n = e(...arguments)), n;
  };
}

function mapActivationToFusedKernel(e) {
  return "relu" === e ? "relu" : "linear" === e ? "linear" : "elu" === e ? "elu" : null;
}

function calcL2Norms(e, t) {
  return tidy(() => sqrt$2(sum$2(mul(e, e), t, !0)));
}

class Constraint extends Serializable {
  getConfig() {
    return {};
  }

}

class MaxNorm extends Constraint {
  constructor(e) {
    super(), this.defaultMaxValue = 2, this.defaultAxis = 0, this.maxValue = null != e.maxValue ? e.maxValue : this.defaultMaxValue, this.axis = null != e.axis ? e.axis : this.defaultAxis;
  }

  apply(e) {
    return tidy(() => {
      var t = calcL2Norms(e, this.axis),
          n = clipByValue$1(t, 0, this.maxValue);
      return mul(e, div$1(n, add$2(epsilon$1(), t)));
    });
  }

  getConfig() {
    return {
      maxValue: this.maxValue,
      axis: this.axis
    };
  }

}

MaxNorm.className = "MaxNorm", registerClass(MaxNorm);

class UnitNorm extends Constraint {
  constructor(e) {
    super(), this.defaultAxis = 0, this.axis = null != e.axis ? e.axis : this.defaultAxis;
  }

  apply(e) {
    return tidy(() => div$1(e, add$2(epsilon$1(), calcL2Norms(e, this.axis))));
  }

  getConfig() {
    return {
      axis: this.axis
    };
  }

}

UnitNorm.className = "UnitNorm", registerClass(UnitNorm);

class NonNeg extends Constraint {
  apply(e) {
    return relu$3(e);
  }

}

NonNeg.className = "NonNeg", registerClass(NonNeg);

class MinMaxNorm extends Constraint {
  constructor(e) {
    super(), this.defaultMinValue = 0, this.defaultMaxValue = 1, this.defaultRate = 1, this.defaultAxis = 0, this.minValue = null != e.minValue ? e.minValue : this.defaultMinValue, this.maxValue = null != e.maxValue ? e.maxValue : this.defaultMaxValue, this.rate = null != e.rate ? e.rate : this.defaultRate, this.axis = null != e.axis ? e.axis : this.defaultAxis;
  }

  apply(e) {
    return tidy(() => {
      var t = calcL2Norms(e, this.axis),
          n = add$2(mul(this.rate, clipByValue$1(t, this.minValue, this.maxValue)), mul(1 - this.rate, t));
      return mul(e, div$1(n, add$2(epsilon$1(), t)));
    });
  }

  getConfig() {
    return {
      minValue: this.minValue,
      maxValue: this.maxValue,
      rate: this.rate,
      axis: this.axis
    };
  }

}

MinMaxNorm.className = "MinMaxNorm", registerClass(MinMaxNorm);
var CONSTRAINT_IDENTIFIER_REGISTRY_SYMBOL_MAP = {
  maxNorm: "MaxNorm",
  minMaxNorm: "MinMaxNorm",
  nonNeg: "NonNeg",
  unitNorm: "UnitNorm"
};

function serializeConstraint(e) {
  return serializeKerasObject(e);
}

function deserializeConstraint(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};
  return deserializeKerasObject(e, SerializationMap.getMap().classNameMap, t, "constraint");
}

function getConstraint(e) {
  return null == e ? null : "string" == typeof e ? deserializeConstraint({
    className: e in CONSTRAINT_IDENTIFIER_REGISTRY_SYMBOL_MAP ? CONSTRAINT_IDENTIFIER_REGISTRY_SYMBOL_MAP[e] : e,
    config: {}
  }) : e instanceof Constraint ? e : deserializeConstraint(e);
}

function maxNorm(e) {
  return new MaxNorm(e);
}

function unitNorm(e) {
  return new UnitNorm(e);
}

function nonNeg() {
  return new NonNeg();
}

function minMaxNorm(e) {
  return new MinMaxNorm(e);
}

var exports_constraints = {
  __proto__: null,
  maxNorm,
  unitNorm,
  nonNeg,
  minMaxNorm
};
var VALID_DATA_FORMAT_VALUES = ["channelsFirst", "channelsLast"],
    VALID_INTERPOLATION_FORMAT_VALUES = ["nearest", "bilinear"],
    VALID_PADDING_MODE_VALUES = ["valid", "same", "causal"],
    VALID_POOL_MODE_VALUES = ["max", "avg"],
    VALID_BIDIRECTIONAL_MERGE_MODES = ["sum", "mul", "concat", "ave"],
    nameMap = new Map();

function checkDataFormat(e) {
  checkStringTypeUnionValue(VALID_DATA_FORMAT_VALUES, "DataFormat", e);
}

function checkInterpolationFormat(e) {
  checkStringTypeUnionValue(VALID_INTERPOLATION_FORMAT_VALUES, "InterpolationFormat", e);
}

function checkPaddingMode(e) {
  checkStringTypeUnionValue(VALID_PADDING_MODE_VALUES, "PaddingMode", e);
}

function checkPoolMode(e) {
  checkStringTypeUnionValue(VALID_POOL_MODE_VALUES, "PoolMode", e);
}

var _nameScopeStack = [],
    _nameScopeDivider = "/";

function nameScope(e, t) {
  _nameScopeStack.push(e);

  try {
    var _e629 = t();

    return _nameScopeStack.pop(), _e629;
  } catch (e) {
    throw _nameScopeStack.pop(), e;
  }
}

function currentNameScopePrefix() {
  return 0 === _nameScopeStack.length ? "" : _nameScopeStack.join(_nameScopeDivider) + _nameScopeDivider;
}

function getScopedTensorName(e) {
  if (!isValidTensorName(e)) throw new Error("Not a valid tensor name: '" + e + "'");
  return currentNameScopePrefix() + e;
}

function getUniqueTensorName(e) {
  if (!isValidTensorName(e)) throw new Error("Not a valid tensor name: '" + e + "'");
  nameMap.has(e) || nameMap.set(e, 0);
  var t = nameMap.get(e);

  if (nameMap.set(e, nameMap.get(e) + 1), t > 0) {
    var n = "".concat(e, "_").concat(t);
    return nameMap.set(n, 1), n;
  }

  return e;
}

var tensorNameRegex = new RegExp(/^[A-Za-z0-9][-A-Za-z0-9\._\/]*$/);

function isValidTensorName(e) {
  return !!e.match(tensorNameRegex);
}

function isInteger(e) {
  return e === parseInt(e.toString(), 10);
}

function arrayProd(e, t, n) {
  null == t && (t = 0), null == n && (n = e.length);
  var r = 1;

  for (var a = t; a < n; ++a) {
    r *= e[a];
  }

  return r;
}

function min$2(e) {
  if (0 === e.length) return Number.NaN;
  var t = Number.POSITIVE_INFINITY;

  for (var n = 0; n < e.length; n++) {
    var r = e[n];
    r < t && (t = r);
  }

  return t;
}

function max$2(e) {
  if (0 === e.length) return Number.NaN;
  var t = Number.NEGATIVE_INFINITY;

  for (var n = 0; n < e.length; n++) {
    var r = e[n];
    r > t && (t = r);
  }

  return t;
}

function range$3(e, t) {
  if (t < e) throw new ValueError("end (".concat(t, ") < begin (").concat(e, ") is forbidden."));
  var n = [];

  for (var r = e; r < t; ++r) {
    n.push(r);
  }

  return n;
}

function cast$2(e, t) {
  return cast$3(e, t);
}

function expandDims$2(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : -1;
  var n = e.shape.slice();
  return t < 0 && (t = n.length + t + 1), n.splice(t, 0, 1), reshape$3(e, n);
}

function repeat$1(e, t) {
  return tidy(() => {
    if (2 !== e.shape.length) throw new ValueError("repeat() expects a rank-2 tensor, but received a rank-".concat(e.shape.length, " tensor."));
    return tile$2(expandDims$2(e, 1), [1, t, 1]);
  });
}

function flatten$2(e) {
  var t = [arrayProd(e.shape)];
  return reshape$3(e, t);
}

function batchFlatten(e) {
  if (e.rank <= 1) throw new ValueError("batchFlatten requires a minimum rank of 2. Got rank: ".concat(e.rank, "."));
  var t = [e.shape[0], arrayProd(e.shape, 1)];
  return reshape$3(e, t);
}

function sliceAlongFirstAxis(e, t, n) {
  return tidy(() => {
    switch (e.rank) {
      case 1:
        return slice1d(e, t, n);

      case 2:
        return slice2d(e, [t, 0], [n, e.shape[1]]);

      case 3:
        return slice3d(e, [t, 0, 0], [n, e.shape[1], e.shape[2]]);

      case 4:
        return slice4d(e, [t, 0, 0, 0], [n, e.shape[1], e.shape[2], e.shape[3]]);

      case 5:
        return slice$2(e, [t, 0, 0, 0, 0], [n, e.shape[1], e.shape[2], e.shape[3], e.shape[4]]);

      case 6:
        return slice$2(e, [t, 0, 0, 0, 0, 0], [n, e.shape[1], e.shape[2], e.shape[3], e.shape[4], e.shape[5]]);

      default:
        throw new ValueError("sliceAlongFirstAxis() received an unsupported tensor rank: ".concat(e.rank));
    }
  });
}

function sliceAlongLastAxis(e, t, n) {
  return tidy(() => {
    switch (e.rank) {
      case 1:
        return slice1d(e, t, n);

      case 2:
        return slice2d(e, [0, t], [e.shape[0], n]);

      case 3:
        return slice3d(e, [0, 0, t], [e.shape[0], e.shape[1], n]);

      case 4:
        return slice4d(e, [0, 0, 0, t], [e.shape[0], e.shape[1], e.shape[2], n]);

      default:
        throw new ValueError("sliceAlongLastAxis() received an unsupported tensor rank: ".concat(e.rank));
    }
  });
}

function sliceAlongAxis(e, t, n, r) {
  return tidy(() => {
    switch (e.rank) {
      case 1:
        return slice1d(e, t, n);

      case 2:
        switch (r) {
          case 1:
            return sliceAlongFirstAxis(e, t, n);

          case 2:
            return sliceAlongLastAxis(e, t, n);

          default:
            throw new ValueError("The axis is not within the rank of the tensor ".concat(r));
        }

      case 3:
        switch (r) {
          case 1:
            return sliceAlongFirstAxis(e, t, n);

          case 2:
            return slice3d(e, [0, t, 0], [e.shape[0], n, e.shape[2]]);

          case 3:
            return sliceAlongLastAxis(e, t, n);

          default:
            throw new ValueError("The axis is not within the rank of the tensor ".concat(r));
        }

      case 4:
        switch (r) {
          case 1:
            return sliceAlongFirstAxis(e, t, n);

          case 2:
            return slice4d(e, [0, t, 0, 0], [e.shape[0], n, e.shape[2], e.shape[3]]);

          case 3:
            return slice4d(e, [0, 0, t, 0], [e.shape[0], e.shape[1], n, e.shape[3]]);

          case 4:
            return sliceAlongLastAxis(e, t, n);

          default:
            throw new ValueError("The axis is not within the rank of the tensor ".concat(r));
        }

      default:
        throw new ValueError("sliceAlongLastAxis() received an unsupported tensor rank: ".concat(e.rank));
    }
  });
}

function concatenate$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : -1;
  var n;
  return t < 0 && (n = e[0].rank, t = 0 !== n ? n : 0), t === e[0].rank && (t = -1), concat$2(e, t);
}

function concatAlongFirstAxis(e, t) {
  switch (e.rank) {
    case 1:
      return concat1d([e, t]);

    case 2:
      return concat2d([e, t], 0);

    case 3:
      return concat3d([e, t], 0);

    case 4:
      return concat4d([e, t], 0);

    default:
      throw new ValueError("concatAlongFirstAxis() received an unsupported tensor rank: ".concat(e.rank));
  }
}

function tile$2(e, t) {
  if (Array.isArray(t) || (t = [t]), e.rank !== t.length) throw new ValueError("The length of input n (".concat(t.length, ") does not match the number of dimensions in input x (").concat(e.rank, ")"));
  return tile$3(e, t);
}

function randomNormal$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 0;
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 1;
  var r = arguments.length > 3 ? arguments[3] : undefined;
  var a = arguments.length > 4 ? arguments[4] : undefined;
  return randomNormal$2(e, t, n, r, a);
}

function dot$1(e, t, n, r) {
  if (e.rank < 2 || t.rank < 2) throw new NotImplementedError("dot requires both inputs to be rank >= 2 but got x shape = ".concat(e.shape, " and y shape = ").concat(t.shape));
  if (t.rank >= 3 && e.shape.slice(-1)[0] !== t.shape.slice(-2)[0]) throw new NotImplementedError("If rank y >= 3, then the second last dim of y must equal the last dim of x but got x shape = ".concat(e.shape, " and  y shape = ").concat(t.shape));
  if (2 === e.rank && 2 === t.rank) return matMul({
    a: e,
    b: t,
    transposeA: !1,
    transposeB: !1,
    bias: r ? reshapeBias(e.rank, r, imageDataFormat()) : null,
    activation: n
  });
  {
    var a = e.shape.slice(),
        s = a.pop();
    e = reshape$3(e, [-1, s]);
    var o = t.shape.slice(),
        i = o.pop(),
        l = o.pop(),
        u = [...o, i],
        c = Array.from({
      length: t.rank
    }, (e, n) => 0 === n ? t.rank - 2 : n <= t.rank - 2 ? n - 1 : n);
    t = reshape$3(transpose$2(t, c), [l, -1]);
    var _p23 = [...a, ...u];
    return reshape$3(matMul({
      a: e,
      b: t,
      transposeA: !1,
      transposeB: !1,
      bias: r ? reshapeBias(e.rank, r, imageDataFormat()) : null,
      activation: n
    }), _p23);
  }
}

function gather(e, t, n) {
  return tidy(() => (t = Array.isArray(t) ? tensor1d(t, "int32") : cast$3(t, "int32"), gather$1(e, t, n)));
}

function square$1(e) {
  return mul(e, e);
}

function reshapeBias(e, t, n) {
  var r = t.shape;
  if (1 !== t.rank && t.rank !== e) throw new ValueError("Unexpected bias dimensions: ".concat(t.rank, "; expected it to be 1 or ").concat(e));

  if (5 === e) {
    if ("channelsFirst" === n) return reshape$3(t, 1 === r.length ? [1, r[0], 1, 1, 1] : [1, r[3], r[0], r[1], r[2]]);
    if ("channelsLast" === n) return reshape$3(t, 1 === r.length ? [1, 1, 1, 1, r[0]] : [1].concat(r));
  } else if (4 === e) {
    if ("channelsFirst" === n) return reshape$3(t, 1 === r.length ? [1, r[0], 1, 1] : [1, r[2], r[0], r[1]]);
    if ("channelsLast" === n) return reshape$3(t, 1 === r.length ? [1, 1, 1, r[0]] : [1].concat(r));
  } else if (3 === e) {
    if ("channelsFirst" === n) return reshape$3(t, 1 === r.length ? [1, r[0], 1] : [1, r[1], r[0]]);
    if ("channelsLast" === n) return reshape$3(t, 1 === r.length ? [1, 1, r[0]] : [1].concat(r));
  } else if (e < 3) return t;

  throw new ValueError("Unsupported input rank by biasAdd: ".concat(t.rank));
}

function biasAdd(e, t, n) {
  return tidy(() => (null == n && (n = imageDataFormat()), checkDataFormat(n), add$2(e, reshapeBias(e.rank, t, n))));
}

function elu$3(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 1;
  if (1 !== t) throw new NotImplementedError("Support for alpha values other than 1 (".concat(t, ") is not implemented yet."));
  return elu$4(e);
}

function softsign(e) {
  return tidy(() => div$1(e, add$2(abs$2(e), 1)));
}

function dropout$1(e, t, n, r) {
  return tidy(() => dropout$2(e, t, n, r));
}

function hardSigmoid(e) {
  return tidy(() => {
    var t = add$2(.5, mul(.2, e));
    return clipByValue$1(t, 0, 1);
  });
}

function inTrainPhase(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  return n ? e() : t();
}

var VALID_FAN_MODE_VALUES = ["fanIn", "fanOut", "fanAvg"],
    VALID_DISTRIBUTION_VALUES = ["normal", "uniform", "truncatedNormal"];

function checkFanMode(e) {
  checkStringTypeUnionValue(VALID_FAN_MODE_VALUES, "FanMode", e);
}

function checkDistribution(e) {
  checkStringTypeUnionValue(VALID_DISTRIBUTION_VALUES, "Distribution", e);
}

class Initializer extends Serializable {
  fromConfigUsesCustomObjects() {
    return !1;
  }

  getConfig() {
    return {};
  }

}

class Zeros extends Initializer {
  apply(e, t) {
    return zeros$2(e, t);
  }

}

Zeros.className = "Zeros", registerClass(Zeros);

class Ones extends Initializer {
  apply(e, t) {
    return ones$1(e, t);
  }

}

Ones.className = "Ones", registerClass(Ones);

class Constant extends Initializer {
  constructor(e) {
    if (super(), "object" != typeof e) throw new ValueError("Expected argument of type ConstantConfig but got ".concat(e));
    if (void 0 === e.value) throw new ValueError("config must have value set but got ".concat(e));
    this.value = e.value;
  }

  apply(e, t) {
    return tidy(() => mul(scalar(this.value), ones$1(e, t)));
  }

  getConfig() {
    return {
      value: this.value
    };
  }

}

Constant.className = "Constant", registerClass(Constant);

class RandomUniform extends Initializer {
  constructor(e) {
    super(), this.DEFAULT_MINVAL = -.05, this.DEFAULT_MAXVAL = .05, this.minval = e.minval || this.DEFAULT_MINVAL, this.maxval = e.maxval || this.DEFAULT_MAXVAL, this.seed = e.seed;
  }

  apply(e, t) {
    return randomUniform$1(e, this.minval, this.maxval, t);
  }

  getConfig() {
    return {
      minval: this.minval,
      maxval: this.maxval,
      seed: this.seed
    };
  }

}

RandomUniform.className = "RandomUniform", registerClass(RandomUniform);

class RandomNormal extends Initializer {
  constructor(e) {
    super(), this.DEFAULT_MEAN = 0, this.DEFAULT_STDDEV = .05, this.mean = e.mean || this.DEFAULT_MEAN, this.stddev = e.stddev || this.DEFAULT_STDDEV, this.seed = e.seed;
  }

  apply(e, t) {
    if ("float32" !== (t = t || "float32") && "int32" !== t) throw new NotImplementedError("randomNormal does not support dType ".concat(t, "."));
    return randomNormal$1(e, this.mean, this.stddev, t, this.seed);
  }

  getConfig() {
    return {
      mean: this.mean,
      stddev: this.stddev,
      seed: this.seed
    };
  }

}

RandomNormal.className = "RandomNormal", registerClass(RandomNormal);

class TruncatedNormal extends Initializer {
  constructor(e) {
    super(), this.DEFAULT_MEAN = 0, this.DEFAULT_STDDEV = .05, this.mean = e.mean || this.DEFAULT_MEAN, this.stddev = e.stddev || this.DEFAULT_STDDEV, this.seed = e.seed;
  }

  apply(e, t) {
    if ("float32" !== (t = t || "float32") && "int32" !== t) throw new NotImplementedError("truncatedNormal does not support dType ".concat(t, "."));
    return truncatedNormal$1(e, this.mean, this.stddev, t, this.seed);
  }

  getConfig() {
    return {
      mean: this.mean,
      stddev: this.stddev,
      seed: this.seed
    };
  }

}

TruncatedNormal.className = "TruncatedNormal", registerClass(TruncatedNormal);

class Identity extends Initializer {
  constructor(e) {
    super(), this.gain = null != e.gain ? e.gain : 1;
  }

  apply(e, t) {
    return tidy(() => {
      if (2 !== e.length || e[0] !== e[1]) throw new ValueError("Identity matrix initializer can only be used for 2D square matrices.");
      return mul(this.gain, eye(e[0]));
    });
  }

  getConfig() {
    return {
      gain: this.gain
    };
  }

}

function computeFans(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : "channelsLast";
  var n, r;
  if (checkDataFormat(t), 2 === e.length) n = e[0], r = e[1];else if (-1 !== [3, 4, 5].indexOf(e.length)) {
    if ("channelsFirst" === t) {
      var _t443 = arrayProd(e, 2);

      n = e[1] * _t443, r = e[0] * _t443;
    } else if ("channelsLast" === t) {
      var _t444 = arrayProd(e, 0, e.length - 2);

      n = e[e.length - 2] * _t444, r = e[e.length - 1] * _t444;
    }
  } else {
    var _t445 = arrayProd(e);

    n = Math.sqrt(_t445), r = Math.sqrt(_t445);
  }
  return [n, r];
}

Identity.className = "Identity", registerClass(Identity);

class VarianceScaling extends Initializer {
  constructor(e) {
    if (super(), e.scale < 0) throw new ValueError("scale must be a positive float. Got: ".concat(e.scale));
    this.scale = null == e.scale ? 1 : e.scale, this.mode = null == e.mode ? "fanIn" : e.mode, checkFanMode(this.mode), this.distribution = null == e.distribution ? "normal" : e.distribution, checkDistribution(this.distribution), this.seed = e.seed;
  }

  apply(e, t) {
    var n = computeFans(e),
        r = n[0],
        a = n[1];
    var s = this.scale;

    if (s /= "fanIn" === this.mode ? Math.max(1, r) : "fanOut" === this.mode ? Math.max(1, a) : Math.max(1, (r + a) / 2), "normal" === this.distribution) {
      var _n252 = Math.sqrt(s);

      if ("float32" !== (t = t || "float32") && "int32" !== t) throw new NotImplementedError("".concat(this.getClassName(), " does not support dType ").concat(t, "."));
      return truncatedNormal$1(e, 0, _n252, t, this.seed);
    }

    {
      var _n253 = Math.sqrt(3 * s);

      return randomUniform$1(e, -_n253, _n253, t);
    }
  }

  getConfig() {
    return {
      scale: this.scale,
      mode: this.mode,
      distribution: this.distribution,
      seed: this.seed
    };
  }

}

VarianceScaling.className = "VarianceScaling", registerClass(VarianceScaling);

class GlorotUniform extends VarianceScaling {
  constructor(e) {
    super({
      scale: 1,
      mode: "fanAvg",
      distribution: "uniform",
      seed: null == e ? null : e.seed
    });
  }

  getClassName() {
    return VarianceScaling.className;
  }

}

GlorotUniform.className = "GlorotUniform", registerClass(GlorotUniform);

class GlorotNormal extends VarianceScaling {
  constructor(e) {
    super({
      scale: 1,
      mode: "fanAvg",
      distribution: "normal",
      seed: null == e ? null : e.seed
    });
  }

  getClassName() {
    return VarianceScaling.className;
  }

}

GlorotNormal.className = "GlorotNormal", registerClass(GlorotNormal);

class HeNormal extends VarianceScaling {
  constructor(e) {
    super({
      scale: 2,
      mode: "fanIn",
      distribution: "normal",
      seed: null == e ? null : e.seed
    });
  }

  getClassName() {
    return VarianceScaling.className;
  }

}

HeNormal.className = "HeNormal", registerClass(HeNormal);

class HeUniform extends VarianceScaling {
  constructor(e) {
    super({
      scale: 2,
      mode: "fanIn",
      distribution: "uniform",
      seed: null == e ? null : e.seed
    });
  }

  getClassName() {
    return VarianceScaling.className;
  }

}

HeUniform.className = "HeUniform", registerClass(HeUniform);

class LeCunNormal extends VarianceScaling {
  constructor(e) {
    super({
      scale: 1,
      mode: "fanIn",
      distribution: "normal",
      seed: null == e ? null : e.seed
    });
  }

  getClassName() {
    return VarianceScaling.className;
  }

}

LeCunNormal.className = "LeCunNormal", registerClass(LeCunNormal);

class LeCunUniform extends VarianceScaling {
  constructor(e) {
    super({
      scale: 1,
      mode: "fanIn",
      distribution: "uniform",
      seed: null == e ? null : e.seed
    });
  }

  getClassName() {
    return VarianceScaling.className;
  }

}

LeCunUniform.className = "LeCunNormal", registerClass(LeCunUniform);

class Orthogonal extends Initializer {
  constructor(e) {
    if (super(), this.DEFAULT_GAIN = 1, this.gain = null == e.gain ? this.DEFAULT_GAIN : e.gain, this.seed = e.seed, null != this.seed) throw new NotImplementedError("Random seed is not implemented for Orthogonal Initializer yet.");
  }

  apply(e, t) {
    return tidy(() => {
      if (e.length < 2) throw new NotImplementedError("Shape must be at least 2D.");
      e[0] * e[1] > 2e3 && console.warn("Orthogonal initializer is being called on a matrix with more than 2000 (".concat(e[0] * e[1], ") elements: Slowness may result."));
      var t = randomNormal$1(e[0] > e[1] ? [e[1], e[0]] : e, 0, 1, "float32");
      var n = linalg.gramSchmidt(t);
      return e[0] > e[1] && (n = transpose$2(n)), mul(this.gain, n);
    });
  }

  getConfig() {
    return {
      gain: this.gain,
      seed: this.seed
    };
  }

}

Orthogonal.className = "Orthogonal", registerClass(Orthogonal);
var INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP = {
  constant: "Constant",
  glorotNormal: "GlorotNormal",
  glorotUniform: "GlorotUniform",
  heNormal: "HeNormal",
  heUniform: "HeUniform",
  identity: "Identity",
  leCunNormal: "LeCunNormal",
  leCunUniform: "LeCunUniform",
  ones: "Ones",
  orthogonal: "Orthogonal",
  randomNormal: "RandomNormal",
  randomUniform: "RandomUniform",
  truncatedNormal: "TruncatedNormal",
  varianceScaling: "VarianceScaling",
  zeros: "Zeros"
};

function deserializeInitializer(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};
  return deserializeKerasObject(e, SerializationMap.getMap().classNameMap, t, "initializer");
}

function serializeInitializer(e) {
  return serializeKerasObject(e);
}

function getInitializer(e) {
  if ("string" == typeof e) {
    var t = e in INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP ? INITIALIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP[e] : e;
    if ("GlorotNormal" === t) return new GlorotNormal();
    if ("GlorotUniform" === t) return new GlorotUniform();
    if ("HeNormal" === t) return new HeNormal();
    if ("HeUniform" === t) return new HeUniform();
    if ("LeCunNormal" === t) return new LeCunNormal();
    if ("LeCunUniform" === t) return new LeCunUniform();
    {
      var _e630 = {};
      return _e630.className = t, _e630.config = {}, deserializeInitializer(_e630);
    }
  }

  return e instanceof Initializer ? e : deserializeInitializer(e);
}

function zeros$1() {
  return new Zeros();
}

function ones() {
  return new Ones();
}

function constant(e) {
  return new Constant(e);
}

function randomUniform(e) {
  return new RandomUniform(e);
}

function randomNormal(e) {
  return new RandomNormal(e);
}

function truncatedNormal(e) {
  return new TruncatedNormal(e);
}

function identity$2(e) {
  return new Identity(e);
}

function varianceScaling(e) {
  return new VarianceScaling(e);
}

function glorotUniform(e) {
  return new GlorotUniform(e);
}

function glorotNormal(e) {
  return new GlorotNormal(e);
}

function heNormal(e) {
  return new HeNormal(e);
}

function heUniform(e) {
  return new HeUniform(e);
}

function leCunNormal(e) {
  return new LeCunNormal(e);
}

function leCunUniform(e) {
  return new LeCunUniform(e);
}

function orthogonal(e) {
  return new Orthogonal(e);
}

var exports_initializers = {
  __proto__: null,
  zeros: zeros$1,
  ones,
  constant,
  randomUniform,
  randomNormal,
  truncatedNormal,
  identity: identity$2,
  varianceScaling,
  glorotUniform,
  glorotNormal,
  heNormal,
  heUniform,
  leCunNormal,
  leCunUniform,
  orthogonal
};
var _nextUniqueTensorId = 0;

function getNextUniqueTensorId() {
  return _nextUniqueTensorId++;
}

var _uidPrefixes = {};

function getUid() {
  var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : "";
  return e in _uidPrefixes || (_uidPrefixes[e] = 0), _uidPrefixes[e] += 1, e + _uidPrefixes[e].toString();
}

function isArrayOfShapes(e) {
  return Array.isArray(e) && Array.isArray(e[0]);
}

function normalizeShapeList(e) {
  return 0 === e.length ? [] : Array.isArray(e[0]) ? e : [e];
}

function getExactlyOneTensor(e) {
  var t;

  if (Array.isArray(e)) {
    if (1 !== e.length) throw new ValueError("Expected Tensor length to be 1; got ".concat(e.length));
    t = e[0];
  } else t = e;

  return t;
}

function getExactlyOneShape(e) {
  if (Array.isArray(e) && Array.isArray(e[0])) {
    if (1 === e.length) return (e = e)[0];
    throw new ValueError("Expected exactly 1 Shape; got ".concat(e.length));
  }

  return e;
}

function countParamsInWeights(e) {
  var t = 0;

  for (var n of e) {
    t += 0 === n.shape.length ? 1 : n.shape.reduce((e, t) => e * t);
  }

  return t;
}

var DEFAULT_VARIABLE_NAME_PREFIX = "Variable";

class LayerVariable {
  constructor(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : "float32";
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : DEFAULT_VARIABLE_NAME_PREFIX;
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !0;
    var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : null;
    this.dtype = null == t ? "float32" : t, this.shape = e.shape, this.id = getNextUniqueTensorId(), this.originalName = getScopedTensorName(n = null == n ? DEFAULT_VARIABLE_NAME_PREFIX : n), this.name = getUniqueTensorName(this.originalName), this.trainable_ = r, this.constraint = a, this.val = variable(e, this.trainable_, this.name, this.dtype);
  }

  read() {
    return this.assertNotDisposed(), this.val;
  }

  write(e) {
    return this.assertNotDisposed(), checkShapesMatch(this.val, e), this.val.id !== e.id && (this.val.assign(e), null != this.constraint && this.val.assign(this.constraint.apply(this.val))), this;
  }

  dispose() {
    this.assertNotDisposed(), this.val.dispose();
  }

  assertNotDisposed() {
    if (this.val.isDisposed) throw new Error("LayersVariable ".concat(this.name, " is already disposed."));
  }

  get trainable() {
    return this.trainable_;
  }

  set trainable(e) {
    this.trainable_ = e, this.val.trainable = e;
  }

}

function checkShapesMatch(e, t) {
  if (e.shape.toString() !== t.shape.toString()) throw new Error("Shape mismatch: " + JSON.stringify(e.shape) + " vs. " + JSON.stringify(t.shape));
}

function batchGetValue(e) {
  return e.map(e => e.read());
}

function batchSetValue(e) {
  e.forEach(e => {
    e[0].write(e[1]);
  });
}

class InputSpec {
  constructor(e) {
    this.dtype = e.dtype, this.shape = e.shape, this.ndim = null != e.shape ? e.shape.length : e.ndim, this.maxNDim = e.maxNDim, this.minNDim = e.minNDim, this.axes = e.axes || {};
  }

}

class SymbolicTensor {
  constructor(e, t, n, r, a, s, o) {
    this.dtype = e, this.shape = t, this.sourceLayer = n, this.inputs = r, this.callArgs = a, this.outputTensorIndex = o, this.id = getNextUniqueTensorId(), null != s && (this.originalName = getScopedTensorName(s), this.name = getUniqueTensorName(this.originalName)), this.rank = t.length;
  }

}

var _nextNodeID = 0;

class Node {
  constructor(e, t) {
    this.callArgs = t, this.id = _nextNodeID++, this.outboundLayer = e.outboundLayer, this.inboundLayers = e.inboundLayers, this.nodeIndices = e.nodeIndices, this.tensorIndices = e.tensorIndices, this.inputTensors = e.inputTensors, this.outputTensors = e.outputTensors, this.inputMasks = e.inputMasks, this.outputMasks = e.outputMasks, this.inputShapes = e.inputShapes, this.outputShapes = e.outputShapes;

    for (var _t446 of e.inboundLayers) {
      null != _t446 && _t446.outboundNodes.push(this);
    }

    e.outboundLayer.inboundNodes.push(this);
  }

  getConfig() {
    var e = [];

    for (var t of this.inboundLayers) {
      e.push(null != t ? t.name : null);
    }

    return {
      outboundLayer: this.outboundLayer ? this.outboundLayer.name : null,
      inboundLayers: e,
      nodeIndices: this.nodeIndices,
      tensorIndices: this.tensorIndices
    };
  }

}

var _nextLayerID = 0;

class Layer extends Serializable {
  constructor() {
    var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};
    super(), this._callHook = null, this._addedWeightNames = [], this._stateful = !1, this.id = _nextLayerID++, this.activityRegularizer = null, this.inputSpec = null, this.supportsMasking = !1, this._trainableWeights = [], this._nonTrainableWeights = [], this._losses = [], this._updates = [], this._built = !1, this.inboundNodes = [], this.outboundNodes = [];
    var t = e.name;

    if (!t) {
      var _e631 = this.getClassName();

      t = toSnakeCase(_e631) + "_" + getUid(_e631);
    }

    if (this.name = t, this.trainable_ = null == e.trainable || e.trainable, null != e.inputShape || null != e.batchInputShape) {
      var _t447;

      if (null != e.batchInputShape) _t447 = e.batchInputShape;else if (null != e.inputShape) {
        var _n254 = null;
        null != e.batchSize && (_n254 = e.batchSize), _t447 = [_n254].concat(e.inputShape);
      }
      this.batchInputShape = _t447;
      var n = e.dtype;
      null == n && (n = e.inputDType), null == n && (n = "float32"), this.dtype = n;
    }

    this.initialWeights = null != e.weights ? e.weights : null, this._refCount = null, this.fastWeightInitDuringBuild = !1;
  }

  static nodeKey(e, t) {
    return e.name + "_ib-" + t.toString();
  }

  getNodeAtIndex(e, t) {
    if (0 === this.inboundNodes.length) throw new RuntimeError("The layer has never been called and thus has no defined ".concat(t, "."));
    if (this.inboundNodes.length <= e) throw new ValueError("Asked to get ".concat(t, " at node ").concat(e, ", but the layer has only ").concat(this.inboundNodes.length, " inbound nodes."));
    return this.inboundNodes[e];
  }

  getInputAt(e) {
    return singletonOrArray(this.getNodeAtIndex(e, "input").inputTensors);
  }

  getOutputAt(e) {
    return singletonOrArray(this.getNodeAtIndex(e, "output").outputTensors);
  }

  get input() {
    if (this.inboundNodes.length > 1) throw new AttributeError("Layer ".concat(this.name, " has multiple inbound nodes, hence the notion of \"layer input\" is ill-defined. Use `getInputAt(nodeIndex)` instead."));
    if (0 === this.inboundNodes.length) throw new AttributeError("Layer ".concat(this.name, " is not connected, no input to return."));
    return singletonOrArray(this.getNodeAtIndex(0, "input").inputTensors);
  }

  get output() {
    if (0 === this.inboundNodes.length) throw new AttributeError("Layer ".concat(this.name, " has no inbound nodes."));
    if (this.inboundNodes.length > 1) throw new AttributeError("Layer ".concat(this.name, " has multiple inbound nodes, hence the notion of \"layer output\" is ill-defined. Use `getOutputAt(nodeIndex)` instead."));
    return singletonOrArray(this.getNodeAtIndex(0, "output").outputTensors);
  }

  get losses() {
    return this._losses;
  }

  calculateLosses() {
    return this.losses.map(e => e());
  }

  get updates() {
    return this._updates;
  }

  get built() {
    return this._built;
  }

  set built(e) {
    this._built = e;
  }

  get trainable() {
    return this.trainable_;
  }

  set trainable(e) {
    this._trainableWeights.forEach(t => t.trainable = e), this.trainable_ = e;
  }

  get trainableWeights() {
    return this.trainable_ ? this._trainableWeights.filter(e => e.trainable) : [];
  }

  set trainableWeights(e) {
    this._trainableWeights = e;
  }

  get nonTrainableWeights() {
    return this.trainable ? this._trainableWeights.filter(e => !e.trainable).concat(this._nonTrainableWeights) : this._trainableWeights.concat(this._nonTrainableWeights);
  }

  set nonTrainableWeights(e) {
    this._nonTrainableWeights = e;
  }

  get weights() {
    return this.trainableWeights.concat(this.nonTrainableWeights);
  }

  get stateful() {
    return this._stateful;
  }

  resetStates() {
    if (!this.stateful) throw new Error("Cannot call the resetStates() method of a non-stateful Layer object.");
  }

  assertInputCompatibility(e) {
    if (e = toList(e), null == this.inputSpec || 0 === this.inputSpec.length) return;
    var t = toList(this.inputSpec);
    if (e.length !== t.length) throw new ValueError("Layer ".concat(this.name, " expects ").concat(t.length, " inputs, but it received ").concat(e.length, " input tensors. Input received: ").concat(e));

    for (var n = 0; n < e.length; n++) {
      var r = e[n],
          a = t[n];
      if (null == a) continue;
      var s = r.rank;
      if (null != a.ndim && s !== a.ndim) throw new ValueError("Input ".concat(n, " is incompatible with layer ").concat(this.name, ": expected ndim=").concat(a.ndim, ", found ndim=").concat(s));
      if (null != a.maxNDim && s > a.maxNDim) throw new ValueError("Input ".concat(n, " is incompatible with layer ").concat(this.name, ": expected max_ndim=").concat(a.maxNDim, ", found ndim=").concat(s));
      if (null != a.minNDim && s < a.minNDim) throw new ValueError("Input ".concat(n, " is incompatible with layer ").concat(this.name, ": expected min_ndim=").concat(a.minNDim, ", found ndim=").concat(s, "."));
      if (null != a.dtype && r.dtype !== a.dtype) throw new ValueError("Input ".concat(n, " is incompatible with layer ").concat(this.name, " : expected dtype=").concat(a.dtype, ", found dtype=").concat(r.dtype, "."));

      if (a.axes) {
        var _e632 = r.shape;

        for (var _t448 in a.axes) {
          var _r205 = Number(_t448),
              _s101 = a.axes[_t448],
              o = _r205 >= 0 ? _e632[_r205] : _e632[_e632.length + _r205];

          if (null != _s101 && -1 === [_s101, null].indexOf(o)) throw new ValueError("Input ".concat(n, " is incompatible with layer ").concat(this.name, ": expected axis ").concat(_r205, " of input shape to have value ").concat(_s101, " but got shape ").concat(_e632, "."));
        }
      }

      if (null != a.shape) for (var _e633 = 0; _e633 < a.shape.length; ++_e633) {
        var _t449 = a.shape[_e633],
            _s102 = r.shape[_e633];
        if (null != _t449 && null != _s102 && _t449 !== _s102) throw new ValueError("Input ".concat(n, " is incompatible with layer ").concat(this.name, ": expected shape=").concat(a.shape, ", found shape=").concat(r.shape, "."));
      }
    }
  }

  call(e, t) {
    return e;
  }

  invokeCallHook(e, t) {
    null != this._callHook && this._callHook(e, t);
  }

  setCallHook(e) {
    this._callHook = e;
  }

  clearCallHook() {
    this._callHook = null;
  }

  apply(e, t) {
    t = t || {}, this.assertNotDisposed();
    var n = toList(e);
    var r = !0;

    for (var _e634 of n) {
      if (!(_e634 instanceof SymbolicTensor)) {
        r = !1;
        break;
      }
    }

    var a = !0;

    for (var _e635 of n) {
      if (_e635 instanceof SymbolicTensor) {
        a = !1;
        break;
      }
    }

    if (r === a) throw new ValueError("Arguments to apply() must be all SymbolicTensors or all Tensors");
    return nameScope(this.name, () => {
      if (!this.built) {
        this.assertInputCompatibility(e);
        var _t450 = [];

        for (var _n255 of toList(e)) {
          _t450.push(_n255.shape);
        }

        this.build(singletonOrArray(_t450)), this.built = !0, this.initialWeights && this.setWeights(this.initialWeights), null === this._refCount && a && (this._refCount = 1);
      }

      if (this.assertInputCompatibility(e), a) {
        var _r206 = this.call(e, t);

        var _a142 = toList(_r206),
            s = [];

        for (var _e636 of _a142) {
          -1 !== n.indexOf(_e636) && (_e636 = _e636.clone()), s.push(_e636);
        }

        if (_r206 = singletonOrArray(s), null != this.activityRegularizer) throw new NotImplementedError("Layer invocation in the presence of activity regularizer(s) is not supported yet.");
        return _r206;
      }

      {
        var _n256 = collectInputShape(e),
            _r207 = this.computeOutputShape(_n256);

        var _a143;

        var _s103 = guessOutputDType(e);

        if (this.warnOnIncompatibleInputShape(Array.isArray(e) ? _n256[0] : _n256), _a143 = null != _r207 && _r207.length > 0 && Array.isArray(_r207[0]) ? _r207.map((n, r) => new SymbolicTensor(_s103, n, this, toList(e), t, this.name, r)) : new SymbolicTensor(_s103, _r207, this, toList(e), t, this.name), this.addInboundNode(e, _a143, null, null, _n256, _r207, t), this._refCount++, null != this.activityRegularizer) throw new NotImplementedError("Layer invocation in the presence of activity regularizer(s) is not supported yet.");
        return _a143;
      }
    });
  }

  warnOnIncompatibleInputShape(e) {
    if (null != this.batchInputShape) if (e.length !== this.batchInputShape.length) console.warn("The rank of the input tensor provided (shape: ".concat(JSON.stringify(e), ") does not match that of the batchInputShape (").concat(JSON.stringify(this.batchInputShape), ") of the layer ").concat(this.name));else {
      var t = !1;
      this.batchInputShape.forEach((n, r) => {
        null != n && null != e[r] && e[r] !== n && (t = !0);
      }), t && console.warn("The shape of the input tensor (".concat(JSON.stringify(e), ") does not match the expectation of layer ").concat(this.name, ": ").concat(JSON.stringify(this.batchInputShape)));
    }
  }

  get outputShape() {
    if (null == this.inboundNodes || 0 === this.inboundNodes.length) throw new AttributeError("The layer ".concat(this.name, " has never been called and thus has no defined output shape."));
    var e = [];

    for (var t of this.inboundNodes) {
      var n = JSON.stringify(t.outputShapes);
      -1 === e.indexOf(n) && e.push(n);
    }

    if (1 === e.length) {
      var _e637 = this.inboundNodes[0].outputShapes;
      return Array.isArray(_e637) && Array.isArray(_e637[0]) && 1 === _e637.length ? _e637[0] : _e637;
    }

    throw new AttributeError("The layer ".concat(this.name, " has multiple inbound nodes with different output shapes. Hence the notion of \"output shape\" is ill-defined for the layer."));
  }

  countParams() {
    if (!this.built) throw new RuntimeError("You tried to call countParams() on ".concat(this.name, ", but the layer is not built yet. Build it first by calling build(batchInputShape)."));
    return countParamsInWeights(this.weights);
  }

  build(e) {
    this.built = !0;
  }

  getWeights() {
    var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : !1;
    return batchGetValue(e ? this.trainableWeights : this.weights);
  }

  setWeights(e) {
    tidy(() => {
      var t = this.weights;
      if (t.length !== e.length) throw new ValueError("You called setWeights(weights) on layer \"".concat(this.name, "\" with a weight list of length ").concat(e.length, ", but the layer was expecting ").concat(t.length, " weights. Provided weights: ").concat(e, "..."));
      if (0 === t.length) return;
      var n = [],
          r = batchGetValue(t);

      for (var a = 0; a < r.length; ++a) {
        var s = r[a],
            o = t[a],
            i = e[a];
        if (!arraysEqual(s.shape, i.shape)) throw new ValueError("Layer weight shape ".concat(s.shape, " not compatible with provided weight shape ").concat(i.shape));
        n.push([o, i]);
      }

      batchSetValue(n);
    });
  }

  addWeight(e, t, n, r, a, s, o) {
    if (-1 !== this._addedWeightNames.indexOf(e)) throw new ValueError("Duplicate weight name ".concat(e, " for layer ").concat(this.name));
    this._addedWeightNames.push(e), null == n && (n = "float32"), this.fastWeightInitDuringBuild && (r = getInitializer("zeros"));
    var i = r.apply(t, n),
        l = new LayerVariable(i, n, e, s, o);
    return i.dispose(), null != a && this.addLoss(() => a.apply(l.read())), null == s && (s = !0), s ? this._trainableWeights.push(l) : this._nonTrainableWeights.push(l), l;
  }

  setFastWeightInitDuringBuild(e) {
    this.fastWeightInitDuringBuild = e;
  }

  addLoss(e) {
    null == e || Array.isArray(e) && 0 === e.length || (e = toList(e), null != this._losses && this.losses.push(...e));
  }

  computeOutputShape(e) {
    return e;
  }

  computeMask(e, t) {
    if (!this.supportsMasking) {
      if (null != t) {
        if (!Array.isArray(t)) throw new TypeError("Layer ".concat(this.name, " does not support masking, but was passed an inputMask."));
        t.forEach(e => {
          if (null != e) throw new TypeError("Layer ".concat(this.name, " does not support masking, but was passed an inputMask."));
        });
      }

      return null;
    }

    return t;
  }

  addInboundNode(e, t, n, r, a, s) {
    var o = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : null;
    var i = toList(e);
    t = toList(t), n = toList(n), r = toList(r), a = normalizeShapeList(a), s = normalizeShapeList(s);
    var l = [],
        u = [],
        c = [];

    for (var _e638 of i) {
      l.push(_e638.sourceLayer), u.push(_e638.nodeIndex), c.push(_e638.tensorIndex);
    }

    new Node({
      outboundLayer: this,
      inboundLayers: l,
      nodeIndices: u,
      tensorIndices: c,
      inputTensors: i,
      outputTensors: t,
      inputMasks: n,
      outputMasks: r,
      inputShapes: a,
      outputShapes: s
    }, o);

    for (var _e639 = 0; _e639 < t.length; _e639++) {
      t[_e639].sourceLayer = this, t[_e639].nodeIndex = this.inboundNodes.length - 1, t[_e639].tensorIndex = _e639;
    }
  }

  getConfig() {
    var e = {
      name: this.name,
      trainable: this.trainable
    };
    return null != this.batchInputShape && (e.batchInputShape = this.batchInputShape), null != this.dtype && (e.dtype = this.dtype), e;
  }

  disposeWeights() {
    return this.weights.forEach(e => e.dispose()), this.weights.length;
  }

  assertNotDisposed() {
    if (0 === this._refCount) throw new Error("Layer '".concat(this.name, "' is already disposed."));
  }

  dispose() {
    if (!this.built) throw new Error("Cannot dispose Layer ".concat(this.name, " because it has not been built yet."));
    if (null === this._refCount) throw new Error("Cannot dispose Layer ".concat(this.name, " because it has not been used yet."));
    this.assertNotDisposed();
    var e = 0;
    return 0 == --this._refCount && (e = this.disposeWeights()), {
      refCountAfterDispose: this._refCount,
      numDisposedVariables: e
    };
  }

}

function collectInputShape(e) {
  e = toList(e);
  var t = [];

  for (var n of e) {
    t.push(n.shape);
  }

  return singletonOrArray(t);
}

function guessOutputDType(e) {
  return "float32";
}

function getSourceInputs(e, t, n) {
  if ((null == t || null != n && n > 0) && (t = e.sourceLayer, n = e.nodeIndex), 0 === t.inboundNodes.length) return [e];
  {
    var _e640 = t.inboundNodes[n];
    if (0 === _e640.inboundLayers.length) return _e640.inputTensors;
    {
      var _t451 = [];

      for (var _n257 = 0; _n257 < _e640.inboundLayers.length; _n257++) {
        var r = getSourceInputs(_e640.inputTensors[_n257], _e640.inboundLayers[_n257], _e640.nodeIndices[_n257]);

        for (var _e641 of r) {
          -1 === _t451.indexOf(_e641) && _t451.push(_e641);
        }
      }

      return _t451;
    }
  }
}

class InputLayer extends Layer {
  constructor(e) {
    if (super({
      dtype: e.dtype,
      name: null != e.name ? e.name : getUid("input").toString()
    }), null == e.batchSize && (e.batchSize = null), null == e.sparse && (e.sparse = !1), this.trainable = !1, this.built = !0, this.sparse = e.sparse, null != e.inputShape && null != e.batchInputShape) throw new ValueError("Only provide the inputShape OR batchInputShape argument to inputLayer, not both at the same time.");
    var t = e.batchInputShape;

    if (null == t) {
      if (null == e.inputShape) throw new ValueError("An InputLayer should be passed either a `batchInputShape` or an `inputShape`.");
      t = [e.batchSize].concat(e.inputShape);
    } else if (null != e.batchSize) throw new ValueError("Cannot specify batchSize if batchInputShape is specified when creating an InputLayer.");

    var n = e.dtype || "float32";
    this.batchInputShape = t, this.dtype = n, this.inputSpec = [{
      shape: t
    }];
    var r = new SymbolicTensor(this.dtype, this.batchInputShape, this, [], {}, this.name);
    r.nodeIndex = 0, r.tensorIndex = 0, new Node({
      outboundLayer: this,
      inboundLayers: [],
      nodeIndices: [],
      tensorIndices: [],
      inputTensors: [r],
      outputTensors: [r],
      inputMasks: [null],
      outputMasks: [null],
      inputShapes: [t],
      outputShapes: [t]
    });
  }

  apply(e, t) {
    throw new ValueError("Cannot pass any input to an InputLayer's apply() method. InputLayer name: ".concat(this.name));
  }

  dispose() {
    return {
      refCountAfterDispose: this._refCount,
      numDisposedVariables: 0
    };
  }

  getConfig() {
    return {
      batchInputShape: this.batchInputShape,
      dtype: this.dtype,
      sparse: this.sparse,
      name: this.name
    };
  }

}

function Input(e) {
  if (null == e.batchShape && null == e.shape) throw new Error("Please provide to Input either a `shape` or a `batchShape` argument. Note that `shape` does not include the batch dimension.");
  if (null != e.batchShape && null != e.shape) throw new ValueError("Please provide either a `shape` or `batchShape` argument to Input, but not both.");
  var t = e.batchShape;
  null != e.shape && null == t && (t = [null].concat(e.shape));
  var n = e.dtype;
  return null == n && (n = "float32"), new InputLayer({
    batchInputShape: t,
    name: e.name,
    dtype: n,
    sparse: e.sparse
  }).inboundNodes[0].outputTensors[0];
}

function resolveScalarsInLogs(_x86) {
  return _resolveScalarsInLogs.apply(this, arguments);
}

function _resolveScalarsInLogs() {
  _resolveScalarsInLogs = _asyncToGenerator(function* (e) {
    if (null == e) return;
    var t = [],
        n = [],
        r = [];

    for (var a in e) {
      var s = e[a];

      if ("number" != typeof s) {
        var _e1161 = s;
        t.push(_e1161.data()), n.push(a), r.push(_e1161);
      }
    }

    if (t.length > 0) {
      var _a321 = yield Promise.all(t);

      for (var _t778 = 0; _t778 < _a321.length; ++_t778) {
        e[n[_t778]] = _a321[_t778][0];
      }

      dispose(r);
    }
  });
  return _resolveScalarsInLogs.apply(this, arguments);
}

function disposeTensorsInLogs(e) {
  if (null != e) for (var t in e) {
    var n = e[t];
    "number" != typeof n && n.dispose();
  }
}

var ModelLoggingVerbosity;
InputLayer.className = "InputLayer", registerClass(InputLayer), function (e) {
  e[e.SILENT = 0] = "SILENT", e[e.VERBOSE = 1] = "VERBOSE";
}(ModelLoggingVerbosity || (ModelLoggingVerbosity = {}));
var DEFAULT_YIELD_EVERY_MS = 125;

class BaseCallback {
  constructor() {
    this.validationData = null;
  }

  setParams(e) {
    this.params = e;
  }

  onEpochBegin(e, t) {
    return _asyncToGenerator(function* () {})();
  }

  onEpochEnd(e, t) {
    return _asyncToGenerator(function* () {})();
  }

  onBatchBegin(e, t) {
    return _asyncToGenerator(function* () {})();
  }

  onBatchEnd(e, t) {
    return _asyncToGenerator(function* () {})();
  }

  onTrainBegin(e) {
    return _asyncToGenerator(function* () {})();
  }

  onTrainEnd(e) {
    return _asyncToGenerator(function* () {})();
  }

  setModel(e) {}

}

class CallbackList {
  constructor(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 10;
    null == e && (e = []), this.callbacks = e, this.queueLength = t;
  }

  append(e) {
    this.callbacks.push(e);
  }

  setParams(e) {
    for (var t of this.callbacks) {
      t.setParams(e);
    }
  }

  setModel(e) {
    for (var t of this.callbacks) {
      t.setModel(e);
    }
  }

  onEpochBegin(e, t) {
    var _this116 = this;

    return _asyncToGenerator(function* () {
      null == t && (t = {});

      for (var n of _this116.callbacks) {
        yield n.onEpochBegin(e, t);
      }
    })();
  }

  onEpochEnd(e, t) {
    var _this117 = this;

    return _asyncToGenerator(function* () {
      null == t && (t = {});

      for (var n of _this117.callbacks) {
        yield n.onEpochEnd(e, t);
      }
    })();
  }

  onBatchBegin(e, t) {
    var _this118 = this;

    return _asyncToGenerator(function* () {
      null == t && (t = {});

      for (var n of _this118.callbacks) {
        yield n.onBatchBegin(e, t);
      }
    })();
  }

  onBatchEnd(e, t) {
    var _this119 = this;

    return _asyncToGenerator(function* () {
      null == t && (t = {});

      for (var n of _this119.callbacks) {
        yield n.onBatchEnd(e, t);
      }
    })();
  }

  onTrainBegin(e) {
    var _this120 = this;

    return _asyncToGenerator(function* () {
      null == e && (e = {});

      for (var t of _this120.callbacks) {
        yield t.onTrainBegin(e);
      }
    })();
  }

  onTrainEnd(e) {
    var _this121 = this;

    return _asyncToGenerator(function* () {
      null == e && (e = {});

      for (var t of _this121.callbacks) {
        yield t.onTrainEnd(e);
      }
    })();
  }

}

class BaseLogger extends BaseCallback {
  constructor() {
    super();
  }

  onEpochBegin(e) {
    var _this122 = this;

    return _asyncToGenerator(function* () {
      _this122.seen = 0, _this122.totals = {};
    })();
  }

  onBatchEnd(e, t) {
    var _this123 = this;

    return _asyncToGenerator(function* () {
      null == t && (t = {});
      var n = null == t.size ? 0 : t.size;
      _this123.seen += n;

      var _loop39 = function _loop39(_e642) {
        var r = t[_e642];
        if ("number" == typeof r) _this123.totals.hasOwnProperty(_e642) || (_this123.totals[_e642] = 0), _this123.totals[_e642] = _this123.totals[_e642] + r * n;else {
          var _t452;

          _e642 in _this123.totals ? _t452 = _this123.totals[_e642] : _this123.totals[_e642] = 0;
          var a = tidy(() => add$2(_this123.totals[_e642], mul(r, n)));
          _this123.totals[_e642] = a, null != _t452 && _t452.dispose();
        }
      };

      for (var _e642 in t) {
        _loop39(_e642);
      }
    })();
  }

  onEpochEnd(e, t) {
    var _this124 = this;

    return _asyncToGenerator(function* () {
      if (null != t) {
        var _loop40 = function _loop40(_e643) {
          null != _this124.totals[_e643] && ("number" == typeof _this124.totals[_e643] ? t[_e643] = _this124.totals[_e643] / _this124.seen : tidy(() => {
            var n = mul(div$1(1, _this124.seen), _this124.totals[_e643]);
            t[_e643] = n, _this124.totals[_e643].dispose(), keep(t[_e643]);
          }));
        };

        for (var _e643 of _this124.params.metrics) {
          _loop40(_e643);
        }
      }
    })();
  }

}

class History extends BaseCallback {
  onTrainBegin(e) {
    var _this125 = this;

    return _asyncToGenerator(function* () {
      _this125.epoch = [], _this125.history = {};
    })();
  }

  onEpochEnd(e, t) {
    var _this126 = this;

    return _asyncToGenerator(function* () {
      null == t && (t = {}), _this126.epoch.push(e);

      for (var _e644 in t) {
        null == _this126.history[_e644] && (_this126.history[_e644] = []), _this126.history[_e644].push(t[_e644]);
      }
    })();
  }

  syncData() {
    var _this127 = this;

    return _asyncToGenerator(function* () {
      var e = [],
          t = [],
          n = [];

      for (var _r208 in _this127.history) {
        var a = _this127.history[_r208];

        for (var s = 0; s < a.length; ++s) {
          "number" != typeof a[s] && (e.push(a[s].data()), t.push(_r208), n.push(s));
        }
      }

      var r = yield Promise.all(e);

      for (var _e645 = 0; _e645 < r.length; ++_e645) {
        _this127.history[t[_e645]][n[_e645]].dispose(), _this127.history[t[_e645]][n[_e645]] = r[_e645][0];
      }
    })();
  }

}

class CustomCallback extends BaseCallback {
  constructor(e, t) {
    if (super(), this.currentEpoch = 0, this.yieldEvery = t || "auto", "auto" === this.yieldEvery && (this.yieldEvery = DEFAULT_YIELD_EVERY_MS), "never" === this.yieldEvery && null != e.onYield) throw new Error("yieldEvery is `never` but you provided an `onYield` callback. Either change `yieldEvery` or remove the callback");
    isNumber(this.yieldEvery) && (this.maybeWait = debounce(this.maybeWait.bind(this), this.yieldEvery)), this.trainBegin = e.onTrainBegin, this.trainEnd = e.onTrainEnd, this.epochBegin = e.onEpochBegin, this.epochEnd = e.onEpochEnd, this.batchBegin = e.onBatchBegin, this.batchEnd = e.onBatchEnd, this.yield = e.onYield;
  }

  maybeWait(e, t, n) {
    var _this128 = this;

    return _asyncToGenerator(function* () {
      var r = [];
      null != _this128.yield && (yield resolveScalarsInLogs(n), r.push(_this128.yield(e, t, n))), r.push(nextFrame()), yield Promise.all(r);
    })();
  }

  onEpochBegin(e, t) {
    var _this129 = this;

    return _asyncToGenerator(function* () {
      _this129.currentEpoch = e, null != _this129.epochBegin && (yield resolveScalarsInLogs(t), yield _this129.epochBegin(e, t));
    })();
  }

  onEpochEnd(e, t) {
    var _this130 = this;

    return _asyncToGenerator(function* () {
      var n = [];
      null != _this130.epochEnd && (yield resolveScalarsInLogs(t), n.push(_this130.epochEnd(e, t))), "epoch" === _this130.yieldEvery && n.push(nextFrame()), yield Promise.all(n);
    })();
  }

  onBatchBegin(e, t) {
    var _this131 = this;

    return _asyncToGenerator(function* () {
      null != _this131.batchBegin && (yield resolveScalarsInLogs(t), yield _this131.batchBegin(e, t));
    })();
  }

  onBatchEnd(e, t) {
    var _this132 = this;

    return _asyncToGenerator(function* () {
      var n = [];
      null != _this132.batchEnd && (yield resolveScalarsInLogs(t), n.push(_this132.batchEnd(e, t))), "batch" === _this132.yieldEvery ? n.push(nextFrame()) : isNumber(_this132.yieldEvery) && n.push(_this132.maybeWait(_this132.currentEpoch, e, t)), yield Promise.all(n);
    })();
  }

  onTrainBegin(e) {
    var _this133 = this;

    return _asyncToGenerator(function* () {
      null != _this133.trainBegin && (yield resolveScalarsInLogs(e), yield _this133.trainBegin(e));
    })();
  }

  onTrainEnd(e) {
    var _this134 = this;

    return _asyncToGenerator(function* () {
      null != _this134.trainEnd && (yield resolveScalarsInLogs(e), yield _this134.trainEnd(e));
    })();
  }

}

function standardizeCallbacks(e, t) {
  return null == e && (e = {}), e instanceof BaseCallback ? [e] : Array.isArray(e) && e[0] instanceof BaseCallback ? e : toList(e).map(e => new CustomCallback(e, t));
}

class CallbackConstructorRegistry {
  constructor() {}

  static registerCallbackConstructor(e, t) {
    assert$4(e >= 0 && Number.isInteger(e), () => "Verbosity level is expected to be an integer >= 0, but got ".concat(e)), CallbackConstructorRegistry.checkForDuplicate(t), null == CallbackConstructorRegistry.constructors[e] && (CallbackConstructorRegistry.constructors[e] = []), CallbackConstructorRegistry.constructors[e].push(t);
  }

  static checkForDuplicate(e) {
    for (var t in CallbackConstructorRegistry.constructors) {
      CallbackConstructorRegistry.constructors[+t].forEach(t => {
        if (t === e) throw new ValueError("Duplicate callback constructor.");
      });
    }
  }

  static clear() {
    CallbackConstructorRegistry.constructors = {};
  }

  static createCallbacks(e) {
    var t = [];

    for (var n in CallbackConstructorRegistry.constructors) {
      var r = +n;
      e >= r && t.push(...CallbackConstructorRegistry.constructors[r]);
    }

    return t.map(e => new e());
  }

}

function configureCallbacks(e, t, n, r, a, s, o, i, l) {
  var u = new History(),
      c = [new BaseLogger(), ...CallbackConstructorRegistry.createCallbacks(t)];
  null != e && c.push(...e), c.push(u);
  var p = new CallbackList(c);
  return p.setParams({
    epochs: n,
    initialEpoch: r,
    samples: a,
    steps: s,
    batchSize: o,
    verbose: t,
    doValidation: i,
    metrics: l
  }), {
    callbackList: p,
    history: u
  };
}

function deserialize(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  return deserializeKerasObject(e, SerializationMap.getMap().classNameMap, t, "layer", n);
}

function l2Normalize(e, t) {
  return tidy(() => {
    "float32" !== e.dtype && (e = cast$3(e, "float32"));
    var n = sum$2(square$1(e), t, !0),
        r = fill$2(n.shape, epsilon$1()),
        a = sqrt$2(maximum$3(n, r));
    return div$1(e, a);
  });
}

function meanSquaredError$1(e, t) {
  return tidy(() => mean$1(square$1(sub$2(t, e)), -1));
}

function meanAbsoluteError$1(e, t) {
  return tidy(() => mean$1(abs$2(sub$2(t, e)), -1));
}

function meanAbsolutePercentageError$1(e, t) {
  return tidy(() => {
    var n = sub$2(e, t),
        r = clipByValue$1(abs$2(e), epsilon$1(), Number.MAX_VALUE),
        a = abs$2(div$1(n, r));
    return mul(100, mean$1(a, -1));
  });
}

function meanSquaredLogarithmicError(e, t) {
  return tidy(() => {
    var n = clipByValue$1(t, epsilon$1(), Number.MAX_VALUE),
        r = log$3(add$2(1, n)),
        a = clipByValue$1(e, epsilon$1(), Number.MAX_VALUE),
        s = log$3(add$2(1, a));
    return mean$1(square$1(sub$2(r, s)), -1);
  });
}

function squaredHinge(e, t) {
  return tidy(() => {
    var n = maximum$3(0, sub$2(1, mul(e, t)));
    return mean$1(square$1(n), -1);
  });
}

function hinge(e, t) {
  return tidy(() => {
    var n = maximum$3(0, sub$2(1, mul(e, t)));
    return mean$1(n, -1);
  });
}

function categoricalHinge(e, t) {
  return tidy(() => {
    var n = sum$2(mul(e, t), -1),
        r = max$3(mul(sub$2(1, e), t), -1);
    return maximum$3(0, add$2(1, sub$2(r, n)));
  });
}

function logcosh(e, t) {
  return tidy(() => {
    var n = Math.log(2),
        r = sub$2(t, e),
        a = sub$2(add$2(r, softplus$2(mul(-2, r))), n);
    return mean$1(a, -1);
  });
}

function categoricalCrossentropy$2(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  return tidy(() => {
    if (n) t = softmax$3(t);else {
      var _e646 = sum$2(t, t.shape.length - 1, !0);

      t = div$1(t, _e646);
    }
    return t = clipByValue$1(t, epsilon$1(), 1 - epsilon$1()), neg$2(sum$2(mul(cast$3(e, "float32"), log$3(t)), t.shape.length - 1));
  });
}

function sparseCategoricalCrossentropy$1(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  return tidy(() => {
    var r = cast$3(floor$2(flatten$2(e)), "int32"),
        a = (t = clipByValue$1(t, epsilon$1(), 1 - epsilon$1())).shape;
    return categoricalCrossentropy$2(reshape$3(oneHot$2(r, a[a.length - 1]), a), t, n);
  });
}

function sigmoidCrossEntropyWithLogits(e, t) {
  if (!arraysEqual(e.shape, t.shape)) throw new ValueError("logits and labels must have the same shape, but got shapes ".concat(JSON.stringify(e.shape), " and ").concat(JSON.stringify(t.shape)));
  return tidy(() => {
    var n = relu$3(t),
        r = neg$2(abs$2(t));
    return add$2(sub$2(n, mul(t, e)), log1p$2(exp$2(r)));
  });
}

function binaryCrossentropy$2(e, t) {
  return tidy(() => {
    var n;
    return n = clipByValue$1(t, epsilon$1(), 1 - epsilon$1()), n = log$3(div$1(n, sub$2(1, n))), mean$1(sigmoidCrossEntropyWithLogits(e, n), -1);
  });
}

function kullbackLeiblerDivergence(e, t) {
  return tidy(() => {
    var n = clipByValue$1(e, epsilon$1(), 1),
        r = clipByValue$1(t, epsilon$1(), 1);
    return sum$2(mul(e, log$3(div$1(n, r))), -1);
  });
}

function poisson(e, t) {
  return tidy(() => {
    var n = log$3(add$2(epsilon$1(), t));
    return mean$1(sub$2(t, mul(e, n)), -1);
  });
}

function cosineProximity$1(e, t) {
  return tidy(() => {
    var n = l2Normalize(e, -1),
        r = l2Normalize(t, -1),
        a = mul(n, r);
    return neg$2(sum$2(a, -1));
  });
}

CallbackConstructorRegistry.constructors = {};
var lossesMap = {
  meanSquaredError: meanSquaredError$1,
  meanAbsoluteError: meanAbsoluteError$1,
  meanAbsolutePercentageError: meanAbsolutePercentageError$1,
  meanSquaredLogarithmicError,
  squaredHinge,
  hinge,
  categoricalHinge,
  logcosh,
  categoricalCrossentropy: categoricalCrossentropy$2,
  sparseCategoricalCrossentropy: sparseCategoricalCrossentropy$1,
  binaryCrossentropy: binaryCrossentropy$2,
  kullbackLeiblerDivergence,
  poisson,
  cosineProximity: cosineProximity$1
};

function get$1(e) {
  if ("string" == typeof e) {
    if (e in lossesMap) return lossesMap[e];
    var t = "Unknown loss ".concat(e);
    throw e.toLowerCase().includes("softmaxcrossentropy") && (t = "Unknown loss ".concat(e, ". Use \"categoricalCrossentropy\" as the string name for tf.losses.softmaxCrossEntropy")), new ValueError(t);
  }

  return e;
}

function binaryAccuracy$1(e, t) {
  return tidy(() => {
    var n = mul(.5, onesLike$2(t)),
        r = cast$2(greater$3(t, n), e.dtype);
    return mean$1(equal$2(e, r), -1);
  });
}

function categoricalAccuracy$1(e, t) {
  return tidy(() => cast$2(equal$2(argMax$2(e, -1), argMax$2(t, -1)), "float32"));
}

function truePositives(e, t) {
  return tidy(() => cast$3(sum$2(logicalAnd$2(equal$2(e, 1), equal$2(t, 1))), "float32"));
}

function falseNegatives(e, t) {
  return tidy(() => cast$3(sum$2(logicalAnd$2(equal$2(e, 1), equal$2(t, 0))), "float32"));
}

function falsePositives(e, t) {
  return tidy(() => cast$3(sum$2(logicalAnd$2(equal$2(e, 0), equal$2(t, 1))), "float32"));
}

function precision$1(e, t) {
  return tidy(() => {
    var n = truePositives(e, t),
        r = falsePositives(e, t),
        a = add$2(n, r);
    return cast$3(where(greater$3(a, 0), div$1(n, a), 0), "float32");
  });
}

function recall$1(e, t) {
  return tidy(() => {
    var n = truePositives(e, t),
        r = falseNegatives(e, t),
        a = add$2(n, r);
    return cast$3(where(greater$3(a, 0), div$1(n, a), 0), "float32");
  });
}

function binaryCrossentropy$1(e, t) {
  return binaryCrossentropy$2(e, t);
}

function sparseCategoricalAccuracy$1(e, t) {
  return e.rank === t.rank && (e = squeeze(e, [e.rank - 1])), (t = argMax$2(t, -1)).dtype !== e.dtype && (t = cast$3(t, e.dtype)), cast$3(equal$2(e, t), "float32");
}

var mse$1 = meanSquaredError$1,
    MSE$1 = meanSquaredError$1,
    mae = meanAbsoluteError$1,
    MAE = meanAbsoluteError$1,
    mape$1 = meanAbsolutePercentageError$1,
    MAPE$1 = meanAbsolutePercentageError$1,
    categoricalCrossentropy$1 = categoricalCrossentropy$2,
    cosine = cosineProximity$1,
    sparseCategoricalCrossentropy = sparseCategoricalCrossentropy$1,
    metricsMap = {
  binaryAccuracy: binaryAccuracy$1,
  categoricalAccuracy: categoricalAccuracy$1,
  precision: precision$1,
  categoricalCrossentropy: categoricalCrossentropy$1,
  sparseCategoricalCrossentropy,
  mse: mse$1,
  MSE: MSE$1,
  mae,
  MAE,
  mape: mape$1,
  MAPE: MAPE$1,
  cosine
};

function get(e) {
  if ("string" == typeof e && e in metricsMap) return metricsMap[e];
  if ("string" != typeof e && null != e) return e;
  throw new ValueError("Unknown metric ".concat(e));
}

function getLossOrMetricName(e) {
  if (assert$3(null !== e, "Unknown LossOrMetricFn ".concat(e)), "string" == typeof e) return e;
  {
    var t;

    for (var n of Object.keys(lossesMap)) {
      if (lossesMap[n] === e) {
        t = n;
        break;
      }
    }

    if (void 0 !== t) return t;

    for (var _n258 of Object.keys(metricsMap)) {
      if (metricsMap[_n258] === e) {
        t = _n258;
        break;
      }
    }

    return void 0 !== t ? t : e.name;
  }
}

function getOptimizer(e) {
  var t = {
    Adagrad: () => train.adagrad(.01),
    Adadelta: () => train.adadelta(1, .95, epsilon$1()),
    Adam: () => train.adam(.001, .9, .999, epsilon$1()),
    Adamax: () => train.adamax(.002, .9, .999, epsilon$1(), 0),
    RMSProp: () => train.rmsprop(.001, .9, 0, epsilon$1()),
    SGD: () => train.sgd(.01)
  };
  if (t.adagrad = t.Adagrad, t.adadelta = t.Adadelta, t.adam = t.Adam, t.adamax = t.Adamax, t.rmsprop = t.RMSProp, t.sgd = t.SGD, e in t) return t[e]();
  throw new ValueError("Unknown Optimizer ".concat(e));
}

var MAX_USER_DEFINED_METADATA_SERIALIZED_LENGTH = 1048576;

function checkUserDefinedMetadata(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  if (null == e || "object" != typeof e || Object.getPrototypeOf(e) !== Object.prototype || !plainObjectCheck(e)) throw new Error("User-defined metadata is expected to be a JSON object, but is not.");

  if (n) {
    var _n259 = JSON.stringify(e);

    _n259.length > MAX_USER_DEFINED_METADATA_SERIALIZED_LENGTH && console.warn("User-defined metadata of model \"".concat(t, "\" is too large in size (length=").concat(_n259.length, " when serialized). It is not recommended to store such large objects in user-defined metadata. Please make sure its serialized length is <= ").concat(MAX_USER_DEFINED_METADATA_SERIALIZED_LENGTH, "."));
  }
}

function plainObjectCheck(e) {
  if (null === e) return !0;

  if ("object" == typeof e) {
    if (Object.getPrototypeOf(e) === Object.prototype) {
      var t = Object.keys(e);

      for (var n of t) {
        if ("string" != typeof n) return !1;
        if (!plainObjectCheck(e[n])) return !1;
      }

      return !0;
    }

    if (Array.isArray(e)) {
      for (var _t453 of e) {
        if (!plainObjectCheck(_t453)) return !1;
      }

      return !0;
    }

    return !1;
  }

  {
    var _t454 = typeof e;

    return "string" === _t454 || "number" === _t454 || "boolean" === _t454;
  }
}

function printSummary(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : console.log;
  var a = isModelSequentialLike(e),
      s = ["Layer (type)", "Output shape", "Param #"];
  var o;

  if (a ? (t = t || 65, n = n || [.45, .85, 1]) : (t = t || 98, n = n || [.33, .55, .67, 1]), n[n.length - 1] <= 1 && (n = n.map(e => Math.floor(t * e))), !a) {
    s.push("Receives inputs"), o = [];

    for (var _t455 in e.nodesByDepth) {
      o.push(...e.nodesByDepth[_t455]);
    }
  }

  r("_".repeat(t)), printRow(s, n, r), r("=".repeat(t));
  var i = e.layers;

  for (var _e647 = 0; _e647 < i.length; ++_e647) {
    a ? printLayerSummary(i[_e647], n, r) : printLayerSummaryWithConnections(i[_e647], n, o, r), r((_e647 === i.length - 1 ? "=" : "_").repeat(t));
  }

  e.checkTrainableWeightsConsistency();
  var l = countTrainableParams(e),
      u = countParamsInWeights(e.nonTrainableWeights);
  r("Total params: ".concat(l + u)), r("Trainable params: ".concat(l)), r("Non-trainable params: ".concat(u)), r("_".repeat(t));
}

function countTrainableParams(e) {
  var t;
  return t = countParamsInWeights(null != e.collectedTrainableWeights ? e.collectedTrainableWeights : e.trainableWeights), t;
}

function isModelSequentialLike(e) {
  var t = !0;
  var n = [],
      r = [];

  for (var _t456 in e.nodesByDepth) {
    n.push(e.nodesByDepth[_t456]);
  }

  for (var _e648 of n) {
    if (_e648.length > 1 || 1 === _e648.length && _e648[0].inboundLayers.length > 1) {
      t = !1;
      break;
    }

    r.push(..._e648);
  }

  if (t) for (var _n260 of e.layers) {
    var _e649 = !1;

    for (var a of _n260.inboundNodes) {
      if (-1 !== r.indexOf(a)) {
        if (_e649) {
          t = !1;
          break;
        }

        _e649 = !0;
      }
    }

    if (!t) break;
  }
  return t;
}

function printRow(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : console.log;
  var r = "";

  for (var _n261 = 0; _n261 < e.length; ++_n261) {
    _n261 > 0 && (r = r.slice(0, r.length - 1) + " "), r += e[_n261], r = r.slice(0, t[_n261]), r += " ".repeat(t[_n261] - r.length);
  }

  n(r);
}

function printLayerSummary(e, t, n) {
  var r;

  try {
    r = JSON.stringify(e.outputShape);
  } catch (e) {
    r = "multiple";
  }

  printRow(["".concat(e.name, " (").concat(e.getClassName(), ")"), r, e.countParams().toString()], t, n);
}

function printLayerSummaryWithConnections(e, t, n, r) {
  var a;

  try {
    a = JSON.stringify(e.outputShape);
  } catch (e) {
    a = "multiple";
  }

  var s = [];

  for (var _t457 of e.inboundNodes) {
    if (!(null != n && n.length > 0 && -1 === n.indexOf(_t457))) for (var _e650 = 0; _e650 < _t457.inboundLayers.length; ++_e650) {
      s.push("".concat(_t457.inboundLayers[_e650].name, "[").concat(_t457.nodeIndices[_e650], "][").concat(_t457.tensorIndices[_e650], "]"));
    }
  }

  var o = e.name,
      i = e.getClassName(),
      l = 0 === s.length ? "" : s[0];
  printRow(["".concat(o, " (").concat(i, ")"), a, e.countParams().toString(), l], t, r);

  for (var _e651 = 1; _e651 < s.length; ++_e651) {
    printRow(["", "", "", s[_e651]], t, r);
  }
}

function isArrayItemInputOrOutputName(e, t, n) {
  return ("inboundNodes" === e || "outputLayers" === e || "inputLayers" === e) && 0 === t && "string" == typeof n;
}

function convertPythonicToTs(e, t) {
  if (null === e) return null;
  if ("string" == typeof e) return toCamelCase(e);
  if ("number" == typeof e || "boolean" == typeof e) return e;

  if (e instanceof Array) {
    var n = [],
        r = e.length;

    for (var a = 0; a < r; ++a) {
      var _r209 = e[a];
      isArrayItemInputOrOutputName(t, a, _r209) ? n.push(_r209) : n.push(convertPythonicToTs(_r209, t));
    }

    return n;
  }

  {
    var _t458 = {};

    for (var _n262 of Object.keys(e)) {
      var _r210 = e[_n262];
      if ("name" === _n262 && "string" == typeof _r210) _t458[_n262] = _r210;else {
        var _e652 = toCamelCase(_n262);

        _t458[_e652] = convertPythonicToTs(_r210, _e652);
      }
    }

    return _t458;
  }
}

function convertTsToPythonic(e, t) {
  if (null == e) return null;
  if ("string" == typeof e) return toSnakeCase(e);
  if ("number" == typeof e || "boolean" == typeof e) return e;

  if (e instanceof Array) {
    var n = [],
        r = e.length;

    for (var a = 0; a < r; ++a) {
      var _r211 = e[a];
      isArrayItemInputOrOutputName(t, a, _r211) ? n.push(_r211) : n.push(convertTsToPythonic(_r211, t));
    }

    return n;
  }

  {
    var _t459 = {};

    for (var _n263 of Object.keys(e)) {
      var _r212 = e[_n263];
      _t459[toSnakeCase(_n263)] = "name" !== _n263 && "className" !== _n263 || "string" != typeof _r212 ? convertTsToPythonic(_r212, _n263) : _r212;
    }

    return _t459;
  }
}

var version$6 = "3.8.0";

function assertFeedCompatibility(e, t) {
  if (null == e.dtype || e.dtype === t.dtype) return t;

  try {
    return cast$3(t, e.dtype);
  } catch (n) {
    throw new ValueError("The dtype of the feed (".concat(t.dtype, ") can not be cast to the dtype of the key '").concat(e.name, "' (").concat(e.dtype, ")."));
  }
}

class FeedDict {
  constructor(e) {
    if (this.id2Value = {}, this.id2Mask = {}, this.name2Id = {}, e instanceof FeedDict) for (var t in e.id2Value) {
      this.id2Value[t] = e.id2Value[t], t in e.id2Mask && (this.id2Mask[t] = e.id2Mask[t]);
    } else {
      if (null == e) return;

      for (var _t460 of e) {
        this.add(_t460.key, _t460.value);
      }
    }
  }

  add(e, t, n) {
    if (null != this.id2Value[e.id]) throw new ValueError("Duplicate key: name=".concat(e.name, ", id=").concat(e.id));
    return this.id2Value[e.id] = assertFeedCompatibility(e, t), this.name2Id[e.name] = e.id, null != n && (this.id2Mask[e.id] = n), this;
  }

  addFeed(e) {
    this.add(e.key, e.value);
  }

  hasKey(e) {
    return null != this.id2Value[e.id];
  }

  names() {
    return Object.keys(this.name2Id);
  }

  getValue(e) {
    if (e instanceof SymbolicTensor) {
      if (null == this.id2Value[e.id]) throw new ValueError("Nonexistent key: ".concat(e.name));
      return this.id2Value[e.id];
    }

    {
      var t = this.name2Id[e];
      if (null == t) throw new ValueError("Feed dict has no SymbolicTensor name: ".concat(e));
      return this.id2Value[t];
    }
  }

  getMask(e) {
    if (e instanceof SymbolicTensor) {
      if (null == this.id2Value[e.id]) throw new ValueError("Nonexistent key: ".concat(e.name));
      return this.id2Mask[e.id];
    }

    {
      var t = this.name2Id[e];
      if (null == t) throw new ValueError("Feed dict has no SymbolicTensor name: ".concat(e));
      return this.id2Mask[t];
    }
  }

  disposeMasks() {
    null != this.id2Mask && dispose(this.id2Mask);
  }

}

var cachedSorted = {},
    cachedRecipientCounts = {};

function execute(e, t, n, r) {
  var a = null != n && n.training,
      s = Array.isArray(e),
      o = s ? e : [e],
      i = o.map(e => e.name),
      l = [],
      u = t.names();

  for (var _e653 of i) {
    -1 !== u.indexOf(_e653) ? l.push(t.getValue(_e653)) : l.push(null);
  }

  null != r && (r.maxNumTensors = -Infinity, r.minNumTensors = Infinity);
  var c = i.join(",") + "|" + t.names().join(",");
  var p, d;

  if (null == cachedSorted[c]) {
    var _e654 = getTopologicalSortAndRecipientCounts(o, t);

    p = _e654.sorted, d = _e654.recipientCounts, cachedSorted[c] = p, cachedRecipientCounts[c] = d;
  }

  p = cachedSorted[c], d = {}, a || Object.assign(d, cachedRecipientCounts[c]);
  var h = new FeedDict(t);

  for (var _e655 = 0; _e655 < p.length; ++_e655) {
    if (null != r) {
      var _e656 = memory().numTensors;
      _e656 > r.maxNumTensors && (r.maxNumTensors = _e656), _e656 < r.minNumTensors && (r.minNumTensors = _e656);
    }

    var _s104 = p[_e655],
        _o73 = _s104.sourceLayer;
    if (_o73 instanceof InputLayer) continue;
    var _u31 = [],
        _c21 = [],
        m = [];
    var f = !1;

    for (var _e657 of _s104.inputs) {
      var _n264 = h.getValue(_e657),
          _r213 = h.getMask(_e657);

      _u31.push(_n264), _c21.push(_r213), null != _r213 && (f = !0), a || (d[_e657.name]--, 0 !== d[_e657.name] || t.hasKey(_e657) || -1 !== i.indexOf(_e657.name) || _n264.isDisposed || !0 === _e657.sourceLayer.stateful || m.push(_n264));
    }

    f && ((n = n || {}).mask = _c21[0]);
    var g = toList(_o73.apply(_u31, n));
    var $ = null;
    _o73.supportsMasking && ($ = _o73.computeMask(_u31, _c21));
    var y = getNodeOutputs(_s104),
        b = Array.isArray(y) ? y : [y];

    for (var _e658 = 0; _e658 < b.length; ++_e658) {
      h.hasKey(b[_e658]) || h.add(b[_e658], g[_e658], Array.isArray($) ? $[0] : $);

      var _t461 = i.indexOf(b[_e658].name);

      -1 !== _t461 && (l[_t461] = g[_e658]);
    }

    a || dispose(m);
  }

  return h.disposeMasks(), s ? l : l[0];
}

function getTopologicalSortAndRecipientCounts(e, t) {
  assert$4(null != e && e.length > 0, () => "Expected at least one fetch, got none");
  var n = [],
      r = {};

  if (1 === e.length) {
    var a = getTopologicalSortAndRecipientCountsForOneFetch(e[0], t);
    n = a.sorted, r = a.recipientMap;
  } else {
    var _a144 = new Set();

    for (var s of e) {
      var {
        sorted: _e659,
        recipientMap: o
      } = getTopologicalSortAndRecipientCountsForOneFetch(s, t);

      for (var _t462 of _e659) {
        _a144.has(_t462.name) || (n.push(_t462), _a144.add(_t462.name));
      }

      var _loop41 = function _loop41(_e660) {
        null == r[_e660] && (r[_e660] = new Set()), o[_e660].forEach(t => r[_e660].add(t));
      };

      for (var _e660 in o) {
        _loop41(_e660);
      }
    }
  }

  return {
    sorted: n,
    recipientCounts: recipientMap2Counts(r)
  };
}

function recipientMap2Counts(e) {
  var t = {};

  for (var n in e) {
    t[n] = e[n].size;
  }

  return t;
}

function getTopologicalSortAndRecipientCountsForOneFetch(e, t) {
  var n = new Set(),
      r = [],
      a = {};

  for (var _e661 of t.names()) {
    n.add(_e661);
  }

  var s = [],
      o = [];

  for (s.push(e); s.length > 0;) {
    var _e662 = s[s.length - 1];

    if (n.has(_e662.name)) {
      s.pop();
      continue;
    }

    var _t463 = o[o.length - 1] === s.length - 1;

    if (0 === _e662.inputs.length || _t463) s.pop(), r.push(_e662), n.add(_e662.name), _t463 && o.pop();else {
      o.push(s.length - 1);

      for (var _t464 of _e662.inputs) {
        null == a[_t464.name] && (a[_t464.name] = new Set()), a[_t464.name].add(_e662.name), n.has(_t464.name) || s.push(_t464);
      }
    }
  }

  return {
    sorted: r,
    recipientMap: a
  };
}

function getNodeOutputs(e) {
  var t;
  if (1 === e.sourceLayer.inboundNodes.length) t = e.sourceLayer.output;else {
    var n = null;

    for (var _t465 = 0; _t465 < e.sourceLayer.inboundNodes.length; ++_t465) {
      for (var r of e.sourceLayer.inboundNodes[_t465].outputTensors) {
        if (r.id === e.id) {
          n = _t465;
          break;
        }
      }
    }

    t = e.sourceLayer.getOutputAt(n);
  }
  return t;
}

class Container extends Layer {
  constructor(e) {
    if (super({}), this.containerNodes = new Set(), this.name = e.name, null == this.name) {
      var _e663 = this.getClassName().toLowerCase();

      this.name = getUid(_e663);
    }

    if (this.supportsMasking = !1, this.trainable_ = !0, this.inputs = Array.isArray(e.inputs) ? e.inputs.slice() : [e.inputs], this.outputs = Array.isArray(e.outputs) ? e.outputs.slice() : [e.outputs], unique$2(this.inputs).length !== this.inputs.length) throw new ValueError("The list of inputs passed to the model is redundant. All inputs should only appear once. Found: ".concat(this.inputs.map(e => e.name)));
    unique$2(this.outputs).length !== this.outputs.length && console.warn("The list of outputs passed to the model is redundant. All outputs should only appear once. Found: ".concat(this.outputs.map(e => e.name))), this.inputLayers = [], this.inputLayersNodeIndices = [], this.inputLayersTensorIndices = [], this.outputLayers = [], this.outputLayersNodeIndices = [], this.outputLayersTensorIndices = [], this.layers = [], this.internalContainerRefs = [];

    for (var _e664 of this.outputs) {
      var _t466 = _e664.nodeIndex,
          _n265 = _e664.tensorIndex;
      this.outputLayers.push(_e664.sourceLayer), this.outputLayersNodeIndices.push(_t466), this.outputLayersTensorIndices.push(_n265);
    }

    for (var _e665 of this.inputs) {
      var _t467 = _e665.sourceLayer,
          _n266 = _e665.nodeIndex,
          _r214 = _e665.tensorIndex;
      assert$3(0 === _n266, "input layer has >1 nodes"), assert$3(0 === _r214, "input layer has >1 tensors"), this.inputLayers.push(_t467), this.inputLayersNodeIndices.push(_n266), this.inputLayersTensorIndices.push(_r214);
    }

    this.inputNames = [], this.outputNames = [], this.feedInputShapes = [], this.feedInputNames = [], this.feedOutputNames = [];

    for (var _t468 = 0; _t468 < this.inputLayers.length; _t468++) {
      var _n267 = this.inputLayers[_t468];
      if (!(_n267 instanceof InputLayer)) throw new TypeError("Input layers to a LayersModel must be InputLayer objects. Received inputs: ".concat(e.inputs, ". Input ").concat(_t468, " (0-based) originates from layer type ").concat(_n267.getClassName(), "."));
      this.inputNames.push(_n267.name), this.feedInputShapes.push(_n267.batchInputShape), this.feedInputNames.push(_n267.name);
    }

    for (var _e666 of this.outputLayers) {
      this.outputNames.push(_e666.name);
    }

    this.internalInputShapes = this.inputs.map(e => e.shape), this.internalOutputShapes = this.outputs.map(e => e.shape);

    var t = {},
        n = {},
        r = {},
        a = {},
        s = {},
        o = [],
        i = (e, t, n, r, a, l) => {
      null != r && null != a && null != l || (r = e.sourceLayer, a = e.nodeIndex, l = e.tensorIndex);
      var u = r.inboundNodes[a];
      if (-1 !== n.indexOf(u)) throw new RuntimeError("The tensor ".concat(e.name, " at layer \"").concat(r.name, "\" is part of a cycle."));
      if (-1 !== t.indexOf(u)) return;
      this.containerNodes.add(Container.nodeKey(r, a)), r.id in s || (s[r.id] = Object.keys(s).length), -1 === n.indexOf(u) && n.push(u);
      var c = u.inboundLayers.length;

      for (var _e667 = 0; _e667 < c; _e667++) {
        i(u.inputTensors[_e667], t, n, u.inboundLayers[_e667], u.nodeIndices[_e667], u.tensorIndices[_e667]);
      }

      for (t.push(u); n.indexOf(u) >= 0;) {
        n.splice(n.indexOf(u), 1);
      }

      o.push(u);
    },
        l = [],
        u = [];

    for (var _e668 of this.outputs) {
      i(_e668, l, u);
    }

    var c = o.slice().reverse();

    for (var _e669 of c) {
      n[_e669.id] = _e669, _e669.id in t || (t[_e669.id] = 0);
      var _s105 = t[_e669.id];
      _s105 = Math.max(_s105, null == r[_e669.outboundLayer.id] ? 0 : r[_e669.outboundLayer.id]), r[_e669.outboundLayer.id] = _s105, a[_e669.outboundLayer.id] = _e669.outboundLayer, t[_e669.id] = _s105;

      for (var _r215 = 0; _r215 < _e669.inboundLayers.length; _r215++) {
        var _a145 = _e669.inboundLayers[_r215].inboundNodes[_e669.nodeIndices[_r215]];
        t[_a145.id] = Math.max(_s105 + 1, null == t[_a145.id] ? 0 : t[_a145.id]), n[_a145.id] = _a145;
      }
    }

    var p = {};

    for (var _e670 in t) {
      var _r216 = t[_e670];
      _r216 in p || (p[_r216] = []), p[_r216].push(n[_e670]);
    }

    var d = {};

    for (var _e671 in r) {
      var _t469 = r[_e671];
      _t469 in d || (d[_t469] = []), d[_t469].push(a[_e671]);
    }

    var h = Object.keys(d).map(e => parseInt(e, 10)).sort(reverseNumberCompare);
    this.layers = [];

    for (var _e672 of h) {
      var _t470 = d[_e672];

      _t470.sort((e, t) => {
        var n = s[e.id],
            r = s[t.id];
        return n < r ? -1 : n > r ? 1 : 0;
      });

      for (var _e673 of _t470) {
        _e673 instanceof Container && this.internalContainerRefs.push(_e673), this.layers.push(_e673);
      }
    }

    this.layersByDepth = d, h = Object.keys(p).map(e => parseInt(e, 10)).sort(reverseNumberCompare);
    var m = this.inputs.slice(),
        f = [];

    for (var _e674 of h) {
      for (var _t471 of p[_e674]) {
        var _e675 = _t471.outboundLayer;

        if (null != _e675) {
          for (var _n268 of _t471.inputTensors) {
            if (-1 === m.indexOf(_n268)) throw new RuntimeError("Graph disconnected: cannot obtain value for tensor ".concat(_n268, " at layer \"").concat(_e675.name, "\". The following previous layers were accessed without issue: ").concat(f));
          }

          for (var _e676 of _t471.outputTensors) {
            m.push(_e676);
          }

          f.push(_e675.name);
        }
      }
    }

    this.nodesByDepth = p;
    var g = this.layers.map(e => e.name);

    var _loop42 = function _loop42(_e677) {
      var t = g.filter(t => t === _e677).length;
      if (1 !== t) throw new RuntimeError("The name \"".concat(_e677, "\" is used ").concat(t, " times in the model. All layer names should be unique. Layer names: ") + JSON.stringify(g));
    };

    for (var _e677 of g) {
      _loop42(_e677);
    }

    this.outboundNodes = [], this.inboundNodes = [], new Node({
      outboundLayer: this,
      inboundLayers: [],
      nodeIndices: [],
      tensorIndices: [],
      inputTensors: this.inputs,
      outputTensors: this.outputs,
      inputMasks: this.inputs.map(e => null),
      outputMasks: this.outputs.map(e => null),
      inputShapes: this.inputs.map(e => e.shape),
      outputShapes: this.outputs.map(e => e.shape)
    }), this.built = !0, this._refCount = 1;
  }

  assertNotDisposed() {
    if (0 === this._refCount) throw new Error("Container '".concat(this.name, "' is already disposed."));
  }

  dispose() {
    this.assertNotDisposed();
    var e = {
      refCountAfterDispose: null,
      numDisposedVariables: 0
    };

    if (0 == --this._refCount) {
      for (var t of this.layers) {
        e.numDisposedVariables += t.dispose().numDisposedVariables;
      }

      for (var _t472 of this.internalContainerRefs) {
        e.numDisposedVariables += _t472.dispose().numDisposedVariables;
      }
    }

    return e.refCountAfterDispose = this._refCount, e;
  }

  get trainable() {
    return this.trainable_;
  }

  set trainable(e) {
    this.layers.forEach(t => {
      t._trainableWeights.forEach(t => t.trainable = e);
    }), this.trainable_ = e;
  }

  get trainableWeights() {
    if (this._trainableWeights.length > 0) throw new ValueError("Container instance unexpectedly contains _trainableWeights.The trainable weights of a Container are a union of the trainable weights of its consituent Layers. Its own _trainableWeights must remain an empty Array.");
    if (!this.trainable) return [];
    var e = [];

    for (var t of this.layers) {
      e = e.concat(t.trainableWeights);
    }

    return e;
  }

  get nonTrainableWeights() {
    var e = [];

    for (var t of this.layers) {
      e.push(...t.nonTrainableWeights);
    }

    if (!this.trainable) {
      var _t473 = [];

      for (var _e678 of this.layers) {
        _t473.push(..._e678.trainableWeights);
      }

      return _t473.concat(e);
    }

    return e;
  }

  get weights() {
    return this.trainableWeights.concat(this.nonTrainableWeights);
  }

  loadWeights(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !0;
    var n = {};
    var r = 0;

    for (var _e679 of this.layers) {
      for (var _t474 of _e679.weights) {
        if (null != n[_t474.originalName]) throw new ValueError("Duplicate weight name: ".concat(_t474.originalName));
        n[_t474.originalName] = _t474, r++;
      }
    }

    var a = [];

    for (var _r217 in e) {
      var s = _r217;

      if (null == n[_r217]) {
        var _e680 = _r217.split("/");

        s = _e680.slice(0, -2).concat([_e680[_e680.length - 1]]).join("/");
      }

      if (null != n[s]) a.push([n[s], e[_r217]]);else if (t) throw new ValueError("Provided weight data has no target variable: ".concat(_r217));
      delete n[s];
    }

    if (t) {
      var _e681 = [];

      for (var _t475 in n) {
        _e681.push(_t475);
      }

      if (_e681.length > 0) throw new ValueError("".concat(_e681.length, " of ").concat(r, " weights are not set: ").concat(_e681));
    }

    batchSetValue(a);
  }

  updatedConfig() {
    var e = this.getConfig(),
        t = {};
    return t.className = this.getClassName(), t.config = e, t.kerasVersion = "tfjs-layers ".concat(version$6), t.backend = "TensorFlow.js", t;
  }

  toJSON(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !0;
    var n = convertTsToPythonic(this.updatedConfig());
    return t ? JSON.stringify(n) : n;
  }

  call(e, t) {
    return tidy(() => {
      e = toList(e);
      var n = new FeedDict();

      for (var _t476 = 0; _t476 < this.inputs.length; ++_t476) {
        n.add(this.inputs[_t476], e[_t476]);
      }

      return execute(this.outputs, n, t);
    });
  }

  computeMask(e, t) {
    return tidy(() => {
      var n;
      return e = toList(e), n = null == t ? pyListRepeat(null, e.length) : toList(t), this.runInternalGraph(e, n)[1];
    });
  }

  computeOutputShape(e) {
    var t = normalizeShapeList(e);
    if (t.length !== this.inputLayers.length) throw new ValueError("Invalid inputShape argument ".concat(e, ": model has ").concat(this.inputLayers.length, " tensor inputs."));
    var n = {};

    for (var _e682 = 0; _e682 < t.length; _e682++) {
      n[this.inputLayers[_e682].name + "_0_0"] = t[_e682];
    }

    var r = Object.keys(this.nodesByDepth).map(e => parseInt(e, 10)).sort(reverseNumberCompare);
    if (r.length > 1) for (var _e683 of r) {
      var _t477 = this.nodesByDepth[_e683];

      for (var _e684 of _t477) {
        var _t478 = _e684.outboundLayer;
        if (-1 !== this.inputLayers.map(e => e.id).indexOf(_t478.id)) continue;
        var _r218 = [];

        for (var _t479 = 0; _t479 < _e684.inboundLayers.length; _t479++) {
          _r218.push(n["".concat(_e684.inboundLayers[_t479].name, "_").concat(_e684.nodeIndices[_t479], "_").concat(_e684.tensorIndices[_t479])]);
        }

        var _a146 = normalizeShapeList(_t478.computeOutputShape(singletonOrArray(_r218))),
            _s106 = _t478.inboundNodes.indexOf(_e684);

        for (var _e685 = 0; _e685 < _a146.length; _e685++) {
          n["".concat(_t478.name, "_").concat(_s106, "_").concat(_e685)] = _a146[_e685];
        }
      }
    }
    var a = [],
        s = [];

    for (var _e686 = 0; _e686 < this.outputLayers.length; _e686++) {
      s.push("".concat(this.outputLayers[_e686].name, "_").concat(this.outputLayersNodeIndices[_e686], "_").concat(this.outputLayersTensorIndices[_e686]));
    }

    for (var _e687 = 0; _e687 < s.length; _e687++) {
      var _t480 = s[_e687];
      assert$3(_t480 in n), a.push(n[_t480]);
    }

    return singletonOrArray(a);
  }

  runInternalGraph(e, t) {
    null == t && (t = pyListRepeat(null, e.length));
    var n = {};

    for (var _r219 = 0; _r219 < this.inputs.length; ++_r219) {
      n[this.inputs[_r219].id] = [e[_r219], t[_r219]];
    }

    var r = Object.keys(this.nodesByDepth).map(e => parseInt(e, 10)).sort(reverseNumberCompare);

    for (var _e688 of r) {
      var _t481 = this.nodesByDepth[_e688];

      for (var _e689 of _t481) {
        var _t482 = _e689.outboundLayer,
            _r220 = _e689.inputTensors,
            _a147 = _e689.outputTensors,
            _s107 = new Array();

        for (var _e690 of _r220) {
          _e690.id in n && _s107.push(n[_e690.id]);
        }

        if (_s107.length === _r220.length) {
          var _r221 = void 0,
              _o74 = void 0,
              i = void 0,
              l = void 0,
              u = {};

          if (null != _e689.callArgs && (u = _e689.callArgs), 1 === _s107.length) {
            var [_e691, _n269] = _s107[0];
            null == u.mask && (u.mask = _n269), i = toList(_t482.call(_e691, u)), l = toList(_t482.computeMask(_e691, _n269)), _r221 = [_e691], _o74 = [_n269];
          } else _r221 = _s107.map(e => e[0]), _o74 = _s107.map(e => e[1]), null == u.mask && (u.mask = _o74), i = toList(_t482.call(_r221, u)), l = toList(_t482.computeMask(_r221, _o74));

          if (_t482.activityRegularizer) throw new NotImplementedError("LayersModel invocation with concrete Tensor value(s) in the presence of activity regularizer(s) is not supported yet.");

          for (var _e692 = 0; _e692 < _a147.length; ++_e692) {
            n[_a147[_e692].id] = [i[_e692], l[_e692]];
          }
        }
      }
    }

    var a = [],
        s = [],
        o = [];

    for (var _e693 of this.outputs) {
      assert$3(_e693.id in n, "Could not compute output ".concat(_e693.name, " : ").concat(_e693.id));
      var [_t483, _r222] = n[_e693.id];
      o.push(_t483.shape), a.push(_t483), s.push(_r222);
    }

    return [a, s, o];
  }

  buildNodeConversionMap(e) {
    var t = {};
    var n;

    for (var _e694 of this.layers) {
      n = _e694 instanceof Container ? 1 : 0;

      for (var r = 0; r < _e694.inboundNodes.length; r++) {
        var a = Container.nodeKey(_e694, r);
        this.containerNodes.has(a) && (t[a] = n, n += 1);
      }
    }

    return t;
  }

  getLayer(e, t) {
    if (null != t) {
      if (this.layers.length <= t) throw new ValueError("Was asked to retrieve layer at index ".concat(t, ", but model only has ").concat(this.layers.length, " layer(s)."));
      return this.layers[t];
    }

    if (null == e) throw new ValueError("Provide either a layer name or layer index");

    for (var _t484 of this.layers) {
      if (_t484.name === e) return _t484;
    }

    throw new ValueError("No such layer: ".concat(e));
  }

  calculateLosses() {
    return tidy(() => {
      var e = [];

      for (var t of this.layers) {
        for (var n = 0; n < t.inboundNodes.length; ++n) {
          var r = Container.nodeKey(t, n);
          this.containerNodes.has(r) && e.push(...t.calculateLosses());
        }
      }

      return e;
    });
  }

  getConfig() {
    var e = {
      name: this.name
    },
        t = this.buildNodeConversionMap(this.layers),
        n = [];

    for (var _e695 of this.layers) {
      var _r223 = _e695.getClassName(),
          _a148 = _e695.getConfig(),
          s = [];

      for (var _n270 = 0; _n270 < _e695.inboundNodes.length; _n270++) {
        var _r224 = _e695.inboundNodes[_n270],
            _a149 = Container.nodeKey(_e695, _n270);

        var _o75 = {};

        if (this.containerNodes.has(_a149)) {
          if (_r224.callArgs) try {
            JSON.stringify(_r224.callArgs), _o75 = _r224.callArgs;
          } catch (t) {
            console.warn("Layer ".concat(_e695.name, " was passed non-serializable keyword arguments: ").concat(_r224.callArgs, ". They will not be included in the serialized model (and thus will be missing at deserialization time).")), _o75 = {};
          }

          if (_r224.inboundLayers.length > 0) {
            var _e696 = [];

            for (var _n271 = 0; _n271 < _r224.inboundLayers.length; _n271++) {
              var _a150 = _r224.inboundLayers[_n271],
                  _s108 = _r224.tensorIndices[_n271];
              var i = t[Container.nodeKey(_a150, _r224.nodeIndices[_n271])];
              null == i && (i = 0), _e696.push([_a150.name, i, _s108, _o75]);
            }

            s.push(_e696);
          }
        }
      }

      var o = {};
      o.name = _e695.name, o.className = _r223, o.config = _a148, o.inboundNodes = s, n.push(o);
    }

    e.layers = n;
    var r = [];

    for (var _e697 = 0; _e697 < this.inputLayers.length; _e697++) {
      var _n272 = this.inputLayers[_e697],
          _a151 = Container.nodeKey(_n272, this.inputLayersNodeIndices[_e697]);

      if (!this.containerNodes.has(_a151)) continue;
      var _s109 = t[_a151];
      null == _s109 && (_s109 = 0), r.push([_n272.name, _s109, this.inputLayersTensorIndices[_e697]]);
    }

    e.inputLayers = r;
    var a = [];

    for (var _e698 = 0; _e698 < this.outputLayers.length; _e698++) {
      var _n273 = this.outputLayers[_e698],
          _r225 = Container.nodeKey(_n273, this.outputLayersNodeIndices[_e698]);

      if (!this.containerNodes.has(_r225)) continue;
      var _s110 = t[_r225];
      null == _s110 && (_s110 = 0), a.push([_n273.name, _s110, this.outputLayersTensorIndices[_e698]]);
    }

    return e.outputLayers = a, e;
  }

  static fromConfig(e, t) {
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
    var a = {},
        s = {};

    function o(e, t) {
      e.name in s ? s[e.name].push(t) : s[e.name] = [t];
    }

    function i(e, t) {
      var n = [];
      var r;

      for (var _s111 of t) {
        var _i45 = _s111[0],
            _l37 = _s111[1],
            _u32 = _s111[2];
        if (r = null == _s111[3] ? {} : _s111[3], !(_i45 in a)) return void o(e, t);
        var _c22 = a[_i45];
        if (_c22.inboundNodes.length <= _l37) return void o(e, t);
        n.push(_c22.inboundNodes[_l37].outputTensors[_u32]);
      }

      n.length > 0 && e.apply(singletonOrArray(n), r);
    }

    function l(e) {
      var n = e.name,
          s = deserialize(e, null != t.customObjects ? t.customObjects : {});
      s.setFastWeightInitDuringBuild(r), a[n] = s, e.inboundNodes.forEach(e => {
        if (!(e instanceof Array)) throw new ValueError("Corrupted configuration, expected array for nodeData: ".concat(e));
        o(s, e);
      });
    }

    var u = t.name,
        c = t.layers;

    for (var _e699 of c) {
      l(_e699);
    }

    for (; !isObjectEmpty(s);) {
      for (var _e700 of c) {
        var _t485 = a[_e700.name];

        if (_t485.name in s) {
          var _e701 = s[_t485.name];
          delete s[_t485.name];

          for (var _n274 of _e701) {
            i(_t485, _n274);
          }
        }
      }
    }

    var p = [],
        d = [],
        h = t.inputLayers;

    for (var _e702 of h) {
      var _t486 = _e702[0],
          _n275 = _e702[1],
          _r226 = _e702[2];
      assert$3(_t486 in a), p.push(a[_t486].inboundNodes[_n275].outputTensors[_r226]);
    }

    var m = t.outputLayers;

    for (var _e703 of m) {
      var _t487 = _e703[0],
          _n276 = _e703[1],
          _r227 = _e703[2];
      assert$3(_t487 in a), d.push(a[_t487].inboundNodes[_n276].outputTensors[_r227]);
    }

    return new e({
      inputs: p,
      outputs: d,
      name: u
    });
  }

  get stateful() {
    if (this._stateful) throw new ValueError("Container instance unexpectedly has _stateful = true. The statefulness of a Container is determined by the Layers it contains. Its _stateful property must remain the default false.");

    for (var _e704 of this.layers) {
      if (_e704.stateful) return !0;
    }

    return !1;
  }

  resetStates() {
    tidy(() => {
      this.layers.forEach(e => {
        e.stateful && e.resetStates();
      });
    });
  }

}

function standardizeSampleOrClassWeights(e, t, n) {
  var r = t.length;
  if (null == e || Array.isArray(e) && 0 === e.length) return t.map(e => null);
  if (1 === r) return Array.isArray(e) && 1 === e.length ? e : "object" == typeof e && t[0] in e ? [e[t[0]]] : [e];

  if (Array.isArray(e)) {
    if (e.length !== r) throw new Error("Provided ".concat(n, " is an array of ").concat(e.length, " element(s), but the model has ").concat(r, " outputs. Make sure a set of weights is provided for each model output."));
    return e;
  }

  if ("object" == typeof e && Object.keys(e).length > 0 && "object" == typeof e[Object.keys(e)[0]]) {
    var _n277 = [];
    return t.forEach(t => {
      _n277.push(t in e ? e[t] : null);
    }), _n277;
  }

  throw new Error("The model has multiple (".concat(r, ") outputs, so ").concat(n, " must be either an array with ").concat(r, " elements or an object with ").concat(t, " keys. Provided ").concat(n, " not understood: ").concat(JSON.stringify(e)));
}

function standardizeClassWeights(e, t) {
  return standardizeSampleOrClassWeights(e, t, "classWeight");
}

function standardizeWeights(_x87, _x88, _x89, _x90) {
  return _standardizeWeights.apply(this, arguments);
}

function _standardizeWeights() {
  _standardizeWeights = _asyncToGenerator(function* (e, t, n, r) {
    if (null != t || null != r) throw new Error("Support sampleWeight is not implemented yet");

    if (null != n) {
      var _t779 = tidy(() => {
        if (1 === e.shape.length) return clone(e);

        if (2 === e.shape.length) {
          if (e.shape[1] > 1) return argMax$2(e, 1);
          if (1 === e.shape[1]) return reshape$3(e, [e.shape[0]]);
          throw new Error("Encountered unexpected last-dimension size (".concat(e.shape[1], ") during handling of class weights. The size is expected to be >= 1."));
        }

        throw new Error("Unexpected rank of target (y) tensor (".concat(e.rank, ") during handling of class weights. The rank is expected to be 1 or 2."));
      }),
          _r450 = Array.from(yield _t779.data());

      dispose(_t779);
      var a = [];
      return _r450.forEach(e => {
        if (null == n[e]) throw new Error("classWeight must contain all classes in the training data. The class ".concat(e, " exists in the data but not in classWeight"));
        a.push(n[e]);
      }), tensor1d(a, "float32");
    }

    return null;
  });
  return _standardizeWeights.apply(this, arguments);
}

function computeWeightedLoss(e, t) {
  return mul(e, t);
}

var DEFAULT_VALIDATION_BATCH_SIZE = 32;

function standardizeDataIteratorOutput(e, t) {
  var n, r;
  n = t.xs, r = t.ys, assert$4(null != n && null != r, () => "A Dataset iterator for fitDataset() is expected to generate objects of the form `{xs: xVal, ys: yVal}`, where the two values may be `tf.Tensor`, an array of Tensors, or a map of string to Tensor.  The provided Dataset instead generates ".concat(t));
  var a = flattenTensorOrArrayOrMap("input", e.inputNames, n),
      s = flattenTensorOrArrayOrMap("output", e.outputNames, r),
      o = a[0].shape[0];
  assert$4(a.length === e.inputs.length, () => "LayersModel has ".concat(e.inputs.length, " inputs, but the dataset provides ").concat(a.length, " inputs.  (Expected input keys: ").concat(JSON.stringify(e.inputNames), ")")), assert$4(s.length === e.outputs.length, () => "LayersModel has ".concat(e.outputs.length, " outputs, but the dataset provides ").concat(s.length, " outputs.  (Expected output keys: ").concat(JSON.stringify(e.outputNames), ")"));

  var _loop43 = function _loop43(_t488) {
    assert$4(a[_t488].shape[0] === o, () => "Batch size mismatch: input ".concat(e.inputNames[_t488], " has ").concat(a[_t488].shape[0], "; expected  ").concat(o, " based on input ").concat(e.inputNames[0], "."));
  };

  for (var _t488 = 0; _t488 < a.length; _t488++) {
    _loop43(_t488);
  }

  var _loop44 = function _loop44(_t489) {
    assert$4(s[_t489].shape[0] === o, () => "Batch size mismatch: output ".concat(e.outputNames[_t489], " has ").concat(s[_t489].shape[0], "; expected  ").concat(o, " based on input ").concat(e.inputNames[0], "."));
  };

  for (var _t489 = 0; _t489 < s.length; _t489++) {
    _loop44(_t489);
  }

  return {
    xs: a,
    ys: s
  };
}

function flattenTensorOrArrayOrMap(e, t, n) {
  if (n instanceof Tensor) return [n];
  if (Array.isArray(n)) return assert$4(n.length === t.length, () => "Received an array of ".concat(n.length, " Tensors, but expected ").concat(t.length, " to match the ").concat(e, " keys ").concat(t, ".")), n;
  {
    var r = [];

    for (var a of t) {
      if (null == n[a]) throw new ValueError("The feature data generated by the dataset lacks the required ".concat(e, " key '").concat(a, "'."));
      r.push(n[a]);
    }

    return r;
  }
}

function standardizeTensorValidationData(e) {
  if (3 === e.length) throw new NotImplementedError("Validation with sample weights is not implemented yet.");
  return {
    xs: e[0],
    ys: e[1]
  };
}

function fitDataset(_x91, _x92, _x93) {
  return _fitDataset.apply(this, arguments);
}

function _fitDataset() {
  _fitDataset = _asyncToGenerator(function* (e, t, n) {
    var r = null != n.batchesPerEpoch;
    if (assert$4(null != e.optimizer, () => "You must compile a model before training/testing. Use LayersModel.compile(modelCompileConfig)."), assert$4(null != n, () => "For fitDataset(), the 2nd argument (config) is required, but it is not provided in this call."), assert$4(null != n.epochs && n.epochs > 0 && Number.isInteger(n.epochs), () => "For fitDataset(), config.epochs is expected to be a positive integer, but got ".concat(n.epochs)), assert$4(!r || n.batchesPerEpoch > 0 && Number.isInteger(n.batchesPerEpoch), () => "For fitDataset(), config.batchesPerEpoch is expected to be a positive integer if specified, but got ".concat(n.batchesPerEpoch)), assert$4(null == n.validationSplit, () => "`validationSplit` is not supported by `fitDataset()`. Use validationData instead."), e.isTraining) throw new Error("Cannot start training because another fit() call is ongoing.");
    e.isTraining = !0;

    try {
      var a = null != n.validationData;
      var s, o;
      if (a) if (isDatasetObject(n.validationData)) assert$4(null == n.validationBatches || n.validationBatches > 0 && Number.isInteger(n.validationBatches), () => "For fitDataset() with dataset-based validation, config.validationBatches is expected not to be provided, or to be a positive integer, but got ".concat(n.validationBatches));else {
        var _e1162 = standardizeTensorValidationData(n.validationData);

        s = _e1162.xs, o = _e1162.ys;
      }
      var i = e.makeTrainFunction(),
          l = e.getDedupedMetricsNames();
      var u;
      u = a ? l.slice().concat(l.map(e => "val_" + e)) : l.slice();

      var c = standardizeCallbacks(n.callbacks, n.yieldEvery),
          _p43 = null == n.verbose ? 1 : n.verbose,
          {
        callbackList: d,
        history: h
      } = configureCallbacks(c, _p43, n.epochs, null, null, getStepsPerEpoch(t, n), null, a, u);

      d.setModel(e), e.history = h, yield d.onTrainBegin(), e.stopTraining_ = !1;
      var m = null == n.initialEpoch ? 0 : n.initialEpoch,
          f = yield t.iterator();

      for (; m < n.epochs;) {
        var _u66 = {};
        yield d.onEpochBegin(m);
        var _c44 = 0,
            _p44 = 0;

        for (r || (f = yield t.iterator()); !r || _c44 < n.batchesPerEpoch;) {
          var _t780 = yield f.next();

          if (r && _t780.done) {
            console.warn("You provided `batchesPerEpoch` as ".concat(n.batchesPerEpoch, ", but your dataset iterator ran out of data after ").concat(_c44, " batches; interrupting training. Make sure that your dataset can generate at least `batchesPerEpoch * epochs` batches (in this case, ") + n.batchesPerEpoch * n.epochs + " batches). You may need to use the repeat() function when building your dataset.");
            break;
          }

          if (null != _t780.value) {
            var {
              xs: _r451,
              ys: _a322
            } = standardizeDataIteratorOutput(e, _t780.value),
                _s226 = {};
            _s226.batch = _p44, _s226.size = _r451[0].shape[0], yield d.onBatchBegin(_p44, _s226);
            var _o161 = [];

            if (null != n.classWeight) {
              var _t781 = standardizeClassWeights(n.classWeight, e.outputNames);

              for (var _e1163 = 0; _e1163 < _t781.length; ++_e1163) {
                _o161.push(yield standardizeWeights(_a322[_e1163], null, _t781[_e1163]));
              }
            }

            var _u67 = _r451.concat(_a322).concat(_o161),
                _h26 = i(_u67);

            dispose(_u67);

            for (var _e1164 = 0; _e1164 < l.length; ++_e1164) {
              var _t782 = _h26[_e1164];
              _s226[l[_e1164]] = _t782, keep(_t782);
            }

            yield d.onBatchEnd(_p44, _s226), disposeTensorsInLogs(_s226), _p44++, _c44++;
          }

          if (r ? _c44 >= n.batchesPerEpoch : _t780.done) {
            if (a) {
              var _t783 = void 0;

              _t783 = isDatasetObject(n.validationData) ? toList(yield e.evaluateDataset(n.validationData, {
                batches: n.validationBatches
              })) : toList(e.evaluate(s, o, {
                batchSize: null == n.validationBatchSize ? DEFAULT_VALIDATION_BATCH_SIZE : n.validationBatchSize,
                verbose: 0
              }));

              for (var _n456 = 0; _n456 < e.metricsNames.length; ++_n456) {
                _u66["val_".concat(e.metricsNames[_n456])] = _t783[_n456];
              }
            }

            break;
          }

          if (e.stopTraining_) break;
        }

        if (yield d.onEpochEnd(m, _u66), m++, e.stopTraining_) break;
      }

      return yield d.onTrainEnd(), yield e.history.syncData(), e.history;
    } finally {
      e.isTraining = !1;
    }
  });
  return _fitDataset.apply(this, arguments);
}

function getStepsPerEpoch(e, t) {
  var n = null;
  return null != t.batchesPerEpoch ? n = t.batchesPerEpoch : Number.isFinite(e.size) && (n = e.size), n;
}

function isDatasetObject(e) {
  return "function" == typeof e.iterator;
}

function isLazyIteratorObject(e) {
  return "function" == typeof e.next;
}

function evaluateDataset(_x94, _x95, _x96) {
  return _evaluateDataset.apply(this, arguments);
}

function _evaluateDataset() {
  _evaluateDataset = _asyncToGenerator(function* (e, t, n) {
    var r = null != (n = n || {}).batches,
        a = e.testFunction;
    var s = [];
    if (n.verbose > 0) throw new NotImplementedError("Verbose mode is not implemented yet.");
    assert$4(!r || n.batches > 0 && Number.isInteger(n.batches), () => "Test loop expects `batches` to be a positive integer, but received ".concat(JSON.stringify(n.batches)));
    var o = isLazyIteratorObject(t) ? t : yield t.iterator();
    var i = 0,
        l = 0;

    var _loop66 = function* _loop66() {
      var t = yield o.next();

      if (s = tidy(() => {
        if (t.value) {
          (function () {
            var {
              xs: n,
              ys: r
            } = standardizeDataIteratorOutput(e, t.value),
                o = n.concat(r),
                u = tidy(() => a(o));
            if (dispose(o), 0 === l) for (var _e1166 = 0; _e1166 < u.length; ++_e1166) {
              s.push(scalar(0));
            }
            var c = o[0].shape[0];

            var _loop67 = function _loop67(_e1167) {
              var t = u[_e1167],
                  n = s[_e1167];
              s[_e1167] = tidy(() => add$2(s[_e1167], mul(c, t))), l > 0 && dispose(n);
            };

            for (var _e1167 = 0; _e1167 < u.length; ++_e1167) {
              _loop67(_e1167);
            }

            dispose(u), i += c, ++l;
          })();
        }

        return s;
      }), t.done) {
        r && console.warn("Your dataset iterator ran out of data during evaluateDataset(). Interrupting evalution. Make sure that your dataset can generate at least `batches` batches (in this case, ".concat(n.batches, " batches). You may need to use the repeat() function when building your dataset."));
        return "break";
      }
    };

    for (; !r || l < n.batches;) {
      var _ret8 = yield* _loop66();

      if (_ret8 === "break") break;
    }

    for (var _e1165 = 0; _e1165 < s.length; ++_e1165) {
      var _t784 = s[_e1165];
      s[_e1165] = div$1(s[_e1165], i), dispose(_t784);
    }

    return singletonOrArray(s);
  });
  return _evaluateDataset.apply(this, arguments);
}

function checkBatchSize(e) {
  assert$4(e > 0 && Number.isInteger(e), () => "batchSize is required to be a positive integer, but got ".concat(e));
}

function sliceArrays(e, t, n) {
  return null == e ? [null] : Array.isArray(e) ? e.map(e => sliceAlongFirstAxis(e, t, n - t)) : sliceAlongFirstAxis(e, t, n - t);
}

function sliceArraysByIndices(e, t) {
  return tidy(() => null == e ? null : Array.isArray(e) ? e.map(e => sliceArraysByIndices(e, t)) : gather(e, "int32" === t.dtype ? t : cast$3(t, "int32")));
}

function makeBatches(e, t) {
  var n = [];
  var r = 0,
      a = null;

  for (; r < e;) {
    a = r + t, a >= e && (a = e), n.push([r, a]), r = a;
  }

  return n;
}

function fitLoop(_x97, _x98, _x99, _x100, _x101, _x102, _x103, _x104, _x105, _x106, _x107, _x108, _x109, _x110, _x111) {
  return _fitLoop.apply(this, arguments);
}

function _fitLoop() {
  _fitLoop = _asyncToGenerator(function* (e, t, n, r, a, s, o, i, l, u, c, p, d, h, m) {
    null == a && (a = 32), null == s && (s = 1), null == c && (c = !0), null == d && (d = 0);
    var f = !1;
    if (null != l && null != u && (f = !0), null != m && (f = !0, null == h)) throw new ValueError("Can only use `validationSteps` when doing step-wise training, i.e., `stepsPerEpoch` must be set.");
    var g = e.checkNumSamples(n, a, h, "steps_per_epoch");
    var $;
    null != g && ($ = range$3(0, g)), null == o && (o = 1);
    var {
      callbackList: y,
      history: b
    } = configureCallbacks(i, o, s, d, g, h, a, f, p);
    y.setModel(e), e.history = b, yield y.onTrainBegin(), e.stopTraining_ = !1;

    var _loop68 = function* _loop68(_o162) {
      yield y.onEpochBegin(_o162);
      var s = {};
      if (null != h) throw new NotImplementedError("stepsPerEpoch mode is not implemented yet.");
      {
        yield* function* () {
          if ("batch" === c) throw new NotImplementedError("batch shuffling is not implemneted yet");
          c && shuffle($);
          var o = tensor1d($),
              i = makeBatches(g, a);

          var _loop69 = function* _loop69(_c45) {
            var p = {};
            if (yield y.onBatchBegin(_c45, p), tidy(() => {
              var d = i[_c45][0],
                  h = i[_c45][1],
                  m = sliceAlongFirstAxis(o, d, h - d);
              p.batch = _c45, p.size = h - d;
              var g = sliceArraysByIndices(n, m),
                  $ = t(g);

              for (var _e1168 = 0; _e1168 < r.length; ++_e1168) {
                var _t785 = $[_e1168];
                p[r[_e1168]] = _t785, keep(_t785);
              }

              if (_c45 === i.length - 1 && f) {
                var _t786 = e.testLoop(l, u, a);

                for (var _e1169 = 0; _e1169 < r.length; ++_e1169) {
                  var _n457 = r[_e1169],
                      _a323 = _t786[_e1169];
                  keep(_a323), s["val_" + _n457] = _a323;
                }
              }
            }), yield y.onBatchEnd(_c45, p), disposeTensorsInLogs(p), e.stopTraining_) return "break";
          };

          for (var _c45 = 0; _c45 < i.length; ++_c45) {
            var _ret10 = yield* _loop69(_c45);

            if (_ret10 === "break") break;
          }

          o.dispose();
        }();
      }
      if (yield y.onEpochEnd(_o162, s), e.stopTraining_) return "break";
    };

    for (var _o162 = d; _o162 < s; ++_o162) {
      var _ret9 = yield* _loop68(_o162);

      if (_ret9 === "break") break;
    }

    return yield y.onTrainEnd(), yield e.history.syncData(), e.history;
  });
  return _fitLoop.apply(this, arguments);
}

function fitTensors(_x112, _x113, _x114) {
  return _fitTensors.apply(this, arguments);
}

function _fitTensors() {
  _fitTensors = _asyncToGenerator(function* (e, t, n) {
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : {};
    if (e.isTraining) throw new Error("Cannot start training because another fit() call is ongoing.");
    var a, s, o, i, l, u, c;
    e.isTraining = !0;

    try {
      var _p45 = null == r.batchSize ? 32 : r.batchSize;

      checkBatchSize(_p45);
      var d = !1,
          h = yield e.standardizeUserData(t, n, r.sampleWeight, r.classWeight, d, _p45);
      a = h[0], s = h[1], c = h[2];
      var m,
          f = !1;

      if (null != r.validationData && r.validationData.length > 0) {
        if (f = !0, 2 !== r.validationData.length) throw 3 === r.validationData.length ? new NotImplementedError("validationData including sample weights is not supported yet.") : new ValueError("When passing validation data, it must contain 2 (valX, valY) or 3 (valX, valY, valSampleWeight) items; ".concat(r.validationData, " is invalid."));
        o = r.validationData[0], i = r.validationData[1];

        var _t787 = !0,
            _n458 = yield e.standardizeUserData(o, i, null, null, _t787, _p45);

        l = _n458[0], u = _n458[1], m = l.concat(u);
      } else if (null != r.validationSplit && r.validationSplit > 0 && r.validationSplit < 1) {
        f = !0;

        var _e1170 = Math.floor(a[0].shape[0] * (1 - r.validationSplit)),
            _t788 = a[0].shape[0];

        l = sliceArrays(a, _e1170, _t788), a = sliceArrays(a, 0, _e1170), u = sliceArrays(s, _e1170, _t788), s = sliceArrays(s, 0, _e1170), m = l.concat(u);
      } else null != r.validationSteps && (f = !0);

      var g = a.concat(s).concat(c);
      e.checkTrainableWeightsConsistency();
      var $ = e.makeTrainFunction(),
          y = e.getDedupedMetricsNames();
      var b, x;
      f ? (e.makeTestFunction(), b = e.testFunction, x = y.slice().concat(y.map(e => "val_" + e))) : (b = null, m = [], x = y.slice());
      var v = standardizeCallbacks(r.callbacks, r.yieldEvery);
      return yield fitLoop(e, $, g, y, _p45, r.epochs, r.verbose, v, b, m, r.shuffle, x, r.initialEpoch, null, null);
    } finally {
      e.isTraining = !1, disposeNewTensors(a, t), disposeNewTensors(s, n), disposeNewTensors(l, o), disposeNewTensors(u, i), null != c && dispose(c);
    }
  });
  return _fitTensors.apply(this, arguments);
}

function ensureTensorsRank2OrHigher(e) {
  var t = [];
  e instanceof Tensor && (e = [e]);

  for (var n = 0; n < e.length; ++n) {
    var r = e[n];
    if (1 === r.rank) t.push(expandDims$2(r, 1));else {
      if (0 === r.rank) throw new Error("Expected tensor to be at least 1D, but received a 0D tensor (scalar).");
      t.push(r);
    }
  }

  return t;
}

function disposeNewTensors(e, t) {
  if (null == e) return;
  var n = [];
  if (t instanceof Tensor) n.push(t.id);else if (Array.isArray(t)) t.forEach(e => n.push(e.id));else if (null != t) for (var _e705 in t) {
    n.push(t[_e705].id);
  }
  var r = [];
  if (e instanceof Tensor) -1 === n.indexOf(e.id) && r.push(e);else if (Array.isArray(e)) e.forEach(e => {
    -1 === n.indexOf(e.id) && r.push(e);
  });else if (null != e) for (var _t490 in e) {
    var a = e[_t490];
    -1 === n.indexOf(a.id) && r.push(a);
  }
  r.forEach(e => {
    e.isDisposed || e.dispose();
  });
}

function isDataTensor(e) {
  return e instanceof Tensor;
}

function isDataArray(e) {
  return Array.isArray(e);
}

function isDataDict(e) {
  return !isDataTensor(e) && !isDataArray(e);
}

function standardizeInputData(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !0;
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : "";

  if (null == t || 0 === t.length) {
    if (null != e) {
      var _t491 = !1;

      if (isDataArray(e) && e.length > 0) _t491 = !0;else if (isDataDict(e)) {
        for (var _n278 in e) {
          if (e.hasOwnProperty(_n278)) {
            _t491 = !0;
            break;
          }
        }
      } else _t491 = !0;
      if (_t491) throw new ValueError("Error when checking model ".concat(a, " expected no data, but got ").concat(e));
    }

    return [];
  }

  if (null == e) return t.map(e => null);
  var s;

  if (isDataDict(e)) {
    e = e, s = [];

    for (var _n279 of t) {
      if (null == e[_n279]) throw new ValueError("No data provided for \"".concat(_n279, "\". Need data for each key in: ").concat(t));
      s.push(e[_n279]);
    }
  } else if (isDataArray(e)) {
    if ((e = e).length !== t.length) throw new ValueError("Error when checking model ".concat(a, ": the Array of Tensors that you are passing to your model is not the size the model expected. Expected to see ").concat(t.length, " Tensor(s), but instead got the following list of Tensor(s): ").concat(e));
    s = e;
  } else {
    if (e = e, t.length > 1) throw new ValueError("The model ".concat(a, " expects ").concat(t.length, " Tensor(s), but only received one Tensor. Found: Tensor with shape ").concat(e.shape));
    s = [e];
  }

  if (s = ensureTensorsRank2OrHigher(s), null != n) for (var _e706 = 0; _e706 < t.length; ++_e706) {
    if (null == n[_e706]) continue;
    var o = s[_e706];
    if (o.shape.length !== n[_e706].length) throw new ValueError("Error when checking ".concat(a, ": expected ").concat(t[_e706], " to have ").concat(n[_e706].length, " dimension(s). but got array with shape ").concat(o.shape));

    for (var _s112 = 0; _s112 < n[_e706].length; ++_s112) {
      if (0 === _s112 && !r) continue;
      var i = o.shape[_s112],
          l = n[_e706][_s112];
      if (null != l && l >= 0 && i !== l) throw new ValueError("Error when checking ".concat(a, ": expected ").concat(t[_e706], " to have shape [").concat(n[_e706], "], but got array with shape [").concat(o.shape, "]."));
    }
  }
  return s;
}

function checkArrayLengths(e, t, n) {
  var r = unique$2(e.map(e => e.shape[0]));
  r.sort();
  var a = unique$2(t.map(e => e.shape[0]));
  if (a.sort(), r.length > 1) throw new ValueError("All input Tensors (x) should have the same number of samples. Got array shapes: ".concat(JSON.stringify(e.map(e => e.shape))));
  if (a.length > 1) throw new ValueError("All target Tensors (y) should have the same number of samples. Got array shapes: ".concat(JSON.stringify(t.map(e => e.shape))));
  if (r.length > 0 && a.length > 0 && !arraysEqual(r, a)) throw new ValueError("Input Tensors should have the same number of samples as target Tensors. Found ".concat(r[0], " input sample(s) and ").concat(a[0], " target sample(s)."));
}

function checkLossAndTargetCompatibility(e, t, n) {
  var r = [meanSquaredError$1, binaryCrossentropy$2, categoricalCrossentropy$2];

  for (var a = 0; a < e.length; ++a) {
    var s = e[a],
        o = t[a],
        i = n[a];

    if (null != o) {
      if (o === categoricalCrossentropy$2 && 1 === s.shape[s.shape.length - 1]) throw new ValueError("You are passing a target array of shape ".concat(s.shape, " while using a loss 'categorical_crossentropy'. 'categorical_crossentropy'expects targets to be binary matrices (1s and 0s) of shape [samples, classes]."));

      if (-1 !== r.indexOf(o)) {
        var _e707 = s.shape.slice(1),
            _t492 = i.slice(1);

        for (var _n280 = 0; _n280 < _e707.length; ++_n280) {
          var _r228 = _e707[_n280],
              _a152 = _t492[_n280];
          if (null != _a152 && _r228 !== _a152) throw new ValueError("A target Tensor with shape ".concat(s.shape, " was passed for an output of shape ").concat(i, ", while using a loss function that expects targets to have the same shape as the output."));
        }
      }
    }
  }
}

function checkInputData(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !0;
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : "";
  var s;

  if (Array.isArray(e)) {
    if (e.length !== t.length) throw new ValueError("Error when checking model ".concat(a, ": the Array of Tensors that you are passing to your model is not the size the the model expected. Expected to see ").concat(t.length, " Tensor(s), but instead got ").concat(e.length, " Tensors(s)."));
    s = e;
  } else {
    if (t.length > 1) throw new ValueError("The model expects ".concat(t.length, " ").concat(a, " Tensors, but only received one Tensor. Found: array with shape ").concat(JSON.stringify(e.shape), "."));
    s = [e];
  }

  if (null != n) for (var _e708 = 0; _e708 < t.length; ++_e708) {
    if (null == n[_e708]) continue;
    var o = s[_e708];
    if (o.shape.length !== n[_e708].length) throw new ValueError("Error when checking ".concat(a, ": expected ").concat(t[_e708], " to have ").concat(n[_e708].length, " dimension(s), but got array with shape ").concat(JSON.stringify(o.shape)));

    for (var _s113 = 0; _s113 < n[_e708].length; ++_s113) {
      if (0 === _s113 && !r) continue;
      var i = o.shape[_s113],
          l = n[_e708][_s113];
      if (null != l && l !== i) throw new ValueError("Error when checking ".concat(a, ": expected ").concat(t[_e708], " to have shape ").concat(JSON.stringify(n[_e708]), " but got array with shape ").concat(JSON.stringify(o.shape), "."));
    }
  }
}

function collectMetrics(e, t) {
  if (null == e || Array.isArray(e) && 0 === e.length) return t.map(e => []);
  var n;
  if ("string" == typeof e || "function" == typeof e) n = [e];else {
    if (!Array.isArray(e) && "object" != typeof e) throw new TypeError("Type of metrics argument not understood. Expected an string,function, Array, or Object, found: ".concat(e));
    n = e;
  }
  if (Array.isArray(n)) return t.map(e => n);
  {
    var _e709 = [];

    for (var r of t) {
      var _t493 = n.hasOwnProperty(r) ? n[r] : [];

      Array.isArray(_t493) || (_t493 = [_t493]), _e709.push(_t493);
    }

    return _e709;
  }
}

var LAYERS_MODEL_FORMAT_NAME = "layers-model";

class LayersModel extends Container {
  constructor(e) {
    super(e), this.isTraining = !1;
  }

  summary(e, t) {
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : console.log;
    if (!this.built) throw new ValueError("This model has never been called, thus its weights have not been created yet. So no summary can be displayed. Build the model first (e.g., by calling it on some test data).");
    printSummary(this, e, t, n);
  }

  compile(e) {
    var _this135 = this;

    if (null == e.loss && (e.loss = []), this.loss = e.loss, "string" == typeof e.optimizer) this.optimizer_ = getOptimizer(e.optimizer), this.isOptimizerOwned = !0;else {
      if (!(e.optimizer instanceof Optimizer)) throw new ValueError("User-defined optimizer must be an instance of tf.Optimizer.");
      this.optimizer_ = e.optimizer, this.isOptimizerOwned = !1;
    }
    var t = [];
    if (Array.isArray(e.loss) || "string" == typeof e.loss || "function" == typeof e.loss) {
      if (Array.isArray(e.loss)) {
        if (e.loss.length !== this.outputs.length) throw new ValueError("When passing an Array as loss, it should have one entry per model output. The model has ".concat(this.outputs.length, " output(s), but you passed loss=").concat(e.loss, "."));
        t = e.loss.map(e => get$1(e));
      } else {
        var _n281 = get$1(e.loss);

        this.outputs.forEach(e => {
          t.push(_n281);
        });
      }
    } else {
      e.loss = e.loss;

      for (var _t494 in e.loss) {
        if (-1 === this.outputNames.indexOf(_t494)) throw new ValueError("Unknown entry in loss dictionary: \"".concat(_t494, "\". Only expected the following keys: ").concat(this.outputNames));
      }

      for (var _n282 of this.outputNames) {
        null == e.loss[_n282] && console.warn("Output \"".concat(_n282, "\" is missing from loss dictionary. We assume this was done on purpose, and we will not be expecting data to be passed to ").concat(_n282, " during training")), t.push(get$1(e.loss[_n282]));
      }
    }
    this.lossFunctions = t, this.feedOutputNames = [], this.feedOutputShapes = [], this.feedLossFns = [];

    for (var _e710 = 0; _e710 < this.outputs.length; ++_e710) {
      var _t495 = this.internalOutputShapes[_e710];
      this.feedOutputNames.push(this.outputNames[_e710]), this.feedOutputShapes.push(_t495), this.feedLossFns.push(this.lossFunctions[_e710]);
    }

    var n = [];
    this.metrics = e.metrics, this.metricsNames = ["loss"], this.metricsTensors = [], nameScope("loss", () => {
      for (var _e711 = 0; _e711 < this.outputs.length; ++_e711) {
        if (-1 !== n.indexOf(_e711)) continue;
        var _t496 = this.lossFunctions[_e711];
        this.outputs.length > 1 && (this.metricsTensors.push([_t496, _e711]), this.metricsNames.push(this.outputNames[_e711] + "_loss"));
      }
    });

    var r = collectMetrics(e.metrics, this.outputNames),
        a = (e, t, n) => {
      this.outputNames.length > 1 && (t = this.outputNames[e] + "_" + t), this.metricsNames.push(t), this.metricsTensors.push([n, e]);
    };

    nameScope("metric", () => {
      var _loop45 = function _loop45(_e712) {
        -1 === n.indexOf(_e712) && (t => {
          var n, r, s;

          for (var o of t) {
            if ("string" == typeof o && -1 !== ["accuracy", "acc", "crossentropy", "ce"].indexOf(o)) {
              var _t498 = _this135.internalOutputShapes[_e712];

              var _a153 = void 0;

              1 === _t498[_t498.length - 1] || _this135.lossFunctions[_e712] === binaryCrossentropy$2 ? -1 !== ["accuracy", "acc"].indexOf(o) ? r = binaryAccuracy$1 : -1 !== ["crossentropy", "ce"].indexOf(o) && (r = binaryCrossentropy$1) : _this135.lossFunctions[_e712] === sparseCategoricalCrossentropy$1 ? -1 !== ["accuracy", "acc"].indexOf(o) ? r = sparseCategoricalAccuracy$1 : -1 !== ["crossentropy", "ce"].indexOf(o) && (r = sparseCategoricalCrossentropy) : -1 !== ["accuracy", "acc"].indexOf(o) ? r = categoricalAccuracy$1 : -1 !== ["crossentropy", "ce"].indexOf(o) && (r = categoricalCrossentropy$1), -1 !== ["accuracy", "acc"].indexOf(o) ? _a153 = "acc" : -1 !== ["crossentropy", "ce"].indexOf(o) && (_a153 = "ce"), s = r, n = "" + _a153;
            } else {
              var _e713 = get(o);

              s = _e713, n = "" + getLossOrMetricName(o);
            }

            var _t497 = void 0;

            nameScope(n, () => {
              _t497 = s;
            }), a(_e712, n, _t497);
          }
        })(r[_e712]);
      };

      for (var _e712 = 0; _e712 < this.outputs.length; ++_e712) {
        _loop45(_e712);
      }
    }), this.collectedTrainableWeights = this.trainableWeights;
  }

  checkTrainableWeightsConsistency() {
    null != this.collectedTrainableWeights && this.trainableWeights.length !== this.collectedTrainableWeights.length && console.warn("Discrepancy between trainableweights and collected trainable weights. Did you set `model.trainable` without calling `model.compile()` afterwards?");
  }

  evaluate(e, t) {
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};
    var r = null == n.batchSize ? 32 : n.batchSize;
    checkBatchSize(r);
    var a = this.standardizeUserDataXY(e, t, !0, r);

    try {
      var s = a[0].concat(a[1]);
      return this.makeTestFunction(), singletonOrArray(this.testLoop(this.testFunction, s, r, n.verbose, n.steps));
    } finally {
      disposeNewTensors(a[0], e), disposeNewTensors(a[1], t);
    }
  }

  evaluateDataset(e, t) {
    var _this136 = this;

    return _asyncToGenerator(function* () {
      return _this136.makeTestFunction(), evaluateDataset(_this136, e, t);
    })();
  }

  checkNumSamples(e, t, n) {
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : "steps";
    var a;

    if (null != n) {
      if (a = null, null != t) throw new ValueError("If ".concat(r, " is set, batchSize must be null or undefined.Got batchSize = ").concat(t));
    } else {
      if (null == e) throw new ValueError("Either the input data should have a defined shape, or ".concat(r, " shoud be specified."));
      a = Array.isArray(e) ? e[0].shape[0] : e.shape[0];
    }

    return a;
  }

  execute(e, t) {
    if (Array.isArray(t) && 0 === t.length) throw new ValueError("`outputs` is an empty Array, which is not allowed.");
    var n = Array.isArray(t),
        r = this.retrieveSymbolicTensors(n ? t : [t]),
        a = new FeedDict();

    if (e instanceof Tensor && (e = [e]), Array.isArray(e)) {
      if (e.length !== this.inputs.length) throw new ValueError("The number of inputs provided (".concat(e.length, ") does not match the number of inputs of this model (").concat(this.inputs.length, ")."));

      for (var _t499 = 0; _t499 < this.inputs.length; ++_t499) {
        a.add(this.inputs[_t499], e[_t499]);
      }
    } else for (var _t500 of this.inputs) {
      var _n283 = e[_t500.name];
      if (null == _n283) throw new ValueError("No value is provided for the model's input ".concat(_t500.name));
      a.add(_t500, _n283);
    }

    var s = execute(r, a);
    return n ? s : s[0];
  }

  retrieveSymbolicTensors(e) {
    var t = pyListRepeat(null, e.length);
    var n = e.length;

    for (var r of this.layers) {
      var a = Array.isArray(r.output) ? r.output : [r.output],
          s = a.map(e => e.name);

      for (var _r229 = 0; _r229 < e.length; ++_r229) {
        var o = s.indexOf(e[_r229]);
        if (-1 !== o && (t[_r229] = a[o], n--), 0 === n) break;
      }

      if (0 === n) break;
    }

    if (n > 0) {
      var _n284 = [];
      throw t.forEach((t, r) => {
        null == t && _n284.push(e[r]);
      }), new ValueError("Cannot find SymbolicTensors for output name(s): ".concat(JSON.stringify(_n284)));
    }

    return t;
  }

  predictLoop(e) {
    var _this137 = this;

    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 32;
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
    return tidy(() => {
      var r = this.checkNumSamples(e);
      if (n) throw new NotImplementedError("Verbose predictLoop() is not implemented yet.");
      var a = makeBatches(r, t),
          s = this.outputs.map(e => []);

      var _loop46 = function _loop46(_t501) {
        tidy(() => {
          var n = sliceArrays(e, a[_t501][0], a[_t501][1]),
              r = [];
          if (Array.isArray(n)) for (var _e714 = 0; _e714 < n.length; ++_e714) {
            r.push({
              key: _this137.inputs[_e714],
              value: n[_e714]
            });
          } else r.push({
            key: _this137.inputs[0],
            value: n
          });
          var s = new FeedDict(r);
          return execute(_this137.outputs, s);
        }).forEach((e, t) => s[t].push(e));
      };

      for (var _t501 = 0; _t501 < a.length; ++_t501) {
        _loop46(_t501);
      }

      return singletonOrArray(s.map(e => concat$2(e, 0)));
    });
  }

  predict(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};
    var n = ensureTensorsRank2OrHigher(e);
    checkInputData(n, this.inputNames, this.feedInputShapes, !1);

    try {
      var r = null == t.batchSize ? 32 : t.batchSize;
      return checkBatchSize(r), this.predictLoop(n, r);
    } finally {
      disposeNewTensors(n, e);
    }
  }

  predictOnBatch(e) {
    checkInputData(e, this.inputNames, this.feedInputShapes, !0);
    var t = (Array.isArray(e) ? e[0] : e).shape[0];
    return this.predictLoop(e, t);
  }

  standardizeUserDataXY(e, t) {
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !0;
    var r = arguments.length > 3 ? arguments[3] : undefined;
    if (null == this.optimizer_) throw new RuntimeError("You must compile a model before training/testing. Use LayersModel.compile(modelCompileArgs).");
    var a = [];

    for (var _e715 = 0; _e715 < this.feedOutputShapes.length; ++_e715) {
      var _t502 = this.feedOutputShapes[_e715];
      a.push(this.feedLossFns[_e715] === sparseCategoricalCrossentropy$1 ? _t502.slice(0, _t502.length - 1).concat([1]) : _t502);
    }

    if (checkArrayLengths(e = standardizeInputData(e, this.feedInputNames, this.feedInputShapes, !1, "input"), t = standardizeInputData(t, this.feedOutputNames, a, !1, "target")), checkLossAndTargetCompatibility(t, this.feedLossFns, this.feedOutputShapes), this.stateful && null != r && r > 0 && e[0].shape[0] % r != 0) throw new ValueError("In a stateful network, you should only pass inputs with a number of samples that is divisible by the batch size ".concat(r, ". Found: ").concat(e[0].shape[0], " sample(s)."));
    return [e, t];
  }

  standardizeUserData(e, t, n, r) {
    var _arguments4 = arguments,
        _this138 = this;

    return _asyncToGenerator(function* () {
      var a = _arguments4.length > 4 && _arguments4[4] !== undefined ? _arguments4[4] : !0;
      var s = _arguments4.length > 5 ? _arguments4[5] : undefined;

      var [o, i] = _this138.standardizeUserDataXY(e, t, a, s);

      if (null != n) throw new Error("sample weight is not supported yet.");
      var l = null;

      if (null != r) {
        var _e716 = standardizeClassWeights(r, _this138.outputNames);

        l = [];

        for (var _t503 = 0; _t503 < _e716.length; ++_t503) {
          l.push(yield standardizeWeights(i[_t503], null, _e716[_t503]));
        }
      }

      return [o, i, l];
    })();
  }

  testLoop(e, t, n) {
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 0;
    var a = arguments.length > 4 ? arguments[4] : undefined;
    return tidy(() => {
      var s = this.checkNumSamples(t, n, a, "steps"),
          o = [];
      if (r > 0) throw new NotImplementedError("Verbose mode is not implemented yet.");
      if (null != a) throw new NotImplementedError("steps mode in testLoop() is not implemented yet");
      {
        var _r230 = makeBatches(s, n),
            _a154 = tensor1d(range$3(0, s));

        for (var _n285 = 0; _n285 < _r230.length; ++_n285) {
          var _s114 = _r230[_n285][0],
              i = _r230[_n285][1],
              l = sliceAlongFirstAxis(_a154, _s114, i - _s114),
              u = sliceArraysByIndices(t, l),
              c = e(u);
          if (0 === _n285) for (var _e717 = 0; _e717 < c.length; ++_e717) {
            o.push(scalar(0));
          }

          for (var _e718 = 0; _e718 < c.length; ++_e718) {
            o[_e718] = add$2(o[_e718], mul(i - _s114, c[_e718]));
          }
        }

        for (var _e719 = 0; _e719 < o.length; ++_e719) {
          o[_e719] = div$1(o[_e719], s);
        }
      }
      return o;
    });
  }

  getDedupedMetricsNames() {
    var e = this.metricsNames,
        t = [];

    for (var n = 0; n < e.length; ++n) {
      var r = e[n];
      var a = r;
      count(e, r) > 1 && (a += "_".concat(count(e.slice(0, n), r))), t.push(a);
    }

    return t;
  }

  makeTrainFunction() {
    return e => {
      var t = [],
          n = e.slice(0, this.inputs.length),
          r = e.slice(this.inputs.length, this.inputs.length + this.outputs.length),
          a = e.slice(this.inputs.length + this.outputs.length, this.inputs.length + 2 * this.outputs.length),
          s = [],
          o = this.collectedTrainableWeights.map(e => e.read());
      return [this.optimizer_.minimize(() => {
        var e = [];

        for (var _t504 = 0; _t504 < this.inputs.length; ++_t504) {
          e.push({
            key: this.inputs[_t504],
            value: n[_t504]
          });
        }

        var o = new FeedDict(e),
            i = execute(this.outputs, o, {
          training: !0
        });
        var l;

        for (var _e720 = 0; _e720 < this.lossFunctions.length; ++_e720) {
          var _n286 = (0, this.lossFunctions[_e720])(r[_e720], i[_e720]);

          null != a[_e720] && (_n286 = computeWeightedLoss(_n286, a[_e720]));

          var _s115 = mean$1(_n286);

          t.push(_s115), l = 0 === _e720 ? _n286 : add$2(l, _n286);
        }

        for (var _e721 = 0; _e721 < this.metricsTensors.length; ++_e721) {
          var _n287 = void 0;

          if (this.outputs.length > 1 && _e721 < this.outputs.length) _n287 = t[_e721];else {
            var _t505 = this.metricsTensors[_e721][1];
            _n287 = mean$1((0, this.metricsTensors[_e721][0])(r[_t505], i[_t505]));
          }
          keep(_n287), s.push(_n287);
        }

        return l = mean$1(l), this.calculateLosses().forEach(e => {
          l = add$2(l, e);
        }), l;
      }, !0, o)].concat(s);
    };
  }

  makeTestFunction() {
    this.testFunction = e => tidy(() => {
      var t = [];
      var n;
      var r = e.slice(0, this.inputs.length),
          a = e.slice(this.inputs.length, this.inputs.length + this.outputs.length),
          s = [];

      for (var _e722 = 0; _e722 < this.inputs.length; ++_e722) {
        s.push({
          key: this.inputs[_e722],
          value: r[_e722]
        });
      }

      var o = new FeedDict(s),
          i = execute(this.outputs, o);

      for (var _e723 = 0; _e723 < this.lossFunctions.length; ++_e723) {
        var _r231 = mean$1((0, this.lossFunctions[_e723])(a[_e723], i[_e723]));

        n = 0 === _e723 ? _r231 : add$2(n, _r231), t.push(n);
      }

      for (var _e724 = 0; _e724 < this.metricsTensors.length; ++_e724) {
        var _n288 = this.metricsTensors[_e724][1],
            _r232 = mean$1((0, this.metricsTensors[_e724][0])(a[_n288], i[_n288]));

        t.push(_r232);
      }

      return t;
    });
  }

  fit(e, t) {
    var _arguments5 = arguments,
        _this139 = this;

    return _asyncToGenerator(function* () {
      var n = _arguments5.length > 2 && _arguments5[2] !== undefined ? _arguments5[2] : {};
      return fitTensors(_this139, e, t, n);
    })();
  }

  fitDataset(e, t) {
    var _this140 = this;

    return _asyncToGenerator(function* () {
      return fitDataset(_this140, e, t);
    })();
  }

  trainOnBatch(e, t) {
    var _this141 = this;

    return _asyncToGenerator(function* () {
      var n = yield _this141.standardizeUserData(e, t),
          r = n[0],
          a = n[1],
          s = _this141.makeTrainFunction()(r.concat(a)),
          o = [];

      for (var _e725 of s) {
        var _t506 = yield _e725.data();

        o.push(_t506[0]);
      }

      return dispose(s), singletonOrArray(o);
    })();
  }

  getNamedWeights(e) {
    var t = [],
        n = null != e && e.trainableOnly,
        r = n ? this.trainableWeights : this.weights,
        a = this.getWeights(n);

    for (var _e726 = 0; _e726 < r.length; ++_e726) {
      n && !r[_e726].trainable || t.push({
        name: r[_e726].originalName,
        tensor: a[_e726]
      });
    }

    return t;
  }

  set stopTraining(e) {
    this.stopTraining_ = e;
  }

  get stopTraining() {
    return this.stopTraining_;
  }

  get optimizer() {
    return this.optimizer_;
  }

  set optimizer(e) {
    this.optimizer_ !== e && (this.optimizer_ = e, this.isOptimizerOwned = !1);
  }

  dispose() {
    var e = super.dispose();

    if (0 === e.refCountAfterDispose && null != this.optimizer && this.isOptimizerOwned) {
      var t = memory().numTensors;
      this.optimizer_.dispose(), e.numDisposedVariables += t - memory().numTensors;
    }

    return e;
  }

  getLossIdentifiers() {
    var e;
    if ("string" == typeof this.loss) e = toSnakeCase(this.loss);else if (Array.isArray(this.loss)) {
      for (var _e727 of this.loss) {
        if ("string" != typeof _e727) throw new Error("Serialization of non-string loss is not supported.");
      }

      e = this.loss.map(e => toSnakeCase(e));
    } else {
      var t = Object.keys(this.loss);
      e = {};
      var n = this.loss;

      for (var r of t) {
        if ("string" != typeof n[r]) throw new Error("Serialization of non-string loss is not supported.");
        e[r] = toSnakeCase(n[r]);
      }
    }
    return e;
  }

  getMetricIdentifiers() {
    if ("string" == typeof this.metrics || "function" == typeof this.metrics) return [toSnakeCase(getLossOrMetricName(this.metrics))];
    if (Array.isArray(this.metrics)) return this.metrics.map(e => toSnakeCase(getLossOrMetricName(e)));
    {
      var _e728 = {};

      for (var t in this.metrics) {
        _e728[t] = toSnakeCase(getLossOrMetricName(this.metrics[t]));
      }

      return _e728;
    }
  }

  getTrainingConfig() {
    return {
      loss: this.getLossIdentifiers(),
      metrics: this.getMetricIdentifiers(),
      optimizer_config: {
        class_name: this.optimizer.getClassName(),
        config: this.optimizer.getConfig()
      }
    };
  }

  loadTrainingConfig(e) {
    if (null != e.weighted_metrics) throw new Error("Loading weight_metrics is not supported yet.");
    if (null != e.loss_weights) throw new Error("Loading loss_weights is not supported yet.");
    if (null != e.sample_weight_mode) throw new Error("Loading sample_weight_mode is not supported yet.");
    var t = deserialize(convertPythonicToTs(e.optimizer_config));
    var n, r;
    if ("string" == typeof e.loss) n = toCamelCase(e.loss);else if (Array.isArray(e.loss)) n = e.loss.map(e => toCamelCase(e));else if (null != e.loss) {
      n = {};

      for (var _t507 in e.loss) {
        n[_t507] = toCamelCase(e.loss[_t507]);
      }
    }
    if (Array.isArray(e.metrics)) r = e.metrics.map(e => toCamelCase(e));else if (null != e.metrics) {
      r = {};

      for (var _t508 in e.metrics) {
        r[_t508] = toCamelCase(e.metrics[_t508]);
      }
    }
    this.compile({
      loss: n,
      metrics: r,
      optimizer: t
    });
  }

  save(e, t) {
    var _this142 = this;

    return _asyncToGenerator(function* () {
      if ("string" == typeof e) {
        var _t509 = getSaveHandlers(e);

        if (0 === _t509.length) throw new ValueError("Cannot find any save handlers for URL '".concat(e, "'"));
        if (_t509.length > 1) throw new ValueError("Found more than one (".concat(_t509.length, ") save handlers for URL '").concat(e, "'"));
        e = _t509[0];
      }

      if (null == e.save) throw new ValueError("LayersModel.save() cannot proceed because the IOHandler provided does not have the `save` attribute defined.");
      var n = yield encodeWeights(_this142.getNamedWeights(t)),
          r = {
        modelTopology: _this142.toJSON(null, !1),
        format: LAYERS_MODEL_FORMAT_NAME,
        generatedBy: "TensorFlow.js tfjs-layers v".concat(version$6),
        convertedBy: null
      };

      if (null != t && t.includeOptimizer && null != _this142.optimizer) {
        r.trainingConfig = _this142.getTrainingConfig();
        var _e729 = "optimizer",
            {
          data: _t510,
          specs: a
        } = yield encodeWeights(yield _this142.optimizer.getWeights(), _e729);
        n.specs.push(...a), n.data = concatenateArrayBuffers([n.data, _t510]);
      }

      return null != _this142.userDefinedMetadata && (checkUserDefinedMetadata(_this142.userDefinedMetadata, _this142.name, !0), r.userDefinedMetadata = _this142.userDefinedMetadata), r.weightData = n.data, r.weightSpecs = n.specs, e.save(r);
    })();
  }

  setUserDefinedMetadata(e) {
    checkUserDefinedMetadata(e, this.name), this.userDefinedMetadata = e;
  }

  getUserDefinedMetadata() {
    return this.userDefinedMetadata;
  }

}

LayersModel.className = "Model", registerClass(LayersModel);

class Functional extends LayersModel {}

function modelFromJSON(_x115, _x116) {
  return _modelFromJSON.apply(this, arguments);
}

function _modelFromJSON() {
  _modelFromJSON = _asyncToGenerator(function* (e, t) {
    "modelTopology" in e || (e = {
      modelTopology: e
    });
    var n = (e = e).modelTopology;
    null != n.model_config && (n = n.model_config);
    var r = deserialize(convertPythonicToTs(n), t);

    if (null != e.weightsManifest) {
      var _t789 = yield loadWeights(e.weightsManifest, e.pathPrefix, r.weights.map(e => e.originalName)),
          _n459 = {};

      for (var _e1171 of r.weights) {
        _n459[_e1171.originalName] = _t789[_e1171.originalName];
      }

      r.loadWeights(_n459), dispose(_t789);
    }

    return r;
  });
  return _modelFromJSON.apply(this, arguments);
}

function loadLayersModelInternal(_x117, _x118) {
  return _loadLayersModelInternal.apply(this, arguments);
}

function _loadLayersModelInternal() {
  _loadLayersModelInternal = _asyncToGenerator(function* (e, t) {
    if (null == t && (t = {}), "string" == typeof e) {
      var n = getLoadHandlers(e, t);
      if (0 === n.length) n.push(browserHTTPRequest(e, t));else if (n.length > 1) throw new ValueError("Found more than one (".concat(n.length, ") load handlers for URL '").concat(e, "'"));
      e = n[0];
    }

    return loadLayersModelFromIOHandler(e, void 0, t);
  });
  return _loadLayersModelInternal.apply(this, arguments);
}

function loadLayersModelFromIOHandler(_x119, _x120, _x121) {
  return _loadLayersModelFromIOHandler.apply(this, arguments);
}

function _loadLayersModelFromIOHandler() {
  _loadLayersModelFromIOHandler = _asyncToGenerator(function* (e, t, n) {
    if (null == n && (n = {}), null == e.load) throw new ValueError("Cannot proceed with model loading because the IOHandler provided does not have the `load` method implemented.");
    var r = yield e.load();
    var a = r.modelTopology;
    null != a.model_config && (a = a.model_config);
    var s = null == n.strict || n.strict,
        o = null != r.weightData && null != r.weightSpecs && s,
        i = deserialize(convertPythonicToTs(a), t, o),
        l = r.trainingConfig;

    if (null != l && i.loadTrainingConfig(l), null != r.userDefinedMetadata && i.setUserDefinedMetadata(r.userDefinedMetadata), null != r.weightData) {
      if (null == r.weightSpecs) throw new ValueError("LayersModel artifacts contains weight data, but not weight specs. Therefore loading of weights cannot proceed.");
      var {
        modelWeights: _e1172,
        optimizerWeights: _t790
      } = decodeModelAndOptimizerWeights(r.weightData, r.weightSpecs);
      i.loadWeights(_e1172, s), null != i.optimizer && _t790.length > 0 && (yield i.optimizer.setWeights(_t790)), dispose(_e1172), dispose(_t790.map(e => e.tensor));
    }

    return i;
  });
  return _loadLayersModelFromIOHandler.apply(this, arguments);
}

function decodeModelAndOptimizerWeights(e, t) {
  var n = decodeWeights(e, t),
      r = {},
      a = [];
  return t.forEach(e => {
    "optimizer" === e.group ? a.push({
      name: e.name,
      tensor: n[e.name]
    }) : r[e.name] = n[e.name];
  }), {
    modelWeights: r,
    optimizerWeights: a
  };
}

Functional.className = "Functional", registerClass(Functional);

class Sequential extends LayersModel {
  constructor(e) {
    if (super({
      inputs: [],
      outputs: []
    }), e = e || {}, this.trainable = !0, this.built = !1, this.name = null != e.name ? e.name : getUid("sequential_"), null != e.layers) for (var t of e.layers) {
      this.add(t);
    }
  }

  checkShape(e) {
    if (e.inboundNodes[0].outputTensors[0].shape.some(e => e < 0)) throw new ValueError("Negative dimension size caused by adding layer ".concat(e.name, " with input shape [").concat(e.inboundNodes[0].inputTensors[0].shape, "]"));
  }

  add(e) {
    var t = e instanceof Sequential || e instanceof LayersModel;
    var n;

    if (t) {
      if (n = e, 1 !== n.outputs.length) throw new ValueError("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");
      if (1 !== n.inputs.length) throw new ValueError("All layers in a Sequential model should have a single input tensor. For multi-input layers, use the functional API.");
    }

    if (0 === this.outputs.length) {
      if (0 === e.inboundNodes.length) {
        if (null == e.batchInputShape) throw new ValueError("The first layer in a Sequential model must get an `inputShape` or `batchInputShape` argument.");

        var _t511 = Input({
          batchShape: e.batchInputShape,
          dtype: e.dtype,
          name: e.name + "_input"
        });

        e.apply(_t511);
      }

      if (t) this.outputs = n.outputs, this.inputs = n.inputs;else {
        if (1 !== e.inboundNodes.length) throw new ValueError("A layer added to a Sequential model must not already be connected somewhere else. LayersModel received layer ".concat(e.name, " which has ").concat(e.inboundNodes.length, " pre-existing inbound connections."));
        if (1 !== e.inboundNodes[0].outputTensors.length) throw new ValueError("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");
        this.checkShape(e), this.outputs = [e.inboundNodes[0].outputTensors[0]], this.inputs = getSourceInputs(this.outputs[0]);
      }
      this.inboundNodes = [], new Node({
        outboundLayer: this,
        inboundLayers: [],
        nodeIndices: [],
        tensorIndices: [],
        inputTensors: this.inputs,
        outputTensors: this.outputs,
        inputMasks: pyListRepeat(null, this.inputs.length),
        outputMasks: [null],
        inputShapes: this.inputs.map(e => e.shape),
        outputShapes: this.outputs[0].shape
      });
    } else {
      var _t512 = e.apply(this.outputs[0]);

      if (Array.isArray(_t512)) throw new TypeError("All layers in a Sequential model should have a single output tensor. For multi-output layers, use the functional API.");
      this.checkShape(e), this.outputs = [_t512], this.inboundNodes[0].outputTensors = this.outputs, this.inboundNodes[0].outputShapes = [this.outputs[0].shape];
    }

    this.layers.push(e), this.built = !1;
  }

  pop() {
    if (0 === this.layers.length) throw new TypeError("There are no layers in the model.");
    if (this.layers.pop(), 0 === this.layers.length) this.outputs = [], this.inboundNodes = [], this.outboundNodes = [];else {
      var _e730 = this.layers.length - 1;

      this.layers[_e730].outboundNodes = [], this.outputs = [this.layers[_e730].output], this.inboundNodes[0].outputTensors = this.outputs, this.inboundNodes[0].outputShapes = [this.outputs[0].shape];
    }
  }

  call(e, t) {
    return null == this.model && this.build(), this.model.call(e, t);
  }

  build(e) {
    if (getExactlyOneShape(e), 0 === this.inputs.length || 0 === this.outputs.length) throw new TypeError("Sequential model cannot be built: model is empty. Add some layers first.");
    this.model = new LayersModel({
      inputs: this.inputs,
      outputs: this.outputs[0],
      name: this.name + "_model"
    }), this.model.trainable = this.trainable, this.supportsMasking = this.model.supportsMasking, this.inputLayers = this.model.inputLayers, this.inputLayersNodeIndices = this.model.inputLayersNodeIndices, this.inputLayersTensorIndices = this.model.inputLayersTensorIndices, this.outputLayers = this.model.outputLayers, this.outputLayersNodeIndices = this.model.outputLayersNodeIndices, this.outputLayersTensorIndices = this.model.outputLayersTensorIndices, this.nodesByDepth = this.model.nodesByDepth, this.containerNodes = this.model.containerNodes, this.outputNames = this.model.outputNames, this.inputNames = this.model.inputNames, this.built = !0;
  }

  countParams() {
    return this.built || this.build(), super.countParams();
  }

  summary(e, t) {
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : console.log;
    this.built || this.build(), super.summary(e, t, n);
  }

  setWeights(e) {
    null == this.model && this.build(), this.model.setWeights(e);
  }

  evaluate(e, t) {
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};
    if (!this.built) throw new RuntimeError("The model needs to be compiled before being used.");
    return this.model.evaluate(e, t, n);
  }

  evaluateDataset(e, t) {
    var _this143 = this;

    return _asyncToGenerator(function* () {
      if (!_this143.built) throw new RuntimeError("The model needs to be compiled before being used.");
      return _this143.model.evaluateDataset(e, t);
    })();
  }

  predict(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};
    return null == this.model && this.build(), this.model.predict(e, t);
  }

  predictOnBatch(e) {
    return null == this.model && this.build(), this.model.predictOnBatch(e);
  }

  compile(e) {
    this.build(), this.model.compile(e), this.optimizer_ = this.model.optimizer, this.isOptimizerOwned = this.model.isOptimizerOwned, this.loss = this.model.loss, this.metrics = this.model.metrics, this.metricsTensors = this.model.metricsTensors, this.metricsNames = this.model.metricsNames;
  }

  get optimizer() {
    return null == this.model ? void 0 : this.model.optimizer;
  }

  set optimizer(e) {
    this.model.optimizer = e;
  }

  fit(e, t) {
    var _arguments6 = arguments,
        _this144 = this;

    return _asyncToGenerator(function* () {
      var n = _arguments6.length > 2 && _arguments6[2] !== undefined ? _arguments6[2] : {};
      if (!_this144.built) throw new RuntimeError("The model needs to be compiled before being used.");
      return _this144.model.fit(e, t, n);
    })();
  }

  fitDataset(e, t) {
    var _this145 = this;

    return _asyncToGenerator(function* () {
      if (!_this145.built) throw new RuntimeError("The model needs to be compiled before being used.");
      return _this145.model.fitDataset(e, t);
    })();
  }

  trainOnBatch(e, t) {
    var _this146 = this;

    return _asyncToGenerator(function* () {
      return _this146.model.trainOnBatch(e, t);
    })();
  }

  static fromConfig(e, t) {
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
    var a,
        s = {};

    if (t instanceof Array) {
      if (null == t[0].className || "Merge" === t[0].className) throw new ValueError("Legacy serialization format not supported yet.");
      a = t;
    } else assert$4(null != t.layers, () => "When the config data for a Sequential model is not an Array, it must be an Object that contains the 'layers' field."), a = t.layers, delete t.layers, s = t;

    var o = new e(s);
    if (!(o instanceof Sequential)) throw new NotImplementedError("Sequential.fromConfig called on non-Sequential input: ".concat(o));

    for (var _e731 of a) {
      var _t513 = deserialize(_e731, void 0, r);

      r && _t513.setFastWeightInitDuringBuild(!0), o.add(_t513);
    }

    return o;
  }

  set stopTraining(e) {
    if (null == this.model) throw new ValueError("Cannot set the stopTraining property of a sequential model before it is compiled.");
    this.model.stopTraining = e;
  }

  get stopTraining() {
    if (null == this.model) throw new ValueError("Cannot get the stopTraining property of a sequential model before it is compiled.");
    return this.model.stopTraining;
  }

  getConfig() {
    var e = [];

    for (var t of this.layers) {
      var n = {};
      n.className = t.getClassName(), n.config = t.getConfig(), e.push(n);
    }

    return {
      name: this.name,
      layers: e
    };
  }

}

function model(e) {
  return new LayersModel(e);
}

function sequential(e) {
  return new Sequential(e);
}

function loadLayersModel(e, t) {
  return null == t && (t = {}), loadLayersModelInternal(e, t);
}

function input(e) {
  return Input(e);
}

function registerCallbackConstructor(e, t) {
  CallbackConstructorRegistry.registerCallbackConstructor(e, t);
}

Sequential.className = "Sequential", registerClass(Sequential);

class Activation$1 extends Serializable {
  getConfig() {
    return {};
  }

}

class Elu extends Activation$1 {
  apply(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 1;
    return elu$3(e, t);
  }

}

Elu.className = "elu", registerClass(Elu);

class Selu extends Activation$1 {
  apply(e) {
    return selu$2(e);
  }

}

Selu.className = "selu", registerClass(Selu);

class Relu extends Activation$1 {
  apply(e) {
    return relu$3(e);
  }

}

Relu.className = "relu", registerClass(Relu);

class Relu6 extends Activation$1 {
  apply(e) {
    return tidy(() => minimum$3(6, relu$3(e)));
  }

}

Relu6.className = "relu6", registerClass(Relu6);

class Linear extends Activation$1 {
  apply(e) {
    return e;
  }

}

Linear.className = "linear", registerClass(Linear);

class Sigmoid extends Activation$1 {
  apply(e) {
    return sigmoid$2(e);
  }

}

Sigmoid.className = "sigmoid", registerClass(Sigmoid);

class HardSigmoid extends Activation$1 {
  apply(e) {
    return hardSigmoid(e);
  }

}

HardSigmoid.className = "hardSigmoid", registerClass(HardSigmoid);

class Softplus extends Activation$1 {
  apply(e) {
    return softplus$2(e);
  }

}

Softplus.className = "softplus", registerClass(Softplus);

class Softsign extends Activation$1 {
  apply(e) {
    return softsign(e);
  }

}

Softsign.className = "softsign", registerClass(Softsign);

class Tanh extends Activation$1 {
  apply(e) {
    return tanh$2(e);
  }

}

Tanh.className = "tanh", registerClass(Tanh);

class Softmax$1 extends Activation$1 {
  apply(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : -1;
    return softmax$3(e, t);
  }

}

Softmax$1.className = "softmax", registerClass(Softmax$1);

class LogSoftmax extends Activation$1 {
  apply(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : -1;
    return logSoftmax(e, t);
  }

}

LogSoftmax.className = "logSoftmax", registerClass(LogSoftmax);

class Swish extends Activation$1 {
  apply(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 1;
    return tidy(() => mul(sigmoid$2(mul(e, t)), e));
  }

}

Swish.className = "swish", registerClass(Swish);

class Mish extends Activation$1 {
  apply(e) {
    return tidy(() => mul(e, tanh$2(softplus$2(e))));
  }

}

function serializeActivation(e) {
  return e.getClassName();
}

function deserializeActivation(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};
  return deserializeKerasObject(e, SerializationMap.getMap().classNameMap, t, "activation");
}

function getActivation(e) {
  if (null == e) return deserializeActivation({
    className: "linear",
    config: {}
  });

  if ("string" == typeof e) {
    var t = {};
    return t.className = e, t.config = {}, deserializeActivation(t);
  }

  return e instanceof Activation$1 ? e : deserializeActivation(e);
}

function assertObjectArgs(e) {
  if (null != e && "object" != typeof e) throw new Error("Argument to L1L2 regularizer's constructor is expected to be an object, but received: ".concat(e));
}

Mish.className = "mish", registerClass(Mish);

class Regularizer extends Serializable {}

class L1L2 extends Regularizer {
  constructor(e) {
    super(), assertObjectArgs(e), this.l1 = null == e || null == e.l1 ? .01 : e.l1, this.l2 = null == e || null == e.l2 ? .01 : e.l2, this.hasL1 = 0 !== this.l1, this.hasL2 = 0 !== this.l2;
  }

  apply(e) {
    return tidy(() => {
      var t = zeros$2([1]);
      return this.hasL1 && (t = add$2(t, sum$2(mul(this.l1, abs$2(e))))), this.hasL2 && (t = add$2(t, sum$2(mul(this.l2, square$1(e))))), reshape$3(t, []);
    });
  }

  getConfig() {
    return {
      l1: this.l1,
      l2: this.l2
    };
  }

  static fromConfig(e, t) {
    return new e({
      l1: t.l1,
      l2: t.l2
    });
  }

}

function l1$1(e) {
  return assertObjectArgs(e), new L1L2({
    l1: null != e ? e.l1 : null,
    l2: 0
  });
}

function l2$1(e) {
  return assertObjectArgs(e), new L1L2({
    l2: null != e ? e.l2 : null,
    l1: 0
  });
}

L1L2.className = "L1L2", registerClass(L1L2);
var REGULARIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP = {
  l1l2: "L1L2"
};

function serializeRegularizer(e) {
  return serializeKerasObject(e);
}

function deserializeRegularizer(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};
  return deserializeKerasObject(e, SerializationMap.getMap().classNameMap, t, "regularizer");
}

function getRegularizer(e) {
  return null == e ? null : "string" == typeof e ? deserializeRegularizer({
    className: e in REGULARIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP ? REGULARIZER_IDENTIFIER_REGISTRY_SYMBOL_MAP[e] : e,
    config: {}
  }) : e instanceof Regularizer ? e : deserializeRegularizer(e);
}

class ReLU extends Layer {
  constructor(e) {
    super(null == e ? {} : e), this.supportsMasking = !0, null != e && (this.maxValue = e.maxValue);
  }

  call(e, t) {
    e = getExactlyOneTensor(e);
    var n = relu$3(e);
    return null != this.maxValue && (n = clipByValue$1(n, 0, this.maxValue)), n;
  }

  computeOutputShape(e) {
    return e;
  }

  getConfig() {
    var e = {
      maxValue: this.maxValue
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

ReLU.className = "ReLU", registerClass(ReLU);

class LeakyReLU extends Layer {
  constructor(e) {
    super(null == e ? {} : e), this.DEFAULT_ALPHA = .3, null == e && (e = {}), this.alpha = null == e.alpha ? this.DEFAULT_ALPHA : e.alpha;
  }

  call(e, t) {
    var n = getExactlyOneTensor(e);
    return leakyRelu$2(n, this.alpha);
  }

  computeOutputShape(e) {
    return e;
  }

  getConfig() {
    var e = {
      alpha: this.alpha
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

LeakyReLU.className = "LeakyReLU", registerClass(LeakyReLU);

class PReLU extends Layer {
  constructor(e) {
    if (super(null == e ? {} : e), this.DEFAULT_ALPHA_INITIALIZER = "zeros", null == e && (e = {}), this.supportsMasking = !0, this.alphaInitializer = getInitializer(e.alphaInitializer || this.DEFAULT_ALPHA_INITIALIZER), this.alphaRegularizer = getRegularizer(e.alphaRegularizer), this.alphaConstraint = getConstraint(e.alphaConstraint), null == e.sharedAxes) this.sharedAxes = null;else if (Array.isArray(e.sharedAxes)) this.sharedAxes = e.sharedAxes;else {
      if ("number" != typeof e.sharedAxes) throw new ValueError("Expected sharedAxes to be a number or an array of numbers, but got ".concat(e.sharedAxes));
      this.sharedAxes = [e.sharedAxes];
    }
  }

  build(e) {
    var t = (e = getExactlyOneShape(e)).slice(1);
    if (null != this.sharedAxes) for (var _e732 of this.sharedAxes) {
      t[_e732 - 1] = 1;
    }
    this.alpha = this.addWeight("alpha", t, "float32", this.alphaInitializer, this.alphaRegularizer, !0, this.alphaConstraint);
    var n = {};
    if (null != this.sharedAxes) for (var _t514 = 1; _t514 < e.length; ++_t514) {
      n[_t514] = e[_t514];
    }
    this.inputSpec = [new InputSpec({
      ndim: e.length,
      axes: n
    })], this.built = !0;
  }

  call(e, t) {
    return e = getExactlyOneTensor(e), prelu$3(e, this.alpha.read());
  }

  getConfig() {
    var e = {
      alphaInitializer: serializeInitializer(this.alphaInitializer),
      alphaRegularizer: serializeRegularizer(this.alphaRegularizer),
      alphaConstraint: serializeConstraint(this.alphaConstraint),
      sharedAxes: this.sharedAxes
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

PReLU.className = "PReLU", registerClass(PReLU);

class ELU$3 extends Layer {
  constructor(e) {
    if (super(null == e ? {} : e), this.DEFAULT_ALPHA = 1, null == e && (e = {}), null != e.alpha && e.alpha !== this.DEFAULT_ALPHA) throw new NotImplementedError("Non-default alpha value (".concat(e.alpha, ") is not supported by the ELU layer yet."));
    this.alpha = null == e.alpha ? this.DEFAULT_ALPHA : e.alpha;
  }

  call(e, t) {
    var n = getExactlyOneTensor(e);
    return elu$4(n);
  }

  computeOutputShape(e) {
    return e;
  }

  getConfig() {
    var e = {
      alpha: this.alpha
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

ELU$3.className = "ELU", registerClass(ELU$3);

class ThresholdedReLU extends Layer {
  constructor(e) {
    super(null == e ? {} : e), this.DEFAULT_THETA = 1, null == e && (e = {}), this.theta = null == e.theta ? this.DEFAULT_THETA : e.theta;
  }

  call(e, t) {
    var n = getExactlyOneTensor(e);
    return mul(n, cast$3(greater$3(n, this.theta), "float32"));
  }

  computeOutputShape(e) {
    return e;
  }

  getConfig() {
    var e = {
      theta: this.theta
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

ThresholdedReLU.className = "ThresholdedReLU", registerClass(ThresholdedReLU);

class Softmax extends Layer {
  constructor(e) {
    super(null == e ? {} : e), this.DEFAULT_AXIS = 1, null == e && (e = {}), this.softmax = new Softmax$1().apply, this.axis = null == e.axis ? this.DEFAULT_AXIS : e.axis;
  }

  call(e, t) {
    var n = getExactlyOneTensor(e);
    return this.softmax(n, this.axis);
  }

  computeOutputShape(e) {
    return e;
  }

  getConfig() {
    var e = {
      axis: this.axis
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

function normalizeArray(e, t, n) {
  if ("number" == typeof e) return pyListRepeat(e, t);
  if (e.length !== t) throw new ValueError("The ".concat(n, " argument must be an integer or tuple of ").concat(t, " integers. Received: ").concat(e.length, " elements."));

  for (var r = 0; r < t; ++r) {
    var a = e[r];
    if (!isInteger(a)) throw new ValueError("The ".concat(n, " argument must be an integer or tuple of ").concat(t, " integers. Received: ").concat(JSON.stringify(e), " including a non-integer number ").concat(a));
  }

  return e;
}

function convOutputLength(e, t, n, r) {
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : 1;
  if (null == e) return e;
  var s;
  return s = "same" === n ? e : e - (t + (t - 1) * (a - 1)) + 1, Math.floor((s + r - 1) / r);
}

function deconvLength(e, t, n, r) {
  if (null == e) return null;
  if ("valid" === r) e = e * t + max$2([n - t, 0]);else {
    if ("same" !== r) throw new ValueError("Unsupport padding mode: ".concat(r, "."));
    e *= t;
  }
  return e;
}

function preprocessConv2DInput(e, t) {
  return tidy(() => (checkDataFormat(t), "channelsFirst" === t ? transpose$2(e, [0, 2, 3, 1]) : e));
}

function preprocessConv3DInput(e, t) {
  return tidy(() => (checkDataFormat(t), "channelsFirst" === t ? transpose$2(e, [0, 2, 3, 4, 1]) : e));
}

function conv1dWithBias(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 1;
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : "valid";
  var s = arguments.length > 5 ? arguments[5] : undefined;
  var o = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : 1;
  return tidy(() => {
    if (null == s && (s = imageDataFormat()), checkDataFormat(s), 3 !== e.shape.length) throw new ValueError("The input of a conv1dWithBias operation should be 3, but is ".concat(e.shape.length, " instead."));
    if (3 !== t.shape.length) throw new ValueError("The kernel for a conv1dWithBias operation should be 3, but is ".concat(t.shape.length, " instead"));
    if (null != n && 1 !== n.shape.length) throw new ValueError("The bias for a conv1dWithBias operation should be 1, but is ".concat(t.shape.length, " instead"));
    if ("channelsFirst" === s && (e = transpose$2(e, [0, 2, 1])), "causal" === a) throw new NotImplementedError("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");
    var i = conv1d$1(e, t, r, "same" === a ? "same" : "valid", "NWC", o);
    return null != n && (i = biasAdd(i, n)), i;
  });
}

function conv2dWithBiasActivation(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : [1, 1];
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : "valid";
  var s = arguments.length > 5 ? arguments[5] : undefined;
  var o = arguments.length > 6 ? arguments[6] : undefined;
  var i = arguments.length > 7 && arguments[7] !== undefined ? arguments[7] : null;
  return tidy(() => {
    if (null == s && (s = imageDataFormat()), checkDataFormat(s), 3 !== e.rank && 4 !== e.rank) throw new ValueError("conv2dWithBiasActivation expects input to be of rank 3 or 4, but received ".concat(e.rank, "."));
    if (3 !== t.rank && 4 !== t.rank) throw new ValueError("conv2dWithBiasActivation expects kernel to be of rank 3 or 4, but received ".concat(e.rank, "."));
    var l = preprocessConv2DInput(e, s);
    if ("causal" === a) throw new NotImplementedError("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");
    return l = conv2d$2({
      x: l,
      filter: t,
      strides: r,
      pad: "same" === a ? "same" : "valid",
      dilations: o,
      dataFormat: "NHWC",
      bias: n,
      activation: i
    }), "channelsFirst" === s && (l = transpose$2(l, [0, 3, 1, 2])), l;
  });
}

function conv3dWithBias(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : [1, 1, 1];
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : "valid";
  var s = arguments.length > 5 ? arguments[5] : undefined;
  var o = arguments.length > 6 ? arguments[6] : undefined;
  return tidy(() => {
    if (null == s && (s = imageDataFormat()), checkDataFormat(s), 4 !== e.rank && 5 !== e.rank) throw new ValueError("conv3dWithBias expects input to be of rank 4 or 5, but received ".concat(e.rank, "."));
    if (4 !== t.rank && 5 !== t.rank) throw new ValueError("conv3dWithBias expects kernel to be of rank 4 or 5, but received ".concat(e.rank, "."));
    var i = preprocessConv3DInput(e, s);
    if ("causal" === a) throw new NotImplementedError("The support for CAUSAL padding mode in conv3dWithBias is not implemented yet.");
    return i = conv3d$1(i, t, r, "same" === a ? "same" : "valid", "NDHWC", o), null != n && (i = biasAdd(i, n)), "channelsFirst" === s && (i = transpose$2(i, [0, 4, 1, 2, 3])), i;
  });
}

Softmax.className = "Softmax", registerClass(Softmax);

class BaseConv extends Layer {
  constructor(e, t) {
    if (super(t), this.bias = null, this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal", this.DEFAULT_BIAS_INITIALIZER = "zeros", BaseConv.verifyArgs(t), this.rank = e, assertPositiveInteger(this.rank, "rank"), 1 !== this.rank && 2 !== this.rank && 3 !== this.rank) throw new NotImplementedError("Convolution layer for rank other than 1, 2, or 3 (".concat(this.rank, ") is not implemented yet."));
    if (this.kernelSize = normalizeArray(t.kernelSize, e, "kernelSize"), this.strides = normalizeArray(null == t.strides ? 1 : t.strides, e, "strides"), this.padding = null == t.padding ? "valid" : t.padding, checkPaddingMode(this.padding), this.dataFormat = null == t.dataFormat ? "channelsLast" : t.dataFormat, checkDataFormat(this.dataFormat), this.activation = getActivation(t.activation), this.useBias = null == t.useBias || t.useBias, this.biasInitializer = getInitializer(t.biasInitializer || this.DEFAULT_BIAS_INITIALIZER), this.biasConstraint = getConstraint(t.biasConstraint), this.biasRegularizer = getRegularizer(t.biasRegularizer), this.activityRegularizer = getRegularizer(t.activityRegularizer), this.dilationRate = normalizeArray(null == t.dilationRate ? 1 : t.dilationRate, e, "dilationRate"), 1 === this.rank && Array.isArray(this.dilationRate) && 1 !== this.dilationRate.length) throw new ValueError("dilationRate must be a number or an array of a single number for 1D convolution, but received ".concat(JSON.stringify(this.dilationRate)));

    if (2 === this.rank) {
      if ("number" == typeof this.dilationRate) this.dilationRate = [this.dilationRate, this.dilationRate];else if (2 !== this.dilationRate.length) throw new ValueError("dilationRate must be a number or array of two numbers for 2D convolution, but received ".concat(JSON.stringify(this.dilationRate)));
    } else if (3 === this.rank) if ("number" == typeof this.dilationRate) this.dilationRate = [this.dilationRate, this.dilationRate, this.dilationRate];else if (3 !== this.dilationRate.length) throw new ValueError("dilationRate must be a number or array of three numbers for 3D convolution, but received ".concat(JSON.stringify(this.dilationRate)));
  }

  static verifyArgs(e) {
    if (assert$3("kernelSize" in e, "required key 'kernelSize' not in config"), "number" != typeof e.kernelSize && !checkArrayTypeAndLength(e.kernelSize, "number", 1, 3)) throw new ValueError("BaseConv expects config.kernelSize to be number or number[] with length 1, 2, or 3, but received ".concat(JSON.stringify(e.kernelSize), "."));
  }

  getConfig() {
    var e = {
      kernelSize: this.kernelSize,
      strides: this.strides,
      padding: this.padding,
      dataFormat: this.dataFormat,
      dilationRate: this.dilationRate,
      activation: serializeActivation(this.activation),
      useBias: this.useBias,
      biasInitializer: serializeInitializer(this.biasInitializer),
      biasRegularizer: serializeRegularizer(this.biasRegularizer),
      activityRegularizer: serializeRegularizer(this.activityRegularizer),
      biasConstraint: serializeConstraint(this.biasConstraint)
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

class Conv extends BaseConv {
  constructor(e, t) {
    super(e, t), this.kernel = null, Conv.verifyArgs(t), this.filters = t.filters, assertPositiveInteger(this.filters, "filters"), this.kernelInitializer = getInitializer(t.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER), this.kernelConstraint = getConstraint(t.kernelConstraint), this.kernelRegularizer = getRegularizer(t.kernelRegularizer);
  }

  build(e) {
    e = getExactlyOneShape(e);
    var t = "channelsFirst" === this.dataFormat ? 1 : e.length - 1;
    if (null == e[t]) throw new ValueError("The channel dimension of the input should be defined. Found ".concat(e[t]));
    var n = e[t],
        r = this.kernelSize.concat([n, this.filters]);
    this.kernel = this.addWeight("kernel", r, null, this.kernelInitializer, this.kernelRegularizer, !0, this.kernelConstraint), this.useBias && (this.bias = this.addWeight("bias", [this.filters], null, this.biasInitializer, this.biasRegularizer, !0, this.biasConstraint)), this.inputSpec = [{
      ndim: this.rank + 2,
      axes: {
        [t]: n
      }
    }], this.built = !0;
  }

  call(e, t) {
    return tidy(() => {
      var t;
      e = getExactlyOneTensor(e);
      var n = null == this.bias ? null : this.bias.read(),
          r = mapActivationToFusedKernel(this.activation.getClassName());
      if (null != r && 2 === this.rank) t = conv2dWithBiasActivation(e, this.kernel.read(), n, this.strides, this.padding, this.dataFormat, this.dilationRate, r);else {
        if (1 === this.rank) t = conv1dWithBias(e, this.kernel.read(), n, this.strides[0], this.padding, this.dataFormat, this.dilationRate[0]);else if (2 === this.rank) t = conv2dWithBiasActivation(e, this.kernel.read(), n, this.strides, this.padding, this.dataFormat, this.dilationRate);else {
          if (3 !== this.rank) throw new NotImplementedError("convolutions greater than 3D are not implemented yet.");
          t = conv3dWithBias(e, this.kernel.read(), n, this.strides, this.padding, this.dataFormat, this.dilationRate);
        }
        null != this.activation && (t = this.activation.apply(t));
      }
      return t;
    });
  }

  computeOutputShape(e) {
    e = getExactlyOneShape(e);
    var t = [],
        n = "channelsLast" === this.dataFormat ? e.slice(1, e.length - 1) : e.slice(2);

    for (var _e733 = 0; _e733 < n.length; ++_e733) {
      var _r233 = convOutputLength(n[_e733], this.kernelSize[_e733], this.padding, this.strides[_e733], "number" == typeof this.dilationRate ? this.dilationRate : this.dilationRate[_e733]);

      t.push(_r233);
    }

    var r = [e[0]];
    return "channelsLast" === this.dataFormat ? (r = r.concat(t), r.push(this.filters)) : (r.push(this.filters), r = r.concat(t)), r;
  }

  getConfig() {
    var e = {
      filters: this.filters,
      kernelInitializer: serializeInitializer(this.kernelInitializer),
      kernelRegularizer: serializeRegularizer(this.kernelRegularizer),
      kernelConstraint: serializeConstraint(this.kernelConstraint)
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

  static verifyArgs(e) {
    if (!("filters" in e) || "number" != typeof e.filters || e.filters < 1) throw new ValueError("Convolution layer expected config.filters to be a 'number' > 0 but got ".concat(JSON.stringify(e.filters)));
  }

}

class Conv2D extends Conv {
  constructor(e) {
    super(2, e), Conv2D.verifyArgs(e);
  }

  getConfig() {
    var e = super.getConfig();
    return delete e.rank, e;
  }

  static verifyArgs(e) {
    if ("number" != typeof e.kernelSize && !checkArrayTypeAndLength(e.kernelSize, "number", 1, 2)) throw new ValueError("Conv2D expects config.kernelSize to be number or number[] with length 1 or 2, but received ".concat(JSON.stringify(e.kernelSize), "."));
  }

}

Conv2D.className = "Conv2D", registerClass(Conv2D);

class Conv3D extends Conv {
  constructor(e) {
    super(3, e), Conv3D.verifyArgs(e);
  }

  getConfig() {
    var e = super.getConfig();
    return delete e.rank, e;
  }

  static verifyArgs(e) {
    if ("number" != typeof e.kernelSize && (!Array.isArray(e.kernelSize) || 1 !== e.kernelSize.length && 3 !== e.kernelSize.length)) throw new ValueError("Conv3D expects config.kernelSize to be number or [number, number, number], but received ".concat(JSON.stringify(e.kernelSize), "."));
  }

}

Conv3D.className = "Conv3D", registerClass(Conv3D);

class Conv2DTranspose extends Conv2D {
  constructor(e) {
    if (super(e), this.inputSpec = [new InputSpec({
      ndim: 4
    })], "same" !== this.padding && "valid" !== this.padding) throw new ValueError("Conv2DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode ".concat(this.padding));
  }

  build(e) {
    if (4 !== (e = getExactlyOneShape(e)).length) throw new ValueError("Input should have rank 4; Received input shape: " + JSON.stringify(e));
    var t = "channelsFirst" === this.dataFormat ? 1 : e.length - 1;
    if (null == e[t]) throw new ValueError("The channel dimension of the inputs should be defined. Found `None`.");
    var n = e[t],
        r = this.kernelSize.concat([this.filters, n]);
    this.kernel = this.addWeight("kernel", r, "float32", this.kernelInitializer, this.kernelRegularizer, !0, this.kernelConstraint), this.useBias && (this.bias = this.addWeight("bias", [this.filters], "float32", this.biasInitializer, this.biasRegularizer, !0, this.biasConstraint)), this.inputSpec = [new InputSpec({
      ndim: 4,
      axes: {
        [t]: n
      }
    })], this.built = !0;
  }

  call(e, t) {
    return tidy(() => {
      var t = getExactlyOneTensor(e);
      if (4 !== t.shape.length) throw new ValueError("Conv2DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-".concat(t.shape.length));
      var n = t.shape;
      var r, a;
      "channelsFirst" === this.dataFormat ? (r = 2, a = 3) : (r = 1, a = 2);
      var s = n[a],
          o = this.kernelSize[1],
          i = this.strides[1],
          l = [n[0], deconvLength(n[r], this.strides[0], this.kernelSize[0], this.padding), deconvLength(s, i, o, this.padding), this.filters];
      "channelsLast" !== this.dataFormat && (t = transpose$2(t, [0, 2, 3, 1]));
      var u = conv2dTranspose$1(t, this.kernel.read(), l, this.strides, this.padding);
      return "channelsLast" !== this.dataFormat && (u = transpose$2(u, [0, 3, 1, 2])), null != this.bias && (u = biasAdd(u, this.bias.read(), this.dataFormat)), null != this.activation && (u = this.activation.apply(u)), u;
    });
  }

  computeOutputShape(e) {
    var t = (e = getExactlyOneShape(e)).slice();
    var n, r, a;
    "channelsFirst" === this.dataFormat ? (n = 1, r = 2, a = 3) : (n = 3, r = 1, a = 2);
    var s = this.kernelSize[0],
        o = this.kernelSize[1],
        i = this.strides[0],
        l = this.strides[1];
    return t[n] = this.filters, t[r] = deconvLength(t[r], i, s, this.padding), t[a] = deconvLength(t[a], l, o, this.padding), t;
  }

  getConfig() {
    var e = super.getConfig();
    return delete e.dilationRate, e;
  }

}

Conv2DTranspose.className = "Conv2DTranspose", registerClass(Conv2DTranspose);

class Conv3DTranspose extends Conv3D {
  constructor(e) {
    if (super(e), this.inputSpec = [new InputSpec({
      ndim: 5
    })], "same" !== this.padding && "valid" !== this.padding) throw new ValueError("Conv3DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode ".concat(this.padding));
  }

  build(e) {
    if (5 !== (e = getExactlyOneShape(e)).length) throw new ValueError("Input should have rank 5; Received input shape: " + JSON.stringify(e));
    var t = "channelsFirst" === this.dataFormat ? 1 : e.length - 1;
    if (null == e[t]) throw new ValueError("The channel dimension of the inputs should be defined. Found `None`.");
    var n = e[t],
        r = this.kernelSize.concat([this.filters, n]);
    this.kernel = this.addWeight("kernel", r, "float32", this.kernelInitializer, this.kernelRegularizer, !0, this.kernelConstraint), this.useBias && (this.bias = this.addWeight("bias", [this.filters], "float32", this.biasInitializer, this.biasRegularizer, !0, this.biasConstraint)), this.inputSpec = [new InputSpec({
      ndim: 5,
      axes: {
        [t]: n
      }
    })], this.built = !0;
  }

  call(e, t) {
    return tidy(() => {
      var t = getExactlyOneTensor(e);
      if (5 !== t.shape.length) throw new ValueError("Conv3DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-".concat(t.shape.length));
      var n = t.shape;
      var r, a, s;
      "channelsFirst" === this.dataFormat ? (s = 2, r = 3, a = 4) : (s = 1, r = 2, a = 3);
      var o = n[r],
          i = n[a],
          l = this.kernelSize[1],
          u = this.kernelSize[2],
          c = this.strides[1],
          p = this.strides[2],
          d = [n[0], deconvLength(n[s], this.strides[0], this.kernelSize[0], this.padding), deconvLength(o, c, l, this.padding), deconvLength(i, p, u, this.padding), this.filters];
      "channelsLast" !== this.dataFormat && (t = transpose$2(t, [0, 2, 3, 4, 1]));
      var h = conv3dTranspose$1(t, this.kernel.read(), d, this.strides, this.padding);
      return "channelsLast" !== this.dataFormat && (h = transpose$2(h, [0, 4, 1, 2, 3])), null !== this.bias && (h = biasAdd(h, this.bias.read(), this.dataFormat)), null !== this.activation && (h = this.activation.apply(h)), h;
    });
  }

  computeOutputShape(e) {
    var t = (e = getExactlyOneShape(e)).slice();
    var n, r, a, s;
    "channelsFirst" === this.dataFormat ? (n = 1, r = 2, a = 3, s = 4) : (n = 4, r = 1, a = 2, s = 3);
    var o = this.kernelSize[0],
        i = this.kernelSize[1],
        l = this.kernelSize[2],
        u = this.strides[0],
        c = this.strides[1],
        p = this.strides[2];
    return t[n] = this.filters, t[r] = deconvLength(t[r], u, o, this.padding), t[a] = deconvLength(t[a], c, i, this.padding), t[s] = deconvLength(t[s], p, l, this.padding), t;
  }

  getConfig() {
    var e = super.getConfig();
    return delete e.dilationRate, e;
  }

}

Conv3DTranspose.className = "Conv3DTranspose", registerClass(Conv3DTranspose);

class SeparableConv extends Conv {
  constructor(e, t) {
    if (super(e, t), this.DEFAULT_DEPTHWISE_INITIALIZER = "glorotUniform", this.DEFAULT_POINTWISE_INITIALIZER = "glorotUniform", this.depthwiseKernel = null, this.pointwiseKernel = null, null == t.filters) throw new ValueError("The `filters` configuration field is required by SeparableConv, but is unspecified.");
    if (null != t.kernelInitializer || null != t.kernelRegularizer || null != t.kernelConstraint) throw new ValueError("Fields kernelInitializer, kernelRegularizer and kernelConstraint are invalid for SeparableConv2D. Use depthwiseInitializer, depthwiseRegularizer, depthwiseConstraint, pointwiseInitializer, pointwiseRegularizer and pointwiseConstraint instead.");
    if (null != t.padding && "same" !== t.padding && "valid" !== t.padding) throw new ValueError("SeparableConv".concat(this.rank, "D supports only padding modes: 'same' and 'valid', but received ").concat(JSON.stringify(t.padding)));
    this.depthMultiplier = null == t.depthMultiplier ? 1 : t.depthMultiplier, this.depthwiseInitializer = getInitializer(t.depthwiseInitializer || this.DEFAULT_DEPTHWISE_INITIALIZER), this.depthwiseRegularizer = getRegularizer(t.depthwiseRegularizer), this.depthwiseConstraint = getConstraint(t.depthwiseConstraint), this.pointwiseInitializer = getInitializer(t.depthwiseInitializer || this.DEFAULT_POINTWISE_INITIALIZER), this.pointwiseRegularizer = getRegularizer(t.pointwiseRegularizer), this.pointwiseConstraint = getConstraint(t.pointwiseConstraint);
  }

  build(e) {
    if ((e = getExactlyOneShape(e)).length < this.rank + 2) throw new ValueError("Inputs to SeparableConv".concat(this.rank, "D should have rank ").concat(this.rank + 2, ", but received input shape: ").concat(JSON.stringify(e)));
    var t = "channelsFirst" === this.dataFormat ? 1 : e.length - 1;
    if (null == e[t] || e[t] < 0) throw new ValueError("The channel dimension of the inputs should be defined, but found ".concat(JSON.stringify(e[t])));
    var n = e[t],
        r = this.kernelSize.concat([n, this.depthMultiplier]),
        a = [];

    for (var _e734 = 0; _e734 < this.rank; ++_e734) {
      a.push(1);
    }

    a.push(n * this.depthMultiplier, this.filters);
    var s = !0;
    this.depthwiseKernel = this.addWeight("depthwise_kernel", r, "float32", this.depthwiseInitializer, this.depthwiseRegularizer, s, this.depthwiseConstraint), this.pointwiseKernel = this.addWeight("pointwise_kernel", a, "float32", this.pointwiseInitializer, this.pointwiseRegularizer, s, this.pointwiseConstraint), this.bias = this.useBias ? this.addWeight("bias", [this.filters], "float32", this.biasInitializer, this.biasRegularizer, s, this.biasConstraint) : null, this.inputSpec = [new InputSpec({
      ndim: this.rank + 2,
      axes: {
        [t]: n
      }
    })], this.built = !0;
  }

  call(e, t) {
    return tidy(() => {
      var t;
      if (e = getExactlyOneTensor(e), 1 === this.rank) throw new NotImplementedError("1D separable convolution is not implemented yet.");
      return 2 === this.rank && ("channelsFirst" === this.dataFormat && (e = transpose$2(e, [0, 2, 3, 1])), t = separableConv2d$1(e, this.depthwiseKernel.read(), this.pointwiseKernel.read(), this.strides, this.padding, this.dilationRate, "NHWC")), this.useBias && (t = biasAdd(t, this.bias.read(), this.dataFormat)), null != this.activation && (t = this.activation.apply(t)), "channelsFirst" === this.dataFormat && (t = transpose$2(t, [0, 3, 1, 2])), t;
    });
  }

  getConfig() {
    var e = super.getConfig();
    return delete e.rank, delete e.kernelInitializer, delete e.kernelRegularizer, delete e.kernelConstraint, e.depthwiseInitializer = serializeInitializer(this.depthwiseInitializer), e.pointwiseInitializer = serializeInitializer(this.pointwiseInitializer), e.depthwiseRegularizer = serializeRegularizer(this.depthwiseRegularizer), e.pointwiseRegularizer = serializeRegularizer(this.pointwiseRegularizer), e.depthwiseConstraint = serializeConstraint(this.depthwiseConstraint), e.pointwiseConstraint = serializeConstraint(this.pointwiseConstraint), e;
  }

}

SeparableConv.className = "SeparableConv";

class SeparableConv2D extends SeparableConv {
  constructor(e) {
    super(2, e);
  }

}

SeparableConv2D.className = "SeparableConv2D", registerClass(SeparableConv2D);

class Conv1D extends Conv {
  constructor(e) {
    super(1, e), Conv1D.verifyArgs(e), this.inputSpec = [{
      ndim: 3
    }];
  }

  getConfig() {
    var e = super.getConfig();
    return delete e.rank, delete e.dataFormat, e;
  }

  static verifyArgs(e) {
    if ("number" != typeof e.kernelSize && !checkArrayTypeAndLength(e.kernelSize, "number", 1, 1)) throw new ValueError("Conv1D expects config.kernelSize to be number or number[] with length 1, but received ".concat(JSON.stringify(e.kernelSize), "."));
  }

}

Conv1D.className = "Conv1D", registerClass(Conv1D);

class Cropping2D extends Layer {
  constructor(e) {
    super(e), this.cropping = "number" == typeof e.cropping ? [[e.cropping, e.cropping], [e.cropping, e.cropping]] : "number" == typeof e.cropping[0] ? [[e.cropping[0], e.cropping[0]], [e.cropping[1], e.cropping[1]]] : e.cropping, this.dataFormat = void 0 === e.dataFormat ? "channelsLast" : e.dataFormat, this.inputSpec = [{
      ndim: 4
    }];
  }

  computeOutputShape(e) {
    return "channelsFirst" === this.dataFormat ? [e[0], e[1], e[2] - this.cropping[0][0] - this.cropping[0][1], e[3] - this.cropping[1][0] - this.cropping[1][1]] : [e[0], e[1] - this.cropping[0][0] - this.cropping[0][1], e[2] - this.cropping[1][0] - this.cropping[1][1], e[3]];
  }

  call(e, t) {
    return tidy(() => {
      if (e = getExactlyOneTensor(e), "channelsLast" === this.dataFormat) {
        var _t515 = sliceAlongAxis(e, this.cropping[0][0], e.shape[1] - this.cropping[0][0] - this.cropping[0][1], 2);

        return sliceAlongAxis(_t515, this.cropping[1][0], e.shape[2] - this.cropping[1][1] - this.cropping[1][0], 3);
      }

      {
        var _t516 = sliceAlongAxis(e, this.cropping[0][0], e.shape[2] - this.cropping[0][0] - this.cropping[0][1], 3);

        return sliceAlongAxis(_t516, this.cropping[1][0], e.shape[3] - this.cropping[1][1] - this.cropping[1][0], 4);
      }
    });
  }

  getConfig() {
    var e = {
      cropping: this.cropping,
      dataFormat: this.dataFormat
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

Cropping2D.className = "Cropping2D", registerClass(Cropping2D);

class UpSampling2D extends Layer {
  constructor(e) {
    super(e), this.DEFAULT_SIZE = [2, 2], this.inputSpec = [{
      ndim: 4
    }], this.size = null == e.size ? this.DEFAULT_SIZE : e.size, this.dataFormat = null == e.dataFormat ? "channelsLast" : e.dataFormat, checkDataFormat(this.dataFormat), this.interpolation = null == e.interpolation ? "nearest" : e.interpolation, checkInterpolationFormat(this.interpolation);
  }

  computeOutputShape(e) {
    return "channelsFirst" === this.dataFormat ? [e[0], e[1], null == e[2] ? null : this.size[0] * e[2], null == e[3] ? null : this.size[1] * e[3]] : [e[0], null == e[1] ? null : this.size[0] * e[1], null == e[2] ? null : this.size[1] * e[2], e[3]];
  }

  call(e, t) {
    return tidy(() => {
      var t = getExactlyOneTensor(e);
      var n = t.shape;

      if ("channelsFirst" === this.dataFormat) {
        t = transpose$2(t, [0, 2, 3, 1]);

        var _e735 = this.size[0] * n[2],
            r = this.size[1] * n[3],
            a = "nearest" === this.interpolation ? image$1.resizeNearestNeighbor(t, [_e735, r]) : image$1.resizeBilinear(t, [_e735, r]);

        return transpose$2(a, [0, 3, 1, 2]);
      }

      {
        var _e736 = this.size[0] * n[1],
            _r234 = this.size[1] * n[2];

        return "nearest" === this.interpolation ? image$1.resizeNearestNeighbor(t, [_e736, _r234]) : image$1.resizeBilinear(t, [_e736, _r234]);
      }
    });
  }

  getConfig() {
    var e = {
      size: this.size,
      dataFormat: this.dataFormat
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

function depthwiseConv2d$1(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : [1, 1];
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : "valid";
  var a = arguments.length > 4 ? arguments[4] : undefined;
  var s = arguments.length > 5 ? arguments[5] : undefined;
  return tidy(() => {
    null == a && (a = imageDataFormat()), checkDataFormat(a);
    var o = preprocessConv2DInput(e, a);
    if (4 !== e.rank) throw new ValueError("Input for depthwiseConv2d is required to be 4-D, but is instead ".concat(e.rank, "-D"));
    if (4 !== t.rank) throw new ValueError("depthwiseKernel is required to be 4-D, but is instead ".concat(t.rank, "-D"));
    return o = depthwiseConv2d$3(o, t, n, "same" === r ? "same" : "valid", "NHWC", s), "channelsFirst" === a && (o = transpose$2(o, [0, 3, 1, 2])), o;
  });
}

UpSampling2D.className = "UpSampling2D", registerClass(UpSampling2D);

class DepthwiseConv2D extends BaseConv {
  constructor(e) {
    super(2, e), this.depthwiseKernel = null, this.depthMultiplier = null == e.depthMultiplier ? 1 : e.depthMultiplier, this.depthwiseInitializer = getInitializer(e.depthwiseInitializer || this.DEFAULT_KERNEL_INITIALIZER), this.depthwiseConstraint = getConstraint(e.depthwiseConstraint), this.depthwiseRegularizer = getRegularizer(e.depthwiseRegularizer);
  }

  build(e) {
    if ((e = getExactlyOneShape(e)).length < 4) throw new ValueError("Inputs to DepthwiseConv2D should have rank 4. Received input shape: ".concat(JSON.stringify(e), "."));
    var t = "channelsFirst" === this.dataFormat ? 1 : 3;
    if (null == e[t] || e[t] < 0) throw new ValueError("The channel dimension of the inputs to DepthwiseConv2D should be defined, but is not (".concat(e[t], ")."));
    var n = e[t];
    this.depthwiseKernel = this.addWeight("depthwise_kernel", [this.kernelSize[0], this.kernelSize[1], n, this.depthMultiplier], null, this.depthwiseInitializer, this.depthwiseRegularizer, !0, this.depthwiseConstraint), this.bias = this.useBias ? this.addWeight("bias", [n * this.depthMultiplier], null, this.biasInitializer, this.biasRegularizer, !0, this.biasConstraint) : null, this.built = !0;
  }

  call(e, t) {
    return tidy(() => {
      var t = depthwiseConv2d$1(e = getExactlyOneTensor(e), this.depthwiseKernel.read(), this.strides, this.padding, this.dataFormat, null);
      return this.useBias && (t = biasAdd(t, this.bias.read(), this.dataFormat)), null != this.activation && (t = this.activation.apply(t)), t;
    });
  }

  computeOutputShape(e) {
    e = getExactlyOneShape(e);
    var t = "channelsFirst" === this.dataFormat ? e[3] : e[2],
        n = "channelsFirst" === this.dataFormat ? e[1] * this.depthMultiplier : e[3] * this.depthMultiplier,
        r = convOutputLength("channelsFirst" === this.dataFormat ? e[2] : e[1], this.kernelSize[0], this.padding, this.strides[0]),
        a = convOutputLength(t, this.kernelSize[1], this.padding, this.strides[1]);
    return "channelsFirst" === this.dataFormat ? [e[0], n, r, a] : [e[0], r, a, n];
  }

  getConfig() {
    var e = super.getConfig();
    return e.depthMultiplier = this.depthMultiplier, e.depthwiseInitializer = serializeInitializer(this.depthwiseInitializer), e.depthwiseRegularizer = serializeRegularizer(this.depthwiseRegularizer), e.depthwiseConstraint = serializeConstraint(this.depthwiseRegularizer), e;
  }

}

function standardizeArgs(e, t, n, r) {
  if (Array.isArray(e)) {
    if (null != t || null != n) throw new ValueError("When inputs is an array, neither initialState or constants should be provided");
    null != r && (n = e.slice(e.length - r, e.length), e = e.slice(0, e.length - r)), e.length > 1 && (t = e.slice(1, e.length)), e = e[0];
  }

  function a(e) {
    return null == e || Array.isArray(e) ? e : [e];
  }

  return {
    inputs: e,
    initialState: t = a(t),
    constants: n = a(n)
  };
}

function rnn$1(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
  var a = arguments.length > 4 ? arguments[4] : undefined;
  var s = arguments.length > 5 ? arguments[5] : undefined;
  var o = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : !1;
  var i = arguments.length > 7 && arguments[7] !== undefined ? arguments[7] : !1;
  return tidy(() => {
    var l = t.shape.length;
    if (l < 3) throw new ValueError("Input should be at least 3D, but is ".concat(l, "D."));
    var u = [1, 0].concat(range$3(2, l));
    if (t = transpose$2(t, u), null != s) throw new NotImplementedError("The rnn() functoin of the deeplearn.js backend does not support constants yet.");
    o && console.warn("Backend rnn(): the unroll = true option is not applicable to the imperative deeplearn.js backend."), null != a && ((a = cast$3(cast$3(a, "bool"), "float32")).rank === l - 1 && (a = expandDims$3(a, -1)), a = transpose$2(a, u)), r && (t = reverse$2(t, 0), null != a && (a = reverse$2(a, 0)));
    var c = [];
    var p,
        d = n;
    var h = t.shape[0],
        m = unstack(t);
    var f, g;
    null != a && (f = unstack(a));

    var _loop47 = function _loop47(_t517) {
      var n = m[_t517],
          r = tidy(() => e(n, d));
      if (null == a) p = r[0], d = r[1];else {
        var _e737 = tidy(() => {
          var e = f[_t517],
              n = sub$2(onesLike$2(e), e);
          return {
            output: add$2(mul(r[0], e), mul(d[0], n)),
            newStates: d.map((t, a) => add$2(mul(r[1][a], e), mul(t, n)))
          };
        });

        p = _e737.output, d = _e737.newStates;
      }
      i && c.push(p);
    };

    for (var _t517 = 0; _t517 < h; ++_t517) {
      _loop47(_t517);
    }

    return i && (g = stack(c, 1)), [p, g, d];
  });
}

DepthwiseConv2D.className = "DepthwiseConv2D", registerClass(DepthwiseConv2D);

class RNN extends Layer {
  constructor(e) {
    var t;
    if (super(e), null == e.cell) throw new ValueError("cell property is missing for the constructor of RNN.");
    if (t = Array.isArray(e.cell) ? new StackedRNNCells({
      cells: e.cell
    }) : e.cell, null == t.stateSize) throw new ValueError("The RNN cell should have an attribute `stateSize` (tuple of integers, one integer per RNN state).");
    this.cell = t, this.returnSequences = null != e.returnSequences && e.returnSequences, this.returnState = null != e.returnState && e.returnState, this.goBackwards = null != e.goBackwards && e.goBackwards, this._stateful = null != e.stateful && e.stateful, this.unroll = null != e.unroll && e.unroll, this.supportsMasking = !0, this.inputSpec = [new InputSpec({
      ndim: 3
    })], this.stateSpec = null, this.states_ = null, this.numConstants = null, this.keptStates = [];
  }

  getStates() {
    return null == this.states_ ? range$3(0, Array.isArray(this.cell.stateSize) ? this.cell.stateSize.length : 1).map(e => null) : this.states_;
  }

  setStates(e) {
    this.states_ = e;
  }

  computeOutputShape(e) {
    isArrayOfShapes(e) && (e = e[0]), e = e;
    var t = this.cell.stateSize;
    Array.isArray(t) || (t = [t]);
    var n = t[0];
    var r;

    if (r = this.returnSequences ? [e[0], e[1], n] : [e[0], n], this.returnState) {
      var _n289 = [];

      for (var _r235 of t) {
        _n289.push([e[0], _r235]);
      }

      return [r].concat(_n289);
    }

    return r;
  }

  computeMask(e, t) {
    return tidy(() => {
      Array.isArray(t) && (t = t[0]);
      var e = this.returnSequences ? t : null;

      if (this.returnState) {
        var _t518 = this.states.map(e => null);

        return [e].concat(_t518);
      }

      return e;
    });
  }

  get states() {
    if (null == this.states_) {
      var _e738 = Array.isArray(this.cell.stateSize) ? this.cell.stateSize.length : 1,
          t = [];

      for (var n = 0; n < _e738; ++n) {
        t.push(null);
      }

      return t;
    }

    return this.states_;
  }

  set states(e) {
    this.states_ = e;
  }

  build(e) {
    if (null != this.numConstants) throw new NotImplementedError("Constants support is not implemented in RNN yet.");
    isArrayOfShapes(e) && (e = e[0]), e = e;
    var t = this.stateful ? e[0] : null,
        n = e.slice(2);
    this.inputSpec[0] = new InputSpec({
      shape: [t, null, ...n]
    });
    var r = [e[0]].concat(e.slice(2));
    var a;

    if (this.cell.build(r), a = Array.isArray(this.cell.stateSize) ? this.cell.stateSize : [this.cell.stateSize], null != this.stateSpec) {
      if (!arraysEqual(this.stateSpec.map(e => e.shape[e.shape.length - 1]), a)) throw new ValueError("An initialState was passed that is not compatible with cell.stateSize. Received stateSpec=".concat(this.stateSpec, "; However cell.stateSize is ").concat(this.cell.stateSize));
    } else this.stateSpec = a.map(e => new InputSpec({
      shape: [null, e]
    }));

    this.stateful && this.resetStates();
  }

  resetStates(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;
    tidy(() => {
      if (!this.stateful) throw new AttributeError("Cannot call resetStates() on an RNN Layer that is not stateful.");
      var n = this.inputSpec[0].shape[0];
      if (null == n) throw new ValueError("If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.");
      if (null == this.states_) this.states_ = Array.isArray(this.cell.stateSize) ? this.cell.stateSize.map(e => zeros$2([n, e])) : [zeros$2([n, this.cell.stateSize])];else if (null == e) dispose(this.states_), null != this.keptStates && (dispose(this.keptStates), this.keptStates = []), Array.isArray(this.cell.stateSize) ? this.states_ = this.cell.stateSize.map(e => zeros$2([n, e])) : this.states_[0] = zeros$2([n, this.cell.stateSize]);else {
        if (Array.isArray(e) || (e = [e]), e.length !== this.states_.length) throw new ValueError("Layer ".concat(this.name, " expects ").concat(this.states_.length, " state(s), but it received ").concat(e.length, " state value(s). Input received: ").concat(e));
        !0 === t ? this.keptStates.push(this.states_.slice()) : dispose(this.states_);

        for (var _t519 = 0; _t519 < this.states_.length; ++_t519) {
          var r = e[_t519],
              a = Array.isArray(this.cell.stateSize) ? this.cell.stateSize[_t519] : this.cell.stateSize,
              s = [n, a];
          if (!arraysEqual(r.shape, s)) throw new ValueError("State ".concat(_t519, " is incompatible with layer ").concat(this.name, ": expected shape=").concat(s, ", received shape=").concat(r.shape));
          this.states_[_t519] = r;
        }
      }
      this.states_ = this.states_.map(e => keep(e.clone()));
    });
  }

  apply(e, t) {
    var n = null == t ? null : t.initialState,
        r = null == t ? null : t.constants;
    null == t && (t = {});
    var a = standardizeArgs(e, n, r, this.numConstants);
    e = a.inputs, n = a.initialState, r = a.constants;
    var s = [],
        o = [];

    if (null != n) {
      t.initialState = n, s = s.concat(n), this.stateSpec = [];

      for (var _e739 of n) {
        this.stateSpec.push(new InputSpec({
          shape: _e739.shape
        }));
      }

      o = o.concat(this.stateSpec);
    }

    if (null != r && (t.constants = r, s = s.concat(r), this.numConstants = r.length), s[0] instanceof SymbolicTensor) {
      var _n290 = [e].concat(s),
          _r236 = this.inputSpec.concat(o),
          _a155 = this.inputSpec;

      this.inputSpec = _r236;
      var i = super.apply(_n290, t);
      return this.inputSpec = _a155, i;
    }

    return super.apply(e, t);
  }

  call(e, t) {
    return tidy(() => {
      var n = null == t ? null : t.mask,
          r = null == t ? null : t.training;
      var a = null == t ? null : t.initialState;
      e = getExactlyOneTensor(e), null == a && (a = this.stateful ? this.states_ : this.getInitialState(e));
      var s = Array.isArray(this.cell.stateSize) ? this.cell.stateSize.length : 1;
      if (a.length !== s) throw new ValueError("RNN Layer has ".concat(s, " state(s) but was passed ").concat(a.length, " initial state(s)."));
      this.unroll && console.warn("Ignoring unroll = true for RNN layer, due to imperative backend.");
      var o = {
        training: r
      },
          i = rnn$1((e, t) => {
        var n = this.cell.call([e].concat(t), o);
        return [n[0], n.slice(1)];
      }, e, a, this.goBackwards, n, null, this.unroll, this.returnSequences),
          l = i[0],
          u = i[1],
          c = i[2];
      this.stateful && this.resetStates(c, r);
      var p = this.returnSequences ? u : l;
      return this.returnState ? [p].concat(c) : p;
    });
  }

  getInitialState(e) {
    return tidy(() => {
      var t = zeros$2(e.shape);
      return t = sum$2(t, [1, 2]), t = expandDims$2(t), Array.isArray(this.cell.stateSize) ? this.cell.stateSize.map(e => e > 1 ? tile$2(t, [1, e]) : t) : this.cell.stateSize > 1 ? [tile$2(t, [1, this.cell.stateSize])] : [t];
    });
  }

  get trainableWeights() {
    return this.trainable ? this.cell.trainableWeights : [];
  }

  get nonTrainableWeights() {
    return this.trainable ? this.cell.nonTrainableWeights : this.cell.weights;
  }

  setFastWeightInitDuringBuild(e) {
    super.setFastWeightInitDuringBuild(e), null != this.cell && this.cell.setFastWeightInitDuringBuild(e);
  }

  getConfig() {
    var e = super.getConfig(),
        t = {
      returnSequences: this.returnSequences,
      returnState: this.returnState,
      goBackwards: this.goBackwards,
      stateful: this.stateful,
      unroll: this.unroll
    };
    null != this.numConstants && (t.numConstants = this.numConstants);
    var n = this.cell.getConfig();
    return this.getClassName() === RNN.className && (t.cell = {
      className: this.cell.getClassName(),
      config: n
    }), Object.assign({}, n, e, t);
  }

  static fromConfig(e, t) {
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};
    var r = deserialize(t.cell, n);
    return new e(Object.assign(t, {
      cell: r
    }));
  }

}

RNN.className = "RNN", registerClass(RNN);

class RNNCell extends Layer {}

class SimpleRNNCell extends RNNCell {
  constructor(e) {
    super(e), this.DEFAULT_ACTIVATION = "tanh", this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal", this.DEFAULT_RECURRENT_INITIALIZER = "orthogonal", this.DEFAULT_BIAS_INITIALIZER = "zeros", this.units = e.units, assertPositiveInteger(this.units, "units"), this.activation = getActivation(null == e.activation ? this.DEFAULT_ACTIVATION : e.activation), this.useBias = null == e.useBias || e.useBias, this.kernelInitializer = getInitializer(e.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER), this.recurrentInitializer = getInitializer(e.recurrentInitializer || this.DEFAULT_RECURRENT_INITIALIZER), this.biasInitializer = getInitializer(e.biasInitializer || this.DEFAULT_BIAS_INITIALIZER), this.kernelRegularizer = getRegularizer(e.kernelRegularizer), this.recurrentRegularizer = getRegularizer(e.recurrentRegularizer), this.biasRegularizer = getRegularizer(e.biasRegularizer), this.kernelConstraint = getConstraint(e.kernelConstraint), this.recurrentConstraint = getConstraint(e.recurrentConstraint), this.biasConstraint = getConstraint(e.biasConstraint), this.dropout = min$2([1, max$2([0, null == e.dropout ? 0 : e.dropout])]), this.recurrentDropout = min$2([1, max$2([0, null == e.recurrentDropout ? 0 : e.recurrentDropout])]), this.stateSize = this.units, this.dropoutMask = null, this.recurrentDropoutMask = null;
  }

  build(e) {
    e = getExactlyOneShape(e), this.kernel = this.addWeight("kernel", [e[e.length - 1], this.units], null, this.kernelInitializer, this.kernelRegularizer, !0, this.kernelConstraint), this.recurrentKernel = this.addWeight("recurrent_kernel", [this.units, this.units], null, this.recurrentInitializer, this.recurrentRegularizer, !0, this.recurrentConstraint), this.bias = this.useBias ? this.addWeight("bias", [this.units], null, this.biasInitializer, this.biasRegularizer, !0, this.biasConstraint) : null, this.built = !0;
  }

  call(e, t) {
    return tidy(() => {
      if (2 !== (e = e).length) throw new ValueError("SimpleRNNCell expects 2 input Tensors, got ".concat(e.length, "."));
      var n = e[1];
      e = e[0];
      var r = null != t.training && t.training;
      var a;
      0 < this.dropout && this.dropout < 1 && null == this.dropoutMask && (this.dropoutMask = generateDropoutMask({
        ones: () => onesLike$2(e),
        rate: this.dropout,
        training: r
      })), 0 < this.recurrentDropout && this.recurrentDropout < 1 && null == this.recurrentDropoutMask && (this.recurrentDropoutMask = generateDropoutMask({
        ones: () => onesLike$2(n),
        rate: this.recurrentDropout,
        training: r
      }));
      var s = this.dropoutMask,
          o = this.recurrentDropoutMask;
      a = dot$1(null != s ? mul(e, s) : e, this.kernel.read()), null != this.bias && (a = biasAdd(a, this.bias.read())), null != o && (n = mul(n, o));
      var i = add$2(a, dot$1(n, this.recurrentKernel.read()));
      return null != this.activation && (i = this.activation.apply(i)), [i, i];
    });
  }

  getConfig() {
    var e = super.getConfig(),
        t = {
      units: this.units,
      activation: serializeActivation(this.activation),
      useBias: this.useBias,
      kernelInitializer: serializeInitializer(this.kernelInitializer),
      recurrentInitializer: serializeInitializer(this.recurrentInitializer),
      biasInitializer: serializeInitializer(this.biasInitializer),
      kernelRegularizer: serializeRegularizer(this.kernelRegularizer),
      recurrentRegularizer: serializeRegularizer(this.recurrentRegularizer),
      biasRegularizer: serializeRegularizer(this.biasRegularizer),
      activityRegularizer: serializeRegularizer(this.activityRegularizer),
      kernelConstraint: serializeConstraint(this.kernelConstraint),
      recurrentConstraint: serializeConstraint(this.recurrentConstraint),
      biasConstraint: serializeConstraint(this.biasConstraint),
      dropout: this.dropout,
      recurrentDropout: this.recurrentDropout
    };
    return Object.assign({}, e, t);
  }

}

SimpleRNNCell.className = "SimpleRNNCell", registerClass(SimpleRNNCell);

class SimpleRNN extends RNN {
  constructor(e) {
    e.cell = new SimpleRNNCell(e), super(e);
  }

  call(e, t) {
    return tidy(() => (null != this.cell.dropoutMask && (dispose(this.cell.dropoutMask), this.cell.dropoutMask = null), null != this.cell.recurrentDropoutMask && (dispose(this.cell.recurrentDropoutMask), this.cell.recurrentDropoutMask = null), super.call(e, {
      mask: null == t ? null : t.mask,
      training: null == t ? null : t.training,
      initialState: null == t ? null : t.initialState
    })));
  }

  static fromConfig(e, t) {
    return new e(t);
  }

}

SimpleRNN.className = "SimpleRNN", registerClass(SimpleRNN);

class GRUCell extends RNNCell {
  constructor(e) {
    if (super(e), this.DEFAULT_ACTIVATION = "tanh", this.DEFAULT_RECURRENT_ACTIVATION = "hardSigmoid", this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal", this.DEFAULT_RECURRENT_INITIALIZER = "orthogonal", this.DEFAULT_BIAS_INITIALIZER = "zeros", e.resetAfter) throw new ValueError("GRUCell does not support reset_after parameter set to true.");
    this.units = e.units, assertPositiveInteger(this.units, "units"), this.activation = getActivation(void 0 === e.activation ? this.DEFAULT_ACTIVATION : e.activation), this.recurrentActivation = getActivation(void 0 === e.recurrentActivation ? this.DEFAULT_RECURRENT_ACTIVATION : e.recurrentActivation), this.useBias = null == e.useBias || e.useBias, this.kernelInitializer = getInitializer(e.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER), this.recurrentInitializer = getInitializer(e.recurrentInitializer || this.DEFAULT_RECURRENT_INITIALIZER), this.biasInitializer = getInitializer(e.biasInitializer || this.DEFAULT_BIAS_INITIALIZER), this.kernelRegularizer = getRegularizer(e.kernelRegularizer), this.recurrentRegularizer = getRegularizer(e.recurrentRegularizer), this.biasRegularizer = getRegularizer(e.biasRegularizer), this.kernelConstraint = getConstraint(e.kernelConstraint), this.recurrentConstraint = getConstraint(e.recurrentConstraint), this.biasConstraint = getConstraint(e.biasConstraint), this.dropout = min$2([1, max$2([0, null == e.dropout ? 0 : e.dropout])]), this.recurrentDropout = min$2([1, max$2([0, null == e.recurrentDropout ? 0 : e.recurrentDropout])]), this.implementation = e.implementation, this.stateSize = this.units, this.dropoutMask = null, this.recurrentDropoutMask = null;
  }

  build(e) {
    e = getExactlyOneShape(e), this.kernel = this.addWeight("kernel", [e[e.length - 1], 3 * this.units], null, this.kernelInitializer, this.kernelRegularizer, !0, this.kernelConstraint), this.recurrentKernel = this.addWeight("recurrent_kernel", [this.units, 3 * this.units], null, this.recurrentInitializer, this.recurrentRegularizer, !0, this.recurrentConstraint), this.bias = this.useBias ? this.addWeight("bias", [3 * this.units], null, this.biasInitializer, this.biasRegularizer, !0, this.biasConstraint) : null, this.built = !0;
  }

  call(e, t) {
    return tidy(() => {
      if (2 !== (e = e).length) throw new ValueError("GRUCell expects 2 input Tensors (inputs, h, c), got ".concat(e.length, "."));
      var n = null != t.training && t.training;
      var r = e[1];
      e = e[0], 0 < this.dropout && this.dropout < 1 && null == this.dropoutMask && (this.dropoutMask = generateDropoutMask({
        ones: () => onesLike$2(e),
        rate: this.dropout,
        training: n,
        count: 3
      })), 0 < this.recurrentDropout && this.recurrentDropout < 1 && null == this.recurrentDropoutMask && (this.recurrentDropoutMask = generateDropoutMask({
        ones: () => onesLike$2(r),
        rate: this.recurrentDropout,
        training: n,
        count: 3
      }));
      var a = this.recurrentDropoutMask;
      var s, o, i;
      0 < this.dropout && this.dropout < 1 && (e = mul(e, this.dropoutMask[0]));
      var l = dot$1(e, this.kernel.read());
      this.useBias && (l = biasAdd(l, this.bias.read())), 0 < this.recurrentDropout && this.recurrentDropout < 1 && (r = mul(r, a[0]));
      var u = this.recurrentKernel.read(),
          [c, p] = split$2(u, [2 * this.units, this.units], u.rank - 1),
          d = dot$1(r, c),
          [h, m, f] = split$2(l, 3, l.rank - 1),
          [g, $] = split$2(d, 2, d.rank - 1);
      s = this.recurrentActivation.apply(add$2(h, g)), o = this.recurrentActivation.apply(add$2(m, $));
      var y = dot$1(mul(o, r), p);
      i = this.activation.apply(add$2(f, y));
      var b = add$2(mul(s, r), mul(add$2(1, neg$2(s)), i));
      return [b, b];
    });
  }

  getConfig() {
    var e = super.getConfig(),
        t = {
      units: this.units,
      activation: serializeActivation(this.activation),
      recurrentActivation: serializeActivation(this.recurrentActivation),
      useBias: this.useBias,
      kernelInitializer: serializeInitializer(this.kernelInitializer),
      recurrentInitializer: serializeInitializer(this.recurrentInitializer),
      biasInitializer: serializeInitializer(this.biasInitializer),
      kernelRegularizer: serializeRegularizer(this.kernelRegularizer),
      recurrentRegularizer: serializeRegularizer(this.recurrentRegularizer),
      biasRegularizer: serializeRegularizer(this.biasRegularizer),
      activityRegularizer: serializeRegularizer(this.activityRegularizer),
      kernelConstraint: serializeConstraint(this.kernelConstraint),
      recurrentConstraint: serializeConstraint(this.recurrentConstraint),
      biasConstraint: serializeConstraint(this.biasConstraint),
      dropout: this.dropout,
      recurrentDropout: this.recurrentDropout,
      implementation: this.implementation,
      resetAfter: !1
    };
    return Object.assign({}, e, t);
  }

}

GRUCell.className = "GRUCell", registerClass(GRUCell);

class GRU extends RNN {
  constructor(e) {
    0 === e.implementation && console.warn("`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call."), e.cell = new GRUCell(e), super(e);
  }

  call(e, t) {
    return tidy(() => (null != this.cell.dropoutMask && (dispose(this.cell.dropoutMask), this.cell.dropoutMask = null), null != this.cell.recurrentDropoutMask && (dispose(this.cell.recurrentDropoutMask), this.cell.recurrentDropoutMask = null), super.call(e, {
      mask: null == t ? null : t.mask,
      training: null == t ? null : t.training,
      initialState: null == t ? null : t.initialState
    })));
  }

  static fromConfig(e, t) {
    return 0 === t.implmentation && (t.implementation = 1), new e(t);
  }

}

GRU.className = "GRU", registerClass(GRU);

class LSTMCell extends RNNCell {
  constructor(e) {
    super(e), this.DEFAULT_ACTIVATION = "tanh", this.DEFAULT_RECURRENT_ACTIVATION = "hardSigmoid", this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal", this.DEFAULT_RECURRENT_INITIALIZER = "orthogonal", this.DEFAULT_BIAS_INITIALIZER = "zeros", this.units = e.units, assertPositiveInteger(this.units, "units"), this.activation = getActivation(void 0 === e.activation ? this.DEFAULT_ACTIVATION : e.activation), this.recurrentActivation = getActivation(void 0 === e.recurrentActivation ? this.DEFAULT_RECURRENT_ACTIVATION : e.recurrentActivation), this.useBias = null == e.useBias || e.useBias, this.kernelInitializer = getInitializer(e.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER), this.recurrentInitializer = getInitializer(e.recurrentInitializer || this.DEFAULT_RECURRENT_INITIALIZER), this.biasInitializer = getInitializer(e.biasInitializer || this.DEFAULT_BIAS_INITIALIZER), this.unitForgetBias = e.unitForgetBias, this.kernelRegularizer = getRegularizer(e.kernelRegularizer), this.recurrentRegularizer = getRegularizer(e.recurrentRegularizer), this.biasRegularizer = getRegularizer(e.biasRegularizer), this.kernelConstraint = getConstraint(e.kernelConstraint), this.recurrentConstraint = getConstraint(e.recurrentConstraint), this.biasConstraint = getConstraint(e.biasConstraint), this.dropout = min$2([1, max$2([0, null == e.dropout ? 0 : e.dropout])]), this.recurrentDropout = min$2([1, max$2([0, null == e.recurrentDropout ? 0 : e.recurrentDropout])]), this.implementation = e.implementation, this.stateSize = [this.units, this.units], this.dropoutMask = null, this.recurrentDropoutMask = null;
  }

  build(e) {
    var t;
    var n;

    if (e = getExactlyOneShape(e), this.kernel = this.addWeight("kernel", [e[e.length - 1], 4 * this.units], null, this.kernelInitializer, this.kernelRegularizer, !0, this.kernelConstraint), this.recurrentKernel = this.addWeight("recurrent_kernel", [this.units, 4 * this.units], null, this.recurrentInitializer, this.recurrentRegularizer, !0, this.recurrentConstraint), this.useBias) {
      if (this.unitForgetBias) {
        var _e740 = this.biasInitializer,
            r = this.units;
        n = new ((t = class extends Initializer {
          apply(t, n) {
            var a = _e740.apply([r]),
                s = new Ones().apply([r]),
                o = _e740.apply([2 * r]);

            return concatAlongFirstAxis(concatAlongFirstAxis(a, s), o);
          }

        }).className = "CustomInit", t)();
      } else n = this.biasInitializer;

      this.bias = this.addWeight("bias", [4 * this.units], null, n, this.biasRegularizer, !0, this.biasConstraint);
    } else this.bias = null;

    this.built = !0;
  }

  call(e, t) {
    return tidy(() => {
      var n = null != t.training && t.training;
      if (3 !== (e = e).length) throw new ValueError("LSTMCell expects 3 input Tensors (inputs, h, c), got ".concat(e.length, "."));
      var r = e[1];
      var a = e[2];
      e = e[0], 0 < this.dropout && this.dropout < 1 && null == this.dropoutMask && (this.dropoutMask = generateDropoutMask({
        ones: () => onesLike$2(e),
        rate: this.dropout,
        training: n,
        count: 4
      })), 0 < this.recurrentDropout && this.recurrentDropout < 1 && null == this.recurrentDropoutMask && (this.recurrentDropoutMask = generateDropoutMask({
        ones: () => onesLike$2(r),
        rate: this.recurrentDropout,
        training: n,
        count: 4
      }));
      var s = this.recurrentDropoutMask;
      var o, i, l, u;
      0 < this.dropout && this.dropout < 1 && (e = mul(e, this.dropoutMask[0]));
      var c = dot$1(e, this.kernel.read());
      0 < this.recurrentDropout && this.recurrentDropout < 1 && (r = mul(r, s[0])), c = add$2(c, dot$1(r, this.recurrentKernel.read())), this.useBias && (c = biasAdd(c, this.bias.read()));
      var [p, d, h, m] = split$2(c, 4, c.rank - 1);
      o = this.recurrentActivation.apply(p), i = this.recurrentActivation.apply(d), l = add$2(mul(i, a), mul(o, this.activation.apply(h))), u = this.recurrentActivation.apply(m);
      var f = mul(u, this.activation.apply(l));
      return [f, f, l];
    });
  }

  getConfig() {
    var e = super.getConfig(),
        t = {
      units: this.units,
      activation: serializeActivation(this.activation),
      recurrentActivation: serializeActivation(this.recurrentActivation),
      useBias: this.useBias,
      kernelInitializer: serializeInitializer(this.kernelInitializer),
      recurrentInitializer: serializeInitializer(this.recurrentInitializer),
      biasInitializer: serializeInitializer(this.biasInitializer),
      unitForgetBias: this.unitForgetBias,
      kernelRegularizer: serializeRegularizer(this.kernelRegularizer),
      recurrentRegularizer: serializeRegularizer(this.recurrentRegularizer),
      biasRegularizer: serializeRegularizer(this.biasRegularizer),
      activityRegularizer: serializeRegularizer(this.activityRegularizer),
      kernelConstraint: serializeConstraint(this.kernelConstraint),
      recurrentConstraint: serializeConstraint(this.recurrentConstraint),
      biasConstraint: serializeConstraint(this.biasConstraint),
      dropout: this.dropout,
      recurrentDropout: this.recurrentDropout,
      implementation: this.implementation
    };
    return Object.assign({}, e, t);
  }

}

LSTMCell.className = "LSTMCell", registerClass(LSTMCell);

class LSTM extends RNN {
  constructor(e) {
    0 === e.implementation && console.warn("`implementation=0` has been deprecated, and now defaults to `implementation=1`. Please update your layer call."), e.cell = new LSTMCell(e), super(e);
  }

  call(e, t) {
    return tidy(() => (null != this.cell.dropoutMask && (dispose(this.cell.dropoutMask), this.cell.dropoutMask = null), null != this.cell.recurrentDropoutMask && (dispose(this.cell.recurrentDropoutMask), this.cell.recurrentDropoutMask = null), super.call(e, {
      mask: null == t ? null : t.mask,
      training: null == t ? null : t.training,
      initialState: null == t ? null : t.initialState
    })));
  }

  static fromConfig(e, t) {
    return 0 === t.implmentation && (t.implementation = 1), new e(t);
  }

}

LSTM.className = "LSTM", registerClass(LSTM);

class StackedRNNCells extends RNNCell {
  constructor(e) {
    super(e), this.cells = e.cells;
  }

  get stateSize() {
    var e = [];

    for (var t of this.cells.slice().reverse()) {
      Array.isArray(t.stateSize) ? e.push(...t.stateSize) : e.push(t.stateSize);
    }

    return e;
  }

  call(e, t) {
    return tidy(() => {
      var n = (e = e).slice(1);
      var r = [];

      for (var _e741 of this.cells.slice().reverse()) {
        Array.isArray(_e741.stateSize) ? r.push(n.splice(0, _e741.stateSize.length)) : r.push(n.splice(0, 1));
      }

      r.reverse();
      var a = [];
      var s;

      for (var o = 0; o < this.cells.length; ++o) {
        var i = this.cells[o];
        n = r[o], s = 0 === o ? [e[0]].concat(n) : [s[0]].concat(n), s = i.call(s, t), a.push(s.slice(1));
      }

      n = [];

      for (var _e742 of a.slice().reverse()) {
        n.push(..._e742);
      }

      return [s[0]].concat(n);
    });
  }

  build(e) {
    var t;
    isArrayOfShapes(e) && (e = e[0]), e = e, this.cells.forEach((n, r) => {
      nameScope("RNNCell_".concat(r), () => {
        n.build(e), t = Array.isArray(n.stateSize) ? n.stateSize[0] : n.stateSize, e = [e[0], t];
      });
    }), this.built = !0;
  }

  getConfig() {
    var e = super.getConfig(),
        t = this.cells.map(e => ({
      className: e.getClassName(),
      config: e.getConfig()
    }));
    return Object.assign({}, e, {
      cells: t
    });
  }

  static fromConfig(e, t) {
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};
    var r = [];

    for (var _e743 of t.cells) {
      r.push(deserialize(_e743, n));
    }

    return new e({
      cells: r
    });
  }

  get trainableWeights() {
    if (!this.trainable) return [];
    var e = [];

    for (var t of this.cells) {
      e.push(...t.trainableWeights);
    }

    return e;
  }

  get nonTrainableWeights() {
    var e = [];

    for (var t of this.cells) {
      e.push(...t.nonTrainableWeights);
    }

    if (!this.trainable) {
      var _t520 = [];

      for (var _e744 of this.cells) {
        _t520.push(..._e744.trainableWeights);
      }

      return _t520.concat(e);
    }

    return e;
  }

  getWeights() {
    var e = [];

    for (var t of this.cells) {
      e.push(...t.weights);
    }

    return batchGetValue(e);
  }

  setWeights(e) {
    var t = [];

    for (var n of this.cells) {
      var r = e.splice(n.weights.length);

      for (var _e745 = 0; _e745 < n.weights.length; ++_e745) {
        t.push([n.weights[_e745], r[_e745]]);
      }
    }

    batchSetValue(t);
  }

}

function generateDropoutMask(e) {
  var {
    ones: t,
    rate: n,
    training: r = !1,
    count: a = 1
  } = e,
      s = () => dropout$1(t(), n),
      o = () => inTrainPhase(s, t, r);

  return !a || a <= 1 ? keep(o().clone()) : Array(a).fill(void 0).map(o).map(e => keep(e.clone()));
}

StackedRNNCells.className = "StackedRNNCells", registerClass(StackedRNNCells);

var __rest = function __rest(e, t) {
  var n = {};

  for (var r in e) {
    Object.prototype.hasOwnProperty.call(e, r) && t.indexOf(r) < 0 && (n[r] = e[r]);
  }

  if (null != e && "function" == typeof Object.getOwnPropertySymbols) {
    var a = 0;

    for (r = Object.getOwnPropertySymbols(e); a < r.length; a++) {
      t.indexOf(r[a]) < 0 && Object.prototype.propertyIsEnumerable.call(e, r[a]) && (n[r[a]] = e[r[a]]);
    }
  }

  return n;
};

class ConvRNN2D extends RNN {
  constructor(e) {
    if (e.unroll) throw new NotImplementedError("Unrolling is not possible with convolutional RNNs.");
    if (Array.isArray(e.cell)) throw new NotImplementedError("It is not possible at the moment to stack convolutional cells.");
    super(e), this.inputSpec = [new InputSpec({
      ndim: 5
    })];
  }

  call(e, t) {
    return tidy(() => {
      if (null != this.cell.dropoutMask && (dispose(this.cell.dropoutMask), this.cell.dropoutMask = null), null != this.cell.recurrentDropoutMask && (dispose(this.cell.recurrentDropoutMask), this.cell.recurrentDropoutMask = null), t && t.constants) throw new ValueError("ConvRNN2D cell does not support constants");
      return super.call(e, {
        mask: null == t ? null : t.mask,
        training: null == t ? null : t.training,
        initialState: null == t ? null : t.initialState
      });
    });
  }

  computeOutputShape(e) {
    var t = this.computeSingleOutputShape(e);
    return this.returnSequences || (t = [t[0], ...t.slice(2)]), this.returnState && (t = [t, ...Array(2).fill([e[0], ...t.slice(-3)])]), t;
  }

  getInitialState(e) {
    return tidy(() => {
      var {
        stateSize: t
      } = this.cell,
          n = this.computeSingleOutputShape(e.shape),
          r = zeros$2([n[0], ...n.slice(2)]);
      return Array.isArray(t) ? Array(t.length).fill(r) : [r];
    });
  }

  resetStates(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;
    tidy(() => {
      if (!this.stateful) throw new AttributeError("Cannot call resetStates() on an RNN Layer that is not stateful.");
      var n = this.inputSpec[0].shape,
          r = this.computeSingleOutputShape(n),
          a = [r[0], ...r.slice(2)];
      if (null == n[0]) throw new ValueError("If an RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: \n- If using a Sequential model, specify the batch size by passing a `batchInputShape` option to your first layer.\n- If using the functional API, specify the batch size by passing a `batchShape` option to your Input layer.");
      if (null == this.getStates()) this.states_ = Array.isArray(this.cell.stateSize) ? this.cell.stateSize.map(() => zeros$2(a)) : [zeros$2(a)];else if (null == e) dispose(this.states_), null != this.keptStates && (dispose(this.keptStates), this.keptStates = []), Array.isArray(this.cell.stateSize) ? this.states_ = this.cell.stateSize.map(() => zeros$2(a)) : this.states_[0] = zeros$2(a);else {
        if (Array.isArray(e) || (e = [e]), e.length !== this.states_.length) throw new ValueError("Layer ".concat(this.name, " expects ").concat(this.states_.length, " state(s), but it received ").concat(e.length, " state value(s). Input received: ").concat(e));
        t ? this.keptStates.push(this.states_.slice()) : dispose(this.states_);

        for (var _t521 = 0; _t521 < this.states_.length; ++_t521) {
          var _n291 = e[_t521],
              _r237 = a;
          if (!arraysEqual(_n291.shape, _r237)) throw new ValueError("State ".concat(_t521, " is incompatible with layer ").concat(this.name, ": expected shape=").concat(_r237, ", received shape=").concat(_n291.shape));
          this.states_[_t521] = _n291;
        }
      }
      this.states_ = this.states_.map(e => keep(e.clone()));
    });
  }

  computeSingleOutputShape(e) {
    var {
      dataFormat: t,
      filters: n,
      kernelSize: r,
      padding: a,
      strides: s,
      dilationRate: o
    } = this.cell,
        i = "channelsFirst" === t,
        l = e[i ? 4 : 3],
        u = convOutputLength(e[i ? 3 : 2], r[0], a, s[0], o[0]),
        c = convOutputLength(l, r[1], a, s[1], o[1]);
    return [...e.slice(0, 2), ...(i ? [n, u, c] : [u, c, n])];
  }

}

ConvRNN2D.className = "ConvRNN2D";

class ConvLSTM2DCell extends LSTMCell {
  constructor(e) {
    var {
      filters: t,
      kernelSize: n,
      strides: r,
      padding: a,
      dataFormat: s,
      dilationRate: o
    } = e;
    super(Object.assign({}, e, {
      units: t
    })), this.filters = t, assertPositiveInteger(this.filters, "filters"), this.kernelSize = normalizeArray(n, 2, "kernelSize"), this.kernelSize.forEach(e => assertPositiveInteger(e, "kernelSize")), this.strides = normalizeArray(r || 1, 2, "strides"), this.strides.forEach(e => assertPositiveInteger(e, "strides")), this.padding = a || "valid", checkPaddingMode(this.padding), this.dataFormat = s || "channelsLast", checkDataFormat(this.dataFormat), this.dilationRate = normalizeArray(o || 1, 2, "dilationRate"), this.dilationRate.forEach(e => assertPositiveInteger(e, "dilationRate"));
  }

  build(e) {
    var t;
    e = getExactlyOneShape(e);
    var n = "channelsFirst" === this.dataFormat ? 1 : e.length - 1;
    if (null == e[n]) throw new ValueError("The channel dimension of the input should be defined. Found ".concat(e[n]));
    var r = this.kernelSize.concat([e[n], 4 * this.filters]);
    this.kernel = this.addWeight("kernel", r, null, this.kernelInitializer, this.kernelRegularizer, !0, this.kernelConstraint);
    var a = this.kernelSize.concat([this.filters, 4 * this.filters]);

    if (this.recurrentKernel = this.addWeight("recurrent_kernel", a, null, this.recurrentInitializer, this.recurrentRegularizer, !0, this.recurrentConstraint), this.useBias) {
      var _e746;

      if (this.unitForgetBias) {
        var _n292 = this.biasInitializer,
            _r238 = this.filters;
        _e746 = new (t = class extends Initializer {
          apply(e, t) {
            return concatenate$1([_n292.apply([_r238]), ones$1([_r238]), _n292.apply([2 * _r238])]);
          }

        }, t.className = "CustomInit", t)();
      } else _e746 = this.biasInitializer;

      this.bias = this.addWeight("bias", [4 * this.filters], null, _e746, this.biasRegularizer, !0, this.biasConstraint);
    }

    this.built = !0;
  }

  call(e, t) {
    return tidy(() => {
      if (3 !== e.length) throw new ValueError("ConvLSTM2DCell expects 3 input Tensors (inputs, h, c), got ".concat(e.length, "."));
      var n = t.training || !1,
          r = e[0],
          a = e[1],
          s = e[2];
      0 < this.dropout && this.dropout < 1 && null == this.dropoutMask && (this.dropoutMask = generateDropoutMask({
        ones: () => onesLike$2(r),
        rate: this.dropout,
        training: n,
        count: 4
      }));

      var o = this.dropoutMask,
          i = (e, t, n) => t && t[n] ? mul(t[n], e) : e;

      var l = i(r, o, 0),
          u = i(r, o, 1),
          c = i(r, o, 2),
          p = i(r, o, 3);
      0 < this.recurrentDropout && this.recurrentDropout < 1 && null == this.recurrentDropoutMask && (this.recurrentDropoutMask = generateDropoutMask({
        ones: () => onesLike$2(a),
        rate: this.recurrentDropout,
        training: n,
        count: 4
      }));
      var d = this.recurrentDropoutMask;
      var h = i(a, d, 0),
          m = i(a, d, 1),
          f = i(a, d, 2),
          g = i(a, d, 3);
      var [$, y, b, x] = split$2(this.kernel.read(), 4, 3),
          [v, I, C, S] = this.useBias ? split$2(this.bias.read(), 4) : [null, null, null, null];
      l = this.inputConv(l, $, v, this.padding), u = this.inputConv(u, y, I, this.padding), c = this.inputConv(c, b, C, this.padding), p = this.inputConv(p, x, S, this.padding);
      var [k, T, N, w] = split$2(this.recurrentKernel.read(), 4, 3);
      h = this.recurrentConv(h, k), m = this.recurrentConv(m, T), f = this.recurrentConv(f, N), g = this.recurrentConv(g, w);
      var E = this.recurrentActivation.apply(add$2(l, h)),
          A = this.recurrentActivation.apply(add$2(u, m)),
          D = add$2(mul(A, s), mul(E, this.activation.apply(add$2(c, f)))),
          R = mul(this.recurrentActivation.apply(add$2(p, g)), this.activation.apply(D));
      return [R, R, D];
    });
  }

  getConfig() {
    var e = super.getConfig(),
        t = __rest(e, ["units"]);

    return Object.assign({}, t, {
      filters: this.filters,
      kernelSize: this.kernelSize,
      padding: this.padding,
      dataFormat: this.dataFormat,
      dilationRate: this.dilationRate,
      strides: this.strides
    });
  }

  inputConv(e, t, n, r) {
    var a = conv2d$3(e, t, this.strides, r || "valid", "channelsFirst" === this.dataFormat ? "NCHW" : "NHWC", this.dilationRate);
    return n ? biasAdd(a, n, this.dataFormat) : a;
  }

  recurrentConv(e, t) {
    return conv2d$3(e, t, 1, "same", "channelsFirst" === this.dataFormat ? "NCHW" : "NHWC");
  }

}

ConvLSTM2DCell.className = "ConvLSTM2DCell", registerClass(ConvLSTM2DCell);

class ConvLSTM2D extends ConvRNN2D {
  constructor(e) {
    var t = new ConvLSTM2DCell(e);
    super(Object.assign({}, e, {
      cell: t
    }));
  }

  static fromConfig(e, t) {
    return new e(t);
  }

}

ConvLSTM2D.className = "ConvLSTM2D", registerClass(ConvLSTM2D);

class Dropout extends Layer {
  constructor(e) {
    super(e), this.rate = Math.max(Math.min(e.rate, 1), 0), this.noiseShape = e.noiseShape, this.seed = e.seed, this.supportsMasking = !0;
  }

  getNoiseShape(e) {
    if (null == this.noiseShape) return this.noiseShape;
    var t = e.shape,
        n = [];

    for (var _e747 = 0; _e747 < this.noiseShape.length; ++_e747) {
      n.push(null == this.noiseShape[_e747] ? t[_e747] : this.noiseShape[_e747]);
    }

    return n;
  }

  call(e, t) {
    return tidy(() => {
      this.invokeCallHook(e, t);
      var n = getExactlyOneTensor(e);

      if (0 < this.rate && this.rate < 1) {
        var _e748 = null != t.training && t.training,
            r = this.getNoiseShape(n);

        return inTrainPhase(() => dropout$1(n, this.rate, r, this.seed), () => n, _e748);
      }

      return e;
    });
  }

  getConfig() {
    var e = {
      rate: this.rate,
      noiseShape: this.noiseShape,
      seed: this.seed
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

  dispose() {
    return super.dispose();
  }

}

Dropout.className = "Dropout", registerClass(Dropout);

class SpatialDropout1D extends Dropout {
  constructor(e) {
    super(e), this.inputSpec = [{
      ndim: 3
    }];
  }

  getNoiseShape(e) {
    var t = e.shape;
    return [t[0], 1, t[2]];
  }

}

SpatialDropout1D.className = "SpatialDropout1D", registerClass(SpatialDropout1D);

class Dense extends Layer {
  constructor(e) {
    if (super(e), this.activation = null, this.useBias = !0, this.kernel = null, this.bias = null, this.DEFAULT_KERNEL_INITIALIZER = "glorotNormal", this.DEFAULT_BIAS_INITIALIZER = "zeros", null == e.batchInputShape && null == e.inputShape && null != e.inputDim) {
      var t = null;
      null != e.batchSize && (t = e.batchSize), this.batchInputShape = [t, e.inputDim];
    }

    this.units = e.units, assertPositiveInteger(this.units, "units"), this.activation = getActivation(e.activation), null != e.useBias && (this.useBias = e.useBias), this.kernelInitializer = getInitializer(e.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER), this.biasInitializer = getInitializer(e.biasInitializer || this.DEFAULT_BIAS_INITIALIZER), this.kernelConstraint = getConstraint(e.kernelConstraint), this.biasConstraint = getConstraint(e.biasConstraint), this.kernelRegularizer = getRegularizer(e.kernelRegularizer), this.biasRegularizer = getRegularizer(e.biasRegularizer), this.activityRegularizer = getRegularizer(e.activityRegularizer), this.supportsMasking = !0, this.inputSpec = [{
      minNDim: 2
    }];
  }

  build(e) {
    var t = (e = getExactlyOneShape(e))[e.length - 1];
    null == this.kernel && (this.kernel = this.addWeight("kernel", [t, this.units], null, this.kernelInitializer, this.kernelRegularizer, !0, this.kernelConstraint), this.useBias && (this.bias = this.addWeight("bias", [this.units], null, this.biasInitializer, this.biasRegularizer, !0, this.biasConstraint))), this.inputSpec = [{
      minNDim: 2,
      axes: {
        [-1]: t
      }
    }], this.built = !0;
  }

  computeOutputShape(e) {
    var t = (e = getExactlyOneShape(e)).slice();
    return t[t.length - 1] = this.units, t;
  }

  call(e, t) {
    return tidy(() => {
      this.invokeCallHook(e, t);
      var n = getExactlyOneTensor(e),
          r = mapActivationToFusedKernel(this.activation.getClassName());
      var a;
      return null != r ? a = dot$1(n, this.kernel.read(), r, this.bias ? this.bias.read() : null) : (a = dot$1(n, this.kernel.read()), null != this.bias && (a = biasAdd(a, this.bias.read())), null != this.activation && (a = this.activation.apply(a))), a;
    });
  }

  getConfig() {
    var e = {
      units: this.units,
      activation: serializeActivation(this.activation),
      useBias: this.useBias,
      kernelInitializer: serializeInitializer(this.kernelInitializer),
      biasInitializer: serializeInitializer(this.biasInitializer),
      kernelRegularizer: serializeRegularizer(this.kernelRegularizer),
      biasRegularizer: serializeRegularizer(this.biasRegularizer),
      activityRegularizer: serializeRegularizer(this.activityRegularizer),
      kernelConstraint: serializeConstraint(this.kernelConstraint),
      biasConstraint: serializeConstraint(this.biasConstraint)
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

Dense.className = "Dense", registerClass(Dense);

class Flatten extends Layer {
  constructor(e) {
    super(e = e || {}), this.inputSpec = [{
      minNDim: 3
    }], this.dataFormat = e.dataFormat;
  }

  computeOutputShape(e) {
    e = getExactlyOneShape(e);

    for (var t of e.slice(1)) {
      if (null == t) throw new ValueError("The shape of the input to \"Flatten\" is not fully defined (got ".concat(e.slice(1), "). Make sure to pass a complete \"input_shape\" or \"batch_input_shape\" argument to the first layer in your model."));
    }

    return [e[0], arrayProd(e, 1)];
  }

  call(e, t) {
    return tidy(() => {
      this.invokeCallHook(e, t);
      var n = getExactlyOneTensor(e);

      if ("channelsFirst" === this.dataFormat && n.rank > 1) {
        var _e749 = [0];

        for (var _t522 = 2; _t522 < n.rank; ++_t522) {
          _e749.push(_t522);
        }

        _e749.push(1), n = transpose$2(n, _e749);
      }

      return batchFlatten(n);
    });
  }

  getConfig() {
    var e = {};
    null != this.dataFormat && (e.dataFormat = this.dataFormat);
    var t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

Flatten.className = "Flatten", registerClass(Flatten);

class Activation extends Layer {
  constructor(e) {
    super(e), this.supportsMasking = !0, this.activation = getActivation(e.activation);
  }

  call(e, t) {
    return tidy(() => {
      this.invokeCallHook(e, t);
      var n = getExactlyOneTensor(e);
      return this.activation.apply(n);
    });
  }

  getConfig() {
    var e = {
      activation: serializeActivation(this.activation)
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

Activation.className = "Activation", registerClass(Activation);

class RepeatVector extends Layer {
  constructor(e) {
    super(e), this.n = e.n, this.inputSpec = [{
      ndim: 2
    }];
  }

  computeOutputShape(e) {
    return [e[0], this.n, e[1]];
  }

  call(e, t) {
    return tidy(() => repeat$1(e = getExactlyOneTensor(e), this.n));
  }

  getConfig() {
    var e = {
      n: this.n
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

RepeatVector.className = "RepeatVector", registerClass(RepeatVector);

class Reshape extends Layer {
  constructor(e) {
    super(e), this.targetShape = e.targetShape;

    for (var _e750 = 0; _e750 < this.targetShape.length; ++_e750) {
      this.isUnknown(this.targetShape[_e750]) && (this.targetShape[_e750] = null);
    }
  }

  isUnknown(e) {
    return e < 0 || null == e;
  }

  fixUnknownDimension(e, t) {
    var n = "Total size of new array must be unchanged.",
        r = t.slice();
    var a = 1,
        s = null;

    for (var _e751 = 0; _e751 < r.length; ++_e751) {
      var _t523 = r[_e751];

      if (this.isUnknown(_t523)) {
        if (null !== s) throw new ValueError("Can only specifiy one unknown dimension.");
        s = _e751;
      } else a *= _t523;
    }

    var o = arrayProd(e);

    if (null !== s) {
      if (0 === a || o % a != 0) throw new ValueError(n);
      r[s] = o / a;
    } else if (o !== a) throw new ValueError(n);

    return r;
  }

  computeOutputShape(e) {
    var t = !1;

    for (var n = 0; n < e.length; ++n) {
      if (this.isUnknown(e[n])) {
        t = !0;
        break;
      }
    }

    return t ? e.slice(0, 1).concat(this.targetShape) : e.slice(0, 1).concat(this.fixUnknownDimension(e.slice(1), this.targetShape));
  }

  call(e, t) {
    return tidy(() => {
      this.invokeCallHook(e, t);
      var n = getExactlyOneTensor(e),
          r = n.shape,
          a = r.slice(0, 1).concat(this.fixUnknownDimension(r.slice(1), this.targetShape));
      return reshape$3(n, a);
    });
  }

  getConfig() {
    var e = {
      targetShape: this.targetShape
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

Reshape.className = "Reshape", registerClass(Reshape);

class Permute extends Layer {
  constructor(e) {
    if (super(e), null == e.dims) throw new Error("Required configuration field `dims` is missing during Permute constructor call.");
    if (!Array.isArray(e.dims)) throw new Error("Permute constructor requires `dims` to be an Array, but received ".concat(e.dims, " instead."));
    var t = range$3(1, e.dims.length + 1);
    if (!arraysEqual(e.dims.slice().sort(), t)) throw new Error("Invalid permutation `dims`: " + JSON.stringify(e.dims) + " `dims` must contain consecutive integers starting from 1.");
    this.dims = e.dims, this.dimsIncludingBatch = [0].concat(this.dims), this.inputSpec = [new InputSpec({
      ndim: this.dims.length + 1
    })];
  }

  computeOutputShape(e) {
    var t = (e = getExactlyOneShape(e)).slice();
    return this.dims.forEach((n, r) => {
      t[r + 1] = e[n];
    }), t;
  }

  call(e, t) {
    return transpose$2(getExactlyOneTensor(e), this.dimsIncludingBatch);
  }

  getConfig() {
    var e = {
      dims: this.dims
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

Permute.className = "Permute", registerClass(Permute);

class Masking extends Layer {
  constructor(e) {
    super(null == e ? {} : e), this.supportsMasking = !0, this.maskValue = null != e ? null == e.maskValue ? 0 : e.maskValue : 0;
  }

  computeOutputShape(e) {
    return e;
  }

  getConfig() {
    var e = super.getConfig(),
        t = {
      maskValue: this.maskValue
    };
    return Object.assign(t, e), t;
  }

  computeMask(e, t) {
    var n = getExactlyOneTensor(e);
    return any$2(notEqual$2(n, this.maskValue), -1);
  }

  call(e, t) {
    return tidy(() => {
      this.invokeCallHook(e, t);
      var n = getExactlyOneTensor(e),
          r = any$2(notEqual$2(n, this.maskValue), -1, !0);
      return mul(n, cast$3(r, n.dtype));
    });
  }

}

Masking.className = "Masking", registerClass(Masking);

class Embedding extends Layer {
  constructor(e) {
    if (super(e), this.embeddings = null, this.DEFAULT_EMBEDDINGS_INITIALIZER = "randomUniform", null == e.batchInputShape && null == e.inputShape) {
      var t = null;
      null != e.batchSize && (t = e.batchSize), this.batchInputShape = null == e.inputLength ? [t, null] : [t].concat(toList(e.inputLength));
    }

    this.inputDim = e.inputDim, assertPositiveInteger(this.inputDim, "inputDim"), this.outputDim = e.outputDim, assertPositiveInteger(this.outputDim, "outputDim"), this.embeddingsInitializer = getInitializer(e.embeddingsInitializer || this.DEFAULT_EMBEDDINGS_INITIALIZER), this.embeddingsRegularizer = getRegularizer(e.embeddingsRegularizer), this.activityRegularizer = getRegularizer(e.activityRegularizer), this.embeddingsConstraint = getConstraint(e.embeddingsConstraint), this.maskZero = e.maskZero, this.supportsMasking = e.maskZero, this.inputLength = e.inputLength;
  }

  build(e) {
    this.embeddings = this.addWeight("embeddings", [this.inputDim, this.outputDim], this.dtype, this.embeddingsInitializer, this.embeddingsRegularizer, !0, this.embeddingsConstraint), this.built = !0;
  }

  warnOnIncompatibleInputShape(e) {}

  computeMask(e, t) {
    return tidy(() => this.maskZero ? (e = getExactlyOneTensor(e), notEqual$2(e, zerosLike$2(e))) : null);
  }

  computeOutputShape(e) {
    if (e = getExactlyOneShape(e), null == this.inputLength) return [...e, this.outputDim];
    var t = toList(this.inputLength);
    if (t.length !== e.length - 1) throw new ValueError("\"inputLength\" is ".concat(this.inputLength, ", but received input shape has shape ").concat(e));
    {
      var n = 0;

      for (var r = 0; r < t.length; ++r) {
        var a = t[r],
            s = e[r + 1];
        if (null != a && null != s && a !== s) throw new ValueError("\"inputLength\" is ".concat(this.inputLength, ", but received input shape has shape ").concat(e));
        null == a && (t[n] = s), n++;
      }
    }
    return [e[0], ...t, this.outputDim];
  }

  call(e, t) {
    return tidy(() => {
      this.invokeCallHook(e, t);
      var n = getExactlyOneTensor(e);
      "int32" !== n.dtype && (n = cast$2(n, "int32"));
      var r = gather(this.embeddings.read(), reshape$3(n, [n.size]));
      return reshape$3(r, getExactlyOneShape(this.computeOutputShape(n.shape)));
    });
  }

  getConfig() {
    var e = {
      inputDim: this.inputDim,
      outputDim: this.outputDim,
      embeddingsInitializer: serializeInitializer(this.embeddingsInitializer),
      embeddingsRegularizer: serializeRegularizer(this.embeddingsRegularizer),
      activityRegularizer: serializeRegularizer(this.activityRegularizer),
      embeddingsConstraint: serializeConstraint(this.embeddingsConstraint),
      maskZero: this.maskZero,
      inputLength: this.inputLength
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

Embedding.className = "Embedding", registerClass(Embedding);

class Merge extends Layer {
  constructor(e) {
    super(e || {}), this.supportsMasking = !0;
  }

  mergeFunction(e) {
    throw new NotImplementedError();
  }

  computeElementwiseOpOutputShape(e, t) {
    if (null == e || null == t) return null;
    if (e.length < t.length) return this.computeElementwiseOpOutputShape(t, e);
    if (0 === t.length) return e;
    var n = e.slice(0, e.length - t.length);

    for (var r = 0; r < t.length; ++r) {
      var a = e[e.length - t.length + r],
          s = t[r];
      if (null == a || null == s || a < 0 || s < 0) n.push(null);else if (1 === a) n.push(s);else if (1 === s) n.push(a);else {
        if (a !== s) throw new ValueError("Operands could not be broadcast together with shapes " + JSON.stringify(e) + " " + JSON.stringify(t));
        n.push(a);
      }
    }

    return n;
  }

  build(e) {
    if (Array.isArray(e) && !Array.isArray(e[0]) && (e = [getExactlyOneShape(e)]), (e = e).length < 2) throw new ValueError("A merge layer should be called on an Array of at least 2 inputs. Got ".concat(e.length, " input(s)."));
    var t = [];

    for (var _n293 of e) {
      null != _n293 && null !== _n293[0] && t.push(_n293[0]);
    }

    if (t = unique$2(t), t.length > 1) throw new ValueError("Can not merge tensors with different batch sizes. Got tensors with shapes: ".concat(JSON.stringify(e), "."));
    var n = null == e[0] ? null : e[0].slice(1);

    for (var _t524 = 1; _t524 < e.length; ++_t524) {
      var _r239 = null == e[_t524] ? null : e[_t524].slice(1);

      n = this.computeElementwiseOpOutputShape(n, _r239);
    }

    var r = e.map(e => e.length);
    this.reshapeRequired = -1 !== e.indexOf(null) || 1 !== unique$2(r).length;
  }

  call(e, t) {
    return tidy(() => {
      if (e = e, this.reshapeRequired) {
        var _t525 = [],
            n = e.map(e => e.rank);

        if (-1 === n.indexOf(null)) {
          var r = max$2(n);

          for (var _n294 of e) {
            var _e752 = _n294.rank;

            for (var _t526 = 0; _t526 < r - _e752; ++_t526) {
              _n294 = expandDims$2(_n294, 1);
            }

            _t525.push(_n294);
          }

          return this.mergeFunction(_t525);
        }

        {
          var _n295 = !1;

          for (var _r241 of e) {
            var _e753 = _r241.rank;

            if (null == _e753) {
              var _e754 = _r241.shape,
                  _a156 = _e754[0],
                  s = _e754.slice(1).concat([_a156]);

              var o = reshape$3(_r241, [_a156].concat(arrayProd(_e754.slice(1))));
              o = transpose$2(o, [1, 0]), o = reshape$3(o, s), _t525.push(o), _n295 = !0;
            } else if (_e753 > 1) {
              var _a157 = range$3(1, _e753).concat([0]);

              _t525.push(transpose$2(_r241, _a157)), _n295 = !0;
            } else _t525.push(_r241);
          }

          var _r240 = this.mergeFunction(_t525);

          var a = _r240.rank;
          if (_n295) if (null == a) {
            var _e755 = _r240.shape,
                _t527 = _e755[_e755.length - 1],
                _n296 = [_t527].concat(_e755.slice(0, _e755.length - 1));

            _r240 = reshape$3(transpose$2(reshape$3(_r240, [-1, _t527]), [1, 0]), _n296);
          } else if (a > 1) {
            var _e756 = [a - 1].concat(range$3(0, a - 1));

            _r240 = transpose$2(_r240, _e756);
          }
          return _r240;
        }
      }

      return this.mergeFunction(e);
    });
  }

  computeOutputShape(e) {
    var t;
    t = null == (e = e)[0] ? null : e[0].slice(1);

    for (var _n297 = 1; _n297 < e.length; ++_n297) {
      var r = null == e[_n297] ? null : e[_n297].slice(1);
      t = this.computeElementwiseOpOutputShape(t, r);
    }

    var n = [];

    for (var _t528 of e) {
      null != _t528 && null !== _t528[0] && n.push(_t528[0]);
    }

    return n = unique$2(n), t = 1 === n.length ? n.concat(t) : [null].concat(t), t;
  }

  computeMask(e, t) {
    return tidy(() => {
      if (null == t) return null;
      if (!Array.isArray(t)) throw new ValueError("`mask` should be an Array");
      if (!Array.isArray(e)) throw new ValueError("`inputs` should be an Array");
      if (t.length !== e.length) throw new ValueError("The Array 'inputs' and 'mask' are expected to have the same length, but have different lengths (".concat(e.length, " vs ").concat(t.length, ")"));
      if (t.every(e => null == e)) return null;
      var n = (t = t.map(e => null == e ? e : expandDims$3(e, 0)))[0];

      for (var _e757 = 1; _e757 < t.length - 1; ++_e757) {
        n = logicalAnd$2(n, t[_e757]);
      }

      return n;
    });
  }

}

class Add extends Merge {
  constructor(e) {
    super(e);
  }

  mergeFunction(e) {
    return tidy(() => {
      var t = e[0].clone();

      for (var n = 1; n < e.length; ++n) {
        t = add$2(t, e[n]);
      }

      return t;
    });
  }

}

Add.className = "Add", registerClass(Add);

class Multiply extends Merge {
  constructor(e) {
    super(e);
  }

  mergeFunction(e) {
    return tidy(() => {
      var t = e[0].clone();

      for (var n = 1; n < e.length; ++n) {
        t = mul(t, e[n]);
      }

      return t;
    });
  }

}

Multiply.className = "Multiply", registerClass(Multiply);

class Average extends Merge {
  constructor(e) {
    super(e);
  }

  mergeFunction(e) {
    return tidy(() => {
      var t = e[0].clone();

      for (var n = 1; n < e.length; ++n) {
        t = add$2(t, e[n]);
      }

      return mul(1 / e.length, t);
    });
  }

}

Average.className = "Average", registerClass(Average);

class Maximum extends Merge {
  constructor(e) {
    super(e);
  }

  mergeFunction(e) {
    return tidy(() => {
      var t = e[0];

      for (var n = 1; n < e.length; ++n) {
        t = maximum$3(t, e[n]);
      }

      return t;
    });
  }

}

Maximum.className = "Maximum", registerClass(Maximum);

class Minimum extends Merge {
  constructor(e) {
    super(e);
  }

  mergeFunction(e) {
    return tidy(() => {
      var t = e[0];

      for (var n = 1; n < e.length; ++n) {
        t = minimum$3(t, e[n]);
      }

      return t;
    });
  }

}

Minimum.className = "Minimum", registerClass(Minimum);

class Concatenate extends Merge {
  constructor(e) {
    super(e), this.DEFAULT_AXIS = -1, null == e && (e = {}), this.axis = null == e.axis ? this.DEFAULT_AXIS : e.axis, this.supportsMasking = !0, this.reshapeRequired = !1;
  }

  build(e) {
    if (!Array.isArray(e) || !Array.isArray(e[0]) || 1 === e.length) throw new ValueError("A `Concatenate` layer should be called on a list of at least 2 inputs");
    e = e;
    var t = !0;

    for (var _n298 of e) {
      if (null != _n298) {
        t = !1;
        break;
      }
    }

    if (t) return;
    var n = [];

    for (var _t529 = 0; _t529 < e.length; ++_t529) {
      var r = e[_t529].slice();

      r.splice(this.axis, 1);
      var a = !1;

      for (var _e758 of n) {
        if (arraysEqual(_e758, r)) {
          a = !0;
          break;
        }
      }

      a || n.push(r);
    }

    if (n.length > 1) throw new ValueError("A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got input shapes: " + JSON.stringify(e));
  }

  mergeFunction(e) {
    return tidy(() => concatenate$1(e, this.axis));
  }

  computeOutputShape(e) {
    if (!Array.isArray(e) || !Array.isArray(e[0])) throw new ValueError("A `Concatenate` layer should be called on a list of inputs.");
    var t = e,
        n = t[0].slice(),
        r = this.axis < 0 ? n.length + this.axis : this.axis;

    for (var _e759 of t.slice(1)) {
      if (null == n[r] || null == _e759[r]) {
        n[r] = null;
        break;
      }

      n[r] += _e759[r];
    }

    return n;
  }

  computeMask(e, t) {
    if (null == t) return null;
    if (!Array.isArray(t)) throw new ValueError("`mask` should be an array for Concatenate");
    if (!Array.isArray(e)) throw new ValueError("`inputs` should be an array for Concatenate");
    if (t.length !== e.length) throw new ValueError("Mismatch in the length of mask (".concat(t.length, ") and the legnth of inputs (").concat(e.length, ")"));
    return tidy(() => {
      var n = !0;
      if (t.forEach(e => {
        null == e || (n = !1);
      }), n) return null;
      var r = [];

      for (var _n299 = 0; _n299 < e.length; ++_n299) {
        r.push(null == t[_n299] ? cast$3(onesLike$2(e[_n299]), "bool") : t[_n299].rank < e[_n299].rank ? expandDims$3(t[_n299], -1) : t[_n299]);
      }

      var a = concat$2(r, this.axis);
      return all$2(a, -1, !1);
    });
  }

  getConfig() {
    var e = {
      axis: this.axis
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

function interpretAxis(e, t) {
  for (; e < 0;) {
    e += t;
  }

  return e;
}

function batchDot(e, t, n) {
  if (e.shape.length > 3 || t.shape.length > 3) throw new NotImplementedError("batchDot is not implemented for tensors of 4D or higher rank yet");
  if (assert$4(e.shape.length >= 2, () => "batchDot requires the rank of x to be >= 2, but got ".concat(e.shape.length)), assert$4(e.shape.length >= 2, () => "batchDot requires the rank of y to be >= 2, but got ".concat(t.shape.length)), "number" == typeof n && (n = [n, n]), "complex64" === e.dtype || "complex64" === t.dtype) throw new NotImplementedError("batchDot is not implemented for complex64-type Tensors yet.");
  var r = e.shape.length,
      a = t.shape.length;
  null == n && (n = [r - 1, a - 2]);
  var s = n;
  return tidy(() => {
    var n, o;

    if (r > a) {
      n = r - a;
      var _e760 = [];

      for (var _t530 = 0; _t530 < n; ++_t530) {
        _e760.push(1);
      }

      t = reshape$3(t, t.shape.concat(_e760));
    } else if (a > r) {
      n = a - r;
      var _t531 = [];

      for (var _e761 = 0; _e761 < n; ++_e761) {
        _t531.push(1);
      }

      e = reshape$3(e, e.shape.concat(_t531));
    } else n = 0;

    if (o = 2 === e.shape.length && 2 === t.shape.length ? s[0] === s[1] ? sum$2(mul(e, t), s[0]) : sum$2(mul(transpose$2(e, [1, 0]), t), s[1]) : matMul$1(e, t, s[0] !== e.shape.length - 1, s[1] === t.shape.length - 1), n > 0) {
      var _e762;

      _e762 = r > a ? r + a - 3 : r - 1;
      var _t532 = [];

      for (var _r242 = _e762; _r242 < _e762 + n; ++_r242) {
        _t532.push(_r242);
      }

      o = squeeze(o, _t532);
    }

    return 1 === o.shape.length && (o = expandDims$3(o, 1)), o;
  });
}

Concatenate.className = "Concatenate", registerClass(Concatenate);

class Dot extends Merge {
  constructor(e) {
    super(e), this.axes = e.axes, this.normalize = null != e.normalize && e.normalize, this.supportsMasking = !0, this.reshapeRequired = !1;
  }

  build(e) {
    assert$4(Array.isArray(e) && 2 === e.length && Array.isArray(e[0]) && Array.isArray(e[1]), () => "A `Dot` layer should be called on a list of exactly 2 inputs.");
    var t = e[0],
        n = e[1];
    if (t.length > 3 || n.length > 3) throw new NotImplementedError("Dot layer does not support tensors of 4D or higher rank yet.");
    var r = this.interpretAxes(t, n);
    if (t[r[0]] !== n[r[1]]) throw new ValueError("Dimension incompatibility: ".concat(t[r[0]], " !== ").concat(n[r[1]]));
  }

  mergeFunction(e) {
    if (2 !== e.length) throw new ValueError("A `Dot` layer must be called on exactly 2 inputs, but received ".concat(e.length, " input(s)."));
    var t,
        n = e[0],
        r = e[1];
    return t = Array.isArray(this.axes) ? this.axes.map((t, n) => interpretAxis(t, e[n].shape.length)) : [interpretAxis(this.axes, n.shape.length), interpretAxis(this.axes, r.shape.length)], this.normalize && (n = l2Normalize(n, t[0]), r = l2Normalize(r, t[1])), batchDot(n, r, t);
  }

  interpretAxes(e, t) {
    var n;
    return n = Array.isArray(this.axes) ? this.axes : [interpretAxis(this.axes, e.length), interpretAxis(this.axes, t.length)], n;
  }

  computeOutputShape(e) {
    assert$4(Array.isArray(e) && 2 === e.length && Array.isArray(e[0]) && Array.isArray(e[1]), () => "A `Dot` layer should be called on a list of exactly 2 inputs.");
    var t = e[0].slice(),
        n = e[1].slice();
    if (t.length > 3 || n.length > 3) throw new NotImplementedError("Dot layer does not support tensors of 4D or higher rank yet.");
    var r = this.interpretAxes(t, n);
    t.splice(r[0], 1), n.splice(r[1], 1), n.splice(0, 1);
    var a = t.concat(n);
    return 1 === a.length && a.push(1), a;
  }

  computeMask(e, t) {
    return null;
  }

  getConfig() {
    var e = {
      axes: this.axes,
      normalize: this.normalize
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

Dot.className = "Dot", registerClass(Dot);

class GaussianNoise extends Layer {
  constructor(e) {
    super(e), this.supportsMasking = !0, this.stddev = e.stddev;
  }

  computeOutputShape(e) {
    return e;
  }

  getConfig() {
    var e = super.getConfig(),
        t = {
      stddev: this.stddev
    };
    return Object.assign(t, e), t;
  }

  call(e, t) {
    return tidy(() => {
      this.invokeCallHook(e, t);
      var n = getExactlyOneTensor(e);
      return inTrainPhase(() => add$2(randomNormal$1(n.shape, 0, this.stddev), n), () => n, t.training || !1);
    });
  }

}

GaussianNoise.className = "GaussianNoise", registerClass(GaussianNoise);

class GaussianDropout extends Layer {
  constructor(e) {
    super(e), this.supportsMasking = !0, this.rate = e.rate;
  }

  computeOutputShape(e) {
    return e;
  }

  getConfig() {
    var e = super.getConfig(),
        t = {
      rate: this.rate
    };
    return Object.assign(t, e), t;
  }

  call(e, t) {
    return tidy(() => {
      this.invokeCallHook(e, t);
      var n = getExactlyOneTensor(e);
      return this.rate > 0 && this.rate < 1 ? inTrainPhase(() => {
        var e = Math.sqrt(this.rate / (1 - this.rate));
        return mul(n, randomNormal$1(n.shape, 1, e));
      }, () => n, t.training || !1) : n;
    });
  }

}

GaussianDropout.className = "GaussianDropout", registerClass(GaussianDropout);

class AlphaDropout extends Layer {
  constructor(e) {
    super(e), this.supportsMasking = !0, this.rate = e.rate, this.noiseShape = e.noiseShape;
  }

  _getNoiseShape(e) {
    return this.noiseShape || getExactlyOneTensor(e).shape;
  }

  computeOutputShape(e) {
    return e;
  }

  getConfig() {
    var e = super.getConfig(),
        t = {
      rate: this.rate
    };
    return Object.assign(t, e), t;
  }

  call(e, t) {
    return tidy(() => {
      if (this.rate < 1 && this.rate > 0) {
        var n = this._getNoiseShape(e),
            r = () => {
          var t = getExactlyOneTensor(e),
              r = -1.7580993408473766;
          var a = greaterEqual$2(randomUniform$1(n), this.rate);
          a = cast$2(a, "float32");
          var s = ((1 - this.rate) * (1 + this.rate * r ** 2)) ** -.5,
              o = -s * r * this.rate,
              i = add$2(mul(t, a), mul(add$2(a, -1), r));
          return add$2(mul(i, s), o);
        };

        return inTrainPhase(r, () => getExactlyOneTensor(e), t.training || !1);
      }

      return e;
    });
  }

}

function batchNormalization$1(e, t, n, r, a) {
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : .001;
  var o;
  if (2 === e.rank) o = batchNorm2d(e, t, n, r, a, s);else if (3 === e.rank) o = batchNorm3d(e, t, n, r, a, s);else {
    if (4 !== e.rank) throw new NotImplementedError("batchNormalization is not implemented for array of rank ".concat(e.rank, " yet"));
    o = batchNorm4d(e, t, n, r, a, s);
  }
  return o;
}

function regularNormalizeBatchInTraining(e, t, n, r) {
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : .001;
  return tidy(() => {
    var s = moments(e, r),
        o = s.mean,
        i = s.variance;
    return [batchNormalization$1(e, o, i, n, t, a), o, i];
  });
}

function broadcastNormalizeBatchInTraining(e, t, n, r) {
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : .001;
  return tidy(() => {
    var s = moments(e, r),
        o = s.mean,
        i = s.variance,
        l = [];

    for (var _t533 of range$3(0, e.rank)) {
      -1 !== r.indexOf(_t533) ? l.push(1) : l.push(e.shape[_t533]);
    }

    var u = reshape$3(o, l),
        c = reshape$3(i, l),
        p = null == t ? null : reshape$3(t, l),
        d = null == n ? null : reshape$3(n, l);
    return [batchNormalization$1(e, u, c, d, p, a), o, i];
  });
}

function normalizeBatchInTraining(e, t, n, r) {
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : .001;
  return arraysEqual(r.slice().sort(), range$3(0, e.rank - 1)) ? regularNormalizeBatchInTraining(e, t, n, r, a) : broadcastNormalizeBatchInTraining(e, t, n, r, a);
}

AlphaDropout.className = "AlphaDropout", registerClass(AlphaDropout);

class BatchNormalization extends Layer {
  constructor(e) {
    null == e && (e = {}), super(e), this.supportsMasking = !0, this.axis = null == e.axis ? -1 : e.axis, this.momentum = null == e.momentum ? .99 : e.momentum, this.epsilon = null == e.epsilon ? .001 : e.epsilon, this.center = null == e.center || e.center, this.scale = null == e.scale || e.scale, this.betaInitializer = getInitializer(e.betaInitializer || "zeros"), this.gammaInitializer = getInitializer(e.gammaInitializer || "ones"), this.movingMeanInitializer = getInitializer(e.movingMeanInitializer || "zeros"), this.movingVarianceInitializer = getInitializer(e.movingVarianceInitializer || "ones"), this.betaConstraint = getConstraint(e.betaConstraint), this.gammaConstraint = getConstraint(e.gammaConstraint), this.betaRegularizer = getRegularizer(e.betaRegularizer), this.gammaRegularizer = getRegularizer(e.gammaRegularizer);
  }

  build(e) {
    e = getExactlyOneShape(e);
    var t = this.axis >= 0 ? this.axis : this.axis + e.length,
        n = e[t];
    if (null == n) throw new ValueError("Axis ".concat(t, " of input tensor should have a defined dimension but the layer received an input with shape ").concat(JSON.stringify(e), "."));
    this.inputSpec = [new InputSpec({
      ndim: e.length,
      axes: {
        [t]: n
      }
    })];
    var r = [n];
    this.scale && (this.gamma = this.addWeight("gamma", r, null, this.gammaInitializer, this.gammaRegularizer, !0, this.gammaConstraint)), this.center && (this.beta = this.addWeight("beta", r, null, this.betaInitializer, this.betaRegularizer, !0, this.betaConstraint)), this.movingMean = this.addWeight("moving_mean", r, null, this.movingMeanInitializer, null, !1), this.movingVariance = this.addWeight("moving_variance", r, null, this.movingVarianceInitializer, null, !1), this.built = !0;
  }

  call(e, t) {
    return tidy(() => {
      var n = null != t.training && t.training,
          r = getExactlyOneTensor(e),
          a = r.shape,
          s = a.length,
          o = range$3(0, s),
          i = this.axis >= 0 ? this.axis : this.axis + s;
      o.splice(i, 1);
      var l = pyListRepeat(1, s);
      l[i] = a[i];
      var u = o.slice();
      u.sort();
      var c = !arraysEqual(u, range$3(0, s).slice(0, s - 1));
      if (!n) return (() => {
        if (c) {
          var _e763 = reshape$3(this.movingMean.read(), l),
              _t534 = reshape$3(this.movingVariance.read(), l),
              _n300 = this.center ? reshape$3(this.beta.read(), l) : null,
              _a158 = this.scale ? reshape$3(this.gamma.read(), l) : null;

          return batchNormalization$1(r, _e763, _t534, _n300, _a158, this.epsilon);
        }

        return batchNormalization$1(r, this.movingMean.read(), this.movingVariance.read(), null == this.beta ? null : this.beta.read(), null == this.gamma ? null : this.gamma.read(), this.epsilon);
      })();

      var [p, d, h] = normalizeBatchInTraining(r, this.gamma.read(), this.beta.read(), o, this.epsilon),
          m = (e, t, n) => {
        tidy(() => {
          var r = 1 - n,
              a = e.read(),
              s = mul(sub$2(a, t), r);
          e.write(sub$2(a, s));
        });
      };

      return (() => {
        m(this.movingMean, d, this.momentum), m(this.movingVariance, h, this.momentum);
      })(), p;
    });
  }

  getConfig() {
    var e = {
      axis: this.axis,
      momentum: this.momentum,
      epsilon: this.epsilon,
      center: this.center,
      scale: this.scale,
      betaInitializer: serializeInitializer(this.betaInitializer),
      gammaInitializer: serializeInitializer(this.gammaInitializer),
      movingMeanInitializer: serializeInitializer(this.movingMeanInitializer),
      movingVarianceInitializer: serializeInitializer(this.movingVarianceInitializer),
      betaRegularizer: serializeRegularizer(this.betaRegularizer),
      gammaRegularizer: serializeRegularizer(this.gammaRegularizer),
      betaConstraint: serializeConstraint(this.betaConstraint),
      gammaConstraint: serializeConstraint(this.gammaConstraint)
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

BatchNormalization.className = "BatchNormalization", registerClass(BatchNormalization);

class LayerNormalization extends Layer {
  constructor(e) {
    if (null == e && (e = {}), super(e), this.axis = null == e.axis ? -1 : e.axis, "number" == typeof this.axis) {
      if (!Number.isInteger(this.axis)) throw new Error("Expected axis to be an integer, but received ".concat(this.axis));
    } else {
      if (!Array.isArray(this.axis)) throw new Error("Expected axis to be an integer or an array of integers, but received ".concat(JSON.stringify(this.axis)));

      for (var _e764 of this.axis) {
        if (!Number.isInteger(_e764)) throw new Error("Expected axis to be an array of integers, but received ".concat(JSON.stringify(this.axis)));
      }
    }

    this.epsilon = null == e.epsilon ? .001 : e.epsilon, this.center = null == e.center || e.center, this.scale = null == e.scale || e.scale, this.betaInitializer = getInitializer(e.betaInitializer || "zeros"), this.gammaInitializer = getInitializer(e.gammaInitializer || "ones"), this.betaRegularizer = getRegularizer(e.betaRegularizer), this.gammaRegularizer = getRegularizer(e.gammaRegularizer), this.supportsMasking = !0;
  }

  build(e) {
    var t = (e = getExactlyOneShape(e)).length;
    "number" == typeof this.axis && (this.axis = [this.axis]);

    for (var _e765 = 0; _e765 < this.axis.length; ++_e765) {
      this.axis[_e765] < 0 && (this.axis[_e765] += t);
    }

    for (var _e766 of this.axis) {
      if (_e766 < 0 || _e766 >= t) throw new Error("Invalid axis: ".concat(_e766));
    }

    if (this.axis.length !== unique$2(this.axis).length) throw new Error("Found duplicate axes in: ".concat(this.axis));
    var n = this.axis.map(t => e[t]);
    this.gamma = this.scale ? this.addWeight("gamma", n, "float32", this.gammaInitializer, this.gammaRegularizer, !0) : null, this.beta = this.center ? this.addWeight("beta", n, "float32", this.betaInitializer, this.betaRegularizer, !0) : null, this.built = !0;
  }

  call(e, t) {
    var n = getExactlyOneTensor(e),
        r = n.shape,
        a = r.length;
    return tidy(() => {
      var {
        mean: e,
        variance: t
      } = moments(n, this.axis, !0);
      var s = pyListRepeat(1, a);

      for (var _e767 of this.axis) {
        s[_e767] = r[_e767];
      }

      var o = e => null != e && e.shape.length !== a && this.axis !== [a - 1] ? reshape$3(e, s) : e;

      var i = o(this.gamma.read()),
          l = o(this.beta.read());
      var u = [],
          c = [];

      for (var _e768 = 0; _e768 < a; ++_e768) {
        -1 !== this.axis.indexOf(_e768) ? (u.push(r[_e768]), c.push(1)) : (u.push(1), c.push(r[_e768]));
      }

      return e = tile$3(e, u), t = tile$3(t, u), i = tile$3(i, c), l = tile$3(l, c), batchNormalization$1(n, e, t, l, i, this.epsilon);
    });
  }

  getConfig() {
    var e = {
      axis: this.axis,
      epsilon: this.epsilon,
      center: this.center,
      scale: this.scale,
      betaInitializer: serializeInitializer(this.betaInitializer),
      gammaInitializer: serializeInitializer(this.gammaInitializer),
      betaRegularizer: serializeRegularizer(this.betaRegularizer),
      gammaRegularizer: serializeRegularizer(this.gammaRegularizer)
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

function spatial2dPadding(e, t, n) {
  return tidy(() => {
    if (4 !== e.rank) throw new ValueError("temporalPadding expects input tensor to be 4-D, but received a ".concat(e.rank, "-D tensor."));
    if (null == t && (t = [[1, 1], [1, 1]]), 2 !== t.length || 2 !== t[0].length || 2 !== t[1].length) throw new ValueError("spatial2dPadding expects `padding` to be an Array of two Arrays, each of which is an Array of two integers.");
    if (null == n && (n = imageDataFormat()), "channelsLast" !== n && "channelsFirst" !== n) throw new ValueError("Unknown data format: ".concat(n, ". Supported data formats are 'channelsLast' and 'channelsFirst."));
    var r;
    return r = "channelsFirst" === n ? [[0, 0], [0, 0], t[0], t[1]] : [[0, 0], t[0], t[1], [0, 0]], pad(e, r);
  });
}

LayerNormalization.className = "LayerNormalization", registerClass(LayerNormalization);

class ZeroPadding2D extends Layer {
  constructor(e) {
    if (null == e && (e = {}), super(e), this.dataFormat = null == e.dataFormat ? imageDataFormat() : e.dataFormat, null == e.padding) this.padding = [[1, 1], [1, 1]];else if ("number" == typeof e.padding) this.padding = [[e.padding, e.padding], [e.padding, e.padding]];else {
      if (e.padding = e.padding, 2 !== e.padding.length) throw new ValueError("ZeroPadding2D expects padding to be a length-2 array, but received a length-".concat(e.padding.length, " array."));
      var t, n;
      if ("number" == typeof e.padding[0]) t = [e.padding[0], e.padding[0]], n = [e.padding[1], e.padding[1]];else {
        if (e.padding = e.padding, 2 !== e.padding[0].length) throw new ValueError("ZeroPadding2D expects height padding to be a length-2 array, but received a length-".concat(e.padding[0].length, " array."));
        if (t = e.padding[0], 2 !== e.padding[1].length) throw new ValueError("ZeroPadding2D expects width padding to be a length-2 array, but received a length-".concat(e.padding[1].length, " array."));
        n = e.padding[1];
      }
      this.padding = [t, n];
    }
    this.inputSpec = [new InputSpec({
      ndim: 4
    })];
  }

  computeOutputShape(e) {
    var t, n;
    return e = getExactlyOneShape(e), "channelsFirst" === this.dataFormat ? (t = null != e[2] && e[2] >= 0 ? e[2] + this.padding[0][0] + this.padding[0][1] : null, n = null != e[3] && e[3] >= 0 ? e[3] + this.padding[1][0] + this.padding[1][1] : null, [e[0], e[1], t, n]) : (t = null != e[1] && e[1] >= 0 ? e[1] + this.padding[0][0] + this.padding[0][1] : null, n = null != e[2] && e[2] >= 0 ? e[2] + this.padding[1][0] + this.padding[1][1] : null, [e[0], t, n, e[3]]);
  }

  call(e, t) {
    return tidy(() => spatial2dPadding(getExactlyOneTensor(e), this.padding, this.dataFormat));
  }

  getConfig() {
    var e = {
      padding: this.padding,
      dataFormat: this.dataFormat
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

function pool2d(e, t, n, r, a, s) {
  return tidy(() => {
    var o;
    checkDataFormat(a), checkPoolMode(s), checkPaddingMode(r), null == n && (n = [1, 1]), null == r && (r = "valid"), null == a && (a = imageDataFormat()), null == s && (s = "max"), e = preprocessConv2DInput(e, a);
    var i = "same" === r ? "same" : "valid";
    return o = "max" === s ? maxPool$2(e, t, n, i) : avgPool$2(e, t, n, i), "channelsFirst" === a && (o = transpose$2(o, [0, 3, 1, 2])), o;
  });
}

function pool3d$1(e, t, n, r, a, s) {
  return tidy(() => {
    var o;
    checkDataFormat(a), checkPoolMode(s), checkPaddingMode(r), null == n && (n = [1, 1, 1]), null == r && (r = "valid"), null == a && (a = imageDataFormat()), null == s && (s = "max"), e = preprocessConv3DInput(e, a);
    var i = "same" === r ? "same" : "valid";
    return o = "max" === s ? maxPool3d$1(e, t, n, i) : avgPool3d$1(e, t, n, i), "channelsFirst" === a && (o = transpose$2(o, [0, 4, 1, 2, 3])), o;
  });
}

ZeroPadding2D.className = "ZeroPadding2D", registerClass(ZeroPadding2D);

class Pooling1D extends Layer {
  constructor(e) {
    if (null == e.poolSize && (e.poolSize = 2), super(e), "number" == typeof e.poolSize) this.poolSize = [e.poolSize];else {
      if (!Array.isArray(e.poolSize) || 1 !== e.poolSize.length || "number" != typeof e.poolSize[0]) throw new ValueError("poolSize for 1D convolutional layer must be a number or an Array of a single number, but received ".concat(JSON.stringify(e.poolSize)));
      this.poolSize = e.poolSize;
    }
    if (assertPositiveInteger(this.poolSize, "poolSize"), null == e.strides) this.strides = this.poolSize;else if ("number" == typeof e.strides) this.strides = [e.strides];else {
      if (!Array.isArray(e.strides) || 1 !== e.strides.length || "number" != typeof e.strides[0]) throw new ValueError("strides for 1D convolutional layer must be a number or an Array of a single number, but received ".concat(JSON.stringify(e.strides)));
      this.strides = e.strides;
    }
    assertPositiveInteger(this.strides, "strides"), this.padding = null == e.padding ? "valid" : e.padding, checkPaddingMode(this.padding), this.inputSpec = [new InputSpec({
      ndim: 3
    })];
  }

  computeOutputShape(e) {
    var t = convOutputLength((e = getExactlyOneShape(e))[1], this.poolSize[0], this.padding, this.strides[0]);
    return [e[0], t, e[2]];
  }

  call(e, t) {
    return tidy(() => {
      this.invokeCallHook(e, t), e = expandDims$2(getExactlyOneTensor(e), 2);
      var n = this.poolingFunction(getExactlyOneTensor(e), [this.poolSize[0], 1], [this.strides[0], 1], this.padding, "channelsLast");
      return squeeze(n, [2]);
    });
  }

  getConfig() {
    var e = {
      poolSize: this.poolSize,
      padding: this.padding,
      strides: this.strides
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

class MaxPooling1D extends Pooling1D {
  constructor(e) {
    super(e);
  }

  poolingFunction(e, t, n, r, a) {
    return checkDataFormat(a), checkPaddingMode(r), pool2d(e, t, n, r, a, "max");
  }

}

MaxPooling1D.className = "MaxPooling1D", registerClass(MaxPooling1D);

class AveragePooling1D extends Pooling1D {
  constructor(e) {
    super(e);
  }

  poolingFunction(e, t, n, r, a) {
    return checkDataFormat(a), checkPaddingMode(r), pool2d(e, t, n, r, a, "avg");
  }

}

AveragePooling1D.className = "AveragePooling1D", registerClass(AveragePooling1D);

class Pooling2D extends Layer {
  constructor(e) {
    if (null == e.poolSize && (e.poolSize = [2, 2]), super(e), this.poolSize = Array.isArray(e.poolSize) ? e.poolSize : [e.poolSize, e.poolSize], null == e.strides) this.strides = this.poolSize;else if (Array.isArray(e.strides)) {
      if (2 !== e.strides.length) throw new ValueError("If the strides property of a 2D pooling layer is an Array, it is expected to have a length of 2, but received length ".concat(e.strides.length, "."));
      this.strides = e.strides;
    } else this.strides = [e.strides, e.strides];
    assertPositiveInteger(this.poolSize, "poolSize"), assertPositiveInteger(this.strides, "strides"), this.padding = null == e.padding ? "valid" : e.padding, this.dataFormat = null == e.dataFormat ? "channelsLast" : e.dataFormat, checkDataFormat(this.dataFormat), checkPaddingMode(this.padding), this.inputSpec = [new InputSpec({
      ndim: 4
    })];
  }

  computeOutputShape(e) {
    e = getExactlyOneShape(e);
    var t = "channelsFirst" === this.dataFormat ? e[2] : e[1],
        n = "channelsFirst" === this.dataFormat ? e[3] : e[2];
    return t = convOutputLength(t, this.poolSize[0], this.padding, this.strides[0]), n = convOutputLength(n, this.poolSize[1], this.padding, this.strides[1]), "channelsFirst" === this.dataFormat ? [e[0], e[1], t, n] : [e[0], t, n, e[3]];
  }

  call(e, t) {
    return tidy(() => (this.invokeCallHook(e, t), this.poolingFunction(getExactlyOneTensor(e), this.poolSize, this.strides, this.padding, this.dataFormat)));
  }

  getConfig() {
    var e = {
      poolSize: this.poolSize,
      padding: this.padding,
      strides: this.strides,
      dataFormat: this.dataFormat
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

class MaxPooling2D extends Pooling2D {
  constructor(e) {
    super(e);
  }

  poolingFunction(e, t, n, r, a) {
    return checkDataFormat(a), checkPaddingMode(r), pool2d(e, t, n, r, a, "max");
  }

}

MaxPooling2D.className = "MaxPooling2D", registerClass(MaxPooling2D);

class AveragePooling2D extends Pooling2D {
  constructor(e) {
    super(e);
  }

  poolingFunction(e, t, n, r, a) {
    return checkDataFormat(a), checkPaddingMode(r), pool2d(e, t, n, r, a, "avg");
  }

}

AveragePooling2D.className = "AveragePooling2D", registerClass(AveragePooling2D);

class Pooling3D extends Layer {
  constructor(e) {
    if (null == e.poolSize && (e.poolSize = [2, 2, 2]), super(e), this.poolSize = Array.isArray(e.poolSize) ? e.poolSize : [e.poolSize, e.poolSize, e.poolSize], null == e.strides) this.strides = this.poolSize;else if (Array.isArray(e.strides)) {
      if (3 !== e.strides.length) throw new ValueError("If the strides property of a 3D pooling layer is an Array, it is expected to have a length of 3, but received length ".concat(e.strides.length, "."));
      this.strides = e.strides;
    } else this.strides = [e.strides, e.strides, e.strides];
    assertPositiveInteger(this.poolSize, "poolSize"), assertPositiveInteger(this.strides, "strides"), this.padding = null == e.padding ? "valid" : e.padding, this.dataFormat = null == e.dataFormat ? "channelsLast" : e.dataFormat, checkDataFormat(this.dataFormat), checkPaddingMode(this.padding), this.inputSpec = [new InputSpec({
      ndim: 5
    })];
  }

  computeOutputShape(e) {
    e = getExactlyOneShape(e);
    var t = "channelsFirst" === this.dataFormat ? e[2] : e[1],
        n = "channelsFirst" === this.dataFormat ? e[3] : e[2],
        r = "channelsFirst" === this.dataFormat ? e[4] : e[3];
    return t = convOutputLength(t, this.poolSize[0], this.padding, this.strides[0]), n = convOutputLength(n, this.poolSize[1], this.padding, this.strides[1]), r = convOutputLength(r, this.poolSize[2], this.padding, this.strides[2]), "channelsFirst" === this.dataFormat ? [e[0], e[1], t, n, r] : [e[0], t, n, r, e[4]];
  }

  call(e, t) {
    return tidy(() => (this.invokeCallHook(e, t), this.poolingFunction(getExactlyOneTensor(e), this.poolSize, this.strides, this.padding, this.dataFormat)));
  }

  getConfig() {
    var e = {
      poolSize: this.poolSize,
      padding: this.padding,
      strides: this.strides,
      dataFormat: this.dataFormat
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

class MaxPooling3D extends Pooling3D {
  constructor(e) {
    super(e);
  }

  poolingFunction(e, t, n, r, a) {
    return checkDataFormat(a), checkPaddingMode(r), pool3d$1(e, t, n, r, a, "max");
  }

}

MaxPooling3D.className = "MaxPooling3D", registerClass(MaxPooling3D);

class AveragePooling3D extends Pooling3D {
  constructor(e) {
    super(e);
  }

  poolingFunction(e, t, n, r, a) {
    return checkDataFormat(a), checkPaddingMode(r), pool3d$1(e, t, n, r, a, "avg");
  }

}

AveragePooling3D.className = "AveragePooling3D", registerClass(AveragePooling3D);

class GlobalPooling1D extends Layer {
  constructor(e) {
    super(e), this.inputSpec = [new InputSpec({
      ndim: 3
    })];
  }

  computeOutputShape(e) {
    return [e[0], e[2]];
  }

  call(e, t) {
    throw new NotImplementedError();
  }

}

class GlobalAveragePooling1D extends GlobalPooling1D {
  constructor(e) {
    super(e || {});
  }

  call(e, t) {
    return tidy(() => {
      var t = getExactlyOneTensor(e);
      return mean$1(t, 1);
    });
  }

}

GlobalAveragePooling1D.className = "GlobalAveragePooling1D", registerClass(GlobalAveragePooling1D);

class GlobalMaxPooling1D extends GlobalPooling1D {
  constructor(e) {
    super(e || {});
  }

  call(e, t) {
    return tidy(() => {
      var t = getExactlyOneTensor(e);
      return max$3(t, 1);
    });
  }

}

GlobalMaxPooling1D.className = "GlobalMaxPooling1D", registerClass(GlobalMaxPooling1D);

class GlobalPooling2D extends Layer {
  constructor(e) {
    super(e), this.dataFormat = null == e.dataFormat ? "channelsLast" : e.dataFormat, checkDataFormat(this.dataFormat), this.inputSpec = [new InputSpec({
      ndim: 4
    })];
  }

  computeOutputShape(e) {
    return e = e, "channelsLast" === this.dataFormat ? [e[0], e[3]] : [e[0], e[1]];
  }

  call(e, t) {
    throw new NotImplementedError();
  }

  getConfig() {
    var e = {
      dataFormat: this.dataFormat
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

}

class GlobalAveragePooling2D extends GlobalPooling2D {
  call(e, t) {
    return tidy(() => {
      var t = getExactlyOneTensor(e);
      return mean$1(t, "channelsLast" === this.dataFormat ? [1, 2] : [2, 3]);
    });
  }

}

GlobalAveragePooling2D.className = "GlobalAveragePooling2D", registerClass(GlobalAveragePooling2D);

class GlobalMaxPooling2D extends GlobalPooling2D {
  call(e, t) {
    return tidy(() => {
      var t = getExactlyOneTensor(e);
      return max$3(t, "channelsLast" === this.dataFormat ? [1, 2] : [2, 3]);
    });
  }

}

GlobalMaxPooling2D.className = "GlobalMaxPooling2D", registerClass(GlobalMaxPooling2D);

class Wrapper extends Layer {
  constructor(e) {
    super(e), this.layer = e.layer;
  }

  build(e) {
    this.built = !0;
  }

  get trainable() {
    return null != this.layer && this.layer.trainable;
  }

  set trainable(e) {
    null != this.layer && (this.layer.trainable = e);
  }

  get trainableWeights() {
    return this.layer.trainableWeights;
  }

  get nonTrainableWeights() {
    return this.layer.nonTrainableWeights;
  }

  get updates() {
    return this.layer._updates;
  }

  get losses() {
    return this.layer.losses;
  }

  getWeights() {
    return this.layer.getWeights();
  }

  setWeights(e) {
    this.layer.setWeights(e);
  }

  getConfig() {
    var e = {
      layer: {
        className: this.layer.getClassName(),
        config: this.layer.getConfig()
      }
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

  setFastWeightInitDuringBuild(e) {
    super.setFastWeightInitDuringBuild(e), null != this.layer && this.layer.setFastWeightInitDuringBuild(e);
  }

  static fromConfig(e, t) {
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};
    var r = deserialize(t.layer, n);
    delete t.layer;
    var a = {
      layer: r
    };
    return Object.assign(a, t), new e(a);
  }

}

class TimeDistributed extends Wrapper {
  constructor(e) {
    super(e), this.supportsMasking = !0;
  }

  build(e) {
    if ((e = getExactlyOneShape(e)).length < 3) throw new ValueError("TimeDistributed layer expects an input shape >= 3D, but received input shape ".concat(JSON.stringify(e)));
    this.inputSpec = [{
      shape: e
    }];
    var t = [e[0]].concat(e.slice(2));
    this.layer.built || (this.layer.build(t), this.layer.built = !0), super.build(e);
  }

  computeOutputShape(e) {
    var t = [(e = getExactlyOneShape(e))[0]].concat(e.slice(2)),
        n = this.layer.computeOutputShape(t);
    return [n[0], e[1]].concat(n.slice(1));
  }

  call(e, t) {
    return tidy(() => rnn$1((e, n) => [getExactlyOneTensor(this.layer.call(e, t)), []], e = getExactlyOneTensor(e), [], !1, null, null, !1, !0)[1]);
  }

}

function checkBidirectionalMergeMode(e) {
  checkStringTypeUnionValue(VALID_BIDIRECTIONAL_MERGE_MODES, "BidirectionalMergeMode", e);
}

TimeDistributed.className = "TimeDistributed", registerClass(TimeDistributed);
var DEFAULT_BIDIRECTIONAL_MERGE_MODE = "concat";

class Bidirectional extends Wrapper {
  constructor(e) {
    super(e);
    var t = e.layer.getConfig(),
        n = {};
    n.className = e.layer.getClassName(), n.config = t, this.forwardLayer = deserialize(n), t.goBackwards = !0 !== t.goBackwards;
    var r = {};
    if (r.className = e.layer.getClassName(), r.config = t, this.backwardLayer = deserialize(r), this.forwardLayer.name = "forward_" + this.forwardLayer.name, this.backwardLayer.name = "backward_" + this.backwardLayer.name, this.mergeMode = void 0 === e.mergeMode ? DEFAULT_BIDIRECTIONAL_MERGE_MODE : e.mergeMode, checkBidirectionalMergeMode(this.mergeMode), e.weights) throw new NotImplementedError("weights support is not implemented for Bidirectional layer yet.");
    this._stateful = e.layer.stateful, this.returnSequences = e.layer.returnSequences, this.returnState = e.layer.returnState, this.supportsMasking = !0, this._trainable = !0, this.inputSpec = e.layer.inputSpec, this.numConstants = null;
  }

  get trainable() {
    return this._trainable;
  }

  set trainable(e) {
    this._trainable = e, null != this.forwardLayer && (this.forwardLayer.trainable = e), null != this.backwardLayer && (this.backwardLayer.trainable = e);
  }

  getWeights() {
    return this.forwardLayer.getWeights().concat(this.backwardLayer.getWeights());
  }

  setWeights(e) {
    var t = Math.floor(e.length / 2);
    this.forwardLayer.setWeights(e.slice(0, t)), this.backwardLayer.setWeights(e.slice(t));
  }

  computeOutputShape(e) {
    var t,
        n,
        r,
        a = this.forwardLayer.computeOutputShape(e);
    return Array.isArray(a) && Array.isArray(a[0]) || (a = [a]), a = a, this.returnState ? (r = a.slice(1), t = a[0]) : t = a[0], t = t, "concat" === this.mergeMode ? (t[t.length - 1] *= 2, n = [t]) : n = null == this.mergeMode ? [t, t.slice()] : [t], this.returnState ? null == this.mergeMode ? n.concat(r).concat(r.slice()) : [t].concat(r).concat(r.slice()) : singletonOrArray(n);
  }

  apply(e, t) {
    var n = null == t ? null : t.initialState,
        r = null == t ? null : t.constants;
    null == t && (t = {});
    var a = standardizeArgs(e, n, r, this.numConstants);
    if (e = a.inputs, n = a.initialState, r = a.constants, Array.isArray(e) && (n = e.slice(1), e = e[0]), (null == n || 0 === n.length) && null == r) return super.apply(e, t);
    var s = [],
        o = [];

    if (null != n) {
      var _e769 = n.length;
      if (_e769 % 2 > 0) throw new ValueError("When passing `initialState` to a Bidrectional RNN, the state should be an Array containing the states of the underlying RNNs.");
      t.initialState = n, s.push(...n);

      var _r243 = n.map(e => new InputSpec({
        shape: e.shape
      }));

      this.forwardLayer.stateSpec = _r243.slice(0, _e769 / 2), this.backwardLayer.stateSpec = _r243.slice(_e769 / 2), o.push(..._r243);
    }

    if (null != r) throw new NotImplementedError("Support for constants in Bidirectional layers is not implemented yet.");
    var i = s[0] instanceof SymbolicTensor;

    for (var _e770 of s) {
      if (_e770 instanceof SymbolicTensor !== i) throw new ValueError("The initial state of a Bidirectional layer cannot be specified as a mix of symbolic and non-symbolic tensors");
    }

    if (i) {
      var _n301 = [e].concat(s),
          _r244 = this.inputSpec.concat(o),
          _a159 = this.inputSpec;

      this.inputSpec = _r244;

      var _i46 = super.apply(_n301, t);

      return this.inputSpec = _a159, _i46;
    }

    return super.apply(e, t);
  }

  call(e, t) {
    return tidy(() => {
      var n = t.initialState;
      var r, a, s, o;
      if (null == n) r = this.forwardLayer.call(e, t), a = this.backwardLayer.call(e, t);else {
        var _s116 = n.slice(0, n.length / 2),
            _o76 = n.slice(n.length / 2);

        r = this.forwardLayer.call(e, Object.assign(t, {
          initialState: _s116
        })), a = this.backwardLayer.call(e, Object.assign(t, {
          initialState: _o76
        }));
      }
      return this.returnState && (Array.isArray(r) && (s = r.slice(1).concat(a.slice(1))), r = r[0], a = a[0]), this.returnSequences && (a = reverse$2(a, 1)), "concat" === this.mergeMode ? o = concatenate$1([r, a]) : "sum" === this.mergeMode ? o = add$2(r, a) : "ave" === this.mergeMode ? o = mul(.5, add$2(r, a)) : "mul" === this.mergeMode ? o = mul(r, a) : null == this.mergeMode && (o = [r, a]), this.returnState ? null == this.mergeMode ? o.concat(s) : [o].concat(s) : o;
    });
  }

  resetStates(e) {
    this.forwardLayer.resetStates(), this.backwardLayer.resetStates();
  }

  build(e) {
    nameScope(this.forwardLayer.name, () => {
      this.forwardLayer.build(e);
    }), nameScope(this.backwardLayer.name, () => {
      this.backwardLayer.build(e);
    }), this.built = !0;
  }

  computeMask(e, t) {
    var n;

    if (Array.isArray(t) && (t = t[0]), n = this.returnSequences ? null == this.mergeMode ? [t, t] : t : null == this.mergeMode ? [null, null] : null, this.returnState) {
      var _e771 = this.forwardLayer.states.map(e => null);

      return Array.isArray(n) ? n.concat(_e771).concat(_e771) : [n].concat(_e771).concat(_e771);
    }

    return n;
  }

  get trainableWeights() {
    return this.forwardLayer.trainableWeights.concat(this.backwardLayer.trainableWeights);
  }

  get nonTrainableWeights() {
    return this.forwardLayer.nonTrainableWeights.concat(this.backwardLayer.nonTrainableWeights);
  }

  setFastWeightInitDuringBuild(e) {
    super.setFastWeightInitDuringBuild(e), null != this.forwardLayer && this.forwardLayer.setFastWeightInitDuringBuild(e), null != this.backwardLayer && this.backwardLayer.setFastWeightInitDuringBuild(e);
  }

  getConfig() {
    var e = {
      mergeMode: this.mergeMode
    },
        t = super.getConfig();
    return Object.assign(e, t), e;
  }

  static fromConfig(e, t) {
    var n = deserialize(t.layer);
    if (delete t.layer, null != t.numConstants) throw new NotImplementedError("Deserialization of a Bidirectional layer with numConstants present is not supported yet.");
    var r = t;
    return r.layer = n, new e(r);
  }

}

function inputLayer(e) {
  return new InputLayer(e);
}

function elu$2(e) {
  return new ELU$3(e);
}

function reLU(e) {
  return new ReLU(e);
}

function leakyReLU(e) {
  return new LeakyReLU(e);
}

function prelu$2(e) {
  return new PReLU(e);
}

function softmax$2(e) {
  return new Softmax(e);
}

function thresholdedReLU(e) {
  return new ThresholdedReLU(e);
}

function conv1d(e) {
  return new Conv1D(e);
}

function conv2d$1(e) {
  return new Conv2D(e);
}

function conv2dTranspose(e) {
  return new Conv2DTranspose(e);
}

function conv3d(e) {
  return new Conv3D(e);
}

function conv3dTranspose(e) {
  return new Conv3DTranspose(e);
}

function separableConv2d(e) {
  return new SeparableConv2D(e);
}

function cropping2D(e) {
  return new Cropping2D(e);
}

function upSampling2d(e) {
  return new UpSampling2D(e);
}

function depthwiseConv2d(e) {
  return new DepthwiseConv2D(e);
}

function activation(e) {
  return new Activation(e);
}

function dense(e) {
  return new Dense(e);
}

function dropout(e) {
  return new Dropout(e);
}

function spatialDropout1d(e) {
  return new SpatialDropout1D(e);
}

function flatten$1(e) {
  return new Flatten(e);
}

function repeatVector(e) {
  return new RepeatVector(e);
}

function reshape$2(e) {
  return new Reshape(e);
}

function permute(e) {
  return new Permute(e);
}

function embedding(e) {
  return new Embedding(e);
}

function add$1(e) {
  return new Add(e);
}

function average(e) {
  return new Average(e);
}

function concatenate(e) {
  return new Concatenate(e);
}

function maximum$2(e) {
  return new Maximum(e);
}

function minimum$2(e) {
  return new Minimum(e);
}

function multiply$2(e) {
  return new Multiply(e);
}

function dot(e) {
  return new Dot(e);
}

function batchNormalization(e) {
  return new BatchNormalization(e);
}

function layerNormalization(e) {
  return new LayerNormalization(e);
}

function zeroPadding2d(e) {
  return new ZeroPadding2D(e);
}

function averagePooling1d(e) {
  return new AveragePooling1D(e);
}

function avgPool1d(e) {
  return averagePooling1d(e);
}

function avgPooling1d(e) {
  return averagePooling1d(e);
}

function averagePooling2d(e) {
  return new AveragePooling2D(e);
}

function avgPool2d(e) {
  return averagePooling2d(e);
}

function avgPooling2d(e) {
  return averagePooling2d(e);
}

function averagePooling3d(e) {
  return new AveragePooling3D(e);
}

function avgPool3d(e) {
  return averagePooling3d(e);
}

function avgPooling3d(e) {
  return averagePooling3d(e);
}

function globalAveragePooling1d(e) {
  return new GlobalAveragePooling1D(e);
}

function globalAveragePooling2d(e) {
  return new GlobalAveragePooling2D(e);
}

function globalMaxPooling1d(e) {
  return new GlobalMaxPooling1D(e);
}

function globalMaxPooling2d(e) {
  return new GlobalMaxPooling2D(e);
}

function maxPooling1d(e) {
  return new MaxPooling1D(e);
}

function maxPooling2d(e) {
  return new MaxPooling2D(e);
}

function maxPooling3d(e) {
  return new MaxPooling3D(e);
}

function gru(e) {
  return new GRU(e);
}

function gruCell(e) {
  return new GRUCell(e);
}

function lstm(e) {
  return new LSTM(e);
}

function lstmCell(e) {
  return new LSTMCell(e);
}

function simpleRNN(e) {
  return new SimpleRNN(e);
}

function simpleRNNCell(e) {
  return new SimpleRNNCell(e);
}

function convLstm2d(e) {
  return new ConvLSTM2D(e);
}

function convLstm2dCell(e) {
  return new ConvLSTM2DCell(e);
}

function rnn(e) {
  return new RNN(e);
}

function stackedRNNCells(e) {
  return new StackedRNNCells(e);
}

function bidirectional(e) {
  return new Bidirectional(e);
}

function timeDistributed(e) {
  return new TimeDistributed(e);
}

Bidirectional.className = "Bidirectional", registerClass(Bidirectional);
var globalMaxPool1d = globalMaxPooling1d,
    globalMaxPool2d = globalMaxPooling2d,
    maxPool1d = maxPooling1d,
    maxPool2d = maxPooling2d;

function gaussianNoise(e) {
  return new GaussianNoise(e);
}

function gaussianDropout(e) {
  return new GaussianDropout(e);
}

function alphaDropout(e) {
  return new AlphaDropout(e);
}

function masking(e) {
  return new Masking(e);
}

var exports_layers = {
  __proto__: null,
  inputLayer,
  elu: elu$2,
  reLU,
  leakyReLU,
  prelu: prelu$2,
  softmax: softmax$2,
  thresholdedReLU,
  conv1d,
  conv2d: conv2d$1,
  conv2dTranspose,
  conv3d,
  conv3dTranspose,
  separableConv2d,
  cropping2D,
  upSampling2d,
  depthwiseConv2d,
  activation,
  dense,
  dropout,
  spatialDropout1d,
  flatten: flatten$1,
  repeatVector,
  reshape: reshape$2,
  permute,
  embedding,
  add: add$1,
  average,
  concatenate,
  maximum: maximum$2,
  minimum: minimum$2,
  multiply: multiply$2,
  dot,
  batchNormalization,
  layerNormalization,
  zeroPadding2d,
  averagePooling1d,
  avgPool1d,
  avgPooling1d,
  averagePooling2d,
  avgPool2d,
  avgPooling2d,
  averagePooling3d,
  avgPool3d,
  avgPooling3d,
  globalAveragePooling1d,
  globalAveragePooling2d,
  globalMaxPooling1d,
  globalMaxPooling2d,
  maxPooling1d,
  maxPooling2d,
  maxPooling3d,
  gru,
  gruCell,
  lstm,
  lstmCell,
  simpleRNN,
  simpleRNNCell,
  convLstm2d,
  convLstm2dCell,
  rnn,
  stackedRNNCells,
  bidirectional,
  timeDistributed,
  globalMaxPool1d,
  globalMaxPool2d,
  maxPool1d,
  maxPool2d,
  Layer,
  RNN,
  RNNCell,
  input,
  gaussianNoise,
  gaussianDropout,
  alphaDropout,
  masking
};

function binaryAccuracy(e, t) {
  return binaryAccuracy$1(e, t);
}

function binaryCrossentropy(e, t) {
  return binaryCrossentropy$1(e, t);
}

function sparseCategoricalAccuracy(e, t) {
  return sparseCategoricalAccuracy$1(e, t);
}

function categoricalAccuracy(e, t) {
  return categoricalAccuracy$1(e, t);
}

function categoricalCrossentropy(e, t) {
  return categoricalCrossentropy$1(e, t);
}

function precision(e, t) {
  return precision$1(e, t);
}

function recall(e, t) {
  return recall$1(e, t);
}

function cosineProximity(e, t) {
  return cosineProximity$1(e, t);
}

function meanAbsoluteError(e, t) {
  return meanAbsoluteError$1(e, t);
}

function meanAbsolutePercentageError(e, t) {
  return meanAbsolutePercentageError$1(e, t);
}

function MAPE(e, t) {
  return meanAbsolutePercentageError$1(e, t);
}

function mape(e, t) {
  return meanAbsolutePercentageError$1(e, t);
}

function meanSquaredError(e, t) {
  return meanSquaredError$1(e, t);
}

function MSE(e, t) {
  return meanSquaredError$1(e, t);
}

function mse(e, t) {
  return meanSquaredError$1(e, t);
}

var exports_metrics = {
  __proto__: null,
  binaryAccuracy,
  binaryCrossentropy,
  sparseCategoricalAccuracy,
  categoricalAccuracy,
  categoricalCrossentropy,
  precision,
  recall,
  cosineProximity,
  meanAbsoluteError,
  meanAbsolutePercentageError,
  MAPE,
  mape,
  meanSquaredError,
  MSE,
  mse
},
    exports_models = {
  __proto__: null,
  modelFromJSON
};

function l1l2(e) {
  return new L1L2(e);
}

function l1(e) {
  return l1$1(e);
}

function l2(e) {
  return l2$1(e);
}

var exports_regularizers = {
  __proto__: null,
  l1l2,
  l1,
  l2
};

class Callback extends BaseCallback {
  constructor() {
    super(...arguments), this.model = null;
  }

  setModel(e) {
    if (!(e instanceof LayersModel)) throw new Error("model must be a LayersModel, not some other Container");
    this.model = e;
  }

}

function less$2(e, t) {
  return e < t;
}

function greater$2(e, t) {
  return e > t;
}

class EarlyStopping extends Callback {
  constructor(e) {
    if (super(), null == e && (e = {}), e.restoreBestWeights) throw new NotImplementedError("restoreBestWeights = True is not implemented in EarlyStopping yet.");
    this.monitor = e.monitor || "val_loss", this.minDelta = Math.abs(e.minDelta || 0), this.patience = e.patience || 0, this.verbose = e.verbose || 0, this.mode = e.mode || "auto", this.baseline = e.baseline, -1 === ["auto", "min", "max"].indexOf(this.mode) && (console.warn("EarlyStopping mode '".concat(this.mode, "' is invalid. Falling back to mode 'auto'.")), this.mode = "auto"), this.monitorFunc = "min" === this.mode ? less$2 : "max" === this.mode || -1 !== this.monitor.indexOf("acc") ? greater$2 : less$2, this.monitorFunc === less$2 && (this.minDelta *= -1);
  }

  onTrainBegin(e) {
    var _this147 = this;

    return _asyncToGenerator(function* () {
      _this147.wait = 0, _this147.stoppedEpoch = 0, _this147.best = null != _this147.baseline ? _this147.baseline : _this147.monitorFunc === less$2 ? Infinity : -Infinity;
    })();
  }

  onEpochEnd(e, t) {
    var _this148 = this;

    return _asyncToGenerator(function* () {
      yield resolveScalarsInLogs(t);

      var n = _this148.getMonitorValue(t);

      null != n && (_this148.monitorFunc(n - _this148.minDelta, _this148.best) ? (_this148.best = n, _this148.wait = 0) : (_this148.wait++, _this148.wait >= _this148.patience && (_this148.stoppedEpoch = e, _this148.model.stopTraining = !0)));
    })();
  }

  onTrainEnd(e) {
    var _this149 = this;

    return _asyncToGenerator(function* () {
      _this149.stoppedEpoch > 0 && _this149.verbose && console.log("Epoch ".concat(_this149.stoppedEpoch, ": early stopping."));
    })();
  }

  getMonitorValue(e) {
    null == e && (e = {});
    var t = e[this.monitor];
    return null == t && console.warn("Metric for EarlyStopping ".concat(this.monitor, " is not available. Available metrics are: ").concat(Object.keys(e))), t;
  }

}

function earlyStopping(e) {
  return new EarlyStopping(e);
}

var callbacks = {
  earlyStopping
};
var DataType, SaverDef;
!function (e) {
  e[e.DT_INVALID = 0] = "DT_INVALID", e[e.DT_FLOAT = 1] = "DT_FLOAT", e[e.DT_DOUBLE = 2] = "DT_DOUBLE", e[e.DT_INT32 = 3] = "DT_INT32", e[e.DT_UINT8 = 4] = "DT_UINT8", e[e.DT_INT16 = 5] = "DT_INT16", e[e.DT_INT8 = 6] = "DT_INT8", e[e.DT_STRING = 7] = "DT_STRING", e[e.DT_COMPLEX64 = 8] = "DT_COMPLEX64", e[e.DT_INT64 = 9] = "DT_INT64", e[e.DT_BOOL = 10] = "DT_BOOL", e[e.DT_QINT8 = 11] = "DT_QINT8", e[e.DT_QUINT8 = 12] = "DT_QUINT8", e[e.DT_QINT32 = 13] = "DT_QINT32", e[e.DT_BFLOAT16 = 14] = "DT_BFLOAT16", e[e.DT_FLOAT_REF = 101] = "DT_FLOAT_REF", e[e.DT_DOUBLE_REF = 102] = "DT_DOUBLE_REF", e[e.DT_INT32_REF = 103] = "DT_INT32_REF", e[e.DT_UINT8_REF = 104] = "DT_UINT8_REF", e[e.DT_INT16_REF = 105] = "DT_INT16_REF", e[e.DT_INT8_REF = 106] = "DT_INT8_REF", e[e.DT_STRING_REF = 107] = "DT_STRING_REF", e[e.DT_COMPLEX64_REF = 108] = "DT_COMPLEX64_REF", e[e.DT_INT64_REF = 109] = "DT_INT64_REF", e[e.DT_BOOL_REF = 110] = "DT_BOOL_REF", e[e.DT_QINT8_REF = 111] = "DT_QINT8_REF", e[e.DT_QUINT8_REF = 112] = "DT_QUINT8_REF", e[e.DT_QINT32_REF = 113] = "DT_QINT32_REF", e[e.DT_BFLOAT16_REF = 114] = "DT_BFLOAT16_REF";
}(DataType || (DataType = {})), function (e) {
  var t;
  (t = e.CheckpointFormatVersion || (e.CheckpointFormatVersion = {}))[t.LEGACY = 0] = "LEGACY", t[t.V1 = 1] = "V1", t[t.V2 = 2] = "V2";
}(SaverDef || (SaverDef = {}));
var CUSTOM_OPS = {};

function registerOp(e, t) {
  CUSTOM_OPS[e] = {
    tfOpName: e,
    category: "custom",
    inputs: [],
    attrs: [],
    customExecutor: t
  };
}

function getRegisteredOp(e) {
  return CUSTOM_OPS[e];
}

function deregisterOp(e) {
  delete CUSTOM_OPS[e];
}

function getParamValue(e, t, n, r, a) {
  var s = t.inputParams[e];

  if (s && void 0 !== s.inputIndexStart) {
    var _e772 = s.inputIndexStart,
        _o77 = 0 === s.inputIndexEnd ? void 0 : void 0 === s.inputIndexEnd ? _e772 + 1 : s.inputIndexEnd;

    if ("tensor" === s.type) return getTensor(t.inputNames[s.inputIndexStart], n, r, a);
    if ("tensors" === s.type) return t.inputNames.slice(_e772, _o77).map(e => getTensor(e, n, r, a));
    var i = getTensor(t.inputNames.slice(_e772)[0], n, r, a),
        l = i.dataSync();
    return "number" === s.type ? l[0] : toNestedArray(i.shape, l);
  }

  var o = t.attrParams[e];
  return o && o.value;
}

function getTensor(e, t, n, r) {
  var [a, s] = parseNodeName(e);

  if (null != r) {
    var _e773 = r.getHashTableHandleByName(a);

    if (null != _e773) return _e773;
  }

  var o = n.currentContextIds.find(e => !!t[getNodeNameWithContextId(a, e)]);
  return void 0 !== o ? t[getNodeNameWithContextId(a, o)][s] : void 0;
}

function getTensorsForCurrentContenxt(e, t, n) {
  return t[getNodeNameWithContextId(e, n.currentContextId)];
}

function getNodeNameAndIndex(e, t) {
  var [n, r, a] = parseNodeName(e);
  return [getNodeNameWithContextId(n, t && t.currentContextId), r, a];
}

function getNodeNameWithContextId(e, t) {
  return t ? "".concat(e, "-").concat(t) : e;
}

function parseNodeName(e) {
  var t = e.split(":");
  if (1 === t.length) return [e, 0, void 0];
  var n = 3 === t.length ? t[1] : void 0;
  return [t[0], Number(t[t.length - 1]), n];
}

function getPadding(e, t, n) {
  var r = getParamValue("pad", e, t, n);

  if ("explicit" === r) {
    r = getParamValue("explicitPaddings", e, t, n);
    var a = [[0, 0], [0, 0], [0, 0], [0, 0]];

    for (var _e774 = 0; _e774 < 4; _e774++) {
      a[_e774][0] = r[2 * _e774], a[_e774][1] = r[2 * _e774 + 1];
    }

    return a;
  }

  return r;
}

function cloneTensor(e) {
  return e.kept ? e : clone(e);
}

var json$i = [{
  tfOpName: "Add",
  category: "arithmetic",
  inputs: [{
    start: 0,
    name: "a",
    type: "tensor"
  }, {
    start: 1,
    name: "b",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "AddV2",
  category: "arithmetic",
  inputs: [{
    start: 0,
    name: "a",
    type: "tensor"
  }, {
    start: 1,
    name: "b",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "AddN",
  category: "arithmetic",
  inputs: [{
    start: 0,
    end: 0,
    name: "tensors",
    type: "tensors"
  }]
}, {
  tfOpName: "BiasAdd",
  category: "arithmetic",
  inputs: [{
    start: 0,
    name: "a",
    type: "tensor"
  }, {
    start: 1,
    name: "b",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }, {
    tfName: "data_format",
    name: "dataFormat",
    type: "string",
    notSupported: !0
  }]
}, {
  tfOpName: "Sub",
  category: "arithmetic",
  inputs: [{
    start: 0,
    name: "a",
    type: "tensor"
  }, {
    start: 1,
    name: "b",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "RealDiv",
  category: "arithmetic",
  inputs: [{
    start: 0,
    name: "a",
    type: "tensor"
  }, {
    start: 1,
    name: "b",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Div",
  category: "arithmetic",
  inputs: [{
    start: 0,
    name: "a",
    type: "tensor"
  }, {
    start: 1,
    name: "b",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "DivNoNan",
  category: "arithmetic",
  inputs: [{
    start: 0,
    name: "a",
    type: "tensor"
  }, {
    start: 1,
    name: "b",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "FloorDiv",
  category: "arithmetic",
  inputs: [{
    start: 0,
    name: "a",
    type: "tensor"
  }, {
    start: 1,
    name: "b",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Mul",
  category: "arithmetic",
  inputs: [{
    start: 0,
    name: "a",
    type: "tensor"
  }, {
    start: 1,
    name: "b",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Maximum",
  category: "arithmetic",
  inputs: [{
    start: 0,
    name: "a",
    type: "tensor"
  }, {
    start: 1,
    name: "b",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Minimum",
  category: "arithmetic",
  inputs: [{
    start: 0,
    name: "a",
    type: "tensor"
  }, {
    start: 1,
    name: "b",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Pow",
  category: "arithmetic",
  inputs: [{
    start: 0,
    name: "a",
    type: "tensor"
  }, {
    start: 1,
    name: "b",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "SquaredDifference",
  category: "arithmetic",
  inputs: [{
    start: 0,
    name: "a",
    type: "tensor"
  }, {
    start: 1,
    name: "b",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Mod",
  category: "arithmetic",
  inputs: [{
    start: 0,
    name: "a",
    type: "tensor"
  }, {
    start: 1,
    name: "b",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "FloorMod",
  category: "arithmetic",
  inputs: [{
    start: 0,
    name: "a",
    type: "tensor"
  }, {
    start: 1,
    name: "b",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}];
var arithmetic = {
  __proto__: null,
  json: json$i
};
var json$h = [{
  tfOpName: "Abs",
  category: "basic_math",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Acos",
  category: "basic_math",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Asin",
  category: "basic_math",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Atan",
  category: "basic_math",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Atan2",
  category: "basic_math",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "y",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Ceil",
  category: "basic_math",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "ClipByValue",
  category: "basic_math",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "clipValueMin",
    type: "number"
  }, {
    start: 2,
    name: "clipValueMax",
    type: "number"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Complex",
  category: "basic_math",
  inputs: [{
    start: 0,
    name: "real",
    type: "tensor"
  }, {
    start: 1,
    name: "imag",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "ComplexAbs",
  category: "basic_math",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Cos",
  category: "basic_math",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Cosh",
  category: "basic_math",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Elu",
  category: "basic_math",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Exp",
  category: "basic_math",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Floor",
  category: "basic_math",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Log",
  category: "basic_math",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Imag",
  category: "basic_math",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }, {
    tfName: "Tout",
    name: "outputType",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Neg",
  category: "basic_math",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Real",
  category: "basic_math",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }, {
    tfName: "Tout",
    name: "outputType",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Prelu",
  category: "basic_math",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "alpha",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Relu",
  category: "basic_math",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Relu6",
  category: "basic_math",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Selu",
  category: "basic_math",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Sigmoid",
  category: "basic_math",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Sin",
  category: "basic_math",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Sinh",
  category: "basic_math",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Sqrt",
  category: "basic_math",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Rsqrt",
  category: "basic_math",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Square",
  category: "basic_math",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Tan",
  category: "basic_math",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Tanh",
  category: "basic_math",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Sign",
  category: "basic_math",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Round",
  category: "basic_math",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Expm1",
  category: "basic_math",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Log1p",
  category: "basic_math",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Reciprocal",
  category: "basic_math",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Softplus",
  category: "basic_math",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Asinh",
  category: "basic_math",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Acosh",
  category: "basic_math",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Atanh",
  category: "basic_math",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Erf",
  category: "basic_math",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Prod",
  category: "basic_math",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "axes",
    type: "number[]"
  }],
  attrs: [{
    tfName: "keep_dims",
    name: "keepDims",
    type: "bool",
    notSupported: !0
  }, {
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "LeakyRelu",
  category: "basic_math",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "alpha",
    name: "alpha",
    type: "number",
    defaultValue: .2
  }, {
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "IsNan",
  category: "basic_math",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}];
var basicMath = {
  __proto__: null,
  json: json$h
};
var json$g = [{
  tfOpName: "EmptyTensorList",
  category: "control",
  inputs: [{
    start: 0,
    name: "elementShape",
    type: "shape"
  }, {
    start: 1,
    name: "maxNumElements",
    type: "number"
  }],
  attrs: [{
    tfName: "element_dtype",
    name: "elementDType",
    type: "dtype"
  }]
}, {
  tfOpName: "LoopCond",
  category: "control",
  inputs: [{
    start: 0,
    name: "pred",
    type: "tensor"
  }]
}, {
  tfOpName: "Switch",
  category: "control",
  inputs: [{
    start: 0,
    name: "data",
    type: "tensor"
  }, {
    start: 1,
    name: "pred",
    type: "tensor"
  }]
}, {
  tfOpName: "Merge",
  category: "control",
  inputs: [{
    start: 0,
    end: 0,
    name: "tensors",
    type: "tensors"
  }]
}, {
  tfOpName: "Enter",
  category: "control",
  inputs: [{
    start: 0,
    name: "tensor",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }, {
    tfName: "frame_name",
    name: "frameName",
    type: "string"
  }, {
    tfName: "is_constant",
    name: "isConstant",
    type: "bool"
  }]
}, {
  tfOpName: "Exit",
  category: "control",
  inputs: [{
    start: 0,
    name: "tensor",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "NextIteration",
  category: "control",
  inputs: [{
    start: 0,
    name: "tensor",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "TensorArrayV3",
  category: "control",
  inputs: [{
    start: 0,
    name: "size",
    type: "number"
  }],
  attrs: [{
    tfName: "dtype",
    name: "dtype",
    type: "dtype"
  }, {
    tfName: "element_shape",
    name: "elementShape",
    type: "shape"
  }, {
    tfName: "dynamic_size",
    name: "dynamicSize",
    type: "bool"
  }, {
    tfName: "clear_after_read",
    name: "clearAfterRead",
    type: "bool"
  }, {
    tfName: "identical_element_shapes",
    name: "identicalElementShapes",
    type: "bool"
  }, {
    tfName: "tensor_array_name",
    name: "name",
    type: "string"
  }]
}, {
  tfOpName: "TensorArrayWriteV3",
  category: "control",
  inputs: [{
    start: 0,
    name: "tensorArrayId",
    type: "tensor"
  }, {
    start: 1,
    name: "index",
    type: "number"
  }, {
    start: 2,
    name: "tensor",
    type: "tensor"
  }, {
    start: 3,
    name: "flowIn",
    type: "number"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "TensorArrayReadV3",
  category: "control",
  inputs: [{
    start: 0,
    name: "tensorArrayId",
    type: "tensor"
  }, {
    start: 1,
    name: "index",
    type: "number"
  }, {
    start: 2,
    name: "flowIn",
    type: "number"
  }],
  attrs: [{
    tfName: "dtype",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "TensorArrayGatherV3",
  category: "control",
  inputs: [{
    start: 0,
    name: "tensorArrayId",
    type: "tensor"
  }, {
    start: 1,
    name: "indices",
    type: "number[]"
  }, {
    start: 2,
    name: "flowIn",
    type: "number"
  }],
  attrs: [{
    tfName: "dtype",
    name: "dtype",
    type: "dtype"
  }, {
    tfName: "element_shape",
    name: "elementShape",
    type: "shape"
  }]
}, {
  tfOpName: "TensorArrayScatterV3",
  category: "control",
  inputs: [{
    start: 0,
    name: "tensorArrayId",
    type: "tensor"
  }, {
    start: 1,
    name: "indices",
    type: "number[]"
  }, {
    start: 2,
    name: "tensor",
    type: "tensor"
  }, {
    start: 3,
    name: "flowIn",
    type: "number"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype"
  }]
}, {
  tfOpName: "TensorArrayConcatV3",
  category: "control",
  inputs: [{
    start: 0,
    name: "tensorArrayId",
    type: "tensor"
  }, {
    start: 1,
    name: "flowIn",
    type: "number"
  }],
  attrs: [{
    tfName: "dtype",
    name: "dtype",
    type: "dtype"
  }, {
    tfName: "element_shape_except0",
    name: "elementShapeExcept0",
    type: "shape",
    notSupported: !0
  }]
}, {
  tfOpName: "TensorArraySplitV3",
  category: "control",
  inputs: [{
    start: 0,
    name: "tensorArrayId",
    type: "tensor"
  }, {
    start: 1,
    name: "tensor",
    type: "tensor"
  }, {
    start: 2,
    name: "lengths",
    type: "number[]"
  }, {
    start: 3,
    name: "flowIn",
    type: "number"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype"
  }]
}, {
  tfOpName: "TensorArraySizeV3",
  category: "control",
  inputs: [{
    start: 0,
    name: "tensorArrayId",
    type: "tensor"
  }, {
    start: 1,
    name: "flowIn",
    type: "number"
  }]
}, {
  tfOpName: "TensorArrayCloseV3",
  category: "control",
  inputs: [{
    start: 0,
    name: "tensorArrayId",
    type: "tensor"
  }]
}, {
  tfOpName: "StatelessIf",
  category: "control",
  inputs: [{
    start: 0,
    name: "cond",
    type: "tensor"
  }, {
    start: 1,
    end: 0,
    name: "args",
    type: "tensors"
  }],
  attrs: [{
    tfName: "then_branch",
    name: "thenBranch",
    type: "func"
  }, {
    tfName: "else_branch",
    name: "elseBranch",
    type: "func"
  }]
}, {
  tfOpName: "If",
  category: "control",
  inputs: [{
    start: 0,
    name: "cond",
    type: "tensor"
  }, {
    start: 1,
    end: 0,
    name: "args",
    type: "tensors"
  }],
  attrs: [{
    tfName: "then_branch",
    name: "thenBranch",
    type: "func"
  }, {
    tfName: "else_branch",
    name: "elseBranch",
    type: "func"
  }]
}, {
  tfOpName: "StatelessWhile",
  category: "control",
  inputs: [{
    start: 0,
    end: 0,
    name: "args",
    type: "tensors"
  }],
  attrs: [{
    tfName: "cond",
    name: "cond",
    type: "func"
  }, {
    tfName: "body",
    name: "body",
    type: "func"
  }]
}, {
  tfOpName: "While",
  category: "control",
  inputs: [{
    start: 0,
    end: 0,
    name: "args",
    type: "tensors"
  }],
  attrs: [{
    tfName: "cond",
    name: "cond",
    type: "func"
  }, {
    tfName: "body",
    name: "body",
    type: "func"
  }]
}, {
  tfOpName: "TensorListScatter",
  category: "control",
  inputs: [{
    start: 0,
    name: "tensor",
    type: "tensor"
  }, {
    start: 1,
    name: "indices",
    type: "number[]"
  }, {
    start: 2,
    name: "elementShape",
    type: "shape"
  }],
  attrs: [{
    tfName: "element_dtype",
    name: "elementDType",
    type: "dtype"
  }]
}, {
  tfOpName: "TensorListScatterV2",
  category: "control",
  inputs: [{
    start: 0,
    name: "tensor",
    type: "tensor"
  }, {
    start: 1,
    name: "indices",
    type: "number[]"
  }, {
    start: 2,
    name: "elementShape",
    type: "shape"
  }, {
    start: 3,
    name: "numElements",
    type: "number"
  }],
  attrs: [{
    tfName: "element_dtype",
    name: "elementDType",
    type: "dtype"
  }]
}, {
  tfOpName: "TensorListGather",
  category: "control",
  inputs: [{
    start: 0,
    name: "tensorListId",
    type: "tensor"
  }, {
    start: 1,
    name: "indices",
    type: "number[]"
  }, {
    start: 2,
    name: "elementShape",
    type: "shape"
  }],
  attrs: [{
    tfName: "element_dtype",
    name: "elementDType",
    type: "dtype"
  }]
}, {
  tfOpName: "TensorListGetItem",
  category: "control",
  inputs: [{
    start: 0,
    name: "tensorListId",
    type: "tensor"
  }, {
    start: 1,
    name: "index",
    type: "number"
  }, {
    start: 2,
    name: "elementShape",
    type: "shape"
  }],
  attrs: [{
    tfName: "element_dtype",
    name: "elementDType",
    type: "dtype"
  }]
}, {
  tfOpName: "TensorListSetItem",
  category: "control",
  inputs: [{
    start: 0,
    name: "tensorListId",
    type: "tensor"
  }, {
    start: 1,
    name: "index",
    type: "number"
  }, {
    start: 2,
    name: "tensor",
    type: "tensor"
  }],
  attrs: [{
    tfName: "element_dtype",
    name: "elementDType",
    type: "dtype"
  }]
}, {
  tfOpName: "TensorListReserve",
  category: "control",
  inputs: [{
    start: 0,
    name: "elementShape",
    type: "shape"
  }, {
    start: 1,
    name: "numElements",
    type: "number"
  }],
  attrs: [{
    tfName: "element_dtype",
    name: "elementDType",
    type: "dtype"
  }]
}, {
  tfOpName: "TensorListFromTensor",
  category: "control",
  inputs: [{
    start: 0,
    name: "tensor",
    type: "tensor"
  }, {
    start: 1,
    name: "elementShape",
    type: "shape"
  }],
  attrs: [{
    tfName: "element_dtype",
    name: "elementDType",
    type: "dtype"
  }]
}, {
  tfOpName: "TensorListStack",
  category: "control",
  inputs: [{
    start: 0,
    name: "tensorListId",
    type: "tensor"
  }, {
    start: 1,
    name: "elementShape",
    type: "shape"
  }],
  attrs: [{
    tfName: "element_dtype",
    name: "elementDType",
    type: "dtype"
  }, {
    tfName: "num_elements",
    name: "numElements",
    type: "dtype"
  }]
}, {
  tfOpName: "TensorListSplit",
  category: "control",
  inputs: [{
    start: 0,
    name: "tensor",
    type: "tensor"
  }, {
    start: 1,
    name: "elementShape",
    type: "shape"
  }, {
    start: 2,
    name: "lengths",
    type: "number[]"
  }],
  attrs: [{
    tfName: "element_dtype",
    name: "elementDType",
    type: "dtype"
  }]
}, {
  tfOpName: "TensorListConcat",
  category: "control",
  inputs: [{
    start: 0,
    name: "tensorListId",
    type: "tensor"
  }],
  attrs: [{
    tfName: "element_shape",
    name: "elementShape",
    type: "shape"
  }, {
    tfName: "element_dtype",
    name: "elementDType",
    type: "dtype"
  }]
}, {
  tfOpName: "TensorListPopBack",
  category: "control",
  inputs: [{
    start: 0,
    name: "tensorListId",
    type: "tensor"
  }, {
    start: 1,
    name: "elementShape",
    type: "shape"
  }],
  attrs: [{
    tfName: "element_dtype",
    name: "elementDType",
    type: "dtype"
  }]
}, {
  tfOpName: "TensorListPushBack",
  category: "control",
  inputs: [{
    start: 0,
    name: "tensorListId",
    type: "tensor"
  }, {
    start: 1,
    name: "tensor",
    type: "tensor"
  }],
  attrs: [{
    tfName: "element_dtype",
    name: "elementDType",
    type: "dtype"
  }]
}];
var control = {
  __proto__: null,
  json: json$g
};
var json$f = [{
  tfOpName: "AvgPool",
  category: "convolution",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "strides",
    name: "strides",
    type: "number[]"
  }, {
    tfName: "padding",
    name: "pad",
    type: "string"
  }, {
    tfName: "data_format",
    name: "dataFormat",
    type: "string",
    notSupported: !0
  }, {
    tfName: "ksize",
    name: "kernelSize",
    type: "number[]"
  }, {
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "MaxPool",
  category: "convolution",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "strides",
    name: "strides",
    type: "number[]"
  }, {
    tfName: "padding",
    name: "pad",
    type: "string"
  }, {
    tfName: "data_format",
    name: "dataFormat",
    type: "string",
    notSupported: !0
  }, {
    tfName: "ksize",
    name: "kernelSize",
    type: "number[]"
  }, {
    tfName: "explicit_paddings",
    name: "explicitPaddings",
    type: "number[]",
    defaultValue: [],
    notSupported: !0
  }, {
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "MaxPoolWithArgmax",
  category: "convolution",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "strides",
    name: "strides",
    type: "number[]"
  }, {
    tfName: "padding",
    name: "pad",
    type: "string"
  }, {
    tfName: "ksize",
    name: "kernelSize",
    type: "number[]"
  }, {
    tfName: "include_batch_in_index",
    name: "includeBatchInIndex",
    type: "bool"
  }, {
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "AvgPool3D",
  category: "convolution",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "strides",
    name: "strides",
    type: "number[]"
  }, {
    tfName: "padding",
    name: "pad",
    type: "string"
  }, {
    tfName: "data_format",
    name: "dataFormat",
    type: "string",
    notSupported: !0
  }, {
    tfName: "ksize",
    name: "kernelSize",
    type: "number[]"
  }, {
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "MaxPool3D",
  category: "convolution",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "strides",
    name: "strides",
    type: "number[]"
  }, {
    tfName: "padding",
    name: "pad",
    type: "string"
  }, {
    tfName: "data_format",
    name: "dataFormat",
    type: "string",
    notSupported: !0
  }, {
    tfName: "ksize",
    name: "kernelSize",
    type: "number[]"
  }, {
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Conv1D",
  category: "convolution",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "filter",
    type: "tensor"
  }],
  attrs: [{
    tfName: "stride",
    name: "stride",
    type: "number"
  }, {
    tfName: "padding",
    name: "pad",
    type: "string"
  }, {
    tfName: "data_format",
    name: "dataFormat",
    type: "string",
    defaultValue: "NWC"
  }, {
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }, {
    tfName: "dilation",
    name: "dilation",
    type: "number",
    defaultValue: 1
  }]
}, {
  tfOpName: "Conv2D",
  category: "convolution",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "filter",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }, {
    tfName: "strides",
    name: "strides",
    type: "number[]"
  }, {
    tfName: "padding",
    name: "pad",
    type: "string"
  }, {
    tfName: "useCudnnOnGpu",
    name: "useCudnnOnGpu",
    type: "bool"
  }, {
    tfName: "data_format",
    name: "dataFormat",
    type: "string",
    defaultValue: "NHWC"
  }, {
    tfName: "explicit_paddings",
    name: "explicitPaddings",
    type: "number[]",
    defaultValue: []
  }, {
    tfName: "dilations",
    name: "dilations",
    type: "number[]"
  }]
}, {
  tfOpName: "_FusedConv2D",
  category: "convolution",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "filter",
    type: "tensor"
  }, {
    start: 2,
    end: 0,
    name: "args",
    type: "tensors"
  }],
  attrs: [{
    tfName: "num_args",
    name: "numArgs",
    type: "number"
  }, {
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }, {
    tfName: "strides",
    name: "strides",
    type: "number[]"
  }, {
    tfName: "padding",
    name: "pad",
    type: "string"
  }, {
    tfName: "explicit_paddings",
    name: "explicitPaddings",
    type: "number[]",
    defaultValue: []
  }, {
    tfName: "use_cudnn_on_gpu",
    name: "useCudnnOnGpu",
    type: "bool",
    defaultValue: !0
  }, {
    tfName: "data_format",
    name: "dataFormat",
    type: "string",
    defaultValue: "NHWC"
  }, {
    tfName: "dilations",
    name: "dilations",
    type: "number[]",
    defaultValue: [1, 1, 1, 1]
  }, {
    tfName: "fused_ops",
    name: "fusedOps",
    type: "string[]",
    defaultValue: []
  }, {
    tfName: "epsilon",
    name: "epsilon",
    type: "number",
    defaultValue: 1e-4
  }, {
    tfName: "leakyrelu_alpha",
    name: "leakyreluAlpha",
    type: "number"
  }]
}, {
  tfOpName: "Conv2DBackpropInput",
  category: "convolution",
  inputs: [{
    start: 2,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "filter",
    type: "tensor"
  }, {
    start: 0,
    name: "outputShape",
    type: "number[]"
  }],
  attrs: [{
    tfName: "strides",
    name: "strides",
    type: "number[]"
  }, {
    tfName: "padding",
    name: "pad",
    type: "string"
  }, {
    tfName: "data_format",
    name: "dataFormat",
    type: "string",
    notSupported: !0
  }, {
    tfName: "explicit_paddings",
    name: "explicitPaddings",
    type: "number[]",
    defaultValue: []
  }, {
    tfName: "dilations",
    name: "dilations",
    type: "number[]",
    notSupported: !0
  }]
}, {
  tfOpName: "DepthwiseConv2d",
  category: "convolution",
  inputs: [{
    start: 0,
    name: "input",
    type: "tensor"
  }, {
    start: 1,
    name: "filter",
    type: "tensor"
  }],
  attrs: [{
    tfName: "strides",
    name: "strides",
    type: "number[]"
  }, {
    tfName: "padding",
    name: "pad",
    type: "string"
  }, {
    tfName: "data_format",
    name: "dataFormat",
    type: "string",
    defaultValue: "NHWC"
  }, {
    tfName: "explicit_paddings",
    name: "explicitPaddings",
    type: "number[]",
    defaultValue: []
  }, {
    tfName: "dilations",
    name: "dilations",
    type: "number[]"
  }]
}, {
  tfOpName: "DepthwiseConv2dNative",
  category: "convolution",
  inputs: [{
    start: 0,
    name: "input",
    type: "tensor"
  }, {
    start: 1,
    name: "filter",
    type: "tensor"
  }],
  attrs: [{
    tfName: "strides",
    name: "strides",
    type: "number[]"
  }, {
    tfName: "padding",
    name: "pad",
    type: "string"
  }, {
    tfName: "data_format",
    name: "dataFormat",
    type: "string",
    defaultValue: "NHWC"
  }, {
    tfName: "explicit_paddings",
    name: "explicitPaddings",
    type: "number[]",
    defaultValue: []
  }, {
    tfName: "dilations",
    name: "dilations",
    type: "number[]"
  }]
}, {
  tfOpName: "FusedDepthwiseConv2dNative",
  category: "convolution",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "filter",
    type: "tensor"
  }, {
    start: 2,
    end: 0,
    name: "args",
    type: "tensors"
  }],
  attrs: [{
    tfName: "num_args",
    name: "numArgs",
    type: "number"
  }, {
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }, {
    tfName: "strides",
    name: "strides",
    type: "number[]"
  }, {
    tfName: "padding",
    name: "pad",
    type: "string"
  }, {
    tfName: "data_format",
    name: "dataFormat",
    type: "string",
    defaultValue: "NHWC"
  }, {
    tfName: "dilations",
    name: "dilations",
    type: "number[]",
    defaultValue: [1, 1, 1, 1]
  }, {
    tfName: "fused_ops",
    name: "fusedOps",
    type: "string[]",
    defaultValue: []
  }, {
    tfName: "explicit_paddings",
    name: "explicitPaddings",
    type: "number[]",
    defaultValue: []
  }]
}, {
  tfOpName: "Conv3D",
  category: "convolution",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "filter",
    type: "tensor"
  }],
  attrs: [{
    tfName: "strides",
    name: "strides",
    type: "number[]"
  }, {
    tfName: "padding",
    name: "pad",
    type: "string"
  }, {
    tfName: "data_format",
    name: "dataFormat",
    type: "string",
    defaultValue: "NHWC"
  }, {
    tfName: "dilations",
    name: "dilations",
    type: "number[]"
  }]
}, {
  tfOpName: "Dilation2D",
  category: "convolution",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "filter",
    type: "tensor"
  }],
  attrs: [{
    tfName: "strides",
    name: "strides",
    type: "number[]"
  }, {
    tfName: "rates",
    name: "dilations",
    type: "number[]"
  }, {
    tfName: "padding",
    name: "pad",
    type: "string"
  }]
}];
var convolution = {
  __proto__: null,
  json: json$f
};
var json$e = [{
  tfOpName: "Fill",
  category: "creation",
  inputs: [{
    start: 0,
    name: "shape",
    type: "number[]"
  }, {
    start: 1,
    name: "value",
    type: "number"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype"
  }]
}, {
  tfOpName: "LinSpace",
  category: "creation",
  inputs: [{
    start: 0,
    name: "start",
    type: "number"
  }, {
    start: 1,
    name: "stop",
    type: "number"
  }, {
    start: 2,
    name: "num",
    type: "number"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "OneHot",
  category: "creation",
  inputs: [{
    start: 0,
    name: "indices",
    type: "tensor"
  }, {
    start: 1,
    name: "depth",
    type: "number"
  }, {
    start: 2,
    name: "onValue",
    type: "number",
    defaultValue: 1
  }, {
    start: 3,
    name: "offValue",
    type: "number",
    defaultValue: 0
  }],
  attrs: [{
    tfName: "axis",
    name: "axis",
    type: "number",
    notSupported: !0
  }, {
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Ones",
  category: "creation",
  inputs: [{
    start: 0,
    name: "shape",
    type: "number[]"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype"
  }]
}, {
  tfOpName: "OnesLike",
  category: "creation",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "dtype",
    name: "dtype",
    type: "dtype"
  }]
}, {
  tfOpName: "RandomUniform",
  category: "creation",
  inputs: [{
    start: 0,
    name: "shape",
    type: "number[]"
  }],
  attrs: [{
    tfName: "minval",
    name: "minval",
    type: "number",
    defaultValue: 0
  }, {
    tfName: "maxval",
    name: "maxval",
    type: "number",
    defaultValue: 1
  }, {
    tfName: "dtype",
    name: "dtype",
    type: "dtype"
  }, {
    tfName: "seed",
    name: "seed",
    type: "number",
    defaultValue: 0
  }, {
    tfName: "seed2",
    name: "seed2",
    type: "number",
    defaultValue: 0,
    notSupported: !0
  }, {
    tfName: "T",
    name: "T",
    type: "number",
    notSupported: !0
  }]
}, {
  tfOpName: "Range",
  category: "creation",
  inputs: [{
    start: 0,
    name: "start",
    type: "number"
  }, {
    start: 1,
    name: "stop",
    type: "number"
  }, {
    start: 2,
    name: "step",
    type: "number",
    defaultValue: 0
  }],
  attrs: [{
    tfName: "Tidx",
    name: "dtype",
    type: "dtype"
  }]
}, {
  tfOpName: "TruncatedNormal",
  category: "creation",
  inputs: [{
    start: 0,
    name: "shape",
    type: "number[]"
  }],
  attrs: [{
    tfName: "means",
    name: "mean",
    type: "number",
    defaultValue: 0
  }, {
    tfName: "stddev",
    name: "stdDev",
    type: "number",
    defaultValue: 1
  }, {
    tfName: "seed",
    name: "seed",
    type: "number"
  }, {
    tfName: "seed2",
    name: "seed2",
    type: "number",
    defaultValue: 0,
    notSupported: !0
  }, {
    tfName: "dtype",
    name: "dtype",
    type: "dtype"
  }, {
    tfName: "T",
    name: "T",
    type: "number",
    notSupported: !0
  }]
}, {
  tfOpName: "Zeros",
  category: "creation",
  inputs: [{
    start: 0,
    name: "shape",
    type: "number[]"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype"
  }]
}, {
  tfOpName: "ZerosLike",
  category: "creation",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype"
  }]
}, {
  tfOpName: "Multinomial",
  category: "creation",
  inputs: [{
    start: 0,
    name: "logits",
    type: "tensor"
  }, {
    start: 1,
    name: "numSamples",
    type: "number"
  }],
  attrs: [{
    tfName: "seed",
    name: "seed",
    type: "number"
  }, {
    tfName: "seed2",
    name: "seed2",
    type: "number"
  }, {
    tfName: "T",
    name: "dtype",
    type: "dtype"
  }, {
    tfName: "output_dtype",
    name: "output_dtype",
    type: "dtype"
  }]
}];
var creation = {
  __proto__: null,
  json: json$e
};
var json$d = [{
  tfOpName: "NonMaxSuppressionV2",
  category: "dynamic",
  inputs: [{
    start: 0,
    name: "boxes",
    type: "tensor"
  }, {
    start: 1,
    name: "scores",
    type: "tensor"
  }, {
    start: 2,
    name: "maxOutputSize",
    type: "number"
  }, {
    start: 3,
    name: "iouThreshold",
    type: "number"
  }]
}, {
  tfOpName: "NonMaxSuppressionV3",
  category: "dynamic",
  inputs: [{
    start: 0,
    name: "boxes",
    type: "tensor"
  }, {
    start: 1,
    name: "scores",
    type: "tensor"
  }, {
    start: 2,
    name: "maxOutputSize",
    type: "number"
  }, {
    start: 3,
    name: "iouThreshold",
    type: "number"
  }, {
    start: 4,
    name: "scoreThreshold",
    type: "number"
  }]
}, {
  tfOpName: "NonMaxSuppressionV4",
  category: "dynamic",
  inputs: [{
    start: 0,
    name: "boxes",
    type: "tensor"
  }, {
    start: 1,
    name: "scores",
    type: "tensor"
  }, {
    start: 2,
    name: "maxOutputSize",
    type: "number"
  }, {
    start: 3,
    name: "iouThreshold",
    type: "number"
  }, {
    start: 4,
    name: "scoreThreshold",
    type: "number"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }, {
    tfName: "T_threshold",
    name: "threshold",
    type: "dtype",
    notSupported: !0
  }, {
    tfName: "pad_to_max_output_size",
    name: "padToMaxOutputSize",
    type: "bool"
  }]
}, {
  tfOpName: "NonMaxSuppressionV5",
  category: "dynamic",
  inputs: [{
    start: 0,
    name: "boxes",
    type: "tensor"
  }, {
    start: 1,
    name: "scores",
    type: "tensor"
  }, {
    start: 2,
    name: "maxOutputSize",
    type: "number"
  }, {
    start: 3,
    name: "iouThreshold",
    type: "number"
  }, {
    start: 4,
    name: "scoreThreshold",
    type: "number"
  }, {
    start: 5,
    name: "softNmsSigma",
    type: "number"
  }]
}, {
  tfOpName: "Where",
  category: "dynamic",
  inputs: [{
    start: 0,
    name: "condition",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "ListDiff",
  category: "dynamic",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "y",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}];
var dynamic = {
  __proto__: null,
  json: json$d
};
var json$c = [{
  tfOpName: "TopKV2",
  category: "evaluation",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "k",
    type: "number"
  }],
  attrs: [{
    tfName: "sorted",
    name: "sorted",
    type: "bool"
  }]
}, {
  tfOpName: "Unique",
  category: "evaluation",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }]
}, {
  tfOpName: "UniqueV2",
  category: "evaluation",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "axis",
    type: "number"
  }]
}];
var evaluation = {
  __proto__: null,
  json: json$c
};
var json$b = [{
  tfOpName: "PlaceholderWithDefault",
  category: "graph",
  inputs: [{
    start: 0,
    name: "default",
    type: "tensor"
  }],
  attrs: [{
    tfName: "shape",
    name: "shape",
    type: "shape"
  }, {
    tfName: "dtype",
    name: "dtype",
    type: "dtype"
  }]
}, {
  tfOpName: "Placeholder",
  category: "graph",
  attrs: [{
    tfName: "shape",
    name: "shape",
    type: "shape"
  }, {
    tfName: "dtype",
    name: "dtype",
    type: "dtype"
  }]
}, {
  tfOpName: "Const",
  category: "graph"
}, {
  tfOpName: "Identity",
  category: "graph",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }]
}, {
  tfOpName: "IdentityN",
  category: "graph",
  inputs: [{
    start: 0,
    end: 0,
    name: "x",
    type: "tensors"
  }]
}, {
  tfOpName: "Snapshot",
  category: "graph",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }]
}, {
  tfOpName: "Rank",
  category: "graph",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }]
}, {
  tfOpName: "Size",
  category: "graph",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }]
}, {
  tfOpName: "Shape",
  category: "graph",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }]
}, {
  tfOpName: "ShapeN",
  category: "graph",
  inputs: [{
    start: 0,
    end: 0,
    name: "x",
    type: "tensors"
  }]
}, {
  tfOpName: "Print",
  category: "graph",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "data",
    type: "tensors"
  }],
  attrs: [{
    tfName: "message",
    name: "message",
    type: "string"
  }, {
    tfName: "first_n",
    name: "firstN",
    type: "number",
    notSupported: !0
  }, {
    tfName: "summarize",
    name: "summarize",
    type: "number",
    defaultValue: 3
  }]
}, {
  tfOpName: "NoOp",
  category: "graph",
  inputs: []
}, {
  tfOpName: "StopGradient",
  category: "graph",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }]
}, {
  tfOpName: "FakeQuantWithMinMaxVars",
  category: "graph",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "min",
    name: "min",
    type: "number"
  }, {
    tfName: "max",
    name: "max",
    type: "number"
  }]
}];
var graph = {
  __proto__: null,
  json: json$b
};
var json$a = [{
  tfOpName: "HashTable",
  category: "hash_table",
  inputs: [],
  attrs: [{
    tfName: "shared_name",
    name: "sharedName",
    type: "string"
  }, {
    tfName: "use_node_name_sharing",
    name: "useNodeNameSharing",
    type: "bool"
  }, {
    tfName: "key_dtype",
    name: "keyDType",
    type: "dtype"
  }, {
    tfName: "value_dtype",
    name: "valueDType",
    type: "dtype"
  }]
}, {
  tfOpName: "HashTableV2",
  category: "hash_table",
  inputs: [],
  attrs: [{
    tfName: "shared_name",
    name: "sharedName",
    type: "string"
  }, {
    tfName: "use_node_name_sharing",
    name: "useNodeNameSharing",
    type: "bool"
  }, {
    tfName: "key_dtype",
    name: "keyDType",
    type: "dtype"
  }, {
    tfName: "value_dtype",
    name: "valueDType",
    type: "dtype"
  }]
}, {
  tfOpName: "LookupTableImport",
  category: "hash_table",
  inputs: [{
    start: 0,
    name: "tableHandle",
    type: "tensor"
  }, {
    start: 1,
    name: "keys",
    type: "tensor"
  }, {
    start: 2,
    name: "values",
    type: "tensor"
  }],
  attrs: [{
    tfName: "Tin",
    name: "tIn",
    type: "dtype",
    notSupported: !0
  }, {
    tfName: "Tout",
    name: "tOut",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "LookupTableImportV2",
  category: "hash_table",
  inputs: [{
    start: 0,
    name: "tableHandle",
    type: "tensor"
  }, {
    start: 1,
    name: "keys",
    type: "tensor"
  }, {
    start: 2,
    name: "values",
    type: "tensor"
  }],
  attrs: [{
    tfName: "Tin",
    name: "tIn",
    type: "dtype",
    notSupported: !0
  }, {
    tfName: "Tout",
    name: "tOut",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "LookupTableFind",
  category: "hash_table",
  inputs: [{
    start: 0,
    name: "tableHandle",
    type: "tensor"
  }, {
    start: 1,
    name: "keys",
    type: "tensor"
  }, {
    start: 2,
    name: "defaultValue",
    type: "tensor"
  }],
  attrs: [{
    tfName: "Tin",
    name: "tIn",
    type: "dtype",
    notSupported: !0
  }, {
    tfName: "Tout",
    name: "tOut",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "LookupTableFindV2",
  category: "hash_table",
  inputs: [{
    start: 0,
    name: "tableHandle",
    type: "tensor"
  }, {
    start: 1,
    name: "keys",
    type: "tensor"
  }, {
    start: 2,
    name: "defaultValue",
    type: "tensor"
  }],
  attrs: [{
    tfName: "Tin",
    name: "tIn",
    type: "dtype",
    notSupported: !0
  }, {
    tfName: "Tout",
    name: "tOut",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "LookupTableSize",
  category: "hash_table",
  inputs: [{
    start: 0,
    name: "tableHandle",
    type: "tensor"
  }]
}, {
  tfOpName: "LookupTableSizeV2",
  category: "hash_table",
  inputs: [{
    start: 0,
    name: "tableHandle",
    type: "tensor"
  }]
}];
var hashTable = {
  __proto__: null,
  json: json$a
};
var json$9 = [{
  tfOpName: "ResizeBilinear",
  category: "image",
  inputs: [{
    start: 0,
    name: "images",
    type: "tensor"
  }, {
    start: 1,
    name: "size",
    type: "number[]"
  }],
  attrs: [{
    tfName: "align_corners",
    name: "alignCorners",
    type: "bool"
  }, {
    tfName: "half_pixel_centers",
    name: "halfPixelCenters",
    type: "bool"
  }, {
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "ResizeNearestNeighbor",
  category: "image",
  inputs: [{
    start: 0,
    name: "images",
    type: "tensor"
  }, {
    start: 1,
    name: "size",
    type: "number[]"
  }],
  attrs: [{
    tfName: "align_corners",
    name: "alignCorners",
    type: "bool"
  }, {
    tfName: "half_pixel_centers",
    name: "halfPixelCenters",
    type: "bool"
  }, {
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "CropAndResize",
  category: "image",
  inputs: [{
    start: 0,
    name: "image",
    type: "tensor"
  }, {
    start: 1,
    name: "boxes",
    type: "tensor"
  }, {
    start: 2,
    name: "boxInd",
    type: "tensor"
  }, {
    start: 3,
    name: "cropSize",
    type: "number[]"
  }],
  attrs: [{
    tfName: "method",
    name: "method",
    type: "string"
  }, {
    tfName: "extrapolation_value",
    name: "extrapolationValue",
    type: "number"
  }]
}];
var image = {
  __proto__: null,
  json: json$9
};
var json$8 = [{
  tfOpName: "Equal",
  category: "logical",
  inputs: [{
    start: 0,
    name: "a",
    type: "tensor"
  }, {
    start: 1,
    name: "b",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "NotEqual",
  category: "logical",
  inputs: [{
    start: 0,
    name: "a",
    type: "tensor"
  }, {
    start: 1,
    name: "b",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Greater",
  category: "logical",
  inputs: [{
    start: 0,
    name: "a",
    type: "tensor"
  }, {
    start: 1,
    name: "b",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "GreaterEqual",
  category: "logical",
  inputs: [{
    start: 0,
    name: "a",
    type: "tensor"
  }, {
    start: 1,
    name: "b",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Less",
  category: "logical",
  inputs: [{
    start: 0,
    name: "a",
    type: "tensor"
  }, {
    start: 1,
    name: "b",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "LessEqual",
  category: "logical",
  inputs: [{
    start: 0,
    name: "a",
    type: "tensor"
  }, {
    start: 1,
    name: "b",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "LogicalAnd",
  category: "logical",
  inputs: [{
    start: 0,
    name: "a",
    type: "tensor"
  }, {
    start: 1,
    name: "b",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "LogicalNot",
  category: "logical",
  inputs: [{
    start: 0,
    name: "a",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "LogicalOr",
  category: "logical",
  inputs: [{
    start: 0,
    name: "a",
    type: "tensor"
  }, {
    start: 1,
    name: "b",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Select",
  category: "logical",
  inputs: [{
    start: 0,
    name: "condition",
    type: "tensor"
  }, {
    start: 1,
    name: "a",
    type: "tensor"
  }, {
    start: 2,
    name: "b",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "SelectV2",
  category: "logical",
  inputs: [{
    start: 0,
    name: "condition",
    type: "tensor"
  }, {
    start: 1,
    name: "a",
    type: "tensor"
  }, {
    start: 2,
    name: "b",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}];
var logical = {
  __proto__: null,
  json: json$8
};
var json$7 = [{
  tfOpName: "_FusedMatMul",
  category: "matrices",
  inputs: [{
    start: 0,
    name: "a",
    type: "tensor"
  }, {
    start: 1,
    name: "b",
    type: "tensor"
  }, {
    start: 2,
    end: 0,
    name: "args",
    type: "tensors"
  }],
  attrs: [{
    tfName: "num_args",
    name: "numArgs",
    type: "number"
  }, {
    tfName: "fused_ops",
    name: "fusedOps",
    type: "string[]",
    defaultValue: []
  }, {
    tfName: "epsilon",
    name: "epsilon",
    type: "number",
    defaultValue: 1e-4
  }, {
    tfName: "transpose_a",
    name: "transposeA",
    type: "bool",
    defaultValue: !1
  }, {
    tfName: "transpose_b",
    name: "transposeB",
    type: "bool",
    defaultValue: !1
  }, {
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "MatMul",
  category: "matrices",
  inputs: [{
    start: 0,
    name: "a",
    type: "tensor"
  }, {
    start: 1,
    name: "b",
    type: "tensor"
  }],
  attrs: [{
    tfName: "transpose_a",
    name: "transposeA",
    type: "bool",
    defaultValue: !1
  }, {
    tfName: "transpose_b",
    name: "transposeB",
    type: "bool",
    defaultValue: !1
  }, {
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "BatchMatMul",
  category: "matrices",
  inputs: [{
    start: 0,
    name: "a",
    type: "tensor"
  }, {
    start: 1,
    name: "b",
    type: "tensor"
  }],
  attrs: [{
    tfName: "adj_x",
    name: "transposeA",
    type: "bool",
    defaultValue: !1
  }, {
    tfName: "adj_y",
    name: "transposeB",
    type: "bool",
    defaultValue: !1
  }, {
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "BatchMatMulV2",
  category: "matrices",
  inputs: [{
    start: 0,
    name: "a",
    type: "tensor"
  }, {
    start: 1,
    name: "b",
    type: "tensor"
  }],
  attrs: [{
    tfName: "adj_x",
    name: "transposeA",
    type: "bool",
    defaultValue: !1
  }, {
    tfName: "adj_y",
    name: "transposeB",
    type: "bool",
    defaultValue: !1
  }, {
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Transpose",
  category: "matrices",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "perm",
    type: "number[]"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "Einsum",
  category: "matrices",
  inputs: [{
    start: 0,
    end: 0,
    name: "tensors",
    type: "tensors"
  }],
  attrs: [{
    tfName: "equation",
    name: "equation",
    type: "string"
  }, {
    tfName: "N",
    name: "n",
    type: "number",
    defaultValue: 2
  }, {
    tfName: "T",
    name: "dtype",
    type: "dtype"
  }]
}];
var matrices = {
  __proto__: null,
  json: json$7
};
var json$6 = [{
  tfOpName: "FusedBatchNorm",
  category: "normalization",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "scale",
    type: "tensor"
  }, {
    start: 2,
    name: "offset",
    type: "tensor"
  }, {
    start: 3,
    name: "mean",
    type: "tensor"
  }, {
    start: 4,
    name: "variance",
    type: "tensor"
  }],
  attrs: [{
    tfName: "epsilon",
    name: "epsilon",
    type: "number",
    defaultValue: .001
  }, {
    tfName: "data_format",
    name: "dataFormat",
    type: "string",
    notSupported: !0
  }]
}, {
  tfOpName: "FusedBatchNormV2",
  category: "normalization",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "scale",
    type: "tensor"
  }, {
    start: 2,
    name: "offset",
    type: "tensor"
  }, {
    start: 3,
    name: "mean",
    type: "tensor"
  }, {
    start: 4,
    name: "variance",
    type: "tensor"
  }],
  attrs: [{
    tfName: "epsilon",
    name: "epsilon",
    type: "number",
    defaultValue: .001
  }, {
    tfName: "data_format",
    name: "dataFormat",
    type: "string",
    notSupported: !0
  }]
}, {
  tfOpName: "FusedBatchNormV3",
  category: "normalization",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "scale",
    type: "tensor"
  }, {
    start: 2,
    name: "offset",
    type: "tensor"
  }, {
    start: 3,
    name: "mean",
    type: "tensor"
  }, {
    start: 4,
    name: "variance",
    type: "tensor"
  }],
  attrs: [{
    tfName: "epsilon",
    name: "epsilon",
    type: "number",
    defaultValue: .001
  }, {
    tfName: "data_format",
    name: "dataFormat",
    type: "string",
    notSupported: !0
  }]
}, {
  tfOpName: "LRN",
  category: "normalization",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "depth_radius",
    name: "radius",
    type: "number",
    defaultValue: 5
  }, {
    tfName: "bias",
    name: "bias",
    type: "number",
    defaultValue: 1
  }, {
    tfName: "alpha",
    name: "alpha",
    type: "number",
    defaultValue: 1
  }, {
    tfName: "beta",
    name: "beta",
    type: "number",
    defaultValue: .5
  }]
}, {
  tfOpName: "Softmax",
  category: "normalization",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }]
}, {
  tfOpName: "LogSoftmax",
  category: "normalization",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }]
}, {
  tfOpName: "SparseToDense",
  category: "normalization",
  inputs: [{
    start: 0,
    name: "sparseIndices",
    type: "tensor"
  }, {
    start: 1,
    name: "outputShape",
    type: "number[]"
  }, {
    start: 2,
    name: "sparseValues",
    type: "tensor"
  }, {
    start: 3,
    name: "defaultValue",
    type: "tensor"
  }],
  attrs: [{
    tfName: "validate_indices",
    name: "validateIndices",
    type: "bool",
    defaultValue: !0,
    notSupported: !0
  }]
}];
var normalization = {
  __proto__: null,
  json: json$6
};
var json$5 = [{
  tfOpName: "Bincount",
  category: "reduction",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "size",
    type: "number"
  }, {
    start: 2,
    name: "weights",
    type: "tensor"
  }]
}, {
  tfOpName: "DenseBincount",
  category: "reduction",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "size",
    type: "number"
  }, {
    start: 2,
    name: "weights",
    type: "tensor"
  }],
  attrs: [{
    tfName: "binary_output",
    name: "binaryOutput",
    type: "bool"
  }]
}, {
  tfOpName: "Max",
  category: "reduction",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "axis",
    type: "number[]"
  }],
  attrs: [{
    tfName: "keep_dims",
    name: "keepDims",
    type: "bool"
  }]
}, {
  tfOpName: "Mean",
  category: "reduction",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "axis",
    type: "number[]"
  }],
  attrs: [{
    tfName: "keep_dims",
    name: "keepDims",
    type: "bool"
  }]
}, {
  tfOpName: "Min",
  category: "reduction",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "axis",
    type: "number[]"
  }],
  attrs: [{
    tfName: "keep_dims",
    name: "keepDims",
    type: "bool"
  }]
}, {
  tfOpName: "Sum",
  category: "reduction",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "axis",
    type: "number[]"
  }],
  attrs: [{
    tfName: "keep_dims",
    name: "keepDims",
    type: "bool"
  }]
}, {
  tfOpName: "All",
  category: "reduction",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "axis",
    type: "number[]"
  }],
  attrs: [{
    tfName: "keep_dims",
    name: "keepDims",
    type: "bool"
  }]
}, {
  tfOpName: "Any",
  category: "reduction",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "axis",
    type: "number[]"
  }],
  attrs: [{
    tfName: "keep_dims",
    name: "keepDims",
    type: "bool"
  }]
}, {
  tfOpName: "ArgMax",
  category: "reduction",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "axis",
    type: "number"
  }]
}, {
  tfOpName: "ArgMin",
  category: "reduction",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "axis",
    type: "number"
  }]
}, {
  tfOpName: "Prod",
  category: "reduction",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "axis",
    type: "number[]"
  }],
  attrs: [{
    tfName: "keep_dims",
    name: "keepDims",
    type: "bool"
  }]
}, {
  tfOpName: "Cumsum",
  category: "reduction",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "axis",
    type: "number"
  }],
  attrs: [{
    tfName: "exclusive",
    name: "exclusive",
    type: "bool"
  }, {
    tfName: "reverse",
    name: "reverse",
    type: "bool"
  }]
}];
var reduction = {
  __proto__: null,
  json: json$5
};
var json$4 = [{
  tfOpName: "ConcatV2",
  category: "slice_join",
  inputs: [{
    start: 0,
    end: -1,
    name: "tensors",
    type: "tensors"
  }, {
    start: -1,
    name: "axis",
    type: "number"
  }],
  attrs: [{
    tfName: "N",
    name: "n",
    type: "number",
    defaultValue: 2
  }]
}, {
  tfOpName: "Concat",
  category: "slice_join",
  inputs: [{
    start: 1,
    end: 0,
    name: "tensors",
    type: "tensors"
  }, {
    start: 0,
    name: "axis",
    type: "number"
  }],
  attrs: [{
    tfName: "N",
    name: "n",
    type: "number",
    defaultValue: 2
  }]
}, {
  tfOpName: "GatherV2",
  category: "slice_join",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "indices",
    type: "tensor"
  }, {
    start: 2,
    name: "axis",
    type: "number",
    defaultValue: 0
  }],
  attrs: [{
    tfName: "batch_dims",
    name: "batchDims",
    type: "number",
    defaultValue: 0
  }]
}, {
  tfOpName: "Gather",
  category: "slice_join",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "indices",
    type: "tensor"
  }],
  attrs: [{
    tfName: "validate_indices",
    name: "validateIndices",
    type: "bool",
    notSupported: !0
  }]
}, {
  tfOpName: "Reverse",
  category: "slice_join",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "dims",
    type: "bool[]"
  }]
}, {
  tfOpName: "ReverseV2",
  category: "slice_join",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "axis",
    type: "number[]"
  }]
}, {
  tfOpName: "Slice",
  category: "slice_join",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "begin",
    type: "number[]"
  }, {
    start: 2,
    name: "size",
    type: "number[]"
  }]
}, {
  tfOpName: "StridedSlice",
  category: "slice_join",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "begin",
    type: "number[]"
  }, {
    start: 2,
    name: "end",
    type: "number[]"
  }, {
    start: 3,
    name: "strides",
    type: "number[]"
  }],
  attrs: [{
    tfName: "begin_mask",
    name: "beginMask",
    type: "number",
    defaultValue: 0
  }, {
    tfName: "end_mask",
    name: "endMask",
    type: "number",
    defaultValue: 0
  }, {
    tfName: "new_axis_mask",
    name: "newAxisMask",
    type: "number",
    defaultValue: 0
  }, {
    tfName: "ellipsis_mask",
    name: "ellipsisMask",
    type: "number",
    defaultValue: 0
  }, {
    tfName: "shrink_axis_mask",
    name: "shrinkAxisMask",
    type: "number",
    defaultValue: 0
  }]
}, {
  tfOpName: "Pack",
  category: "slice_join",
  inputs: [{
    start: 0,
    end: 0,
    name: "tensors",
    type: "tensors"
  }],
  attrs: [{
    tfName: "axis",
    name: "axis",
    type: "number",
    defaultValue: 0
  }]
}, {
  tfOpName: "Unpack",
  category: "slice_join",
  inputs: [{
    start: 0,
    name: "tensor",
    type: "tensor"
  }],
  attrs: [{
    tfName: "axis",
    name: "axis",
    type: "number",
    defaultValue: 0
  }, {
    tfName: "num",
    name: "num",
    type: "number",
    defaultValue: 0,
    notSupported: !0
  }]
}, {
  tfOpName: "Tile",
  category: "slice_join",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "reps",
    type: "number[]"
  }]
}, {
  tfOpName: "Split",
  category: "slice_join",
  inputs: [{
    start: 0,
    name: "axis",
    type: "number",
    defaultValue: 0
  }, {
    start: 1,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "num_split",
    name: "numOrSizeSplits",
    type: "number",
    defaultValue: 1
  }]
}, {
  tfOpName: "SplitV",
  category: "slice_join",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "numOrSizeSplits",
    type: "number[]"
  }, {
    start: 2,
    name: "axis",
    type: "number",
    defaultValue: 0
  }]
}, {
  tfOpName: "ScatterNd",
  category: "slice_join",
  inputs: [{
    start: 0,
    name: "indices",
    type: "tensor"
  }, {
    start: 1,
    name: "values",
    type: "tensor"
  }, {
    start: 2,
    name: "shape",
    type: "number[]"
  }]
}, {
  tfOpName: "GatherNd",
  category: "slice_join",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "indices",
    type: "tensor"
  }]
}, {
  tfOpName: "SparseToDense",
  category: "slice_join",
  inputs: [{
    start: 0,
    name: "sparseIndices",
    type: "tensor"
  }, {
    start: 1,
    name: "outputShape",
    type: "number[]"
  }, {
    start: 2,
    name: "sparseValues",
    type: "tensor"
  }, {
    start: 3,
    name: "defaultValue",
    type: "tensor"
  }],
  attrs: [{
    tfName: "validate_indices",
    name: "validateIndices",
    type: "bool",
    defaultValue: !1,
    notSupported: !0
  }]
}];
var sliceJoin = {
  __proto__: null,
  json: json$4
};
var json$3 = [{
  tfOpName: "SparseFillEmptyRows",
  category: "sparse",
  inputs: [{
    start: 0,
    name: "indices",
    type: "tensor"
  }, {
    start: 1,
    name: "values",
    type: "tensor"
  }, {
    start: 2,
    name: "denseShape",
    type: "tensor"
  }, {
    start: 3,
    name: "defaultValue",
    type: "tensor"
  }]
}, {
  tfOpName: "SparseReshape",
  category: "sparse",
  inputs: [{
    start: 0,
    name: "inputIndices",
    type: "tensor"
  }, {
    start: 1,
    name: "inputShape",
    type: "tensor"
  }, {
    start: 2,
    name: "newShape",
    type: "tensor"
  }],
  attrs: [{
    tfName: "T",
    name: "dtype",
    type: "dtype",
    notSupported: !0
  }]
}, {
  tfOpName: "SparseSegmentMean",
  category: "sparse",
  inputs: [{
    start: 0,
    name: "data",
    type: "tensor"
  }, {
    start: 1,
    name: "indices",
    type: "tensor"
  }, {
    start: 2,
    name: "segmentIds",
    type: "tensor"
  }]
}, {
  tfOpName: "SparseSegmentSum",
  category: "sparse",
  inputs: [{
    start: 0,
    name: "data",
    type: "tensor"
  }, {
    start: 1,
    name: "indices",
    type: "tensor"
  }, {
    start: 2,
    name: "segmentIds",
    type: "tensor"
  }]
}];
var sparse = {
  __proto__: null,
  json: json$3
};
var json$2 = [{
  tfOpName: "FFT",
  category: "spectral",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }]
}, {
  tfOpName: "IFFT",
  category: "spectral",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }]
}, {
  tfOpName: "RFFT",
  category: "spectral",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "fft_length",
    type: "number",
    notSupported: !0
  }]
}, {
  tfOpName: "IRFFT",
  category: "spectral",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "fft_length",
    type: "number",
    notSupported: !0
  }]
}];
var spectral = {
  __proto__: null,
  json: json$2
};
var json$1 = [{
  tfOpName: "StringNGrams",
  category: "string",
  inputs: [{
    start: 0,
    name: "data",
    type: "tensor"
  }, {
    start: 1,
    name: "dataSplits",
    type: "tensor"
  }],
  attrs: [{
    tfName: "separator",
    name: "separator",
    type: "string"
  }, {
    tfName: "ngram_widths",
    name: "nGramWidths",
    type: "number[]"
  }, {
    tfName: "left_pad",
    name: "leftPad",
    type: "string"
  }, {
    tfName: "right_pad",
    name: "rightPad",
    type: "string"
  }, {
    tfName: "pad_width",
    name: "padWidth",
    type: "number"
  }, {
    tfName: "preserve_short_sequences",
    name: "preserveShortSequences",
    type: "bool"
  }],
  outputs: ["ngrams", "ngrams_splits"]
}, {
  tfOpName: "StringSplit",
  category: "string",
  inputs: [{
    start: 0,
    name: "input",
    type: "tensor"
  }, {
    start: 1,
    name: "delimiter",
    type: "tensor"
  }],
  attrs: [{
    tfName: "skip_empty",
    name: "skipEmpty",
    type: "bool"
  }],
  outputs: ["indices", "values", "shape"]
}, {
  tfOpName: "StringToHashBucketFast",
  category: "string",
  inputs: [{
    start: 0,
    name: "input",
    type: "tensor"
  }],
  attrs: [{
    tfName: "num_buckets",
    name: "numBuckets",
    type: "number"
  }]
}];
var string = {
  __proto__: null,
  json: json$1
};
var json = [{
  tfOpName: "Cast",
  category: "transformation",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "SrcT",
    name: "sdtype",
    type: "dtype",
    notSupported: !0
  }, {
    tfName: "DstT",
    name: "dtype",
    type: "dtype"
  }]
}, {
  tfOpName: "ExpandDims",
  category: "transformation",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "axis",
    type: "number"
  }]
}, {
  tfOpName: "MirrorPad",
  category: "transformation",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "padding",
    type: "number[]"
  }],
  attrs: [{
    tfName: "mode",
    name: "mode",
    type: "string"
  }]
}, {
  tfOpName: "Pad",
  category: "transformation",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "padding",
    type: "number[]"
  }],
  attrs: [{
    tfName: "constant_value",
    name: "constantValue",
    type: "number",
    defaultValue: 0
  }]
}, {
  tfOpName: "PadV2",
  category: "transformation",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "padding",
    type: "number[]"
  }, {
    start: 2,
    name: "constantValue",
    type: "number",
    defaultValue: 0
  }]
}, {
  tfOpName: "Reshape",
  category: "transformation",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "shape",
    type: "number[]"
  }]
}, {
  tfOpName: "Squeeze",
  category: "transformation",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "axis",
    tfDeprecatedName: "squeeze_dims",
    name: "axis",
    type: "number[]"
  }]
}, {
  tfOpName: "SpaceToBatchND",
  category: "transformation",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "blockShape",
    type: "number[]"
  }, {
    start: 2,
    name: "paddings",
    type: "number[]"
  }]
}, {
  tfOpName: "BatchToSpaceND",
  category: "transformation",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "blockShape",
    type: "number[]"
  }, {
    start: 2,
    name: "crops",
    type: "number[]"
  }]
}, {
  tfOpName: "DepthToSpace",
  category: "transformation",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }],
  attrs: [{
    tfName: "block_size",
    name: "blockSize",
    type: "number"
  }, {
    tfName: "data_format",
    name: "dataFormat",
    type: "string"
  }]
}, {
  tfOpName: "BroadcastTo",
  category: "transformation",
  inputs: [{
    start: 0,
    name: "x",
    type: "tensor"
  }, {
    start: 1,
    name: "shape",
    type: "number[]"
  }],
  attrs: []
}];
var transformation = {
  __proto__: null,
  json
};

class OperationMapper {
  static get Instance() {
    return this._instance || (this._instance = new this());
  }

  constructor() {
    var e = [].concat(...[arithmetic, basicMath, control, convolution, creation, dynamic, evaluation, graph, hashTable, image, logical, matrices, normalization, reduction, sliceJoin, sparse, spectral, string, transformation].map(e => e.json));
    this.opMappers = e.reduce((e, t) => (e[t.tfOpName] = t, e), {});
  }

  transformGraph(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};
    var n = [],
        r = [],
        a = [],
        s = e.node.reduce((e, t) => (e[t.name] = this.mapNode(t), t.op.startsWith("Placeholder") ? n.push(e[t.name]) : "Const" === t.op ? r.push(e[t.name]) : null != t.input && 0 !== t.input.length || a.push(e[t.name]), e), {});
    var o = [];
    var i = [];
    var l = {},
        u = {};
    null != t && (l = this.mapSignatureEntries(t.inputs), u = this.mapSignatureEntries(t.outputs));
    var c = Object.keys(s);
    c.forEach(e => {
      var t = s[e];
      t.inputNames.forEach((e, n) => {
        var [r,, a] = getNodeNameAndIndex(e),
            o = s[r];

        if (null != o.outputs) {
          var _e775 = o.outputs.indexOf(a);

          -1 !== _e775 && (t.inputNames[n] = "".concat(r, ":").concat(_e775));
        }

        t.inputs.push(o), o.children.push(t);
      });
    }), 0 === Object.keys(u).length ? c.forEach(e => {
      var t = s[e];
      0 === t.children.length && i.push(t);
    }) : Object.keys(u).forEach(e => {
      var [t] = getNodeNameAndIndex(e),
          n = s[t];
      null != n && (n.signatureKey = u[e], i.push(n));
    }), Object.keys(l).length > 0 ? Object.keys(l).forEach(e => {
      var [t] = getNodeNameAndIndex(e),
          n = s[t];
      n && (n.signatureKey = l[e], o.push(n));
    }) : o = n;
    var p = {};
    null != e.library && null != e.library.function && (p = e.library.function.reduce((e, t) => (e[t.signature.name] = this.mapFunction(t), e), {}));
    var d = {
      nodes: s,
      inputs: o,
      outputs: i,
      weights: r,
      placeholders: n,
      signature: t,
      functions: p
    };
    return a.length > 0 && (d.initNodes = a), d;
  }

  mapSignatureEntries(e) {
    return Object.keys(e || {}).reduce((t, n) => (t[e[n].name] = n, t), {});
  }

  mapNode(e) {
    var t = getRegisteredOp(e.op) || this.opMappers[e.op] || {};
    null == e.attr && (e.attr = {});
    var n = {
      name: e.name,
      op: e.op,
      category: t.category,
      inputNames: (e.input || []).map(e => e.startsWith("^") ? e.substr(1) : e),
      inputs: [],
      children: [],
      inputParams: {},
      attrParams: {},
      rawAttrs: e.attr,
      outputs: t.outputs
    };
    return null != t.inputs && (n.inputParams = t.inputs.reduce((e, t) => (e[t.name] = {
      type: t.type,
      inputIndexStart: t.start,
      inputIndexEnd: t.end
    }, e), {})), null != t.attrs && (n.attrParams = t.attrs.reduce((t, n) => {
      var r = n.type;
      var a;

      switch (n.type) {
        case "string":
          a = getStringParam(e.attr, n.tfName, n.defaultValue), void 0 === a && n.tfDeprecatedName && (a = getStringParam(e.attr, n.tfDeprecatedName, n.defaultValue));
          break;

        case "string[]":
          a = getStringArrayParam(e.attr, n.tfName, n.defaultValue), void 0 === a && n.tfDeprecatedName && (a = getStringArrayParam(e.attr, n.tfDeprecatedName, n.defaultValue));
          break;

        case "number":
          a = getNumberParam(e.attr, n.tfName, n.defaultValue || 0), void 0 === a && n.tfDeprecatedName && (a = getNumberParam(e.attr, n.tfDeprecatedName, n.defaultValue));
          break;

        case "number[]":
          a = getNumericArrayParam(e.attr, n.tfName, n.defaultValue), void 0 === a && n.tfDeprecatedName && (a = getNumericArrayParam(e.attr, n.tfDeprecatedName, n.defaultValue));
          break;

        case "bool":
          a = getBoolParam(e.attr, n.tfName, n.defaultValue), void 0 === a && n.tfDeprecatedName && (a = getBoolParam(e.attr, n.tfDeprecatedName, n.defaultValue));
          break;

        case "bool[]":
          a = getBoolArrayParam(e.attr, n.tfName, n.defaultValue), void 0 === a && n.tfDeprecatedName && (a = getBoolArrayParam(e.attr, n.tfDeprecatedName, n.defaultValue));
          break;

        case "shape":
          a = getTensorShapeParam(e.attr, n.tfName, n.defaultValue), void 0 === a && n.tfDeprecatedName && (a = getTensorShapeParam(e.attr, n.tfDeprecatedName, n.defaultValue));
          break;

        case "shape[]":
          a = getTensorShapeArrayParam(e.attr, n.tfName, n.defaultValue), void 0 === a && n.tfDeprecatedName && (a = getTensorShapeArrayParam(e.attr, n.tfDeprecatedName, n.defaultValue));
          break;

        case "dtype":
          a = getDtypeParam(e.attr, n.tfName, n.defaultValue), void 0 === a && n.tfDeprecatedName && (a = getDtypeParam(e.attr, n.tfDeprecatedName, n.defaultValue));
          break;

        case "dtype[]":
          a = getDtypeArrayParam(e.attr, n.tfName, n.defaultValue), void 0 === a && n.tfDeprecatedName && (a = getDtypeArrayParam(e.attr, n.tfDeprecatedName, n.defaultValue));
          break;

        case "func":
          a = getFuncParam(e.attr, n.tfName, n.defaultValue), void 0 === a && n.tfDeprecatedName && (a = getFuncParam(e.attr, n.tfDeprecatedName, n.defaultValue));
          break;

        case "tensor":
        case "tensors":
          break;

        default:
          throw new Error("Unsupported param type: ".concat(n.type, " for op: ").concat(e.op));
      }

      return t[n.name] = {
        value: a,
        type: r
      }, t;
    }, {})), n;
  }

  mapFunction(e) {
    var t = e.nodeDef,
        n = [];
    var r = {};
    null != t && (r = t.reduce((e, t) => (e[t.name] = this.mapNode(t), "Const" === t.op && n.push(e[t.name]), e), {}));
    var a = [],
        s = [];
    e.signature.inputArg.forEach(e => {
      var [t] = getNodeNameAndIndex(e.name),
          n = {
        name: t,
        op: "Placeholder",
        inputs: [],
        inputNames: [],
        category: "graph",
        inputParams: {},
        attrParams: {
          dtype: {
            value: parseDtypeParam(e.type),
            type: "dtype"
          }
        },
        children: []
      };
      n.signatureKey = e.name, a.push(n), r[t] = n;
    }), Object.keys(r).forEach(e => {
      var t = r[e];
      t.inputNames.forEach((e, n) => {
        var [a,, s] = getNodeNameAndIndex(e),
            o = r[a];

        if (null != o.outputs) {
          var _e776 = o.outputs.indexOf(s);

          -1 !== _e776 && (t.inputNames[n] = "".concat(a, ":").concat(_e776));
        }

        t.inputs.push(o), o.children.push(t);
      });
    });
    var o = e.ret;
    e.signature.outputArg.forEach(e => {
      var [t, n] = getNodeNameAndIndex(o[e.name]),
          a = r[t];
      null != a && (a.defaultOutput = n, s.push(a));
    });
    var i = this.mapArgsToSignature(e);
    return {
      nodes: r,
      inputs: a,
      outputs: s,
      weights: n,
      placeholders: [],
      signature: i
    };
  }

  mapArgsToSignature(e) {
    return {
      methodName: e.signature.name,
      inputs: e.signature.inputArg.reduce((e, t) => (e[t.name] = this.mapArgToTensorInfo(t), e), {}),
      outputs: e.signature.outputArg.reduce((t, n) => (t[n.name] = this.mapArgToTensorInfo(n, e.ret), t), {})
    };
  }

  mapArgToTensorInfo(e, t) {
    var n = e.name;
    return null != t && (n = t[n]), {
      name: n,
      dtype: e.type
    };
  }

}

function decodeBase64(e) {
  var t = env().global;
  if (void 0 !== t.atob) return t.atob(e);
  if ("undefined" != typeof Buffer) return new Buffer(e, "base64").toString();
  throw new Error("Unable to decode base64 in this environment. Missing built-in atob() or Buffer()");
}

function parseStringParam(e, t) {
  var n = Array.isArray(e) ? String.fromCharCode.apply(null, e) : decodeBase64(e);
  return t ? n : n.toLowerCase();
}

function getStringParam(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
  var a = e[t];
  return null != a ? parseStringParam(a.s, r) : n;
}

function getBoolParam(e, t, n) {
  var r = e[t];
  return r ? r.b : n;
}

function getNumberParam(e, t, n) {
  var r = e[t] || {},
      a = null != r.i ? r.i : null != r.f ? r.f : n;
  return "number" == typeof a ? a : parseInt(a, 10);
}

function parseDtypeParam(e) {
  switch ("string" == typeof e && (e = DataType[e]), e) {
    case DataType.DT_FLOAT:
      return "float32";

    case DataType.DT_INT32:
    case DataType.DT_INT64:
    case DataType.DT_INT8:
    case DataType.DT_UINT8:
      return "int32";

    case DataType.DT_BOOL:
      return "bool";

    case DataType.DT_DOUBLE:
      return "float32";

    case DataType.DT_STRING:
      return "string";

    default:
      return null;
  }
}

function getFuncParam(e, t, n) {
  var r = e[t];
  return r && r.func ? r.func.name : n;
}

function getDtypeParam(e, t, n) {
  var r = e[t];
  return r && r.type ? parseDtypeParam(r.type) : n;
}

function getDtypeArrayParam(e, t, n) {
  var r = e[t];
  return r && r.list && r.list.type ? r.list.type.map(e => parseDtypeParam(e)) : n;
}

function parseTensorShapeParam(e) {
  if (!e.unknownRank) return null != e.dim ? e.dim.map(e => "number" == typeof e.size ? e.size : parseInt(e.size, 10)) : [];
}

function getTensorShapeParam(e, t, n) {
  var r = e[t];
  return r && r.shape ? parseTensorShapeParam(r.shape) : n;
}

function getNumericArrayParam(e, t, n) {
  var r = e[t];
  return r ? ((r.list.f && r.list.f.length ? r.list.f : r.list.i) || []).map(e => "number" == typeof e ? e : parseInt(e, 10)) : n;
}

function getStringArrayParam(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
  var a = e[t];
  return a && a.list && a.list.s ? a.list.s.map(e => parseStringParam(e, r)) : n;
}

function getTensorShapeArrayParam(e, t, n) {
  var r = e[t];
  return r && r.list && r.list.shape ? r.list.shape.map(e => parseTensorShapeParam(e)) : n;
}

function getBoolArrayParam(e, t, n) {
  var r = e[t];
  return r && r.list && r.list.b ? r.list.b : n;
}

class NodeValueImpl {
  constructor(e, t, n) {
    this.node = e, this.tensorMap = t, this.context = n, this.inputs = [], this.attrs = {}, this.inputs = e.inputNames.map(e => this.getInput(e)), null != e.rawAttrs && (this.attrs = Object.keys(e.rawAttrs).reduce((e, t) => (e[t] = this.getAttr(t), e), {}));
  }

  getInput(e) {
    return getTensor(e, this.tensorMap, this.context);
  }

  getAttr(e, t) {
    var n = this.node.rawAttrs[e];
    if (null != n.tensor) return getTensor(e, this.tensorMap, this.context);
    if (null != n.i || null != n.f) return getNumberParam(this.node.rawAttrs, e, t);
    if (null != n.s) return getStringParam(this.node.rawAttrs, e, t);
    if (null != n.b) return getBoolParam(this.node.rawAttrs, e, t);
    if (null != n.shape) return getTensorShapeParam(this.node.rawAttrs, e, t);
    if (null != n.type) return getDtypeParam(this.node.rawAttrs, e, t);

    if (null != n.list) {
      if (null != n.list.i || null != n.list.f) return getNumericArrayParam(this.node.rawAttrs, e, t);
      if (null != n.list.s) return getStringArrayParam(this.node.rawAttrs, e, t);
      if (null != n.list.shape) return getTensorShapeArrayParam(this.node.rawAttrs, e, t);
      if (null != n.list.b) return getBoolArrayParam(this.node.rawAttrs, e, t);
      if (null != n.list.type) return getDtypeArrayParam(this.node.rawAttrs, e, t);
    }

    return t;
  }

}

var executeOp$j = (e, t, n) => {
  switch (e.op) {
    case "BiasAdd":
    case "AddV2":
    case "Add":
      return [add$2(getParamValue("a", e, t, n), getParamValue("b", e, t, n))];

    case "AddN":
      return [addN$2(getParamValue("tensors", e, t, n))];

    case "FloorMod":
    case "Mod":
      return [mod$2(getParamValue("a", e, t, n), getParamValue("b", e, t, n))];

    case "Mul":
      return [mul(getParamValue("a", e, t, n), getParamValue("b", e, t, n))];

    case "RealDiv":
    case "Div":
      return [div$1(getParamValue("a", e, t, n), getParamValue("b", e, t, n))];

    case "DivNoNan":
      return [divNoNan(getParamValue("a", e, t, n), getParamValue("b", e, t, n))];

    case "FloorDiv":
      return [floorDiv$2(getParamValue("a", e, t, n), getParamValue("b", e, t, n))];

    case "Sub":
      return [sub$2(getParamValue("a", e, t, n), getParamValue("b", e, t, n))];

    case "Minimum":
      return [minimum$3(getParamValue("a", e, t, n), getParamValue("b", e, t, n))];

    case "Maximum":
      return [maximum$3(getParamValue("a", e, t, n), getParamValue("b", e, t, n))];

    case "Pow":
      return [pow$2(getParamValue("a", e, t, n), getParamValue("b", e, t, n))];

    case "SquaredDifference":
      return [squaredDifference$2(getParamValue("a", e, t, n), getParamValue("b", e, t, n))];

    default:
      throw TypeError("Node type ".concat(e.op, " is not implemented"));
  }
},
    executeOp$i = (e, t, n) => {
  switch (e.op) {
    case "Abs":
    case "ComplexAbs":
      return [abs$2(getParamValue("x", e, t, n))];

    case "Acos":
      return [acos$2(getParamValue("x", e, t, n))];

    case "Acosh":
      return [acosh$2(getParamValue("x", e, t, n))];

    case "Asin":
      return [asin$2(getParamValue("x", e, t, n))];

    case "Asinh":
      return [asinh$2(getParamValue("x", e, t, n))];

    case "Atan":
      return [atan$2(getParamValue("x", e, t, n))];

    case "Atan2":
      return [atan2$2(getParamValue("x", e, t, n), getParamValue("y", e, t, n))];

    case "Atanh":
      return [atanh$2(getParamValue("x", e, t, n))];

    case "Ceil":
      return [ceil$2(getParamValue("x", e, t, n))];

    case "Complex":
      return [complex$2(getParamValue("real", e, t, n), getParamValue("imag", e, t, n))];

    case "Cos":
      return [cos$2(getParamValue("x", e, t, n))];

    case "Cosh":
      return [cosh$2(getParamValue("x", e, t, n))];

    case "Elu":
      return [elu$4(getParamValue("x", e, t, n))];

    case "Erf":
      return [erf$2(getParamValue("x", e, t, n))];

    case "Exp":
      return [exp$2(getParamValue("x", e, t, n))];

    case "Expm1":
      return [expm1$2(getParamValue("x", e, t, n))];

    case "Floor":
      return [floor$2(getParamValue("x", e, t, n))];

    case "Log":
      return [log$3(getParamValue("x", e, t, n))];

    case "Log1p":
      return [log1p$2(getParamValue("x", e, t, n))];

    case "Imag":
      return [imag$2(getParamValue("x", e, t, n))];

    case "Neg":
      return [neg$2(getParamValue("x", e, t, n))];

    case "Reciprocal":
      return [reciprocal$2(getParamValue("x", e, t, n))];

    case "Real":
      return [real$2(getParamValue("x", e, t, n))];

    case "Relu":
      return [relu$3(getParamValue("x", e, t, n))];

    case "Round":
      return [round$2(getParamValue("x", e, t, n))];

    case "Selu":
      return [selu$2(getParamValue("x", e, t, n))];

    case "Sigmoid":
      return [sigmoid$2(getParamValue("x", e, t, n))];

    case "Sin":
      return [sin$2(getParamValue("x", e, t, n))];

    case "Sign":
      return [sign$2(getParamValue("x", e, t, n))];

    case "Sinh":
      return [sinh$2(getParamValue("x", e, t, n))];

    case "Softplus":
      return [softplus$2(getParamValue("x", e, t, n))];

    case "Sqrt":
      return [sqrt$2(getParamValue("x", e, t, n))];

    case "Square":
      return [square$2(getParamValue("x", e, t, n))];

    case "Tanh":
      return [tanh$2(getParamValue("x", e, t, n))];

    case "Tan":
      return [tan$2(getParamValue("x", e, t, n))];

    case "ClipByValue":
      return [clipByValue$1(getParamValue("x", e, t, n), getParamValue("clipValueMin", e, t, n), getParamValue("clipValueMax", e, t, n))];

    case "Relu6":
      return [relu6$2(getParamValue("x", e, t, n))];

    case "Rsqrt":
      return [rsqrt$2(getTensor(e.inputNames[0], t, n))];

    case "Prod":
      return [prod$2(getParamValue("x", e, t, n), getParamValue("axes", e, t, n))];

    case "LeakyRelu":
      return [leakyRelu$2(getParamValue("x", e, t, n), getParamValue("alpha", e, t, n))];

    case "Prelu":
      return [prelu$3(getParamValue("x", e, t, n), getParamValue("alpha", e, t, n))];

    case "IsNan":
      return [isNaN$3(getTensor(e.inputNames[0], t, n))];

    default:
      throw TypeError("Node type ".concat(e.op, " is not implemented"));
  }
};

function assertShapesMatchAllowUndefinedSize(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : "";

  if ("number" != typeof e && "number" != typeof t) {
    assert$4(e.length === t.length, () => n + " Shapes ".concat(e, " and ").concat(t, " must match"));

    for (var r = 0; r < e.length; r++) {
      var a = e[r],
          s = t[r];
      assert$4(a < 0 || s < 0 || a === s, () => n + " Shapes ".concat(e, " and ").concat(t, " must match"));
    }
  }
}

function fullDefinedShape(e) {
  return "number" != typeof e && !e.some(e => e < 0);
}

function inferElementShape(e, t, n) {
  var r = mergeElementShape(e, n);
  var a = !fullDefinedShape(r);
  if (a && 0 === t.length) throw new Error("Tried to calculate elements of an empty list with non-fully-defined elementShape: ".concat(r));
  if (a && t.forEach(e => {
    r = mergeElementShape(e.shape, r);
  }), !fullDefinedShape(r)) throw new Error("Non-fully-defined elementShape: ".concat(r));
  return r;
}

function mergeElementShape(e, t) {
  if ("number" == typeof e) return t;
  if ("number" == typeof t) return e;
  if (e.length !== t.length) throw new Error("Incompatible ranks during merge: ".concat(e, " vs. ").concat(t));
  var n = [];

  for (var r = 0; r < e.length; ++r) {
    var a = e[r],
        s = t[r];
    if (a >= 0 && s >= 0 && a !== s) throw new Error("Incompatible shape during merge: ".concat(e, " vs. ").concat(t));
    n[r] = a >= 0 ? a : s;
  }

  return n;
}

class TensorArray {
  constructor(e, t, n, r, a, s, o) {
    this.name = e, this.dtype = t, this.maxSize = n, this.elementShape = r, this.identicalElementShapes = a, this.dynamicSize = s, this.clearAfterRead = o, this.tensors = [], this.closed_ = !1, this.idTensor = scalar(0), keep(this.idTensor);
  }

  get id() {
    return this.idTensor.id;
  }

  get closed() {
    return this.closed_;
  }

  clearAndClose(e) {
    this.tensors.forEach(t => {
      null != e && e.has(t.tensor.id) || t.tensor.dispose();
    }), this.tensors = [], this.closed_ = !0, this.idTensor.dispose();
  }

  size() {
    return this.tensors.length;
  }

  read(e) {
    if (this.closed_) throw new Error("TensorArray ".concat(this.name, " has already been closed."));
    if (e < 0 || e >= this.size()) throw new Error("Tried to read from index ".concat(e, ", but array size is: ").concat(this.size()));
    var t = this.tensors[e];
    if (t.cleared) throw new Error("TensorArray ".concat(this.name, ": Could not read index ").concat(e, " twice because it was cleared after a previous read (perhaps try setting clear_after_read = false?)."));
    return this.clearAfterRead && (t.cleared = !0), t.read = !0, t.tensor;
  }

  readMany(e) {
    return e.map(e => this.read(e));
  }

  write(e, t) {
    if (this.closed_) throw new Error("TensorArray ".concat(this.name, " has already been closed."));
    if (e < 0 || !this.dynamicSize && e >= this.maxSize) throw new Error("Tried to write to index ".concat(e, ", but array is not resizeable and size is: ").concat(this.maxSize));
    var n = this.tensors[e] || {};
    if (t.dtype !== this.dtype) throw new Error("TensorArray ".concat(this.name, ": Could not write to TensorArray index ").concat(e, ",\n          because the value dtype is ").concat(t.dtype, ", but TensorArray dtype is ").concat(this.dtype, "."));
    if (0 !== this.size() || null != this.elementShape && 0 !== this.elementShape.length || (this.elementShape = t.shape), assertShapesMatchAllowUndefinedSize(this.elementShape, t.shape, "TensorArray ".concat(this.name, ": Could not write to TensorArray index ").concat(e, ".")), n.read) throw new Error("TensorArray ".concat(this.name, ": Could not write to TensorArray index ").concat(e, ", because it has already been read."));
    if (n.written) throw new Error("TensorArray ".concat(this.name, ": Could not write to TensorArray index ").concat(e, ", because it has already been written."));
    n.tensor = t, keep(t), n.written = !0, this.tensors[e] = n;
  }

  writeMany(e, t) {
    if (e.length !== t.length) throw new Error("TensorArray ".concat(this.name, ": could not write multiple tensors,because the index size: ").concat(e.length, " is not the same as tensors size: ").concat(t.length, "."));
    e.forEach((e, n) => this.write(e, t[n]));
  }

  gather(e, t) {
    if (t && t !== this.dtype) throw new Error("TensorArray dtype is ".concat(this.dtype, " but gather requested dtype ").concat(t));
    if (e) e = e.slice(0, this.size());else {
      e = [];

      for (var _t535 = 0; _t535 < this.size(); _t535++) {
        e.push(_t535);
      }
    }
    if (0 === e.length) return tensor([], [0].concat(this.elementShape));
    var n = this.readMany(e);
    return assertShapesMatchAllowUndefinedSize(this.elementShape, n[0].shape, "TensorArray shape mismatch: "), stack(n, 0);
  }

  concat(e) {
    if (e && e !== this.dtype) throw new Error("TensorArray dtype is ".concat(this.dtype, " but concat requested dtype ").concat(e));
    if (0 === this.size()) return tensor([], [0].concat(this.elementShape));
    var t = [];

    for (var _e777 = 0; _e777 < this.size(); _e777++) {
      t.push(_e777);
    }

    var n = this.readMany(t);
    return assertShapesMatchAllowUndefinedSize(this.elementShape, n[0].shape, "TensorArray shape mismatch: tensor array shape (".concat(this.elementShape, ") vs first tensor shape (").concat(n[0].shape, ")")), concat$2(n, 0);
  }

  scatter(e, t) {
    if (t.dtype !== this.dtype) throw new Error("TensorArray dtype is ".concat(this.dtype, " but tensor has dtype ").concat(t.dtype));
    if (e.length !== t.shape[0]) throw new Error("Expected len(indices) == tensor.shape[0], but saw: ".concat(e.length, " vs. ").concat(t.shape[0]));
    var n = Math.max(...e);
    if (!this.dynamicSize && n >= this.maxSize) throw new Error("Max index must be < array size (".concat(n, "  vs. ").concat(this.maxSize, ")"));
    this.writeMany(e, unstack(t, 0));
  }

  split(e, t) {
    if (t.dtype !== this.dtype) throw new Error("TensorArray dtype is ".concat(this.dtype, " but tensor has dtype ").concat(t.dtype));
    var n = 0;
    var r = e.map(e => (n += e, n));
    if (n !== t.shape[0]) throw new Error("Expected sum of lengths to be equal to\n          tensor.shape[0], but sum of lengths is\n        ".concat(n, ", and tensor's shape is: ").concat(t.shape));
    if (!this.dynamicSize && e.length !== this.maxSize) throw new Error("TensorArray's size is not equal to the size of lengths (".concat(this.maxSize, " vs. ").concat(e.length, "), and the TensorArray is not marked as dynamically resizeable"));
    var a = 0 === n ? 0 : t.size / n,
        s = [];
    tidy(() => {
      t = reshape$3(t, [1, n, a]);

      for (var _n302 = 0; _n302 < e.length; ++_n302) {
        s[_n302] = reshape$3(slice$2(t, [0, 0 === _n302 ? 0 : r[_n302 - 1], 0], [1, e[_n302], a]), this.elementShape);
      }

      return s;
    });
    var o = [];

    for (var _t536 = 0; _t536 < e.length; _t536++) {
      o[_t536] = _t536;
    }

    this.writeMany(o, s);
  }

}

class TensorList {
  constructor(e, t, n) {
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : -1;
    this.tensors = e, this.elementShape = t, this.elementDtype = n, null != e && e.forEach(e => {
      if (n !== e.dtype) throw new Error("Invalid data types; op elements ".concat(n, ", but list elements ").concat(e.dtype));
      assertShapesMatchAllowUndefinedSize(t, e.shape, "TensorList shape mismatch: "), keep(e);
    }), this.idTensor = scalar(0), this.maxNumElements = r, keep(this.idTensor);
  }

  get id() {
    return this.idTensor.id;
  }

  copy() {
    return new TensorList([...this.tensors], this.elementShape, this.elementDtype);
  }

  clearAndClose(e) {
    this.tensors.forEach(t => {
      null != e && e.has(t.id) || t.dispose();
    }), this.tensors.length = 0, this.idTensor.dispose();
  }

  size() {
    return this.tensors.length;
  }

  stack(e, t) {
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : -1;
    if (t !== this.elementDtype) throw new Error("Invalid data types; op elements ".concat(t, ", but list elements ").concat(this.elementDtype));
    if (-1 !== n && this.tensors.length !== n) throw new Error("Operation expected a list with ".concat(n, " elements but got a list with ").concat(this.tensors.length, " elements."));
    assertShapesMatchAllowUndefinedSize(e, this.elementShape, "TensorList shape mismatch: ");
    var r = inferElementShape(this.elementShape, this.tensors, e);
    return tidy(() => {
      var e = this.tensors.map(e => reshape$3(e, r));
      return stack(e, 0);
    });
  }

  popBack(e, t) {
    if (t !== this.elementDtype) throw new Error("Invalid data types; op elements ".concat(t, ", but list elements ").concat(this.elementDtype));
    if (0 === this.size()) throw new Error("Trying to pop from an empty list.");
    var n = inferElementShape(this.elementShape, this.tensors, e),
        r = this.tensors.pop();
    return assertShapesMatchAllowUndefinedSize(r.shape, e, "TensorList shape mismatch: "), reshape$3(r, n);
  }

  pushBack(e) {
    if (e.dtype !== this.elementDtype) throw new Error("Invalid data types; op elements ".concat(e.dtype, ", but list elements ").concat(this.elementDtype));
    if (assertShapesMatchAllowUndefinedSize(e.shape, this.elementShape, "TensorList shape mismatch: "), this.maxNumElements === this.size()) throw new Error("Trying to push element into a full list.");
    keep(e), this.tensors.push(e);
  }

  resize(e) {
    if (e < 0) throw new Error("TensorListResize expects size to be non-negative. Got: ".concat(e));
    if (-1 !== this.maxNumElements && e > this.maxNumElements) throw new Error("TensorListResize input size ".concat(e, " is greater maxNumElement ").concat(this.maxNumElements, "."));
    this.tensors.length = e;
  }

  getItem(e, t, n) {
    if (n !== this.elementDtype) throw new Error("Invalid data types; op elements ".concat(n, ", but list elements ").concat(this.elementDtype));
    if (e < 0 || e > this.tensors.length) throw new Error("Trying to access element ".concat(e, " in a list with ").concat(this.tensors.length, " elements."));
    if (null == this.tensors[e]) throw new Error("element at index ".concat(e, " is null."));
    assertShapesMatchAllowUndefinedSize(this.tensors[e].shape, t, "TensorList shape mismatch: ");
    var r = inferElementShape(this.elementShape, this.tensors, t);
    return reshape$3(this.tensors[e], r);
  }

  setItem(e, t) {
    if (t.dtype !== this.elementDtype) throw new Error("Invalid data types; op elements ".concat(t.dtype, ", but list elements ").concat(this.elementDtype));
    if (e < 0 || -1 !== this.maxNumElements && e >= this.maxNumElements) throw new Error("Trying to set element ".concat(e, " in a list with max ").concat(this.maxNumElements, " elements."));
    assertShapesMatchAllowUndefinedSize(this.elementShape, t.shape, "TensorList shape mismatch: "), keep(t), this.tensors[e] = t;
  }

  gather(e, t, n) {
    if (t !== this.elementDtype) throw new Error("Invalid data types; op elements ".concat(t, ", but list elements ").concat(this.elementDtype));
    assertShapesMatchAllowUndefinedSize(this.elementShape, n, "TensorList shape mismatch: "), e = e.slice(0, this.size());
    var r = inferElementShape(this.elementShape, this.tensors, n);
    return 0 === e.length ? tensor([], [0].concat(r)) : tidy(() => {
      var t = e.map(e => reshape$3(this.tensors[e], r));
      return stack(t, 0);
    });
  }

  concat(e, t) {
    if (e && e !== this.elementDtype) throw new Error("TensorList dtype is ".concat(this.elementDtype, " but concat requested dtype ").concat(e));
    assertShapesMatchAllowUndefinedSize(this.elementShape, t, "TensorList shape mismatch: ");
    var n = inferElementShape(this.elementShape, this.tensors, t);
    return 0 === this.size() ? tensor([], [0].concat(n)) : tidy(() => {
      var e = this.tensors.map(e => reshape$3(e, n));
      return concat$2(e, 0);
    });
  }

}

function fromTensor(e, t, n) {
  var r = e.dtype;
  if (e.shape.length < 1) throw new Error("Tensor must be at least a vector, but saw shape: ".concat(e.shape));
  if (e.dtype !== n) throw new Error("Invalid data types; op elements ".concat(e.dtype, ", but list elements ").concat(n));
  assertShapesMatchAllowUndefinedSize(e.shape.slice(1), t, "TensorList shape mismatch: ");
  var a = unstack(e);
  return new TensorList(a, t, r);
}

function reserve(e, t, n) {
  return new TensorList([], e, t, n);
}

function scatter(e, t, n, r) {
  if (t.length !== e.shape[0]) throw new Error("Expected len(indices) == tensor.shape[0], but saw: ".concat(t.length, " vs. ").concat(e.shape[0]));
  var a = Math.max(...t);
  if (null != r && -1 !== r && a >= r) throw new Error("Max index must be < array size (".concat(a, "  vs. ").concat(r, ")"));
  var s = new TensorList([], n, e.dtype, r),
      o = unstack(e, 0);
  return t.forEach((e, t) => {
    s.setItem(e, o[t]);
  }), s;
}

function split$1(e, t, n) {
  var r = 0;
  var a = t.map(e => (r += e, r));
  if (r !== e.shape[0]) throw new Error("Expected sum of lengths to be equal to\n          tensor.shape[0], but sum of lengths is\n        ".concat(r, ", and tensor's shape is: ").concat(e.shape));
  var s = mergeElementShape(e.shape.slice(1), n),
      o = 0 === r ? 0 : e.size / r,
      i = tidy(() => {
    var n = [];
    e = reshape$3(e, [1, r, o]);

    for (var _r245 = 0; _r245 < t.length; ++_r245) {
      n[_r245] = reshape$3(slice$2(e, [0, 0 === _r245 ? 0 : a[_r245 - 1], 0], [1, t[_r245], o]), s);
    }

    return e.dispose(), n;
  }),
      l = new TensorList([], n, e.dtype, t.length);

  for (var _e778 = 0; _e778 < i.length; _e778++) {
    l.setItem(_e778, i[_e778]);
  }

  return l;
}

var executeOp$h = /*#__PURE__*/function () {
  var _ref32 = _asyncToGenerator(function* (e, t, n) {
    switch (e.op) {
      case "If":
      case "StatelessIf":
        {
          var r = getParamValue("thenBranch", e, t, n),
              a = getParamValue("elseBranch", e, t, n),
              s = getParamValue("cond", e, t, n),
              o = getParamValue("args", e, t, n);
          return (yield s.data())[0] ? n.functionMap[r].executeFunctionAsync(o, n.tensorArrayMap, n.tensorListMap) : n.functionMap[a].executeFunctionAsync(o, n.tensorArrayMap, n.tensorListMap);
        }

      case "While":
      case "StatelessWhile":
        {
          var _ret2 = yield* function* () {
            var r = getParamValue("body", e, t, n),
                a = getParamValue("cond", e, t, n),
                s = getParamValue("args", e, t, n),
                o = yield n.functionMap[a].executeFunctionAsync(s, n.tensorArrayMap, n.tensorListMap),
                i = s.map(e => e.id);
            var l = yield o[0].data();
            o.forEach(e => {
              e.kept || -1 !== i.indexOf(e.id) || e.dispose();
            });
            var u = s;

            var _loop48 = function* _loop48() {
              var e = u;
              u = yield n.functionMap[r].executeFunctionAsync(u, n.tensorArrayMap, n.tensorListMap);
              var t = u.map(e => e.id);
              e.forEach(e => {
                e.kept || -1 !== i.indexOf(e.id) || -1 !== t.indexOf(e.id) || e.dispose();
              });
              var s = yield n.functionMap[a].executeFunctionAsync(u, n.tensorArrayMap, n.tensorListMap);
              l = yield s[0].data(), s.forEach(e => {
                e.kept || -1 !== i.indexOf(e.id) || -1 !== t.indexOf(e.id) || e.dispose();
              });
            };

            for (; l[0];) {
              yield* _loop48();
            }

            return {
              v: u
            };
          }();

          if (typeof _ret2 === "object") return _ret2.v;
        }

      case "LoopCond":
        return [cloneTensor(getParamValue("pred", e, t, n))];

      case "Switch":
        {
          var _r246 = getParamValue("pred", e, t, n);

          var _a160 = getParamValue("data", e, t, n);

          return _a160.kept || (_a160 = cloneTensor(_a160)), (yield _r246.data())[0] ? [void 0, _a160] : [_a160, void 0];
        }

      case "Merge":
        {
          var _r247 = e.inputNames.find(e => void 0 !== getTensor(e, t, n));

          return _r247 ? [cloneTensor(getTensor(_r247, t, n))] : void 0;
        }

      case "Enter":
        {
          var _r248 = getParamValue("frameName", e, t, n),
              _a161 = getParamValue("tensor", e, t, n);

          return n.enterFrame(_r248), [cloneTensor(_a161)];
        }

      case "Exit":
        {
          var _r249 = getParamValue("tensor", e, t, n);

          return n.exitFrame(), [cloneTensor(_r249)];
        }

      case "NextIteration":
        {
          var _r250 = getParamValue("tensor", e, t, n);

          return n.nextIteration(), [cloneTensor(_r250)];
        }

      case "TensorArrayV3":
        {
          var _r251 = getParamValue("size", e, t, n),
              _a162 = getParamValue("dtype", e, t, n),
              _s117 = getParamValue("elementShape", e, t, n),
              _o78 = getParamValue("dynamicSize", e, t, n),
              i = getParamValue("clearAfterRead", e, t, n),
              l = getParamValue("identicalElementShapes", e, t, n),
              u = getParamValue("name", e, t, n),
              c = new TensorArray(u, _a162, _r251, _s117, l, _o78, i);

          return n.addTensorArray(c), [c.idTensor, scalar(1)];
        }

      case "TensorArrayWriteV3":
        {
          var _r252 = getParamValue("tensorArrayId", e, t, n),
              _a163 = getParamValue("index", e, t, n),
              _s118 = getParamValue("tensor", e, t, n),
              _o79 = n.getTensorArray(_r252.id);

          return _o79.write(_a163, _s118), [_o79.idTensor];
        }

      case "TensorArrayReadV3":
        {
          var _r253 = getParamValue("tensorArrayId", e, t, n),
              _a164 = getParamValue("index", e, t, n);

          return [n.getTensorArray(_r253.id).read(_a164)];
        }

      case "TensorArrayGatherV3":
        {
          var _r254 = getParamValue("tensorArrayId", e, t, n),
              _a165 = getParamValue("indices", e, t, n),
              _s119 = getParamValue("dtype", e, t, n);

          return [n.getTensorArray(_r254.id).gather(_a165, _s119)];
        }

      case "TensorArrayScatterV3":
        {
          var _r255 = getParamValue("tensorArrayId", e, t, n),
              _a166 = getParamValue("indices", e, t, n),
              _s120 = getParamValue("tensor", e, t, n),
              _o80 = n.getTensorArray(_r255.id);

          return _o80.scatter(_a166, _s120), [_o80.idTensor];
        }

      case "TensorArrayConcatV3":
        {
          var _r256 = getParamValue("tensorArrayId", e, t, n),
              _a167 = n.getTensorArray(_r256.id),
              _s121 = getParamValue("dtype", e, t, n);

          return [_a167.concat(_s121)];
        }

      case "TensorArraySplitV3":
        {
          var _r257 = getParamValue("tensorArrayId", e, t, n),
              _a168 = getParamValue("tensor", e, t, n),
              _s122 = getParamValue("lengths", e, t, n),
              _o81 = n.getTensorArray(_r257.id);

          return _o81.split(_s122, _a168), [_o81.idTensor];
        }

      case "TensorArraySizeV3":
        {
          var _r258 = getParamValue("tensorArrayId", e, t, n);

          return [scalar(n.getTensorArray(_r258.id).size(), "int32")];
        }

      case "TensorArrayCloseV3":
        {
          var _r259 = getParamValue("tensorArrayId", e, t, n),
              _a169 = n.getTensorArray(_r259.id);

          return _a169.clearAndClose(), [_a169.idTensor];
        }

      case "TensorListSetItem":
        {
          var _r260 = getParamValue("tensorListId", e, t, n),
              _a170 = getParamValue("index", e, t, n),
              _s123 = getParamValue("tensor", e, t, n),
              _o82 = n.getTensorList(_r260.id);

          return _o82.setItem(_a170, _s123), [_o82.idTensor];
        }

      case "TensorListGetItem":
        {
          var _r261 = getParamValue("tensorListId", e, t, n),
              _a171 = getParamValue("index", e, t, n),
              _s124 = getParamValue("elementShape", e, t, n),
              _o83 = getParamValue("elementDType", e, t, n);

          return [n.getTensorList(_r261.id).getItem(_a171, _s124, _o83)];
        }

      case "TensorListScatterV2":
      case "TensorListScatter":
        {
          var _r262 = getParamValue("indices", e, t, n),
              _a172 = scatter(getParamValue("tensor", e, t, n), _r262, getParamValue("elementShape", e, t, n), getParamValue("numElements", e, t, n));

          return n.addTensorList(_a172), [_a172.idTensor];
        }

      case "TensorListReserve":
      case "EmptyTensorList":
        {
          var _r263 = getParamValue("elementShape", e, t, n),
              _a173 = getParamValue("elementDType", e, t, n);

          var _s125;

          _s125 = "TensorListReserve" === e.op ? "numElements" : "maxNumElements";

          var _o84 = reserve(_r263, _a173, getParamValue(_s125, e, t, n));

          return n.addTensorList(_o84), [_o84.idTensor];
        }

      case "TensorListGather":
        {
          var _r264 = getParamValue("tensorListId", e, t, n),
              _a174 = getParamValue("indices", e, t, n),
              _s126 = getParamValue("elementShape", e, t, n),
              _o85 = getParamValue("elementDType", e, t, n);

          return [n.getTensorList(_r264.id).gather(_a174, _o85, _s126)];
        }

      case "TensorListStack":
        {
          var _r265 = getParamValue("tensorListId", e, t, n),
              _a175 = getParamValue("elementShape", e, t, n),
              _s127 = getParamValue("elementDType", e, t, n),
              _o86 = getParamValue("numElements", e, t, n);

          return [n.getTensorList(_r265.id).stack(_a175, _s127, _o86)];
        }

      case "TensorListFromTensor":
        {
          var _r266 = fromTensor(getParamValue("tensor", e, t, n), getParamValue("elementShape", e, t, n), getParamValue("elementDType", e, t, n));

          return n.addTensorList(_r266), [_r266.idTensor];
        }

      case "TensorListConcat":
        {
          var _r267 = getParamValue("tensorListId", e, t, n),
              _a176 = n.getTensorList(_r267.id),
              _s128 = getParamValue("dtype", e, t, n),
              _o87 = getParamValue("elementShape", e, t, n);

          return [_a176.concat(_s128, _o87)];
        }

      case "TensorListPushBack":
        {
          var _r268 = getParamValue("tensorListId", e, t, n),
              _a177 = getParamValue("tensor", e, t, n),
              _s129 = n.getTensorList(_r268.id);

          return _s129.pushBack(_a177), [_s129.idTensor];
        }

      case "TensorListPopBack":
        {
          var _r269 = getParamValue("tensorListId", e, t, n),
              _a178 = getParamValue("elementShape", e, t, n),
              _s130 = getParamValue("elementDType", e, t, n);

          return [n.getTensorList(_r269.id).popBack(_a178, _s130)];
        }

      case "TensorListSplit":
        {
          var _r270 = getParamValue("tensor", e, t, n),
              _a179 = getParamValue("elementShape", e, t, n),
              _s131 = split$1(_r270, getParamValue("lengths", e, t, n), _a179);

          return n.addTensorList(_s131), [_s131.idTensor];
        }

      default:
        throw TypeError("Node type ".concat(e.op, " is not implemented"));
    }
  });

  return function executeOp$h(_x122, _x123, _x124) {
    return _ref32.apply(this, arguments);
  };
}();

function fusedConvAndDepthWiseParams(e, t, n) {
  var [r, a] = getParamValue("fusedOps", e, t, n),
      s = "biasadd" === r,
      o = !s,
      i = "prelu" === a,
      l = "fusedbatchnorm" === r,
      u = getParamValue("numArgs", e, t, n);

  if (s) {
    if (i && 2 !== u) throw new Error("FusedConv2d and DepthwiseConv2d with BiasAdd and Prelu must have two extra arguments: bias and alpha.");
    if (!i && s && 1 !== u) throw new Error("FusedConv2d and DepthwiseConv2d with BiasAdd must have one extra argument: bias.");
  }

  if (l) throw new Error("FusedConv2d and DepthwiseConv2d with FusedBatchNorm is not supported");
  var c = getParamValue("strides", e, t, n),
      p = getPadding(e, t, n),
      d = getParamValue("dataFormat", e, t, n).toUpperCase(),
      h = getParamValue("dilations", e, t, n);
  var [m, f] = getParamValue("args", e, t, n);
  return o && (f = m, m = void 0), {
    stride: c,
    pad: p,
    dataFormat: d,
    dilations: h,
    biasArg: m,
    preluArg: f,
    activationFunc: a,
    leakyreluAlpha: getParamValue("leakyreluAlpha", e, t, n)
  };
}

var executeOp$g = (e, t, n) => {
  switch (e.op) {
    case "Conv1D":
      {
        var r = getParamValue("stride", e, t, n),
            a = getParamValue("pad", e, t, n),
            s = getParamValue("dataFormat", e, t, n).toUpperCase(),
            o = getParamValue("dilation", e, t, n);
        return [conv1d$1(getParamValue("x", e, t, n), getParamValue("filter", e, t, n), r, a, s, o)];
      }

    case "Conv2D":
      {
        var _r271 = getParamValue("strides", e, t, n),
            _a180 = getPadding(e, t, n),
            _s132 = getParamValue("dataFormat", e, t, n).toUpperCase(),
            _o88 = getParamValue("dilations", e, t, n);

        return [conv2d$3(getParamValue("x", e, t, n), getParamValue("filter", e, t, n), [_r271[1], _r271[2]], _a180, _s132, [_o88[1], _o88[2]])];
      }

    case "_FusedConv2D":
      {
        var {
          stride: _r272,
          pad: _a181,
          dataFormat: _s133,
          dilations: _o89,
          biasArg: i,
          preluArg: l,
          activationFunc: u,
          leakyreluAlpha: c
        } = fusedConvAndDepthWiseParams(e, t, n);
        return [conv2d$2({
          x: getParamValue("x", e, t, n),
          filter: getParamValue("filter", e, t, n),
          strides: [_r272[1], _r272[2]],
          pad: _a181,
          dataFormat: _s133,
          dilations: [_o89[1], _o89[2]],
          bias: i,
          activation: u,
          preluActivationWeights: l,
          leakyreluAlpha: c
        })];
      }

    case "FusedDepthwiseConv2dNative":
      {
        var {
          stride: _r273,
          pad: _a182,
          dataFormat: _s134,
          dilations: _o90,
          biasArg: _i47,
          preluArg: _l38,
          activationFunc: _u33,
          leakyreluAlpha: _c23
        } = fusedConvAndDepthWiseParams(e, t, n);
        return [depthwiseConv2d$2({
          x: getParamValue("x", e, t, n),
          filter: getParamValue("filter", e, t, n),
          strides: [_r273[1], _r273[2]],
          pad: _a182,
          dataFormat: _s134,
          dilations: [_o90[1], _o90[2]],
          bias: _i47,
          activation: _u33,
          preluActivationWeights: _l38,
          leakyreluAlpha: _c23
        })];
      }

    case "Conv2DBackpropInput":
    case "Conv2dTranspose":
      {
        var _r274 = getParamValue("outputShape", e, t, n),
            _a183 = getParamValue("strides", e, t, n),
            _s135 = getPadding(e, t, n);

        return [conv2dTranspose$1(getParamValue("x", e, t, n), getParamValue("filter", e, t, n), _r274, [_a183[1], _a183[2]], _s135)];
      }

    case "DepthwiseConv2dNative":
    case "DepthwiseConv2d":
      {
        var _r275 = getParamValue("strides", e, t, n),
            _a184 = getPadding(e, t, n),
            _s136 = getParamValue("dilations", e, t, n),
            _o91 = getParamValue("dataFormat", e, t, n).toUpperCase();

        return [depthwiseConv2d$3(getParamValue("input", e, t, n), getParamValue("filter", e, t, n), [_r275[1], _r275[2]], _a184, _o91, [_s136[1], _s136[2]])];
      }

    case "Conv3D":
      {
        var _r276 = getParamValue("strides", e, t, n),
            _a185 = getParamValue("pad", e, t, n),
            _s137 = getParamValue("dataFormat", e, t, n).toUpperCase(),
            _o92 = getParamValue("dilations", e, t, n);

        return [conv3d$1(getParamValue("x", e, t, n), getParamValue("filter", e, t, n), [_r276[1], _r276[2], _r276[3]], _a185, _s137, [_o92[1], _o92[2], _o92[3]])];
      }

    case "AvgPool":
      {
        var _r277 = getParamValue("strides", e, t, n),
            _a186 = getParamValue("pad", e, t, n),
            _s138 = getParamValue("kernelSize", e, t, n);

        return [avgPool$2(getParamValue("x", e, t, n), [_s138[1], _s138[2]], [_r277[1], _r277[2]], _a186)];
      }

    case "MaxPool":
      {
        var _r278 = getParamValue("strides", e, t, n),
            _a187 = getParamValue("pad", e, t, n),
            _s139 = getParamValue("kernelSize", e, t, n);

        return [maxPool$2(getParamValue("x", e, t, n), [_s139[1], _s139[2]], [_r278[1], _r278[2]], _a187)];
      }

    case "MaxPoolWithArgmax":
      {
        var _r279 = getParamValue("strides", e, t, n),
            _a188 = getParamValue("pad", e, t, n),
            _s140 = getParamValue("kernelSize", e, t, n),
            _o93 = getParamValue("includeBatchInIndex", e, t, n),
            {
          result: _i48,
          indexes: _l39
        } = maxPoolWithArgmax(getParamValue("x", e, t, n), [_s140[1], _s140[2]], [_r279[1], _r279[2]], _a188, _o93);

        return [_i48, _l39];
      }

    case "AvgPool3D":
      {
        var _r280 = getParamValue("strides", e, t, n),
            _a189 = getParamValue("pad", e, t, n),
            _s141 = getParamValue("kernelSize", e, t, n);

        return [avgPool3d$1(getParamValue("x", e, t, n), [_s141[1], _s141[2], _s141[3]], [_r280[1], _r280[2], _r280[3]], _a189)];
      }

    case "MaxPool3D":
      {
        var _r281 = getParamValue("strides", e, t, n),
            _a190 = getParamValue("pad", e, t, n),
            _s142 = getParamValue("kernelSize", e, t, n);

        return [maxPool3d$1(getParamValue("x", e, t, n), [_s142[1], _s142[2], _s142[3]], [_r281[1], _r281[2], _r281[3]], _a190)];
      }

    case "Dilation2D":
      {
        var _r282 = getParamValue("strides", e, t, n),
            _a191 = getParamValue("pad", e, t, n),
            _s143 = getParamValue("dilations", e, t, n),
            _o94 = _r282[1],
            _i49 = _r282[2],
            _l40 = _s143[1],
            _u34 = _s143[2];

        return [dilation2d(getParamValue("x", e, t, n), getParamValue("filter", e, t, n), [_o94, _i49], _a191, [_l40, _u34], "NHWC")];
      }

    default:
      throw TypeError("Node type ".concat(e.op, " is not implemented"));
  }
},
    executeOp$f = (e, t, n) => {
  switch (e.op) {
    case "Fill":
      {
        var r = getParamValue("shape", e, t, n),
            a = getParamValue("dtype", e, t, n);
        return [fill$2(r, getParamValue("value", e, t, n), a)];
      }

    case "LinSpace":
      return [linspace(getParamValue("start", e, t, n), getParamValue("stop", e, t, n), getParamValue("num", e, t, n))];

    case "Multinomial":
      {
        var _r283 = getParamValue("logits", e, t, n),
            _a192 = getParamValue("numSamples", e, t, n),
            s = getParamValue("seed", e, t, n);

        return [multinomial$2(_r283, _a192, s)];
      }

    case "OneHot":
      {
        var _r284 = getParamValue("indices", e, t, n),
            _a193 = getParamValue("depth", e, t, n),
            _s144 = getParamValue("onValue", e, t, n),
            o = getParamValue("offValue", e, t, n);

        return [oneHot$2(_r284, _a193, _s144, o)];
      }

    case "Ones":
      return [ones$1(getParamValue("shape", e, t, n), getParamValue("dtype", e, t, n))];

    case "OnesLike":
      return [onesLike$2(getParamValue("x", e, t, n))];

    case "RandomUniform":
      return [randomUniform$1(getParamValue("shape", e, t, n), getParamValue("minval", e, t, n), getParamValue("maxval", e, t, n), getParamValue("dtype", e, t, n))];

    case "Range":
      return [range$4(getParamValue("start", e, t, n), getParamValue("stop", e, t, n), getParamValue("step", e, t, n), getParamValue("dtype", e, t, n))];

    case "TruncatedNormal":
      {
        var _r285 = getParamValue("shape", e, t, n),
            _a194 = getParamValue("mean", e, t, n),
            _s145 = getParamValue("stdDev", e, t, n),
            _o95 = getParamValue("seed", e, t, n);

        return [truncatedNormal$1(_r285, _a194, _s145, getParamValue("dtype", e, t, n), _o95)];
      }

    case "Zeros":
      return [zeros$2(getParamValue("shape", e, t, n), getParamValue("dtype", e, t, n))];

    case "ZerosLike":
      return [zerosLike$2(getParamValue("x", e, t, n))];

    default:
      throw TypeError("Node type ".concat(e.op, " is not implemented"));
  }
};

function nmsParams(e, t, n) {
  return {
    boxes: getParamValue("boxes", e, t, n),
    scores: getParamValue("scores", e, t, n),
    maxOutputSize: getParamValue("maxOutputSize", e, t, n),
    iouThreshold: getParamValue("iouThreshold", e, t, n),
    scoreThreshold: getParamValue("scoreThreshold", e, t, n),
    softNmsSigma: getParamValue("softNmsSigma", e, t, n)
  };
}

var executeOp$e = /*#__PURE__*/function () {
  var _ref33 = _asyncToGenerator(function* (e, t, n) {
    switch (e.op) {
      case "NonMaxSuppressionV5":
        {
          var {
            boxes: r,
            scores: a,
            maxOutputSize: s,
            iouThreshold: o,
            scoreThreshold: i,
            softNmsSigma: l
          } = nmsParams(e, t, n),
              u = yield image$1.nonMaxSuppressionWithScoreAsync(r, a, s, o, i, l);
          return [u.selectedIndices, u.selectedScores];
        }

      case "NonMaxSuppressionV4":
        {
          var {
            boxes: _r286,
            scores: _a195,
            maxOutputSize: _s146,
            iouThreshold: _o96,
            scoreThreshold: _i50
          } = nmsParams(e, t, n),
              _l41 = getParamValue("padToMaxOutputSize", e, t, n),
              _u35 = yield image$1.nonMaxSuppressionPaddedAsync(_r286, _a195, _s146, _o96, _i50, _l41);

          return [_u35.selectedIndices, _u35.validOutputs];
        }

      case "NonMaxSuppressionV3":
      case "NonMaxSuppressionV2":
        {
          var {
            boxes: _r287,
            scores: _a196,
            maxOutputSize: _s147,
            iouThreshold: _o97,
            scoreThreshold: _i51
          } = nmsParams(e, t, n);
          return [yield image$1.nonMaxSuppressionAsync(_r287, _a196, _s147, _o97, _i51)];
        }

      case "Where":
        {
          var _r288 = cast$3(getParamValue("condition", e, t, n), "bool"),
              _a197 = [yield whereAsync(_r288)];

          return _r288.dispose(), _a197;
        }

      case "ListDiff":
        return setdiff1dAsync(getParamValue("x", e, t, n), getParamValue("y", e, t, n));

      default:
        throw TypeError("Node type ".concat(e.op, " is not implemented"));
    }
  });

  return function executeOp$e(_x125, _x126, _x127) {
    return _ref33.apply(this, arguments);
  };
}(),
    executeOp$d = (e, t, n) => {
  switch (e.op) {
    case "TopKV2":
      {
        var r = getParamValue("x", e, t, n),
            a = getParamValue("k", e, t, n),
            s = getParamValue("sorted", e, t, n),
            o = topk(r, a, s);
        return [o.values, o.indices];
      }

    case "Unique":
      {
        var _r289 = getParamValue("x", e, t, n),
            _a198 = unique$3(_r289);

        return [_a198.values, _a198.indices];
      }

    case "UniqueV2":
      {
        var _r290 = getParamValue("x", e, t, n),
            _a199 = getParamValue("axis", e, t, n),
            _s148 = unique$3(_r290, _a199);

        return [_s148.values, _s148.indices];
      }

    default:
      throw TypeError("Node type ".concat(e.op, " is not implemented"));
  }
},
    executeOp$c = (e, t, n) => {
  switch (e.op) {
    case "Const":
      return t[e.name];

    case "PlaceholderWithDefault":
      var r = getParamValue("default", e, t, n);
      return [getTensor(e.name, t, n) || r];

    case "Placeholder":
      return [getTensor(e.name, t, n)];

    case "Identity":
    case "StopGradient":
    case "FakeQuantWithMinMaxVars":
    case "Snapshot":
      return [cloneTensor(getParamValue("x", e, t, n))];

    case "IdentityN":
      return getParamValue("x", e, t, n).map(e => cloneTensor(e));

    case "Shape":
      return [tensor1d(getParamValue("x", e, t, n).shape, "int32")];

    case "ShapeN":
      return getParamValue("x", e, t, n).map(e => tensor1d(e.shape));

    case "Size":
      return [scalar(getParamValue("x", e, t, n).size, "int32")];

    case "Rank":
      return [scalar(getParamValue("x", e, t, n).rank, "int32")];

    case "NoOp":
      return [scalar(1)];

    case "Print":
      var a = getParamValue("x", e, t, n),
          s = getParamValue("data", e, t, n),
          o = getParamValue("message", e, t, n),
          i = getParamValue("summarize", e, t, n);
      console.warn("The graph has a tf.print() operation,usually used for debugging, which slows down performance."), console.log(o);

      for (var _e779 = 0; _e779 < s.length; _e779++) {
        console.log(Array.prototype.slice.call(s[_e779].dataSync()).slice(0, i));
      }

      return [a];

    default:
      throw TypeError("Node type ".concat(e.op, " is not implemented"));
  }
};

class HashTable {
  constructor(e, t) {
    this.keyDType = e, this.valueDType = t, this.handle = scalar(0), this.tensorMap = new Map(), keep(this.handle);
  }

  get id() {
    return this.handle.id;
  }

  clearAndClose() {
    this.tensorMap.forEach(e => e.dispose()), this.tensorMap.clear(), this.handle.dispose();
  }

  size() {
    return this.tensorMap.size;
  }

  tensorSize() {
    return scalar(this.size(), "int32");
  }

  import(e, t) {
    var _this150 = this;

    return _asyncToGenerator(function* () {
      _this150.checkKeyAndValueTensor(e, t);

      var n = yield e.data();
      return _this150.tensorMap.forEach(e => e.dispose()), _this150.tensorMap.clear(), tidy(() => {
        var e = unstack(t),
            r = n.length,
            a = e.length;
        assert$4(r === a, () => "The number of elements doesn't match, keys has ".concat(r, " elements, the values has ").concat(a, " elements."));

        for (var _t537 = 0; _t537 < r; _t537++) {
          var _r291 = n[_t537],
              _a200 = e[_t537];
          keep(_a200), _this150.tensorMap.set(_r291, _a200);
        }

        return _this150.handle;
      });
    })();
  }

  find(e, t) {
    var _this151 = this;

    return _asyncToGenerator(function* () {
      _this151.checkKeyAndValueTensor(e, t);

      var n = yield e.data();
      return tidy(() => {
        var e = [];

        for (var r = 0; r < n.length; r++) {
          var a = _this151.findWithDefault(n[r], t);

          e.push(a);
        }

        return stack(e);
      });
    })();
  }

  findWithDefault(e, t) {
    var n = this.tensorMap.get(e);
    return null != n ? n : t;
  }

  checkKeyAndValueTensor(e, t) {
    if (e.dtype !== this.keyDType) throw new Error("Expect key dtype ".concat(this.keyDType, ", but got ").concat(e.dtype));
    if (t.dtype !== this.valueDType) throw new Error("Expect value dtype ".concat(this.valueDType, ", but got ").concat(t.dtype));
  }

}

var executeOp$b = /*#__PURE__*/function () {
  var _ref34 = _asyncToGenerator(function* (e, t, n, r) {
    switch (e.op) {
      case "HashTable":
      case "HashTableV2":
        {
          var a = getParamValue("keyDType", e, t, n),
              s = getParamValue("valueDType", e, t, n),
              o = new HashTable(a, s);
          return r.addHashTable(e.name, o), [o.handle];
        }

      case "LookupTableImport":
      case "LookupTableImportV2":
        {
          var _a201 = getParamValue("tableHandle", e, t, n, r),
              _s149 = getParamValue("keys", e, t, n),
              _o98 = getParamValue("values", e, t, n),
              i = r.getHashTableById(_a201.id);

          return [yield i.import(_s149, _o98)];
        }

      case "LookupTableFind":
      case "LookupTableFindV2":
        {
          var _a202 = getParamValue("tableHandle", e, t, n, r),
              _s150 = getParamValue("keys", e, t, n),
              _o99 = getParamValue("defaultValue", e, t, n),
              _i52 = r.getHashTableById(_a202.id);

          return [yield _i52.find(_s150, _o99)];
        }

      case "LookupTableSize":
      case "LookupTableSizeV2":
        {
          var _a203 = getParamValue("tableHandle", e, t, n, r);

          return [r.getHashTableById(_a203.id).tensorSize()];
        }

      default:
        throw TypeError("Node type ".concat(e.op, " is not implemented"));
    }
  });

  return function executeOp$b(_x128, _x129, _x130, _x131) {
    return _ref34.apply(this, arguments);
  };
}(),
    executeOp$a = (e, t, n) => {
  switch (e.op) {
    case "ResizeBilinear":
      {
        var r = getParamValue("images", e, t, n),
            a = getParamValue("size", e, t, n),
            s = getParamValue("alignCorners", e, t, n),
            o = getParamValue("halfPixelCenters", e, t, n);
        return [image$1.resizeBilinear(r, [a[0], a[1]], s, o)];
      }

    case "ResizeNearestNeighbor":
      {
        var _r292 = getParamValue("images", e, t, n),
            _a204 = getParamValue("size", e, t, n),
            _s151 = getParamValue("alignCorners", e, t, n),
            _o100 = getParamValue("halfPixelCenters", e, t, n);

        return [image$1.resizeNearestNeighbor(_r292, [_a204[0], _a204[1]], _s151, _o100)];
      }

    case "CropAndResize":
      {
        var _r293 = getParamValue("image", e, t, n),
            _a205 = getParamValue("boxes", e, t, n),
            _s152 = getParamValue("boxInd", e, t, n),
            _o101 = getParamValue("cropSize", e, t, n),
            i = getParamValue("method", e, t, n),
            l = getParamValue("extrapolationValue", e, t, n);

        return [image$1.cropAndResize(_r293, _a205, _s152, _o101, i, l)];
      }

    default:
      throw TypeError("Node type ".concat(e.op, " is not implemented"));
  }
},
    executeOp$9 = (e, t, n) => {
  switch (e.op) {
    case "Equal":
      return [equal$2(getParamValue("a", e, t, n), getParamValue("b", e, t, n))];

    case "NotEqual":
      return [notEqual$2(getParamValue("a", e, t, n), getParamValue("b", e, t, n))];

    case "Greater":
      return [greater$3(getParamValue("a", e, t, n), getParamValue("b", e, t, n))];

    case "GreaterEqual":
      return [greaterEqual$2(getParamValue("a", e, t, n), getParamValue("b", e, t, n))];

    case "Less":
      return [less$3(getParamValue("a", e, t, n), getParamValue("b", e, t, n))];

    case "LessEqual":
      return [lessEqual$2(getParamValue("a", e, t, n), getParamValue("b", e, t, n))];

    case "LogicalAnd":
      return [logicalAnd$2(getParamValue("a", e, t, n), getParamValue("b", e, t, n))];

    case "LogicalNot":
      return [logicalNot$2(getParamValue("a", e, t, n))];

    case "LogicalOr":
      return [logicalOr$2(getParamValue("a", e, t, n), getParamValue("b", e, t, n))];

    case "Select":
    case "SelectV2":
      return [where(getParamValue("condition", e, t, n), getParamValue("a", e, t, n), getParamValue("b", e, t, n))];

    default:
      throw TypeError("Node type ".concat(e.op, " is not implemented"));
  }
},
    executeOp$8 = (e, t, n) => {
  switch (e.op) {
    case "BatchMatMul":
    case "BatchMatMulV2":
    case "MatMul":
      return [matMul$1(getParamValue("a", e, t, n), getParamValue("b", e, t, n), getParamValue("transposeA", e, t, n), getParamValue("transposeB", e, t, n))];

    case "Einsum":
      return [einsum$2(getParamValue("equation", e, t, n), ...getParamValue("tensors", e, t, n))];

    case "Transpose":
      return [transpose$2(getParamValue("x", e, t, n), getParamValue("perm", e, t, n))];

    case "_FusedMatMul":
      var [r, a] = getParamValue("fusedOps", e, t, n),
          s = "biasadd" === r,
          o = "prelu" === a,
          i = getParamValue("numArgs", e, t, n),
          l = getParamValue("leakyreluAlpha", e, t, n);

      if (s) {
        if (o && 2 !== i) throw new Error("Fused MatMul with BiasAdd and Prelu must have two extra arguments: bias and alpha.");
        if (!o && 1 !== i) throw new Error("Fused MatMul with BiasAdd must have one extra argument: bias.");
      }

      var [u, c] = getParamValue("args", e, t, n);
      return [matMul({
        a: getParamValue("a", e, t, n),
        b: getParamValue("b", e, t, n),
        transposeA: getParamValue("transposeA", e, t, n),
        transposeB: getParamValue("transposeB", e, t, n),
        bias: u,
        activation: a,
        preluActivationWeights: c,
        leakyreluAlpha: l
      })];

    default:
      throw TypeError("Node type ".concat(e.op, " is not implemented"));
  }
},
    executeOp$7 = (e, t, n) => {
  switch (e.op) {
    case "FusedBatchNorm":
    case "FusedBatchNormV2":
    case "FusedBatchNormV3":
      return [batchNorm$2(getParamValue("x", e, t, n), getParamValue("mean", e, t, n), getParamValue("variance", e, t, n), getParamValue("offset", e, t, n), getParamValue("scale", e, t, n), getParamValue("epsilon", e, t, n))];

    case "LRN":
      return [localResponseNormalization(getParamValue("x", e, t, n), getParamValue("radius", e, t, n), getParamValue("bias", e, t, n), getParamValue("alpha", e, t, n), getParamValue("beta", e, t, n))];

    case "Softmax":
      return [softmax$3(getParamValue("x", e, t, n))];

    case "LogSoftmax":
      return [logSoftmax(getParamValue("x", e, t, n))];

    case "SparseToDense":
      return [sparseToDense$2(getParamValue("sparseIndices", e, t, n), getParamValue("outputShape", e, t, n), getParamValue("sparseValues", e, t, n), getParamValue("defaultValue", e, t, n))];

    default:
      throw TypeError("Node type ".concat(e.op, " is not implemented"));
  }
},
    executeOp$6 = (e, t, n) => {
  switch (e.op) {
    case "Max":
      {
        var _r294 = getParamValue("axis", e, t, n),
            _a206 = getParamValue("keepDims", e, t, n);

        return [max$3(getParamValue("x", e, t, n), _r294, _a206)];
      }

    case "Mean":
      {
        var _r295 = getParamValue("axis", e, t, n),
            _a207 = getParamValue("keepDims", e, t, n);

        return [mean$1(getParamValue("x", e, t, n), _r295, _a207)];
      }

    case "Min":
      {
        var _r296 = getParamValue("axis", e, t, n),
            _a208 = getParamValue("keepDims", e, t, n);

        return [min$3(getParamValue("x", e, t, n), _r296, _a208)];
      }

    case "Sum":
      {
        var _r297 = getParamValue("axis", e, t, n),
            _a209 = getParamValue("keepDims", e, t, n);

        return [sum$2(getParamValue("x", e, t, n), _r297, _a209)];
      }

    case "All":
      {
        var _r298 = getParamValue("axis", e, t, n),
            _a210 = getParamValue("keepDims", e, t, n);

        return [all$2(getParamValue("x", e, t, n), _r298, _a210)];
      }

    case "Any":
      {
        var _r299 = getParamValue("axis", e, t, n),
            _a211 = getParamValue("keepDims", e, t, n);

        return [any$2(getParamValue("x", e, t, n), _r299, _a211)];
      }

    case "ArgMax":
      {
        var _r300 = getParamValue("axis", e, t, n);

        return [argMax$2(getParamValue("x", e, t, n), _r300)];
      }

    case "ArgMin":
      {
        var _r301 = getParamValue("axis", e, t, n);

        return [argMin$2(getParamValue("x", e, t, n), _r301)];
      }

    case "Prod":
      {
        var _r302 = getParamValue("axis", e, t, n),
            _a212 = getParamValue("keepDims", e, t, n);

        return [prod$2(getParamValue("x", e, t, n), _r302, _a212)];
      }

    case "Cumsum":
      {
        var _r303 = getParamValue("axis", e, t, n),
            _a213 = getParamValue("exclusive", e, t, n),
            _s153 = getParamValue("reverse", e, t, n);

        return [cumsum$2(getParamValue("x", e, t, n), _r303, _a213, _s153)];
      }

    case "Bincount":
      var r = getParamValue("x", e, t, n),
          a = getParamValue("weights", e, t, n),
          s = getParamValue("size", e, t, n);
      return [bincount$2(r, a, s)];

    case "DenseBincount":
      {
        var _r304 = getParamValue("x", e, t, n),
            _a214 = getParamValue("weights", e, t, n),
            _s154 = getParamValue("size", e, t, n),
            o = getParamValue("binaryOutput", e, t, n);

        return [denseBincount$2(_r304, _a214, _s154, o)];
      }

    default:
      throw TypeError("Node type ".concat(e.op, " is not implemented"));
  }
},
    executeOp$5 = (e, t, n) => {
  switch (e.op) {
    case "ConcatV2":
    case "Concat":
      {
        var r = getParamValue("n", e, t, n),
            a = getParamValue("axis", e, t, n);
        var s = getParamValue("tensors", e, t, n);
        return s = s.slice(0, r), [concat$2(s, a)];
      }

    case "Gather":
      {
        var _r305 = getParamValue("x", e, t, n),
            _a215 = getParamValue("indices", e, t, n);

        return [gather$1(_r305, cast$3(_a215, "int32"), 0)];
      }

    case "GatherV2":
      {
        var _r306 = getParamValue("axis", e, t, n),
            _a216 = getParamValue("batchDims", e, t, n),
            _s155 = getParamValue("x", e, t, n),
            o = getParamValue("indices", e, t, n);

        return [gather$1(_s155, cast$3(o, "int32"), _r306, _a216)];
      }

    case "Reverse":
      {
        var _r307 = getParamValue("dims", e, t, n),
            _a217 = [];

        for (var _e780 = 0; _e780 < _r307.length; _e780++) {
          _r307[_e780] && _a217.push(_e780);
        }

        var _s156 = getParamValue("x", e, t, n);

        return [reverse$2(_s156, _a217)];
      }

    case "ReverseV2":
      {
        var _r308 = getParamValue("axis", e, t, n),
            _a218 = getParamValue("x", e, t, n);

        return [reverse$2(_a218, _r308)];
      }

    case "Slice":
      {
        var _r309 = getParamValue("begin", e, t, n),
            _a219 = getParamValue("size", e, t, n);

        return [slice$2(getParamValue("x", e, t, n), _r309, _a219)];
      }

    case "StridedSlice":
      {
        var _r310 = getParamValue("begin", e, t, n),
            _a220 = getParamValue("end", e, t, n),
            _s157 = getParamValue("strides", e, t, n),
            _o102 = getParamValue("beginMask", e, t, n),
            i = getParamValue("endMask", e, t, n),
            l = getParamValue("ellipsisMask", e, t, n),
            u = getParamValue("newAxisMask", e, t, n),
            c = getParamValue("shrinkAxisMask", e, t, n),
            _p24 = getParamValue("x", e, t, n);

        return [stridedSlice$2(_p24, _r310, _a220, _s157, _o102, i, l, u, c)];
      }

    case "Pack":
      return tidy(() => {
        var r = getParamValue("axis", e, t, n),
            a = getParamValue("tensors", e, t, n),
            s = a[0].shape,
            o = squeeze(a[0]).shape,
            i = a.map(e => {
          var t = arraysEqual(e.shape, s);
          if (!t && !arraysEqual(squeeze(e).shape, o)) throw new Error("the input tensors shape does not match");
          return t ? e : reshape$3(e, s);
        });
        return [stack(i, r)];
      });

    case "Unpack":
      {
        var _r311 = getParamValue("axis", e, t, n),
            _a221 = getParamValue("tensor", e, t, n);

        return unstack(_a221, _r311);
      }

    case "Tile":
      {
        var _r312 = getParamValue("reps", e, t, n);

        return [tile$3(getParamValue("x", e, t, n), _r312)];
      }

    case "Split":
    case "SplitV":
      {
        var _r313 = getParamValue("axis", e, t, n),
            _a222 = getParamValue("numOrSizeSplits", e, t, n),
            _s158 = getParamValue("x", e, t, n);

        return split$2(_s158, _a222, _r313);
      }

    case "ScatterNd":
      {
        var _r314 = getParamValue("indices", e, t, n),
            _a223 = getParamValue("values", e, t, n),
            _s159 = getParamValue("shape", e, t, n);

        return [scatterND(_r314, _a223, _s159)];
      }

    case "GatherNd":
      {
        var _r315 = getParamValue("x", e, t, n),
            _a224 = getParamValue("indices", e, t, n);

        return [gatherND(_r315, _a224)];
      }

    case "SparseToDense":
      {
        var _r316 = getParamValue("sparseIndices", e, t, n),
            _a225 = getParamValue("outputShape", e, t, n),
            _s160 = getParamValue("sparseValues", e, t, n),
            _o103 = getParamValue("defaultValue", e, t, n);

        return [sparseToDense$2(_r316, _s160, _a225, _s160.dtype === _o103.dtype ? _o103 : cast$3(_o103, _s160.dtype))];
      }

    default:
      throw TypeError("Node type ".concat(e.op, " is not implemented"));
  }
},
    executeOp$4 = (e, t, n) => {
  switch (e.op) {
    case "SparseFillEmptyRows":
      {
        var {
          outputIndices: r,
          outputValues: a,
          emptyRowIndicator: s,
          reverseIndexMap: o
        } = sparse$1.sparseFillEmptyRows(getParamValue("indices", e, t, n), getParamValue("values", e, t, n), getParamValue("denseShape", e, t, n), getParamValue("defaultValue", e, t, n));
        return [r, a, s, o];
      }

    case "SparseReshape":
      {
        var {
          outputIndices: _r317,
          outputShape: _a226
        } = sparse$1.sparseReshape(getParamValue("inputIndices", e, t, n), getParamValue("inputShape", e, t, n), getParamValue("newShape", e, t, n));
        return [_r317, _a226];
      }

    case "SparseSegmentMean":
      return [sparse$1.sparseSegmentMean(getParamValue("data", e, t, n), getParamValue("indices", e, t, n), getParamValue("segmentIds", e, t, n))];

    case "SparseSegmentSum":
      return [sparse$1.sparseSegmentSum(getParamValue("data", e, t, n), getParamValue("indices", e, t, n), getParamValue("segmentIds", e, t, n))];

    default:
      throw TypeError("Node type ".concat(e.op, " is not implemented"));
  }
},
    executeOp$3 = (e, t, n) => {
  switch (e.op) {
    case "FFT":
      return [fft$2(getParamValue("x", e, t, n))];

    case "IFFT":
      return [ifft$2(getParamValue("x", e, t, n))];

    case "RFFT":
      return [rfft(getParamValue("x", e, t, n))];

    case "IRFFT":
      return [irfft(getParamValue("x", e, t, n))];

    default:
      throw TypeError("Node type ".concat(e.op, " is not implemented"));
  }
},
    executeOp$2 = (e, t, n) => {
  switch (e.op) {
    case "StringNGrams":
      {
        var {
          nGrams: r,
          nGramsSplits: a
        } = string$1.stringNGrams(getParamValue("data", e, t, n), getParamValue("dataSplits", e, t, n), getParamValue("separator", e, t, n), getParamValue("nGramWidths", e, t, n), getParamValue("leftPad", e, t, n), getParamValue("rightPad", e, t, n), getParamValue("padWidth", e, t, n), getParamValue("preserveShortSequences", e, t, n));
        return [r, a];
      }

    case "StringSplit":
      {
        var {
          indices: _r318,
          values: _a227,
          shape: s
        } = string$1.stringSplit(getParamValue("input", e, t, n), getParamValue("delimiter", e, t, n), getParamValue("skipEmpty", e, t, n));
        return [_r318, _a227, s];
      }

    case "StringToHashBucketFast":
      return [string$1.stringToHashBucketFast(getParamValue("input", e, t, n), getParamValue("numBuckets", e, t, n))];

    default:
      throw TypeError("Node type ".concat(e.op, " is not implemented"));
  }
},
    executeOp$1 = (e, t, n) => {
  switch (e.op) {
    case "Cast":
      return [cast$3(getParamValue("x", e, t, n), getParamValue("dtype", e, t, n))];

    case "ExpandDims":
      {
        var r = getParamValue("axis", e, t, n);
        return [expandDims$3(getParamValue("x", e, t, n), r)];
      }

    case "Squeeze":
      {
        var _r319 = getParamValue("axis", e, t, n);

        return [squeeze(getParamValue("x", e, t, n), _r319)];
      }

    case "Reshape":
      return [reshape$3(getParamValue("x", e, t, n), getParamValue("shape", e, t, n))];

    case "MirrorPad":
      return [mirrorPad$1(getParamValue("x", e, t, n), getParamValue("padding", e, t, n), getParamValue("mode", e, t, n))];

    case "PadV2":
    case "Pad":
      return [pad(getParamValue("x", e, t, n), getParamValue("padding", e, t, n), getParamValue("constantValue", e, t, n))];

    case "SpaceToBatchND":
      {
        var _r320 = getParamValue("blockShape", e, t, n),
            a = getParamValue("paddings", e, t, n);

        return [spaceToBatchND$2(getParamValue("x", e, t, n), _r320, a)];
      }

    case "BatchToSpaceND":
      {
        var _r321 = getParamValue("blockShape", e, t, n),
            _a228 = getParamValue("crops", e, t, n);

        return [batchToSpaceND$2(getParamValue("x", e, t, n), _r321, _a228)];
      }

    case "DepthToSpace":
      {
        var _r322 = getParamValue("blockSize", e, t, n),
            _a229 = getParamValue("dataFormat", e, t, n).toUpperCase();

        return [depthToSpace$2(getParamValue("x", e, t, n), _r322, _a229)];
      }

    case "BroadcastTo":
      return [broadcastTo(getParamValue("x", e, t, n), getParamValue("shape", e, t, n))];

    default:
      throw TypeError("Node type ".concat(e.op, " is not implemented"));
  }
};

function executeOp(e, t, n, r) {
  var a = ((e, t, n) => {
    switch (e.category) {
      case "arithmetic":
        return tidy(() => executeOp$j(e, t, n));

      case "basic_math":
        return tidy(() => executeOp$i(e, t, n));

      case "control":
        return executeOp$h(e, t, n);

      case "convolution":
        return tidy(() => executeOp$g(e, t, n));

      case "creation":
        return tidy(() => executeOp$f(e, t, n));

      case "dynamic":
        return executeOp$e(e, t, n);

      case "evaluation":
        return tidy(() => executeOp$d(e, t, n));

      case "image":
        return tidy(() => executeOp$a(e, t, n));

      case "graph":
        return tidy(() => executeOp$c(e, t, n));

      case "logical":
        return tidy(() => executeOp$9(e, t, n));

      case "matrices":
        return tidy(() => executeOp$8(e, t, n));

      case "normalization":
        return tidy(() => executeOp$7(e, t, n));

      case "reduction":
        return tidy(() => executeOp$6(e, t, n));

      case "slice_join":
        return tidy(() => executeOp$5(e, t, n));

      case "sparse":
        return tidy(() => executeOp$4(e, t, n));

      case "spectral":
        return tidy(() => executeOp$3(e, t, n));

      case "string":
        return tidy(() => executeOp$2(e, t, n));

      case "transformation":
        return tidy(() => executeOp$1(e, t, n));

      case "hash_table":
        return executeOp$b(e, t, n, r);

      case "custom":
        var _a230 = getRegisteredOp(e.op);

        if (_a230 && _a230.customExecutor) return _a230.customExecutor(new NodeValueImpl(e, t, n));
        throw TypeError("Custom op ".concat(e.op, " is not registered."));

      default:
        throw TypeError("Unknown op '".concat(e.op, "'. File an issue at https://github.com/tensorflow/tfjs/issues so we can add it, or register a custom execution with tf.registerOp()"));
    }
  })(e, t, n);

  return isPromise(a) ? a.then(e => [].concat(e)) : [].concat(a);
}

class ExecutionContext {
  constructor() {
    var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : {};
    this.weightMap = e, this.tensorArrayMap = t, this.tensorListMap = n, this.functionMap = r, this.rootContext = {
      id: 0,
      frameName: "",
      iterationId: 0
    }, this.contexts = [this.rootContext], this.lastId = 0, this.generateCurrentContextIds();
  }

  newFrame(e, t) {
    return {
      id: e,
      frameName: t,
      iterationId: 0
    };
  }

  set currentContext(e) {
    this.contexts !== e && (this.contexts = e, this.generateCurrentContextIds());
  }

  get currentContext() {
    return this.contexts;
  }

  get currentContextId() {
    return this._currentContextIds[0];
  }

  get currentContextIds() {
    return this._currentContextIds;
  }

  generateCurrentContextIds() {
    var e = [];

    for (var t = 0; t < this.contexts.length - 1; t++) {
      var n = this.contexts.slice(0, this.contexts.length - t);
      e.push(this.contextIdforContexts(n));
    }

    e.push(""), this._currentContextIds = e;
  }

  contextIdforContexts(e) {
    return e ? e.map(e => 0 === e.id && 0 === e.iterationId ? "" : "".concat(e.frameName, "-").concat(e.iterationId)).join("/") : "";
  }

  enterFrame(e) {
    this.contexts && (this.lastId++, this.contexts = this.contexts.slice(), this.contexts.push(this.newFrame(this.lastId, e)), this._currentContextIds.unshift(this.contextIdforContexts(this.contexts)));
  }

  exitFrame() {
    if (!(this.contexts && this.contexts.length > 1)) throw new Error("Cannot exit frame, the context is empty");
    this.contexts = this.contexts.slice(), this.contexts.splice(-1), this.currentContextIds.shift();
  }

  nextIteration() {
    if (!(this.contexts && this.contexts.length > 0)) throw new Error("Cannot increase frame iteration, the context is empty");
    {
      this.contexts = this.contexts.slice(), this.lastId++;

      var _e781 = Object.assign({}, this.contexts[this.contexts.length - 1]);

      _e781.iterationId += 1, _e781.id = this.lastId, this.contexts.splice(-1, 1, _e781), this._currentContextIds.splice(0, 1, this.contextIdforContexts(this.contexts));
    }
  }

  getWeight(e) {
    return this.weightMap[e];
  }

  addTensorArray(e) {
    this.tensorArrayMap[e.id] = e;
  }

  getTensorArray(e) {
    return this.tensorArrayMap[e];
  }

  addTensorList(e) {
    this.tensorListMap[e.id] = e;
  }

  getTensorList(e) {
    return this.tensorListMap[e];
  }

  dispose(e) {
    for (var t in this.tensorArrayMap) {
      this.tensorArrayMap[t].clearAndClose(e);
    }

    for (var _t538 in this.tensorListMap) {
      this.tensorListMap[_t538].clearAndClose(e);
    }
  }

}

function getExecutionSubgraph(e, t, n, r) {
  var a = new Set(),
      s = [];
  var o = null,
      i = null;
  var l = new Set(),
      u = Object.keys(e).map(e => parseNodeName(e)[0]);
  var c = [];
  null != r && (c = r.map(e => parseNodeName(e.name)[0]));
  var p = [...t];

  for (; p.length > 0;) {
    var _e782 = p.pop();

    (isControlFlow(_e782) || isDynamicShape(_e782) || isHashTable(_e782)) && null == o && (o = _e782, i = o.children.map(e => e.name).filter(e => a.has(e))), a.add(_e782.name), null == n[_e782.name] && -1 === u.indexOf(_e782.name) && -1 === c.indexOf(_e782.name) && (0 !== _e782.inputs.length ? _e782.inputs.forEach(e => {
      l.has(e.name) || (l.add(e.name), p.push(e));
    }) : s.push(_e782.name));
  }

  return {
    inputs: e,
    outputs: t,
    usedNodes: a,
    missingInputs: s,
    dynamicNode: o,
    syncInputs: i
  };
}

function getNodesInTopologicalOrder(e, t, n) {
  var {
    usedNodes: r,
    inputs: a
  } = n,
      s = [],
      o = Object.keys(a).map(e => parseNodeName(e)[0]).map(t => e.nodes[t]),
      i = e.initNodes;
  o.forEach(e => {
    r.has(e.name) && s.push(e);
  }), e.weights.forEach(e => {
    r.has(e.name) && s.push(e);
  }), null != i && i.forEach(e => {
    r.has(e.name) && s.push(e);
  });
  var l = new Set(),
      u = [];

  for (; s.length > 0;) {
    var _e783 = s.pop();

    l.add(_e783.name), t[_e783.name] || u.push(_e783), _e783.children.forEach(e => {
      !l.has(e.name) && r.has(e.name) && e.inputs.every(e => l.has(e.name)) && s.push(e);
    });
  }

  return u;
}

var CONTROL_FLOW_OPS = ["Switch", "Merge", "Enter", "Exit", "NextIteration", "StatelessIf", "StatelessWhile", "if", "While"],
    DYNAMIC_SHAPE_OPS = ["NonMaxSuppressionV2", "NonMaxSuppressionV3", "NonMaxSuppressionV5", "Where"],
    HASH_TABLE_OPS = ["HashTable", "HashTableV2", "LookupTableImport", "LookupTableImportV2", "LookupTableFind", "LookupTableFindV2", "LookupTableSize", "LookupTableSizeV2"];

function isControlFlow(e) {
  return CONTROL_FLOW_OPS.indexOf(e.op) >= 0;
}

function isDynamicShape(e) {
  return DYNAMIC_SHAPE_OPS.indexOf(e.op) >= 0;
}

function isHashTable(e) {
  return HASH_TABLE_OPS.indexOf(e.op) >= 0;
}

class GraphExecutor {
  constructor(e, t) {
    this.graph = e, this.parent = t, this.compiledMap = new Map(), this._weightMap = {}, this.SEPERATOR = ",", this._functions = {}, this._functionExecutorMap = {}, this._outputs = e.outputs, this._inputs = e.inputs, this._initNodes = e.initNodes, this._signature = e.signature, this._functions = e.functions, null != e.functions && Object.keys(e.functions).forEach(t => {
      this._functionExecutorMap[t] = new GraphExecutor(e.functions[t], this);
    });
  }

  get weightIds() {
    return this.parent ? this.parent.weightIds : this._weightIds;
  }

  get functionExecutorMap() {
    return this.parent ? this.parent.functionExecutorMap : this._functionExecutorMap;
  }

  get weightMap() {
    return this.parent ? this.parent.weightMap : this._weightMap;
  }

  set weightMap(e) {
    var t = Object.keys(e).map(t => e[t].map(e => e.id));
    this._weightIds = [].concat(...t), this._weightMap = e;
  }

  set resourceManager(e) {
    this._resourceManager = e;
  }

  get inputs() {
    return this._inputs.map(e => ({
      name: e.name,
      shape: e.attrParams.shape ? e.attrParams.shape.value : void 0,
      dtype: e.attrParams.dtype ? e.attrParams.dtype.value : void 0
    }));
  }

  get outputs() {
    return this._outputs.map(e => ({
      name: e.name,
      shape: e.attrParams.shape ? e.attrParams.shape.value : void 0,
      dtype: e.attrParams.dtype ? e.attrParams.dtype.value : void 0
    }));
  }

  get inputNodes() {
    return this._inputs.map(e => e.signatureKey || e.name);
  }

  get outputNodes() {
    return this._outputs.map(e => {
      var t = e.signatureKey || e.name;
      return e.defaultOutput ? "".concat(t, ":").concat(e.defaultOutput) : t;
    });
  }

  get functions() {
    return Object.keys(this._functions).reduce((e, t) => (e[t] = this._functions[t].signature, e), {});
  }

  getCompilationKey(e, t) {
    var n = e.map(e => e.name).sort(),
        r = t.map(e => e.name).sort();
    return n.join(this.SEPERATOR) + "--" + r.join(this.SEPERATOR);
  }

  compile(e, t) {
    var n = getExecutionSubgraph(e, t, this.weightMap, this._initNodes),
        {
      missingInputs: r,
      dynamicNode: a,
      syncInputs: s
    } = n;
    if (null != a) throw new Error("This execution contains the node '".concat(a.name, "', which has the dynamic op '").concat(a.op, "'. Please use model.executeAsync() instead. Alternatively, to avoid the dynamic ops, specify the inputs [").concat(s, "]"));

    if (r.length > 0) {
      var _n303 = t.map(e => e.name),
          _a231 = Object.keys(e);

      throw new Error("Cannot compute the outputs [".concat(_n303, "] from the provided inputs [").concat(_a231, "]. Missing the following inputs: [").concat(r, "]"));
    }

    return getNodesInTopologicalOrder(this.graph, this.weightMap, n);
  }

  execute(e, t) {
    e = this.mapInputs(e);
    var n = Object.keys(e).sort();
    this.checkInputs(e), this.checkInputShapeAndType(e), t = this.mapOutputs(t), this.checkOutputs(t);
    var r = n.map(e => this.graph.nodes[parseNodeName(e)[0]]),
        a = t.map(e => parseNodeName(e)[0]);
    var s = a.map(e => this.graph.nodes[e]);
    0 === s.length && (s = this._outputs);
    var o = this.getCompilationKey(r, s);
    var i = this.compiledMap.get(o);
    null == i && (i = this.compile(e, s), this.compiledMap.set(o, i));
    var l = {},
        u = {};
    return tidy(() => {
      var n = new ExecutionContext(this.weightMap, l, u, this.functionExecutorMap),
          r = Object.assign({}, this.weightMap);
      Object.keys(e).forEach(t => {
        var [n, a] = parseNodeName(t),
            s = [];
        s[a] = e[t], r[n] = s;
      });
      var s = this.getFrozenTensorIds(r),
          o = {};

      for (var _e784 = 0; _e784 < i.length; _e784++) {
        var _t539 = i[_e784];

        if (!r[_t539.name]) {
          var _e785 = executeOp(_t539, r, n, this._resourceManager);

          if (isPromise(_e785)) throw new Error("The execution of the op '".concat(_t539.op, "' returned a promise. Please use model.executeAsync() instead."));
          r[_t539.name] = _e785, this.checkTensorForDisposal(_t539.name, _t539, r, n, s, a, o);
        }
      }

      return null == this.parent && n.dispose(s), t.map(e => getTensor(e, r, n));
    });
  }

  getFrozenTensorIds(e) {
    var t = [].concat.apply([], Object.keys(e).map(t => e[t]).map(e => e.map(e => e.id)));
    return new Set(t);
  }

  checkTensorForDisposal(e, t, n, r, a, s, o) {
    "control" !== t.category && -1 === s.indexOf(e) && (n[e].forEach(e => {
      null != e && (o[e.id] = (o[e.id] || 0) + t.children.length);
    }), t.inputs.forEach(e => {
      if ("control" !== e.category) {
        var _t540 = getTensorsForCurrentContenxt(e.name, n, r);

        null != _t540 && _t540.forEach(e => {
          if (e && !e.kept && !a.has(e.id)) {
            var _t541 = o[e.id];
            1 === _t541 ? (e.dispose(), delete o[e.id]) : null != _t541 && o[e.id]--;
          }
        });
      }
    }));
  }

  executeAsync(e, t) {
    var _this152 = this;

    return _asyncToGenerator(function* () {
      return _this152._executeAsync(e, t);
    })();
  }

  _executeAsync(e, t) {
    var _arguments7 = arguments,
        _this153 = this;

    return _asyncToGenerator(function* () {
      var n = _arguments7.length > 2 && _arguments7[2] !== undefined ? _arguments7[2] : !1;
      var r = _arguments7.length > 3 && _arguments7[3] !== undefined ? _arguments7[3] : {};
      var a = _arguments7.length > 4 && _arguments7[4] !== undefined ? _arguments7[4] : {};
      n || (e = _this153.mapInputs(e), _this153.checkInputs(e), _this153.checkInputShapeAndType(e), t = _this153.mapOutputs(t), _this153.checkOutputs(t));
      var s = new ExecutionContext(_this153.weightMap, r, a, _this153.functionExecutorMap),
          o = yield _this153.executeWithControlFlow(e, s, t, n),
          i = t.map(e => getTensor(e, o, s)),
          l = i.map(e => e.id),
          u = Object.keys(e).map(t => e[t].id),
          c = new Set([...l, ...u, ..._this153.weightIds]);
      return Object.keys(o).forEach(e => {
        o[e].forEach(e => {
          !e || e.kept || e.isDisposed || c.has(e.id) || e.dispose();
        });
      }), null == _this153.parent && s.dispose(c), i;
    })();
  }

  executeFunctionAsync(e, t, n) {
    var _this154 = this;

    return _asyncToGenerator(function* () {
      var r = e.reduce((e, t, n) => (e[_this154.inputs[n].name] = t, e), {});
      return _this154._executeAsync(r, _this154.outputNodes, !0, t, n);
    })();
  }

  executeWithControlFlow(e, t, n, r) {
    var _this155 = this;

    return _asyncToGenerator(function* () {
      var a = Object.keys(e),
          s = a.map(e => _this155.graph.nodes[parseNodeName(e)[0]]),
          o = n.map(e => parseNodeName(e)[0]);
      var i = o.map(e => _this155.graph.nodes[e]);
      0 === i.length && (i = _this155._outputs);
      var {
        usedNodes: l,
        missingInputs: u,
        dynamicNode: c,
        syncInputs: p
      } = getExecutionSubgraph(e, i, _this155.weightMap, _this155._initNodes),
          d = [...s, ..._this155.graph.weights, ...(_this155._initNodes || [])].map(e => ({
        node: e,
        contexts: t.currentContext
      })),
          h = Object.assign({}, _this155.weightMap);
      Object.keys(e).forEach(t => {
        var [n, r] = parseNodeName(t),
            a = [];
        a[r] = e[t], h[n] = a;
      });

      var m = {},
          f = _this155.getFrozenTensorIds(h),
          g = {};

      for (; d.length > 0;) {
        var _e786 = _this155.processStack(s, d, t, h, g, f, o, m, l);

        yield Promise.all(_e786);
      }

      null != c || r || console.warn("This model execution did not contain any nodes with control flow or dynamic output shapes. You can use model.execute() instead.");
      var $ = i.filter(e => !isControlFlow(e) && !getTensor(e.name, h, t)).map(e => e.name);

      if ($.length > 0) {
        var _e787 = "";
        throw null != c && (_e787 = "Alternatively, to avoid the dynamic ops, use model.execute() and specify the inputs [".concat(p, "]")), new Error("Cannot compute the outputs [".concat($, "] from the provided inputs [").concat(a, "]. Consider providing the following inputs: [").concat(u, "]. ").concat(_e787));
      }

      return h;
    })();
  }

  processStack(e, t, n, r, a, s, o, i, l) {
    var _this156 = this;

    var u = [];

    var _loop49 = function _loop49() {
      var e = t.pop();
      n.currentContext = e.contexts;
      var c = "";

      if ("Enter" === e.node.op && getParamValue("isConstant", e.node, r, n) && ([c] = getNodeNameAndIndex(e.node.name, n)), null == r[e.node.name]) {
        var _p25 = executeOp(e.node, r, n, _this156._resourceManager);

        c || ([c] = getNodeNameAndIndex(e.node.name, n));
        var d = n.currentContext;
        isPromise(_p25) ? u.push(_p25.then(u => (r[c] = u, n.currentContext = d, _this156.checkTensorForDisposal(c, e.node, r, n, s, o, i), _this156.processChildNodes(e.node, t, n, r, a, l), u))) : (r[c] = _p25, _this156.checkTensorForDisposal(c, e.node, r, n, s, o, i), _this156.processChildNodes(e.node, t, n, r, a, l));
      } else _this156.processChildNodes(e.node, t, n, r, a, l);
    };

    for (; t.length > 0;) {
      _loop49();
    }

    return u;
  }

  processChildNodes(e, t, n, r, a, s) {
    e.children.forEach(e => {
      var [o] = getNodeNameAndIndex(e.name, n);
      !a[o] && s.has(e.name) && ("Merge" === e.op ? e.inputNames.some(e => !!getTensor(e, r, n)) && (a[o] = !0, t.push({
        contexts: n.currentContext,
        node: e
      })) : e.inputNames.every(e => !!getTensor(e, r, n)) && (a[o] = !0, t.push({
        contexts: n.currentContext,
        node: e
      })));
    });
  }

  dispose() {
    Object.keys(this.weightMap).forEach(e => this.weightMap[e].forEach(e => e.dispose()));
  }

  checkInputShapeAndType(e) {
    Object.keys(e).forEach(t => {
      var n = e[t],
          [r] = parseNodeName(t),
          a = this.graph.nodes[r];

      if (a.attrParams.shape && a.attrParams.shape.value) {
        var _e788 = a.attrParams.shape.value,
            _t542 = _e788.length === n.shape.length && n.shape.every((t, n) => -1 === _e788[n] || _e788[n] === t);

        assert$4(_t542, () => "The shape of dict['".concat(a.name, "'] provided in model.execute(dict) must be [").concat(_e788, "], but was [").concat(n.shape, "]"));
      }

      a.attrParams.dtype && a.attrParams.dtype.value && assert$4(n.dtype === a.attrParams.dtype.value, () => "The dtype of dict['".concat(a.name, "'] provided in model.execute(dict) must be ").concat(a.attrParams.dtype.value, ", but was ").concat(n.dtype));
    });
  }

  mapInputs(e) {
    var t = {};

    for (var n in e) {
      null != this._signature && null != this._signature.inputs && null != this._signature.inputs[n] ? t[this._signature.inputs[n].name] = e[n] : t[n] = e[n];
    }

    return t;
  }

  checkInputs(e) {
    var t = Object.keys(e).filter(e => {
      var [t] = parseNodeName(e);
      return null == this.graph.nodes[t];
    });
    if (t.length > 0) throw new Error("The dict provided in model.execute(dict) has keys: [".concat(t, "] that are not part of graph"));
  }

  mapOutputs(e) {
    return e.map(e => null != this._signature && null != this._signature.outputs && null != this._signature.outputs[e] ? this._signature.outputs[e].name : e, {});
  }

  checkOutputs(e) {
    e.forEach(e => {
      var [t] = parseNodeName(e);
      if (!this.graph.nodes[t]) throw new Error("The output '".concat(e, "' is not found in the graph"));
    });
  }

}

class ResourceManager {
  constructor() {
    var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : {};
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};
    this.hashTableNameToHandle = e, this.hashTableMap = t;
  }

  addHashTable(e, t) {
    this.hashTableNameToHandle[e] = t.handle, this.hashTableMap[t.id] = t;
  }

  getHashTableHandleByName(e) {
    return this.hashTableNameToHandle[e];
  }

  getHashTableById(e) {
    return this.hashTableMap[e];
  }

  dispose() {
    for (var _e789 in this.hashTableMap) {
      this.hashTableMap[_e789].clearAndClose(), delete this.hashTableMap[_e789];
    }

    for (var _e790 in this.hashTableNameToHandle) {
      this.hashTableNameToHandle[_e790].dispose(), delete this.hashTableNameToHandle[_e790];
    }
  }

}

var TFHUB_SEARCH_PARAM = "?tfjs-format=file",
    DEFAULT_MODEL_NAME = "model.json";

class GraphModel {
  constructor(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};
    this.modelUrl = e, this.loadOptions = t, this.version = "n/a", null == t && (this.loadOptions = {}), this.resourceManager = new ResourceManager();
  }

  get modelVersion() {
    return this.version;
  }

  get inputNodes() {
    return this.executor.inputNodes;
  }

  get outputNodes() {
    return this.executor.outputNodes;
  }

  get inputs() {
    return this.executor.inputs;
  }

  get outputs() {
    return this.executor.outputs;
  }

  get weights() {
    return this.executor.weightMap;
  }

  get metadata() {
    return this.artifacts.userDefinedMetadata;
  }

  get modelSignature() {
    return this.signature;
  }

  findIOHandler() {
    var e = this.modelUrl;
    if (null != e.load) this.handler = e;else if (null != this.loadOptions.requestInit) this.handler = browserHTTPRequest(e, this.loadOptions);else {
      var t = getLoadHandlers(e, this.loadOptions);
      if (0 === t.length) t.push(browserHTTPRequest(e, this.loadOptions));else if (t.length > 1) throw new Error("Found more than one (".concat(t.length, ") load handlers for URL '").concat([e], "'"));
      this.handler = t[0];
    }
  }

  load() {
    var _this157 = this;

    return _asyncToGenerator(function* () {
      if (_this157.findIOHandler(), null == _this157.handler.load) throw new Error("Cannot proceed with model loading because the IOHandler provided does not have the `load` method implemented.");
      var e = yield _this157.handler.load();
      return _this157.loadSync(e);
    })();
  }

  loadSync(e) {
    this.artifacts = e;
    var t = this.artifacts.modelTopology;
    var n;
    n = null != this.artifacts.userDefinedMetadata && null != this.artifacts.userDefinedMetadata.signature ? this.artifacts.userDefinedMetadata.signature : this.artifacts.signature, this.signature = n, this.version = "".concat(t.versions.producer, ".").concat(t.versions.minConsumer);
    var r = decodeWeights(this.artifacts.weightData, this.artifacts.weightSpecs);

    if (this.executor = new GraphExecutor(OperationMapper.Instance.transformGraph(t, this.signature)), this.executor.weightMap = this.convertTensorMapToTensorsMap(r), this.executor.resourceManager = this.resourceManager, null != e.modelInitializer && null != e.modelInitializer.node) {
      var _t543 = OperationMapper.Instance.transformGraph(e.modelInitializer);

      this.initializer = new GraphExecutor(_t543), this.initializer.weightMap = this.executor.weightMap, this.initializer.resourceManager = this.resourceManager, this.initializer.executeAsync({}, []);
    }

    return !0;
  }

  save(e, t) {
    var _this158 = this;

    return _asyncToGenerator(function* () {
      if ("string" == typeof e) {
        var _t544 = getSaveHandlers(e);

        if (0 === _t544.length) throw new Error("Cannot find any save handlers for URL '".concat(e, "'"));
        if (_t544.length > 1) throw new Error("Found more than one (".concat(_t544.length, ") save handlers for URL '").concat(e, "'"));
        e = _t544[0];
      }

      if (null == e.save) throw new Error("GraphModel.save() cannot proceed because the IOHandler provided does not have the `save` attribute defined.");
      return e.save(_this158.artifacts);
    })();
  }

  predict(e, t) {
    return this.execute(e, this.outputNodes);
  }

  normalizeInputs(e) {
    if (!(e instanceof Tensor || Array.isArray(e))) return e;
    if ((e = Array.isArray(e) ? e : [e]).length !== this.inputNodes.length) throw new Error("Input tensor count mismatch,the graph model has ".concat(this.inputNodes.length, " placeholders, while there are ").concat(e.length, " input tensors."));
    return this.inputNodes.reduce((t, n, r) => (t[n] = e[r], t), {});
  }

  normalizeOutputs(e) {
    return e = e || this.outputNodes, Array.isArray(e) ? e : [e];
  }

  execute(e, t) {
    e = this.normalizeInputs(e), t = this.normalizeOutputs(t);
    var n = this.executor.execute(e, t);
    return n.length > 1 ? n : n[0];
  }

  executeAsync(e, t) {
    var _this159 = this;

    return _asyncToGenerator(function* () {
      e = _this159.normalizeInputs(e), t = _this159.normalizeOutputs(t);
      var n = yield _this159.executor.executeAsync(e, t);
      return n.length > 1 ? n : n[0];
    })();
  }

  convertTensorMapToTensorsMap(e) {
    return Object.keys(e).reduce((t, n) => (t[n] = [e[n]], t), {});
  }

  dispose() {
    this.executor.dispose(), this.initializer && this.initializer.dispose(), this.resourceManager.dispose();
  }

}

function loadGraphModel(_x132) {
  return _loadGraphModel.apply(this, arguments);
}

function _loadGraphModel() {
  _loadGraphModel = _asyncToGenerator(function* (e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};
    if (null == e) throw new Error("modelUrl in loadGraphModel() cannot be null. Please provide a url or an IOHandler that loads the model");
    null == t && (t = {}), t.fromTFHub && null == e.load && (e.endsWith("/") || (e += "/"), e = "".concat(e).concat(DEFAULT_MODEL_NAME).concat(TFHUB_SEARCH_PARAM));
    var n = new GraphModel(e, t);
    return yield n.load(), n;
  });
  return _loadGraphModel.apply(this, arguments);
}

var version$5 = "3.8.0";

function deepMap(e, t) {
  return deepMapInternal(e, t);
}

function deepMapInternal(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : new Map();
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : new Set();
  if (null == e) return null;
  if (r.has(e)) throw new Error("Circular references are not supported.");
  if (n.has(e)) return n.get(e);
  var a = t(e);
  if (a.recurse && null !== a.value) throw new Error("A deep map function may not return both a value and recurse=true.");

  if (a.recurse) {
    if (isIterable(e)) {
      var _a232 = Array.isArray(e) ? [] : {};

      r.add(e);

      for (var s in e) {
        var o = deepMapInternal(e[s], t, n, r);
        _a232[s] = o;
      }

      return r.delete(e), _a232;
    }

    throw new Error("Can't recurse into non-iterable type: ".concat(e));
  }

  return n.set(e, a.value), a.value;
}

function deepZip(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : zipToList;
  return deepZipInternal(e, t);
}

function deepZipInternal(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : new Set();
  var r = e[0];
  if (n.has(r)) throw new Error("Circular references are not supported.");
  var a = t(e);
  if (a.recurse && null !== a.value) throw new Error("A deep zip function may not return both a value and recurse=true.");

  if (a.recurse) {
    if (isIterable(r)) {
      var _a233 = Array.isArray(r) ? [] : {};

      n.add(r);

      var _loop50 = function _loop50(s) {
        var r = deepZipInternal(e.map(e => e[s]), t, n);
        _a233[s] = r;
      };

      for (var s in r) {
        _loop50(s);
      }

      return n.delete(r), _a233;
    }

    throw new Error("Can't recurse into non-iterable type: ".concat(r));
  }

  return a.value;
}

function zipToList(e) {
  return null === e ? null : isIterable(e[0]) ? {
    value: null,
    recurse: !0
  } : {
    value: e,
    recurse: !1
  };
}

function deepMapAndAwaitAll(_x133, _x134) {
  return _deepMapAndAwaitAll.apply(this, arguments);
}

function _deepMapAndAwaitAll() {
  _deepMapAndAwaitAll = _asyncToGenerator(function* (e, t) {
    var n = new Map();
    deepMapInternal(e, t, n);

    for (var _e1173 of Array.from(n.keys())) {
      var _t791 = n.get(_e1173);

      if (isPromise(_t791)) {
        var r = yield _t791;
        n.set(_e1173, r);
      }
    }

    return deepMapInternal(e, t, n);
  });
  return _deepMapAndAwaitAll.apply(this, arguments);
}

function isIterable(e) {
  return null != e && !ArrayBuffer.isView(e) && (Array.isArray(e) || "object" == typeof e && !(e instanceof Tensor));
}

function canTensorify(e) {
  return null == e || isPrimitive(e) || Array.isArray(e) || "object" == typeof e && e instanceof Tensor || isTypedArray(e);
}

function isPrimitive(e) {
  return null === e || "object" != typeof e && "function" != typeof e;
}

function deepClone(e) {
  return deepMap(e, cloneIfTensor);
}

function cloneIfTensor(e) {
  return e instanceof Tensor ? {
    value: e.clone(),
    recurse: !1
  } : isIterable(e) ? {
    value: null,
    recurse: !0
  } : {
    value: e,
    recurse: !1
  };
}

class RingBuffer {
  constructor(e) {
    if (this.capacity = e, this.begin = 0, this.end = 0, null == e) throw new RangeError("Can't create a ring buffer of unknown capacity.");
    if (e < 1) throw new RangeError("Can't create ring buffer of capacity < 1.");
    this.data = new Array(e), this.doubledCapacity = 2 * e;
  }

  wrap(e) {
    for (; e < 0;) {
      e += this.doubledCapacity;
    }

    return e % this.doubledCapacity;
  }

  get(e) {
    if (e < 0) throw new RangeError("Can't get item at a negative index.");
    return this.data[e % this.capacity];
  }

  set(e, t) {
    if (e < 0) throw new RangeError("Can't set item at a negative index.");
    this.data[e % this.capacity] = t;
  }

  length() {
    var e = this.end - this.begin;
    return e < 0 && (e = this.doubledCapacity + e), e;
  }

  isFull() {
    return this.length() === this.capacity;
  }

  isEmpty() {
    return 0 === this.length();
  }

  push(e) {
    if (this.isFull()) throw new RangeError("Ring buffer is full.");
    this.set(this.end, e), this.end = this.wrap(this.end + 1);
  }

  pushAll(e) {
    for (var t of e) {
      this.push(t);
    }
  }

  pop() {
    if (this.isEmpty()) throw new RangeError("Ring buffer is empty.");
    this.end = this.wrap(this.end - 1);
    var e = this.get(this.end);
    return this.set(this.end, void 0), e;
  }

  unshift(e) {
    if (this.isFull()) throw new RangeError("Ring buffer is full.");
    this.begin = this.wrap(this.begin - 1), this.set(this.begin, e);
  }

  shift() {
    if (this.isEmpty()) throw new RangeError("Ring buffer is empty.");
    var e = this.get(this.begin);
    return this.set(this.begin, void 0), this.begin = this.wrap(this.begin + 1), e;
  }

  shuffleExcise(e) {
    if (this.isEmpty()) throw new RangeError("Ring buffer is empty.");
    var t = this.wrap(this.begin + e),
        n = this.get(t);
    return this.set(t, this.pop()), n;
  }

}

class GrowingRingBuffer extends RingBuffer {
  constructor() {
    super(GrowingRingBuffer.INITIAL_CAPACITY);
  }

  isFull() {
    return !1;
  }

  push(e) {
    super.isFull() && this.expand(), super.push(e);
  }

  unshift(e) {
    super.isFull() && this.expand(), super.unshift(e);
  }

  expand() {
    var e = 2 * this.capacity,
        t = new Array(e),
        n = this.length();

    for (var _e791 = 0; _e791 < n; _e791++) {
      t[_e791] = this.get(this.wrap(this.begin + _e791));
    }

    this.data = t, this.capacity = e, this.doubledCapacity = 2 * this.capacity, this.begin = 0, this.end = n;
  }

}

function iteratorFromItems(e) {
  return new ArrayIterator(e);
}

function iteratorFromFunction(e) {
  return new FunctionCallIterator(e);
}

function iteratorFromConcatenated(e, t) {
  return new ChainedIterator(e, t);
}

function iteratorFromZipped(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : ZipMismatchMode.FAIL;
  return new ZipIterator(e, t);
}

GrowingRingBuffer.INITIAL_CAPACITY = 32;

class LazyIterator {
  toArray() {
    var _this160 = this;

    return _asyncToGenerator(function* () {
      var e = [];
      var t = yield _this160.next();

      for (; !t.done;) {
        e.push(t.value), t = yield _this160.next();
      }

      return e;
    })();
  }

  toArrayForTest() {
    var _this161 = this;

    return _asyncToGenerator(function* () {
      var e = _this161.prefetch(100),
          t = [];

      var n = yield e.next();

      for (; !n.done;) {
        t.push(n.value), n = yield e.next();
      }

      return t;
    })();
  }

  resolveFully() {
    var _this162 = this;

    return _asyncToGenerator(function* () {
      var e = yield _this162.next();

      for (; !e.done;) {
        e = yield _this162.next();
      }
    })();
  }

  resolveWhile(e) {
    var _this163 = this;

    return _asyncToGenerator(function* () {
      var t = yield _this163.next(),
          n = e(t.value);

      for (; !t.done && n;) {
        t = yield _this163.next(), n = e(t.value);
      }
    })();
  }

  handleErrors(e) {
    return new ErrorHandlingLazyIterator(this, e);
  }

  filter(e) {
    return new FilterIterator(this, e);
  }

  map(e) {
    return new MapIterator(this, e);
  }

  mapAsync(e) {
    return new AsyncMapIterator(this, e);
  }

  serialMapAsync(e) {
    return new AsyncMapIterator(this, e).serial();
  }

  flatmap(e) {
    return new FlatmapIterator(this, e);
  }

  forEachAsync(e) {
    var _this164 = this;

    return _asyncToGenerator(function* () {
      return _this164.map(e).resolveFully();
    })();
  }

  serialForEach(e) {
    var _this165 = this;

    return _asyncToGenerator(function* () {
      return _this165.serialMapAsync(e).resolveWhile(e => !0 === e);
    })();
  }

  rowMajorBatch(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !0;
    return new RowMajorBatchIterator(this, e, t);
  }

  columnMajorBatch(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !0;
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : zipToList;
    return this.rowMajorBatch(e, t).map(e => deepZip(e, n));
  }

  concatenate(e, t) {
    return new ChainedIterator(iteratorFromItems([this, e]), t);
  }

  take(e) {
    return e < 0 || null == e ? this : new TakeIterator(this, e);
  }

  skip(e) {
    return e < 0 || null == e ? this : new SkipIterator(this, e);
  }

  prefetch(e) {
    return new PrefetchIterator(this, e);
  }

  shuffle(e, t) {
    return new ShuffleIterator(this, e, t);
  }

  serial() {
    return new SerialIterator(this);
  }

}

class ArrayIterator extends LazyIterator {
  constructor(e) {
    super(), this.items = e, this.trav = 0;
  }

  summary() {
    return "Array of ".concat(this.items.length, " items");
  }

  next() {
    var _this166 = this;

    return _asyncToGenerator(function* () {
      if (_this166.trav >= _this166.items.length) return {
        value: null,
        done: !0
      };
      var e = _this166.items[_this166.trav];
      return _this166.trav++, {
        value: deepClone(e),
        done: !1
      };
    })();
  }

}

class FunctionCallIterator extends LazyIterator {
  constructor(e) {
    super(), this.nextFn = e;
  }

  summary() {
    return "Function call";
  }

  next() {
    var _this167 = this;

    return _asyncToGenerator(function* () {
      try {
        return _this167.nextFn();
      } catch (e) {
        throw e.message = "Error thrown while iterating through a dataset: ".concat(e.message), e;
      }
    })();
  }

}

class SerialIterator extends LazyIterator {
  constructor(e) {
    super(), this.upstream = e, this.lastRead = Promise.resolve({
      value: null,
      done: !1
    });
  }

  summary() {
    return "".concat(this.upstream.summary(), " -> Serial");
  }

  next() {
    var _this168 = this;

    return _asyncToGenerator(function* () {
      return _this168.lastRead = _this168.lastRead.then(() => _this168.serialNext()), _this168.lastRead;
    })();
  }

  serialNext() {
    var _this169 = this;

    return _asyncToGenerator(function* () {
      return _this169.upstream.next();
    })();
  }

}

class SkipIterator extends LazyIterator {
  constructor(e, t) {
    super(), this.upstream = e, this.maxCount = t, this.count = 0, this.lastRead = Promise.resolve({
      value: null,
      done: !1
    });
  }

  summary() {
    return "".concat(this.upstream.summary(), " -> Skip");
  }

  next() {
    var _this170 = this;

    return _asyncToGenerator(function* () {
      return _this170.lastRead = _this170.lastRead.then(() => _this170.serialNext()), _this170.lastRead;
    })();
  }

  serialNext() {
    var _this171 = this;

    return _asyncToGenerator(function* () {
      for (; _this171.count++ < _this171.maxCount;) {
        var _e792 = yield _this171.upstream.next();

        if (_e792.done) return _e792;
        dispose(_e792.value);
      }

      return _this171.upstream.next();
    })();
  }

}

class TakeIterator extends LazyIterator {
  constructor(e, t) {
    super(), this.upstream = e, this.maxCount = t, this.count = 0;
  }

  summary() {
    return "".concat(this.upstream.summary(), " -> Take");
  }

  next() {
    var _this172 = this;

    return _asyncToGenerator(function* () {
      return _this172.count++ >= _this172.maxCount ? {
        value: null,
        done: !0
      } : _this172.upstream.next();
    })();
  }

}

class RowMajorBatchIterator extends LazyIterator {
  constructor(e, t) {
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !0;
    super(), this.upstream = e, this.batchSize = t, this.enableSmallLastBatch = n, this.lastRead = Promise.resolve({
      value: null,
      done: !1
    });
  }

  summary() {
    return "".concat(this.upstream.summary(), " -> RowMajorBatch");
  }

  next() {
    var _this173 = this;

    return _asyncToGenerator(function* () {
      return _this173.lastRead = _this173.lastRead.then(() => _this173.serialNext()), _this173.lastRead;
    })();
  }

  serialNext() {
    var _this174 = this;

    return _asyncToGenerator(function* () {
      var e = [];

      for (; e.length < _this174.batchSize;) {
        var t = yield _this174.upstream.next();
        if (t.done) return _this174.enableSmallLastBatch && e.length > 0 ? {
          value: e,
          done: !1
        } : {
          value: null,
          done: !0
        };
        e.push(t.value);
      }

      return {
        value: e,
        done: !1
      };
    })();
  }

}

class FilterIterator extends LazyIterator {
  constructor(e, t) {
    super(), this.upstream = e, this.predicate = t, this.lastRead = Promise.resolve({
      value: null,
      done: !1
    });
  }

  summary() {
    return "".concat(this.upstream.summary(), " -> Filter");
  }

  next() {
    var _this175 = this;

    return _asyncToGenerator(function* () {
      return _this175.lastRead = _this175.lastRead.then(() => _this175.serialNext()), _this175.lastRead;
    })();
  }

  serialNext() {
    var _this176 = this;

    return _asyncToGenerator(function* () {
      for (;;) {
        var _e793 = yield _this176.upstream.next();

        if (_e793.done || _this176.predicate(_e793.value)) return _e793;
        dispose(_e793.value);
      }
    })();
  }

}

class MapIterator extends LazyIterator {
  constructor(e, t) {
    super(), this.upstream = e, this.transform = t;
  }

  summary() {
    return "".concat(this.upstream.summary(), " -> Map");
  }

  next() {
    var _this177 = this;

    return _asyncToGenerator(function* () {
      var e = yield _this177.upstream.next();
      if (e.done) return {
        value: null,
        done: !0
      };

      var t = getTensorsInContainer(e.value),
          n = _this177.transform(e.value),
          r = getTensorsInContainer(n);

      for (var _e794 of t) {
        isTensorInList(_e794, r) || _e794.dispose();
      }

      return {
        value: n,
        done: !1
      };
    })();
  }

}

class ErrorHandlingLazyIterator extends LazyIterator {
  constructor(e, t) {
    super(), this.upstream = e, this.handler = t, this.count = 0, this.lastRead = Promise.resolve({
      value: null,
      done: !1
    });
  }

  summary() {
    return "".concat(this.upstream.summary(), " -> handleErrors");
  }

  next() {
    var _this178 = this;

    return _asyncToGenerator(function* () {
      return _this178.lastRead = _this178.lastRead.then(() => _this178.serialNext()), _this178.lastRead;
    })();
  }

  serialNext() {
    var _this179 = this;

    return _asyncToGenerator(function* () {
      for (;;) {
        try {
          return yield _this179.upstream.next();
        } catch (e) {
          if (!_this179.handler(e)) return {
            value: null,
            done: !0
          };
        }
      }
    })();
  }

}

class AsyncMapIterator extends LazyIterator {
  constructor(e, t) {
    super(), this.upstream = e, this.transform = t;
  }

  summary() {
    return "".concat(this.upstream.summary(), " -> AsyncMap");
  }

  next() {
    var _this180 = this;

    return _asyncToGenerator(function* () {
      var e = yield _this180.upstream.next();
      if (e.done) return {
        value: null,
        done: !0
      };
      var t = getTensorsInContainer(e.value),
          n = yield _this180.transform(e.value),
          r = getTensorsInContainer(n);

      for (var _e795 of t) {
        isTensorInList(_e795, r) || _e795.dispose();
      }

      return {
        value: n,
        done: !1
      };
    })();
  }

}

class OneToManyIterator extends LazyIterator {
  constructor() {
    super(), this.outputQueue = new GrowingRingBuffer(), this.lastRead = Promise.resolve({
      value: null,
      done: !1
    });
  }

  next() {
    var _this181 = this;

    return _asyncToGenerator(function* () {
      return _this181.lastRead = _this181.lastRead.then(() => _this181.serialNext()), _this181.lastRead;
    })();
  }

  serialNext() {
    var _this182 = this;

    return _asyncToGenerator(function* () {
      for (; 0 === _this182.outputQueue.length();) {
        if (!(yield _this182.pump())) return {
          value: null,
          done: !0
        };
      }

      return {
        value: _this182.outputQueue.shift(),
        done: !1
      };
    })();
  }

}

class FlatmapIterator extends OneToManyIterator {
  constructor(e, t) {
    super(), this.upstream = e, this.transform = t;
  }

  summary() {
    return "".concat(this.upstream.summary(), " -> Flatmap");
  }

  pump() {
    var _this183 = this;

    return _asyncToGenerator(function* () {
      var e = yield _this183.upstream.next();
      if (e.done) return !1;

      var t = getTensorsInContainer(e.value),
          n = _this183.transform(e.value),
          r = getTensorsInContainer(n);

      _this183.outputQueue.pushAll(n);

      for (var _e796 of t) {
        isTensorInList(_e796, r) || _e796.dispose();
      }

      return !0;
    })();
  }

}

class ChainedIterator extends LazyIterator {
  constructor(e, t) {
    super(), this.baseErrorHandler = t, this.lastRead = null, this.iterator = null, this.moreIterators = e;
  }

  summary() {
    return "TODO: fill in upstream of chained summaries -> Chained";
  }

  next() {
    var _this184 = this;

    return _asyncToGenerator(function* () {
      return _this184.lastRead = _this184.readFromChain(_this184.lastRead), _this184.lastRead;
    })();
  }

  readFromChain(e) {
    var _this185 = this;

    return _asyncToGenerator(function* () {
      if (yield e, null == _this185.iterator) {
        var _e797 = yield _this185.moreIterators.next();

        if (_e797.done) return {
          value: null,
          done: !0
        };
        _this185.iterator = _e797.value, null != _this185.baseErrorHandler && (_this185.iterator = _this185.iterator.handleErrors(_this185.baseErrorHandler));
      }

      var t = yield _this185.iterator.next();
      return t.done ? (_this185.iterator = null, _this185.readFromChain(e)) : t;
    })();
  }

}

var ZipMismatchMode;
!function (e) {
  e[e.FAIL = 0] = "FAIL", e[e.SHORTEST = 1] = "SHORTEST", e[e.LONGEST = 2] = "LONGEST";
}(ZipMismatchMode || (ZipMismatchMode = {}));

class ZipIterator extends LazyIterator {
  constructor(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : ZipMismatchMode.FAIL;
    super(), this.iterators = e, this.mismatchMode = t, this.count = 0, this.currentPromise = null;
  }

  summary() {
    return "{TODO: fill in upstream of zip summaries} -> Zip";
  }

  nextState(e) {
    var _this186 = this;

    return _asyncToGenerator(function* () {
      yield e;
      var t = 0,
          n = 0;
      var r = yield deepMapAndAwaitAll(_this186.iterators, function (e) {
        return e instanceof LazyIterator ? {
          value: e.next().then(e => (t++, e.done && n++, e.value)),
          recurse: !1
        } : {
          value: null,
          recurse: !0
        };
      });
      if (t === n) return {
        value: null,
        done: !0
      };
      if (n > 0) switch (_this186.mismatchMode) {
        case ZipMismatchMode.FAIL:
          throw new Error("Zipped streams should have the same length. Mismatched at element ".concat(_this186.count, "."));

        case ZipMismatchMode.SHORTEST:
          return {
            value: null,
            done: !0
          };
      }
      return _this186.count++, {
        value: r,
        done: !1
      };
    })();
  }

  next() {
    var _this187 = this;

    return _asyncToGenerator(function* () {
      return _this187.currentPromise = _this187.nextState(_this187.currentPromise), _this187.currentPromise;
    })();
  }

}

class PrefetchIterator extends LazyIterator {
  constructor(e, t) {
    super(), this.upstream = e, this.bufferSize = t, this.buffer = new RingBuffer(t);
  }

  summary() {
    return "".concat(this.upstream.summary(), " -> Prefetch");
  }

  refill() {
    for (; !this.buffer.isFull();) {
      var _e798 = this.upstream.next();

      this.buffer.push(_e798);
    }
  }

  next() {
    return this.refill(), this.buffer.shift();
  }

}

class ShuffleIterator extends PrefetchIterator {
  constructor(e, t, n) {
    super(e, t), this.upstream = e, this.windowSize = t, this.upstreamExhausted = !1, this.random = seedrandom.alea(n || now().toString()), this.lastRead = Promise.resolve({
      value: null,
      done: !1
    });
  }

  next() {
    var _this188 = this;

    return _asyncToGenerator(function* () {
      return _this188.lastRead = _this188.lastRead.then(() => _this188.serialNext()), _this188.lastRead;
    })();
  }

  randomInt(e) {
    return Math.floor(this.random() * e);
  }

  chooseIndex() {
    return this.randomInt(this.buffer.length());
  }

  serialNext() {
    var _this189 = this;

    return _asyncToGenerator(function* () {
      for (_this189.upstreamExhausted || _this189.refill(); !_this189.buffer.isEmpty();) {
        var _e799 = _this189.chooseIndex(),
            t = yield _this189.buffer.shuffleExcise(_e799);

        if (!t.done) return _this189.refill(), t;
        _this189.upstreamExhausted = !0;
      }

      return {
        value: null,
        done: !0
      };
    })();
  }

}

class Dataset {
  constructor() {
    this.size = null;
  }

  batch(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !0;
    var n = this;
    var r;
    return assert$4(e > 0, () => "batchSize needs to be positive, but it is\n      ".concat(e)), r = Infinity === this.size || null == this.size ? this.size : t ? Math.ceil(this.size / e) : Math.floor(this.size / e), datasetFromIteratorFn( /*#__PURE__*/_asyncToGenerator(function* () {
      return (yield n.iterator()).columnMajorBatch(e, t, deepBatchConcat);
    }), r);
  }

  concatenate(e) {
    var t = this;
    var n;
    return n = Infinity === this.size || Infinity === e.size ? Infinity : null != this.size && null != e.size ? this.size + e.size : null, datasetFromIteratorFn( /*#__PURE__*/_asyncToGenerator(function* () {
      return (yield t.iterator()).concatenate(yield e.iterator());
    }), n);
  }

  filter(e) {
    var t = this;
    var n;
    return n = Infinity === this.size ? Infinity : null, datasetFromIteratorFn( /*#__PURE__*/_asyncToGenerator(function* () {
      return (yield t.iterator()).filter(t => tidy(() => e(t)));
    }), n);
  }

  forEachAsync(e) {
    var _this190 = this;

    return _asyncToGenerator(function* () {
      return (yield _this190.iterator()).forEachAsync(e);
    })();
  }

  map(e) {
    var t = this;
    return datasetFromIteratorFn( /*#__PURE__*/_asyncToGenerator(function* () {
      return (yield t.iterator()).map(t => tidy(() => e(t)));
    }), this.size);
  }

  mapAsync(e) {
    var t = this;
    return datasetFromIteratorFn( /*#__PURE__*/_asyncToGenerator(function* () {
      return (yield t.iterator()).mapAsync(e);
    }), this.size);
  }

  prefetch(e) {
    if (null == e) throw new RangeError("`Dataset.prefetch()` requires bufferSize to be specified.");
    var t = this;
    return datasetFromIteratorFn( /*#__PURE__*/_asyncToGenerator(function* () {
      return (yield t.iterator()).prefetch(e);
    }), this.size);
  }

  repeat(e) {
    var t = this;
    var n;
    return n = null != this.size && e > 0 ? this.size * e : 0 === e ? 0 : null != this.size && (void 0 === e || e < 0) ? Infinity : null, datasetFromIteratorFn( /*#__PURE__*/_asyncToGenerator(function* () {
      return iteratorFromConcatenated(iteratorFromFunction( /*#__PURE__*/_asyncToGenerator(function* () {
        return {
          value: yield t.iterator(),
          done: !1
        };
      })).take(e));
    }), n);
  }

  skip(e) {
    var t = this;
    var n;
    return n = null != this.size && e >= 0 && this.size >= e ? this.size - e : null != this.size && (this.size < e || void 0 === e || e < 0) ? 0 : null, datasetFromIteratorFn( /*#__PURE__*/_asyncToGenerator(function* () {
      return (yield t.iterator()).skip(e);
    }), n);
  }

  shuffle(e, t) {
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !0;
    if (null == e || e < 0) throw null == this.size ? new RangeError("`Dataset.shuffle()` requires bufferSize to be specified.") : new RangeError("`Dataset.shuffle()` requires bufferSize to be specified.  If your data fits in main memory (for regular JS objects), and/or GPU memory (for `tf.Tensor`s), consider setting bufferSize to the dataset size (".concat(this.size, " elements)"));
    var r = this,
        a = seedrandom.alea(t || now().toString());
    return datasetFromIteratorFn( /*#__PURE__*/_asyncToGenerator(function* () {
      var t = a.int32();
      return n && (t += a.int32()), (yield r.iterator()).shuffle(e, t.toString());
    }), this.size);
  }

  take(e) {
    var t = this;
    var n;
    return n = null != this.size && this.size > e ? e : null != this.size && this.size <= e ? this.size : null, datasetFromIteratorFn( /*#__PURE__*/_asyncToGenerator(function* () {
      return (yield t.iterator()).take(e);
    }), n);
  }

  toArray() {
    var _this191 = this;

    return _asyncToGenerator(function* () {
      if (Infinity === _this191.size) throw new Error("Can not convert infinite data stream to array.");
      return (yield _this191.iterator()).toArray();
    })();
  }

  toArrayForTest() {
    var _this192 = this;

    return _asyncToGenerator(function* () {
      if (Infinity === _this192.size) throw new Error("Can not convert infinite data stream to array.");
      return (yield _this192.iterator()).toArrayForTest();
    })();
  }

}

function datasetFromIteratorFn(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : null;
  return new class extends Dataset {
    constructor() {
      super(...arguments), this.size = t;
    }

    iterator() {
      return _asyncToGenerator(function* () {
        return e();
      })();
    }

  }();
}

function array(e) {
  return datasetFromIteratorFn( /*#__PURE__*/_asyncToGenerator(function* () {
    return iteratorFromItems(e);
  }), e.length);
}

function zip(e) {
  if (!isIterable(e)) throw new Error("The argument to zip() must be an object or array.");
  var t;
  if (Array.isArray(e)) for (var n = 0; n < e.length; n++) {
    t = null == t ? e[n].size : Math.min(t, e[n].size);
  } else if (e instanceof Object) for (var _n304 in e) {
    t = null == t ? e[_n304].size : Math.min(t, e[_n304].size);
  }
  return datasetFromIteratorFn( /*#__PURE__*/_asyncToGenerator(function* () {
    return iteratorFromZipped(yield deepMapAndAwaitAll(e, e => {
      if (e instanceof Dataset) return {
        value: e.iterator(),
        recurse: !1
      };
      if (isIterable(e)) return {
        value: null,
        recurse: !0
      };
      throw new Error("Leaves of the structure passed to zip() must be Datasets, not primitives.");
    }), ZipMismatchMode.SHORTEST);
  }), t);
}

function deepBatchConcat(e) {
  return null === e ? null : canTensorify(e[0]) ? {
    value: batchConcat(e),
    recurse: !1
  } : {
    value: null,
    recurse: !0
  };
}

function batchConcat(e) {
  if (0 === e.length) throw new Error("Can't make a batch of zero elements.");
  return e[0] instanceof Tensor ? stack(e) : tensor(e);
}

Dataset.MAX_BUFFER_SIZE = 1e4;

class TextLineDataset extends Dataset {
  constructor(e) {
    super(), this.input = e;
  }

  iterator() {
    var _this193 = this;

    return _asyncToGenerator(function* () {
      return (yield _this193.input.iterator()).decodeUTF8().split("\n").map(e => (e.endsWith("\r") && (e = e.slice(0, -1)), e));
    })();
  }

}

var CODE_QUOTE = '"',
    STATE_OUT = Symbol("out"),
    STATE_FIELD = Symbol("field"),
    STATE_QUOTE = Symbol("quote"),
    STATE_QUOTE_AFTER_QUOTE = Symbol("quoteafterquote"),
    STATE_WITHIN_QUOTE_IN_QUOTE = Symbol("quoteinquote");

class CSVDataset extends Dataset {
  constructor(e, t) {
    super(), this.input = e, this.hasHeader = !0, this.fullColumnNames = null, this.columnNamesValidated = !1, this.columnConfigs = null, this.configuredColumnsOnly = !1, this.delimiter = ",", this.delimWhitespace = !1, this.base = new TextLineDataset(e), t || (t = {}), this.hasHeader = !1 !== t.hasHeader, this.fullColumnNames = t.columnNames, this.columnConfigs = t.columnConfigs, this.configuredColumnsOnly = t.configuredColumnsOnly, t.delimWhitespace ? (assert$4(null == t.delimiter, () => "Delimiter should not be provided when delimWhitespace is true."), this.delimWhitespace = !0, this.delimiter = " ") : this.delimiter = t.delimiter ? t.delimiter : ",";
  }

  columnNames() {
    var _this194 = this;

    return _asyncToGenerator(function* () {
      return _this194.columnNamesValidated || (yield _this194.setColumnNames()), _this194.configuredColumnsOnly ? Object.keys(_this194.columnConfigs) : _this194.fullColumnNames;
    })();
  }

  setColumnNames() {
    var _this195 = this;

    return _asyncToGenerator(function* () {
      var e = yield _this195.maybeReadHeaderLine();
      if (!_this195.fullColumnNames && !e) throw new Error("Column names must be provided if there is no header line.");
      _this195.fullColumnNames && e && assert$4(e.length === _this195.fullColumnNames.length, () => "The length of provided columnNames (" + _this195.fullColumnNames.length.toString() + ") does not match the length of the header line read from file (" + e.length.toString() + ")."), _this195.fullColumnNames || (_this195.fullColumnNames = e);

      var t = _this195.fullColumnNames.reduce((e, t) => (e[t] = e[t] + 1 || 1, e), {}),
          n = Object.keys(t).filter(e => t[e] > 1);

      if (assert$4(0 === n.length, () => "Duplicate column names found: " + n.toString()), _this195.columnConfigs) for (var _e800 of Object.keys(_this195.columnConfigs)) {
        if (-1 === _this195.fullColumnNames.indexOf(_e800)) throw new Error('The key "' + _e800 + '" provided in columnConfigs does not match any of the column names (' + _this195.fullColumnNames.toString() + ").");
      }
      _this195.columnNamesValidated = !0;
    })();
  }

  maybeReadHeaderLine() {
    var _this196 = this;

    return _asyncToGenerator(function* () {
      if (_this196.hasHeader) {
        var _e801 = yield _this196.base.iterator(),
            t = yield _e801.next();

        if (t.done) throw new Error("No data was found for CSV parsing.");
        return _this196.parseRow(t.value, !1);
      }

      return null;
    })();
  }

  iterator() {
    var _this197 = this;

    return _asyncToGenerator(function* () {
      _this197.columnNamesValidated || (yield _this197.setColumnNames());
      var e = yield _this197.base.iterator();
      return _this197.hasHeader && (e = e.skip(1)), e.map(e => _this197.makeDataElement(e));
    })();
  }

  makeDataElement(e) {
    var t = this.parseRow(e),
        n = {},
        r = {};

    for (var a = 0; a < this.fullColumnNames.length; a++) {
      var s = this.fullColumnNames[a],
          o = this.columnConfigs ? this.columnConfigs[s] : null;

      if (!this.configuredColumnsOnly || o) {
        var i = t[a];
        var l = null;
        if ("" === i) {
          if (o && void 0 !== o.default) l = o.default;else {
            if (o && (o.required || o.isLabel)) throw new Error("Required column ".concat(s, " is empty in this line: ").concat(e));
            l = void 0;
          }
        } else {
          var _e802 = Number(i);

          if (isNaN(_e802)) l = o && "bool" === o.dtype ? this.getBoolean(i) : i;else if (o && o.dtype) switch (o.dtype) {
            case "float32":
            default:
              l = _e802;
              break;

            case "int32":
              l = Math.floor(_e802);
              break;

            case "bool":
              l = this.getBoolean(i);
          } else l = _e802;
        }
        o && o.isLabel ? r[s] = l : n[s] = l;
      }
    }

    return 0 === Object.keys(r).length ? n : {
      xs: n,
      ys: r
    };
  }

  getBoolean(e) {
    return "1" === e || "true" === e.toLowerCase() ? 1 : 0;
  }

  parseRow(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !0;
    var n = [];
    var r = 0;
    var a = e.length;
    var s = STATE_OUT;

    for (var _t545 = 0; _t545 < a; _t545++) {
      switch (s) {
        case STATE_OUT:
          switch (e.charAt(_t545)) {
            case CODE_QUOTE:
              r = _t545 + 1, s = STATE_QUOTE;
              break;

            case this.delimiter:
              if (r = _t545 + 1, " " === this.delimiter && this.delimWhitespace) break;
              n.push(""), s = STATE_OUT;
              break;

            default:
              s = STATE_FIELD, r = _t545;
          }

          break;

        case STATE_FIELD:
          e.charAt(_t545) === this.delimiter && (n.push(e.substring(r, _t545)), s = STATE_OUT, r = _t545 + 1);
          break;

        case STATE_QUOTE:
          e.charAt(_t545) === CODE_QUOTE && (s = STATE_QUOTE_AFTER_QUOTE);
          break;

        case STATE_QUOTE_AFTER_QUOTE:
          switch (e.charAt(_t545)) {
            case this.delimiter:
              n.push(e.substring(r, _t545 - 1)), s = STATE_OUT, r = _t545 + 1;
              break;

            case CODE_QUOTE:
              s = STATE_QUOTE;
              break;

            default:
              s = STATE_WITHIN_QUOTE_IN_QUOTE;
          }

          break;

        case STATE_WITHIN_QUOTE_IN_QUOTE:
          e.charAt(_t545) === CODE_QUOTE && (s = STATE_QUOTE);
      }
    }

    if (n.push(s === STATE_QUOTE_AFTER_QUOTE ? e.substring(r, a - 1) : e.substring(r)), t && n.length !== this.fullColumnNames.length) throw new Error("Invalid row in csv file. Should have ".concat(this.fullColumnNames.length, " elements in a row, but got ").concat(n));
    return n;
  }

}

class MicrophoneIterator extends LazyIterator {
  constructor(e) {
    super(), this.microphoneConfig = e, this.isClosed = !1, this.fftSize = e.fftSize || 1024;
    var t = Math.log2(this.fftSize);
    if (this.fftSize < 0 || t < 4 || t > 14 || !Number.isInteger(t)) throw new Error("Invalid fftSize: it must be a power of 2 between 2 to 4 and 2 to 14, but got ".concat(this.fftSize));
    if (this.numFrames = e.numFramesPerSpectrogram || 43, this.sampleRateHz = e.sampleRateHz, this.columnTruncateLength = e.columnTruncateLength || this.fftSize, this.audioTrackConstraints = e.audioTrackConstraints, this.smoothingTimeConstant = e.smoothingTimeConstant || 0, this.includeSpectrogram = !1 !== e.includeSpectrogram, this.includeWaveform = !0 === e.includeWaveform, !this.includeSpectrogram && !this.includeWaveform) throw new Error("Both includeSpectrogram and includeWaveform are false. At least one type of data should be returned.");
  }

  summary() {
    return "microphone";
  }

  static create() {
    var _arguments8 = arguments;
    return _asyncToGenerator(function* () {
      var e = _arguments8.length > 0 && _arguments8[0] !== undefined ? _arguments8[0] : {};
      if (env().get("IS_NODE")) throw new Error("microphone API is only supported in browser environment.");
      var t = new MicrophoneIterator(e);
      return yield t.start(), t;
    })();
  }

  start() {
    var _this198 = this;

    return _asyncToGenerator(function* () {
      try {
        _this198.stream = yield navigator.mediaDevices.getUserMedia({
          audio: null == _this198.audioTrackConstraints || _this198.audioTrackConstraints,
          video: !1
        });
      } catch (e) {
        throw new Error("Error thrown while initializing video stream: ".concat(e.message));
      }

      if (!_this198.stream) throw new Error("Could not obtain audio from microphone.");
      var e = window.AudioContext || window.webkitAudioContext;

      if (_this198.audioContext = new e(), _this198.sampleRateHz) {
        if (_this198.audioContext.sampleRate !== _this198.sampleRateHz) throw new Error("Mismatch in sampling rate: Expected: ".concat(_this198.sampleRateHz, "; Actual: ").concat(_this198.audioContext.sampleRate));
      } else _this198.sampleRateHz = _this198.audioContext.sampleRate;

      var t = _this198.audioContext.createMediaStreamSource(_this198.stream);

      _this198.analyser = _this198.audioContext.createAnalyser(), _this198.analyser.fftSize = 2 * _this198.fftSize, _this198.analyser.smoothingTimeConstant = _this198.smoothingTimeConstant, t.connect(_this198.analyser), _this198.freqData = new Float32Array(_this198.fftSize), _this198.timeData = new Float32Array(_this198.fftSize);
    })();
  }

  next() {
    var _this199 = this;

    return _asyncToGenerator(function* () {
      if (_this199.isClosed) return {
        value: null,
        done: !0
      };
      var e, t;
      var n = yield _this199.getAudioData();

      if (_this199.includeSpectrogram) {
        var _t546 = _this199.flattenQueue(n.freqDataQueue);

        e = _this199.getTensorFromAudioDataArray(_t546, [_this199.numFrames, _this199.columnTruncateLength, 1]);
      }

      if (_this199.includeWaveform) {
        var _e803 = _this199.flattenQueue(n.timeDataQueue);

        t = _this199.getTensorFromAudioDataArray(_e803, [_this199.numFrames * _this199.fftSize, 1]);
      }

      return {
        value: {
          spectrogram: e,
          waveform: t
        },
        done: !1
      };
    })();
  }

  capture() {
    var _this200 = this;

    return _asyncToGenerator(function* () {
      return (yield _this200.next()).value;
    })();
  }

  getAudioData() {
    var _this201 = this;

    return _asyncToGenerator(function* () {
      var e = [],
          t = [];
      var n = 0;
      return new Promise(r => {
        var a = setInterval(() => {
          _this201.includeSpectrogram && (_this201.analyser.getFloatFrequencyData(_this201.freqData), -Infinity === _this201.freqData[0] && r({
            freqDataQueue: e,
            timeDataQueue: t
          }), e.push(_this201.freqData.slice(0, _this201.columnTruncateLength))), _this201.includeWaveform && (_this201.analyser.getFloatTimeDomainData(_this201.timeData), t.push(_this201.timeData.slice())), ++n === _this201.numFrames && (clearInterval(a), r({
            freqDataQueue: e,
            timeDataQueue: t
          }));
        }, _this201.fftSize / _this201.sampleRateHz * 1e3);
      });
    })();
  }

  stop() {
    this.isClosed || (this.isClosed = !0, this.analyser.disconnect(), this.audioContext.close(), null != this.stream && this.stream.getTracks().length > 0 && this.stream.getTracks()[0].stop());
  }

  toArray() {
    throw new Error("Can not convert infinite audio stream to array.");
  }

  getSampleRate() {
    return this.sampleRateHz;
  }

  flattenQueue(e) {
    var t = e[0].length,
        n = new Float32Array(e.length * t);
    return e.forEach((e, r) => n.set(e, r * t)), n;
  }

  getTensorFromAudioDataArray(e, t) {
    var n = new Float32Array(sizeFromShape(t));
    return n.set(e, n.length - e.length), tensor(n, t);
  }

}

class WebcamIterator extends LazyIterator {
  constructor(e, t) {
    if (super(), this.webcamVideoElement = e, this.webcamConfig = t, this.isClosed = !0, this.resize = !1, this.needToResize()) if (this.resize = !0, this.cropSize = [this.webcamConfig.resizeHeight, this.webcamConfig.resizeWidth], this.cropBoxInd = tensor1d([0], "int32"), this.webcamConfig.centerCrop) {
      var _e804 = 1 * this.webcamConfig.resizeWidth / this.webcamVideoElement.width,
          _t547 = 1 * this.webcamConfig.resizeHeight / this.webcamVideoElement.height,
          n = (1 - _e804) / 2,
          r = (1 - _t547) / 2;

      this.cropBox = tensor2d([r, n, _t547 + r, n + _e804], [1, 4]);
    } else this.cropBox = tensor2d([0, 0, 1, 1], [1, 4]);
  }

  summary() {
    return "webcam";
  }

  static create(e) {
    var _arguments9 = arguments;
    return _asyncToGenerator(function* () {
      var t = _arguments9.length > 1 && _arguments9[1] !== undefined ? _arguments9[1] : {};
      if (env().get("IS_NODE")) throw new Error("tf.data.webcam is only supported in browser environment.");

      if (!e) {
        if (e = document.createElement("video"), !t.resizeWidth || !t.resizeHeight) throw new Error("Please provide webcam video element, or resizeWidth and resizeHeight to create a hidden video element.");
        e.width = t.resizeWidth, e.height = t.resizeHeight;
      }

      var n = new WebcamIterator(e, t);
      return yield n.start(), n;
    })();
  }

  start() {
    var _this202 = this;

    return _asyncToGenerator(function* () {
      _this202.webcamConfig.facingMode && assert$4("user" === _this202.webcamConfig.facingMode || "environment" === _this202.webcamConfig.facingMode, () => "Invalid webcam facing mode: ".concat(_this202.webcamConfig.facingMode, ". Please provide 'user' or 'environment'"));

      try {
        _this202.stream = yield navigator.mediaDevices.getUserMedia({
          video: {
            deviceId: _this202.webcamConfig.deviceId,
            facingMode: _this202.webcamConfig.facingMode ? _this202.webcamConfig.facingMode : "user",
            width: _this202.webcamVideoElement.width,
            height: _this202.webcamVideoElement.height
          }
        });
      } catch (e) {
        throw e.message = "Error thrown while initializing video stream: ".concat(e.message), e;
      }

      if (!_this202.stream) throw new Error("Could not obtain video from webcam.");

      try {
        _this202.webcamVideoElement.srcObject = _this202.stream;
      } catch (e) {
        console.log(e), _this202.webcamVideoElement.src = window.URL.createObjectURL(_this202.stream);
      }

      return _this202.webcamVideoElement.play(), _this202.isClosed = !1, new Promise(e => {
        _this202.webcamVideoElement.onloadedmetadata = () => {
          e();
        };
      });
    })();
  }

  next() {
    var _this203 = this;

    return _asyncToGenerator(function* () {
      if (_this203.isClosed) return {
        value: null,
        done: !0
      };
      var e;

      try {
        e = fromPixels$1(_this203.webcamVideoElement);
      } catch (e) {
        throw new Error("Error thrown converting video to pixels: ".concat(JSON.stringify(e)));
      }

      if (!_this203.resize) return {
        value: e,
        done: !1
      };

      try {
        return {
          value: _this203.cropAndResizeFrame(e),
          done: !1
        };
      } catch (e) {
        throw new Error("Error thrown cropping the video: ".concat(e.message));
      } finally {
        e.dispose();
      }
    })();
  }

  needToResize() {
    return !(!this.webcamConfig.resizeWidth || !this.webcamConfig.resizeHeight || this.webcamVideoElement.width === this.webcamConfig.resizeWidth && this.webcamVideoElement.height === this.webcamConfig.resizeHeight);
  }

  cropAndResizeFrame(e) {
    return tidy(() => {
      var t = expandDims$3(cast$3(e, "float32"), 0);
      var n;
      return n = image$1.cropAndResize(t, this.cropBox, this.cropBoxInd, this.cropSize, "bilinear"), reshape$3(n, n.shape.slice(1));
    });
  }

  capture() {
    var _this204 = this;

    return _asyncToGenerator(function* () {
      return (yield _this204.next()).value;
    })();
  }

  stop() {
    this.stream.getTracks().forEach(e => e.stop());

    try {
      this.webcamVideoElement.srcObject = null;
    } catch (e) {
      console.log(e), this.webcamVideoElement.src = null;
    }

    this.isClosed = !0;
  }

  toArray() {
    throw new Error("Can not convert infinite video stream to array.");
  }

}

class DataSource {}

class StringIterator extends LazyIterator {
  split(e) {
    return new SplitIterator(this, e);
  }

}

class SplitIterator extends StringIterator {
  constructor(e, t) {
    super(), this.upstream = e, this.impl = new SplitIteratorImpl(e, t);
  }

  summary() {
    return this.impl.summary();
  }

  next() {
    var _this205 = this;

    return _asyncToGenerator(function* () {
      return _this205.impl.next();
    })();
  }

}

class SplitIteratorImpl extends OneToManyIterator {
  constructor(e, t) {
    super(), this.upstream = e, this.separator = t, this.carryover = "";
  }

  summary() {
    return "".concat(this.upstream.summary(), " -> Split('").concat(this.separator, "')");
  }

  pump() {
    var _this206 = this;

    return _asyncToGenerator(function* () {
      var e = yield _this206.upstream.next();
      if (e.done) return "" !== _this206.carryover && (_this206.outputQueue.push(_this206.carryover), _this206.carryover = "", !0);
      var t = e.value.split(_this206.separator);
      t[0] = _this206.carryover + t[0];

      for (var _e805 of t.slice(0, -1)) {
        _this206.outputQueue.push(_e805);
      }

      return _this206.carryover = t[t.length - 1], !0;
    })();
  }

}

class ByteChunkIterator extends LazyIterator {
  decodeUTF8() {
    return new Utf8Iterator(this);
  }

}

class Utf8Iterator extends StringIterator {
  constructor(e) {
    super(), this.upstream = e, this.impl = new Utf8IteratorImpl(e);
  }

  summary() {
    return this.impl.summary();
  }

  next() {
    var _this207 = this;

    return _asyncToGenerator(function* () {
      return _this207.impl.next();
    })();
  }

}

class Utf8IteratorImpl extends OneToManyIterator {
  constructor(e) {
    if (super(), this.upstream = e, env().get("IS_BROWSER")) this.decoder = new TextDecoder("utf-8");else {
      var {
        StringDecoder: _e806
      } = __webpack_require__(62289);

      this.decoder = new _e806("utf8");
    }
  }

  summary() {
    return "".concat(this.upstream.summary(), " -> Utf8");
  }

  pump() {
    var _this208 = this;

    return _asyncToGenerator(function* () {
      var e = yield _this208.upstream.next();
      var t, n;
      return !e.done && (t = e.value, n = env().get("IS_BROWSER") ? _this208.decoder.decode(t, {
        stream: !0
      }) : _this208.decoder.write(Buffer.from(t.buffer)), _this208.outputQueue.push(n), !0);
    })();
  }

}

class FileChunkIterator extends ByteChunkIterator {
  constructor(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};
    super(), this.file = e, this.options = t, assert$4(e instanceof Uint8Array || !!env().get("IS_BROWSER") && (e instanceof File || e instanceof Blob), () => "FileChunkIterator only supports File, Blob and Uint8Array right now."), this.offset = t.offset || 0, this.chunkSize = t.chunkSize || 1048576;
  }

  summary() {
    return "FileChunks ".concat(this.file);
  }

  next() {
    var _this209 = this;

    return _asyncToGenerator(function* () {
      if (_this209.offset >= (_this209.file instanceof Uint8Array ? _this209.file.byteLength : _this209.file.size)) return {
        value: null,
        done: !0
      };
      var e = new Promise((e, t) => {
        var n = _this209.offset + _this209.chunkSize;
        if (_this209.file instanceof Uint8Array) e(new Uint8Array(_this209.file.slice(_this209.offset, n)));else {
          var r = new FileReader();
          r.onload = n => {
            var a = r.result;
            if (a instanceof ArrayBuffer && (a = new Uint8Array(a)), !(a instanceof Uint8Array)) return t(new TypeError("FileReader returned unknown type."));
            e(a);
          }, r.onabort = e => t(new Error("Aborted")), r.onerror = e => t(new Error(e.type));

          var a = _this209.file.slice(_this209.offset, n);

          r.readAsArrayBuffer(a);
        }
        _this209.offset = n;
      });
      return {
        value: yield e,
        done: !1
      };
    })();
  }

}

function urlChunkIterator(_x135) {
  return _urlChunkIterator.apply(this, arguments);
}

function _urlChunkIterator() {
  _urlChunkIterator = _asyncToGenerator(function* (e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};
    var n, r;
    "string" == typeof e ? n = e : (n = e.url, r = getRequestInitFromRequest(e));
    var a = yield fetch$1(n, r);

    if (a.ok) {
      var _e1174 = new Uint8Array(yield a.arrayBuffer());

      return new FileChunkIterator(_e1174, t);
    }

    throw new Error(a.statusText);
  });
  return _urlChunkIterator.apply(this, arguments);
}

var getRequestInitFromRequest = e => ({
  method: e.method,
  headers: e.headers,
  body: e.body,
  mode: e.mode,
  credentials: e.credentials,
  cache: e.cache,
  redirect: e.redirect,
  referrer: e.referrer,
  integrity: e.integrity
});

function isLocalPath(e) {
  return "string" == typeof e && "file://" === e.substr(0, 7);
}

class FileDataSource extends DataSource {
  constructor(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};
    super(), this.input = e, this.options = t;
  }

  iterator() {
    var _this210 = this;

    return _asyncToGenerator(function* () {
      if (isLocalPath(_this210.input) && env().get("IS_NODE")) {
        var _e807 = __webpack_require__(54809);

        _this210.input = _e807.readFileSync(_this210.input.substr(7));
      }

      return new FileChunkIterator(_this210.input, _this210.options);
    })();
  }

}

class URLDataSource extends DataSource {
  constructor(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};
    super(), this.url = e, this.fileOptions = t;
  }

  iterator() {
    var _this211 = this;

    return _asyncToGenerator(function* () {
      return isLocalPath(_this211.url) ? new FileDataSource(_this211.url, _this211.fileOptions).iterator() : urlChunkIterator(_this211.url, _this211.fileOptions);
    })();
  }

}

function csv(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};
  return new CSVDataset(new URLDataSource(e), t);
}

function func(e) {
  var t = iteratorFromFunction(e);
  return datasetFromIteratorFn( /*#__PURE__*/_asyncToGenerator(function* () {
    return t;
  }));
}

function generator(e) {
  return datasetFromIteratorFn( /*#__PURE__*/_asyncToGenerator(function* () {
    var t = yield e();
    return iteratorFromFunction(() => t.next());
  }));
}

function webcam(_x136, _x137) {
  return _webcam.apply(this, arguments);
}

function _webcam() {
  _webcam = _asyncToGenerator(function* (e, t) {
    return WebcamIterator.create(e, t);
  });
  return _webcam.apply(this, arguments);
}

function microphone(_x138) {
  return _microphone.apply(this, arguments);
}

function _microphone() {
  _microphone = _asyncToGenerator(function* (e) {
    return MicrophoneIterator.create(e);
  });
  return _microphone.apply(this, arguments);
}

var version$4 = "3.8.0";
var index = {
  __proto__: null,
  array,
  Dataset,
  zip,
  CSVDataset,
  TextLineDataset,
  csv,
  func,
  generator,
  microphone,
  webcam,
  FileDataSource,
  URLDataSource,
  version_data: version$4
};

function assertNotComplex$1(e, t) {
  Array.isArray(e) || (e = [e]), e.forEach(e => {
    null != e && assert$4("complex64" !== e.dtype, () => "".concat(t, " does not support complex64 tensors in the CPU backend."));
  });
}

var whereImpl$1 = whereImpl$2;

class MathBackendCPU extends KernelBackend {
  constructor() {
    super(), this.blockSize = 48, this.firstUse = !0, this.data = new DataStorage(this, engine());
  }

  nextDataId() {
    return MathBackendCPU.nextDataId++;
  }

  write(e, t, n) {
    this.firstUse && (this.firstUse = !1, env().get("IS_NODE") && warn("\n============================\nHi there 👋. Looks like you are running TensorFlow.js in Node.js. To speed things up dramatically, install our node backend, which binds to TensorFlow C++, by running npm i @tensorflow/tfjs-node, or npm i @tensorflow/tfjs-node-gpu if you have CUDA. Then call require('@tensorflow/tfjs-node'); (-gpu suffix for CUDA) at the start of your program. Visit https://github.com/tensorflow/tfjs-node for more details.\n============================"));
    var r = {
      id: this.nextDataId()
    };
    return this.data.set(r, {
      values: e,
      dtype: n,
      refCount: 1
    }), r;
  }

  makeTensorInfo(e, t, n) {
    var r;

    if ("string" === t && null != n && n.length > 0 && isString(n[0])) {
      var a = n.map(e => encodeString(e));
      r = this.write(a, e, t);
    } else r = this.write(n, e, t);

    return {
      dataId: r,
      shape: e,
      dtype: t
    };
  }

  refCount(e) {
    return this.data.has(e) ? this.data.get(e).refCount : 0;
  }

  incRef(e) {
    this.data.get(e).refCount++;
  }

  decRef(e) {
    this.data.has(e) && this.data.get(e).refCount--;
  }

  move(e, t, n, r, a) {
    this.data.set(e, {
      values: t,
      dtype: r,
      refCount: a
    });
  }

  numDataIds() {
    return this.data.numDataIds();
  }

  read(e) {
    var _this212 = this;

    return _asyncToGenerator(function* () {
      return _this212.readSync(e);
    })();
  }

  readSync(e) {
    var {
      dtype: t,
      complexTensorInfos: n
    } = this.data.get(e);
    return "complex64" === t ? mergeRealAndImagArrays(this.readSync(n.real.dataId), this.readSync(n.imag.dataId)) : this.data.get(e).values;
  }

  bufferSync(e) {
    var t = this.readSync(e.dataId);
    var n = t;
    if ("string" === e.dtype) try {
      n = t.map(e => decodeString(e));
    } catch (e) {
      throw new Error("Failed to decode encoded string bytes into utf-8");
    }
    return buffer(e.shape, e.dtype, n);
  }

  makeOutput(e, t, n) {
    var r = this.write(e, t, n);
    return engine().makeTensorFromDataId(r, t, n, this);
  }

  disposeData(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;

    if (this.data.has(e)) {
      if (this.data.get(e).refCount--, !t && this.data.get(e).refCount > 0) return !1;
      var {
        complexTensorInfos: n
      } = this.data.get(e);
      null != n && (this.disposeData(n.real.dataId, !0), this.disposeData(n.imag.dataId, !0)), this.data.delete(e);
    }

    return !0;
  }

  disposeIntermediateTensorInfo(e) {
    this.disposeData(e.dataId);
  }

  time(e) {
    return _asyncToGenerator(function* () {
      var t = now();
      return e(), {
        kernelMs: now() - t
      };
    })();
  }

  memory() {
    return {
      unreliable: !0,
      reasons: ["The reported memory is an upper bound. Due to automatic garbage collection, the true allocated memory may be less."]
    };
  }

  where(e) {
    assertNotComplex$1([e], "where");
    var t = this.readSync(e.dataId);
    return whereImpl$1(e.shape, t);
  }

  dispose() {}

  floatPrecision() {
    return 32;
  }

  epsilon() {
    return super.epsilon();
  }

}

function simpleAbsImpl(e) {
  var t = new Float32Array(e.length);

  for (var n = 0; n < e.length; ++n) {
    t[n] = Math.abs(e[n]);
  }

  return t;
}

MathBackendCPU.nextDataId = 0;

var abs$1 = e => {
  var {
    x: t
  } = e.inputs,
      n = e.backend;
  assertNotComplex$1(t, "abs");
  var r = new Float32Array(sizeFromShape(t.shape));
  return r = simpleAbsImpl(n.data.get(t.dataId).values), n.makeOutput(r, t.shape, "float32");
},
    absConfig$1 = {
  kernelName: Abs,
  backendName: "cpu",
  kernelFunc: abs$1
};

function createSimpleBinaryKernelImpl(e) {
  return (t, n, r, a, s) => {
    var o = assertAndGetBroadcastShape(t, n),
        i = o.length,
        l = computeStrides(o),
        u = getTypedArrayFromDType(s, sizeFromShape(o)),
        c = t.length,
        p = n.length,
        d = computeStrides(t),
        h = computeStrides(n),
        m = getBroadcastDims$1(t, o),
        f = getBroadcastDims$1(n, o);
    if (m.length + f.length === 0) for (var _t548 = 0; _t548 < u.length; ++_t548) {
      u[_t548] = e(r[_t548 % r.length], a[_t548 % a.length]);
    } else {
      var _loop51 = function _loop51(_t549) {
        var n = indexToLoc(_t549, i, l),
            s = n.slice(-c);
        m.forEach(e => s[e] = 0);
        var o = locToIndex(s, c, d),
            g = n.slice(-p);
        f.forEach(e => g[e] = 0);
        var $ = locToIndex(g, p, h);
        u[_t549] = e(r[o], a[$]);
      };

      for (var _t549 = 0; _t549 < u.length; ++_t549) {
        _loop51(_t549);
      }
    }
    return [u, o];
  };
}

function complex$1(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    real: r,
    imag: a
  } = t,
      s = n.data.get(r.dataId).values,
      o = n.data.get(a.dataId).values,
      i = n.makeTensorInfo(r.shape, "complex64");
  return n.data.get(i.dataId).complexTensorInfos = {
    real: n.makeTensorInfo(r.shape, "float32", s),
    imag: n.makeTensorInfo(a.shape, "float32", o)
  }, i;
}

var complexConfig$1 = {
  kernelName: Complex,
  backendName: "cpu",
  kernelFunc: complex$1
};

function zeros(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : "float32";
  if ("complex64" === n) return complex$1({
    inputs: {
      real: zeros(e, t, "float32"),
      imag: zeros(e, t, "float32")
    },
    backend: e
  });
  var r = makeZerosTypedArray(sizeFromShape(t), n);
  return e.makeTensorInfo(t, n, r);
}

function identity$1(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    x: r
  } = t;
  return n.incRef(r.dataId), {
    dataId: r.dataId,
    shape: r.shape,
    dtype: r.dtype
  };
}

var identityConfig$1 = {
  kernelName: Identity$1,
  backendName: "cpu",
  kernelFunc: identity$1
};

function real$1(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    input: r
  } = t,
      a = n.data.get(r.dataId).complexTensorInfos.real,
      s = n.data.get(a.dataId).values;
  return n.makeTensorInfo(a.shape, a.dtype, s);
}

var realConfig$1 = {
  kernelName: Real,
  backendName: "cpu",
  kernelFunc: real$1
};

function cast$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    dtype: s
  } = r;

  if ("complex64" === s) {
    if ("complex64" === a.dtype) return identity$1({
      inputs: {
        x: a
      },
      backend: n
    });

    var _e808 = zeros(n, a.shape, a.dtype),
        _t550 = cast$1({
      inputs: {
        x: a
      },
      backend: n,
      attrs: {
        dtype: "float32"
      }
    }),
        _r323 = complex$1({
      inputs: {
        real: _t550,
        imag: _e808
      },
      backend: n
    });

    return n.disposeIntermediateTensorInfo(_e808), n.disposeIntermediateTensorInfo(_t550), _r323;
  }

  if ("complex64" === a.dtype) {
    var _e809 = real$1({
      inputs: {
        input: a
      },
      backend: n
    }),
        _t551 = cast$1({
      inputs: {
        x: _e809
      },
      backend: n,
      attrs: {
        dtype: s
      }
    });

    return n.disposeIntermediateTensorInfo(_e809), _t551;
  }

  if (!hasEncodingLoss(a.dtype, s)) {
    var _e810 = identity$1({
      inputs: {
        x: a
      },
      backend: n
    });

    return {
      dataId: _e810.dataId,
      shape: _e810.shape,
      dtype: s
    };
  }

  if ("int32" === s) {
    var _e811 = n.data.get(a.dataId).values,
        _t552 = Int32Array.from(_e811);

    return n.makeTensorInfo(a.shape, "int32", _t552);
  }

  if ("bool" === s) {
    var _e812 = n.data.get(a.dataId).values,
        _t553 = toTypedArray([0], a.dtype),
        [_r324, _s161] = createSimpleBinaryKernelImpl((e, t) => e !== t ? 1 : 0)(a.shape, [], _e812, _t553, "bool");

    return n.makeTensorInfo(_s161, "bool", _r324);
  }

  throw new Error("Error in Cast: failed to cast ".concat(a.dtype, " to ").concat(s));
}

var castConfig$1 = {
  kernelName: Cast,
  backendName: "cpu",
  kernelFunc: cast$1
};

function binaryKernelFunc$1(e, t, n, r) {
  return null == n ? _ref50 => {
    var {
      inputs: n,
      backend: a
    } = _ref50;
    var {
      a: s,
      b: o
    } = n,
        i = a;
    assertNotComplex$1([s, o], e);
    var l = i.data.get(s.dataId).values,
        u = i.data.get(o.dataId).values,
        c = "string" === s.dtype ? fromUint8ToStringArray(l) : l,
        p = "string" === s.dtype ? fromUint8ToStringArray(u) : u,
        d = r || s.dtype,
        [h, m] = t(s.shape, o.shape, c, p, d);
    return i.makeTensorInfo(m, d, h);
  } : _ref51 => {
    var {
      inputs: e,
      backend: a
    } = _ref51;
    var {
      a: s,
      b: o
    } = e,
        i = a;

    if ("complex64" === s.dtype || "complex64" === o.dtype) {
      var _e813 = cast$1({
        inputs: {
          x: s
        },
        backend: i,
        attrs: {
          dtype: "complex64"
        }
      }),
          _t554 = i.data.get(_e813.dataId),
          _r325 = _t554.complexTensorInfos.imag,
          _a234 = i.data.get(_t554.complexTensorInfos.real.dataId).values,
          l = i.data.get(_r325.dataId).values,
          u = cast$1({
        inputs: {
          x: o
        },
        backend: i,
        attrs: {
          dtype: "complex64"
        }
      }),
          c = i.data.get(u.dataId),
          _p26 = c.complexTensorInfos.imag,
          d = i.data.get(c.complexTensorInfos.real.dataId).values,
          h = i.data.get(_p26.dataId).values,
          [m, f, g] = n(s.shape, o.shape, _a234, l, d, h),
          $ = i.makeTensorInfo(g, "float32", m),
          y = i.makeTensorInfo(g, "float32", f),
          b = complex$1({
        inputs: {
          real: $,
          imag: y
        },
        backend: i
      });

      return i.disposeIntermediateTensorInfo(_e813), i.disposeIntermediateTensorInfo(u), i.disposeIntermediateTensorInfo($), i.disposeIntermediateTensorInfo(y), b;
    }

    {
      var _e814 = i.data.get(s.dataId).values,
          _n305 = i.data.get(o.dataId).values,
          _a235 = r || s.dtype,
          [_l42, _u36] = t(s.shape, o.shape, _e814, _n305, _a235);

      return i.makeTensorInfo(_u36, _a235, _l42);
    }
  };
}

function createComplexBinaryKernelImpl(e) {
  return (t, n, r, a, s, o) => {
    var i = assertAndGetBroadcastShape(t, n),
        l = sizeFromShape(i),
        u = i.length,
        c = computeStrides(i),
        p = getTypedArrayFromDType("float32", l),
        d = getTypedArrayFromDType("float32", l),
        h = getBroadcastDims$1(t, i),
        m = getBroadcastDims$1(n, i),
        f = mergeRealAndImagArrays(r, a),
        g = mergeRealAndImagArrays(s, o),
        $ = t.length,
        y = computeStrides(t),
        b = n.length,
        x = computeStrides(n);
    if (h.length + m.length === 0) for (var _t555 = 0; _t555 < p.length; _t555++) {
      var _n306 = _t555 % f.length,
          _r326 = _t555 % g.length,
          _a236 = e(f[2 * _n306], f[2 * _n306 + 1], g[2 * _r326], g[2 * _r326 + 1]);

      p[_t555] = _a236.real, d[_t555] = _a236.imag;
    } else {
      var _loop52 = function _loop52(_t556) {
        var n = indexToLoc(_t556, u, c),
            r = n.slice(-$);
        h.forEach(e => r[e] = 0);
        var a = locToIndex(r, $, y),
            s = n.slice(-b);
        m.forEach(e => s[e] = 0);
        var o = locToIndex(s, b, x),
            i = e(f[2 * a], f[2 * a + 1], g[2 * o], g[2 * o + 1]);
        p[_t556] = i.real, d[_t556] = i.imag;
      };

      for (var _t556 = 0; _t556 < p.length; _t556++) {
        _loop52(_t556);
      }
    }
    return [p, d, i];
  };
}

var addImpl = createSimpleBinaryKernelImpl((e, t) => e + t),
    addComplexImpl = createComplexBinaryKernelImpl((e, t, n, r) => ({
  real: e + n,
  imag: t + r
})),
    add = binaryKernelFunc$1(Add$1, addImpl, addComplexImpl),
    addConfig$1 = {
  kernelName: Add$1,
  backendName: "cpu",
  kernelFunc: add
};

function bincountImpl(e, t, n, r, a) {
  var s = sizeFromShape(r),
      o = makeZerosTypedArray(a, n);

  for (var _n307 = 0; _n307 < e.length; _n307++) {
    var _r327 = e[_n307];
    if (_r327 < 0) throw new Error("Input x must be non-negative!");
    _r327 >= a || (o[_r327] += s > 0 ? t[_n307] : 1);
  }

  return o;
}

function bincountReduceImpl(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
  var a = e.shape[0],
      s = e.shape[1],
      o = buffer([a, n], t.dtype);

  for (var i = 0; i < a; i++) {
    for (var _a237 = 0; _a237 < s; _a237++) {
      var _s162 = e.get(i, _a237);

      if (_s162 < 0) throw new Error("Input x must be non-negative!");
      _s162 >= n || o.set(r ? 1 : t.size > 0 ? o.get(i, _s162) + t.get(i, _a237) : o.get(i, _s162) + 1, i, _s162);
    }
  }

  return o;
}

function createSimpleUnaryImpl(e) {
  return (t, n, r) => {
    var a = getTypedArrayFromDType(n, t.length);

    for (var _n308 = 0; _n308 < t.length; ++_n308) {
      a[_n308] = e(t[_n308], r);
    }

    return a;
  };
}

function unaryKernelFunc$1(e, t, n) {
  return _ref52 => {
    var {
      inputs: r,
      attrs: a,
      backend: s
    } = _ref52;
    var {
      x: o
    } = r;
    if (assertNotComplex$1(o, e), "string" === o.dtype || "string" === n) throw new Error("unaryKernelFunc does not support string input/output");
    var i = s,
        l = i.data.get(o.dataId).values,
        u = sizeFromShape(o.shape),
        c = n || o.dtype,
        p = getArrayFromDType(c, u);

    for (var _e815 = 0; _e815 < u; ++_e815) {
      p[_e815] = t(l[_e815], a);
    }

    return i.makeTensorInfo(o.shape, c, p);
  };
}

function unaryKernelFuncFromImpl(e, t, n) {
  return _ref53 => {
    var {
      inputs: r,
      attrs: a,
      backend: s
    } = _ref53;
    var {
      x: o
    } = r;
    if (assertNotComplex$1(o, e), "string" === o.dtype || "string" === n) throw new Error("unaryKernelFunc does not support string input/output");
    var i = s,
        l = i.data.get(o.dataId).values,
        u = n || o.dtype,
        c = t(l, u, a);
    return i.makeTensorInfo(o.shape, u, c);
  };
}

var ceilImpl = createSimpleUnaryImpl(e => Math.ceil(e)),
    ceil$1 = unaryKernelFuncFromImpl(Ceil, ceilImpl),
    ceilConfig$1 = {
  kernelName: Ceil,
  backendName: "cpu",
  kernelFunc: ceil$1
};

function concatImpl$1(e, t, n, r) {
  var a = getArrayFromDType(n, sizeFromShape(t));

  if (r && "string" !== n) {
    var _t557 = 0;
    e.forEach(e => {
      var n = sizeFromShape(e.shape);
      a.set(e.vals, _t557), _t557 += n;
    });
  } else {
    var _r328 = 0;
    e.forEach(e => {
      var s = "string" === n ? fromUint8ToStringArray(e.vals) : e.vals;
      var o = 0;

      for (var _n309 = 0; _n309 < e.shape[0]; ++_n309) {
        var i = _n309 * t[1] + _r328;

        for (var _t558 = 0; _t558 < e.shape[1]; ++_t558) {
          a[i + _t558] = s[o++];
        }
      }

      _r328 += e.shape[1];
    });
  }

  return a;
}

var equalImpl = createSimpleBinaryKernelImpl((e, t) => e === t ? 1 : 0),
    equal$1 = binaryKernelFunc$1(Equal, equalImpl, null, "bool"),
    equalConfig$1 = {
  kernelName: Equal,
  backendName: "cpu",
  kernelFunc: equal$1
},
    expImpl = createSimpleUnaryImpl(e => Math.exp(e)),
    exp$1 = unaryKernelFuncFromImpl(Exp, expImpl),
    expConfig$1 = {
  kernelName: Exp,
  backendName: "cpu",
  kernelFunc: exp$1
},
    expm1Impl = createSimpleUnaryImpl(e => Math.expm1(e)),
    expm1$1 = unaryKernelFuncFromImpl(Expm1, expm1Impl),
    expm1Config$1 = {
  kernelName: Expm1,
  backendName: "cpu",
  kernelFunc: expm1$1
},
    floorImpl = createSimpleUnaryImpl(e => Math.floor(e)),
    floor$1 = unaryKernelFuncFromImpl(Floor, floorImpl),
    floorConfig$1 = {
  kernelName: Floor,
  backendName: "cpu",
  kernelFunc: floor$1
};

function gatherNdImpl(e, t, n, r, a, s, o, i, l) {
  var u = buffer([r, s], n);

  for (var _n310 = 0; _n310 < r; _n310++) {
    var _r329 = [];
    var c = 0;

    for (var _t559 = 0; _t559 < a; _t559++) {
      var _s163 = e[_n310 * a + _t559];
      c += _s163 * o[_t559], _r329.push(_s163);
    }

    if (c < 0 || c >= l / s) throw new Error("Invalid indices: ".concat(_r329, " does not index into ").concat(i));

    for (var _e816 = 0; _e816 < s; _e816++) {
      u.values[_n310 * s + _e816] = t.get(...t.indexToLoc(c * s + _e816));
    }
  }

  return u;
}

function gatherV2Impl(e, t, n) {
  var r = buffer(n, e.dtype);

  for (var _n311 = 0; _n311 < r.size; ++_n311) {
    var a = r.indexToLoc(_n311).slice(),
        s = t.locToIndex([a[0], a[2]]);
    a[2] = t.values[s];
    var o = e.locToIndex(a);
    r.values[_n311] = e.values[o];
  }

  return r;
}

var greaterImpl = createSimpleBinaryKernelImpl((e, t) => e > t ? 1 : 0),
    greater$1 = binaryKernelFunc$1(Greater, greaterImpl, null, "bool"),
    greaterConfig$1 = {
  kernelName: Greater,
  backendName: "cpu",
  kernelFunc: greater$1
},
    greaterEqualImpl = createSimpleBinaryKernelImpl((e, t) => e >= t ? 1 : 0),
    greaterEqual$1 = binaryKernelFunc$1(GreaterEqual, greaterEqualImpl, null, "bool"),
    greaterEqualConfig$1 = {
  kernelName: GreaterEqual,
  backendName: "cpu",
  kernelFunc: greaterEqual$1
},
    lessImpl = createSimpleBinaryKernelImpl((e, t) => e < t ? 1 : 0),
    less$1 = binaryKernelFunc$1(Less, lessImpl, null, "bool"),
    lessConfig$1 = {
  kernelName: Less,
  backendName: "cpu",
  kernelFunc: less$1
},
    lessEqualImpl = createSimpleBinaryKernelImpl((e, t) => e <= t ? 1 : 0),
    lessEqual$1 = binaryKernelFunc$1(LessEqual, lessEqualImpl, null, "bool"),
    lessEqualConfig$1 = {
  kernelName: LessEqual,
  backendName: "cpu",
  kernelFunc: lessEqual$1
};

function linSpaceImpl(e, t, n) {
  var r = (t - e) / (n - 1),
      a = makeZerosTypedArray(n, "float32");
  a[0] = e;

  for (var _e817 = 1; _e817 < a.length; _e817++) {
    a[_e817] = a[_e817 - 1] + r;
  }

  return a;
}

var logImpl = createSimpleUnaryImpl(e => Math.log(e)),
    log$1 = unaryKernelFuncFromImpl(Log, logImpl),
    logConfig$1 = {
  kernelName: Log,
  backendName: "cpu",
  kernelFunc: log$1
};

function maxImpl$1(e, t, n, r) {
  var a = getTypedArrayFromDType(r, sizeFromShape(n));

  for (var _n312 = 0; _n312 < a.length; ++_n312) {
    var _r330 = _n312 * t;

    var s = e[_r330];

    for (var _n313 = 0; _n313 < t; ++_n313) {
      var _t560 = e[_r330 + _n313];
      (Number.isNaN(_t560) || _t560 > s) && (s = _t560);
    }

    a[_n312] = s;
  }

  return a;
}

var maximumImpl = createSimpleBinaryKernelImpl((e, t) => Math.max(e, t)),
    maximum$1 = binaryKernelFunc$1(Maximum$1, maximumImpl),
    maximumConfig$1 = {
  kernelName: Maximum$1,
  backendName: "cpu",
  kernelFunc: maximum$1
},
    minimumImpl = createSimpleBinaryKernelImpl((e, t) => Math.min(e, t)),
    minimum$1 = binaryKernelFunc$1(Minimum$1, minimumImpl),
    minimumConfig$1 = {
  kernelName: Minimum$1,
  backendName: "cpu",
  kernelFunc: minimum$1
},
    multiplyImpl = createSimpleBinaryKernelImpl((e, t) => e * t),
    multiplyComplexImpl = createComplexBinaryKernelImpl((e, t, n, r) => ({
  real: e * n - t * r,
  imag: e * r + t * n
})),
    multiply$1 = binaryKernelFunc$1(Multiply$1, multiplyImpl, multiplyComplexImpl),
    multiplyConfig$1 = {
  kernelName: Multiply$1,
  backendName: "cpu",
  kernelFunc: multiply$1
};

function negImpl(e, t, n) {
  var r = createScalarValue(-1, n);
  return multiplyImpl([], t, r, e, n);
}

function neg$1(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    x: r
  } = t;
  assertNotComplex$1(r, "neg");
  var a = n.data.get(r.dataId).values,
      [s, o] = negImpl(a, r.shape, r.dtype);
  return n.makeTensorInfo(o, r.dtype, s);
}

var negConfig$1 = {
  kernelName: Neg,
  backendName: "cpu",
  kernelFunc: neg$1
},
    notEqualImpl = createSimpleBinaryKernelImpl((e, t) => e !== t ? 1 : 0),
    notEqual$1 = binaryKernelFunc$1(NotEqual, notEqualImpl, null, "bool"),
    notEqualConfig$1 = {
  kernelName: NotEqual,
  backendName: "cpu",
  kernelFunc: notEqual$1
};

function transposeImpl$1(e, t, n, r, a) {
  var s = t.length,
      o = sizeFromShape(t),
      i = computeStrides(t),
      l = computeStrides(a),
      u = getTypedArrayFromDType(n, sizeFromShape(a));

  for (var _t561 = 0; _t561 < o; ++_t561) {
    var _n314 = indexToLoc(_t561, s, i),
        _a238 = new Array(_n314.length);

    for (var _e818 = 0; _e818 < _a238.length; _e818++) {
      _a238[_e818] = _n314[r[_e818]];
    }

    u[locToIndex(_a238, s, l)] = e[_t561];
  }

  return u;
}

function transpose$1(e) {
  var {
    inputs: t,
    attrs: n,
    backend: r
  } = e,
      {
    x: a
  } = t,
      {
    perm: s
  } = n;
  assertNotComplex$1(a, "transpose");
  var o = new Array(a.shape.length);

  for (var _e819 = 0; _e819 < o.length; _e819++) {
    o[_e819] = a.shape[s[_e819]];
  }

  var i = transposeImpl$1(r.data.get(a.dataId).values, a.shape, a.dtype, s, o);
  return {
    dataId: r.write(i, o, a.dtype),
    shape: o,
    dtype: a.dtype
  };
}

var transposeConfig$1 = {
  kernelName: Transpose,
  backendName: "cpu",
  kernelFunc: transpose$1
};

function prodImpl(e, t, n, r) {
  var [a, s] = computeOutAndReduceShapes(e, r),
      o = upcastType(t, "int32"),
      i = makeZerosTypedArray(sizeFromShape(a), o),
      l = sizeFromShape(s);

  for (var _e820 = 0; _e820 < i.length; ++_e820) {
    var _t562 = _e820 * l;

    var _r331 = 1;

    for (var _e821 = 0; _e821 < l; ++_e821) {
      _r331 *= n[_t562 + _e821];
    }

    i[_e820] = _r331;
  }

  return {
    outVals: i,
    outShape: a,
    outDtype: o
  };
}

function prod$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    axis: s,
    keepDims: o
  } = r;
  assertNotComplex$1(a, "prod");
  var i = a.shape.length,
      l = parseAxisParam(s, a.shape),
      u = getAxesPermutation(l, i);
  var c = l,
      p = a;
  var d = [];
  null != u && (p = transpose$1({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      perm: u
    }
  }), d.push(p), c = getInnerMostAxes(c.length, i));
  var h = n.data.get(p.dataId).values,
      {
    outVals: m,
    outShape: f,
    outDtype: g
  } = prodImpl(p.shape, p.dtype, h, c);
  var $ = f;
  return o && ($ = expandShapeToKeepDim(f, l)), d.forEach(e => n.disposeIntermediateTensorInfo(e)), n.makeTensorInfo($, g, m);
}

var prodConfig$1 = {
  kernelName: Prod,
  backendName: "cpu",
  kernelFunc: prod$1
};

function rangeImpl(e, t, n, r) {
  if (e === t || e < t && n < 0 || t < e && n > 1) return makeZerosTypedArray(0, r);
  var a = makeZerosTypedArray(Math.abs(Math.ceil((t - e) / n)), r);
  t < e && 1 === n && (n = -1), a[0] = e;

  for (var _e822 = 1; _e822 < a.length; _e822++) {
    a[_e822] = a[_e822 - 1] + n;
  }

  return a;
}

var rsqrtImpl = createSimpleUnaryImpl(e => 1 / Math.sqrt(e)),
    rsqrt$1 = unaryKernelFuncFromImpl(Rsqrt, rsqrtImpl),
    rsqrtConfig$1 = {
  kernelName: Rsqrt,
  backendName: "cpu",
  kernelFunc: rsqrt$1
};

function sliceImpl(e, t, n, r, a) {
  var s = isSliceContinous(r, t, n),
      o = sizeFromShape(n),
      i = computeStrides(r);

  if (s) {
    var _n315 = computeFlatOffset(t, i);

    return "string" === a ? e.slice(_n315, _n315 + o) : e.subarray(_n315, _n315 + o);
  }

  var l = buffer(r, a, "string" === a ? fromUint8ToStringArray(e) : e),
      u = buffer(n, a);

  for (var _e823 = 0; _e823 < u.size; ++_e823) {
    var _n316 = u.indexToLoc(_e823),
        _r332 = _n316.map((e, n) => e + t[n]);

    u.set(l.get(..._r332), ..._n316);
  }

  return "string" === a ? fromStringArrayToUint8(u.values) : u.values;
}

function slice$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    begin: s,
    size: o
  } = r;
  assertNotComplex$1(a, "slice");
  var [i, l] = parseSliceParams(a, s, o);
  assertParamsValid(a, i, l);
  var u = sliceImpl(n.data.get(a.dataId).values, i, l, a.shape, a.dtype);
  return n.makeTensorInfo(l, a.dtype, u);
}

var sliceConfig$1 = {
  kernelName: Slice,
  backendName: "cpu",
  kernelFunc: slice$1
};

function sparseFillEmptyRowsImpl(e, t, n, r, a, s, o) {
  var i = t[0],
      l = s[0],
      u = new Array(l),
      c = new Array(i),
      p = t[1];

  if (0 === l) {
    if (0 !== i) throw new Error("Received SparseTensor with denseShape[0] = 0 but\n         indices.shape[0] = ".concat(i));
    return [getArrayFromDType(n, 0), [0, p], getArrayFromDType(a, 0), u, c];
  }

  var d = !0,
      h = 0;
  var m = new Array(l).fill(0);

  for (var _t563 = 0; _t563 < i; ++_t563) {
    var _n317 = e[_t563 * p];
    if (_n317 < 0) throw new Error("indices(".concat(_t563, ", 0) is invalid: ").concat(_n317, " < 0"));
    if (_n317 >= l) throw new Error("indices(".concat(_t563, ", 0) is invalid: ").concat(_n317, " >= ").concat(l));
    ++m[_n317], d = d && _n317 >= h, h = _n317;
  }

  var f = !0;

  for (var _e824 = 0; _e824 < l; ++_e824) {
    var _t564 = 0 === m[_e824];

    u[_e824] = _t564, f = f && !_t564, m[_e824] = Math.max(m[_e824], 1), _e824 > 0 && (m[_e824] += m[_e824 - 1]);
  }

  if (f && d) {
    var _t565 = e,
        _n318 = r;

    for (var _e825 = 0; _e825 < i; ++_e825) {
      c[_e825] = _e825;
    }

    return [_t565, [i, p], _n318, u, c];
  }

  {
    var _t566 = m[l - 1],
        _s164 = getArrayFromDType(n, _t566 * p),
        _d13 = getArrayFromDType(a, _t566),
        _h14 = new Array(l).fill(0);

    for (var _t567 = 0; _t567 < i; ++_t567) {
      var _n319 = e[_t567 * p],
          _a239 = (0 === _n319 ? 0 : m[_n319 - 1]) + _h14[_n319];

      _h14[_n319]++;

      for (var _n320 = 0; _n320 < p; ++_n320) {
        _s164[_a239 * p + _n320] = e[_t567 * p + _n320];
      }

      _d13[_a239] = r[_t567], c[_t567] = _a239;
    }

    for (var _e826 = 0; _e826 < l; ++_e826) {
      if (0 === _h14[_e826]) {
        var _t568 = 0 === _e826 ? 0 : m[_e826 - 1];

        _s164[_t568 * p + 0] = _e826;

        for (var _e827 = 1; _e827 < p; ++_e827) {
          _s164[_t568 * p + _e827] = 0;
        }

        _d13[_t568] = o;
      }
    }

    return [_s164, [_t566, p], _d13, u, c];
  }
}

function sparseReshapeImpl(e, t, n, r, a) {
  var s = sizeFromShape(r),
      o = t[0],
      i = a.length,
      l = [];
  var u = 1,
      c = -1;

  for (var _e828 = 0; _e828 < i; ++_e828) {
    var _t569 = a[_e828];

    if (-1 === _t569) {
      if (-1 !== c) throw new Error("only one output dimension may be -1, not both ".concat(c, " and ").concat(_e828));
      c = _e828, l.push(1);
    } else {
      if (_t569 < 0) throw new Error("size ".concat(_e828, " must be non-negative, not ").concat(_t569));
      u *= _t569, l.push(_t569);
    }
  }

  if (-1 !== c) {
    if (u <= 0) throw new Error("reshape cannot infer the missing input size for an empty tensor unless all specified input sizes are non-zero");

    var _e829 = Math.trunc(s / u);

    if (u * _e829 !== s) throw new Error("Input to reshape is a SparseTensor with ".concat(s, "\n          dense values, but the requested shape requires a multiple of ").concat(u, ". inputShape=").concat(r, " outputShape= ").concat(l));
    l[c] = _e829;
  }

  var p = sizeFromShape(l);
  if (p !== s) throw new Error("Input to reshape is a tensor with ".concat(s, " dense values, but the requested shape has ").concat(p, ". inputShape=").concat(r, " outputShape=").concat(l));
  var d = r.length,
      h = [];

  if (d > 0) {
    h[d - 1] = 1;

    for (var _e830 = d - 2; _e830 >= 0; --_e830) {
      h[_e830] = h[_e830 + 1] * r[_e830 + 1];
    }
  }

  var m = [];

  if (i > 0) {
    m[i - 1] = 1;

    for (var _e831 = i - 2; _e831 >= 0; --_e831) {
      m[_e831] = m[_e831 + 1] * l[_e831 + 1];
    }
  }

  var f = getArrayFromDType(n, o * i);

  for (var _t570 = 0; _t570 < o; ++_t570) {
    var _n321 = 0;

    for (var _r333 = 0; _r333 < d; ++_r333) {
      _n321 += e[_t570 * d + _r333] * h[_r333];
    }

    for (var _e832 = 0; _e832 < i; ++_e832) {
      f[_t570 * i + _e832] = Math.trunc(_n321 / m[_e832]), _n321 %= m[_e832];
    }
  }

  return [f, [o, i], l];
}

function sparseSegmentReductionImpl(e, t, n, r, a) {
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : !1;
  var o = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : 0;
  var i = r.length;
  if (i !== a.length) throw new Error("segmentIds and indices should have same size.");
  var l = [t[0], e.length / t[0]],
      u = l[1],
      c = i > 0 ? a[i - 1] + 1 : 0;
  if (c < 0) throw new Error("segment ids must be >= 0");
  var p = t.slice();
  p[0] = c;
  var d = getArrayFromDType(n, p.reduce((e, t) => e * t, 1));
  if (0 === i) return c > 0 && d.fill(o), [d, p];
  if (c <= 0) throw new Error("segment ids must be >= 0");
  var h = 0,
      m = 1,
      f = 0,
      g = a[h];

  for (;;) {
    var _t571 = 0;

    if (m < i) {
      if (_t571 = a[m], g === _t571) {
        ++m;
        continue;
      }

      if (g >= _t571) throw new Error("segment ids are not increasing");
    }

    if (g < 0 || g >= c) throw new Error("Segment id ".concat(g, " out of range [0, ").concat(c, "), possibly because segmentIds input is not sorted."));
    g > f && d.fill(o, f * u, g * u);

    for (var _t572 = h; _t572 < m; ++_t572) {
      var _n322 = r[_t572];
      if (_n322 < 0 || _n322 >= l[0]) throw new Error("Bad: indices[".concat(_t572, "] == ").concat(r[_t572], " out of range [0, ").concat(l[0], ")"));

      for (var _t573 = 0; _t573 < u; _t573++) {
        d[g * u + _t573] += e[_n322 * u + _t573];
      }
    }

    if (s) for (var _e833 = 0; _e833 < u; _e833++) {
      d[g * u + _e833] /= m - h;
    }
    if (h = m, ++m, f = g + 1, g = _t571, m > i) break;
  }

  return f < c && d.fill(o, f * u, c * u), [d, p];
}

var squaredDifferenceImpl = createSimpleBinaryKernelImpl((e, t) => {
  var n = e - t;
  return n * n;
}),
    squaredDifference$1 = binaryKernelFunc$1(SquaredDifference, squaredDifferenceImpl),
    squaredDifferenceConfig$1 = {
  kernelName: SquaredDifference,
  backendName: "cpu",
  kernelFunc: squaredDifference$1
};

function stridedSliceImpl(e, t, n, r) {
  var a = buffer(e, t.dtype);

  for (var _e834 = 0; _e834 < a.size; _e834++) {
    var s = a.indexToLoc(_e834),
        o = new Array(s.length);

    for (var _e835 = 0; _e835 < o.length; _e835++) {
      o[_e835] = s[_e835] * n[_e835] + r[_e835];
    }

    a.set(t.get(...o), ...s);
  }

  return a;
}

class StringNGramsOp {
  constructor(e, t, n, r, a, s) {
    this.separator = encodeString(e), this.nGramWidths = t, this.leftPad = encodeString(n), this.rightPad = encodeString(r), this.padWidth = a, this.preserveShort = s;
  }

  getPadWidth(e) {
    return Math.min(this.padWidth < 0 ? e - 1 : this.padWidth, e - 1);
  }

  getNumNGrams(e, t) {
    var n = this.getPadWidth(t);
    return Math.max(0, e + 2 * n - t + 1);
  }

  createNGrams(e, t, n, r, a, s) {
    var _this213 = this;

    var _loop53 = function _loop53(o) {
      var i = _this213.getPadWidth(s),
          l = Math.max(0, i - o),
          u = Math.max(0, i - (a - (o + 1))),
          c = s - (l + u),
          p = t + (l > 0 ? 0 : o - i);

      var d = 0;
      d += l * _this213.leftPad.length;

      for (var _t574 = 0; _t574 < c; ++_t574) {
        d += e[p + _t574].length;
      }

      d += u * _this213.rightPad.length, d += (l + u + c - 1) * _this213.separator.length, n[r + o] = new Uint8Array(d);
      var h = n[r + o];
      var m = 0;

      var f = e => e.forEach(e => h[m++] = e);

      for (var _e836 = 0; _e836 < l; ++_e836) {
        f(_this213.leftPad), f(_this213.separator);
      }

      for (var _t575 = 0; _t575 < c - 1; ++_t575) {
        f(e[p + _t575]), f(_this213.separator);
      }

      if (c > 0) {
        f(e[p + c - 1]);

        for (var _e837 = 0; _e837 < u; ++_e837) {
          f(_this213.separator), f(_this213.rightPad);
        }
      } else {
        for (var _e838 = 0; _e838 < u - 1; ++_e838) {
          f(_this213.rightPad), f(_this213.separator);
        }

        f(_this213.rightPad);
      }
    };

    for (var o = 0; o < a; ++o) {
      _loop53(o);
    }
  }

  compute(e, t) {
    var _this214 = this;

    var n = e.length,
        r = t.length;

    if (r > 0) {
      var _e839 = t[0];
      if (0 !== _e839) throw new Error("First split value must be 0, got ".concat(_e839));

      for (var _a240 = 1; _a240 < r; ++_a240) {
        var _r334 = t[_a240] >= _e839;

        if (_r334 = _r334 && t[_a240] <= n, !_r334) throw new Error("Invalid split value ".concat(t[_a240], ", must be in [").concat(_e839, ", ").concat(n, "]"));
        _e839 = t[_a240];
      }

      if (_e839 !== n) throw new Error("Last split value must be data size. Expected ".concat(n, ", got ").concat(_e839));
    }

    var a = r - 1,
        s = getArrayFromDType("int32", r);

    if (0 === n || 0 === r) {
      var _e840 = new Array(n);

      for (var _e841 = 0; _e841 <= a; ++_e841) {
        s[_e841] = 0;
      }

      return [_e840, s];
    }

    s[0] = 0;

    var _loop54 = function _loop54(_e842) {
      var n = t[_e842] - t[_e842 - 1];
      var r = 0;
      _this214.nGramWidths.forEach(e => {
        r += _this214.getNumNGrams(n, e);
      }), _this214.preserveShort && n > 0 && 0 === r && (r = 1), s[_e842] = s[_e842 - 1] + r;
    };

    for (var _e842 = 1; _e842 <= a; ++_e842) {
      _loop54(_e842);
    }

    var o = new Array(s[a]);

    var _loop55 = function _loop55(_n323) {
      var r = t[_n323];
      var a = s[_n323];

      if (_this214.nGramWidths.forEach(s => {
        var i = _this214.getNumNGrams(t[_n323 + 1] - t[_n323], s);

        _this214.createNGrams(e, r, o, a, i, s), a += i;
      }), _this214.preserveShort && a === s[_n323]) {
        var _s165 = t[_n323 + 1] - t[_n323];

        if (0 === _s165) return "continue";

        _this214.createNGrams(e, r, o, a, 1, _s165 + 2 * _this214.padWidth);
      }
    };

    for (var _n323 = 0; _n323 < a; ++_n323) {
      var _ret3 = _loop55(_n323);

      if (_ret3 === "continue") continue;
    }

    return [o, s];
  }

}

function stringNGramsImpl(e, t, n, r, a, s, o, i) {
  return new StringNGramsOp(n, r, a, s, o, i).compute(e, t);
}

function split(e, t, n) {
  if (!e.length) return [];

  if (0 === t.length) {
    var _t576 = new Array(e.length);

    for (var _n324 = 0; _n324 < e.length; ++_n324) {
      _t576[_n324] = e.subarray(_n324, _n324 + 1);
    }

    return _t576;
  }

  if (1 === t.length) {
    var _r335 = t[0],
        _a241 = [];
    var s = e.indexOf(_r335);

    for (; -1 !== s;) {
      var _t577 = e.subarray(0, s);

      n && 0 === _t577.length || _a241.push(_t577), s = (e = e.subarray(s + 1)).indexOf(_r335);
    }

    return n && 0 === e.length || _a241.push(e), _a241;
  }

  var r = [];
  var a = 0;

  for (var _s166 = 0; _s166 < e.length + 1; _s166++) {
    if (_s166 === e.length || -1 !== t.indexOf(e[_s166])) {
      var _t578 = e.subarray(a, _s166);

      n && 0 === _t578.length || r.push(_t578), a = _s166 + 1;
    }
  }

  return r;
}

function stringSplitImpl(e, t, n) {
  var r = e.length,
      a = [];
  var s = 0,
      o = 0;
  var i = new Array(r);

  for (var _l43 = 0; _l43 < r; ++_l43) {
    var _r336 = split(e[_l43], t, n),
        _u37 = _r336.length;

    i[_l43] = _u37, s += _u37, o = Math.max(o, _u37), a.push(..._r336);
  }

  var l = getArrayFromDType("int32", 2 * s),
      u = new Array(s),
      c = [r, o];
  var p = 0;

  for (var _e843 = 0; _e843 < r; ++_e843) {
    for (var _t579 = 0; _t579 < i[_e843]; ++_t579) {
      l[2 * p] = _e843, l[2 * p + 1] = _t579, u[p] = a[p], ++p;
    }
  }

  return [l, u, c];
}

function stringToHashBucketFastImpl(e, t) {
  var n = getArrayFromDType("int32", e.length);

  for (var r = 0; r < e.length; ++r) {
    n[r] = fingerPrint64(e[r]).modulo(t).getLowBitsUnsigned();
  }

  return n;
}

var subImpl = createSimpleBinaryKernelImpl((e, t) => e - t),
    subComplexImpl = createComplexBinaryKernelImpl((e, t, n, r) => ({
  real: e - n,
  imag: t - r
})),
    sub$1 = binaryKernelFunc$1(Sub, subImpl, subComplexImpl),
    subConfig$1 = {
  kernelName: Sub,
  backendName: "cpu",
  kernelFunc: sub$1
};

function tileImpl(e, t) {
  var n = new Array(e.rank);

  for (var _r337 = 0; _r337 < n.length; _r337++) {
    n[_r337] = e.shape[_r337] * t[_r337];
  }

  var r = buffer(n, e.dtype);

  for (var _t580 = 0; _t580 < r.values.length; ++_t580) {
    var _n325 = r.indexToLoc(_t580),
        a = new Array(e.rank);

    for (var _t581 = 0; _t581 < a.length; _t581++) {
      a[_t581] = _n325[_t581] % e.shape[_t581];
    }

    var s = e.locToIndex(a);
    r.values[_t580] = e.values[s];
  }

  return r;
}

var comparePair = (e, t) => {
  var n = t.value - e.value;
  return 0 === n ? e.index - t.index : n;
};

function select$2(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : e.length - 1;

  for (; r > n;) {
    if (r - n > 600) {
      var _a242 = r - n + 1,
          _s167 = t - n + 1,
          _o104 = Math.log(_a242),
          i = .5 * Math.exp(2 * _o104 / 3),
          l = .5 * Math.sqrt(_o104 * i * (_a242 - i) / _a242) * Math.sign(_s167 - _a242 / 2);

      select$2(e, t, Math.max(n, Math.floor(t - _s167 * i / _a242 + l)), Math.min(r, Math.floor(t + (_a242 - _s167) * i / _a242 + l)));
    }

    var a = e[t];
    var s = n,
        o = r;

    for (swap(e, n, t), comparePair(e[r], a) > 0 && swap(e, n, r); s < o;) {
      for (swap(e, s, o), s++, o--; comparePair(e[s], a) < 0;) {
        s += 1;
      }

      for (; comparePair(e[o], a) > 0;) {
        o -= 1;
      }
    }

    0 === comparePair(e[n], a) ? swap(e, n, o) : (o += 1, swap(e, o, r)), o <= t && (n = o + 1), t <= o && (r = o - 1);
  }
}

function topKImpl(e, t, n, r, a) {
  var s = t[t.length - 1],
      [o, i] = [e.length / s, s],
      l = getTypedArrayFromDType(n, o * r),
      u = getTypedArrayFromDType("int32", o * r);

  var _loop56 = function _loop56(_t582) {
    var n = _t582 * i,
        s = e.subarray(n, n + i);
    var o = new Array(s.length);
    s.forEach((e, t) => o[t] = {
      value: e,
      index: t
    }), r < o.length && (select$2(o, r), o = o.slice(0, r)), a && o.sort(comparePair);
    var c = _t582 * r,
        p = l.subarray(c, c + r),
        d = u.subarray(c, c + r);

    for (var _e844 = 0; _e844 < r; _e844++) {
      p[_e844] = o[_e844].value, d[_e844] = o[_e844].index;
    }
  };

  for (var _t582 = 0; _t582 < o; _t582++) {
    _loop56(_t582);
  }

  var c = t.slice();
  return c[c.length - 1] = r, [buffer(c, n, l), buffer(c, "int32", u)];
}

function uniqueImpl(e, t, n, r) {
  var a = parseAxisParam(t, n)[0],
      s = [1, n[0], 1];

  for (var _e845 = 0; _e845 < a; _e845++) {
    s[0] *= n[_e845];
  }

  s[1] = n[a];

  for (var _e846 = a + 1; _e846 < n.length; _e846++) {
    s[2] *= n[_e846];
  }

  var o = {},
      i = new Int32Array(n[a]),
      l = new TensorBuffer(s, r, e),
      u = [],
      c = 1 === s[0] && 1 === s[2];

  for (var _t583 = 0; _t583 < n[a]; _t583++) {
    var _n326 = void 0;

    if (c) _n326 = e[_t583].toString();else {
      var _e847 = [];

      for (var _n327 = 0; _n327 < s[0]; _n327++) {
        for (var _r338 = 0; _r338 < s[2]; _r338++) {
          _e847.push(l.get(_n327, _t583, _r338));
        }
      }

      _n326 = _e847.join(",");
    }
    if (void 0 !== o[_n326]) i[_t583] = o[_n326];else {
      var _e848 = Object.keys(o).length;
      o[_n326] = _e848, i[_t583] = _e848, u.push(_t583);
    }
  }

  var p = s.slice();
  p[1] = Object.keys(o).length;
  var d = new TensorBuffer(p, r);
  u.forEach((e, t) => {
    for (var _n328 = 0; _n328 < s[0]; _n328++) {
      for (var _r339 = 0; _r339 < s[2]; _r339++) {
        d.set(l.get(_n328, e, _r339), _n328, t, _r339);
      }
    }
  });
  var h = n.slice();
  return h[a] = p[1], {
    outputValues: d.values,
    outputShape: h,
    indices: i
  };
}

var shared = {
  __proto__: null,
  simpleAbsImpl,
  addImpl,
  bincountImpl,
  bincountReduceImpl,
  ceilImpl,
  concatImpl: concatImpl$1,
  equalImpl,
  expImpl,
  expm1Impl,
  floorImpl,
  gatherNdImpl,
  gatherV2Impl,
  greaterImpl,
  greaterEqualImpl,
  lessImpl,
  lessEqualImpl,
  linSpaceImpl,
  logImpl,
  maxImpl: maxImpl$1,
  maximumImpl,
  minimumImpl,
  multiplyImpl,
  negImpl,
  notEqualImpl,
  prodImpl,
  rangeImpl,
  rsqrtImpl,
  sliceImpl,
  sparseFillEmptyRowsImpl,
  sparseReshapeImpl,
  sparseSegmentReductionImpl,
  squaredDifferenceImpl,
  stridedSliceImpl,
  stringNGramsImpl,
  stringSplitImpl,
  stringToHashBucketFastImpl,
  subImpl,
  tileImpl,
  topKImpl,
  transposeImpl: transposeImpl$1,
  uniqueImpl
};
var version$3 = "3.8.0";
registerBackend("cpu", () => new MathBackendCPU(), 1);
var elu$1 = unaryKernelFunc$1(Elu$1, e => e >= 0 ? e : Math.exp(e) - 1),
    eluConfig$1 = {
  kernelName: Elu$1,
  backendName: "cpu",
  kernelFunc: elu$1
};

function leakyRelu$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    alpha: s
  } = r;
  assertNotComplex$1([a], "leakyRelu");
  var o = sizeFromShape(a.shape),
      i = n.data.get(a.dataId).values,
      l = getTypedArrayFromDType("float32", o);

  for (var _e849 = 0; _e849 < i.length; _e849++) {
    l[_e849] = i[_e849] < 0 ? s * i[_e849] : i[_e849];
  }

  return n.makeTensorInfo(a.shape, "float32", l);
}

var leakyReluConfig$1 = {
  kernelName: LeakyRelu,
  backendName: "cpu",
  kernelFunc: leakyRelu$1
},
    preluImpl = createSimpleBinaryKernelImpl((e, t) => e < 0 ? t * e : e);

function prelu$1(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    x: r,
    alpha: a
  } = t;
  assertNotComplex$1([r, a], "prelu");
  var s = n.data.get(r.dataId).values,
      o = n.data.get(a.dataId).values,
      [i, l] = preluImpl(r.shape, a.shape, s, o, r.dtype);
  return n.makeTensorInfo(l, r.dtype, i);
}

var preluConfig$1 = {
  kernelName: Prelu,
  backendName: "cpu",
  kernelFunc: prelu$1
},
    relu$2 = unaryKernelFunc$1(Relu$1, e => Math.max(0, e)),
    reluConfig$1 = {
  kernelName: Relu$1,
  backendName: "cpu",
  kernelFunc: relu$2
},
    relu6$1 = unaryKernelFunc$1(Relu6$1, e => Math.min(Math.max(0, e), 6)),
    relu6Config$1 = {
  kernelName: Relu6$1,
  backendName: "cpu",
  kernelFunc: relu6$1
},
    sigmoid$1 = unaryKernelFunc$1(Sigmoid$1, e => 1 / (1 + Math.exp(-e))),
    sigmoidConfig$1 = {
  kernelName: Sigmoid$1,
  backendName: "cpu",
  kernelFunc: sigmoid$1
};

function applyActivation(e, t, n, r, a) {
  if ("linear" === n) return identity$1({
    inputs: {
      x: t
    },
    backend: e
  });
  if ("relu" === n) return relu$2({
    inputs: {
      x: t
    },
    backend: e
  });
  if ("elu" === n) return elu$1({
    inputs: {
      x: t
    },
    backend: e
  });
  if ("relu6" === n) return relu6$1({
    inputs: {
      x: t
    },
    backend: e
  });
  if ("prelu" === n) return prelu$1({
    inputs: {
      x: t,
      alpha: r
    },
    backend: e
  });
  if ("leakyrelu" === n) return leakyRelu$1({
    inputs: {
      x: t
    },
    backend: e,
    attrs: {
      alpha: a
    }
  });
  if ("sigmoid" === n) return sigmoid$1({
    inputs: {
      x: t
    },
    backend: e
  });
  throw new Error("Activation ".concat(n, " has not been implemented for the CPU backend."));
}

function reshape$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    shape: s
  } = r,
      o = sizeFromShape(a.shape),
      i = inferFromImplicitShape(s, o),
      l = sizeFromShape(i);
  assert$4(o === l, () => "The new shape (".concat(i, ") has ").concat(l, " elements and the old shape (").concat(a.shape, ") has ").concat(o, " elements. The new shape and old shape must have the same number of elements.")), n.incRef(a.dataId);
  var u = n.data.get(a.dataId);

  if (null != u.complexTensorInfos) {
    var _e850 = u.complexTensorInfos.imag;
    u.complexTensorInfos.real.shape = i, _e850.shape = i;
  }

  return {
    dataId: a.dataId,
    shape: i,
    dtype: a.dtype
  };
}

var reshapeConfig$1 = {
  kernelName: Reshape$1,
  backendName: "cpu",
  kernelFunc: reshape$1
};

function batchMatMul$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    a,
    b: s
  } = t,
      {
    transposeA: o,
    transposeB: i
  } = r;
  assertNotComplex$1([a, s], "matMul");
  var l = a.shape.length,
      u = s.shape.length,
      c = o ? a.shape[l - 2] : a.shape[l - 1],
      p = i ? s.shape[u - 1] : s.shape[u - 2],
      d = o ? a.shape[l - 1] : a.shape[l - 2],
      h = i ? s.shape[u - 2] : s.shape[u - 1],
      m = a.shape.slice(0, -2),
      f = s.shape.slice(0, -2),
      g = sizeFromShape(m),
      $ = sizeFromShape(f);
  assert$4(l >= 2 && u >= 2 && (g === $ || 1 === g || 1 === $), () => "Error in matMul: the input batch dimensions must either be the same or at least one input batch dimension must be 1. Got input batch dimensions of (".concat(m, ") and (").concat(f, ")."));
  var y = (g > $ ? a.shape.slice(0, -2) : s.shape.slice(0, -2)).concat([d, h]);
  assert$4(c === p, () => "Error in matMul: inner shapes (".concat(c, ") and (").concat(p, ") of Tensors with shapes ").concat(a.shape, " and ").concat(s.shape, " and transposeA=").concat(o, " and transposeB=").concat(i, " must match."));
  var b = i ? [$, h, p] : [$, p, h],
      x = reshape$1({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      shape: o ? [g, c, d] : [g, d, c]
    }
  }),
      v = reshape$1({
    inputs: {
      x: s
    },
    backend: n,
    attrs: {
      shape: b
    }
  }),
      I = o ? x.shape[1] : x.shape[2],
      C = o ? x.shape[2] : x.shape[1],
      S = i ? v.shape[1] : v.shape[2],
      k = Math.max(g, $),
      T = n.data.get(x.dataId).values,
      N = n.data.get(v.dataId).values,
      w = computeStrides(x.shape),
      E = computeStrides(v.shape),
      [A, D, R] = o ? [w[0], 1, w[1]] : [w[0], w[1], 1],
      [_, F, P] = i ? [1, E[1], E[0]] : [E[1], 1, E[0]],
      O = C * S,
      M = buffer([k, C, S], x.dtype),
      L = M.values,
      z = n.blockSize;

  for (var _e851 = 0; _e851 < k; _e851++) {
    for (var _t584 = 0; _t584 < C; _t584 += z) {
      for (var _n329 = 0; _n329 < S; _n329 += z) {
        for (var _r340 = 0; _r340 < I; _r340 += z) {
          var _a243 = Math.min(_t584 + z, C),
              _s168 = Math.min(_n329 + z, S),
              _o105 = Math.min(_r340 + z, I);

          for (var _i53 = _t584; _i53 < _a243; _i53++) {
            for (var _t585 = _n329; _t585 < _s168; _t585++) {
              var _n330 = 0;

              for (var _a244 = _r340; _a244 < _o105; _a244++) {
                var _r341 = Math.min(_e851, g - 1) * A,
                    _s169 = Math.min(_e851, $ - 1) * P;

                _n330 += T[_r341 + _i53 * D + _a244 * R] * N[_a244 * _ + _t585 * F + _s169];
              }

              L[_e851 * O + (_i53 * S + _t585)] += _n330;
            }
          }
        }
      }
    }
  }

  return n.disposeIntermediateTensorInfo(x), n.disposeIntermediateTensorInfo(v), n.makeTensorInfo(y, M.dtype, M.values);
}

var batchMatMulConfig$1 = {
  kernelName: BatchMatMul,
  backendName: "cpu",
  kernelFunc: batchMatMul$1
};

function _fusedMatMul$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    a,
    b: s,
    bias: o,
    preluActivationWeights: i
  } = t,
      {
    transposeA: l,
    transposeB: u,
    activation: c,
    leakyreluAlpha: p
  } = r;
  var d, h, m;
  var f = [];
  d = batchMatMul$1({
    inputs: {
      a,
      b: s
    },
    attrs: {
      transposeA: l,
      transposeB: u
    },
    backend: n
  }), o && (h = add({
    inputs: {
      a: d,
      b: o
    },
    backend: n
  }), f.push(d), d = h), c && (m = applyActivation(n, d, c, i, p), f.push(d), d = m);

  for (var _e852 of f) {
    n.disposeIntermediateTensorInfo(_e852);
  }

  return d;
}

var _fusedMatMulConfig$1 = {
  kernelName: _FusedMatMul,
  backendName: "cpu",
  kernelFunc: _fusedMatMul$1
},
    acos$1 = unaryKernelFunc$1(Acos, e => Math.acos(e)),
    acosConfig$1 = {
  kernelName: Acos,
  backendName: "cpu",
  kernelFunc: acos$1
},
    acosh$1 = unaryKernelFunc$1(Acosh, e => Math.acosh(e)),
    acoshConfig$1 = {
  kernelName: Acosh,
  backendName: "cpu",
  kernelFunc: acosh$1
};

function addN$1(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      r = t;
  assertNotComplex$1(t, "addN");
  var a = r.map(e => n.data.get(e.dataId).values),
      s = buffer(r[0].shape, r[0].dtype),
      o = s.values;

  for (var _e853 = 0; _e853 < r.length; _e853++) {
    var _t586 = a[_e853];

    for (var _e854 = 0; _e854 < o.length; _e854++) {
      o[_e854] += _t586[_e854];
    }
  }

  return n.makeTensorInfo(s.shape, s.dtype, s.values);
}

var addNConfig$1 = {
  kernelName: AddN,
  backendName: "cpu",
  kernelFunc: addN$1
};

function all$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    axis: s,
    keepDims: o
  } = r;
  assertNotComplex$1(a, "all");
  var i = parseAxisParam(s, a.shape);
  var l = i;
  var u = getAxesPermutation(l, a.shape.length);
  var c = a;
  null != u && (c = transpose$1({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      perm: u
    }
  }), l = getInnerMostAxes(l.length, a.shape.length)), assertAxesAreInnerMostDims("all", l, c.shape.length);
  var [p, d] = computeOutAndReduceShapes(c.shape, l),
      h = sizeFromShape(d),
      m = makeZerosTypedArray(sizeFromShape(p), c.dtype),
      f = n.data.get(c.dataId).values;

  for (var _e855 = 0; _e855 < m.length; ++_e855) {
    var _t587 = _e855 * h;

    var _n331 = f[_t587];

    for (var _e856 = 0; _e856 < h; ++_e856) {
      var _r342 = f[_t587 + _e856];
      _n331 = _n331 && _r342;
    }

    m[_e855] = _n331;
  }

  null != u && n.disposeIntermediateTensorInfo(c);
  var g = n.makeTensorInfo(p, c.dtype, m);

  if (o) {
    var _e857 = reshape$1({
      inputs: {
        x: g
      },
      backend: n,
      attrs: {
        shape: expandShapeToKeepDim(p, i)
      }
    });

    return n.disposeIntermediateTensorInfo(g), _e857;
  }

  return g;
}

var allConfig$1 = {
  kernelName: All,
  backendName: "cpu",
  kernelFunc: all$1
};

function any$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    axis: s,
    keepDims: o
  } = r;
  assertNotComplex$1(a, "any");
  var i = parseAxisParam(s, a.shape);
  var l = i;
  var u = getAxesPermutation(l, a.shape.length);
  var c = a;
  null != u && (c = transpose$1({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      perm: u
    }
  }), l = getInnerMostAxes(l.length, a.shape.length)), assertAxesAreInnerMostDims("any", l, c.shape.length);
  var [p, d] = computeOutAndReduceShapes(c.shape, l),
      h = sizeFromShape(d),
      m = makeZerosTypedArray(sizeFromShape(p), c.dtype),
      f = n.data.get(c.dataId).values;

  for (var _e858 = 0; _e858 < m.length; ++_e858) {
    var _t588 = _e858 * h;

    var _n332 = f[_t588];

    for (var _e859 = 0; _e859 < h; ++_e859) {
      var _r343 = f[_t588 + _e859];
      _n332 = _n332 || _r343;
    }

    m[_e858] = _n332;
  }

  null != u && n.disposeIntermediateTensorInfo(c);
  var g = n.makeTensorInfo(p, c.dtype, m);

  if (o) {
    var _e860 = reshape$1({
      inputs: {
        x: g
      },
      backend: n,
      attrs: {
        shape: expandShapeToKeepDim(p, i)
      }
    });

    return n.disposeIntermediateTensorInfo(g), _e860;
  }

  return g;
}

var anyConfig$1 = {
  kernelName: Any,
  backendName: "cpu",
  kernelFunc: any$1
};

function argMax$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    axis: s
  } = r;
  assertNotComplex$1(a, "argMax");
  var o = parseAxisParam(s, a.shape);
  var i = getAxesPermutation(o, a.shape.length);
  var l = a;
  var u = [];
  null != i && (l = transpose$1({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      perm: i
    }
  }), u.push(l), o = getInnerMostAxes(o.length, l.shape.length)), o = [o[0]], assertAxesAreInnerMostDims("argMax", o, l.shape.length);
  var [c, p] = computeOutAndReduceShapes(l.shape, o),
      d = makeZerosTypedArray(sizeFromShape(c), "int32"),
      h = sizeFromShape(p),
      m = n.data.get(l.dataId).values;

  for (var _e861 = 0; _e861 < d.length; ++_e861) {
    var _t589 = _e861 * h;

    var _n333 = m[_t589],
        _r344 = 0;

    for (var _e862 = 0; _e862 < h; ++_e862) {
      var _a245 = m[_t589 + _e862];
      _a245 > _n333 && (_n333 = _a245, _r344 = _e862);
    }

    d[_e861] = _r344;
  }

  return u.forEach(e => n.disposeIntermediateTensorInfo(e)), n.makeTensorInfo(c, "int32", d);
}

var argMaxConfig$1 = {
  kernelName: ArgMax,
  backendName: "cpu",
  kernelFunc: argMax$1
};

function argMin$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    axis: s
  } = r;
  assertNotComplex$1(a, "argMin");
  var o = parseAxisParam(s, a.shape);
  var i = getAxesPermutation(o, a.shape.length);
  var l = a;
  var u = [];
  null != i && (l = transpose$1({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      perm: i
    }
  }), u.push(l), o = getInnerMostAxes(o.length, l.shape.length)), o = [o[0]], assertAxesAreInnerMostDims("argMin", o, l.shape.length);
  var [c, p] = computeOutAndReduceShapes(l.shape, o),
      d = makeZerosTypedArray(sizeFromShape(c), "int32"),
      h = sizeFromShape(p),
      m = n.data.get(l.dataId).values;

  for (var _e863 = 0; _e863 < d.length; ++_e863) {
    var _t590 = _e863 * h;

    var _n334 = m[_t590],
        _r345 = 0;

    for (var _e864 = 0; _e864 < h; ++_e864) {
      var _a246 = m[_t590 + _e864];
      _a246 < _n334 && (_n334 = _a246, _r345 = _e864);
    }

    d[_e863] = _r345;
  }

  return u.forEach(e => n.disposeIntermediateTensorInfo(e)), n.makeTensorInfo(c, "int32", d);
}

var argMinConfig$1 = {
  kernelName: ArgMin,
  backendName: "cpu",
  kernelFunc: argMin$1
},
    asin$1 = unaryKernelFunc$1(Asin, e => Math.asin(e)),
    asinConfig$1 = {
  kernelName: Asin,
  backendName: "cpu",
  kernelFunc: asin$1
},
    asinh$1 = unaryKernelFunc$1(Asinh, e => Math.asinh(e)),
    asinhConfig$1 = {
  kernelName: Asinh,
  backendName: "cpu",
  kernelFunc: asinh$1
},
    atan$1 = unaryKernelFunc$1(Atan, e => Math.atan(e)),
    atanConfig$1 = {
  kernelName: Atan,
  backendName: "cpu",
  kernelFunc: atan$1
},
    atan2Impl = createSimpleBinaryKernelImpl((e, t) => Math.atan2(e, t)),
    atan2$1 = binaryKernelFunc$1(Atan2, atan2Impl),
    atan2Config$1 = {
  kernelName: Atan2,
  backendName: "cpu",
  kernelFunc: atan2$1
},
    atanh$1 = unaryKernelFunc$1(Atanh, e => Math.atanh(e)),
    atanhConfig$1 = {
  kernelName: Atanh,
  backendName: "cpu",
  kernelFunc: atanh$1
};

function pool(e, t, n, r, a, s) {
  var o = a.strideHeight,
      i = a.strideWidth,
      l = a.dilationHeight,
      u = a.dilationWidth,
      c = a.effectiveFilterHeight,
      p = a.effectiveFilterWidth,
      d = a.padInfo.top,
      h = a.padInfo.left,
      m = "max" === s ? Number.NEGATIVE_INFINITY : Number.POSITIVE_INFINITY,
      f = buffer(a.outShape, n),
      g = f.values,
      $ = a.outShape[1] * a.outShape[2] * a.outShape[3],
      y = a.outShape[2] * a.outShape[3],
      b = a.outShape[3];

  for (var _t591 = 0; _t591 < a.batchSize; ++_t591) {
    var _n335 = _t591 * $,
        _f10 = _t591 * r[0];

    for (var _t592 = 0; _t592 < a.inChannels; ++_t592) {
      for (var _$7 = 0; _$7 < a.outHeight; ++_$7) {
        var x = _$7 * o - d,
            v = Math.max(0, x),
            I = Math.min(a.inHeight, c + x),
            C = _n335 + _$7 * y;

        for (var _n336 = 0; _n336 < a.outWidth; ++_n336) {
          var _o106 = _n336 * i - h,
              _c24 = Math.max(0, _o106),
              _d14 = Math.min(a.inWidth, p + _o106);

          var _$8 = m,
              _y3 = 0,
              _x139 = 0;

          for (var _n337 = v; _n337 < I; _n337 += l) {
            var _a247 = _f10 + _n337 * r[1];

            for (var _n338 = _c24; _n338 < _d14; _n338 += u) {
              var _o107 = e[_a247 + _n338 * r[2] + _t592];
              "max" === s && _o107 > _$8 ? _$8 = _o107 : "avg" === s && (_y3 += _o107, _x139++);
            }

            if (isNaN(_$8)) break;
          }

          g[C + _n336 * b + _t592] = "avg" === s ? _y3 / _x139 : _$8;
        }
      }
    }
  }

  return f;
}

function maxPoolPositions(e, t, n, r) {
  var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;
  var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : !1;
  var o = buffer(r.outShape, "int32"),
      i = r.strideHeight,
      l = r.strideWidth,
      u = r.dilationHeight,
      c = r.dilationWidth,
      p = r.effectiveFilterHeight,
      d = r.effectiveFilterWidth,
      h = r.padInfo.top,
      m = r.padInfo.left,
      f = buffer(t, n, e);

  for (var _e865 = 0; _e865 < r.batchSize; ++_e865) {
    for (var _t593 = 0; _t593 < r.inChannels; ++_t593) {
      for (var _n339 = 0; _n339 < r.outHeight; ++_n339) {
        var g = _n339 * i - h;
        var $ = g;

        for (; $ < 0;) {
          $ += u;
        }

        var y = Math.min(r.inHeight, p + g);

        for (var _i54 = 0; _i54 < r.outWidth; ++_i54) {
          var _p27 = _i54 * l - m;

          var _h15 = _p27;

          for (; _h15 < 0;) {
            _h15 += c;
          }

          var b = Math.min(r.inWidth, d + _p27);
          var x = Number.NEGATIVE_INFINITY,
              v = -1;

          for (var _n340 = $; _n340 < y; _n340 += u) {
            var _o108 = _n340 - g;

            for (var _i55 = _h15; _i55 < b; _i55 += c) {
              var _l44 = _i55 - _p27,
                  _u38 = f.get(_e865, _n340, _i55, _t593);

              _u38 > x && (x = _u38, v = a ? s ? ((_e865 * r.inHeight + _n340) * r.inWidth + _i55) * r.inChannels + _t593 : (_n340 * r.inWidth + _i55) * r.inChannels + _t593 : _o108 * d + _l44);
            }
          }

          o.set(v, _e865, _n339, _i54, _t593);
        }
      }
    }
  }

  return o;
}

function pool3d(e, t, n, r, a, s) {
  var o = a.strideDepth,
      i = a.strideHeight,
      l = a.strideWidth,
      u = a.dilationDepth,
      c = a.dilationHeight,
      p = a.dilationWidth,
      d = a.effectiveFilterDepth,
      h = a.effectiveFilterHeight,
      m = a.effectiveFilterWidth,
      f = a.padInfo.front,
      g = a.padInfo.top,
      $ = a.padInfo.left,
      y = "max" === s ? Number.NEGATIVE_INFINITY : Number.POSITIVE_INFINITY,
      b = buffer(a.outShape, n),
      x = b.values,
      v = a.outShape[1] * a.outShape[2] * a.outShape[3] * a.outShape[4],
      I = a.outShape[2] * a.outShape[3] * a.outShape[4],
      C = a.outShape[3] * a.outShape[4],
      S = a.outShape[4];

  for (var _t594 = 0; _t594 < a.batchSize; ++_t594) {
    var _n341 = _t594 * v,
        _b2 = _t594 * r[0];

    for (var _t595 = 0; _t595 < a.inChannels; ++_t595) {
      for (var _v3 = 0; _v3 < a.outDepth; ++_v3) {
        var k = _v3 * o - f;
        var T = k;

        for (; T < 0;) {
          T += u;
        }

        var N = Math.min(a.inDepth, d + k),
            w = _n341 + _v3 * I;

        for (var _n342 = 0; _n342 < a.outHeight; ++_n342) {
          var _o109 = _n342 * i - g;

          var _d15 = _o109;

          for (; _d15 < 0;) {
            _d15 += c;
          }

          var _f11 = Math.min(a.inHeight, h + _o109),
              _v4 = w + _n342 * C;

          for (var _n343 = 0; _n343 < a.outWidth; ++_n343) {
            var _o110 = _n343 * l - $;

            var _i56 = _o110;

            for (; _i56 < 0;) {
              _i56 += p;
            }

            var _h16 = Math.min(a.inWidth, m + _o110),
                _g4 = _v4 + _n343 * S;

            var _I2 = y,
                _C2 = 0,
                _k2 = 0;

            for (var _n344 = T; _n344 < N; _n344 += u) {
              var _a248 = _b2 + _n344 * r[1];

              for (var _n345 = _d15; _n345 < _f11; _n345 += c) {
                var _o111 = _a248 + _n345 * r[2];

                for (var _n346 = _i56; _n346 < _h16; _n346 += p) {
                  var _a249 = e[_o111 + _n346 * r[3] + _t595];
                  if ("max" === s && _a249 > _I2 ? _I2 = _a249 : "avg" === s && (_C2 += _a249, _k2++), isNaN(_I2)) break;
                }

                if (isNaN(_I2)) break;
              }

              if (isNaN(_I2)) break;
            }

            x[_g4 + _t595] = "avg" === s ? _C2 / _k2 : _I2;
          }
        }
      }
    }
  }

  return b;
}

function maxPool3dPositions(e, t) {
  var n = buffer(t.outShape, "int32"),
      r = t.strideDepth,
      a = t.strideHeight,
      s = t.strideWidth,
      o = t.dilationDepth,
      i = t.dilationHeight,
      l = t.dilationWidth,
      u = t.effectiveFilterDepth,
      c = t.effectiveFilterHeight,
      p = t.effectiveFilterWidth,
      d = t.padInfo.front,
      h = t.padInfo.top,
      m = t.padInfo.left;

  for (var f = 0; f < t.batchSize; ++f) {
    for (var g = 0; g < t.inChannels; ++g) {
      for (var $ = 0; $ < t.outDepth; ++$) {
        var y = $ * r - d;
        var b = y;

        for (; b < 0;) {
          b += o;
        }

        var x = Math.min(t.inDepth, u + y);

        for (var _r346 = 0; _r346 < t.outHeight; ++_r346) {
          var _u39 = _r346 * a - h;

          var _d16 = _u39;

          for (; _d16 < 0;) {
            _d16 += i;
          }

          var v = Math.min(t.inHeight, c + _u39);

          for (var _a250 = 0; _a250 < t.outWidth; ++_a250) {
            var _h17 = _a250 * s - m;

            var I = _h17;

            for (; I < 0;) {
              I += l;
            }

            var C = Math.min(t.inWidth, p + _h17);
            var S = Number.NEGATIVE_INFINITY,
                k = -1;

            for (var _t596 = b; _t596 < x; _t596 += o) {
              var _n347 = _t596 - y;

              for (var _r347 = _d16; _r347 < v; _r347 += i) {
                var _a251 = _r347 - _u39;

                for (var _s170 = I; _s170 < C; _s170 += l) {
                  var _o112 = _s170 - _h17,
                      _i57 = e.get(f, _t596, _r347, _s170, g);

                  _i57 >= S && (S = _i57, k = _n347 * c * p + _a251 * c + _o112);
                }
              }
            }

            n.set(k, f, $, _r346, _a250, g);
          }
        }
      }
    }
  }

  return n;
}

function avgPool$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t;
  assertNotComplex$1(a, "avgPool");
  var {
    filterSize: s,
    strides: o,
    pad: i,
    dimRoundingMode: l
  } = r;
  assert$4(eitherStridesOrDilationsAreOne(o, 1), () => "Error in avgPool: Either strides or dilations must be 1. Got strides ".concat(o, " and dilations '1'"));
  var u = computePool2DInfo(a.shape, s, o, 1, i, l);
  var c;
  if (1 === u.filterWidth && 1 === u.filterHeight && arraysEqual(u.inShape, u.outShape)) c = identity$1({
    inputs: {
      x: a
    },
    backend: n
  });else {
    var _e866 = n.data.get(a.dataId).values,
        _t597 = computeStrides(a.shape),
        _r348 = pool(_e866, a.shape, a.dtype, _t597, u, "avg");

    c = n.makeTensorInfo(u.outShape, a.dtype, _r348.values);
  }
  return c;
}

var avgPoolConfig$1 = {
  kernelName: AvgPool,
  backendName: "cpu",
  kernelFunc: avgPool$1
};

function avgPool3D$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    filterSize: s,
    strides: o,
    pad: i,
    dimRoundingMode: l,
    dataFormat: u
  } = r;
  assertNotComplex$1(a, "avgPool3d");
  var c = computePool3DInfo(a.shape, s, o, 1, i, l, u),
      p = pool3d(n.data.get(a.dataId).values, a.shape, a.dtype, computeStrides(a.shape), c, "avg");
  return n.makeTensorInfo(p.shape, "float32", p.values);
}

var avgPool3DConfig$1 = {
  kernelName: AvgPool3D,
  backendName: "cpu",
  kernelFunc: avgPool3D$1
};

function avgPool3DGrad$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    dy: a,
    input: s
  } = t,
      {
    filterSize: o,
    strides: i,
    pad: l,
    dimRoundingMode: u
  } = r;
  assertNotComplex$1([a, s], "avgPool3DGrad");
  var c = computePool3DInfo(s.shape, o, i, 1, l, u),
      p = c.strideDepth,
      d = c.strideHeight,
      h = c.strideWidth,
      m = c.filterDepth,
      f = c.filterHeight,
      g = c.filterWidth,
      $ = c.dilationDepth,
      y = c.dilationHeight,
      b = c.dilationWidth,
      x = c.effectiveFilterDepth,
      v = c.effectiveFilterHeight,
      I = c.effectiveFilterWidth,
      C = x - 1 - c.padInfo.front,
      S = I - 1 - c.padInfo.left,
      k = v - 1 - c.padInfo.top,
      T = buffer(s.shape, "float32"),
      N = 1 / (m * f * g),
      w = n.bufferSync(a);

  for (var _e867 = 0; _e867 < c.batchSize; ++_e867) {
    for (var _t598 = 0; _t598 < c.inChannels; ++_t598) {
      for (var _n348 = 0; _n348 < c.inDepth; ++_n348) {
        for (var _r349 = 0; _r349 < c.inHeight; ++_r349) {
          for (var _a252 = 0; _a252 < c.inWidth; ++_a252) {
            var _s171 = _n348 - C,
                _o113 = _r349 - k,
                _i58 = _a252 - S;

            var _l45 = 0;

            for (var _n349 = 0; _n349 < x; _n349 += $) {
              var _r350 = (_s171 + _n349) / p;

              if (!(_r350 < 0 || _r350 >= c.outDepth || Math.floor(_r350) !== _r350)) for (var _n350 = 0; _n350 < v; _n350 += y) {
                var _a253 = (_o113 + _n350) / d;

                if (!(_a253 < 0 || _a253 >= c.outHeight || Math.floor(_a253) !== _a253)) for (var _n351 = 0; _n351 < I; _n351 += b) {
                  var _s172 = (_i58 + _n351) / h;

                  _s172 < 0 || _s172 >= c.outWidth || Math.floor(_s172) !== _s172 || (_l45 += w.get(_e867, _r350, _a253, _s172, _t598));
                }
              }
            }

            T.set(_l45 * N, _e867, _n348, _r349, _a252, _t598);
          }
        }
      }
    }
  }

  return n.makeTensorInfo(T.shape, T.dtype, T.values);
}

var avgPool3DGradConfig = {
  kernelName: AvgPool3DGrad,
  backendName: "cpu",
  kernelFunc: avgPool3DGrad$1
};

function avgPoolGrad$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    dy: a,
    input: s
  } = t,
      o = s;
  assertNotComplex$1([a, s], "avgPoolGrad");
  var {
    filterSize: i,
    strides: l,
    pad: u
  } = r,
      c = computePool2DInfo(o.shape, i, l, 1, u),
      p = c.strideHeight,
      d = c.strideWidth,
      h = c.filterHeight,
      m = c.filterWidth,
      f = c.dilationHeight,
      g = c.dilationWidth,
      $ = c.effectiveFilterHeight,
      y = c.effectiveFilterWidth,
      b = y - 1 - c.padInfo.left,
      x = $ - 1 - c.padInfo.top,
      v = buffer(o.shape, "float32"),
      I = 1 / (h * m),
      C = n.data.get(a.dataId).values,
      S = buffer(a.shape, "float32", C);

  for (var _e868 = 0; _e868 < c.batchSize; ++_e868) {
    for (var _t599 = 0; _t599 < c.inChannels; ++_t599) {
      for (var _n352 = 0; _n352 < c.inHeight; ++_n352) {
        for (var _r351 = 0; _r351 < c.inWidth; ++_r351) {
          var _a254 = _n352 - x,
              _s173 = _r351 - b;

          var _o114 = 0;

          for (var _n353 = 0; _n353 < $; _n353 += f) {
            var _r352 = (_a254 + _n353) / p;

            if (!(_r352 < 0 || _r352 >= c.outHeight || Math.floor(_r352) !== _r352)) for (var _n354 = 0; _n354 < y; _n354 += g) {
              var _a255 = (_s173 + _n354) / d;

              _a255 < 0 || _a255 >= c.outWidth || Math.floor(_a255) !== _a255 || (_o114 += S.get(_e868, _r352, _a255, _t599));
            }
          }

          v.set(_o114 * I, _e868, _n352, _r351, _t599);
        }
      }
    }
  }

  return n.makeTensorInfo(v.shape, v.dtype, v.values);
}

var avgPoolGradConfig$1 = {
  kernelName: AvgPoolGrad,
  backendName: "cpu",
  kernelFunc: avgPoolGrad$1
};

function batchNorm$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    scale: s,
    offset: o,
    mean: i,
    variance: l
  } = t;
  assert$4(i.shape.length === l.shape.length, () => "Batch normalization gradient requires mean and variance to have equal ranks."), assert$4(null == o || i.shape.length === o.shape.length, () => "Batch normalization gradient requires mean and offset to have equal ranks."), assert$4(null == s || i.shape.length === s.shape.length, () => "Batch normalization gradient requires mean and scale to have equal ranks."), assertNotComplex$1([a, i, l, s, o], "batchNorm");
  var {
    varianceEpsilon: u
  } = r;
  null == u && (u = .001);
  var c = n.data.get(a.dataId).values,
      p = n.data.get(i.dataId).values,
      d = n.data.get(l.dataId).values,
      h = s ? n.data.get(s.dataId).values : new Float32Array([1]),
      m = o ? n.data.get(o.dataId).values : new Float32Array([0]),
      f = new Float32Array(c.length),
      g = m.length,
      $ = h.length,
      y = d.length,
      b = p.length;
  var x = 0,
      v = 0,
      I = 0,
      C = 0;

  for (var _e869 = 0; _e869 < c.length; ++_e869) {
    f[_e869] = m[x++] + (c[_e869] - p[v++]) * h[I++] / Math.sqrt(d[C++] + u), x >= g && (x = 0), v >= b && (v = 0), I >= $ && (I = 0), C >= y && (C = 0);
  }

  return n.makeTensorInfo(a.shape, a.dtype, f);
}

var batchNormConfig$1 = {
  kernelName: FusedBatchNorm,
  backendName: "cpu",
  kernelFunc: batchNorm$1
};

function batchToSpaceND$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    blockShape: s,
    crops: o
  } = r;
  assertNotComplex$1([a], "batchToSpaceND");
  var i = s.reduce((e, t) => e * t),
      l = getReshaped(a.shape, s, i),
      u = getPermuted(l.length, s.length),
      c = getReshapedPermuted(a.shape, s, i),
      p = getSliceBeginCoords(o, s.length),
      d = getSliceSize(c, o, s.length),
      h = reshape$1({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      shape: l
    }
  }),
      m = transpose$1({
    inputs: {
      x: h
    },
    backend: n,
    attrs: {
      perm: u
    }
  }),
      f = reshape$1({
    inputs: {
      x: m
    },
    backend: n,
    attrs: {
      shape: c
    }
  }),
      g = slice$1({
    inputs: {
      x: f
    },
    backend: n,
    attrs: {
      begin: p,
      size: d
    }
  });
  return n.disposeIntermediateTensorInfo(h), n.disposeIntermediateTensorInfo(m), n.disposeIntermediateTensorInfo(f), g;
}

var batchToSpaceNDConfig$1 = {
  kernelName: BatchToSpaceND,
  backendName: "cpu",
  kernelFunc: batchToSpaceND$1
};

function bincount$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    weights: s
  } = t,
      {
    size: o
  } = r,
      i = bincountImpl(n.data.get(a.dataId).values, n.data.get(s.dataId).values, s.dtype, s.shape, o);
  return n.makeTensorInfo([o], s.dtype, i);
}

var bincountConfig$1 = {
  kernelName: Bincount,
  backendName: "cpu",
  kernelFunc: bincount$1
},
    clip = unaryKernelFunc$1(ClipByValue, (e, t) => e > t.clipValueMax ? t.clipValueMax : e < t.clipValueMin ? t.clipValueMin : e),
    clipConfig = {
  kernelName: ClipByValue,
  backendName: "cpu",
  kernelFunc: clip
},
    complexAbs$1 = e => {
  var {
    x: t
  } = e.inputs,
      n = e.backend,
      r = new Float32Array(sizeFromShape(t.shape)),
      a = n.data.get(t.dataId),
      s = a.complexTensorInfos.imag,
      o = n.data.get(a.complexTensorInfos.real.dataId).values,
      i = n.data.get(s.dataId).values;

  for (var _e870 = 0; _e870 < o.length; _e870++) {
    r[_e870] = Math.hypot(o[_e870], i[_e870]);
  }

  return n.makeOutput(r, t.shape, "float32");
},
    complexAbsConfig$1 = {
  kernelName: ComplexAbs,
  backendName: "cpu",
  kernelFunc: complexAbs$1
};

function imag$1(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    input: r
  } = t,
      a = n.data.get(r.dataId).complexTensorInfos.imag,
      s = n.data.get(a.dataId).values;
  return n.makeTensorInfo(a.shape, a.dtype, s);
}

var imagConfig$1 = {
  kernelName: Imag,
  backendName: "cpu",
  kernelFunc: imag$1
};

function concat$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    axis: a
  } = r,
      s = parseAxisParam(a, t[0].shape)[0];
  var o = computeOutShape$1(t.map(e => e.shape), s);
  if (0 === sizeFromShape(o)) return n.makeTensorInfo(o, t[0].dtype, []);
  var i = t.filter(e => sizeFromShape(e.shape) > 0);
  if (1 === i.length) return identity$1({
    inputs: {
      x: i[0]
    },
    backend: n
  });

  if (assertParamsConsistent(i.map(e => e.shape), s), "complex64" === i[0].dtype) {
    var _e871 = i.map(e => real$1({
      inputs: {
        input: e
      },
      backend: n
    })),
        _t600 = i.map(e => imag$1({
      inputs: {
        input: e
      },
      backend: n
    })),
        _r353 = concat$1({
      inputs: _e871,
      backend: n,
      attrs: {
        axis: s
      }
    }),
        _a256 = concat$1({
      inputs: _t600,
      backend: n,
      attrs: {
        axis: s
      }
    }),
        _o115 = complex$1({
      inputs: {
        real: _r353,
        imag: _a256
      },
      backend: n
    });

    return _e871.forEach(e => n.disposeIntermediateTensorInfo(e)), _t600.forEach(e => n.disposeIntermediateTensorInfo(e)), n.disposeIntermediateTensorInfo(_r353), n.disposeIntermediateTensorInfo(_a256), _o115;
  }

  var l = i.map(e => {
    var t = sizeFromShape(e.shape.slice(s));
    return reshape$1({
      inputs: {
        x: e
      },
      backend: n,
      attrs: {
        shape: [-1, t]
      }
    });
  }),
      u = l.map(e => ({
    vals: n.data.get(e.dataId).values,
    shape: e.shape
  }));
  o = computeOutShape$1(l.map(e => e.shape), 1);
  var c = concatImpl$1(u, o, t[0].dtype, 1 === l[0].shape[0]),
      p = computeOutShape$1(i.map(e => e.shape), s),
      d = n.makeTensorInfo(p, t[0].dtype, c);
  return l.forEach(e => n.disposeIntermediateTensorInfo(e)), d;
}

var concatConfig$1 = {
  kernelName: Concat,
  backendName: "cpu",
  kernelFunc: concat$1
};

function conv2D(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    filter: s
  } = t,
      {
    strides: o,
    pad: i,
    dataFormat: l,
    dilations: u,
    dimRoundingMode: c
  } = r;
  assertNotComplex$1([a, s], "conv2d");
  var p = convertConv2DDataFormat(l),
      d = computeConv2DInfo(a.shape, s.shape, o, u, i, c, !1, p),
      h = d.filterHeight,
      m = d.filterWidth,
      f = d.dilationHeight,
      g = d.dilationWidth,
      $ = d.padInfo.left,
      y = d.padInfo.top,
      b = "channelsLast" === d.dataFormat,
      x = new TensorBuffer(d.outShape, a.dtype),
      v = computeStrides(a.shape),
      I = computeStrides(s.shape),
      C = v[0],
      S = b ? v[1] : v[2],
      k = b ? v[2] : 1,
      T = b ? 1 : v[1],
      N = x.strides[0],
      w = b ? x.strides[1] : x.strides[2],
      E = b ? x.strides[2] : 1,
      A = b ? 1 : x.strides[1],
      D = n.data.get(a.dataId).values,
      R = n.data.get(s.dataId).values,
      _ = x.values;

  for (var _e872 = 0; _e872 < d.batchSize; ++_e872) {
    var _t601 = _e872 * C,
        _n355 = _e872 * N;

    for (var _e873 = 0; _e873 < d.outHeight; ++_e873) {
      var _r354 = _n355 + _e873 * w,
          _a257 = _e873 * d.strideHeight - y;

      for (var _e874 = 0; _e874 < h; ++_e874) {
        var _n356 = _a257 + _e874 * f;

        if (_n356 < 0 || _n356 >= d.inHeight) continue;

        var _s174 = _e874 * I[0],
            _o116 = _t601 + _n356 * S;

        for (var _e875 = 0; _e875 < d.outWidth; ++_e875) {
          var _t602 = _r354 + _e875 * E,
              _n357 = _e875 * d.strideWidth - $;

          for (var _e876 = 0; _e876 < m; ++_e876) {
            var _r355 = _n357 + _e876 * g;

            if (_r355 < 0 || _r355 >= d.inWidth) continue;

            var _a258 = _o116 + _r355 * k;

            var _i59 = _s174 + _e876 * I[1];

            for (var _e877 = 0; _e877 < d.inChannels; ++_e877) {
              var _n358 = D[_a258 + _e877 * T];

              for (var _e878 = 0; _e878 < d.outChannels; ++_e878) {
                _[_t602 + _e878 * A] += _n358 * R[_i59 + _e878];
              }

              _i59 += d.outChannels;
            }
          }
        }
      }
    }
  }

  return n.makeTensorInfo(x.shape, x.dtype, _);
}

var conv2DConfig$1 = {
  kernelName: Conv2D$1,
  backendName: "cpu",
  kernelFunc: conv2D
};

function conv2DBackpropFilter$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    dy: s
  } = t,
      {
    strides: o,
    pad: i,
    dataFormat: l,
    dimRoundingMode: u,
    filterShape: c
  } = r;
  assertNotComplex$1([a, s], "conv2dBackpropFilter");
  var p = convertConv2DDataFormat(l),
      d = computeConv2DInfo(a.shape, c, o, 1, i, u, !1, p),
      {
    strideHeight: h,
    strideWidth: m,
    filterHeight: f,
    filterWidth: g
  } = d,
      $ = "channelsLast" === d.dataFormat,
      y = new TensorBuffer(d.filterShape, "float32"),
      b = d.padInfo.left,
      x = d.padInfo.top,
      v = n.data.get(a.dataId).values,
      I = n.data.get(s.dataId).values,
      C = new TensorBuffer(a.shape, a.dtype, v),
      S = new TensorBuffer(s.shape, s.dtype, I);

  for (var _e879 = 0; _e879 < f; ++_e879) {
    var _t603 = Math.max(0, Math.ceil((x - _e879) / h)),
        _n359 = Math.min(d.outHeight, (d.inHeight + x - _e879) / h);

    for (var _r356 = 0; _r356 < g; ++_r356) {
      var _a259 = Math.max(0, Math.ceil((b - _r356) / m)),
          _s175 = Math.min(d.outWidth, (d.inWidth + b - _r356) / m);

      for (var _o117 = 0; _o117 < d.inChannels; ++_o117) {
        for (var _i60 = 0; _i60 < d.outChannels; ++_i60) {
          var _l46 = 0;

          for (var _u40 = 0; _u40 < d.batchSize; ++_u40) {
            for (var _c25 = _t603; _c25 < _n359; ++_c25) {
              var _t604 = _e879 + _c25 * h - x;

              for (var _e880 = _a259; _e880 < _s175; ++_e880) {
                var _n360 = _r356 + _e880 * m - b;

                _l46 += $ ? C.get(_u40, _t604, _n360, _o117) * S.get(_u40, _c25, _e880, _i60) : C.get(_u40, _o117, _t604, _n360) * S.get(_u40, _i60, _c25, _e880);
              }
            }
          }

          y.set(_l46, _e879, _r356, _o117, _i60);
        }
      }
    }
  }

  return n.makeTensorInfo(y.shape, y.dtype, y.values);
}

var conv2DBackpropFilterConfig$1 = {
  kernelName: Conv2DBackpropFilter,
  backendName: "cpu",
  kernelFunc: conv2DBackpropFilter$1
};

function conv2DBackpropInput$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    dy: a,
    filter: s
  } = t,
      {
    inputShape: o,
    strides: i,
    pad: l,
    dataFormat: u,
    dimRoundingMode: c
  } = r;
  assertNotComplex$1([a, s], "conv2dBackpropInput");
  var p = computeStrides(s.shape),
      d = computeStrides(a.shape);
  var h = convertConv2DDataFormat(u);
  var m = computeConv2DInfo(o, s.shape, i, 1, l, c, !1, h),
      f = new TensorBuffer(m.inShape, "float32"),
      g = f.values,
      $ = n.data.get(a.dataId).values,
      y = n.data.get(s.dataId).values,
      [b, x, v] = p,
      {
    batchSize: I,
    filterHeight: C,
    filterWidth: S,
    inChannels: k,
    inHeight: T,
    inWidth: N,
    outChannels: w,
    outHeight: E,
    outWidth: A,
    strideHeight: D,
    strideWidth: R
  } = m;
  h = m.dataFormat;

  var _ = C - 1 - m.padInfo.top,
      F = S - 1 - m.padInfo.left,
      P = "channelsLast" === h,
      O = f.strides[0],
      M = P ? f.strides[1] : f.strides[2],
      L = P ? f.strides[2] : 1,
      z = P ? 1 : f.strides[1],
      B = d[0],
      V = P ? d[1] : d[2],
      G = P ? d[2] : 1,
      U = P ? 1 : d[1];

  for (var _e881 = 0; _e881 < I; ++_e881) {
    for (var _t605 = 0; _t605 < k; ++_t605) {
      for (var _n361 = 0; _n361 < T; ++_n361) {
        var _r357 = _n361 - _,
            _a260 = Math.max(0, Math.ceil(_r357 / D)),
            _s176 = Math.min(E, (C + _r357) / D);

        for (var _o118 = 0; _o118 < N; ++_o118) {
          var _i61 = _o118 - F,
              _l47 = Math.max(0, Math.ceil(_i61 / R)),
              _u41 = Math.min(A, (S + _i61) / R);

          var _c26 = 0;

          for (var _n362 = _a260; _n362 < _s176; ++_n362) {
            var _a261 = _n362 * D - _r357;

            for (var _r358 = _l47; _r358 < _u41; ++_r358) {
              var _s177 = B * _e881 + V * _n362 + G * _r358,
                  _o119 = b * (C - 1 - _a261) + x * (S - 1 - (_r358 * R - _i61)) + v * _t605;

              for (var _e882 = 0; _e882 < w; ++_e882) {
                _c26 += $[_s177 + U * _e882] * y[_o119 + _e882];
              }
            }
          }

          g[O * _e881 + M * _n361 + L * _o118 + z * _t605] = _c26;
        }
      }
    }
  }

  return n.makeTensorInfo(f.shape, f.dtype, f.values);
}

var conv2DBackpropInputConfig$1 = {
  kernelName: Conv2DBackpropInput,
  backendName: "cpu",
  kernelFunc: conv2DBackpropInput$1
};

function conv3D$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    filter: s
  } = t,
      {
    strides: o,
    pad: i,
    dilations: l
  } = r;
  assertNotComplex$1([a, s], "conv3d");
  var u = computeConv3DInfo(a.shape, s.shape, o, l, i),
      {
    filterDepth: c,
    filterHeight: p,
    filterWidth: d,
    dilationDepth: h,
    dilationHeight: m,
    dilationWidth: f,
    padInfo: g
  } = u,
      $ = g.front,
      y = g.left,
      b = g.top,
      x = new TensorBuffer(u.outShape, a.dtype),
      v = n.data.get(a.dataId).values,
      I = n.data.get(s.dataId).values,
      C = x.values,
      S = computeStrides(a.shape),
      k = computeStrides(s.shape);

  for (var _e883 = 0; _e883 < u.batchSize; ++_e883) {
    var _t606 = _e883 * S[0],
        _n363 = _e883 * x.strides[0];

    for (var _e884 = 0; _e884 < u.outDepth; ++_e884) {
      var _r359 = _n363 + _e884 * x.strides[1],
          _a262 = _e884 * u.strideDepth - $;

      for (var _e885 = 0; _e885 < c; ++_e885) {
        var _n364 = _a262 + _e885 * h;

        if (_n364 < 0 || _n364 >= u.inDepth) continue;

        var _s178 = _e885 * k[0],
            _o120 = _t606 + _n364 * S[1];

        for (var _e886 = 0; _e886 < u.outHeight; ++_e886) {
          var _t607 = _r359 + _e886 * x.strides[2],
              _n365 = _e886 * u.strideHeight - b;

          for (var _e887 = 0; _e887 < p; ++_e887) {
            var _r360 = _n365 + _e887 * m;

            if (_r360 < 0 || _r360 >= u.inHeight) continue;

            var _a263 = _s178 + _e887 * k[1],
                _i62 = _o120 + _r360 * S[2];

            for (var _e888 = 0; _e888 < u.outWidth; ++_e888) {
              var _n366 = _t607 + _e888 * u.outChannels,
                  _r361 = _e888 * u.strideWidth - y;

              for (var _e889 = 0; _e889 < d; ++_e889) {
                var _t608 = _r361 + _e889 * f;

                if (_t608 < 0 || _t608 >= u.inWidth) continue;

                var _s179 = _i62 + _t608 * u.inChannels;

                var _o121 = _a263 + _e889 * k[2];

                for (var _e890 = 0; _e890 < u.inChannels; ++_e890) {
                  var _t609 = v[_s179 + _e890];

                  for (var _e891 = 0; _e891 < u.outChannels; ++_e891) {
                    C[_n366 + _e891] += _t609 * I[_o121 + _e891];
                  }

                  _o121 += u.outChannels;
                }
              }
            }
          }
        }
      }
    }
  }

  return n.makeTensorInfo(x.shape, x.dtype, x.values);
}

var conv3DConfig$1 = {
  kernelName: Conv3D$1,
  backendName: "cpu",
  kernelFunc: conv3D$1
};

function conv3DBackpropFilterV2$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    dy: s
  } = t,
      {
    strides: o,
    pad: i,
    filterShape: l
  } = r;
  assertNotComplex$1([a, s], "conv3dBackpropFilterV2");
  var u = computeStrides(a.shape),
      c = computeStrides(s.shape),
      p = computeConv3DInfo(a.shape, l, o, 1, i),
      d = p.strideDepth,
      h = p.strideHeight,
      m = p.strideWidth,
      f = p.filterDepth,
      g = p.filterHeight,
      $ = p.filterWidth,
      y = new TensorBuffer(p.filterShape, "float32"),
      b = y.values,
      [x, v, I, C] = y.strides,
      S = n.data.get(s.dataId).values,
      [k, T, N, w] = c,
      E = n.data.get(a.dataId).values,
      [A, D, R, _] = u,
      F = p.padInfo.front,
      P = p.padInfo.left,
      O = p.padInfo.top;

  for (var _e892 = 0; _e892 < f; ++_e892) {
    var _t610 = Math.max(0, Math.ceil((F - _e892) / d)),
        _n367 = Math.min(p.outDepth, (p.inDepth + F - _e892) / d),
        _r362 = _e892 * x;

    for (var _a264 = 0; _a264 < g; ++_a264) {
      var _s180 = Math.max(0, Math.ceil((O - _a264) / h)),
          _o122 = Math.min(p.outHeight, (p.inHeight + O - _a264) / h),
          _i63 = _a264 * v + _r362;

      for (var _r363 = 0; _r363 < $; ++_r363) {
        var _l48 = Math.max(0, Math.ceil((P - _r363) / m)),
            _u42 = Math.min(p.outWidth, (p.inWidth + P - _r363) / m),
            _c27 = _r363 * I + _i63;

        for (var _i64 = 0; _i64 < p.inChannels; ++_i64) {
          var _f12 = _i64 * C + _c27;

          for (var _c28 = 0; _c28 < p.outChannels; ++_c28) {
            var _g5 = 0;

            for (var _f13 = 0; _f13 < p.batchSize; ++_f13) {
              var _p28 = _f13 * A,
                  _$9 = _f13 * k;

              for (var _f14 = _t610; _f14 < _n367; ++_f14) {
                var _t611 = (_e892 + _f14 * d - F) * D + _p28,
                    _n368 = _f14 * T + _$9;

                for (var _e893 = _s180; _e893 < _o122; ++_e893) {
                  var _s181 = (_a264 + _e893 * h - O) * R + _t611,
                      _o123 = _e893 * N + _n368;

                  for (var _e894 = _l48; _e894 < _u42; ++_e894) {
                    _g5 += E[(_r363 + _e894 * m - P) * _ + _s181 + _i64] * S[_e894 * w + _o123 + _c28];
                  }
                }
              }
            }

            b[_f12 + _c28] = _g5;
          }
        }
      }
    }
  }

  return n.makeTensorInfo(y.shape, y.dtype, y.values);
}

var conv3DBackpropFilterV2Config$1 = {
  kernelName: Conv3DBackpropFilterV2,
  backendName: "cpu",
  kernelFunc: conv3DBackpropFilterV2$1
};

function conv3DBackpropInputV2(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    dy: a,
    filter: s
  } = t,
      {
    pad: o,
    strides: i,
    inputShape: l
  } = r;
  assertNotComplex$1([a], "conv3dBackpropInputV2");
  var u = computeStrides(a.shape),
      c = computeStrides(s.shape),
      p = computeConv3DInfo(l, s.shape, i, 1, o),
      d = new TensorBuffer(p.inShape, "float32"),
      h = d.values,
      [m, f, g, $] = d.strides,
      y = n.data.get(a.dataId).values,
      [b, x, v, I] = u,
      C = n.data.get(s.dataId).values,
      [S, k, T, N] = c,
      {
    batchSize: w,
    filterDepth: E,
    filterHeight: A,
    filterWidth: D,
    inChannels: R,
    inDepth: _,
    inHeight: F,
    inWidth: P,
    outChannels: O,
    outDepth: M,
    outHeight: L,
    outWidth: z,
    strideDepth: B,
    strideHeight: V,
    strideWidth: G
  } = p,
      U = E - 1 - p.padInfo.front,
      W = A - 1 - p.padInfo.top,
      q = D - 1 - p.padInfo.left;

  for (var _e895 = 0; _e895 < w; ++_e895) {
    for (var _t612 = 0; _t612 < R; ++_t612) {
      for (var _n369 = 0; _n369 < _; ++_n369) {
        var _r364 = _n369 - U,
            _a265 = Math.max(0, Math.ceil(_r364 / B)),
            _s182 = Math.min(M, (E + _r364) / B);

        for (var _o124 = 0; _o124 < F; ++_o124) {
          var _i65 = _o124 - W,
              _l49 = Math.max(0, Math.ceil(_i65 / V)),
              _u43 = Math.min(L, (A + _i65) / V);

          for (var _c29 = 0; _c29 < P; ++_c29) {
            var _p29 = _c29 - q,
                _d17 = Math.max(0, Math.ceil(_p29 / G)),
                _w2 = Math.min(z, (D + _p29) / G);

            var _R2 = 0;

            for (var _n370 = _a265; _n370 < _s182; ++_n370) {
              var _a266 = _n370 * B - _r364;

              for (var _r365 = _l49; _r365 < _u43; ++_r365) {
                var _s183 = _r365 * V - _i65;

                for (var _o125 = _d17; _o125 < _w2; ++_o125) {
                  var _i66 = b * _e895 + x * _n370 + v * _r365 + I * _o125,
                      _l50 = S * (E - 1 - _a266) + k * (A - 1 - _s183) + T * (D - 1 - (_o125 * G - _p29)) + N * _t612;

                  for (var _e896 = 0; _e896 < O; ++_e896) {
                    _R2 += y[_i66 + _e896] * C[_l50 + _e896];
                  }
                }
              }
            }

            h[m * _e895 + f * _n369 + g * _o124 + $ * _c29 + _t612] = _R2;
          }
        }
      }
    }
  }

  return n.makeTensorInfo(d.shape, d.dtype, d.values);
}

var conv3DBackpropInputV2Config = {
  kernelName: Conv3DBackpropInputV2,
  backendName: "cpu",
  kernelFunc: conv3DBackpropInputV2
},
    cos$1 = unaryKernelFunc$1(Cos, e => Math.cos(e)),
    cosConfig$1 = {
  kernelName: Cos,
  backendName: "cpu",
  kernelFunc: cos$1
},
    cosh$1 = unaryKernelFunc$1(Cosh, e => Math.cosh(e)),
    coshConfig$1 = {
  kernelName: Cosh,
  backendName: "cpu",
  kernelFunc: cosh$1
};

function cropAndResize$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    image: a,
    boxes: s,
    boxInd: o
  } = t,
      {
    cropSize: i,
    method: l,
    extrapolationValue: u
  } = r,
      [c, p, d, h] = a.shape,
      m = s.shape[0],
      [f, g] = i,
      $ = buffer([m, f, g, h], "float32"),
      y = n.data.get(s.dataId).values,
      b = n.data.get(o.dataId).values,
      x = n.data.get(a.dataId).values,
      v = computeStrides(a.shape),
      I = computeStrides($.shape);

  for (var _e897 = 0; _e897 < m; _e897++) {
    var _t613 = 4 * _e897,
        _n371 = y[_t613],
        _r366 = y[_t613 + 1],
        _a267 = y[_t613 + 2],
        _s184 = y[_t613 + 3],
        _o126 = b[_e897];

    if (_o126 >= c) continue;

    var _i67 = f > 1 ? (_a267 - _n371) * (p - 1) / (f - 1) : 0,
        _m6 = g > 1 ? (_s184 - _r366) * (d - 1) / (g - 1) : 0;

    for (var _t614 = 0; _t614 < f; _t614++) {
      var _c30 = f > 1 ? _n371 * (p - 1) + _t614 * _i67 : .5 * (_n371 + _a267) * (p - 1);

      if (_c30 < 0 || _c30 > p - 1) for (var _n372 = 0; _n372 < g; _n372++) {
        for (var _r367 = 0; _r367 < h; _r367++) {
          $.values[_r367 + _n372 * I[2] + _t614 * I[1] + _e897 * I[0]] = u;
        }
      } else if ("bilinear" === l) {
        var _n373 = Math.floor(_c30),
            _a268 = Math.ceil(_c30),
            _i68 = _c30 - _n373;

        for (var _l51 = 0; _l51 < g; _l51++) {
          var _c31 = g > 1 ? _r366 * (d - 1) + _l51 * _m6 : .5 * (_r366 + _s184) * (d - 1);

          if (_c31 < 0 || _c31 > d - 1) {
            for (var _n374 = 0; _n374 < h; _n374++) {
              $.values[_n374 + _l51 * I[2] + _t614 * I[1] + _e897 * I[0]] = u;
            }

            continue;
          }

          var _p30 = Math.floor(_c31),
              _f15 = Math.ceil(_c31),
              _y4 = _c31 - _p30;

          for (var _r368 = 0; _r368 < h; _r368++) {
            var _s185 = _r368 + _p30 * v[2] + _n373 * v[1] + _o126 * v[0];

            var _u44 = x[_s185];
            _s185 = _r368 + _f15 * v[2] + _n373 * v[1] + _o126 * v[0];
            var _c32 = x[_s185];
            _s185 = _r368 + _p30 * v[2] + _a268 * v[1] + _o126 * v[0];
            var _d18 = x[_s185];
            _s185 = _r368 + _f15 * v[2] + _a268 * v[1] + _o126 * v[0];

            var _h18 = x[_s185],
                _m7 = _u44 + (_c32 - _u44) * _y4;

            _s185 = _r368 + _l51 * I[2] + _t614 * I[1] + _e897 * I[0], $.values[_s185] = _m7 + (_d18 + (_h18 - _d18) * _y4 - _m7) * _i68;
          }
        }
      } else for (var _n375 = 0; _n375 < g; ++_n375) {
        var _a269 = g > 1 ? _r366 * (d - 1) + _n375 * _m6 : .5 * (_r366 + _s184) * (d - 1);

        if (_a269 < 0 || _a269 > d - 1) {
          for (var _r369 = 0; _r369 < h; _r369++) {
            $.values[_r369 + _n375 * I[2] + _t614 * I[1] + _e897 * I[0]] = u;
          }

          continue;
        }

        var _i69 = Math.round(_a269),
            _l52 = Math.round(_c30);

        for (var _r370 = 0; _r370 < h; _r370++) {
          $.values[_r370 + _n375 * I[2] + _t614 * I[1] + _e897 * I[0]] = x[_r370 + _i69 * v[2] + _l52 * v[1] + _o126 * v[0]];
        }
      }
    }
  }

  return n.makeTensorInfo($.shape, $.dtype, $.values);
}

var cropAndResizeConfig$1 = {
  kernelName: CropAndResize,
  backendName: "cpu",
  kernelFunc: cropAndResize$1
};

function cumsum$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    axis: s,
    exclusive: o,
    reverse: i
  } = r;
  assertNotComplex$1(a, "cumsum");
  var l = getAxesPermutation([s], a.shape.length);
  var u = a;
  null != l && (u = transpose$1({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      perm: l
    }
  }));
  var c = getInnerMostAxes(1, a.shape.length)[0];
  if (c !== u.shape.length - 1) throw new Error("backend.cumsum in CPU expects an inner-most axis=".concat(u.shape.length - 1, " but got axis=").concat(c));
  var p = upcastType(u.dtype, "int32"),
      d = makeZerosTypedArray(sizeFromShape(u.shape), p),
      h = n.data.get(u.dataId).values,
      m = u.shape[u.shape.length - 1],
      f = i ? (e, t) => e + m - t - 1 : (e, t) => e + t;

  for (var _e898 = 0; _e898 < h.length; _e898 += m) {
    for (var _t615 = 0; _t615 < m; _t615++) {
      var _n376 = f(_e898, _t615);

      if (0 === _t615) d[_n376] = o ? 0 : h[_n376];else {
        var _r371 = f(_e898, _t615 - 1);

        d[_n376] = o ? h[_r371] + d[_r371] : h[_n376] + d[_r371];
      }
    }
  }

  var g = n.makeTensorInfo(u.shape, p, d);

  if (null != l) {
    var _e899 = transpose$1({
      inputs: {
        x: g
      },
      backend: n,
      attrs: {
        perm: getUndoAxesPermutation(l)
      }
    });

    return n.disposeIntermediateTensorInfo(g), n.disposeIntermediateTensorInfo(u), _e899;
  }

  return g;
}

var cumsumConfig$1 = {
  kernelName: Cumsum,
  backendName: "cpu",
  kernelFunc: cumsum$1
};

function denseBincount$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    weights: s
  } = t,
      {
    size: o,
    binaryOutput: i
  } = r;

  if (1 === a.shape.length) {
    var _e900 = bincountImpl(n.data.get(a.dataId).values, n.data.get(s.dataId).values, s.dtype, s.shape, o);

    return n.makeTensorInfo([o], s.dtype, _e900);
  }

  if (2 === a.shape.length) {
    var _e901 = bincountReduceImpl(n.bufferSync(a), n.bufferSync(s), o, i);

    return n.makeTensorInfo(_e901.shape, s.dtype, _e901.values);
  }

  throw new Error("Error in denseBincount: input must be at most rank 2, but got rank".concat(a.shape.length, "."));
}

var denseBincountConfig$1 = {
  kernelName: DenseBincount,
  backendName: "cpu",
  kernelFunc: denseBincount$1
};

function depthToSpace$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    blockSize: s,
    dataFormat: o
  } = r;
  assert$4("NHWC" === o, () => "Only NHWC dataFormat supported on CPU for depthToSpace. Got ".concat(o)), assert$4(s > 1, () => "blockSize should be > 1 for depthToSpace, but was: ".concat(s));
  var i = a.shape[0],
      l = a.shape[1],
      u = a.shape[2],
      c = a.shape[3],
      p = l * s,
      d = u * s,
      h = c / (s * s),
      m = n.data.get(a.dataId).values,
      f = new Float32Array(i * p * d * h);
  var g = 0;

  for (var _e902 = 0; _e902 < i; ++_e902) {
    for (var _t616 = 0; _t616 < p; ++_t616) {
      var _n377 = Math.floor(_t616 / s),
          _r372 = _t616 % s;

      for (var _t617 = 0; _t617 < d; ++_t617) {
        var _a270 = Math.floor(_t617 / s),
            _o127 = (_r372 * s + _t617 % s) * h;

        for (var _t618 = 0; _t618 < h; ++_t618) {
          f[g++] = m[_t618 + _o127 + c * (_a270 + u * (_n377 + l * _e902))];
        }
      }
    }
  }

  return n.makeTensorInfo([i, p, d, h], a.dtype, f);
}

var depthToSpaceConfig$1 = {
  kernelName: DepthToSpace,
  backendName: "cpu",
  kernelFunc: depthToSpace$1
};

function depthwiseConv2dNative$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    filter: s
  } = t,
      {
    strides: o,
    pad: i,
    dilations: l,
    dimRoundingMode: u
  } = r;
  assertNotComplex$1([a, s], "depthwiseConv2DNative");
  var c = computeStrides(a.shape),
      p = computeStrides(s.shape);
  var d = l;
  null == d && (d = [1, 1]), assert$4(eitherStridesOrDilationsAreOne(o, d), () => "Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ".concat(o, " and dilations '").concat(d, "'"));
  var h = computeConv2DInfo(a.shape, s.shape, o, d, i, u, !0),
      {
    filterHeight: m,
    filterWidth: f,
    dilationHeight: g,
    dilationWidth: $,
    padInfo: y
  } = h,
      b = y.left,
      x = y.top,
      v = h.outChannels / h.inChannels,
      I = new TensorBuffer(h.outShape, a.dtype),
      C = n.data.get(a.dataId).values,
      S = n.data.get(s.dataId).values,
      k = I.values;

  for (var _e903 = 0; _e903 < h.batchSize; ++_e903) {
    var _t619 = _e903 * c[0],
        _n378 = _e903 * I.strides[0];

    for (var _e904 = 0; _e904 < h.outHeight; ++_e904) {
      var _r373 = _n378 + _e904 * I.strides[1],
          _a271 = _e904 * h.strideHeight - x;

      for (var _e905 = 0; _e905 < m; ++_e905) {
        var _n379 = _a271 + _e905 * g;

        if (_n379 < 0 || _n379 >= h.inHeight) continue;

        var _s186 = _e905 * p[0],
            _o128 = _t619 + _n379 * c[1];

        for (var _e906 = 0; _e906 < h.outWidth; ++_e906) {
          var _t620 = _r373 + _e906 * I.strides[2],
              _n380 = _e906 * h.strideWidth - b;

          for (var _e907 = 0; _e907 < f; ++_e907) {
            var _r374 = _n380 + _e907 * $;

            if (_r374 < 0 || _r374 >= h.inWidth) continue;

            var _a272 = _o128 + _r374 * h.inChannels;

            var _i70 = _t620,
                _l53 = _s186 + _e907 * p[1];

            for (var _e908 = 0; _e908 < h.inChannels; ++_e908) {
              var _t621 = C[_a272 + _e908];

              for (var _e909 = 0; _e909 < v; ++_e909) {
                k[_i70 + _e909] += _t621 * S[_l53 + _e909];
              }

              _i70 += v, _l53 += v;
            }
          }
        }
      }
    }
  }

  return n.makeTensorInfo(I.shape, I.dtype, I.values);
}

var depthwiseConv2dNativeConfig$1 = {
  kernelName: DepthwiseConv2dNative,
  backendName: "cpu",
  kernelFunc: depthwiseConv2dNative$1
};

function depthwiseConv2dNativeBackpropFilter$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    dy: s
  } = t,
      {
    strides: o,
    dilations: i,
    pad: l,
    dimRoundingMode: u,
    filterShape: c
  } = r;
  assertNotComplex$1([a, s], "depthwiseConv2dNativeBackpropFilter");
  var p = computeConv2DInfo(a.shape, c, o, i, l, u, !0),
      {
    strideHeight: d,
    strideWidth: h,
    filterHeight: m,
    filterWidth: f
  } = p,
      g = new TensorBuffer(p.filterShape, "float32"),
      $ = p.padInfo.left,
      y = p.padInfo.top,
      b = p.outChannels / p.inChannels,
      x = n.data.get(a.dataId).values,
      v = new TensorBuffer(a.shape, a.dtype, x),
      I = n.data.get(s.dataId).values,
      C = new TensorBuffer(s.shape, s.dtype, I);

  for (var _e910 = 0; _e910 < m; ++_e910) {
    var _t622 = Math.max(0, Math.ceil((y - _e910) / d)),
        _n381 = Math.min(p.outHeight, (p.inHeight + y - _e910) / d);

    for (var _r375 = 0; _r375 < f; ++_r375) {
      var _a273 = Math.max(0, Math.ceil(($ - _r375) / h)),
          _s187 = Math.min(p.outWidth, (p.inWidth + $ - _r375) / h);

      for (var _o129 = 0; _o129 < p.outChannels; ++_o129) {
        var _i71 = Math.trunc(_o129 / b),
            _l54 = _o129 % b;

        var _u45 = 0;

        for (var _l55 = 0; _l55 < p.batchSize; ++_l55) {
          for (var _c33 = _t622; _c33 < _n381; ++_c33) {
            var _t623 = _e910 + _c33 * d - y;

            for (var _e911 = _a273; _e911 < _s187; ++_e911) {
              _u45 += v.get(_l55, _t623, _r375 + _e911 * h - $, _i71) * C.get(_l55, _c33, _e911, _o129);
            }
          }
        }

        g.set(_u45, _e910, _r375, _i71, _l54);
      }
    }
  }

  return n.makeTensorInfo(g.shape, g.dtype, g.values);
}

var depthwiseConv2dNativeBackpropFilterConfig$1 = {
  kernelName: DepthwiseConv2dNativeBackpropFilter,
  backendName: "cpu",
  kernelFunc: depthwiseConv2dNativeBackpropFilter$1
};

function depthwiseConv2dNativeBackpropInput$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    dy: a,
    filter: s
  } = t,
      {
    strides: o,
    dilations: i,
    pad: l,
    dimRoundingMode: u,
    inputShape: c
  } = r;
  assertNotComplex$1([a, s], "depthwiseConv2DNativeBackpropInput");
  var p = computeStrides(a.shape),
      d = computeStrides(s.shape),
      h = computeConv2DInfo(c, s.shape, o, i, l, u, !0),
      m = new TensorBuffer(h.inShape, "float32"),
      f = m.values,
      [g, $, y] = m.strides,
      b = n.data.get(a.dataId).values,
      [x, v, I] = p,
      C = n.data.get(s.dataId).values,
      [S, k, T] = d,
      {
    batchSize: N,
    filterHeight: w,
    filterWidth: E,
    inChannels: A,
    inHeight: D,
    inWidth: R,
    outChannels: _,
    outHeight: F,
    outWidth: P,
    strideHeight: O,
    strideWidth: M
  } = h,
      L = w - 1 - h.padInfo.top,
      z = E - 1 - h.padInfo.left,
      B = _ / A;

  for (var _e912 = 0; _e912 < N; ++_e912) {
    for (var _t624 = 0; _t624 < A; ++_t624) {
      for (var _n382 = 0; _n382 < D; ++_n382) {
        var _r376 = _n382 - L,
            _a274 = Math.max(0, Math.ceil(_r376 / O)),
            _s188 = Math.min(F, (w + _r376) / O);

        for (var _o130 = 0; _o130 < R; ++_o130) {
          var _i72 = _o130 - z,
              _l56 = Math.max(0, Math.ceil(_i72 / M)),
              _u46 = Math.min(P, (E + _i72) / M);

          var _c34 = 0;

          for (var _n383 = _a274; _n383 < _s188; ++_n383) {
            var _a275 = _n383 * O - _r376;

            for (var _r377 = _l56; _r377 < _u46; ++_r377) {
              var _s189 = x * _e912 + v * _n383 + I * _r377,
                  _o131 = S * (w - 1 - _a275) + k * (E - 1 - (_r377 * M - _i72)) + T * _t624;

              for (var _e913 = 0; _e913 < B; ++_e913) {
                _c34 += b[_s189 + (_t624 * B + _e913)] * C[_o131 + _e913];
              }
            }
          }

          f[g * _e912 + $ * _n382 + y * _o130 + _t624] = _c34;
        }
      }
    }
  }

  return n.makeTensorInfo(m.shape, m.dtype, m.values);
}

var depthwiseConv2dNativeBackpropInputConfig$1 = {
  kernelName: DepthwiseConv2dNativeBackpropInput,
  backendName: "cpu",
  kernelFunc: depthwiseConv2dNativeBackpropInput$1
};

function diag$1(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    x: r
  } = t,
      a = sizeFromShape(r.shape),
      s = n.data.get(r.dataId).values,
      o = buffer([a, a], r.dtype),
      i = o.values;

  for (var _e914 = 0; _e914 < s.length; _e914++) {
    i[_e914 * a + _e914] = s[_e914];
  }

  var l = [...r.shape, ...r.shape];
  return n.makeTensorInfo(l, o.dtype, o.values);
}

var diagConfig$1 = {
  kernelName: Diag,
  backendName: "cpu",
  kernelFunc: diag$1
},
    dilation2dConfig = {
  kernelName: Dilation2D,
  backendName: "cpu",
  kernelFunc: _ref54 => {
    var {
      inputs: e,
      backend: t,
      attrs: n
    } = _ref54;
    var {
      x: r,
      filter: a
    } = e,
        {
      strides: s,
      pad: o,
      dilations: i
    } = n,
        l = t,
        u = l.data.get(r.dataId).values,
        c = r.shape.length,
        p = l.data.get(a.dataId).values,
        d = a.shape.length,
        {
      batchSize: h,
      inHeight: m,
      inWidth: f,
      inChannels: g,
      outHeight: $,
      outWidth: y,
      padInfo: b,
      strideHeight: x,
      strideWidth: v,
      filterHeight: I,
      filterWidth: C,
      dilationHeight: S,
      dilationWidth: k,
      outShape: T
    } = computeDilation2DInfo(r.shape, a.shape, s, o, "NHWC", i),
        N = sizeFromShape(T),
        w = T.length,
        E = getArrayFromDType(r.dtype, N);

    for (var _e915 = 0; _e915 < h; ++_e915) {
      for (var _t625 = 0; _t625 < $; ++_t625) {
        var _n384 = _t625 * x - b.top;

        for (var _s190 = 0; _s190 < y; ++_s190) {
          var _o132 = _s190 * v - b.left;

          for (var _i73 = 0; _i73 < g; ++_i73) {
            var _l57 = Number.MIN_SAFE_INTEGER;

            for (var _t626 = 0; _t626 < I; ++_t626) {
              var _s191 = _n384 + _t626 * S;

              if (_s191 >= 0 && _s191 < m) for (var _n385 = 0; _n385 < C; ++_n385) {
                var _h19 = _o132 + _n385 * k;

                if (_h19 >= 0 && _h19 < f) {
                  var _o133 = locToIndex([_e915, _s191, _h19, _i73], c, computeStrides(r.shape)),
                      _m8 = locToIndex([_t626, _n385, _i73], d, computeStrides(a.shape)),
                      _f16 = u[_o133] + p[_m8];

                  _f16 > _l57 && (_l57 = _f16);
                }
              }
            }

            E[locToIndex([_e915, _t625, _s190, _i73], w, computeStrides(T))] = _l57;
          }
        }
      }
    }

    return {
      dataId: l.write(toTypedArray(E, r.dtype), T, r.dtype),
      shape: T,
      dtype: r.dtype
    };
  }
},
    dilation2dBackpropFilterConfig = {
  kernelName: Dilation2DBackpropFilter,
  backendName: "cpu",
  kernelFunc: _ref55 => {
    var {
      inputs: e,
      backend: t,
      attrs: n
    } = _ref55;
    var {
      x: r,
      filter: a,
      dy: s
    } = e,
        {
      strides: o,
      pad: i,
      dilations: l
    } = n,
        u = t,
        c = toNestedArray(r.shape, u.data.get(r.dataId).values),
        p = toNestedArray(a.shape, u.data.get(a.dataId).values),
        {
      batchSize: d,
      inHeight: h,
      inWidth: m,
      inChannels: f,
      outHeight: g,
      outWidth: $,
      padInfo: y,
      strideHeight: b,
      strideWidth: x,
      filterHeight: v,
      filterWidth: I,
      dilationHeight: C,
      dilationWidth: S,
      outShape: k
    } = computeDilation2DInfo(r.shape, a.shape, o, i, "NHWC", l);
    assert$4(s.rank === k.length, () => "Error in ".concat(Dilation2DBackpropFilter, ", dy must have the same rank as output ").concat(k.length, ", but got ").concat(s.rank));
    var T = toNestedArray(k, u.data.get(s.dataId).values),
        N = makeZerosNestedTypedArray(a.shape, a.dtype);

    for (var _e916 = 0; _e916 < d; ++_e916) {
      for (var _t627 = 0; _t627 < g; ++_t627) {
        var _n386 = _t627 * b - y.top;

        for (var _r378 = 0; _r378 < $; ++_r378) {
          var _a276 = _r378 * x - y.left;

          for (var _s192 = 0; _s192 < f; ++_s192) {
            var _o134 = Number.MIN_SAFE_INTEGER,
                _i74 = 0,
                _l58 = 0;

            for (var _t628 = 0; _t628 < v; ++_t628) {
              var _r379 = _n386 + _t628 * C;

              if (_r379 >= 0 && _r379 < h) for (var _n387 = 0; _n387 < I; ++_n387) {
                var _u47 = _a276 + _n387 * S;

                if (_u47 >= 0 && _u47 < m) {
                  var _a277 = c[_e916][_r379][_u47][_s192] + p[_t628][_n387][_s192];

                  _a277 > _o134 && (_o134 = _a277, _i74 = _t628, _l58 = _n387);
                }
              }
            }

            N[_i74][_l58][_s192] += T[_e916][_t627][_r378][_s192];
          }
        }
      }
    }

    return {
      dataId: u.write(toTypedArray(N, r.dtype), a.shape, a.dtype),
      shape: a.shape,
      dtype: a.dtype
    };
  }
},
    dilation2dBackpropInputConfig = {
  kernelName: Dilation2DBackpropInput,
  backendName: "cpu",
  kernelFunc: _ref56 => {
    var {
      inputs: e,
      backend: t,
      attrs: n
    } = _ref56;
    var {
      x: r,
      filter: a,
      dy: s
    } = e,
        {
      strides: o,
      pad: i,
      dilations: l
    } = n,
        u = t,
        c = toNestedArray(r.shape, u.data.get(r.dataId).values),
        p = toNestedArray(a.shape, u.data.get(a.dataId).values),
        {
      batchSize: d,
      inHeight: h,
      inWidth: m,
      inChannels: f,
      outHeight: g,
      outWidth: $,
      padInfo: y,
      strideHeight: b,
      strideWidth: x,
      filterHeight: v,
      filterWidth: I,
      dilationHeight: C,
      dilationWidth: S,
      outShape: k
    } = computeDilation2DInfo(r.shape, a.shape, o, i, "NHWC", l);
    assert$4(s.rank === k.length, () => "Error in ".concat(Dilation2DBackpropInput, ", dy must have the same rank as output ").concat(k.length, ", but got ").concat(s.rank));
    var T = toNestedArray(k, u.data.get(s.dataId).values),
        N = makeZerosNestedTypedArray(r.shape, r.dtype);

    for (var _e917 = 0; _e917 < d; ++_e917) {
      for (var _t629 = 0; _t629 < g; ++_t629) {
        var _n388 = _t629 * b - y.top;

        for (var _r380 = 0; _r380 < $; ++_r380) {
          var _a278 = _r380 * x - y.left;

          for (var _s193 = 0; _s193 < f; ++_s193) {
            var _o135 = Number.MIN_SAFE_INTEGER,
                _i75 = _n388 < 0 ? 0 : _n388,
                _l59 = _a278 < 0 ? 0 : _a278;

            for (var _t630 = 0; _t630 < v; ++_t630) {
              var _r381 = _n388 + _t630 * C;

              if (_r381 >= 0 && _r381 < h) for (var _n389 = 0; _n389 < I; ++_n389) {
                var _u48 = _a278 + _n389 * S;

                if (_u48 >= 0 && _u48 < m) {
                  var _a279 = c[_e917][_r381][_u48][_s193] + p[_t630][_n389][_s193];

                  _a279 > _o135 && (_o135 = _a279, _i75 = _r381, _l59 = _u48);
                }
              }
            }

            N[_e917][_i75][_l59][_s193] += T[_e917][_t629][_r380][_s193];
          }
        }
      }
    }

    return {
      dataId: u.write(toTypedArray(N, r.dtype), r.shape, r.dtype),
      shape: r.shape,
      dtype: r.dtype
    };
  }
};

function sum$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    axis: s,
    keepDims: o
  } = r;
  var i;
  assertNotComplex$1(a, "sum"), i = "bool" === a.dtype ? cast$1({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      dtype: "int32"
    }
  }) : identity$1({
    inputs: {
      x: a
    },
    backend: n
  });
  var l = i.shape.length,
      u = parseAxisParam(s, i.shape),
      c = getAxesPermutation(u, l);
  var p = u,
      d = i;
  null != c && (d = transpose$1({
    inputs: {
      x: i
    },
    backend: n,
    attrs: {
      perm: c
    }
  }), p = getInnerMostAxes(p.length, l)), assertAxesAreInnerMostDims("sum", p, d.shape.length);
  var [h, m] = computeOutAndReduceShapes(d.shape, p);
  var f = zeros(n, h, upcastType(d.dtype, "int32"));
  var g = sizeFromShape(m),
      $ = n.data.get(f.dataId).values,
      y = n.data.get(d.dataId).values;

  for (var _e918 = 0; _e918 < $.length; ++_e918) {
    var _t631 = _e918 * g;

    var _n390 = 0;

    for (var _e919 = 0; _e919 < g; ++_e919) {
      _n390 += y[_t631 + _e919];
    }

    $[_e918] = _n390;
  }

  if (o) {
    var _e920 = f;
    f = reshape$1({
      inputs: {
        x: f
      },
      backend: n,
      attrs: {
        shape: expandShapeToKeepDim(f.shape, u)
      }
    }), n.disposeIntermediateTensorInfo(_e920);
  }

  return n.disposeIntermediateTensorInfo(i), null != c && n.disposeIntermediateTensorInfo(d), f;
}

var sumConfig$1 = {
  kernelName: Sum,
  backendName: "cpu",
  kernelFunc: sum$1
};

function einsum$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    equation: a
  } = r,
      s = t,
      {
    allDims: o,
    summedDims: i,
    idDims: l
  } = decodeEinsumEquation(a, s.length);
  checkEinsumDimSizes(o.length, l, s);
  var {
    path: u,
    steps: c
  } = getEinsumComputePath(i, l),
      p = c.length;
  var d = null,
      h = o.length;
  var m = [];

  for (var _e921 = 0; _e921 < p; ++_e921) {
    for (var _t632 of c[_e921]) {
      var {
        permutationIndices: _e922,
        expandDims: _r382
      } = getEinsumPermutation(h, l[_t632]);

      var _a280 = void 0;

      isIdentityPermutation(_e922) ? _a280 = s[_t632] : (_a280 = transpose$1({
        inputs: {
          x: s[_t632]
        },
        backend: n,
        attrs: {
          perm: _e922
        }
      }), m.push(_a280));

      var _o136 = _a280.shape.slice();

      for (var _e923 = 0; _e923 < _r382.length; ++_e923) {
        _o136.splice(_r382[_e923], 0, 1);
      }

      arraysEqual(_a280.shape, _o136) || (_a280 = reshape$1({
        inputs: {
          x: _a280
        },
        backend: n,
        attrs: {
          shape: _o136
        }
      }), m.push(_a280)), null === d ? d = _a280 : (d = multiply$1({
        inputs: {
          a: _a280,
          b: d
        },
        backend: n
      }), m.push(d));
    }

    _e921 < p - 1 && (u[_e921] >= 0 && (d = sum$1({
      inputs: {
        x: d
      },
      backend: n,
      attrs: {
        axis: u[_e921] - (o.length - h),
        keepDims: !1
      }
    }), m.push(d)), h--);
  }

  for (var _e924 of m) {
    _e924 !== d && n.disposeIntermediateTensorInfo(_e924);
  }

  return d;
}

var einsumConfig$1 = {
  kernelName: Einsum,
  backendName: "cpu",
  kernelFunc: einsum$1
};

function eluGrad$1(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    dy: r,
    y: a
  } = t;
  assertNotComplex$1([r, a], "eluGrad");
  var s = new Float32Array(sizeFromShape(a.shape)),
      o = n.data.get(a.dataId).values,
      i = n.data.get(r.dataId).values;

  for (var _e925 = 0; _e925 < o.length; ++_e925) {
    var _t633 = o[_e925];
    s[_e925] = _t633 >= 1 ? i[_e925] : i[_e925] * (_t633 + 1);
  }

  return n.makeTensorInfo(a.shape, "float32", s);
}

var eluGradConfig$1 = {
  kernelName: EluGrad,
  backendName: "cpu",
  kernelFunc: eluGrad$1
},
    p = ERF_P,
    a1 = ERF_A1,
    a2 = ERF_A2,
    a3 = ERF_A3,
    a4 = ERF_A4,
    a5 = ERF_A5,
    erf$1 = unaryKernelFunc$1(Erf, e => {
  var t = Math.sign(e),
      n = Math.abs(e),
      r = 1 / (1 + p * n);
  return t * (1 - ((((a5 * r + a4) * r + a3) * r + a2) * r + a1) * r * Math.exp(-n * n));
}),
    erfConfig$1 = {
  kernelName: Erf,
  backendName: "cpu",
  kernelFunc: erf$1
};

function expandDims$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    input: a
  } = t,
      {
    dim: s
  } = r,
      o = a.shape.length,
      i = a.shape.slice();
  var l = s;
  return s < 0 && (assert$4(-(o + 1) <= s, () => "Axis must be in the interval [".concat(-(o + 1), ", ").concat(o, "]")), l = o + s + 1), i.splice(l, 0, 1), reshape$1({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      shape: i
    }
  });
}

var expandDimsConfig$1 = {
  kernelName: ExpandDims,
  backendName: "cpu",
  kernelFunc: expandDims$1
},
    realDivImpl = createSimpleBinaryKernelImpl((e, t) => e / t),
    div = binaryKernelFunc$1(RealDiv, realDivImpl),
    realDivConfig$1 = {
  kernelName: RealDiv,
  backendName: "cpu",
  kernelFunc: div
};

function fftBatch(e, t, n) {
  var r = e.shape,
      a = r[0],
      s = r[1],
      o = n.data.get(e.dataId),
      i = o.complexTensorInfos.real,
      l = o.complexTensorInfos.imag,
      u = [a, s],
      c = sizeFromShape(u),
      p = getTypedArrayFromDType("float32", c),
      d = getTypedArrayFromDType("float32", c);

  for (var _e926 = 0; _e926 < a; _e926++) {
    var _r383 = slice$1({
      inputs: {
        x: i
      },
      backend: n,
      attrs: {
        begin: [_e926, 0],
        size: [1, s]
      }
    }),
        _a281 = slice$1({
      inputs: {
        x: l
      },
      backend: n,
      attrs: {
        begin: [_e926, 0],
        size: [1, s]
      }
    }),
        _o137 = complex$1({
      inputs: {
        real: _r383,
        imag: _a281
      },
      backend: n
    }),
        {
      real: _u49,
      imag: _c35
    } = fftImpl$1(_o137, t, n),
        _h20 = mergeRealAndImagArrays(_u49, _c35);

    for (var _t634 = 0; _t634 < s; _t634++) {
      var _n391 = getComplexWithIndex(_h20, _t634);

      p[_e926 * s + _t634] = _n391.real, d[_e926 * s + _t634] = _n391.imag;
    }

    n.disposeIntermediateTensorInfo(_r383), n.disposeIntermediateTensorInfo(_a281), n.disposeIntermediateTensorInfo(_o137);
  }

  var h = n.makeTensorInfo(u, "float32", p),
      m = n.makeTensorInfo(u, "float32", d),
      f = complex$1({
    inputs: {
      real: h,
      imag: m
    },
    backend: n
  });
  return n.disposeIntermediateTensorInfo(h), n.disposeIntermediateTensorInfo(m), f;
}

function fftImpl$1(e, t, n) {
  var r = sizeFromShape(e.shape),
      a = n.data.get(e.dataId),
      s = n.data.get(a.complexTensorInfos.real.dataId).values,
      o = n.data.get(a.complexTensorInfos.imag.dataId).values;

  if (isExponentOf2(r)) {
    var _a282 = fftRadix2(s, o, r, t, n),
        i = [e.shape[0], e.shape[1]];

    if (t) {
      var _e927 = n.makeTensorInfo(i, "float32", _a282.real),
          _t635 = n.makeTensorInfo(i, "float32", _a282.imag),
          _s194 = n.makeTensorInfo([], "float32", createScalarValue(r, "float32")),
          _o138 = identity$1({
        inputs: {
          x: _s194
        },
        backend: n
      }),
          l = realDivConfig$1.kernelFunc({
        inputs: {
          a: _e927,
          b: _s194
        },
        backend: n
      }),
          u = realDivConfig$1.kernelFunc({
        inputs: {
          a: _t635,
          b: _o138
        },
        backend: n
      }),
          c = n.data.get(l.dataId).values,
          _p31 = n.data.get(u.dataId).values;

      return n.disposeIntermediateTensorInfo(_e927), n.disposeIntermediateTensorInfo(_t635), n.disposeIntermediateTensorInfo(_s194), n.disposeIntermediateTensorInfo(_o138), n.disposeIntermediateTensorInfo(l), n.disposeIntermediateTensorInfo(u), {
        real: c,
        imag: _p31
      };
    }

    return _a282;
  }

  return splitRealAndImagArrays(fourierTransformByMatmul(mergeRealAndImagArrays(s, o), r, t));
}

function isExponentOf2(e) {
  return 0 == (e & e - 1);
}

function fftRadix2(e, t, n, r, a) {
  if (1 === n) return {
    real: e,
    imag: t
  };

  var s = mergeRealAndImagArrays(e, t),
      o = n / 2,
      i = complexWithEvenIndex(s),
      l = i.real,
      u = i.imag,
      c = [l.length],
      p = a.makeTensorInfo(c, "float32", l),
      d = a.makeTensorInfo(c, "float32", u),
      h = complex$1({
    inputs: {
      real: p,
      imag: d
    },
    backend: a
  }),
      m = complexWithOddIndex(s),
      f = m.real,
      g = m.imag,
      $ = [f.length],
      y = a.makeTensorInfo($, "float32", f),
      b = a.makeTensorInfo($, "float32", g),
      x = complex$1({
    inputs: {
      real: y,
      imag: b
    },
    backend: a
  }),
      v = fftRadix2(l, u, o, r, a),
      I = v.real,
      C = v.imag,
      S = [I.length],
      k = a.makeTensorInfo(S, "float32", I),
      T = a.makeTensorInfo(S, "float32", C),
      N = complex$1({
    inputs: {
      real: k,
      imag: T
    },
    backend: a
  }),
      w = fftRadix2(f, g, o, r, a),
      E = w.real,
      A = w.imag,
      D = [E.length],
      R = a.makeTensorInfo(D, "float32", E),
      _ = a.makeTensorInfo(D, "float32", A),
      F = complex$1({
    inputs: {
      real: R,
      imag: _
    },
    backend: a
  }),
      P = exponents(n, r),
      O = [P.real.length],
      M = a.makeTensorInfo(O, "float32", P.real),
      L = a.makeTensorInfo(O, "float32", P.imag),
      z = complex$1({
    inputs: {
      real: M,
      imag: L
    },
    backend: a
  }),
      B = multiply$1({
    inputs: {
      a: z,
      b: F
    },
    backend: a
  }),
      V = add({
    inputs: {
      a: N,
      b: B
    },
    backend: a
  }),
      G = sub$1({
    inputs: {
      a: N,
      b: B
    },
    backend: a
  }),
      U = real$1({
    inputs: {
      input: V
    },
    backend: a
  }),
      W = real$1({
    inputs: {
      input: G
    },
    backend: a
  }),
      q = imag$1({
    inputs: {
      input: V
    },
    backend: a
  }),
      H = imag$1({
    inputs: {
      input: G
    },
    backend: a
  }),
      K = concat$1({
    inputs: [U, W],
    backend: a,
    attrs: {
      axis: 0
    }
  }),
      j = concat$1({
    inputs: [q, H],
    backend: a,
    attrs: {
      axis: 0
    }
  }),
      X = a.data.get(K.dataId).values,
      Y = a.data.get(j.dataId).values;

  return a.disposeIntermediateTensorInfo(p), a.disposeIntermediateTensorInfo(d), a.disposeIntermediateTensorInfo(h), a.disposeIntermediateTensorInfo(y), a.disposeIntermediateTensorInfo(b), a.disposeIntermediateTensorInfo(x), a.disposeIntermediateTensorInfo(k), a.disposeIntermediateTensorInfo(T), a.disposeIntermediateTensorInfo(N), a.disposeIntermediateTensorInfo(R), a.disposeIntermediateTensorInfo(_), a.disposeIntermediateTensorInfo(F), a.disposeIntermediateTensorInfo(M), a.disposeIntermediateTensorInfo(L), a.disposeIntermediateTensorInfo(z), a.disposeIntermediateTensorInfo(B), a.disposeIntermediateTensorInfo(V), a.disposeIntermediateTensorInfo(G), a.disposeIntermediateTensorInfo(U), a.disposeIntermediateTensorInfo(q), a.disposeIntermediateTensorInfo(W), a.disposeIntermediateTensorInfo(H), a.disposeIntermediateTensorInfo(K), a.disposeIntermediateTensorInfo(j), {
    real: X,
    imag: Y
  };
}

function fourierTransformByMatmul(e, t, n) {
  var r = new Float32Array(2 * t);

  for (var a = 0; a < t; a++) {
    var s = 0,
        o = 0;

    for (var _r384 = 0; _r384 < t; _r384++) {
      var i = exponent(a * _r384, t, n),
          l = getComplexWithIndex(e, _r384);
      s += l.real * i.real - l.imag * i.imag, o += l.real * i.imag + l.imag * i.real;
    }

    n && (s /= t, o /= t), assignToTypedArray(r, s, o, a);
  }

  return r;
}

function fft$1(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    input: r
  } = t,
      a = sizeFromShape(r.shape),
      s = r.shape[r.shape.length - 1],
      o = reshape$1({
    inputs: {
      x: r
    },
    backend: n,
    attrs: {
      shape: [a / s, s]
    }
  }),
      i = fftBatch(o, !1, n),
      l = reshape$1({
    inputs: {
      x: i
    },
    backend: n,
    attrs: {
      shape: r.shape
    }
  });
  return n.disposeIntermediateTensorInfo(o), n.disposeIntermediateTensorInfo(i), l;
}

var fftConfig$1 = {
  kernelName: FFT,
  backendName: "cpu",
  kernelFunc: fft$1
};

function fill$1(e) {
  var {
    backend: t,
    attrs: n
  } = e,
      {
    shape: r,
    value: a,
    dtype: s
  } = n,
      o = s || inferDtype(a),
      i = getArrayFromDType(o, sizeFromShape(r));
  return fillValues(i, a, o), t.makeTensorInfo(r, o, i);
}

var fillConfig$1 = {
  kernelName: Fill,
  backendName: "cpu",
  kernelFunc: fill$1
};

function fillValues(e, t, n) {
  e.fill(t);
}

var flipLeftRightConfig$1 = {
  kernelName: FlipLeftRight,
  backendName: "cpu",
  kernelFunc: _ref57 => {
    var {
      inputs: e,
      backend: t
    } = _ref57;
    var {
      image: n
    } = e,
        r = t,
        a = getTypedArrayFromDType(n.dtype, sizeFromShape(n.shape)),
        [s, o, i, l] = n.shape,
        u = r.data.get(n.dataId).values;

    for (var _e928 = 0; _e928 < s; _e928++) {
      var _t636 = _e928 * i * o * l;

      for (var _e929 = 0; _e929 < o; _e929++) {
        var _n392 = _e929 * (i * l);

        for (var _e930 = 0; _e930 < i; _e930++) {
          var _r385 = _e930 * l;

          for (var _s195 = 0; _s195 < l; _s195++) {
            var _o139 = Math.round(i - _e930 - 1),
                c = _t636 + _n392 + _r385 + _s195;

            var _p32 = u[c];
            _o139 >= 0 && _o139 < i && (_p32 = u[_t636 + _n392 + _o139 * l + _s195]), a[c] = _p32;
          }
        }
      }
    }

    return {
      dataId: r.write(a, n.shape, n.dtype),
      shape: n.shape,
      dtype: n.dtype
    };
  }
},
    floorDivImpl = createSimpleBinaryKernelImpl((e, t) => Math.floor(e / t)),
    floorDiv$1 = binaryKernelFunc$1(FloorDiv, floorDivImpl, null, "int32"),
    floorDivConfig$1 = {
  kernelName: FloorDiv,
  backendName: "cpu",
  kernelFunc: floorDiv$1
};

function fusedConv2D(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    filter: s,
    bias: o,
    preluActivationWeights: i
  } = t,
      {
    strides: l,
    pad: u,
    dataFormat: c,
    dilations: p,
    dimRoundingMode: d,
    activation: h,
    leakyreluAlpha: m
  } = r;
  var f = conv2D({
    inputs: {
      x: a,
      filter: s
    },
    backend: n,
    attrs: {
      strides: l,
      pad: u,
      dataFormat: c,
      dilations: p,
      dimRoundingMode: d
    }
  });

  if (o) {
    var _e931 = f;
    f = add({
      inputs: {
        a: f,
        b: o
      },
      backend: n
    }), n.disposeIntermediateTensorInfo(_e931);
  }

  if (h) {
    var _e932 = f;
    f = applyActivation(n, f, h, i, m), n.disposeIntermediateTensorInfo(_e932);
  }

  return f;
}

var fusedConv2DConfig$1 = {
  kernelName: FusedConv2D,
  backendName: "cpu",
  kernelFunc: fusedConv2D
};

function fusedDepthwiseConv2D$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    filter: s,
    bias: o,
    preluActivationWeights: i
  } = t,
      {
    strides: l,
    pad: u,
    dataFormat: c,
    dilations: p,
    dimRoundingMode: d,
    activation: h,
    leakyreluAlpha: m
  } = r;
  var f = depthwiseConv2dNative$1({
    inputs: {
      x: a,
      filter: s
    },
    backend: n,
    attrs: {
      strides: l,
      pad: u,
      dataFormat: c,
      dilations: p,
      dimRoundingMode: d
    }
  });

  if (o) {
    var _e933 = f;
    f = add({
      inputs: {
        a: f,
        b: o
      },
      backend: n
    }), n.disposeIntermediateTensorInfo(_e933);
  }

  if (h) {
    var _e934 = f;
    f = applyActivation(n, f, h, i, m), n.disposeIntermediateTensorInfo(_e934);
  }

  return f;
}

var fusedDepthwiseConv2DConfig$1 = {
  kernelName: FusedDepthwiseConv2D,
  backendName: "cpu",
  kernelFunc: fusedDepthwiseConv2D$1
};

function gatherNd$1(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    params: r,
    indices: a
  } = t,
      s = sizeFromShape(r.shape),
      o = a.shape,
      i = o[o.length - 1],
      [l, u, c, p] = prepareAndValidate(r, a);
  if (0 === u) return n.makeTensorInfo(l, r.dtype, []);
  var d = gatherNdImpl(n.data.get(a.dataId).values, n.bufferSync(r), r.dtype, u, i, c, p, r.shape, s);
  return n.makeTensorInfo(l, r.dtype, d.values);
}

var gatherNdConfig$1 = {
  kernelName: GatherNd,
  backendName: "cpu",
  kernelFunc: gatherNd$1
};

function gatherV2$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    indices: s
  } = t,
      {
    axis: o,
    batchDims: i
  } = r;
  assertNotComplex$1([a, s], "gatherV2");
  var l = i;
  null == i && (l = 0);
  var u = sizeFromShape(s.shape),
      c = collectGatherOpShapeInfo(a, s, parseAxisParam(o, a.shape)[0], l),
      p = reshape$1({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      shape: [c.batchSize, c.outerSize, c.dimSize, c.sliceSize]
    }
  }),
      d = reshape$1({
    inputs: {
      x: s
    },
    backend: n,
    attrs: {
      shape: [c.batchSize, u / c.batchSize]
    }
  }),
      h = [c.batchSize, c.outerSize, u / c.batchSize, c.sliceSize],
      m = n.bufferSync(d),
      f = gatherV2Impl(n.bufferSync(p), m, h);
  return n.disposeIntermediateTensorInfo(p), n.disposeIntermediateTensorInfo(d), n.makeTensorInfo(c.outputShape, f.dtype, f.values);
}

var gatherV2Config$1 = {
  kernelName: GatherV2,
  backendName: "cpu",
  kernelFunc: gatherV2$1
};

function ifft$1(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    input: r
  } = t,
      a = sizeFromShape(r.shape),
      s = r.shape[r.shape.length - 1],
      o = reshape$1({
    inputs: {
      x: r
    },
    backend: n,
    attrs: {
      shape: [a / s, s]
    }
  }),
      i = fftBatch(o, !0, n),
      l = reshape$1({
    inputs: {
      x: i
    },
    backend: n,
    attrs: {
      shape: r.shape
    }
  });
  return n.disposeIntermediateTensorInfo(o), n.disposeIntermediateTensorInfo(i), l;
}

var ifftConfig$1 = {
  kernelName: IFFT,
  backendName: "cpu",
  kernelFunc: ifft$1
},
    isFinite$2 = unaryKernelFunc$1(IsFinite, e => Number.isFinite(e) ? 1 : 0, "bool"),
    isFiniteConfig$1 = {
  kernelName: IsFinite,
  backendName: "cpu",
  kernelFunc: isFinite$2
},
    isInf$1 = unaryKernelFunc$1(IsInf, e => Infinity === Math.abs(e) ? 1 : 0, "bool"),
    isInfConfig$1 = {
  kernelName: IsInf,
  backendName: "cpu",
  kernelFunc: isInf$1
},
    isNaN$2 = unaryKernelFunc$1(IsNan, e => Number.isNaN(e) ? 1 : 0, "bool"),
    isNaNConfig$1 = {
  kernelName: IsNan,
  backendName: "cpu",
  kernelFunc: isNaN$2
};

function linSpace$1(e) {
  var {
    backend: t,
    attrs: n
  } = e,
      {
    start: r,
    stop: a,
    num: s
  } = n,
      o = linSpaceImpl(r, a, s);
  return t.makeTensorInfo([o.length], "float32", o);
}

var linSpaceConfig$1 = {
  kernelName: LinSpace,
  backendName: "cpu",
  kernelFunc: linSpace$1
},
    log1p$1 = unaryKernelFunc$1(Log1p, e => Math.log1p(e)),
    log1pConfig$1 = {
  kernelName: Log1p,
  backendName: "cpu",
  kernelFunc: log1p$1
},
    logicalAndImpl = createSimpleBinaryKernelImpl((e, t) => e && t),
    logicalAnd$1 = binaryKernelFunc$1(LogicalAnd, logicalAndImpl, null, "bool"),
    logicalAndConfig$1 = {
  kernelName: LogicalAnd,
  backendName: "cpu",
  kernelFunc: logicalAnd$1
},
    logicalNot$1 = unaryKernelFunc$1(LogicalNot, e => e ? 0 : 1, "bool"),
    logicalNotConfig$1 = {
  kernelName: LogicalNot,
  backendName: "cpu",
  kernelFunc: logicalNot$1
},
    logicalOrImpl = createSimpleBinaryKernelImpl((e, t) => e || t),
    logicalOr$1 = binaryKernelFunc$1(LogicalOr, logicalOrImpl, null, "bool"),
    logicalOrConfig$1 = {
  kernelName: LogicalOr,
  backendName: "cpu",
  kernelFunc: logicalOr$1
};

function lRN(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    depthRadius: s,
    bias: o,
    alpha: i,
    beta: l
  } = r;
  assertNotComplex$1(a, "LRN");
  var u = a.shape[3],
      c = u - 1,
      p = n.data.get(a.dataId).values,
      d = sizeFromShape(a.shape),
      h = new Float32Array(d);

  function m(e) {
    var t = e % u;
    var n = e - t + Math.max(0, t - s);
    var r = e - t + Math.min(t + s, c);
    var a = 0;

    for (; n <= r; n++) {
      var _e935 = p[n];
      a += _e935 * _e935;
    }

    return a;
  }

  for (var _e936 = 0; _e936 < d; _e936++) {
    var _t637 = m(_e936),
        _n393 = p[_e936] * Math.pow(o + i * _t637, -l);

    h[_e936] = _n393;
  }

  return n.makeTensorInfo(a.shape, a.dtype, h);
}

var lRNConfig = {
  kernelName: LRN,
  backendName: "cpu",
  kernelFunc: lRN
};

function lRNGrad(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    y: s,
    dy: o
  } = t,
      {
    depthRadius: i,
    bias: l,
    alpha: u,
    beta: c
  } = r;
  assertNotComplex$1(o, "LRNGrad");
  var p = sizeFromShape(o.shape),
      d = o.shape[3],
      h = n.data.get(o.dataId).values,
      m = n.data.get(a.dataId).values,
      f = n.data.get(s.dataId).values,
      g = new Float32Array(p),
      $ = p;

  for (var _e937 = 0; _e937 < $; _e937++) {
    var _t638 = _e937 % d,
        _n394 = _e937 - _t638 + Math.max(0, _t638 - i),
        _r386 = _e937 - _t638 + Math.min(d, _t638 + i + 1);

    var _a283 = 0;

    for (var _e938 = _n394; _e938 < _r386; _e938++) {
      _a283 += Math.pow(m[_e938], 2);
    }

    _a283 = u * _a283 + l;

    for (var _t639 = _n394; _t639 < _r386; _t639++) {
      var _n395 = -2 * u * c * m[_t639] * f[_e937] / _a283;

      _e937 === _t639 && (_n395 += Math.pow(_a283, -c)), _n395 *= h[_e937], g[_t639] += _n395;
    }
  }

  return n.makeTensorInfo(o.shape, a.dtype, g);
}

var lRNGradConfig = {
  kernelName: LRNGrad,
  backendName: "cpu",
  kernelFunc: lRNGrad
};

function max$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    reductionIndices: s,
    keepDims: o
  } = r,
      i = n;
  var l = a.shape;
  var u = l.length,
      c = parseAxisParam(s, l);
  var p = c;
  var d = getAxesPermutation(p, u);
  var h = i.data.get(a.dataId).values;

  if (null != d) {
    var _e939 = new Array(u);

    for (var _t640 = 0; _t640 < _e939.length; _t640++) {
      _e939[_t640] = l[d[_t640]];
    }

    h = transposeImpl$1(h, l, a.dtype, d, _e939), p = getInnerMostAxes(p.length, u), l = _e939;
  }

  assertNotComplex$1(a, "max"), assertAxesAreInnerMostDims("max", p, u);
  var [m, f] = computeOutAndReduceShapes(l, p),
      g = maxImpl$1(h, sizeFromShape(f), m, a.dtype),
      $ = i.write(g, m, a.dtype);
  var y = m;
  return o && (y = expandShapeToKeepDim(m, c)), {
    dataId: $,
    shape: y,
    dtype: a.dtype
  };
}

var maxConfig$1 = {
  kernelName: Max,
  backendName: "cpu",
  kernelFunc: max$1
};

function maxPool$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t;
  assertNotComplex$1(a, "maxPool");
  var {
    filterSize: s,
    strides: o,
    pad: i,
    dimRoundingMode: l
  } = r;
  assert$4(eitherStridesOrDilationsAreOne(o, 1), () => "Error in maxPool: Either strides or dilations must be 1. Got strides ".concat(o, " and dilations '1'"));
  var u = computePool2DInfo(a.shape, s, o, 1, i, l);
  var c;
  if (1 === u.filterWidth && 1 === u.filterHeight && arraysEqual(u.inShape, u.outShape)) c = identity$1({
    inputs: {
      x: a
    },
    backend: n
  });else {
    var _e940 = n.data.get(a.dataId).values,
        _t641 = computeStrides(a.shape),
        _r387 = pool(_e940, a.shape, a.dtype, _t641, u, "max");

    c = n.makeTensorInfo(u.outShape, a.dtype, _r387.values);
  }
  return c;
}

var maxPoolConfig$1 = {
  kernelName: MaxPool,
  backendName: "cpu",
  kernelFunc: maxPool$1
};

function maxPool3D(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    filterSize: s,
    strides: o,
    pad: i,
    dimRoundingMode: l,
    dataFormat: u
  } = r;
  assertNotComplex$1(a, "maxPool3d");
  var c = computePool3DInfo(a.shape, s, o, 1, i, l, u),
      p = pool3d(n.data.get(a.dataId).values, a.shape, a.dtype, computeStrides(a.shape), c, "max");
  return n.makeTensorInfo(p.shape, "float32", p.values);
}

var maxPool3DConfig$1 = {
  kernelName: MaxPool3D,
  backendName: "cpu",
  kernelFunc: maxPool3D
};

function maxPool3DGrad$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    dy: a,
    input: s
  } = t,
      {
    filterSize: o,
    strides: i,
    pad: l,
    dimRoundingMode: u
  } = r;
  assertNotComplex$1([a, s], "maxPool3DGrad");
  var c = computePool3DInfo(s.shape, o, i, 1, l, u),
      p = maxPool3dPositions(n.bufferSync(s), c),
      d = c.strideDepth,
      h = c.strideHeight,
      m = c.strideWidth,
      f = c.dilationDepth,
      g = c.dilationHeight,
      $ = c.dilationWidth,
      y = c.effectiveFilterDepth,
      b = c.effectiveFilterHeight,
      x = c.effectiveFilterWidth,
      v = y - 1 - c.padInfo.front,
      I = x - 1 - c.padInfo.left,
      C = b - 1 - c.padInfo.top,
      S = buffer(s.shape, "float32"),
      k = n.bufferSync(a);

  for (var _e941 = 0; _e941 < c.batchSize; ++_e941) {
    for (var _t642 = 0; _t642 < c.inChannels; ++_t642) {
      for (var _n396 = 0; _n396 < c.inDepth; ++_n396) {
        for (var _r388 = 0; _r388 < c.inHeight; ++_r388) {
          for (var _a284 = 0; _a284 < c.inWidth; ++_a284) {
            var _s196 = _n396 - v,
                _o140 = _r388 - C,
                _i76 = _a284 - I;

            var _l60 = 0;

            for (var _n397 = 0; _n397 < y; _n397 += f) {
              var _r389 = (_s196 + _n397) / d;

              if (!(_r389 < 0 || _r389 >= c.outDepth || Math.floor(_r389) !== _r389)) for (var _a285 = 0; _a285 < b; _a285 += g) {
                var _s197 = (_o140 + _a285) / h;

                if (!(_s197 < 0 || _s197 >= c.outHeight || Math.floor(_s197) !== _s197)) for (var _o141 = 0; _o141 < x; _o141 += $) {
                  var _u50 = (_i76 + _o141) / m;

                  if (_u50 < 0 || _u50 >= c.outWidth || Math.floor(_u50) !== _u50) continue;

                  var _d19 = y * b * x - 1 - p.get(_e941, _r389, _s197, _u50, _t642) === _n397 * b * x + _a285 * x + _o141 ? 1 : 0;

                  0 !== _d19 && (_l60 += k.get(_e941, _r389, _s197, _u50, _t642) * _d19);
                }
              }
            }

            S.set(_l60, _e941, _n396, _r388, _a284, _t642);
          }
        }
      }
    }
  }

  return n.makeTensorInfo(S.shape, S.dtype, S.values);
}

var maxPool3DGradConfig = {
  kernelName: MaxPool3DGrad,
  backendName: "cpu",
  kernelFunc: maxPool3DGrad$1
};

function maxPoolGrad$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    dy: a,
    input: s,
    output: o
  } = t,
      i = s;
  assertNotComplex$1([s, o], "maxPoolGrad");
  var {
    filterSize: l,
    strides: u,
    pad: c,
    dimRoundingMode: p
  } = r,
      d = computePool2DInfo(i.shape, l, u, 1, c, p),
      h = n.data.get(i.dataId).values,
      m = buffer(d.outShape, i.dtype, maxPoolPositions(h, i.shape, i.dtype, d).values),
      f = d.strideHeight,
      g = d.strideWidth,
      $ = d.dilationHeight,
      y = d.dilationWidth,
      b = d.effectiveFilterHeight,
      x = d.effectiveFilterWidth,
      v = x - 1 - d.padInfo.left,
      I = b - 1 - d.padInfo.top,
      C = buffer(i.shape, "float32"),
      S = n.data.get(a.dataId).values,
      k = buffer(a.shape, "float32", S);

  for (var _e942 = 0; _e942 < d.batchSize; ++_e942) {
    for (var _t643 = 0; _t643 < d.inChannels; ++_t643) {
      for (var _n398 = 0; _n398 < d.inHeight; ++_n398) {
        for (var _r390 = 0; _r390 < d.inWidth; ++_r390) {
          var _a286 = _n398 - I,
              _s198 = _r390 - v;

          var _o142 = 0;

          for (var _n399 = 0; _n399 < b; _n399 += $) {
            var _r391 = (_a286 + _n399) / f;

            if (!(_r391 < 0 || _r391 >= d.outHeight || Math.floor(_r391) !== _r391)) for (var _a287 = 0; _a287 < x; _a287 += y) {
              var _i77 = (_s198 + _a287) / g;

              if (_i77 < 0 || _i77 >= d.outWidth || Math.floor(_i77) !== _i77) continue;

              var _l61 = b * x - 1 - m.get(_e942, _r391, _i77, _t643) === _n399 * x + _a287 ? 1 : 0;

              0 !== _l61 && (_o142 += k.get(_e942, _r391, _i77, _t643) * _l61);
            }
          }

          C.set(_o142, _e942, _n398, _r390, _t643);
        }
      }
    }
  }

  return n.makeTensorInfo(C.shape, C.dtype, C.values);
}

var maxPoolGradConfig$1 = {
  kernelName: MaxPoolGrad,
  backendName: "cpu",
  kernelFunc: maxPoolGrad$1
};

function maxPoolWithArgmaxImpl$1(e, t, n, r, a) {
  var s = pool(e, t, n, computeStrides(t), a, "max"),
      o = maxPoolPositions(e, t, n, a, !0, r);
  return [s.values, o.values];
}

var maxPoolWithArgmaxConfig$1 = {
  kernelName: MaxPoolWithArgmax,
  backendName: "cpu",
  kernelFunc: _ref58 => {
    var {
      inputs: e,
      attrs: t,
      backend: n
    } = _ref58;
    var {
      x: r
    } = e,
        {
      filterSize: a,
      strides: s,
      pad: o,
      includeBatchInIndex: i
    } = t,
        l = n;
    assertNotComplex$1(r, "MaxPoolWithArgmax");
    var u = l.data.get(r.dataId).values,
        c = computePool2DInfo(r.shape, a, s, [1, 1], o),
        [p, d] = maxPoolWithArgmaxImpl$1(u, r.shape, r.dtype, i, c),
        h = l.write(p, c.outShape, r.dtype),
        m = l.write(d, c.outShape, r.dtype);
    return [{
      dataId: h,
      shape: c.outShape,
      dtype: r.dtype
    }, {
      dataId: m,
      shape: c.outShape,
      dtype: "int32"
    }];
  }
};

function mean(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    axis: s,
    keepDims: o
  } = r,
      i = parseAxisParam(s, a.shape),
      l = sizeFromShape(computeOutAndReduceShapes(a.shape, i)[1]),
      u = [],
      c = n.makeTensorInfo([], "float32", new Float32Array([l]));
  u.push(c);
  var p = cast$1({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      dtype: "float32"
    }
  });
  u.push(p);
  var d = div({
    inputs: {
      a: p,
      b: c
    },
    backend: n
  });
  u.push(d);
  var h = sum$1({
    inputs: {
      x: d
    },
    backend: n,
    attrs: {
      axis: s,
      keepDims: o
    }
  });
  return u.forEach(e => n.disposeIntermediateTensorInfo(e)), h;
}

var meanConfig$1 = {
  kernelName: Mean,
  backendName: "cpu",
  kernelFunc: mean
};

function min$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    axis: s,
    keepDims: o
  } = r;
  assertNotComplex$1(a, "min");
  var i = parseAxisParam(s, a.shape);
  var l = i;
  var u = getAxesPermutation(l, a.shape.length);
  var c = a;
  null != u && (c = transpose$1({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      perm: u
    }
  }), l = getInnerMostAxes(l.length, a.shape.length)), assertAxesAreInnerMostDims("min", l, c.shape.length);
  var [p, d] = computeOutAndReduceShapes(c.shape, l),
      h = sizeFromShape(d),
      m = makeZerosTypedArray(sizeFromShape(p), c.dtype),
      f = n.data.get(c.dataId).values;

  for (var _e943 = 0; _e943 < m.length; ++_e943) {
    var _t644 = _e943 * h;

    var _n400 = f[_t644];

    for (var _e944 = 0; _e944 < h; ++_e944) {
      var _r392 = f[_t644 + _e944];
      (Number.isNaN(_r392) || _r392 < _n400) && (_n400 = _r392);
    }

    m[_e943] = _n400;
  }

  null != u && n.disposeIntermediateTensorInfo(c);
  var g = n.makeTensorInfo(p, c.dtype, m);

  if (o) {
    var _e945 = reshape$1({
      inputs: {
        x: g
      },
      backend: n,
      attrs: {
        shape: expandShapeToKeepDim(p, i)
      }
    });

    return n.disposeIntermediateTensorInfo(g), _e945;
  }

  return g;
}

var minConfig$1 = {
  kernelName: Min,
  backendName: "cpu",
  kernelFunc: min$1
};

function mirrorPad(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    paddings: s,
    mode: o
  } = r;
  assertNotComplex$1(a, "mirrorPad");
  var i = s.map((e, t) => e[0] + a.shape[t] + e[1]),
      l = s.map(e => e[0]),
      u = s.map((e, t) => e[0] + a.shape[t]),
      c = "reflect" === o ? 0 : 1,
      p = n.data.get(a.dataId).values,
      d = a.shape.length,
      h = computeStrides(a.shape),
      m = sizeFromShape(i),
      f = i.length,
      g = computeStrides(i),
      $ = getTypedArrayFromDType(a.dtype, m);

  for (var _e946 = 0; _e946 < m; _e946++) {
    var _t645 = indexToLoc(_e946, f, g);

    for (var _e947 = 0; _e947 < f; _e947++) {
      _t645[_e947] < l[_e947] ? _t645[_e947] = 2 * l[_e947] - _t645[_e947] - c : _t645[_e947] >= u[_e947] && (_t645[_e947] = 2 * (u[_e947] - 1) - _t645[_e947] + c);
    }

    _t645 = _t645.map((e, t) => e - l[t]);

    var _n401 = locToIndex(_t645, d, h);

    $[_e946] = p[_n401];
  }

  return {
    dataId: n.write($, i, a.dtype),
    shape: i,
    dtype: a.dtype
  };
}

var mirrorPadConfig$1 = {
  kernelName: MirrorPad,
  backendName: "cpu",
  kernelFunc: mirrorPad
},
    modImpl = createSimpleBinaryKernelImpl((e, t) => {
  var n = e % t;
  return e < 0 && t < 0 || e >= 0 && t >= 0 ? n : (n + t) % t;
}),
    mod$1 = binaryKernelFunc$1(Mod, modImpl),
    modConfig$1 = {
  kernelName: Mod,
  backendName: "cpu",
  kernelFunc: mod$1
};

function softmax$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    logits: a
  } = t,
      {
    dim: s
  } = r,
      o = a.shape.length;
  var i = s;
  if (-1 === i && (i = o - 1), i !== o - 1) throw Error("Softmax along a non-last dimension is not yet supported. Logits was rank ".concat(o, " and dim was ").concat(i));
  var l = parseAxisParam([i], a.shape),
      u = max$1({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      reductionIndices: l,
      keepDims: !1
    }
  }),
      c = expandShapeToKeepDim(u.shape, l),
      p = reshape$1({
    inputs: {
      x: u
    },
    backend: n,
    attrs: {
      shape: c
    }
  }),
      d = sub$1({
    inputs: {
      a,
      b: p
    },
    backend: n
  }),
      h = exp$1({
    inputs: {
      x: d
    },
    backend: n
  }),
      m = sum$1({
    inputs: {
      x: h
    },
    backend: n,
    attrs: {
      axis: l,
      keepDims: !1
    }
  }),
      f = reshape$1({
    inputs: {
      x: m
    },
    backend: n,
    attrs: {
      shape: c
    }
  }),
      g = div({
    inputs: {
      a: h,
      b: f
    },
    backend: n
  });
  return n.disposeIntermediateTensorInfo(u), n.disposeIntermediateTensorInfo(p), n.disposeIntermediateTensorInfo(d), n.disposeIntermediateTensorInfo(h), n.disposeIntermediateTensorInfo(m), n.disposeIntermediateTensorInfo(f), g;
}

var softmaxConfig$1 = {
  kernelName: Softmax$2,
  backendName: "cpu",
  kernelFunc: softmax$1
};

function multinomial$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    logits: a
  } = t,
      {
    numSamples: s,
    seed: o,
    normalized: i
  } = r;
  assertNotComplex$1(a, "multinomial");
  var l = i ? a : softmax$1({
    inputs: {
      logits: a
    },
    backend: n,
    attrs: {
      dim: -1
    }
  }),
      u = l.shape[0],
      c = l.shape[1],
      p = n.data.get(l.dataId).values,
      d = [u, s],
      h = makeZerosTypedArray(sizeFromShape(d), "int32");

  for (var _e948 = 0; _e948 < u; ++_e948) {
    var _t646 = _e948 * c,
        _n402 = new Float32Array(c - 1);

    _n402[0] = p[_t646];

    for (var _e949 = 1; _e949 < _n402.length; ++_e949) {
      _n402[_e949] = _n402[_e949 - 1] + p[_t646 + _e949];
    }

    var _r393 = seedrandom.alea(o.toString()),
        _a288 = _e948 * s;

    for (var _e950 = 0; _e950 < s; ++_e950) {
      var _t647 = _r393();

      h[_a288 + _e950] = _n402.length;

      for (var _r394 = 0; _r394 < _n402.length; _r394++) {
        if (_t647 < _n402[_r394]) {
          h[_a288 + _e950] = _r394;
          break;
        }
      }
    }
  }

  return i || n.disposeIntermediateTensorInfo(l), n.makeTensorInfo(d, "int32", h);
}

var multinomialConfig$1 = {
  kernelName: Multinomial,
  backendName: "cpu",
  kernelFunc: multinomial$1
},
    nonMaxSuppressionV3Impl$1 = nonMaxSuppressionV3Impl$2;

function nonMaxSuppressionV3$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    boxes: a,
    scores: s
  } = t,
      {
    maxOutputSize: o,
    iouThreshold: i,
    scoreThreshold: l
  } = r;
  assertNotComplex$1(a, "NonMaxSuppression");
  var u = n.data.get(a.dataId).values,
      c = n.data.get(s.dataId).values,
      {
    selectedIndices: p
  } = nonMaxSuppressionV3Impl$1(u, c, o, i, l);
  return n.makeTensorInfo([p.length], "int32", new Int32Array(p));
}

var nonMaxSuppressionV3Config$1 = {
  kernelName: NonMaxSuppressionV3,
  backendName: "cpu",
  kernelFunc: nonMaxSuppressionV3$1
},
    nonMaxSuppressionV4Impl$1 = nonMaxSuppressionV4Impl$2;

function nonMaxSuppressionV4$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    boxes: a,
    scores: s
  } = t,
      {
    maxOutputSize: o,
    iouThreshold: i,
    scoreThreshold: l,
    padToMaxOutputSize: u
  } = r;
  assertNotComplex$1(a, "NonMaxSuppressionPadded");
  var c = n.data.get(a.dataId).values,
      p = n.data.get(s.dataId).values,
      {
    selectedIndices: d,
    validOutputs: h
  } = nonMaxSuppressionV4Impl$1(c, p, o, i, l, u);
  return [n.makeTensorInfo([d.length], "int32", new Int32Array(d)), n.makeTensorInfo([], "int32", new Int32Array([h]))];
}

var nonMaxSuppressionV4Config$1 = {
  kernelName: NonMaxSuppressionV4,
  backendName: "cpu",
  kernelFunc: nonMaxSuppressionV4$1
},
    nonMaxSuppressionV5Impl$1 = nonMaxSuppressionV5Impl$2;

function nonMaxSuppressionV5$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    boxes: a,
    scores: s
  } = t,
      {
    maxOutputSize: o,
    iouThreshold: i,
    scoreThreshold: l,
    softNmsSigma: u
  } = r;
  assertNotComplex$1(a, "NonMaxSuppressionWithScore");
  var c = n.data.get(a.dataId).values,
      p = n.data.get(s.dataId).values,
      d = o,
      h = i,
      m = l,
      f = u,
      {
    selectedIndices: g,
    selectedScores: $
  } = nonMaxSuppressionV5Impl$1(c, p, d, h, m, f);
  return [n.makeTensorInfo([g.length], "int32", new Int32Array(g)), n.makeTensorInfo([$.length], "float32", new Float32Array($))];
}

var nonMaxSuppressionV5Config$1 = {
  kernelName: NonMaxSuppressionV5,
  backendName: "cpu",
  kernelFunc: nonMaxSuppressionV5$1
};

function oneHot$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    indices: a
  } = t,
      {
    depth: s,
    onValue: o,
    offValue: i
  } = r;
  assertNotComplex$1(a, "oneHot");
  var l = sizeFromShape(a.shape),
      u = new Float32Array(l * s);
  u.fill(i);
  var c = n.data.get(a.dataId).values;

  for (var _e951 = 0; _e951 < l; ++_e951) {
    c[_e951] >= 0 && c[_e951] < s && (u[_e951 * s + c[_e951]] = o);
  }

  return n.makeTensorInfo([...a.shape, s], "int32", u);
}

var oneHotConfig$1 = {
  kernelName: OneHot,
  backendName: "cpu",
  kernelFunc: oneHot$1
};

function zerosLike$1(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    x: r
  } = t;
  if ("string" === r.dtype) throw new Error("zerosLike is not supported for string tensors");

  if ("complex64" === r.dtype) {
    var _e952 = real$1({
      inputs: {
        input: r
      },
      backend: n
    }),
        _t648 = zerosLike$1({
      inputs: {
        x: _e952
      },
      backend: n
    }),
        a = imag$1({
      inputs: {
        input: r
      },
      backend: n
    }),
        s = zerosLike$1({
      inputs: {
        x: a
      },
      backend: n
    }),
        o = complex$1({
      inputs: {
        real: _t648,
        imag: s
      },
      backend: n
    });

    return n.disposeIntermediateTensorInfo(_e952), n.disposeIntermediateTensorInfo(_t648), n.disposeIntermediateTensorInfo(a), n.disposeIntermediateTensorInfo(s), o;
  }

  return fill$1({
    backend: n,
    attrs: {
      shape: r.shape,
      value: 0,
      dtype: r.dtype
    }
  });
}

var zerosLikeConfig$1 = {
  kernelName: ZerosLike,
  backendName: "cpu",
  kernelFunc: zerosLike$1
};

function onesLike$1(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    x: r
  } = t;
  if ("string" === r.dtype) throw new Error("onesLike is not supported for string tensors");

  if ("complex64" === r.dtype) {
    var _e953 = real$1({
      inputs: {
        input: r
      },
      backend: n
    }),
        _t649 = onesLike$1({
      inputs: {
        x: _e953
      },
      backend: n
    }),
        a = imag$1({
      inputs: {
        input: r
      },
      backend: n
    }),
        s = zerosLike$1({
      inputs: {
        x: a
      },
      backend: n
    }),
        o = complex$1({
      inputs: {
        real: _t649,
        imag: s
      },
      backend: n
    });

    return n.disposeIntermediateTensorInfo(_e953), n.disposeIntermediateTensorInfo(_t649), n.disposeIntermediateTensorInfo(a), n.disposeIntermediateTensorInfo(s), o;
  }

  return fill$1({
    backend: n,
    attrs: {
      shape: r.shape,
      value: 1,
      dtype: r.dtype
    }
  });
}

var onesLikeConfig$1 = {
  kernelName: OnesLike,
  backendName: "cpu",
  kernelFunc: onesLike$1
};

function pack$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    axis: a
  } = r;
  if (1 === t.length) return expandDims$1({
    inputs: {
      input: t[0]
    },
    backend: n,
    attrs: {
      dim: a
    }
  });
  var s = t[0].shape,
      o = t[0].dtype;
  t.forEach(e => {
    assertShapesMatch(s, e.shape, "All tensors passed to stack must have matching shapes"), assert$4(o === e.dtype, () => "All tensors passed to stack must have matching dtypes");
  });
  var i = [],
      l = concat$1({
    inputs: t.map(e => {
      var t = expandDims$1({
        inputs: {
          input: e
        },
        backend: n,
        attrs: {
          dim: a
        }
      });
      return i.push(t), t;
    }),
    backend: n,
    attrs: {
      axis: a
    }
  });
  return i.forEach(e => n.disposeIntermediateTensorInfo(e)), l;
}

var packConfig$1 = {
  kernelName: Pack,
  backendName: "cpu",
  kernelFunc: pack$1
};

function padV2$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    paddings: s,
    constantValue: o
  } = r;
  assertNotComplex$1(a, "pad");
  var i = s.map((e, t) => e[0] + a.shape[t] + e[1]),
      l = s.map(e => e[0]),
      u = n.data.get(a.dataId).values,
      c = sizeFromShape(a.shape),
      p = a.shape.length,
      d = computeStrides(a.shape),
      h = sizeFromShape(i),
      m = i.length,
      f = computeStrides(i),
      g = getTypedArrayFromDType(a.dtype, h);
  0 !== o && g.fill(o);

  for (var _e954 = 0; _e954 < c; _e954++) {
    g[locToIndex(indexToLoc(_e954, p, d).map((e, t) => e + l[t]), m, f)] = u[_e954];
  }

  return {
    dataId: n.write(g, i, a.dtype),
    shape: i,
    dtype: a.dtype
  };
}

var padV2Config$1 = {
  kernelName: PadV2,
  backendName: "cpu",
  kernelFunc: padV2$1
},
    powImpl = createSimpleBinaryKernelImpl((e, t) => Math.pow(e, t)),
    pow$1 = binaryKernelFunc$1(Pow, powImpl),
    powConfig$1 = {
  kernelName: Pow,
  backendName: "cpu",
  kernelFunc: pow$1
};

function range$2(e) {
  var {
    backend: t,
    attrs: n
  } = e,
      {
    start: r,
    stop: a,
    dtype: s,
    step: o
  } = n,
      i = rangeImpl(r, a, o, s);
  return t.makeTensorInfo([i.length], s, i);
}

var rangeConfig$1 = {
  kernelName: Range,
  backendName: "cpu",
  kernelFunc: range$2
},
    reciprocal$1 = unaryKernelFunc$1(Reciprocal, e => 1 / e),
    reciprocalConfig$1 = {
  kernelName: Reciprocal,
  backendName: "cpu",
  kernelFunc: reciprocal$1
};

function resizeBilinear$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    images: a
  } = t,
      {
    alignCorners: s,
    halfPixelCenters: o,
    size: i
  } = r;
  assertNotComplex$1(a, "resizeBilinear");
  var l = computeStrides(a.shape),
      [u, c] = i,
      [p, d, h, m] = a.shape,
      f = n.data.get(a.dataId).values,
      g = new Float32Array(sizeFromShape([p, u, c, m])),
      $ = [s && u > 1 ? d - 1 : d, s && c > 1 ? h - 1 : h],
      y = [s && u > 1 ? u - 1 : u, s && c > 1 ? c - 1 : c];
  var b = 0;
  var x = $[0] / y[0],
      v = $[1] / y[1];

  for (var _e955 = 0; _e955 < p; _e955++) {
    for (var _t650 = 0; _t650 < u; _t650++) {
      var _n403 = void 0;

      _n403 = o ? x * (_t650 + .5) - .5 : x * _t650;

      var _r395 = Math.max(0, Math.floor(_n403)),
          _a289 = _n403 - _r395,
          _s199 = Math.min(d - 1, Math.ceil(_n403)),
          _i78 = _e955 * l[0] + _r395 * l[1],
          _u51 = _e955 * l[0] + _s199 * l[1];

      for (var _e956 = 0; _e956 < c; _e956++) {
        var _t651 = void 0;

        _t651 = o ? v * (_e956 + .5) - .5 : v * _e956;

        var _n404 = Math.max(0, Math.floor(_t651)),
            _r396 = _t651 - _n404,
            _s200 = Math.min(h - 1, Math.ceil(_t651)),
            _c36 = _i78 + _n404 * l[2],
            _p33 = _u51 + _n404 * l[2],
            _d20 = _i78 + _s200 * l[2],
            _$10 = _u51 + _s200 * l[2];

        for (var _e957 = 0; _e957 < m; _e957++) {
          var _t652 = f[_c36 + _e957],
              _n405 = f[_p33 + _e957],
              _s201 = _t652 + (f[_d20 + _e957] - _t652) * _r396;

          g[b++] = _s201 + (_n405 + (f[_$10 + _e957] - _n405) * _r396 - _s201) * _a289;
        }
      }
    }
  }

  return n.makeTensorInfo([p, u, c, m], "float32", g);
}

var resizeBilinearConfig$1 = {
  kernelName: ResizeBilinear,
  backendName: "cpu",
  kernelFunc: resizeBilinear$1
};

function resizeBilinearGrad$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    images: a,
    dy: s
  } = t,
      {
    alignCorners: o
  } = r;
  assertNotComplex$1([s, a], "resizeBilinearGrad");
  var i = computeStrides(a.shape),
      [l, u, c, p] = a.shape,
      [, d, h] = s.shape,
      m = new Float32Array(l * u * c * p),
      f = [o && d > 1 ? u - 1 : u, o && h > 1 ? c - 1 : c],
      g = [o && d > 1 ? d - 1 : d, o && h > 1 ? h - 1 : h],
      $ = f[0] / g[0],
      y = f[1] / g[1],
      b = n.data.get(s.dataId).values;
  var x = 0;

  for (var _e958 = 0; _e958 < l; _e958++) {
    var _t653 = _e958 * i[0];

    for (var _e959 = 0; _e959 < d; _e959++) {
      var _n406 = _e959 * $,
          _r397 = Math.floor(_n406),
          _a290 = Math.min(Math.ceil(_n406), u - 1),
          _s202 = _t653 + _r397 * i[1],
          _o143 = _t653 + _a290 * i[1],
          _l62 = _n406 - _r397,
          _d21 = 1 - _l62;

      for (var _e960 = 0; _e960 < h; _e960++) {
        var _t654 = _e960 * y,
            _n407 = Math.floor(_t654),
            _r398 = Math.min(Math.ceil(_t654), c - 1),
            _a291 = _t654 - _n407,
            _u52 = 1 - _a291,
            _h21 = _s202 + _n407 * i[2],
            _f17 = _s202 + _r398 * i[2],
            _g6 = _o143 + _n407 * i[2],
            _$11 = _o143 + _r398 * i[2],
            v = _d21 * _u52,
            I = _d21 * _a291,
            C = _l62 * _u52,
            S = _l62 * _a291;

        for (var _e961 = 0; _e961 < p; _e961++) {
          var _t655 = b[x++];
          m[_h21 + _e961] += _t655 * v, m[_f17 + _e961] += _t655 * I, m[_g6 + _e961] += _t655 * C, m[_$11 + _e961] += _t655 * S;
        }
      }
    }
  }

  return n.makeTensorInfo([l, c, u, p], "float32", m);
}

var resizeBilinearGradConfig$1 = {
  kernelName: ResizeBilinearGrad,
  backendName: "cpu",
  kernelFunc: resizeBilinearGrad$1
};

function resizeNearestNeighbor$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    images: a
  } = t,
      {
    alignCorners: s,
    halfPixelCenters: o,
    size: i
  } = r;
  assertNotComplex$1(a, "resizeNearestNeighbor");
  var l = computeStrides(a.shape),
      [u, c] = i,
      [p, d, h, m] = a.shape,
      f = n.data.get(a.dataId).values,
      g = new Float32Array(p * u * c * m),
      $ = [s && u > 1 ? d - 1 : d, s && c > 1 ? h - 1 : h],
      y = [s && u > 1 ? u - 1 : u, s && c > 1 ? c - 1 : c],
      b = $[0] / y[0],
      x = $[1] / y[1];
  var v = 0;

  for (var _e962 = 0; _e962 < p; _e962++) {
    var _t656 = _e962 * l[0];

    for (var _e963 = 0; _e963 < u; _e963++) {
      var _n408 = o ? b * (_e963 + .5) : b * _e963;

      var _r399 = Math.min(d - 1, s ? Math.round(_n408) : Math.floor(_n408));

      o && (_r399 = Math.max(0, _r399));

      var _a292 = _t656 + _r399 * l[1];

      for (var _e964 = 0; _e964 < c; _e964++) {
        var _t657 = o ? x * (_e964 + .5) : x * _e964;

        var _n409 = Math.min(h - 1, s ? Math.round(_t657) : Math.floor(_t657));

        o && (_n409 = Math.max(0, _n409));

        var _r400 = _a292 + _n409 * l[2];

        for (var _e965 = 0; _e965 < m; _e965++) {
          g[v++] = f[_r400 + _e965];
        }
      }
    }
  }

  return n.makeTensorInfo([p, u, c, m], a.dtype, g);
}

var resizeNearestNeighborConfig$1 = {
  kernelName: ResizeNearestNeighbor,
  backendName: "cpu",
  kernelFunc: resizeNearestNeighbor$1
};

function resizeNearestNeighborGrad$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    images: a,
    dy: s
  } = t,
      {
    alignCorners: o
  } = r;
  assertNotComplex$1([s, a], "resizeNearestNeighborGrad");
  var i = computeStrides(a.shape),
      l = computeStrides(s.shape),
      [u, c, p, d] = a.shape,
      [, h, m] = s.shape,
      f = new Float32Array(u * c * p * d),
      g = n.data.get(s.dataId).values,
      $ = [o && h > 1 ? c - 1 : c, o && m > 1 ? p - 1 : p],
      y = [o && h > 1 ? h - 1 : h, o && m > 1 ? m - 1 : m],
      b = $[0] / y[0],
      x = $[1] / y[1],
      v = 1 / b,
      I = 1 / x,
      C = 2 * Math.ceil(v) + 2,
      S = 2 * Math.ceil(I) + 2;

  for (var _e966 = 0; _e966 < u; _e966++) {
    var _t658 = _e966 * i[0];

    for (var _e967 = 0; _e967 < c; _e967++) {
      var _n410 = _t658 + _e967 * i[1],
          _r401 = Math.floor(_e967 * v),
          _a293 = Math.floor(_r401 - C / 2);

      for (var _r402 = 0; _r402 < p; _r402++) {
        var _s203 = _n410 + _r402 * i[2],
            _u53 = Math.floor(_r402 * I),
            _$12 = Math.floor(_u53 - S / 2);

        for (var _n411 = 0; _n411 < d; _n411++) {
          var _i79 = 0;

          for (var _s204 = 0; _s204 < C; _s204++) {
            var _u54 = _s204 + _a293;

            if (_u54 < 0 || _u54 >= h) continue;

            var _d22 = _t658 + _u54 * l[1],
                _f18 = _u54 * b;

            if (_e967 === Math.min(c - 1, o ? Math.round(_f18) : Math.floor(_f18))) for (var _e968 = 0; _e968 < S; _e968++) {
              var _t659 = _e968 + _$12;

              if (_t659 < 0 || _t659 >= m) continue;

              var _a294 = _d22 + _t659 * l[2],
                  _s205 = _t659 * x;

              _r402 === Math.min(p - 1, o ? Math.round(_s205) : Math.floor(_s205)) && (_i79 += g[_a294 + _n411]);
            }
          }

          f[_s203 + _n411] = _i79;
        }
      }
    }
  }

  return n.makeTensorInfo(a.shape, a.dtype, f);
}

var resizeNearestNeighborGradConfig$1 = {
  kernelName: ResizeNearestNeighborGrad,
  backendName: "cpu",
  kernelFunc: resizeNearestNeighborGrad$1
};

function reverse$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    dims: s
  } = r;
  assertNotComplex$1(a, "reverse");
  var o = a.shape.length,
      i = parseAxisParam(s, a.shape);
  if (0 === o) return identity$1({
    inputs: {
      x: a
    },
    backend: n
  });
  var l = new TensorBuffer(a.shape, a.dtype),
      u = n.bufferSync(a);

  var _loop57 = function _loop57(_e969) {
    var t = l.indexToLoc(_e969),
        n = t.slice();
    i.forEach(e => n[e] = a.shape[e] - 1 - n[e]), l.set(u.get(...n), ...t);
  };

  for (var _e969 = 0; _e969 < l.size; _e969++) {
    _loop57(_e969);
  }

  return n.makeTensorInfo(l.shape, l.dtype, l.values);
}

var reverseConfig$1 = {
  kernelName: Reverse,
  backendName: "cpu",
  kernelFunc: reverse$1
},
    rotateWithOffsetConfig$1 = {
  kernelName: RotateWithOffset,
  backendName: "cpu",
  kernelFunc: _ref59 => {
    var {
      inputs: e,
      attrs: t,
      backend: n
    } = _ref59;
    var {
      image: r
    } = e,
        {
      radians: a,
      fillValue: s,
      center: o
    } = t,
        i = n,
        l = getTypedArrayFromDType(r.dtype, sizeFromShape(r.shape)),
        [u, c, p, d] = r.shape,
        [h, m] = getImageCenter(o, c, p),
        f = Math.sin(a),
        g = Math.cos(a),
        $ = i.data.get(r.dataId).values;

    for (var _e970 = 0; _e970 < u; _e970++) {
      var _t660 = _e970 * p * c * d;

      for (var _e971 = 0; _e971 < c; _e971++) {
        var _n412 = _e971 * (p * d);

        for (var _r403 = 0; _r403 < p; _r403++) {
          var _a295 = _r403 * d;

          for (var _o144 = 0; _o144 < d; _o144++) {
            var _i80 = [u, _e971, _r403, _o144],
                y = _i80[2],
                b = _i80[1];
            var x = (y - h) * g - (b - m) * f,
                v = (y - h) * f + (b - m) * g;
            x = Math.round(x + h), v = Math.round(v + m);
            var I = s;
            "number" != typeof s && (I = 3 === _o144 ? 255 : s[_o144]), x >= 0 && x < p && v >= 0 && v < c && (I = $[_t660 + v * (p * d) + x * d + _o144]), l[_t660 + _n412 + _a295 + _o144] = I;
          }
        }
      }
    }

    return {
      dataId: i.write(l, r.shape, r.dtype),
      shape: r.shape,
      dtype: r.dtype
    };
  }
},
    round$1 = unaryKernelFunc$1(Round, e => {
  var t = Math.floor(e);
  return e - t < .5 ? Math.floor(e) : e - t > .5 ? Math.ceil(e) : t % 2 == 0 ? t : t + 1;
}),
    roundConfig$1 = {
  kernelName: Round,
  backendName: "cpu",
  kernelFunc: round$1
};

function scatterImpl(e, t, n, r, a, s, o, i, l, u) {
  var c = [r / a, a],
      p = e.values,
      d = t.values;
  if (0 === r) return buffer(n, t.dtype);
  var h = buffer(c, t.dtype);
  h.values.fill(l);

  for (var _e972 = 0; _e972 < s; _e972++) {
    var _s206 = [];
    var _l63 = 0;

    for (var _t661 = 0; _t661 < o; _t661++) {
      var _n413 = p[_e972 * o + _t661];
      _s206.push(_n413), _l63 += _n413 * i[_t661];
    }

    if (_l63 < 0 || _l63 >= r / a) throw new Error("Invalid indices: ".concat(_s206, " does not index into ").concat(n));

    for (var _n414 = 0; _n414 < a; _n414++) {
      u ? h.values[_l63 * a + _n414] += d[_e972 * a + _n414] : h.values[_l63 * a + _n414] = 0 === t.rank ? d[0] : d[_e972 * a + _n414];
    }
  }

  return h;
}

function scatterNd$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    indices: a,
    updates: s
  } = t,
      {
    shape: o
  } = r,
      {
    sliceRank: i,
    numUpdates: l,
    sliceSize: u,
    strides: c,
    outputSize: p
  } = calculateShapes(s, a, o),
      d = scatterImpl(n.bufferSync(a), n.bufferSync(s), o, p, u, l, i, c, 0, !0);
  return n.makeTensorInfo(o, d.dtype, d.values);
}

var scatterNdConfig$1 = {
  kernelName: ScatterNd,
  backendName: "cpu",
  kernelFunc: scatterNd$1
};

function select$1(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    condition: r,
    t: a,
    e: s
  } = t;
  assertNotComplex$1([r, a, s], "select");
  var o = r.shape.length,
      i = n.data.get(r.dataId).values,
      l = n.data.get(a.dataId).values,
      u = n.data.get(s.dataId).values,
      c = upcastType(a.dtype, s.dtype),
      p = makeZerosTypedArray(sizeFromShape(a.shape), c);
  var d = 0;
  var h = 0 === o || o > 1 || 1 === a.shape.length ? 1 : sizeFromShape(a.shape.slice(1));

  for (var _e973 = 0; _e973 < i.length; _e973++) {
    for (var _t662 = 0; _t662 < h; _t662++) {
      p[d++] = 1 === i[_e973] ? l[_e973] : u[_e973];
    }
  }

  return n.makeTensorInfo(a.shape, c, p);
}

var selectConfig$1 = {
  kernelName: Select,
  backendName: "cpu",
  kernelFunc: select$1
},
    scaleAlpha = SELU_SCALEALPHA,
    scale = SELU_SCALE,
    selu$1 = unaryKernelFunc$1(Selu$1, e => e >= 0 ? scale * e : scaleAlpha * (Math.exp(e) - 1)),
    seluConfig$1 = {
  kernelName: Selu$1,
  backendName: "cpu",
  kernelFunc: selu$1
},
    sign$1 = unaryKernelFunc$1(Sign, e => e < 0 ? -1 : e > 0 ? 1 : 0),
    signConfig$1 = {
  kernelName: Sign,
  backendName: "cpu",
  kernelFunc: sign$1
},
    sin$1 = unaryKernelFunc$1(Sin, e => Math.sin(e)),
    sinConfig$1 = {
  kernelName: Sin,
  backendName: "cpu",
  kernelFunc: sin$1
},
    sinh$1 = unaryKernelFunc$1(Sinh, e => Math.sinh(e)),
    sinhConfig$1 = {
  kernelName: Sinh,
  backendName: "cpu",
  kernelFunc: sinh$1
},
    epsilon = 1.1920928955078125e-7,
    threshold = Math.log(epsilon) + 2,
    softplus$1 = unaryKernelFunc$1(Softplus$1, e => {
  var t = e > -threshold,
      n = e < threshold,
      r = Math.exp(e);
  var a;
  return a = n ? r : t ? e : Math.log(1 + r), a;
}),
    softplusConfig$1 = {
  kernelName: Softplus$1,
  backendName: "cpu",
  kernelFunc: softplus$1
};

function spaceToBatchND$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    blockShape: s,
    paddings: o
  } = r;
  assertNotComplex$1([a], "spaceToBatchND");
  var i = sizeFromShape(s),
      l = [[0, 0]];
  l.push(...o);

  for (var _e974 = 1 + s.length; _e974 < a.shape.length; ++_e974) {
    l.push([0, 0]);
  }

  var u = padV2Config$1.kernelFunc({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      paddings: l,
      constantValue: 0
    }
  }),
      c = getReshaped(u.shape, s, i, !1),
      p = getPermuted(c.length, s.length, !1),
      d = getReshapedPermuted(u.shape, s, i, !1),
      h = reshape$1({
    inputs: {
      x: u
    },
    backend: n,
    attrs: {
      shape: c
    }
  }),
      m = transpose$1({
    inputs: {
      x: h
    },
    backend: n,
    attrs: {
      perm: p
    }
  }),
      f = reshape$1({
    inputs: {
      x: m
    },
    backend: n,
    attrs: {
      shape: d
    }
  });
  return n.disposeIntermediateTensorInfo(u), n.disposeIntermediateTensorInfo(h), n.disposeIntermediateTensorInfo(m), f;
}

var spaceToBatchNDConfig$1 = {
  kernelName: SpaceToBatchND,
  backendName: "cpu",
  kernelFunc: spaceToBatchND$1
};

function sparseFillEmptyRows$1(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    indices: r,
    values: a,
    denseShape: s,
    defaultValue: o
  } = t;
  if (1 !== s.shape.length) throw new Error("Dense shape must be a vector, saw:\n        ".concat(s.shape));
  if (2 !== r.shape.length) throw new Error("Indices must be a matrix, saw:\n        ".concat(r.shape));
  if (1 !== a.shape.length) throw new Error("Values must be a vector, saw:\n        ".concat(a.shape));
  if (0 !== o.shape.length) throw new Error("Default value must be a scalar, saw:\n        ".concat(o.shape));
  var i = n.data.get(r.dataId).values,
      l = n.data.get(a.dataId).values,
      u = n.data.get(s.dataId).values,
      c = n.data.get(o.dataId).values[0],
      [p, d, h, m, f] = sparseFillEmptyRowsImpl(i, r.shape, r.dtype, l, a.dtype, u, c);
  return [n.makeTensorInfo(d, r.dtype, p), n.makeTensorInfo([d[0]], a.dtype, h), n.makeTensorInfo([m.length], "bool", new Uint8Array(m.map(e => Number(e)))), n.makeTensorInfo([f.length], r.dtype, new Int32Array(f))];
}

var sparseFillEmptyRowsConfig$1 = {
  kernelName: SparseFillEmptyRows,
  backendName: "cpu",
  kernelFunc: sparseFillEmptyRows$1
};

function sparseReshape$1(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    inputIndices: r,
    inputShape: a,
    newShape: s
  } = t;
  if (2 !== r.shape.length) throw new Error("Input indices should be a matrix but received shape\n        ".concat(r.shape));
  if (1 !== a.shape.length) throw new Error("Input shape should be a vector but received shape\n        ".concat(a.shape));
  if (1 !== s.shape.length) throw new Error("Target shape should be a vector but received shape ".concat(s.shape));
  var o = Array.from(n.data.get(a.dataId).values),
      i = n.data.get(r.dataId).values,
      l = Array.from(n.data.get(s.dataId).values),
      [u, c, p] = sparseReshapeImpl(i, r.shape, r.dtype, o, l);
  return [n.makeTensorInfo(c, r.dtype, u), n.makeTensorInfo([p.length], s.dtype, new Int32Array(p))];
}

var sparseReshapeConfig$1 = {
  kernelName: SparseReshape,
  backendName: "cpu",
  kernelFunc: sparseReshape$1
};

function sparseSegmentMean$1(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    data: r,
    indices: a,
    segmentIds: s
  } = t;
  if (r.shape.length < 1) throw new Error("Data should be at least 1 dimensional but received scalar");
  if (1 !== a.shape.length) throw new Error("Indices should be a vector but received shape\n          ".concat(a.shape));
  if (1 !== s.shape.length) throw new Error("Segment ids should be a vector but received shape\n          ".concat(s.shape));
  var o = n.data.get(r.dataId).values,
      i = n.data.get(a.dataId).values,
      l = n.data.get(s.dataId).values,
      [u, c] = sparseSegmentReductionImpl(o, r.shape, r.dtype, i, l, !0);
  return n.makeTensorInfo(c, r.dtype, u);
}

var sparseSegmentMeanConfig$1 = {
  kernelName: SparseSegmentMean,
  backendName: "cpu",
  kernelFunc: sparseSegmentMean$1
};

function sparseSegmentSum$1(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    data: r,
    indices: a,
    segmentIds: s
  } = t;
  if (r.shape.length < 1) throw new Error("Data should be at least 1 dimensional but received scalar");
  if (1 !== a.shape.length) throw new Error("Indices should be a vector but received shape\n         ".concat(a.shape));
  if (1 !== s.shape.length) throw new Error("Segment ids should be a vector but received shape\n         ".concat(s.shape));
  var o = n.data.get(r.dataId).values,
      i = n.data.get(a.dataId).values,
      l = n.data.get(s.dataId).values,
      [u, c] = sparseSegmentReductionImpl(o, r.shape, r.dtype, i, l);
  return n.makeTensorInfo(c, r.dtype, u);
}

var sparseSegmentSumConfig$1 = {
  kernelName: SparseSegmentSum,
  backendName: "cpu",
  kernelFunc: sparseSegmentSum$1
};

function sparseToDense$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    sparseIndices: a,
    sparseValues: s,
    defaultValue: o
  } = t,
      {
    outputShape: i
  } = r,
      {
    sliceRank: l,
    numUpdates: u,
    sliceSize: c,
    strides: p,
    outputSize: d
  } = calculateShapes(s, a, i),
      h = scatterImpl(n.bufferSync(a), n.bufferSync(s), i, d, c, u, l, p, n.data.get(o.dataId).values[0], !1);
  return n.makeTensorInfo(i, h.dtype, h.values);
}

var sparseToDenseConfig$1 = {
  kernelName: SparseToDense,
  backendName: "cpu",
  kernelFunc: sparseToDense$1
};

function splitV$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    numOrSizeSplits: s,
    axis: o
  } = r,
      i = parseAxisParam(o, a.shape)[0],
      l = prepareSplitSize(a, s, i),
      u = new Array(a.shape.length).fill(0),
      c = a.shape.slice();
  return l.map(e => {
    var t = [...c];
    t[i] = e;
    var r = slice$1({
      inputs: {
        x: a
      },
      backend: n,
      attrs: {
        begin: u,
        size: t
      }
    });
    return u[i] += e, r;
  });
}

var splitVConfig$1 = {
  kernelName: SplitV,
  backendName: "cpu",
  kernelFunc: splitV$1
},
    sqrt$1 = unaryKernelFunc$1(Sqrt, e => Math.sqrt(e)),
    sqrtConfig$1 = {
  kernelName: Sqrt,
  backendName: "cpu",
  kernelFunc: sqrt$1
},
    squareConfig$1 = {
  kernelName: Square,
  backendName: "cpu",
  kernelFunc: _ref60 => {
    var {
      inputs: e,
      backend: t
    } = _ref60;
    var {
      x: n
    } = e,
        r = t;
    assertNotComplex$1(n, "square");
    var a = r.data.get(n.dataId).values,
        s = new Float32Array(a.length);

    for (var _e975 = 0; _e975 < a.length; ++_e975) {
      var _t663 = a[_e975];
      s[_e975] = _t663 * _t663;
    }

    return {
      dataId: r.write(s, n.shape, n.dtype),
      shape: n.shape,
      dtype: n.dtype
    };
  }
},
    step$1 = unaryKernelFunc$1(Step, (e, t) => {
  var n = t;
  return isNaN(e) ? NaN : e > 0 ? 1 : n.alpha;
}),
    stepConfig$1 = {
  kernelName: Step,
  backendName: "cpu",
  kernelFunc: step$1
};

function stridedSlice$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    begin: s,
    end: o,
    strides: i,
    beginMask: l,
    endMask: u,
    ellipsisMask: c,
    newAxisMask: p,
    shrinkAxisMask: d
  } = r;
  assertNotComplex$1(a, "stridedSlice");
  var {
    nonStrided: h,
    $begin: m,
    $strides: f,
    size: g,
    newShape: $,
    outShape: y
  } = sliceInfo(a.shape, s, o, i, l, u, c, p, d),
      b = reshape$1({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      shape: $
    }
  });
  var x;

  if (h) {
    var _e976 = slice$1({
      inputs: {
        x: b
      },
      backend: n,
      attrs: {
        begin: m,
        size: g
      }
    });

    x = reshape$1({
      inputs: {
        x: _e976
      },
      backend: n,
      attrs: {
        shape: y
      }
    }), n.disposeIntermediateTensorInfo(_e976);
  } else if (y.some(e => 0 === e)) x = n.makeTensorInfo(y, a.dtype, []);else {
    var _e977 = stridedSliceImpl(y, n.bufferSync(b), f, m);

    x = n.makeTensorInfo(_e977.shape, _e977.dtype, _e977.values);
  }

  var v = reshape$1({
    inputs: {
      x
    },
    backend: n,
    attrs: {
      shape: y
    }
  });
  return n.disposeIntermediateTensorInfo(b), n.disposeIntermediateTensorInfo(x), v;
}

var stridedSliceConfig$1 = {
  kernelName: StridedSlice,
  backendName: "cpu",
  kernelFunc: stridedSlice$1
};

function stringNGrams$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    separator: a,
    nGramWidths: s,
    leftPad: o,
    rightPad: i,
    padWidth: l,
    preserveShortSequences: u
  } = r,
      {
    data: c,
    dataSplits: p
  } = t,
      d = n.data.get(c.dataId).values,
      h = n.data.get(p.dataId).values,
      [m, f] = stringNGramsImpl(d, h, a, s, o, i, l, u);
  return [n.makeTensorInfo([m.length], "string", m), n.makeTensorInfo(p.shape, "int32", f)];
}

var stringNGramsConfig$1 = {
  kernelName: StringNGrams,
  backendName: "cpu",
  kernelFunc: stringNGrams$1
};

function stringSplit$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    skipEmpty: a
  } = r,
      {
    input: s,
    delimiter: o
  } = t;
  if ("string" !== s.dtype) throw new Error("Input must be of datatype string");
  if (1 !== s.shape.length) throw new Error("Input must be a vector, got shape: ".concat(s.shape));
  if (0 !== o.shape.length) throw new Error("Delimiter must be a scalar, got shape: ".concat(o.shape));
  var i = n.data.get(s.dataId).values,
      l = n.data.get(o.dataId).values[0],
      [u, c, p] = stringSplitImpl(i, l, a),
      d = c.length;
  return [n.makeTensorInfo([d, 2], "int32", u), n.makeTensorInfo([d], "string", c), n.makeTensorInfo([2], "int32", new Int32Array(p))];
}

var stringSplitConfig$1 = {
  kernelName: StringSplit,
  backendName: "cpu",
  kernelFunc: stringSplit$1
};

function stringToHashBucketFast$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    numBuckets: a
  } = r,
      {
    input: s
  } = t;
  if ("string" !== s.dtype) throw new Error("Input must be of datatype string");
  if (a <= 0) throw new Error("Number of buckets must be at least 1");
  var o = stringToHashBucketFastImpl(n.data.get(s.dataId).values, a);
  return n.makeTensorInfo(s.shape, "int32", o);
}

var stringToHashBucketFastConfig$1 = {
  kernelName: StringToHashBucketFast,
  backendName: "cpu",
  kernelFunc: stringToHashBucketFast$1
},
    tan$1 = unaryKernelFunc$1(Tan, e => Math.tan(e)),
    tanConfig$1 = {
  kernelName: Tan,
  backendName: "cpu",
  kernelFunc: tan$1
},
    tanh$1 = unaryKernelFunc$1(Tanh$1, e => Math.tanh(e)),
    tanhConfig$1 = {
  kernelName: Tanh$1,
  backendName: "cpu",
  kernelFunc: tanh$1
};

function tile$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    reps: s
  } = r;
  assertNotComplex$1(a, "tile");
  var o = tileImpl(n.bufferSync(a), s);
  return n.makeTensorInfo(o.shape, o.dtype, o.values);
}

var tileConfig$1 = {
  kernelName: Tile,
  backendName: "cpu",
  kernelFunc: tile$1
};

function topK$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    k: s,
    sorted: o
  } = r;
  assertNotComplex$1(a, "topk");
  var i = n.data.get(a.dataId).values,
      [l, u] = topKImpl(i, a.shape, a.dtype, s, o);
  return [n.makeTensorInfo(l.shape, l.dtype, l.values), n.makeTensorInfo(u.shape, u.dtype, u.values)];
}

var topKConfig$1 = {
  kernelName: TopK,
  backendName: "cpu",
  kernelFunc: topK$1
};

function transform$1(e) {
  var {
    inputs: t,
    attrs: n,
    backend: r
  } = e,
      {
    image: a,
    transforms: s
  } = t,
      {
    interpolation: o,
    fillMode: i,
    fillValue: l,
    outputShape: u
  } = n,
      [c, p, d, h] = a.shape,
      [m, f] = null != u ? u : [p, d],
      g = [c, m, f, h],
      $ = computeStrides(a.shape),
      y = $[0],
      b = $[1],
      x = $[2],
      v = getTypedArrayFromDType(a.dtype, sizeFromShape(g));
  v.fill(l);
  var I = r.data.get(a.dataId).values,
      C = r.data.get(s.dataId).values;

  for (var _e978 = 0; _e978 < c; ++_e978) {
    var _t664 = 1 === s.shape[0] ? C : C.subarray(8 * _e978, 8 * _e978 + 8);

    for (var _n415 = 0; _n415 < m; ++_n415) {
      for (var _r404 = 0; _r404 < f; ++_r404) {
        for (var _a296 = 0; _a296 < h; ++_a296) {
          var _s207 = void 0;

          var _u55 = _t664[6] * _r404 + _t664[7] * _n415 + 1;

          if (0 === _u55) continue;

          var _c37 = (_t664[3] * _r404 + _t664[4] * _n415 + _t664[5]) / _u55,
              _h22 = mapCoord((_t664[0] * _r404 + _t664[1] * _n415 + _t664[2]) / _u55, d, i),
              _m9 = mapCoord(_c37, p, i);

          switch (o) {
            case "nearest":
              _s207 = nearestInterpolation(I, p, d, y, b, x, _e978, _m9, _h22, _a296, l);
              break;

            case "bilinear":
              _s207 = bilinearInterpolation(I, p, d, y, b, x, _e978, _m9, _h22, _a296, l);
              break;

            default:
              throw new Error("Error in Transform: Expect 'nearest' or 'bilinear', but got ".concat(o));
          }

          v[_e978 * y + _n415 * b + _r404 * x + _a296] = _s207;
        }
      }
    }

    return r.makeTensorInfo(g, a.dtype, v);
  }

  return {
    dataId: r.write(v, g, a.dtype),
    shape: a.shape,
    dtype: a.dtype
  };
}

var transformConfig$1 = {
  kernelName: Transform,
  backendName: "cpu",
  kernelFunc: transform$1
};

function mapCoord(e, t, n) {
  switch (n) {
    case "reflect":
      return mapCoordReflect(e, t);

    case "wrap":
      return mapCoordWrap(e, t);

    case "nearest":
      return mapCoordNearest(e, t);

    default:
      return mapCoordConstant(e);
  }
}

function mapCoordReflect(e, t) {
  var n = e;
  if (n < 0) {
    if (t <= 1) n = 0;else {
      var _e979 = 2 * t;

      n < _e979 && (n = _e979 * Math.trunc(-n / _e979) + n), n = n < -t ? n + _e979 : -n - 1;
    }
  } else if (n > t - 1) if (t <= 1) n = 0;else {
    var _e980 = 2 * t;

    n -= _e980 * Math.trunc(n / _e980), n >= t && (n = _e980 - n - 1);
  }
  return clamp(0, n, t - 1);
}

function mapCoordWrap(e, t) {
  var n = e;
  return n < 0 ? t <= 1 ? n = 0 : n += t * (Math.trunc(-n / (t - 1)) + 1) : n > t - 1 && (t <= 1 ? n = 0 : n -= t * Math.trunc(n / (t - 1))), clamp(0, n, t - 1);
}

function mapCoordConstant(e, t) {
  return e;
}

function mapCoordNearest(e, t) {
  return clamp(0, e, t - 1);
}

function readWithFillValue(e, t, n, r, a, s, o, i, l, u, c) {
  return 0 <= i && i < t && 0 <= l && l < n ? e[o * r + i * a + l * s + u] : c;
}

function nearestInterpolation(e, t, n, r, a, s, o, i, l, u, c) {
  return readWithFillValue(e, t, n, r, a, s, o, Math.round(i), Math.round(l), u, c);
}

function bilinearInterpolation(e, t, n, r, a, s, o, i, l, u, c) {
  var p = Math.floor(i),
      d = Math.floor(l),
      h = p + 1,
      m = d + 1;
  return (h - i) * ((m - l) * readWithFillValue(e, t, n, r, a, s, o, p, d, u, c) + (l - d) * readWithFillValue(e, t, n, r, a, s, o, p, m, u, c)) + (i - p) * ((m - l) * readWithFillValue(e, t, n, r, a, s, o, h, d, u, c) + (l - d) * readWithFillValue(e, t, n, r, a, s, o, h, m, u, c));
}

function unique$1(e) {
  var {
    inputs: t,
    attrs: n,
    backend: r
  } = e,
      {
    axis: a
  } = n,
      {
    x: s
  } = t;
  assertNotComplex$1(s, "unique");
  var o = r.data.get(s.dataId).values,
      {
    outputValues: i,
    outputShape: l,
    indices: u
  } = uniqueImpl(o, a, s.shape, s.dtype);
  return [r.makeTensorInfo(l, s.dtype, i), r.makeTensorInfo([u.length], "int32", u)];
}

var uniqueConfig$1 = {
  kernelName: Unique,
  backendName: "cpu",
  kernelFunc: unique$1
};

function unpack$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    value: a
  } = t;
  var {
    axis: s
  } = r;
  s < 0 && (s += a.shape.length);
  var o = a.shape.length,
      i = a.shape[s],
      l = new Array(o - 1);
  var u = 0;

  for (var _e981 = 0; _e981 < o; _e981++) {
    _e981 !== s && (l[u++] = a.shape[_e981]);
  }

  var c = new Array(o).fill(0),
      p = a.shape.slice();
  p[s] = 1;
  var d = new Array(i);

  for (var _e982 = 0; _e982 < d.length; _e982++) {
    c[s] = _e982;

    var _t665 = slice$1({
      inputs: {
        x: a
      },
      backend: n,
      attrs: {
        begin: c,
        size: p
      }
    });

    d[_e982] = reshape$1({
      inputs: {
        x: _t665
      },
      backend: n,
      attrs: {
        shape: l
      }
    }), n.disposeIntermediateTensorInfo(_t665);
  }

  return d;
}

var unpackConfig$1 = {
  kernelName: Unpack,
  backendName: "cpu",
  kernelFunc: unpack$1
};

function unsortedSegmentSum$1(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    segmentIds: s
  } = t,
      {
    numSegments: o
  } = r;
  assertNotComplex$1(a, "unsortedSegmentSum");
  var i = [],
      l = [],
      u = a.shape.length - s.shape.length;
  var c = s;

  for (var _e983 = 0; _e983 < u; ++_e983) {
    var _t666 = expandDims$1({
      inputs: {
        input: c
      },
      backend: n,
      attrs: {
        dim: _e983 + 1
      }
    });

    c = _t666, l.push(_t666);
  }

  for (var _e984 = 0; _e984 < o; ++_e984) {
    var _t667 = createScalarValue(_e984, "int32"),
        _r405 = n.makeTensorInfo([], "int32", _t667),
        _s208 = equal$1({
      inputs: {
        a: _r405,
        b: c
      },
      backend: n
    }),
        _o145 = cast$1({
      inputs: {
        x: _s208
      },
      backend: n,
      attrs: {
        dtype: "float32"
      }
    }),
        _u56 = multiply$1({
      inputs: {
        a: _o145,
        b: a
      },
      backend: n
    }),
        _p34 = sum$1({
      inputs: {
        x: _u56
      },
      backend: n,
      attrs: {
        axis: 0,
        keepDims: !1
      }
    });

    i.push(_p34), l.push(_r405), l.push(_s208), l.push(_o145), l.push(_u56), l.push(_p34);
  }

  var p = pack$1({
    inputs: i,
    backend: n,
    attrs: {
      axis: 0
    }
  });
  return l.forEach(e => n.disposeIntermediateTensorInfo(e)), p;
}

var unsortedSegmentSumConfig$1 = {
  kernelName: UnsortedSegmentSum,
  backendName: "cpu",
  kernelFunc: unsortedSegmentSum$1
},
    kernelConfigs$1 = [_fusedMatMulConfig$1, absConfig$1, acosConfig$1, acoshConfig$1, addConfig$1, addNConfig$1, allConfig$1, anyConfig$1, argMaxConfig$1, argMinConfig$1, asinConfig$1, asinhConfig$1, atanConfig$1, atan2Config$1, atanhConfig$1, avgPoolConfig$1, avgPool3DConfig$1, avgPool3DGradConfig, avgPoolGradConfig$1, batchMatMulConfig$1, batchNormConfig$1, batchToSpaceNDConfig$1, bincountConfig$1, castConfig$1, ceilConfig$1, clipConfig, complexConfig$1, complexAbsConfig$1, concatConfig$1, conv2DBackpropFilterConfig$1, conv2DBackpropInputConfig$1, conv2DConfig$1, conv3DBackpropFilterV2Config$1, conv3DBackpropInputV2Config, conv3DConfig$1, cosConfig$1, coshConfig$1, cropAndResizeConfig$1, cumsumConfig$1, denseBincountConfig$1, depthToSpaceConfig$1, depthwiseConv2dNativeConfig$1, depthwiseConv2dNativeBackpropFilterConfig$1, depthwiseConv2dNativeBackpropInputConfig$1, diagConfig$1, dilation2dConfig, dilation2dBackpropInputConfig, dilation2dBackpropFilterConfig, realDivConfig$1, einsumConfig$1, eluConfig$1, eluGradConfig$1, equalConfig$1, erfConfig$1, expConfig$1, expandDimsConfig$1, expm1Config$1, fftConfig$1, fillConfig$1, flipLeftRightConfig$1, floorConfig$1, floorDivConfig$1, fusedConv2DConfig$1, fusedDepthwiseConv2DConfig$1, gatherNdConfig$1, gatherV2Config$1, greaterConfig$1, greaterEqualConfig$1, identityConfig$1, ifftConfig$1, imagConfig$1, isFiniteConfig$1, isInfConfig$1, isNaNConfig$1, leakyReluConfig$1, lessConfig$1, lessEqualConfig$1, linSpaceConfig$1, logConfig$1, log1pConfig$1, logicalAndConfig$1, logicalNotConfig$1, logicalOrConfig$1, lRNConfig, lRNGradConfig, maximumConfig$1, maxPoolConfig$1, maxPool3DConfig$1, maxPool3DGradConfig, maxPoolGradConfig$1, maxPoolWithArgmaxConfig$1, maxConfig$1, meanConfig$1, minConfig$1, minimumConfig$1, mirrorPadConfig$1, modConfig$1, multinomialConfig$1, multiplyConfig$1, negConfig$1, nonMaxSuppressionV3Config$1, nonMaxSuppressionV4Config$1, nonMaxSuppressionV5Config$1, notEqualConfig$1, oneHotConfig$1, onesLikeConfig$1, packConfig$1, padV2Config$1, powConfig$1, preluConfig$1, prodConfig$1, rangeConfig$1, realConfig$1, reciprocalConfig$1, reluConfig$1, relu6Config$1, reshapeConfig$1, resizeBilinearConfig$1, resizeBilinearGradConfig$1, resizeNearestNeighborConfig$1, resizeNearestNeighborGradConfig$1, reverseConfig$1, rotateWithOffsetConfig$1, roundConfig$1, rsqrtConfig$1, scatterNdConfig$1, selectConfig$1, seluConfig$1, sigmoidConfig$1, signConfig$1, sinConfig$1, sinhConfig$1, sliceConfig$1, softmaxConfig$1, softplusConfig$1, spaceToBatchNDConfig$1, sparseFillEmptyRowsConfig$1, sparseReshapeConfig$1, sparseSegmentMeanConfig$1, sparseSegmentSumConfig$1, sparseToDenseConfig$1, splitVConfig$1, sqrtConfig$1, squareConfig$1, squaredDifferenceConfig$1, stepConfig$1, stridedSliceConfig$1, stringNGramsConfig$1, stringSplitConfig$1, stringToHashBucketFastConfig$1, subConfig$1, sumConfig$1, tanConfig$1, tanhConfig$1, tileConfig$1, topKConfig$1, transposeConfig$1, transformConfig$1, uniqueConfig$1, unpackConfig$1, unsortedSegmentSumConfig$1, zerosLikeConfig$1];

for (var _e985 of kernelConfigs$1) {
  registerKernel(_e985);
}

var contexts = {},
    WEBGL_ATTRIBUTES = {
  alpha: !1,
  antialias: !1,
  premultipliedAlpha: !1,
  preserveDrawingBuffer: !1,
  depth: !1,
  stencil: !1,
  failIfMajorPerformanceCaveat: !0
};

function setWebGLContext(e, t) {
  contexts[e] = t;
}

function getWebGLContext(e) {
  if (!(e in contexts)) {
    var _t668 = getWebGLRenderingContext(e);

    if (null === _t668) return console.log("Could not get context for WebGL version", e), null;
    contexts[e] = _t668;
  }

  var t = contexts[e];
  return t.isContextLost() ? (delete contexts[e], getWebGLContext(e)) : (t.disable(t.DEPTH_TEST), t.disable(t.STENCIL_TEST), t.disable(t.BLEND), t.disable(t.DITHER), t.disable(t.POLYGON_OFFSET_FILL), t.disable(t.SAMPLE_COVERAGE), t.enable(t.SCISSOR_TEST), t.enable(t.CULL_FACE), t.cullFace(t.BACK), contexts[e]);
}

function createCanvas(e) {
  if ("undefined" != typeof OffscreenCanvas && 2 === e) return new OffscreenCanvas(300, 150);
  if ("undefined" != typeof document) return document.createElement("canvas");
  throw new Error("Cannot create a canvas in this context");
}

function getWebGLRenderingContext(e) {
  if (1 !== e && 2 !== e) throw new Error("Cannot get WebGL rendering context, WebGL is disabled.");
  var t = createCanvas(e);
  return t.addEventListener("webglcontextlost", t => {
    t.preventDefault(), delete contexts[e];
  }, !1), 1 === e ? t.getContext("webgl", WEBGL_ATTRIBUTES) || t.getContext("experimental-webgl", WEBGL_ATTRIBUTES) : t.getContext("webgl2", WEBGL_ATTRIBUTES);
}

var PackingScheme, TextureUsage, PhysicalTextureType;

function getUnpackedMatrixTextureShapeWidthHeight(e, t) {
  return [t, e];
}

function getUnpackedArraySizeFromMatrixSize(e, t) {
  return e * t;
}

function getDenseTexShape(e) {
  var t = sizeFromShape(e);
  return sizeToSquarishShape(Math.ceil(t / 4));
}

function getPackedMatrixTextureShapeWidthHeight(e, t) {
  return [Math.max(1, Math.ceil(t / 2)), Math.max(1, Math.ceil(e / 2))];
}

function getPackedRGBAArraySizeFromMatrixShape(e, t) {
  var [n, r] = getPackedMatrixTextureShapeWidthHeight(e, t);
  return n * r * 4;
}

function getTextureConfig(e, t) {
  var n = e;
  var r, a, s, o, i, l, u, c, p, d;
  return 2 === env().getNumber("WEBGL_VERSION") ? (r = n.R32F, a = n.R16F, s = n.RGBA16F, o = n.RGBA32F, i = n.RED, u = 4, c = 1, p = n.HALF_FLOAT, d = n.FLOAT) : (r = e.RGBA, a = e.RGBA, s = e.RGBA, o = n.RGBA, i = e.RGBA, u = 4, c = 4, p = null != t ? t.HALF_FLOAT_OES : null, d = e.FLOAT), l = e.RGBA, {
    internalFormatFloat: r,
    internalFormatHalfFloat: a,
    internalFormatPackedHalfFloat: s,
    internalFormatPackedFloat: o,
    textureFormatFloat: i,
    downloadTextureFormat: l,
    downloadUnpackNumChannels: u,
    defaultNumChannels: c,
    textureTypeHalfFloat: p,
    textureTypeFloat: d
  };
}

function callAndCheck(e, t) {
  var n = t();
  return env().getBool("DEBUG") && checkWebGLError(e), n;
}

function checkWebGLError(e) {
  var t = e.getError();
  if (t !== e.NO_ERROR) throw new Error("WebGL Error: " + getWebGLErrorMessage(e, t));
}

!function (e) {
  e[e.DENSE = 0] = "DENSE", e[e.SHARED_BATCH = 1] = "SHARED_BATCH";
}(PackingScheme || (PackingScheme = {})), function (e) {
  e[e.RENDER = 0] = "RENDER", e[e.UPLOAD = 1] = "UPLOAD", e[e.PIXELS = 2] = "PIXELS", e[e.DOWNLOAD = 3] = "DOWNLOAD";
}(TextureUsage || (TextureUsage = {})), function (e) {
  e[e.UNPACKED_FLOAT16 = 0] = "UNPACKED_FLOAT16", e[e.UNPACKED_FLOAT32 = 1] = "UNPACKED_FLOAT32", e[e.PACKED_4X1_UNSIGNED_BYTE = 2] = "PACKED_4X1_UNSIGNED_BYTE", e[e.PACKED_2X2_FLOAT32 = 3] = "PACKED_2X2_FLOAT32", e[e.PACKED_2X2_FLOAT16 = 4] = "PACKED_2X2_FLOAT16";
}(PhysicalTextureType || (PhysicalTextureType = {}));
var MIN_FLOAT16 = 5.96e-8,
    MAX_FLOAT16 = 65504;

function canBeRepresented(e) {
  return !!(env().getBool("WEBGL_RENDER_FLOAT32_ENABLED") || 0 === e || MIN_FLOAT16 < Math.abs(e) && Math.abs(e) < MAX_FLOAT16);
}

function getWebGLErrorMessage(e, t) {
  switch (t) {
    case e.NO_ERROR:
      return "NO_ERROR";

    case e.INVALID_ENUM:
      return "INVALID_ENUM";

    case e.INVALID_VALUE:
      return "INVALID_VALUE";

    case e.INVALID_OPERATION:
      return "INVALID_OPERATION";

    case e.INVALID_FRAMEBUFFER_OPERATION:
      return "INVALID_FRAMEBUFFER_OPERATION";

    case e.OUT_OF_MEMORY:
      return "OUT_OF_MEMORY";

    case e.CONTEXT_LOST_WEBGL:
      return "CONTEXT_LOST_WEBGL";

    default:
      return "Unknown error code ".concat(t);
  }
}

function getExtensionOrThrow(e, t) {
  return throwIfNull(e, () => e.getExtension(t), 'Extension "' + t + '" not supported on this browser.');
}

function createVertexShader$1(e, t) {
  var n = throwIfNull(e, () => e.createShader(e.VERTEX_SHADER), "Unable to create vertex WebGLShader.");
  if (callAndCheck(e, () => e.shaderSource(n, t)), callAndCheck(e, () => e.compileShader(n)), !1 === e.getShaderParameter(n, e.COMPILE_STATUS)) throw console.log(e.getShaderInfoLog(n)), new Error("Failed to compile vertex shader.");
  return n;
}

function createFragmentShader(e, t) {
  var n = throwIfNull(e, () => e.createShader(e.FRAGMENT_SHADER), "Unable to create fragment WebGLShader.");
  if (callAndCheck(e, () => e.shaderSource(n, t)), callAndCheck(e, () => e.compileShader(n)), !1 === e.getShaderParameter(n, e.COMPILE_STATUS)) throw logShaderSourceAndInfoLog(t, e.getShaderInfoLog(n)), new Error("Failed to compile fragment shader.");
  return n;
}

var lineNumberRegex = /ERROR: [0-9]+:([0-9]+):/g;

function logShaderSourceAndInfoLog(e, t) {
  var n = lineNumberRegex.exec(t);
  if (null == n) return console.log("Couldn't parse line number in error: ".concat(t)), void console.log(e);
  var r = +n[1],
      a = e.split("\n"),
      s = a.length.toString().length + 2,
      o = a.map((e, t) => rightPad((t + 1).toString(), s) + e);
  var i = 0;

  for (var _e986 = 0; _e986 < o.length; _e986++) {
    i = Math.max(o[_e986].length, i);
  }

  var l = o.slice(0, r - 1),
      u = o.slice(r - 1, r),
      c = o.slice(r);
  console.log(l.join("\n")), console.log(t.split("\n")[0]), console.log("%c ".concat(rightPad(u[0], i)), "border:1px solid red; background-color:#e3d2d2; color:#a61717"), console.log(c.join("\n"));
}

function createProgram(e) {
  return throwIfNull(e, () => e.createProgram(), "Unable to create WebGLProgram.");
}

function linkProgram(e, t) {
  if (callAndCheck(e, () => e.linkProgram(t)), !1 === e.getProgramParameter(t, e.LINK_STATUS)) throw console.log(e.getProgramInfoLog(t)), new Error("Failed to link vertex and fragment shaders.");
}

function validateProgram(e, t) {
  if (callAndCheck(e, () => e.validateProgram(t)), !1 === e.getProgramParameter(t, e.VALIDATE_STATUS)) throw console.log(e.getProgramInfoLog(t)), new Error("Shader program validation failed.");
}

function createStaticVertexBuffer(e, t) {
  var n = throwIfNull(e, () => e.createBuffer(), "Unable to create WebGLBuffer");
  return callAndCheck(e, () => e.bindBuffer(e.ARRAY_BUFFER, n)), callAndCheck(e, () => e.bufferData(e.ARRAY_BUFFER, t, e.STATIC_DRAW)), n;
}

function createStaticIndexBuffer(e, t) {
  var n = throwIfNull(e, () => e.createBuffer(), "Unable to create WebGLBuffer");
  return callAndCheck(e, () => e.bindBuffer(e.ELEMENT_ARRAY_BUFFER, n)), callAndCheck(e, () => e.bufferData(e.ELEMENT_ARRAY_BUFFER, t, e.STATIC_DRAW)), n;
}

function createTexture(e) {
  return throwIfNull(e, () => e.createTexture(), "Unable to create WebGLTexture.");
}

function validateTextureSize(e, t) {
  var n = env().getNumber("WEBGL_MAX_TEXTURE_SIZE");
  if (e <= 0 || t <= 0) throw new Error("Requested texture size [".concat(e, "x").concat(t, "] is invalid."));
  if (e > n || t > n) throw new Error("Requested texture size [".concat(e, "x").concat(t, "] greater than WebGL maximum on this browser / GPU [").concat(n, "x").concat(n, "]."));
}

function createFramebuffer(e) {
  return throwIfNull(e, () => e.createFramebuffer(), "Unable to create WebGLFramebuffer.");
}

function bindVertexBufferToProgramAttribute(e, t, n, r, a, s, o) {
  var i = e.getAttribLocation(t, n);
  return -1 !== i && (callAndCheck(e, () => e.bindBuffer(e.ARRAY_BUFFER, r)), callAndCheck(e, () => e.vertexAttribPointer(i, a, e.FLOAT, !1, s, o)), callAndCheck(e, () => e.enableVertexAttribArray(i)), !0);
}

function bindTextureUnit(e, t, n) {
  validateTextureUnit(e, n), callAndCheck(e, () => e.activeTexture(e.TEXTURE0 + n)), callAndCheck(e, () => e.bindTexture(e.TEXTURE_2D, t));
}

function getProgramUniformLocationOrThrow(e, t, n) {
  return throwIfNull(e, () => e.getUniformLocation(t, n), 'uniform "' + n + '" not present in program.');
}

function getProgramUniformLocation(e, t, n) {
  return e.getUniformLocation(t, n);
}

function bindTextureToProgramUniformSampler(e, t, n, r) {
  callAndCheck(e, () => bindTextureUnit(e, t, r)), callAndCheck(e, () => e.uniform1i(n, r));
}

function bindColorTextureToFramebuffer(e, t, n) {
  callAndCheck(e, () => e.bindFramebuffer(e.FRAMEBUFFER, n)), callAndCheck(e, () => e.framebufferTexture2D(e.FRAMEBUFFER, e.COLOR_ATTACHMENT0, e.TEXTURE_2D, t, 0));
}

function unbindColorTextureFromFramebuffer(e, t) {
  callAndCheck(e, () => e.bindFramebuffer(e.FRAMEBUFFER, t)), callAndCheck(e, () => e.framebufferTexture2D(e.FRAMEBUFFER, e.COLOR_ATTACHMENT0, e.TEXTURE_2D, null, 0));
}

function validateFramebuffer(e) {
  var t = e.checkFramebufferStatus(e.FRAMEBUFFER);
  if (t !== e.FRAMEBUFFER_COMPLETE) throw new Error("Error binding framebuffer: " + getFramebufferErrorMessage(e, t));
}

function getFramebufferErrorMessage(e, t) {
  switch (t) {
    case e.FRAMEBUFFER_INCOMPLETE_ATTACHMENT:
      return "FRAMEBUFFER_INCOMPLETE_ATTACHMENT";

    case e.FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT:
      return "FRAMEBUFFER_INCOMPLETE_MISSING_ATTACHMENT";

    case e.FRAMEBUFFER_INCOMPLETE_DIMENSIONS:
      return "FRAMEBUFFER_INCOMPLETE_DIMENSIONS";

    case e.FRAMEBUFFER_UNSUPPORTED:
      return "FRAMEBUFFER_UNSUPPORTED";

    default:
      return "unknown error ".concat(t);
  }
}

function throwIfNull(e, t, n) {
  var r = callAndCheck(e, () => t());
  if (null == r) throw new Error(n);
  return r;
}

function validateTextureUnit(e, t) {
  var n = e.MAX_COMBINED_TEXTURE_IMAGE_UNITS - 1,
      r = t + e.TEXTURE0;
  if (r < e.TEXTURE0 || r > n) throw new Error("textureUnit must be in [gl.TEXTURE0, gl.TEXTURE".concat(n, "]."));
}

function getBatchDim(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 2;
  return sizeFromShape(e.slice(0, e.length - t));
}

function getRowsCols(e) {
  if (0 === e.length) throw Error("Cannot get rows and columns of an empty shape array.");
  return [e.length > 1 ? e[e.length - 2] : 1, e[e.length - 1]];
}

function getShapeAs3D(e) {
  var t = [1, 1, 1];
  return 0 === e.length || 1 === e.length && 1 === e[0] || (t = [getBatchDim(e), ...getRowsCols(e)]), t;
}

function getTextureShapeFromLogicalShape(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;
  var n = env().getNumber("WEBGL_MAX_TEXTURE_SIZE");

  if (t && (n *= 2, 1 === (e = e.map((t, n) => n >= e.length - 2 ? nearestLargerEven(e[n]) : e[n])).length && (e = [2, e[0]])), 2 !== e.length) {
    var _t669 = squeezeShape(e);

    e = _t669.newShape;
  }

  var r = sizeFromShape(e);
  if (e.length <= 1 && r <= n) return [1, r];
  if (2 === e.length && e[0] <= n && e[1] <= n) return e;
  if (3 === e.length && e[0] * e[1] <= n && e[2] <= n) return [e[0] * e[1], e[2]];
  if (3 === e.length && e[0] <= n && e[1] * e[2] <= n) return [e[0], e[1] * e[2]];
  if (4 === e.length && e[0] * e[1] * e[2] <= n && e[3] <= n) return [e[0] * e[1] * e[2], e[3]];
  if (4 === e.length && e[0] <= n && e[1] * e[2] * e[3] <= n) return [e[0], e[1] * e[2] * e[3]];

  if (t) {
    var _t670 = getBatchDim(e);

    var _n416 = 2,
        a = 2;
    return e.length && ([_n416, a] = getRowsCols(e)), r = _t670 * (_n416 / 2) * (a / 2), sizeToSquarishShape(r).map(e => 2 * e);
  }

  return sizeToSquarishShape(r);
}

function isEven(e) {
  return e % 2 == 0;
}

function isReshapeFree(e, t) {
  if (arraysEqual(e = e.slice(-2), t = t.slice(-2))) return !0;
  if (!e.length || !t.length) return !0;
  if (0 === e[0] || 0 === e[1] || 0 === t[0] || 0 === t[1]) return !0;

  if (e.length !== t.length) {
    var n = e.slice(-1)[0],
        r = t.slice(-1)[0];
    if (n === r) return !0;
    if (isEven(n) && isEven(r) && (1 === e[0] || 1 === t[0])) return !0;
  }

  return e[1] === t[1] && isEven(e[0]) && isEven(t[0]);
}

var MAX_TEXTURE_SIZE, MAX_TEXTURES_IN_SHADER;

function getWebGLMaxTextureSize(e) {
  if (null == MAX_TEXTURE_SIZE) {
    var t = getWebGLContext(e);
    MAX_TEXTURE_SIZE = t.getParameter(t.MAX_TEXTURE_SIZE);
  }

  return MAX_TEXTURE_SIZE;
}

function getMaxTexturesInShader(e) {
  if (null == MAX_TEXTURES_IN_SHADER) {
    var t = getWebGLContext(e);
    MAX_TEXTURES_IN_SHADER = t.getParameter(t.MAX_TEXTURE_IMAGE_UNITS);
  }

  return Math.min(16, MAX_TEXTURES_IN_SHADER);
}

function getWebGLDisjointQueryTimerVersion(e) {
  if (0 === e) return 0;
  var t;
  var n = getWebGLContext(e);
  return t = hasExtension(n, "EXT_disjoint_timer_query_webgl2") && 2 === e ? 2 : hasExtension(n, "EXT_disjoint_timer_query") ? 1 : 0, t;
}

function hasExtension(e, t) {
  return null != e.getExtension(t);
}

function isWebGLVersionEnabled(e) {
  try {
    if (null != getWebGLContext(e)) return !0;
  } catch (e) {
    return console.log("Error when getting WebGL context: ", e), !1;
  }

  return !1;
}

function isCapableOfRenderingToFloatTexture(e) {
  if (0 === e) return !1;
  var t = getWebGLContext(e);

  if (1 === e) {
    if (!hasExtension(t, "OES_texture_float")) return !1;
  } else if (!hasExtension(t, "EXT_color_buffer_float")) return !1;

  return createFloatTextureAndBindToFramebuffer(t);
}

function isDownloadFloatTextureEnabled(e) {
  if (0 === e) return !1;
  var t = getWebGLContext(e);

  if (1 !== e) {
    if (hasExtension(t, "EXT_color_buffer_float")) return createFloatTextureAndBindToFramebuffer(t);
    var _e987 = "EXT_color_buffer_half_float";

    if (hasExtension(t, _e987)) {
      var n = t.getExtension(_e987);
      return createHalfFloatTextureAndBindToFramebuffer(t, n);
    }

    return !1;
  }

  return !!hasExtension(t, "OES_texture_float") && !!hasExtension(t, "WEBGL_color_buffer_float") && createFloatTextureAndBindToFramebuffer(t);
}

function createFloatTextureAndBindToFramebuffer(e) {
  var t = getTextureConfig(e),
      n = e.createTexture();
  e.bindTexture(e.TEXTURE_2D, n), e.texImage2D(e.TEXTURE_2D, 0, t.internalFormatFloat, 1, 1, 0, t.textureFormatFloat, t.textureTypeFloat, null);
  var r = e.createFramebuffer();
  e.bindFramebuffer(e.FRAMEBUFFER, r), e.framebufferTexture2D(e.FRAMEBUFFER, e.COLOR_ATTACHMENT0, e.TEXTURE_2D, n, 0);
  var a = e.checkFramebufferStatus(e.FRAMEBUFFER) === e.FRAMEBUFFER_COMPLETE;
  return e.bindTexture(e.TEXTURE_2D, null), e.bindFramebuffer(e.FRAMEBUFFER, null), e.deleteTexture(n), e.deleteFramebuffer(r), a;
}

function createHalfFloatTextureAndBindToFramebuffer(e, t) {
  var n = getTextureConfig(e, t),
      r = e.createTexture();
  e.bindTexture(e.TEXTURE_2D, r), e.texImage2D(e.TEXTURE_2D, 0, n.internalFormatHalfFloat, 1, 1, 0, n.textureFormatFloat, n.textureTypeHalfFloat, null);
  var a = e.createFramebuffer();
  e.bindFramebuffer(e.FRAMEBUFFER, a), e.framebufferTexture2D(e.FRAMEBUFFER, e.COLOR_ATTACHMENT0, e.TEXTURE_2D, r, 0);
  var s = e.checkFramebufferStatus(e.FRAMEBUFFER) === e.FRAMEBUFFER_COMPLETE;
  return e.bindTexture(e.TEXTURE_2D, null), e.bindFramebuffer(e.FRAMEBUFFER, null), e.deleteTexture(r), e.deleteFramebuffer(a), s;
}

function isWebGLFenceEnabled(e) {
  return 2 === e && null != getWebGLContext(e).fenceSync;
}

function assertNotComplex(e, t) {
  Array.isArray(e) || (e = [e]), e.forEach(e => {
    null != e && assert$4("complex64" !== e.dtype, () => "".concat(t, " does not support complex64 tensors in the WebGL backend."));
  });
}

var ENV = env();

function getGlslDifferences() {
  var e, t, n, r, a, s, o, i, l, u;
  return 2 === env().getNumber("WEBGL_VERSION") ? (e = "#version 300 es", t = "in", n = "out", r = "in", a = "texture", s = "outputColor", o = "out vec4 outputColor;", i = "\n      bool isnan_custom(float val) {\n        return (val > 0.0 || val < 0.0) ? false : val != 0.0;\n      }\n\n      bvec4 isnan_custom(vec4 val) {\n        return bvec4(isnan_custom(val.x),\n          isnan_custom(val.y), isnan_custom(val.z), isnan_custom(val.w));\n      }\n\n      #define isnan(value) isnan_custom(value)\n    ", l = "", u = "\n      #define round(value) newRound(value)\n      int newRound(float value) {\n        return int(floor(value + 0.5));\n      }\n\n      ivec4 newRound(vec4 value) {\n        return ivec4(floor(value + vec4(0.5)));\n      }\n    ") : (e = "", t = "attribute", n = "varying", r = "varying", a = "texture2D", s = "gl_FragColor", o = "", i = "\n      #define isnan(value) isnan_custom(value)\n      bool isnan_custom(float val) {\n        return (val > 0. || val < 1. || val == 0.) ? false : true;\n      }\n      bvec4 isnan_custom(vec4 val) {\n        return bvec4(isnan(val.x), isnan(val.y), isnan(val.z), isnan(val.w));\n      }\n    ", l = "\n      uniform float INFINITY;\n\n      bool isinf(float val) {\n        return abs(val) == INFINITY;\n      }\n      bvec4 isinf(vec4 val) {\n        return equal(abs(val), vec4(INFINITY));\n      }\n    ", u = "\n      int round(float value) {\n        return int(floor(value + 0.5));\n      }\n\n      ivec4 round(vec4 value) {\n        return ivec4(floor(value + vec4(0.5)));\n      }\n    "), {
    version: e,
    attribute: t,
    varyingVs: n,
    varyingFs: r,
    texture2D: a,
    output: s,
    defineOutput: o,
    defineSpecialNaN: i,
    defineSpecialInf: l,
    defineRound: u
  };
}

function getLogicalCoordinatesFromFlatIndex(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : "index";
  var r = computeStrides(t);
  return r.map((t, a) => "int ".concat(e[a], " = ").concat(n, " / ").concat(t, "; ").concat(a === r.length - 1 ? "int ".concat(e[a + 1], " = ").concat(n, " - ").concat(e[a], " * ").concat(t) : "index -= ".concat(e[a], " * ").concat(t), ";")).join("");
}

function getLogicalCoordinatesFromFlatIndexByUniform(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : "index";
  var r = computeStrides(t);
  return r.map((t, a) => "int ".concat(e[a], " = ").concat(n, " / outShapeStrides[").concat(a, "]; ").concat(a === r.length - 1 ? "int ".concat(e[a + 1], " = ").concat(n, " - ").concat(e[a], " * outShapeStrides[").concat(a, "]") : "index -= ".concat(e[a], " * outShapeStrides[").concat(a, "]"), ";")).join("");
}

function getFlatIndexFrom3D(e) {
  var t = computeStrides(e).map(e => e.toString());
  return "\n  int getFlatIndex(ivec3 coords) {\n    return coords.x * ".concat(t[0], " + coords.y * ").concat(t[1], " + coords.z;\n  }\n");
}

ENV.registerFlag("HAS_WEBGL", () => ENV.getNumber("WEBGL_VERSION") > 0), ENV.registerFlag("WEBGL_VERSION", () => isWebGLVersionEnabled(2) ? 2 : isWebGLVersionEnabled(1) ? 1 : 0), ENV.registerFlag("WEBGL_CHECK_NUMERICAL_PROBLEMS", () => !1), ENV.registerFlag("WEBGL_BUFFER_SUPPORTED", () => 2 === ENV.get("WEBGL_VERSION")), ENV.registerFlag("WEBGL_CPU_FORWARD", () => !0), ENV.registerFlag("WEBGL_FORCE_F16_TEXTURES", () => !1), ENV.registerFlag("WEBGL_PACK", () => ENV.getBool("HAS_WEBGL")), ENV.registerFlag("WEBGL_PACK_NORMALIZATION", () => ENV.getBool("WEBGL_PACK")), ENV.registerFlag("WEBGL_PACK_CLIP", () => ENV.getBool("WEBGL_PACK")), ENV.registerFlag("WEBGL_PACK_DEPTHWISECONV", () => ENV.getBool("WEBGL_PACK")), ENV.registerFlag("WEBGL_PACK_BINARY_OPERATIONS", () => ENV.getBool("WEBGL_PACK")), ENV.registerFlag("WEBGL_PACK_UNARY_OPERATIONS", () => ENV.getBool("WEBGL_PACK")), ENV.registerFlag("WEBGL_PACK_ARRAY_OPERATIONS", () => ENV.getBool("WEBGL_PACK")), ENV.registerFlag("WEBGL_PACK_IMAGE_OPERATIONS", () => ENV.getBool("WEBGL_PACK")), ENV.registerFlag("WEBGL_PACK_REDUCE", () => ENV.getBool("WEBGL_PACK")), ENV.registerFlag("WEBGL_LAZILY_UNPACK", () => ENV.getBool("WEBGL_PACK")), ENV.registerFlag("WEBGL_CONV_IM2COL", () => ENV.getBool("WEBGL_PACK")), ENV.registerFlag("WEBGL_MAX_TEXTURE_SIZE", () => getWebGLMaxTextureSize(ENV.getNumber("WEBGL_VERSION"))), ENV.registerFlag("WEBGL_MAX_TEXTURES_IN_SHADER", () => getMaxTexturesInShader(ENV.getNumber("WEBGL_VERSION"))), ENV.registerFlag("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION", () => {
  var e = ENV.getNumber("WEBGL_VERSION");
  return 0 === e ? 0 : getWebGLDisjointQueryTimerVersion(e);
}), ENV.registerFlag("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE", () => ENV.getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") > 0 && !isMobile()), ENV.registerFlag("WEBGL_RENDER_FLOAT32_CAPABLE", () => isCapableOfRenderingToFloatTexture(ENV.getNumber("WEBGL_VERSION"))), ENV.registerFlag("WEBGL_RENDER_FLOAT32_ENABLED", () => !ENV.getBool("WEBGL_FORCE_F16_TEXTURES") && ENV.getBool("WEBGL_RENDER_FLOAT32_CAPABLE")), ENV.registerFlag("WEBGL_DOWNLOAD_FLOAT_ENABLED", () => isDownloadFloatTextureEnabled(ENV.getNumber("WEBGL_VERSION"))), ENV.registerFlag("WEBGL_FENCE_API_ENABLED", () => isWebGLFenceEnabled(ENV.getNumber("WEBGL_VERSION"))), ENV.registerFlag("WEBGL_SIZE_UPLOAD_UNIFORM", () => ENV.getBool("WEBGL_RENDER_FLOAT32_ENABLED") ? 4 : 0), ENV.registerFlag("WEBGL_DELETE_TEXTURE_THRESHOLD", () => -1, e => {
  if (e < 0 && -1 !== e) throw new Error("WEBGL_DELETE_TEXTURE_THRESHOLD must be -1 (indicating never delete) or at least 0, but got ".concat(e, "."));
}), ENV.registerFlag("WEBGL_FLUSH_THRESHOLD", () => isMobile() && ENV.getBool("IS_CHROME") ? 1 : -1, e => {
  if (e < 0 && -1 !== e) throw new Error("WEBGL_FLUSH_THRESHOLD must be -1 (indicating never manual flush) or at least 0, but got ".concat(e, "."));
}), ENV.registerFlag("CPU_HANDOFF_SIZE_THRESHOLD", () => 128), ENV.registerFlag("WEBGL_USE_SHAPES_UNIFORMS", () => !1), ENV.registerFlag("TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD", () => 1e5), ENV.registerFlag("TOPK_K_CPU_HANDOFF_THRESHOLD", () => 128);
var ENCODE_FLOAT_SNIPPET = "\n  const float FLOAT_MAX = 1.70141184e38;\n  const float FLOAT_MIN = 1.17549435e-38;\n\n  lowp vec4 encode_float(highp float v) {\n    if (isnan(v)) {\n      return vec4(255, 255, 255, 255);\n    }\n\n    highp float av = abs(v);\n\n    if(av < FLOAT_MIN) {\n      return vec4(0.0, 0.0, 0.0, 0.0);\n    } else if(v > FLOAT_MAX) {\n      return vec4(0.0, 0.0, 128.0, 127.0) / 255.0;\n    } else if(v < -FLOAT_MAX) {\n      return vec4(0.0, 0.0,  128.0, 255.0) / 255.0;\n    }\n\n    highp vec4 c = vec4(0,0,0,0);\n\n    highp float e = floor(log2(av));\n    highp float m = exp2(fract(log2(av))) - 1.0;\n\n    c[2] = floor(128.0 * m);\n    m -= c[2] / 128.0;\n    c[1] = floor(32768.0 * m);\n    m -= c[1] / 32768.0;\n    c[0] = floor(8388608.0 * m);\n\n    highp float ebias = e + 127.0;\n    c[3] = floor(ebias / 2.0);\n    ebias -= c[3] * 2.0;\n    c[2] += floor(ebias) * 128.0;\n\n    c[3] += 128.0 * step(0.0, -v);\n\n    return c / 255.0;\n  }\n";

class DecodeMatrixProgram {
  constructor(e) {
    this.variableNames = ["A"], this.packedInputs = !1, this.packedOutput = !0, this.outPackingScheme = PackingScheme.DENSE;
    var t = getDenseTexShape(e),
        n = getGlslDifferences();
    this.outputShape = e, this.userCode = "\n      ivec3 outCoordsFromFlatIndex(int index) {\n        ".concat(getLogicalCoordinatesFromFlatIndex(["r", "c", "d"], e), "\n        return ivec3(r, c, d);\n      }\n\n      void main() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n          vec2(").concat(t[0], ", ").concat(t[1], "));\n        int index = 4 * (resTexRC.x * ").concat(t[1], " + resTexRC.y);\n\n        vec4 result = vec4(0.);\n\n        for (int i=0; i<4; i++) {\n          int flatIndex = index + i;\n          ivec3 rc = outCoordsFromFlatIndex(flatIndex);\n          result[i] = getA(rc.x, rc.y, rc.z);\n        }\n\n        ").concat(n.output, " = result;\n      }\n    ");
  }

}

class DecodeMatrixPackedProgram {
  constructor(e) {
    this.variableNames = ["A"], this.packedInputs = !0, this.packedOutput = !0, this.outPackingScheme = PackingScheme.DENSE;
    var t = getDenseTexShape(e),
        n = getGlslDifferences();
    this.outputShape = e, this.userCode = "\n      ivec3 outCoordsFromFlatIndex(int index) {\n        ".concat(getLogicalCoordinatesFromFlatIndex(["r", "c", "d"], e), "\n        return ivec3(r, c, d);\n      }\n\n      void main() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n          vec2(").concat(t[0], ", ").concat(t[1], "));\n        int index = 4 * (resTexRC.x * ").concat(t[1], " + resTexRC.y);\n\n        vec4 result = vec4(0.);\n\n        for (int i=0; i<4; i++) {\n          int flatIndex = index + i;\n          ivec3 rc = outCoordsFromFlatIndex(flatIndex);\n          result[i] = getChannel(getA(rc.x, rc.y, rc.z), vec2(rc.y, rc.z));\n        }\n\n        ").concat(n.output, " = result;\n      }\n    ");
  }

}

class EncodeFloatProgram {
  constructor(e) {
    this.variableNames = ["A"], this.outTexUsage = TextureUsage.DOWNLOAD;
    var t = getGlslDifferences();
    this.outputShape = e, this.userCode = "\n      ".concat(ENCODE_FLOAT_SNIPPET, "\n\n      void main() {\n        float x = getAAtOutCoords();\n        ").concat(t.output, " = encode_float(x);\n      }\n    ");
  }

}

class EncodeFloatPackedProgram {
  constructor(e) {
    this.variableNames = ["A"], this.packedInputs = !0, this.packedOutput = !1, this.outTexUsage = TextureUsage.DOWNLOAD;
    var t = getGlslDifferences();
    this.outputShape = e, this.userCode = "\n      ".concat(ENCODE_FLOAT_SNIPPET, "\n\n      void main() {\n        ivec3 coords = getOutputCoords();\n        float x = getChannel(getAAtOutCoords(), vec2(coords.y, coords.z));\n        ").concat(t.output, " = encode_float(x);\n      }\n    ");
  }

}

class EncodeMatrixProgram {
  constructor(e, t) {
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
    this.variableNames = ["A"];
    var r = getGlslDifferences(),
        [a, s] = t;
    this.outputShape = e;
    var o = "result";
    n && (o = "floor(result * 255. + 0.5)"), this.userCode = "\n      ".concat(getFlatIndexFrom3D(e), "\n\n      void main() {\n        ivec3 coords = getOutputCoords();\n\n        int flatIndex = getFlatIndex(coords);\n        int offset = imod(flatIndex, 4);\n\n        flatIndex = idiv(flatIndex, 4, 1.);\n\n        int r = flatIndex / ").concat(s, ";\n        int c = imod(flatIndex, ").concat(s, ");\n        vec2 uv = (vec2(c, r) + halfCR) / vec2(").concat(s, ".0, ").concat(a, ".0);\n        vec4 values = ").concat(r.texture2D, "(A, uv);\n\n        float result;\n\n        if(offset == 0) {\n          result = values[0];\n        } else if(offset == 1) {\n          result = values[1];\n        } else if(offset == 2) {\n          result = values[2];\n        } else {\n          result = values[3];\n        }\n\n        ").concat(r.output, " = vec4(").concat(o, ", 0., 0., 0.);\n      }\n    ");
  }

}

class EncodeMatrixPackedProgram {
  constructor(e, t) {
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
    this.variableNames = ["A"], this.packedInputs = !1, this.packedOutput = !0;
    var r = getGlslDifferences(),
        [a, s] = t;
    this.outputShape = e;
    var o = "",
        i = "result";
    n && (i = "floor(result * 255. + 0.5)");

    for (var _t671 = 0; _t671 <= 1; _t671++) {
      for (var _n417 = 0; _n417 <= 1; _n417++) {
        var _i81 = 2 * _t671 + _n417;

        o += "\n          localCoords = coords;\n          if(localCoords[2] + ".concat(_n417, " < ").concat(e[2], ") {\n            localCoords[2] += ").concat(_n417, ";\n            if(localCoords[1] + ").concat(_t671, " < ").concat(e[1], ") {\n              localCoords[1] += ").concat(_t671, ";\n\n              flatIndex = getFlatIndex(localCoords);\n              offset = imod(flatIndex, 4);\n\n              flatIndex = idiv(flatIndex, 4, 1.);\n\n              r = flatIndex / ").concat(s, ";\n              c = imod(flatIndex, ").concat(s, ");\n              uv = (vec2(c, r) + halfCR) / vec2(").concat(s, ".0, ").concat(a, ".0);\n              values = ").concat(r.texture2D, "(A, uv);\n\n              if(offset == 0) {\n                result[").concat(_i81, "] = values[0];\n              } else if(offset == 1) {\n                result[").concat(_i81, "] = values[1];\n              } else if(offset == 2) {\n                result[").concat(_i81, "] = values[2];\n              } else {\n                result[").concat(_i81, "] = values[3];\n              }\n            }\n          }\n        ");
      }
    }

    this.userCode = "\n      ".concat(getFlatIndexFrom3D(e), "\n\n      void main() {\n        ivec3 coords = getOutputCoords();\n\n        vec4 result = vec4(0.);\n        int flatIndex, r, c, offset;\n        ivec3 localCoords;\n        vec2 uv;\n        vec4 values;\n\n        ").concat(o, "\n\n        ").concat(r.output, " = ").concat(i, ";\n      }\n    ");
  }

}

function createVertexShader(e) {
  var t = getGlslDifferences();
  return createVertexShader$1(e, "".concat(t.version, "\n    precision highp float;\n    ").concat(t.attribute, " vec3 clipSpacePos;\n    ").concat(t.attribute, " vec2 uv;\n    ").concat(t.varyingVs, " vec2 resultUV;\n\n    void main() {\n      gl_Position = vec4(clipSpacePos, 1);\n      resultUV = uv;\n    }"));
}

function createVertexBuffer(e) {
  return createStaticVertexBuffer(e, new Float32Array([-1, 1, 0, 0, 1, -1, -1, 0, 0, 0, 1, 1, 0, 1, 1, 1, -1, 0, 1, 0]));
}

function createIndexBuffer(e) {
  return createStaticIndexBuffer(e, new Uint16Array([0, 1, 2, 2, 1, 3]));
}

function createAndConfigureTexture(e, t, n, r, a, s) {
  validateTextureSize(t, n);
  var o = createTexture(e),
      i = e.TEXTURE_2D;
  return callAndCheck(e, () => e.bindTexture(i, o)), callAndCheck(e, () => e.texParameteri(i, e.TEXTURE_WRAP_S, e.CLAMP_TO_EDGE)), callAndCheck(e, () => e.texParameteri(i, e.TEXTURE_WRAP_T, e.CLAMP_TO_EDGE)), callAndCheck(e, () => e.texParameteri(i, e.TEXTURE_MIN_FILTER, e.NEAREST)), callAndCheck(e, () => e.texParameteri(i, e.TEXTURE_MAG_FILTER, e.NEAREST)), callAndCheck(e, () => e.texImage2D(i, 0, r, t, n, 0, a, s, null)), callAndCheck(e, () => e.bindTexture(e.TEXTURE_2D, null)), o;
}

function getInternalFormatForFloat32MatrixTexture(e) {
  return e.internalFormatFloat;
}

function createFloat32MatrixTexture(e, t, n, r) {
  var [a, s] = getUnpackedMatrixTextureShapeWidthHeight(t, n);
  return createAndConfigureTexture(e, a, s, getInternalFormatForFloat32MatrixTexture(r), r.textureFormatFloat, e.FLOAT);
}

function getInternalFormatForFloat16MatrixTexture(e) {
  return e.internalFormatHalfFloat;
}

function createFloat16MatrixTexture(e, t, n, r) {
  var [a, s] = getUnpackedMatrixTextureShapeWidthHeight(t, n);
  return createAndConfigureTexture(e, a, s, getInternalFormatForFloat16MatrixTexture(r), r.textureFormatFloat, r.textureTypeHalfFloat);
}

function getInternalFormatForUnsignedBytesMatrixTexture(e) {
  return e.downloadTextureFormat;
}

function createUnsignedBytesMatrixTexture(e, t, n, r) {
  var [a, s] = getUnpackedMatrixTextureShapeWidthHeight(t, n);
  return createAndConfigureTexture(e, a, s, getInternalFormatForUnsignedBytesMatrixTexture(r), e.RGBA, e.UNSIGNED_BYTE);
}

function getInternalFormatForPackedMatrixTexture(e) {
  return e.internalFormatPackedFloat;
}

function createPackedMatrixTexture(e, t, n, r) {
  var [a, s] = getPackedMatrixTextureShapeWidthHeight(t, n);
  return createAndConfigureTexture(e, a, s, getInternalFormatForPackedMatrixTexture(r), e.RGBA, e.FLOAT);
}

function getInternalFormatForFloat16PackedMatrixTexture(e) {
  return e.internalFormatPackedHalfFloat;
}

function createFloat16PackedMatrixTexture(e, t, n, r) {
  var [a, s] = getPackedMatrixTextureShapeWidthHeight(t, n);
  return createAndConfigureTexture(e, a, s, getInternalFormatForFloat16PackedMatrixTexture(r), e.RGBA, r.textureTypeHalfFloat);
}

function bindVertexProgramAttributeStreams(e, t, n) {
  return callAndCheck(e, () => e.bindBuffer(e.ARRAY_BUFFER, n)), bindVertexBufferToProgramAttribute(e, t, "clipSpacePos", n, 3, 20, 0) && bindVertexBufferToProgramAttribute(e, t, "uv", n, 2, 20, 12);
}

function uploadDenseMatrixToTexture(e, t, n, r, a, s) {
  var o, i, l;
  callAndCheck(e, () => e.bindTexture(e.TEXTURE_2D, t)), a instanceof Uint8Array ? (o = new Uint8Array(n * r * 4), i = e.UNSIGNED_BYTE, l = e.RGBA) : (o = new Float32Array(n * r * 4), i = e.FLOAT, l = s.internalFormatPackedFloat), o.set(a), callAndCheck(e, () => e.texImage2D(e.TEXTURE_2D, 0, l, n, r, 0, e.RGBA, i, o)), callAndCheck(e, () => e.bindTexture(e.TEXTURE_2D, null));
}

function uploadPixelDataToTexture(e, t, n) {
  callAndCheck(e, () => e.bindTexture(e.TEXTURE_2D, t)), n.data instanceof Uint8Array ? callAndCheck(e, () => e.texImage2D(e.TEXTURE_2D, 0, e.RGBA, n.width, n.height, 0, e.RGBA, e.UNSIGNED_BYTE, n.data)) : callAndCheck(e, () => e.texImage2D(e.TEXTURE_2D, 0, e.RGBA, e.RGBA, e.UNSIGNED_BYTE, n)), callAndCheck(e, () => e.bindTexture(e.TEXTURE_2D, null));
}

function createBufferFromOutputTexture(e, t, n, r) {
  var a = e.createBuffer();
  callAndCheck(e, () => e.bindBuffer(e.PIXEL_PACK_BUFFER, a));
  var s = 16 * t * n;
  return callAndCheck(e, () => e.bufferData(e.PIXEL_PACK_BUFFER, s, e.STREAM_READ)), callAndCheck(e, () => e.readPixels(0, 0, n, t, e.RGBA, e.FLOAT, 0)), callAndCheck(e, () => e.bindBuffer(e.PIXEL_PACK_BUFFER, null)), a;
}

function downloadFloat32MatrixFromBuffer(e, t, n) {
  var r = e,
      a = new Float32Array(n);
  return r.bindBuffer(r.PIXEL_PACK_BUFFER, t), r.getBufferSubData(r.PIXEL_PACK_BUFFER, 0, a), r.bindBuffer(r.PIXEL_PACK_BUFFER, null), a;
}

function downloadByteEncodedFloatMatrixFromOutputTexture(e, t, n, r) {
  var [a, s] = getUnpackedMatrixTextureShapeWidthHeight(t, n),
      o = new Uint8Array(getUnpackedArraySizeFromMatrixSize(t * n, 4));
  return callAndCheck(e, () => e.readPixels(0, 0, a, s, r.downloadTextureFormat, e.UNSIGNED_BYTE, o)), new Float32Array(o.buffer);
}

function downloadPackedMatrixFromBuffer(e, t, n, r, a, s, o, i) {
  var l = e,
      u = new Float32Array(getPackedRGBAArraySizeFromMatrixShape(s, o));
  return l.bindBuffer(l.PIXEL_PACK_BUFFER, t), l.getBufferSubData(l.PIXEL_PACK_BUFFER, 0, u), l.bindBuffer(l.PIXEL_PACK_BUFFER, null), u;
}

function downloadMatrixFromPackedOutputTexture(e, t, n) {
  var r = new Float32Array(t * n * 4);
  return callAndCheck(e, () => e.readPixels(0, 0, n, t, e.RGBA, e.FLOAT, r)), r;
}

class GPGPUContext {
  constructor(e) {
    this.outputTexture = null, this.program = null, this.disposed = !1, this.vertexAttrsAreBound = !1, this.itemsToPoll = [];
    var t = env().getNumber("WEBGL_VERSION");
    null != e ? (this.gl = e, setWebGLContext(t, e)) : this.gl = getWebGLContext(t);
    var n = "WEBGL_color_buffer_float";
    var r = "EXT_color_buffer_half_float";

    if (1 === env().getNumber("WEBGL_VERSION")) {
      var _e988 = "OES_texture_half_float";
      if (this.textureFloatExtension = getExtensionOrThrow(this.gl, "OES_texture_float"), hasExtension(this.gl, _e988)) this.textureHalfFloatExtension = getExtensionOrThrow(this.gl, _e988);else if (env().get("WEBGL_FORCE_F16_TEXTURES")) throw new Error("GL context does not support half float textures, yet the environment flag WEBGL_FORCE_F16_TEXTURES is set to true.");
      if (this.colorBufferFloatExtension = this.gl.getExtension(n), hasExtension(this.gl, r)) this.colorBufferHalfFloatExtension = getExtensionOrThrow(this.gl, r);else if (env().get("WEBGL_FORCE_F16_TEXTURES")) throw new Error("GL context does not support color renderable half floats, yet the environment flag WEBGL_FORCE_F16_TEXTURES is set to true.");
    } else if (n = "EXT_color_buffer_float", hasExtension(this.gl, n)) this.colorBufferFloatExtension = this.gl.getExtension(n);else {
      if (!hasExtension(this.gl, r)) throw new Error("GL context does not support color renderable floats");
      this.colorBufferHalfFloatExtension = this.gl.getExtension(r);
    }

    this.vertexBuffer = createVertexBuffer(this.gl), this.indexBuffer = createIndexBuffer(this.gl), this.framebuffer = createFramebuffer(this.gl), this.textureConfig = getTextureConfig(this.gl, this.textureHalfFloatExtension);
  }

  get debug() {
    return env().getBool("DEBUG");
  }

  dispose() {
    if (this.disposed) return;
    null != this.program && console.warn("Disposing a GPGPUContext that still has a bound WebGLProgram. This is probably a resource leak, delete the program with GPGPUContext.deleteProgram before disposing."), null != this.outputTexture && console.warn("Disposing a GPGPUContext that still has a bound output matrix texture.  This is probably a resource leak, delete the output matrix texture with GPGPUContext.deleteMatrixTexture before disposing.");
    var e = this.gl;
    callAndCheck(e, () => e.finish()), callAndCheck(e, () => e.bindFramebuffer(e.FRAMEBUFFER, null)), callAndCheck(e, () => e.deleteFramebuffer(this.framebuffer)), callAndCheck(e, () => e.bindBuffer(e.ARRAY_BUFFER, null)), callAndCheck(e, () => e.bindBuffer(e.ELEMENT_ARRAY_BUFFER, null)), callAndCheck(e, () => e.deleteBuffer(this.indexBuffer)), this.disposed = !0;
  }

  createFloat32MatrixTexture(e, t) {
    return this.throwIfDisposed(), createFloat32MatrixTexture(this.gl, e, t, this.textureConfig);
  }

  createFloat16MatrixTexture(e, t) {
    return this.throwIfDisposed(), createFloat16MatrixTexture(this.gl, e, t, this.textureConfig);
  }

  createUnsignedBytesMatrixTexture(e, t) {
    return this.throwIfDisposed(), createUnsignedBytesMatrixTexture(this.gl, e, t, this.textureConfig);
  }

  uploadPixelDataToTexture(e, t) {
    this.throwIfDisposed(), uploadPixelDataToTexture(this.gl, e, t);
  }

  uploadDenseMatrixToTexture(e, t, n, r) {
    this.throwIfDisposed(), uploadDenseMatrixToTexture(this.gl, e, t, n, r, this.textureConfig);
  }

  createFloat16PackedMatrixTexture(e, t) {
    return this.throwIfDisposed(), createFloat16PackedMatrixTexture(this.gl, e, t, this.textureConfig);
  }

  createPackedMatrixTexture(e, t) {
    return this.throwIfDisposed(), createPackedMatrixTexture(this.gl, e, t, this.textureConfig);
  }

  deleteMatrixTexture(e) {
    this.throwIfDisposed(), this.outputTexture === e && (unbindColorTextureFromFramebuffer(this.gl, this.framebuffer), this.outputTexture = null), callAndCheck(this.gl, () => this.gl.deleteTexture(e));
  }

  downloadByteEncodedFloatMatrixFromOutputTexture(e, t, n) {
    return this.downloadMatrixDriver(e, () => downloadByteEncodedFloatMatrixFromOutputTexture(this.gl, t, n, this.textureConfig));
  }

  downloadPackedMatrixFromBuffer(e, t, n, r, a, s) {
    return downloadPackedMatrixFromBuffer(this.gl, e, t, n, r, a, s);
  }

  downloadFloat32MatrixFromBuffer(e, t) {
    return downloadFloat32MatrixFromBuffer(this.gl, e, t);
  }

  createBufferFromTexture(e, t, n) {
    this.bindTextureToFrameBuffer(e);
    var r = createBufferFromOutputTexture(this.gl, t, n);
    return this.unbindTextureToFrameBuffer(), r;
  }

  createAndWaitForFence() {
    var e = this.createFence(this.gl);
    return this.pollFence(e);
  }

  createFence(e) {
    var t, n;

    if (env().getBool("WEBGL_FENCE_API_ENABLED")) {
      var r = e,
          a = r.fenceSync(r.SYNC_GPU_COMMANDS_COMPLETE, 0);
      e.flush(), n = () => {
        var e = r.clientWaitSync(a, 0, 0);
        return e === r.ALREADY_SIGNALED || e === r.CONDITION_SATISFIED;
      }, t = a;
    } else env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") > 0 ? (t = this.beginQuery(), this.endQuery(), n = () => this.isQueryAvailable(t, env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"))) : n = () => !0;

    return {
      query: t,
      isFencePassed: n
    };
  }

  downloadMatrixFromPackedTexture(e, t, n) {
    return this.downloadMatrixDriver(e, () => downloadMatrixFromPackedOutputTexture(this.gl, t, n));
  }

  createProgram(e) {
    this.throwIfDisposed();
    var t = this.gl,
        n = createFragmentShader(t, e);
    null == this.vertexShader && (this.vertexShader = createVertexShader(t));
    var r = createProgram(t);
    return callAndCheck(t, () => t.attachShader(r, this.vertexShader)), callAndCheck(t, () => t.attachShader(r, n)), linkProgram(t, r), this.debug && validateProgram(t, r), this.vertexAttrsAreBound || (this.setProgram(r), this.vertexAttrsAreBound = bindVertexProgramAttributeStreams(t, this.program, this.vertexBuffer)), r;
  }

  deleteProgram(e) {
    this.throwIfDisposed(), e === this.program && (this.program = null), null != e && callAndCheck(this.gl, () => this.gl.deleteProgram(e));
  }

  setProgram(e) {
    this.throwIfDisposed(), this.program = e, null != this.program && this.debug && validateProgram(this.gl, this.program), callAndCheck(this.gl, () => this.gl.useProgram(e));
  }

  getUniformLocation(e, t) {
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !0;
    return this.throwIfDisposed(), n ? getProgramUniformLocationOrThrow(this.gl, e, t) : getProgramUniformLocation(this.gl, e, t);
  }

  getAttributeLocation(e, t) {
    return this.throwIfDisposed(), callAndCheck(this.gl, () => this.gl.getAttribLocation(e, t));
  }

  getUniformLocationNoThrow(e, t) {
    return this.throwIfDisposed(), this.gl.getUniformLocation(e, t);
  }

  setInputMatrixTexture(e, t, n) {
    this.throwIfDisposed(), this.throwIfNoProgram(), bindTextureToProgramUniformSampler(this.gl, e, t, n);
  }

  setOutputMatrixTexture(e, t, n) {
    this.setOutputMatrixTextureDriver(e, n, t);
  }

  setOutputPackedMatrixTexture(e, t, n) {
    this.throwIfDisposed();
    var [r, a] = getPackedMatrixTextureShapeWidthHeight(t, n);
    this.setOutputMatrixTextureDriver(e, r, a);
  }

  setOutputMatrixWriteRegion(e, t, n, r) {
    this.setOutputMatrixWriteRegionDriver(n, e, r, t);
  }

  setOutputPackedMatrixWriteRegion(e, t, n, r) {
    throw new Error("setOutputPackedMatrixWriteRegion not implemented.");
  }

  debugValidate() {
    null != this.program && validateProgram(this.gl, this.program), validateFramebuffer(this.gl);
  }

  executeProgram() {
    this.throwIfDisposed(), this.throwIfNoProgram();
    var e = this.gl;
    this.debug && this.debugValidate(), callAndCheck(e, () => e.drawElements(e.TRIANGLES, 6, e.UNSIGNED_SHORT, 0));
  }

  blockUntilAllProgramsCompleted() {
    this.throwIfDisposed(), callAndCheck(this.gl, () => this.gl.finish());
  }

  getQueryTimerExtension() {
    return null == this.disjointQueryTimerExtension && (this.disjointQueryTimerExtension = getExtensionOrThrow(this.gl, 2 === env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION") ? "EXT_disjoint_timer_query_webgl2" : "EXT_disjoint_timer_query")), this.disjointQueryTimerExtension;
  }

  getQueryTimerExtensionWebGL2() {
    return this.getQueryTimerExtension();
  }

  getQueryTimerExtensionWebGL1() {
    return this.getQueryTimerExtension();
  }

  beginQuery() {
    if (2 === env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")) {
      var _e989 = this.gl,
          _t672 = this.getQueryTimerExtensionWebGL2(),
          n = _e989.createQuery();

      return _e989.beginQuery(_t672.TIME_ELAPSED_EXT, n), n;
    }

    var e = this.getQueryTimerExtensionWebGL1(),
        t = e.createQueryEXT();
    return e.beginQueryEXT(e.TIME_ELAPSED_EXT, t), t;
  }

  endQuery() {
    if (2 === env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION")) {
      var _e990 = this.gl,
          t = this.getQueryTimerExtensionWebGL2();
      return void _e990.endQuery(t.TIME_ELAPSED_EXT);
    }

    var e = this.getQueryTimerExtensionWebGL1();
    e.endQueryEXT(e.TIME_ELAPSED_EXT);
  }

  waitForQueryAndGetTime(e) {
    var _this215 = this;

    return _asyncToGenerator(function* () {
      return yield repeatedTry(() => _this215.disposed || _this215.isQueryAvailable(e, env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"))), _this215.getQueryTime(e, env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_VERSION"));
    })();
  }

  getQueryTime(e, t) {
    if (0 === t) return null;

    if (2 === t) {
      var _t673 = this.gl;
      return _t673.getQueryParameter(e, _t673.QUERY_RESULT) / 1e6;
    }

    {
      var _t674 = this.getQueryTimerExtensionWebGL1();

      return _t674.getQueryObjectEXT(e, _t674.QUERY_RESULT_EXT) / 1e6;
    }
  }

  isQueryAvailable(e, t) {
    if (0 === t) return !0;

    if (2 === t) {
      var _t675 = this.gl,
          n = this.getQueryTimerExtensionWebGL2(),
          r = _t675.getQueryParameter(e, _t675.QUERY_RESULT_AVAILABLE);

      return null == this.disjoint && (this.disjoint = this.gl.getParameter(n.GPU_DISJOINT_EXT)), r && !this.disjoint;
    }

    {
      var _t676 = this.getQueryTimerExtensionWebGL1(),
          _n418 = _t676.getQueryObjectEXT(e, _t676.QUERY_RESULT_AVAILABLE_EXT);

      return null == this.disjoint && (this.disjoint = this.gl.getParameter(_t676.GPU_DISJOINT_EXT)), _n418 && !this.disjoint;
    }
  }

  pollFence(e) {
    return new Promise(t => {
      this.addItemToPoll(() => e.isFencePassed(), () => t());
    });
  }

  pollItems() {
    var e = linearSearchLastTrue(this.itemsToPoll.map(e => e.isDoneFn));

    for (var t = 0; t <= e; ++t) {
      var {
        resolveFn: _e991
      } = this.itemsToPoll[t];

      _e991();
    }

    this.itemsToPoll = this.itemsToPoll.slice(e + 1);
  }

  addItemToPoll(e, t) {
    this.itemsToPoll.push({
      isDoneFn: e,
      resolveFn: t
    }), this.itemsToPoll.length > 1 || repeatedTry(() => (this.pollItems(), 0 === this.itemsToPoll.length));
  }

  bindTextureToFrameBuffer(e) {
    this.throwIfDisposed(), bindColorTextureToFramebuffer(this.gl, e, this.framebuffer), this.debug && validateFramebuffer(this.gl);
  }

  unbindTextureToFrameBuffer() {
    null != this.outputTexture ? (bindColorTextureToFramebuffer(this.gl, this.outputTexture, this.framebuffer), this.debug && validateFramebuffer(this.gl)) : unbindColorTextureFromFramebuffer(this.gl, this.framebuffer);
  }

  downloadMatrixDriver(e, t) {
    this.bindTextureToFrameBuffer(e);
    var n = t();
    return this.unbindTextureToFrameBuffer(), n;
  }

  setOutputMatrixTextureDriver(e, t, n) {
    this.throwIfDisposed();
    var r = this.gl;
    bindColorTextureToFramebuffer(r, e, this.framebuffer), this.debug && validateFramebuffer(r), this.outputTexture = e, callAndCheck(r, () => r.viewport(0, 0, t, n)), callAndCheck(r, () => r.scissor(0, 0, t, n));
  }

  setOutputMatrixWriteRegionDriver(e, t, n, r) {
    this.throwIfDisposed(), callAndCheck(this.gl, () => this.gl.scissor(e, t, n, r));
  }

  throwIfDisposed() {
    if (this.disposed) throw new Error("Attempted to use disposed GPGPUContext.");
  }

  throwIfNoProgram() {
    if (null == this.program) throw new Error("No GPU program is currently set.");
  }

}

function linearSearchLastTrue(e) {
  var t = 0;

  for (; t < e.length && e[t](); ++t) {
    ;
  }

  return t - 1;
}

var {
  getBroadcastDims
} = backend_util;

function makeShader(e, t, n) {
  var r = [];

  if (e.forEach(e => {
    var t = sizeFromShape(e.shapeInfo.logicalShape);

    if (e.shapeInfo.isUniform ? r.push("uniform float ".concat(e.name).concat(t > 1 ? "[".concat(t, "]") : "", ";")) : (r.push("uniform sampler2D ".concat(e.name, ";")), r.push("uniform int offset".concat(e.name, ";"))), n.enableShapeUniforms) {
      var {
        uniformShape: _t677
      } = getUniformInfoFromShape(n.packedInputs, e.shapeInfo.logicalShape, e.shapeInfo.texShape);

      switch (_t677.length) {
        case 1:
          r.push("uniform int ".concat(e.name, "Shape;"));
          break;

        case 2:
          r.push("uniform ivec2 ".concat(e.name, "Shape;"));
          break;

        case 3:
          r.push("uniform ivec3 ".concat(e.name, "Shape;"));
          break;

        case 4:
          r.push("uniform ivec4 ".concat(e.name, "Shape;"));
      }

      r.push("uniform ivec2 ".concat(e.name, "TexShape;"));
    }
  }), n.enableShapeUniforms) {
    switch (t.logicalShape.length) {
      case 1:
        r.push("uniform int outShape;");
        break;

      case 2:
        r.push("uniform ivec2 outShape;"), r.push("uniform int outShapeStrides;");
        break;

      case 3:
        r.push("uniform ivec3 outShape;"), r.push("uniform ivec2 outShapeStrides;");
        break;

      case 4:
        r.push("uniform ivec4 outShape;"), r.push("uniform ivec3 outShapeStrides;");
    }

    r.push("uniform ivec2 outTexShape;");
  }

  n.customUniforms && n.customUniforms.forEach(e => {
    r.push("uniform ".concat(e.type, " ").concat(e.name).concat(e.arrayIndex ? "[".concat(e.arrayIndex, "]") : "", ";"));
  });
  var a = r.join("\n"),
      s = e.map(e => getInputSamplingSnippet(e, t, n.packedInputs, n.enableShapeUniforms)).join("\n"),
      o = t.texShape,
      i = getGlslDifferences(),
      l = getFloatTextureSampleSnippet(i);
  var u,
      c,
      p = getShaderPrefix(i);
  return t.isPacked ? (u = getPackedOutputSamplingSnippet(t.logicalShape, o, n.enableShapeUniforms), c = getFloatTextureSetRGBASnippet(i)) : (u = getOutputSamplingSnippet(t.logicalShape, o, n.enableShapeUniforms), c = getFloatTextureSetRSnippet(i)), n.packedInputs && (p += SHADER_PACKED_PREFIX), [p, l, c, a, u, s, n.userCode].join("\n");
}

function getSamplerFromInInfo(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;
  var n = e.shapeInfo.logicalShape;

  switch (n.length) {
    case 0:
      return getSamplerScalar(e, t);

    case 1:
      return getSampler1D(e, t);

    case 2:
      return getSampler2D(e, t);

    case 3:
      return getSampler3D(e, t);

    case 4:
      return getSampler4D(e, t);

    case 5:
      return getSampler5D(e);

    case 6:
      return getSampler6D(e);

    default:
      throw new Error("".concat(n.length, "-D input sampling is not yet supported"));
  }
}

function getPackedSamplerFromInInfo(e, t) {
  switch (e.shapeInfo.logicalShape.length) {
    case 0:
      return getPackedSamplerScalar(e);

    case 1:
      return getPackedSampler1D(e, t);

    case 2:
      return getPackedSampler2D(e, t);

    case 3:
      return getPackedSampler3D(e, t);

    default:
      return getPackedSamplerND(e, t);
  }
}

function getInputSamplingSnippet(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : !1;
  var r = arguments.length > 3 ? arguments[3] : undefined;
  var a = "";
  return a += n ? getPackedSamplerFromInInfo(e, r) : getSamplerFromInInfo(e, r), e.shapeInfo.logicalShape.length <= t.logicalShape.length && (a += n ? getPackedSamplerAtOutputCoords(e, t) : getSamplerAtOutputCoords(e, t)), a;
}

function getPackedOutputSamplingSnippet(e, t, n) {
  switch (e.length) {
    case 0:
      return getOutputScalarCoords();

    case 1:
      return getOutputPacked1DCoords(e, t, n);

    case 2:
      return getOutputPacked2DCoords(e, t, n);

    case 3:
      return getOutputPacked3DCoords(e, t, n);

    default:
      return getOutputPackedNDCoords(e, t, n);
  }
}

function getOutputSamplingSnippet(e, t, n) {
  switch (e.length) {
    case 0:
      return getOutputScalarCoords();

    case 1:
      return getOutput1DCoords(e, t, n);

    case 2:
      return getOutput2DCoords(e, t, n);

    case 3:
      return getOutput3DCoords(e, t, n);

    case 4:
      return getOutput4DCoords(e, t, n);

    case 5:
      return getOutput5DCoords(e, t);

    case 6:
      return getOutput6DCoords(e, t);

    default:
      throw new Error("".concat(e.length, "-D output sampling is not yet supported"));
  }
}

function getFloatTextureSampleSnippet(e) {
  return "\n    float sampleTexture(sampler2D textureSampler, vec2 uv) {\n      return ".concat(e.texture2D, "(textureSampler, uv).r;\n    }\n  ");
}

function getFloatTextureSetRSnippet(e) {
  return "\n    void setOutput(float val) {\n      ".concat(e.output, " = vec4(val, 0, 0, 0);\n    }\n  ");
}

function getFloatTextureSetRGBASnippet(e) {
  return "\n    void setOutput(vec4 val) {\n      ".concat(e.output, " = val;\n    }\n  ");
}

function getShaderPrefix(e) {
  return "".concat(e.version, "\n    precision highp float;\n    precision highp int;\n    precision highp sampler2D;\n    ").concat(e.varyingFs, " vec2 resultUV;\n    ").concat(e.defineOutput, "\n    const vec2 halfCR = vec2(0.5, 0.5);\n\n    struct ivec5\n    {\n      int x;\n      int y;\n      int z;\n      int w;\n      int u;\n    };\n\n    struct ivec6\n    {\n      int x;\n      int y;\n      int z;\n      int w;\n      int u;\n      int v;\n    };\n\n    uniform float NAN;\n    ").concat(e.defineSpecialNaN, "\n    ").concat(e.defineSpecialInf, "\n    ").concat(e.defineRound, "\n\n    int imod(int x, int y) {\n      return x - y * (x / y);\n    }\n\n    int idiv(int a, int b, float sign) {\n      int res = a / b;\n      int mod = imod(a, b);\n      if (sign < 0. && mod != 0) {\n        res -= 1;\n      }\n      return res;\n    }\n\n    //Based on the work of Dave Hoskins\n    //https://www.shadertoy.com/view/4djSRW\n    #define HASHSCALE1 443.8975\n    float random(float seed){\n      vec2 p = resultUV * seed;\n      vec3 p3  = fract(vec3(p.xyx) * HASHSCALE1);\n      p3 += dot(p3, p3.yzx + 19.19);\n      return fract((p3.x + p3.y) * p3.z);\n    }\n\n    ").concat(SAMPLE_1D_SNIPPET, "\n    ").concat(SAMPLE_2D_SNIPPET, "\n    ").concat(SAMPLE_3D_SNIPPET, "\n  ");
}

var SAMPLE_1D_SNIPPET = "\nvec2 uvFromFlat(int texNumR, int texNumC, int index) {\n  int texR = index / texNumC;\n  int texC = index - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\nvec2 packedUVfrom1D(int texNumR, int texNumC, int index) {\n  int texelIndex = index / 2;\n  int texR = texelIndex / texNumC;\n  int texC = texelIndex - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\n",
    SAMPLE_2D_SNIPPET = "\nvec2 packedUVfrom2D(int texelsInLogicalRow, int texNumR,\n  int texNumC, int row, int col) {\n  int texelIndex = (row / 2) * texelsInLogicalRow + (col / 2);\n  int texR = texelIndex / texNumC;\n  int texC = texelIndex - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\n",
    SAMPLE_3D_SNIPPET = "\nvec2 packedUVfrom3D(int texNumR, int texNumC,\n    int texelsInBatch, int texelsInLogicalRow, int b,\n    int row, int col) {\n  int index = b * texelsInBatch + (row / 2) * texelsInLogicalRow + (col / 2);\n  int texR = index / texNumC;\n  int texC = index - texR * texNumC;\n  return (vec2(texC, texR) + halfCR) / vec2(texNumC, texNumR);\n}\n",
    SHADER_PACKED_PREFIX = "\n  float getChannel(vec4 frag, vec2 innerDims) {\n    vec2 modCoord = mod(innerDims, 2.);\n    return modCoord.x == 0. ?\n      (modCoord.y == 0. ? frag.r : frag.g) :\n      (modCoord.y == 0. ? frag.b : frag.a);\n  }\n  float getChannel(vec4 frag, int dim) {\n    float modCoord = mod(float(dim), 2.);\n    return modCoord == 0. ? frag.r : frag.g;\n  }\n";

function getOutputScalarCoords() {
  return "\n    int getOutputCoords() {\n      return 0;\n    }\n  ";
}

function getOutputPacked1DCoords(e, t, n) {
  var r = [Math.ceil(t[0] / 2), Math.ceil(t[1] / 2)];
  return 1 === r[0] ? n ? "\n      int getOutputCoords() {\n        return 2 * int(resultUV.x * ceil(float(outTexShape[1]) / 2.0));\n      }\n    " : "\n      int getOutputCoords() {\n        return 2 * int(resultUV.x * ".concat(r[1], ".0);\n      }\n    ") : 1 === r[1] ? n ? "\n      int getOutputCoords() {\n        return 2 * int(resultUV.y * ceil(float(outTexShape[0]) / 2.0));\n      }\n    " : "\n      int getOutputCoords() {\n        return 2 * int(resultUV.y * ".concat(r[0], ".0);\n      }\n    ") : n ? "\n    int getOutputCoords() {\n      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(packedTexShape[0], packedTexShape[1]));\n      return 2 * (resTexRC.x * packedTexShape[1] + resTexRC.y);\n    }\n  " : "\n    int getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(".concat(r[0], ", ").concat(r[1], "));\n      return 2 * (resTexRC.x * ").concat(r[1], " + resTexRC.y);\n    }\n  ");
}

function getOutput1DCoords(e, t, n) {
  return 1 === t[0] ? n ? "\n      int getOutputCoords() {\n        return int(resultUV.x * float(outTexShape[1]));\n      }\n    " : "\n      int getOutputCoords() {\n        return int(resultUV.x * ".concat(t[1], ".0);\n      }\n    ") : 1 === t[1] ? n ? "\n      int getOutputCoords() {\n        return int(resultUV.y * float(outTexShape[0]));\n      }\n    " : "\n      int getOutputCoords() {\n        return int(resultUV.y * ".concat(t[0], ".0);\n      }\n    ") : n ? "\n    int getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(outTexShape[0], outTexShape[1]));\n      return resTexRC.x * outTexShape[1] + resTexRC.y;\n    }\n  " : "\n    int getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(".concat(t[0], ", ").concat(t[1], "));\n      return resTexRC.x * ").concat(t[1], " + resTexRC.y;\n    }\n  ");
}

function getOutputPacked3DCoords(e, t, n) {
  if (n) return "\n    ivec3 getOutputCoords() {\n      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\n      int texelsInLogicalRow = int(ceil(float(outShape[2]) / 2.0));\n      int texelsInBatch = texelsInLogicalRow * int(ceil(float(outShape[1]) / 2.0));\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(packedTexShape[0], packedTexShape[1]));\n      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;\n\n      int b = index / texelsInBatch;\n      index -= b * texelsInBatch;\n\n      int r = 2 * (index / texelsInLogicalRow);\n      int c = imod(index, texelsInLogicalRow) * 2;\n\n      return ivec3(b, r, c);\n    }\n  ";
  var r = [Math.ceil(t[0] / 2), Math.ceil(t[1] / 2)],
      a = Math.ceil(e[2] / 2),
      s = a * Math.ceil(e[1] / 2);
  return "\n    ivec3 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(".concat(r[0], ", ").concat(r[1], "));\n      int index = resTexRC.x * ").concat(r[1], " + resTexRC.y;\n\n      int b = index / ").concat(s, ";\n      index -= b * ").concat(s, ";\n\n      int r = 2 * (index / ").concat(a, ");\n      int c = imod(index, ").concat(a, ") * 2;\n\n      return ivec3(b, r, c);\n    }\n  ");
}

function getOutput3DCoords(e, t, n) {
  if (n) return "\n  ivec3 getOutputCoords() {\n    ivec2 resTexRC = ivec2(resultUV.yx *\n                           vec2(outTexShape[0], outTexShape[1]));\n    int index = resTexRC.x * outTexShape[1] + resTexRC.y;\n    ".concat(getLogicalCoordinatesFromFlatIndexByUniform(["r", "c", "d"], e), "\n    return ivec3(r, c, d);\n  }\n");
  var r = getLogicalCoordinatesFromFlatIndex(["r", "c", "d"], e);
  return "\n    ivec3 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(".concat(t[0], ", ").concat(t[1], "));\n      int index = resTexRC.x * ").concat(t[1], " + resTexRC.y;\n      ").concat(r, "\n      return ivec3(r, c, d);\n    }\n  ");
}

function getOutputPackedNDCoords(e, t, n) {
  if (n) return "\n    ivec4 getOutputCoords() {\n      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(packedTexShape[0], packedTexShape[1]));\n      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;\n\n      int texelsInLogicalRow = int(ceil(float(outShape[3]) / 2.0));\n      int texelsInBatch = texelsInLogicalRow * int(ceil(float(outShape[2]) / 2.0));\n      int texelsInBatchN = texelsInBatch * outShape[1];\n\n      int b2 = index / texelsInBatchN;\n      index -= b2 * texelsInBatchN;\n\n      int b = index / texelsInBatch;\n      index -= b * texelsInBatch;\n\n      int r = 2 * (index / texelsInLogicalRow);\n      int c = imod(index, texelsInLogicalRow) * 2;\n\n      return ivec4(b2, b, r, c);\n    }\n  ";
  var r = [Math.ceil(t[0] / 2), Math.ceil(t[1] / 2)],
      a = Math.ceil(e[e.length - 1] / 2),
      s = a * Math.ceil(e[e.length - 2] / 2);
  var o = s,
      i = "",
      l = "b, r, c";

  for (var _t678 = 2; _t678 < e.length - 1; _t678++) {
    o *= e[e.length - _t678 - 1], i = "\n      int b".concat(_t678, " = index / ").concat(o, ";\n      index -= b").concat(_t678, " * ").concat(o, ";\n    ") + i, l = "b".concat(_t678, ", ") + l;
  }

  return "\n    ivec".concat(e.length, " getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(").concat(r[0], ", ").concat(r[1], "));\n      int index = resTexRC.x * ").concat(r[1], " + resTexRC.y;\n\n      ").concat(i, "\n\n      int b = index / ").concat(s, ";\n      index -= b * ").concat(s, ";\n\n      int r = 2 * (index / ").concat(a, ");\n      int c = imod(index, ").concat(a, ") * 2;\n\n      return ivec").concat(e.length, "(").concat(l, ");\n    }\n  ");
}

function getOutput4DCoords(e, t, n) {
  if (n) return "\n    ivec4 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n        vec2(outTexShape[0], outTexShape[1]));\n      int index = resTexRC.x * outTexShape[1] + resTexRC.y;\n      ".concat(getLogicalCoordinatesFromFlatIndexByUniform(["r", "c", "d", "d2"], e), "\n      return ivec4(r, c, d, d2);\n    }\n  ");
  var r = getLogicalCoordinatesFromFlatIndex(["r", "c", "d", "d2"], e);
  return "\n    ivec4 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n        vec2(".concat(t[0], ", ").concat(t[1], "));\n      int index = resTexRC.x * ").concat(t[1], " + resTexRC.y;\n      ").concat(r, "\n      return ivec4(r, c, d, d2);\n    }\n  ");
}

function getOutput5DCoords(e, t) {
  var n = getLogicalCoordinatesFromFlatIndex(["r", "c", "d", "d2", "d3"], e);
  return "\n    ivec5 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx * vec2(".concat(t[0], ",\n                             ").concat(t[1], "));\n\n      int index = resTexRC.x * ").concat(t[1], " + resTexRC.y;\n\n      ").concat(n, "\n\n      ivec5 outShape = ivec5(r, c, d, d2, d3);\n      return outShape;\n    }\n  ");
}

function getOutput6DCoords(e, t) {
  var n = getLogicalCoordinatesFromFlatIndex(["r", "c", "d", "d2", "d3", "d4"], e);
  return "\n    ivec6 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n        vec2(".concat(t[0], ", ").concat(t[1], "));\n      int index = resTexRC.x * ").concat(t[1], " + resTexRC.y;\n\n      ").concat(n, "\n\n      ivec6 result = ivec6(r, c, d, d2, d3, d4);\n      return result;\n    }\n  ");
}

function getOutputPacked2DCoords(e, t, n) {
  var r = [Math.ceil(t[0] / 2), Math.ceil(t[1] / 2)];
  if (arraysEqual(e, t)) return n ? "\n      ivec2 getOutputCoords() {\n        ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\n        return 2 * ivec2(resultUV.yx * vec2(packedTexShape[0], packedTexShape[1]));\n      }\n    " : "\n      ivec2 getOutputCoords() {\n        return 2 * ivec2(resultUV.yx * vec2(".concat(r[0], ", ").concat(r[1], "));\n      }\n    ");
  var a = Math.ceil(e[1] / 2);
  return n ? "\n    ivec2 getOutputCoords() {\n      ivec2 packedTexShape = ivec2(ceil(float(outTexShape[0]) / 2.0), ceil(float(outTexShape[1]) / 2.0));\n      int texelsInLogicalRow = int(ceil(float(outShape[1]) / 2.0));\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(packedTexShape[0], packedTexShape[1]));\n\n      int index = resTexRC.x * packedTexShape[1] + resTexRC.y;\n      int r = 2 * (index / texelsInLogicalRow);\n      int c = imod(index, texelsInLogicalRow) * 2;\n\n      return ivec2(r, c);\n    }\n  " : "\n    ivec2 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(".concat(r[0], ", ").concat(r[1], "));\n\n      int index = resTexRC.x * ").concat(r[1], " + resTexRC.y;\n      int r = 2 * (index / ").concat(a, ");\n      int c = imod(index, ").concat(a, ") * 2;\n\n      return ivec2(r, c);\n    }\n  ");
}

function getOutput2DCoords(e, t, n) {
  return arraysEqual(e, t) ? n ? "\n      ivec2 getOutputCoords() {\n        return ivec2(resultUV.yx * vec2(outTexShape[0], outTexShape[1]));\n      }\n    " : "\n      ivec2 getOutputCoords() {\n        return ivec2(resultUV.yx * vec2(".concat(t[0], ", ").concat(t[1], "));\n      }\n    ") : 1 === e[1] ? n ? "\n      ivec2 getOutputCoords() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n                               vec2(outTexShape[0], outTexShape[1]));\n        int index = resTexRC.x * outTexShape[1] + resTexRC.y;\n        return ivec2(index, 0);\n      }\n    " : "\n      ivec2 getOutputCoords() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n                               vec2(".concat(t[0], ", ").concat(t[1], "));\n        int index = resTexRC.x * ").concat(t[1], " + resTexRC.y;\n        return ivec2(index, 0);\n      }\n    ") : 1 === e[0] ? n ? "\n      ivec2 getOutputCoords() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n                               vec2(outTexShape[0], outTexShape[1]));\n        int index = resTexRC.x * outTexShape[1] + resTexRC.y;\n        return ivec2(0, index);\n      }\n    " : "\n      ivec2 getOutputCoords() {\n        ivec2 resTexRC = ivec2(resultUV.yx *\n                               vec2(".concat(t[0], ", ").concat(t[1], "));\n        int index = resTexRC.x * ").concat(t[1], " + resTexRC.y;\n        return ivec2(0, index);\n      }\n    ") : n ? "\n    ivec2 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(outTexShape[0], outTexShape[1]));\n      int index = resTexRC.x * outTexShape[1] + resTexRC.y;\n      int r = index / outShape[1];\n      int c = index - r * outShape[1];\n      return ivec2(r, c);\n    }\n  " : "\n    ivec2 getOutputCoords() {\n      ivec2 resTexRC = ivec2(resultUV.yx *\n                             vec2(".concat(t[0], ", ").concat(t[1], "));\n      int index = resTexRC.x * ").concat(t[1], " + resTexRC.y;\n      int r = index / ").concat(e[1], ";\n      int c = index - r * ").concat(e[1], ";\n      return ivec2(r, c);\n    }\n  ");
}

function getFlatOffsetUniformName(e) {
  return "offset".concat(e);
}

function getPackedSamplerScalar(e) {
  var t = e.name;
  return "\n    vec4 ".concat("get" + t.charAt(0).toUpperCase() + t.slice(1), "() {\n      return ").concat(getGlslDifferences().texture2D, "(").concat(t, ", halfCR);\n    }\n  ");
}

function getSamplerScalar(e, t) {
  var n = e.name,
      r = "get" + n.charAt(0).toUpperCase() + n.slice(1);
  if (e.shapeInfo.isUniform) return "float ".concat(r, "() {return ").concat(n, ";}");
  var [a, s] = e.shapeInfo.texShape;
  if (1 === a && 1 === s) return "\n      float ".concat(r, "() {\n        return sampleTexture(").concat(n, ", halfCR);\n      }\n    ");
  var o = getFlatOffsetUniformName(n);
  if (t) return "\n    float ".concat(r, "() {\n      vec2 uv = uvFromFlat(").concat(n, "TexShape[0], ").concat(n, "TexShape[1], ").concat(o, ");\n      return sampleTexture(").concat(n, ", uv);\n    }\n  ");
  var [i, l] = e.shapeInfo.texShape;
  return "\n    float ".concat(r, "() {\n      vec2 uv = uvFromFlat(").concat(i, ", ").concat(l, ", ").concat(o, ");\n      return sampleTexture(").concat(n, ", uv);\n    }\n  ");
}

function getPackedSampler1D(e, t) {
  var n = e.name,
      r = "get" + n.charAt(0).toUpperCase() + n.slice(1),
      a = e.shapeInfo.texShape,
      s = getGlslDifferences();
  if (t) return "\n    vec4 ".concat(r, "(int index) {\n      ivec2 packedTexShape = ivec2(ceil(float(").concat(n, "TexShape[0]) / 2.0), ceil(float(").concat(n, "TexShape[1]) / 2.0));\n      vec2 uv = packedUVfrom1D(\n        packedTexShape[0], packedTexShape[1], index);\n      return ").concat(s.texture2D, "(").concat(n, ", uv);\n    }\n  ");
  var o = [Math.ceil(a[0] / 2), Math.ceil(a[1] / 2)];
  return "\n    vec4 ".concat(r, "(int index) {\n      vec2 uv = packedUVfrom1D(\n        ").concat(o[0], ", ").concat(o[1], ", index);\n      return ").concat(s.texture2D, "(").concat(n, ", uv);\n    }\n  ");
}

function getSampler1D(e, t) {
  var n = e.name,
      r = "get" + n.charAt(0).toUpperCase() + n.slice(1);
  if (e.shapeInfo.isUniform) return "\n      float ".concat(r, "(int index) {\n        ").concat(getUniformSampler(e), "\n      }\n    ");
  var a = e.shapeInfo.texShape,
      s = a[0],
      o = a[1];
  if (1 === o && 1 === s) return "\n      float ".concat(r, "(int index) {\n        return sampleTexture(").concat(n, ", halfCR);\n      }\n    ");
  var i = getFlatOffsetUniformName(n);
  return 1 === o ? t ? "\n      float ".concat(r, "(int index) {\n        vec2 uv = vec2(0.5, (float(index + ").concat(i, ") + 0.5) / float(").concat(n, "TexShape[0]));\n        return sampleTexture(").concat(n, ", uv);\n      }\n    ") : "\n      float ".concat(r, "(int index) {\n        vec2 uv = vec2(0.5, (float(index + ").concat(i, ") + 0.5) / ").concat(s, ".0);\n        return sampleTexture(").concat(n, ", uv);\n      }\n    ") : 1 === s ? t ? "\n      float ".concat(r, "(int index) {\n        vec2 uv = vec2((float(index + ").concat(i, ") + 0.5) / float(").concat(n, "TexShape[1]), 0.5);\n        return sampleTexture(").concat(n, ", uv);\n      }\n    ") : "\n      float ".concat(r, "(int index) {\n        vec2 uv = vec2((float(index + ").concat(i, ") + 0.5) / ").concat(o, ".0, 0.5);\n        return sampleTexture(").concat(n, ", uv);\n      }\n    ") : t ? "\n    float ".concat(r, "(int index) {\n      vec2 uv = uvFromFlat(").concat(n, "TexShape[0], ").concat(n, "TexShape[1], index + ").concat(i, ");\n      return sampleTexture(").concat(n, ", uv);\n    }\n  ") : "\n    float ".concat(r, "(int index) {\n      vec2 uv = uvFromFlat(").concat(s, ", ").concat(o, ", index + ").concat(i, ");\n      return sampleTexture(").concat(n, ", uv);\n    }\n  ");
}

function getPackedSampler2D(e, t) {
  var n = e.shapeInfo.logicalShape,
      r = e.name,
      a = "get" + r.charAt(0).toUpperCase() + r.slice(1),
      s = e.shapeInfo.texShape,
      o = s[0],
      i = s[1],
      l = getGlslDifferences();
  if (null != s && arraysEqual(n, s)) return t ? "\n      vec4 ".concat(a, "(int row, int col) {\n        vec2 uv = (vec2(col, row) + halfCR) / vec2(").concat(r, "TexShape[1], ").concat(r, "TexShape[0]);\n\n        return ").concat(l.texture2D, "(").concat(r, ", uv);\n      }\n    ") : "\n      vec4 ".concat(a, "(int row, int col) {\n        vec2 uv = (vec2(col, row) + halfCR) / vec2(").concat(i, ".0, ").concat(o, ".0);\n\n        return ").concat(l.texture2D, "(").concat(r, ", uv);\n      }\n    ");
  if (t) return "\n    vec4 ".concat(a, "(int row, int col) {\n      ivec2 packedTexShape = ivec2(ceil(float(").concat(r, "TexShape[0]) / 2.0), ceil(float(").concat(r, "TexShape[1]) / 2.0));\n      int valuesPerRow = int(ceil(float(").concat(r, "Shape[1]) / 2.0));\n      vec2 uv = packedUVfrom2D(valuesPerRow, packedTexShape[0], packedTexShape[1], row, col);\n      return ").concat(l.texture2D, "(").concat(r, ", uv);\n    }\n  ");
  var u = [Math.ceil(s[0] / 2), Math.ceil(s[1] / 2)];
  return "\n    vec4 ".concat(a, "(int row, int col) {\n      vec2 uv = packedUVfrom2D(").concat(Math.ceil(n[1] / 2), ", ").concat(u[0], ", ").concat(u[1], ", row, col);\n      return ").concat(l.texture2D, "(").concat(r, ", uv);\n    }\n  ");
}

function getSampler2D(e, t) {
  var n = e.shapeInfo.logicalShape,
      r = e.name,
      a = "get" + r.charAt(0).toUpperCase() + r.slice(1),
      s = e.shapeInfo.texShape;
  if (null != s && arraysEqual(n, s)) return t ? "\n      float ".concat(a, "(int row, int col) {\n        vec2 uv = (vec2(col, row) + halfCR) / vec2(").concat(r, "TexShape[1], ").concat(r, "TexShape[0]);\n        return sampleTexture(").concat(r, ", uv);\n      }\n    ") : "\n    float ".concat(a, "(int row, int col) {\n      vec2 uv = (vec2(col, row) + halfCR) / vec2(").concat(s[1], ".0, ").concat(s[0], ".0);\n      return sampleTexture(").concat(r, ", uv);\n    }\n  ");
  var {
    newShape: o,
    keptDims: i
  } = squeezeShape(n);

  if (o.length < n.length) {
    var _n419 = ["row", "col"];
    return "\n      ".concat(getSamplerFromInInfo(squeezeInputInfo(e, o), t), "\n      float ").concat(a, "(int row, int col) {\n        return ").concat(a, "(").concat(getSqueezedParams(_n419, i), ");\n      }\n    ");
  }

  if (e.shapeInfo.isUniform) return "\n      float ".concat(a, "(int row, int col) {\n        int index = round(dot(vec2(row, col), vec2(").concat(n[1], ", 1)));\n        ").concat(getUniformSampler(e), "\n      }\n    ");
  var l = s[0],
      u = s[1],
      c = getFlatOffsetUniformName(r);
  return 1 === u ? t ? "\n      float ".concat(a, "(int row, int col) {\n        float index = dot(vec3(row, col, ").concat(c, "), vec3(").concat(r, "Shape[1], 1, 1));\n        vec2 uv = vec2(0.5, (index + 0.5) / float(").concat(r, "TexShape[0]));\n        return sampleTexture(").concat(r, ", uv);\n      }\n    ") : "\n    float ".concat(a, "(int row, int col) {\n      float index = dot(vec3(row, col, ").concat(c, "), vec3(").concat(n[1], ", 1, 1));\n      vec2 uv = vec2(0.5, (index + 0.5) / ").concat(l, ".0);\n      return sampleTexture(").concat(r, ", uv);\n    }\n  ") : 1 === l ? t ? "\n      float ".concat(a, "(int row, int col) {\n        float index = dot(vec3(row, col, ").concat(c, "), vec3(").concat(r, "Shape[1], 1, 1));\n        vec2 uv = vec2((index + 0.5) / float(").concat(r, "TexShape[1]), 0.5);\n        return sampleTexture(").concat(r, ", uv);\n      }\n    ") : "\n    float ".concat(a, "(int row, int col) {\n      float index = dot(vec3(row, col, ").concat(c, "), vec3(").concat(n[1], ", 1, 1));\n      vec2 uv = vec2((index + 0.5) / ").concat(u, ".0, 0.5);\n      return sampleTexture(").concat(r, ", uv);\n    }\n  ") : t ? "\n      float ".concat(a, "(int row, int col) {\n        // Explicitly use integer operations as dot() only works on floats.\n        int index = row * ").concat(r, "Shape[1] + col + ").concat(c, ";\n        vec2 uv = uvFromFlat(").concat(r, "TexShape[0], ").concat(r, "TexShape[1], index);\n        return sampleTexture(").concat(r, ", uv);\n      }\n    ") : "\n  float ".concat(a, "(int row, int col) {\n    // Explicitly use integer operations as dot() only works on floats.\n    int index = row * ").concat(n[1], " + col + ").concat(c, ";\n    vec2 uv = uvFromFlat(").concat(l, ", ").concat(u, ", index);\n    return sampleTexture(").concat(r, ", uv);\n  }\n");
}

function getPackedSampler3D(e, t) {
  var n = e.shapeInfo.logicalShape,
      r = e.name,
      a = "get" + r.charAt(0).toUpperCase() + r.slice(1),
      s = e.shapeInfo.texShape,
      o = [Math.ceil(s[0] / 2), Math.ceil(s[1] / 2)];

  if (1 === n[0]) {
    var _r406 = [1, 2],
        _s209 = ["b", "row", "col"];
    return "\n        ".concat(getPackedSamplerFromInInfo(squeezeInputInfo(e, n.slice(1)), t), "\n        vec4 ").concat(a, "(int b, int row, int col) {\n          return ").concat(a, "(").concat(getSqueezedParams(_s209, _r406), ");\n        }\n      ");
  }

  var i = getGlslDifferences();
  if (t) return "\n    vec4 ".concat(a, "(int b, int row, int col) {\n      ivec2 packedTexShape = ivec2(ceil(float(").concat(r, "TexShape[0]) / 2.0), ceil(float(").concat(r, "TexShape[1]) / 2.0));\n      int valuesPerRow = int(ceil(float(").concat(r, "Shape[2]) / 2.0));\n      int texelsInBatch = valuesPerRow * int(ceil(float(").concat(r, "Shape[1]) / 2.0));\n      vec2 uv = packedUVfrom3D(\n        packedTexShape[0], packedTexShape[1], texelsInBatch, valuesPerRow, b, row, col);\n      return ").concat(i.texture2D, "(").concat(r, ", uv);\n    }\n  ");
  var l = o[0],
      u = o[1],
      c = Math.ceil(n[2] / 2);
  return "\n    vec4 ".concat(a, "(int b, int row, int col) {\n      vec2 uv = packedUVfrom3D(\n        ").concat(l, ", ").concat(u, ", ").concat(c * Math.ceil(n[1] / 2), ", ").concat(c, ", b, row, col);\n      return ").concat(i.texture2D, "(").concat(r, ", uv);\n    }\n  ");
}

function getSampler3D(e, t) {
  var n = e.shapeInfo.logicalShape,
      r = e.name,
      a = "get" + r.charAt(0).toUpperCase() + r.slice(1),
      s = n[1] * n[2],
      o = n[2],
      {
    newShape: i,
    keptDims: l
  } = squeezeShape(n);

  if (i.length < n.length) {
    var _n420 = ["row", "col", "depth"];
    return "\n        ".concat(getSamplerFromInInfo(squeezeInputInfo(e, i), t), "\n        float ").concat(a, "(int row, int col, int depth) {\n          return ").concat(a, "(").concat(getSqueezedParams(_n420, l), ");\n        }\n      ");
  }

  if (e.shapeInfo.isUniform) return "\n      float ".concat(a, "(int row, int col, int depth) {\n        int index = round(dot(vec3(row, col, depth),\n                          vec3(").concat(s, ", ").concat(o, ", 1)));\n        ").concat(getUniformSampler(e), "\n      }\n    ");
  var u = e.shapeInfo.texShape,
      c = u[0],
      p = u[1],
      d = e.shapeInfo.flatOffset;
  if (p === s && null == d) return t ? "\n      float ".concat(a, "(int row, int col, int depth) {\n        int stride1 = ").concat(r, "Shape[2];\n        float texR = float(row);\n        float texC = dot(vec2(col, depth), vec2(stride1, 1));\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(").concat(r, "TexShape[1], ").concat(r, "TexShape[0]);\n        return sampleTexture(").concat(r, ", uv);\n      }\n    ") : "\n        float ".concat(a, "(int row, int col, int depth) {\n          float texR = float(row);\n          float texC = dot(vec2(col, depth), vec2(").concat(o, ", 1));\n          vec2 uv = (vec2(texC, texR) + halfCR) /\n                     vec2(").concat(p, ".0, ").concat(c, ".0);\n          return sampleTexture(").concat(r, ", uv);\n        }\n      ");
  if (p === o && null == d) return t ? "\n      float ".concat(a, "(int row, int col, int depth) {\n        float texR = dot(vec2(row, col), vec2(").concat(r, "Shape[1], 1));\n        float texC = float(depth);\n        vec2 uv = (vec2(texC, texR) + halfCR) / vec2(").concat(r, "TexShape[1], ").concat(r, "TexShape[0]);\n        return sampleTexture(").concat(r, ", uv);\n      }\n    ") : "\n    float ".concat(a, "(int row, int col, int depth) {\n      float texR = dot(vec2(row, col), vec2(").concat(n[1], ", 1));\n      float texC = float(depth);\n      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(").concat(p, ".0, ").concat(c, ".0);\n      return sampleTexture(").concat(r, ", uv);\n    }\n  ");
  var h = getFlatOffsetUniformName(r);
  return t ? "\n    float ".concat(a, "(int row, int col, int depth) {\n      // Explicitly use integer operations as dot() only works on floats.\n      int stride0 = ").concat(r, "Shape[1] * ").concat(r, "Shape[2];\n      int stride1 = ").concat(r, "Shape[2];\n      int index = row * ").concat(s, " + col * ").concat(o, " + depth + ").concat(h, ";\n      vec2 uv = uvFromFlat(").concat(r, "TexShape[0], ").concat(r, "TexShape[1], index);\n      return sampleTexture(").concat(r, ", uv);\n    }\n    ") : "\n      float ".concat(a, "(int row, int col, int depth) {\n        // Explicitly use integer operations as dot() only works on floats.\n        int index = row * ").concat(s, " + col * ").concat(o, " + depth + ").concat(h, ";\n        vec2 uv = uvFromFlat(").concat(c, ", ").concat(p, ", index);\n        return sampleTexture(").concat(r, ", uv);\n      }\n  ");
}

function getPackedSamplerND(e, t) {
  var n = e.name,
      r = "get" + n.charAt(0).toUpperCase() + n.slice(1),
      a = getGlslDifferences();
  if (t) return "\n    vec4 ".concat(r, "(int b2, int b, int row, int col) {\n      int valuesPerRow = int(ceil(float(").concat(n, "Shape[3]) / 2.0));\n      int texelsInBatch = valuesPerRow * int(ceil(float(").concat(n, "Shape[2]) / 2.0));\n      int index = b * texelsInBatch + (row / 2) * valuesPerRow + (col / 2);\n      texelsInBatch *= ").concat(n, "Shape[1];\n      index = b2 * texelsInBatch + index;\n      ivec2 packedTexShape = ivec2(ceil(float(").concat(n, "TexShape[0]) / 2.0), ceil(float(").concat(n, "TexShape[1]) / 2.0));\n      int texR = index / packedTexShape[1];\n      int texC = index - texR * packedTexShape[1];\n      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(packedTexShape[1], packedTexShape[0]); return ").concat(a.texture2D, "(").concat(n, ", uv);\n    }\n  ");
  var s = e.shapeInfo.logicalShape,
      o = s.length,
      i = e.shapeInfo.texShape,
      l = [Math.ceil(i[0] / 2), Math.ceil(i[1] / 2)],
      u = l[0],
      c = l[1],
      p = Math.ceil(s[o - 1] / 2);
  var d = p * Math.ceil(s[o - 2] / 2),
      h = "int b, int row, int col",
      m = "b * ".concat(d, " + (row / 2) * ").concat(p, " + (col / 2)");

  for (var _e992 = 2; _e992 < o - 1; _e992++) {
    h = "int b".concat(_e992, ", ") + h, d *= s[o - _e992 - 1], m = "b".concat(_e992, " * ").concat(d, " + ") + m;
  }

  return "\n    vec4 ".concat(r, "(").concat(h, ") {\n      int index = ").concat(m, ";\n      int texR = index / ").concat(c, ";\n      int texC = index - texR * ").concat(c, ";\n      vec2 uv = (vec2(texC, texR) + halfCR) / vec2(").concat(c, ", ").concat(u, ");\n      return ").concat(a.texture2D, "(").concat(n, ", uv);\n    }\n  ");
}

function getSampler4D(e, t) {
  var n = e.shapeInfo.logicalShape,
      r = e.name,
      a = "get" + r.charAt(0).toUpperCase() + r.slice(1),
      s = n[3],
      o = n[2] * s,
      i = n[1] * o,
      {
    newShape: l,
    keptDims: u
  } = squeezeShape(n);

  if (l.length < n.length) {
    var _n421 = ["row", "col", "depth", "depth2"];
    return "\n      ".concat(getSamplerFromInInfo(squeezeInputInfo(e, l), t), "\n      float ").concat(a, "(int row, int col, int depth, int depth2) {\n        return ").concat(a, "(").concat(getSqueezedParams(_n421, u), ");\n      }\n    ");
  }

  if (e.shapeInfo.isUniform) return "\n      float ".concat(a, "(int row, int col, int depth, int depth2) {\n        int index = round(dot(vec4(row, col, depth, depth2),\n                          vec4(").concat(i, ", ").concat(o, ", ").concat(s, ", 1)));\n        ").concat(getUniformSampler(e), "\n      }\n    ");
  var c = e.shapeInfo.flatOffset,
      p = e.shapeInfo.texShape,
      d = p[0],
      h = p[1],
      m = "int stride2 = ".concat(r, "Shape[3];"),
      f = "int stride1 = ".concat(r, "Shape[2] * stride2;"),
      g = "int stride0 = ".concat(r, "Shape[1] * stride1;");
  if (h === i && null == c) return t ? "\n      float ".concat(a, "(int row, int col, int depth, int depth2) {\n        ").concat(m, "\n        ").concat(f, "\n        float texR = float(row);\n        float texC =\n            dot(vec3(col, depth, depth2),\n                vec3(stride1, stride2, 1));\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(").concat(r, "TexShape[1], ").concat(r, "TexShape[0]);\n        return sampleTexture(").concat(r, ", uv);\n      }\n    ") : "\n      float ".concat(a, "(int row, int col, int depth, int depth2) {\n        float texR = float(row);\n        float texC =\n            dot(vec3(col, depth, depth2),\n                vec3(").concat(o, ", ").concat(s, ", 1));\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(").concat(h, ".0, ").concat(d, ".0);\n        return sampleTexture(").concat(r, ", uv);\n      }\n    ");
  if (h === s && null == c) return t ? "\n      float ".concat(a, "(int row, int col, int depth, int depth2) {\n        float texR = dot(vec3(row, col, depth),\n                         vec3(").concat(r, "Shape[1] * ").concat(r, "Shape[2], ").concat(r, "Shape[2], 1));\n        float texC = float(depth2);\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                  vec2(").concat(r, "TexShape[1], ").concat(r, "TexShape[0]);\n        return sampleTexture(").concat(r, ", uv);\n      }\n    ") : "\n      float ".concat(a, "(int row, int col, int depth, int depth2) {\n        float texR = dot(vec3(row, col, depth),\n                         vec3(").concat(n[1] * n[2], ", ").concat(n[2], ", 1));\n        float texC = float(depth2);\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                  vec2(").concat(h, ".0, ").concat(d, ".0);\n        return sampleTexture(").concat(r, ", uv);\n      }\n    ");
  var $ = getFlatOffsetUniformName(r);
  return t ? "\n    float ".concat(a, "(int row, int col, int depth, int depth2) {\n      // Explicitly use integer operations as dot() only works on floats.\n      ").concat(m, "\n      ").concat(f, "\n      ").concat(g, "\n      int index = row * stride0 + col * stride1 +\n          depth * stride2 + depth2;\n      vec2 uv = uvFromFlat(").concat(r, "TexShape[0], ").concat(r, "TexShape[1], index + ").concat($, ");\n      return sampleTexture(").concat(r, ", uv);\n    }\n  ") : "\n    float ".concat(a, "(int row, int col, int depth, int depth2) {\n      // Explicitly use integer operations as dot() only works on floats.\n      int index = row * ").concat(i, " + col * ").concat(o, " +\n          depth * ").concat(s, " + depth2;\n      vec2 uv = uvFromFlat(").concat(d, ", ").concat(h, ", index + ").concat($, ");\n      return sampleTexture(").concat(r, ", uv);\n    }\n  ");
}

function getSampler5D(e) {
  var t = e.shapeInfo.logicalShape,
      n = e.name,
      r = "get" + n.charAt(0).toUpperCase() + n.slice(1),
      a = t[4],
      s = t[3] * a,
      o = t[2] * s,
      i = t[1] * o,
      {
    newShape: l,
    keptDims: u
  } = squeezeShape(t);

  if (l.length < t.length) {
    var _t679 = ["row", "col", "depth", "depth2", "depth3"];
    return "\n      ".concat(getSamplerFromInInfo(squeezeInputInfo(e, l)), "\n      float ").concat(r, "(int row, int col, int depth, int depth2, int depth3) {\n        return ").concat(r, "(").concat(getSqueezedParams(_t679, u), ");\n      }\n    ");
  }

  if (e.shapeInfo.isUniform) return "\n      float ".concat(r, "(int row, int col, int depth, int depth2, int depth3) {\n        float index = dot(\n          vec4(row, col, depth, depth2),\n          vec4(").concat(i, ", ").concat(o, ", ").concat(s, ", ").concat(a, ")) +\n          depth3;\n        ").concat(getUniformSampler(e), "\n      }\n    ");
  var c = e.shapeInfo.flatOffset,
      p = e.shapeInfo.texShape,
      d = p[0],
      h = p[1];
  return h === i && null == c ? "\n      float ".concat(r, "(int row, int col, int depth, int depth2, int depth3) {\n        int texR = row;\n        float texC = dot(vec4(col, depth, depth2, depth3),\n                         vec4(").concat(o, ", ").concat(s, ", ").concat(a, ", 1));\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(").concat(h, ".0, ").concat(d, ".0);\n        return sampleTexture(").concat(n, ", uv);\n      }\n    ") : h === a && null == c ? "\n      float ".concat(r, "(int row, int col, int depth, int depth2, int depth3) {\n        float texR = dot(\n          vec4(row, col, depth, depth2),\n          vec4(").concat(t[1] * t[2] * t[3], ",\n               ").concat(t[2] * t[3], ", ").concat(t[3], ", 1));\n        int texC = depth3;\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                  vec2(").concat(h, ".0, ").concat(d, ".0);\n        return sampleTexture(").concat(n, ", uv);\n      }\n    ") : "\n    float ".concat(r, "(int row, int col, int depth, int depth2, int depth3) {\n      // Explicitly use integer operations as dot() only works on floats.\n      int index = row * ").concat(i, " + col * ").concat(o, " + depth * ").concat(s, " +\n          depth2 * ").concat(a, " + depth3 + ").concat(getFlatOffsetUniformName(n), ";\n      vec2 uv = uvFromFlat(").concat(d, ", ").concat(h, ", index);\n      return sampleTexture(").concat(n, ", uv);\n    }\n  ");
}

function getSampler6D(e) {
  var t = e.shapeInfo.logicalShape,
      n = e.name,
      r = "get" + n.charAt(0).toUpperCase() + n.slice(1),
      {
    newShape: a,
    keptDims: s
  } = squeezeShape(t);

  if (a.length < t.length) {
    var _t680 = ["row", "col", "depth", "depth2", "depth3", "depth4"];
    return "\n      ".concat(getSamplerFromInInfo(squeezeInputInfo(e, a)), "\n      float ").concat(r, "(int row, int col, int depth,\n                    int depth2, int depth3, int depth4) {\n        return ").concat(r, "(").concat(getSqueezedParams(_t680, s), ");\n      }\n    ");
  }

  var o = t[5],
      i = t[4] * o,
      l = t[3] * i,
      u = t[2] * l,
      c = t[1] * u;
  if (e.shapeInfo.isUniform) return "\n      float ".concat(r, "(int row, int col, int depth,\n                  int depth2, int depth3, int depth4) {\n        int index = round(dot(\n          vec4(row, col, depth, depth2),\n          vec4(").concat(c, ", ").concat(u, ", ").concat(l, ", ").concat(i, ")) +\n          dot(\n            vec2(depth3, depth4),\n            vec2(").concat(o, ", 1)));\n        ").concat(getUniformSampler(e), "\n      }\n    ");
  var p = e.shapeInfo.flatOffset,
      d = e.shapeInfo.texShape,
      h = d[0],
      m = d[1];
  return m === c && null == p ? "\n      float ".concat(r, "(int row, int col, int depth,\n                    int depth2, int depth3, int depth4) {\n        int texR = row;\n        float texC = dot(vec4(col, depth, depth2, depth3),\n          vec4(").concat(u, ", ").concat(l, ", ").concat(i, ", ").concat(o, ")) +\n               float(depth4);\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                   vec2(").concat(m, ".0, ").concat(h, ".0);\n        return sampleTexture(").concat(n, ", uv);\n      }\n    ") : m === o && null == p ? "\n      float ".concat(r, "(int row, int col, int depth,\n                    int depth2, int depth3, int depth4) {\n        float texR = dot(vec4(row, col, depth, depth2),\n          vec4(").concat(t[1] * t[2] * t[3] * t[4], ",\n               ").concat(t[2] * t[3] * t[4], ",\n               ").concat(t[3] * t[4], ",\n               ").concat(t[4], ")) + float(depth3);\n        int texC = depth4;\n        vec2 uv = (vec2(texC, texR) + halfCR) /\n                  vec2(").concat(m, ".0, ").concat(h, ".0);\n        return sampleTexture(").concat(n, ", uv);\n      }\n    ") : "\n    float ".concat(r, "(int row, int col, int depth,\n                  int depth2, int depth3, int depth4) {\n      // Explicitly use integer operations as dot() only works on floats.\n      int index = row * ").concat(c, " + col * ").concat(u, " + depth * ").concat(l, " +\n          depth2 * ").concat(i, " + depth3 * ").concat(o, " + depth4 + ").concat(getFlatOffsetUniformName(n), ";\n      vec2 uv = uvFromFlat(").concat(h, ", ").concat(m, ", index);\n      return sampleTexture(").concat(n, ", uv);\n    }\n  ");
}

function getUniformSampler(e) {
  var t = e.name,
      n = sizeFromShape(e.shapeInfo.logicalShape);
  return n < 2 ? "return ".concat(t, ";") : "\n    for (int i = 0; i < ".concat(n, "; i++) {\n      if (i == index) {\n        return ").concat(t, "[i];\n      }\n    }\n  ");
}

function getPackedSamplerAtOutputCoords(e, t) {
  var n = e.name,
      r = n.charAt(0).toUpperCase() + n.slice(1),
      a = "get" + r + "AtOutCoords",
      s = e.shapeInfo.logicalShape.length,
      o = t.logicalShape.length,
      i = getBroadcastDims(e.shapeInfo.logicalShape, t.logicalShape),
      l = getCoordsDataType(o),
      u = o - s;
  var c;
  var p = ["x", "y", "z", "w", "u", "v"];
  c = 0 === s ? "" : o < 2 && i.length >= 1 ? "coords = 0;" : i.map(e => "coords.".concat(p[e + u], " = 0;")).join("\n");
  var d = "";
  d = o < 2 && s > 0 ? "coords" : e.shapeInfo.logicalShape.map((e, t) => "coords.".concat(p[t + u])).join(", ");
  var h = "return outputValue;";
  var m = 1 === sizeFromShape(e.shapeInfo.logicalShape),
      f = 1 === sizeFromShape(t.logicalShape);

  if (1 !== s || m || f) {
    if (m && !f) h = 1 === o ? "\n        return vec4(outputValue.x, outputValue.x, 0., 0.);\n      " : "\n        return vec4(outputValue.x);\n      ";else if (i.length) {
      var _e993 = s - 2,
          _t681 = s - 1;

      i.indexOf(_e993) > -1 && i.indexOf(_t681) > -1 ? h = "return vec4(outputValue.x);" : i.indexOf(_e993) > -1 ? h = "return vec4(outputValue.x, outputValue.y, outputValue.x, outputValue.y);" : i.indexOf(_t681) > -1 && (h = "return vec4(outputValue.xx, outputValue.zz);");
    }
  } else h = "\n      return vec4(outputValue.xy, outputValue.xy);\n    ";

  return "\n    vec4 ".concat(a, "() {\n      ").concat(l, " coords = getOutputCoords();\n      ").concat(c, "\n      vec4 outputValue = get").concat(r, "(").concat(d, ");\n      ").concat(h, "\n    }\n  ");
}

function getSamplerAtOutputCoords(e, t) {
  var n = e.name,
      r = n.charAt(0).toUpperCase() + n.slice(1),
      a = "get" + r + "AtOutCoords",
      s = e.shapeInfo.logicalShape.length,
      o = t.logicalShape.length;
  if (!e.shapeInfo.isUniform && s === o && null == e.shapeInfo.flatOffset && arraysEqual(e.shapeInfo.texShape, t.texShape)) return "\n      float ".concat(a, "() {\n        return sampleTexture(").concat(n, ", resultUV);\n      }\n    ");
  var i = getCoordsDataType(o),
      l = getBroadcastDims(e.shapeInfo.logicalShape, t.logicalShape),
      u = o - s;
  var c;
  var p = ["x", "y", "z", "w", "u", "v"];
  c = 0 === s ? "" : o < 2 && l.length >= 1 ? "coords = 0;" : l.map(e => "coords.".concat(p[e + u], " = 0;")).join("\n");
  var d = "";
  return d = o < 2 && s > 0 ? "coords" : e.shapeInfo.logicalShape.map((e, t) => "coords.".concat(p[t + u])).join(", "), "\n    float ".concat(a, "() {\n      ").concat(i, " coords = getOutputCoords();\n      ").concat(c, "\n      return get").concat(r, "(").concat(d, ");\n    }\n  ");
}

function getCoordsDataType(e) {
  if (e <= 1) return "int";
  if (2 === e) return "ivec2";
  if (3 === e) return "ivec3";
  if (4 === e) return "ivec4";
  if (5 === e) return "ivec5";
  if (6 === e) return "ivec6";
  throw Error("GPU for rank ".concat(e, " is not yet supported"));
}

function getUniformInfoFromShape(e, t, n) {
  var {
    newShape: r
  } = squeezeShape(t),
      a = t.length,
      s = e && 3 === a && 1 === t[0],
      o = s ? t.slice(1) : r,
      i = !e && a > 1 && !arraysEqual(t, n) && r.length < a || s;
  return {
    useSqueezeShape: i,
    uniformShape: i ? o : t
  };
}

function squeezeInputInfo(e, t) {
  var n = JSON.parse(JSON.stringify(e));
  return n.shapeInfo.logicalShape = t, n;
}

function getSqueezedParams(e, t) {
  return t.map(t => e[t]).join(", ");
}

function compileProgram(e, t, n, r) {
  var a = n.map((e, n) => {
    var r = {
      logicalShape: e.shape,
      texShape: e.isUniform ? null : e.texData.texShape,
      isUniform: e.isUniform,
      isPacked: !e.isUniform && e.texData.isPacked,
      flatOffset: null
    };
    return null != e.texData && null != e.texData.slice && e.texData.slice.flatOffset > 0 && (r.flatOffset = e.texData.slice.flatOffset), {
      name: t.variableNames[n],
      shapeInfo: r
    };
  }),
      s = a.map(e => e.shapeInfo),
      o = {
    logicalShape: r.shape,
    texShape: r.texData.texShape,
    isUniform: !1,
    isPacked: r.texData.isPacked,
    flatOffset: null
  },
      i = makeShader(a, o, t),
      l = e.createProgram(i);
  var u = null;
  var c = e.getUniformLocation(l, "NAN", !1);
  1 === env().getNumber("WEBGL_VERSION") && (u = e.getUniformLocation(l, "INFINITY", !1));
  var p = !1,
      d = {},
      h = {},
      m = {};

  for (var _n422 = 0; _n422 < t.variableNames.length; _n422++) {
    var _r407 = t.variableNames[_n422];
    d[_r407] = e.getUniformLocation(l, _r407, p), d["offset".concat(_r407)] = e.getUniformLocation(l, "offset".concat(_r407), p), t.enableShapeUniforms && (h["".concat(_r407, "Shape")] = e.getUniformLocation(l, "".concat(_r407, "Shape"), p), m["".concat(_r407, "TexShape")] = e.getUniformLocation(l, "".concat(_r407, "TexShape"), p));
  }

  var f, g, $;
  t.enableShapeUniforms && (f = e.getUniformLocation(l, "outShape", p), $ = e.getUniformLocation(l, "outShapeStrides", p), g = e.getUniformLocation(l, "outTexShape", p));
  var y = [];
  return t.customUniforms && t.customUniforms.forEach((t, n) => {
    y[n] = e.getUniformLocation(l, t.name, p);
  }), {
    program: t,
    source: i,
    webGLProgram: l,
    uniformLocations: d,
    customUniformLocations: y,
    inShapeInfos: s,
    outShapeInfo: o,
    infLoc: u,
    nanLoc: c,
    inShapesLocations: h,
    inTexShapesLocations: m,
    outShapeLocation: f,
    outShapeStridesLocation: $,
    outTexShapeLocation: g
  };
}

function validateBinaryAndProgram(e, t) {
  if (e.length !== t.length) throw Error("Binary was compiled with ".concat(e.length, " inputs, but was executed with ").concat(t.length, " inputs"));
  e.forEach((e, n) => {
    var r = e.logicalShape,
        a = t[n],
        s = a.shape;
    if (!arraysEqual(r, s)) throw Error("Binary was compiled with different shapes than the current args. Shapes ".concat(r, " and ").concat(s, " must match"));
    if (e.isUniform && a.isUniform) return;
    var o = e.texShape,
        i = a.isUniform ? null : a.texData.texShape;
    if (!arraysEqual(o, i)) throw Error("Binary was compiled with different texture shapes than the current args. Shape ".concat(o, " and ").concat(i, " must match"));
  });
}

function runProgram(e, t, n, r, a) {
  t.program.enableShapeUniforms || (validateBinaryAndProgram(t.inShapeInfos, n), validateBinaryAndProgram([t.outShapeInfo], [r]));
  var s = r.texData.texture,
      o = r.texData.texShape;
  r.texData.isPacked ? e.setOutputPackedMatrixTexture(s, o[0], o[1]) : e.setOutputMatrixTexture(s, o[0], o[1]), e.setProgram(t.webGLProgram), 1 === env().getNumber("WEBGL_VERSION") && null !== t.infLoc && e.gl.uniform1f(t.infLoc, Infinity), null !== t.nanLoc && e.gl.uniform1f(t.nanLoc, NaN), n.forEach((n, r) => {
    var a = t.program.variableNames[r],
        s = t.uniformLocations[a],
        o = t.uniformLocations["offset".concat(a)],
        i = t.inShapesLocations["".concat(a, "Shape")],
        l = t.inTexShapesLocations["".concat(a, "TexShape")];

    if (i) {
      var {
        uniformShape: _r408
      } = getUniformInfoFromShape(t.program.packedInputs, n.shape, n.texData.texShape);

      switch (_r408.length) {
        case 1:
          e.gl.uniform1iv(i, new Int32Array(_r408));
          break;

        case 2:
          e.gl.uniform2iv(i, new Int32Array(_r408));
          break;

        case 3:
          e.gl.uniform3iv(i, new Int32Array(_r408));
          break;

        case 4:
          e.gl.uniform4iv(i, new Int32Array(_r408));
      }
    }

    if (l && e.gl.uniform2i(l, n.texData.texShape[0], n.texData.texShape[1]), null != s) if (n.isUniform) {
      if (sizeFromShape(n.shape) < 2) e.gl.uniform1f(s, n.uniformValues[0]);else {
        var _t682 = n.uniformValues;
        _t682 instanceof Float32Array || (_t682 = new Float32Array(_t682)), e.gl.uniform1fv(s, _t682);
      }
    } else null != n.texData.slice && null != o && e.gl.uniform1i(o, n.texData.slice.flatOffset), e.setInputMatrixTexture(n.texData.texture, s, r);
  });
  var i = t.outShapeLocation;
  if (i) switch (r.shape.length) {
    case 1:
      e.gl.uniform1iv(i, new Int32Array(r.shape));
      break;

    case 2:
      e.gl.uniform2iv(i, new Int32Array(r.shape));
      break;

    case 3:
      e.gl.uniform3iv(i, new Int32Array(r.shape));
      break;

    case 4:
      e.gl.uniform4iv(i, new Int32Array(r.shape));
  }

  if (t.outShapeStridesLocation) {
    var _n423 = computeStrides(r.shape);

    switch (r.shape.length) {
      case 2:
        e.gl.uniform1iv(t.outShapeStridesLocation, new Int32Array(_n423));
        break;

      case 3:
        e.gl.uniform2iv(t.outShapeStridesLocation, new Int32Array(_n423));
        break;

      case 4:
        e.gl.uniform3iv(t.outShapeStridesLocation, new Int32Array(_n423));
    }
  }

  t.outTexShapeLocation && e.gl.uniform2i(t.outTexShapeLocation, r.texData.texShape[0], r.texData.texShape[1]), t.program.customUniforms && a && t.program.customUniforms.forEach((n, r) => {
    var s = t.customUniformLocations[r],
        o = a[r];
    if ("float" === n.type) e.gl.uniform1fv(s, o);else if ("vec2" === n.type) e.gl.uniform2fv(s, o);else if ("vec3" === n.type) e.gl.uniform3fv(s, o);else if ("vec4" === n.type) e.gl.uniform4fv(s, o);else if ("int" === n.type) e.gl.uniform1iv(s, o);else if ("ivec2" === n.type) e.gl.uniform2iv(s, o);else if ("ivec3" === n.type) e.gl.uniform3iv(s, o);else {
      if ("ivec4" !== n.type) throw Error("uniform type ".concat(n.type, " is not supported yet."));
      e.gl.uniform4iv(s, o);
    }
  }), e.executeProgram();
}

function makeShaderKey(e, t, n) {
  var r = "";
  t.concat(n).forEach(t => {
    var a = null != t.texData && null != t.texData.slice && t.texData.slice.flatOffset > 0;

    if (e.enableShapeUniforms && !t.isUniform) {
      var s = t.texData.texShape,
          {
        useSqueezeShape: o,
        uniformShape: i
      } = getUniformInfoFromShape(e.packedInputs, t.shape, s);
      var l = "",
          u = "",
          c = "";

      if (1 === i.length && e.packedInputs) {
        var _e994 = [Math.ceil(s[0] / 2), Math.ceil(s[1] / 2)];
        l = "".concat(_e994[0] > 1, "_").concat(_e994[1] > 1);
      } else if (2 !== i.length || e.packedInputs) {
        if (i.length > 2 && !e.packedInputs) {
          var _e995 = computeStrides(i);

          c = "".concat(_e995[0] === s[1], "_").concat(_e995[_e995.length - 1] === s[1]);
        }
      } else u = "".concat(i[0] > 1, "_").concat(i[1] > 1);

      var _p35 = t.shape.length,
          d = 2 === _p35 && arraysEqual(t.shape, s),
          h = 1 === sizeFromShape(t.shape),
          m = getBroadcastDims$1(t.shape, n.shape),
          f = !e.packedInputs && _p35 === n.shape.length && arraysEqual(s, n.texData.texShape);
      r += "".concat(_p35, "_").concat(f, "_").concat(o, "_").concat(i.length, "_").concat(h, "_").concat(m, "_").concat(d, "_").concat(l, "_").concat(u, "_").concat(c, "_").concat(e.packedInputs || _p35 > 2 ? "" : "".concat(s[0] > 1, "_").concat(s[1] > 1), "_").concat(a);
    } else r += "".concat(t.shape, "_").concat(t.isUniform ? "uniform" : t.texData.texShape, "_").concat(a);
  });
  var a = e.constructor.name;
  return a += "_" + r + "_" + e.userCode + "".concat(env().getNumber("WEBGL_VERSION")), a;
}

function useShapeUniforms(e) {
  return env().getBool("WEBGL_USE_SHAPES_UNIFORMS") && e <= 4;
}

var {
  addImpl: addImplCPU,
  bincountImpl: bincountImplCPU,
  bincountReduceImpl: bincountReduceImplCPU,
  ceilImpl: ceilImplCPU,
  concatImpl: concatImplCPU,
  equalImpl: equalImplCPU,
  expImpl: expImplCPU,
  expm1Impl: expm1ImplCPU,
  floorImpl: floorImplCPU,
  gatherNdImpl: gatherNdImplCPU,
  gatherV2Impl: gatherV2ImplCPU,
  greaterImpl: greaterImplCPU,
  greaterEqualImpl: greaterEqualImplCPU,
  lessImpl: lessImplCPU,
  lessEqualImpl: lessEqualImplCPU,
  linSpaceImpl: linSpaceImplCPU,
  logImpl: logImplCPU,
  maxImpl: maxImplCPU,
  maximumImpl: maximumImplCPU,
  minimumImpl: minimumImplCPU,
  multiplyImpl: multiplyImplCPU,
  negImpl: negImplCPU,
  notEqualImpl: notEqualImplCPU,
  prodImpl: prodImplCPU,
  rangeImpl: rangeImplCPU,
  rsqrtImpl: rsqrtImplCPU,
  simpleAbsImpl: simpleAbsImplCPU,
  sliceImpl: sliceImplCPU,
  sparseFillEmptyRowsImpl: sparseFillEmptyRowsImplCPU,
  sparseReshapeImpl: sparseReshapeImplCPU,
  sparseSegmentReductionImpl: sparseSegmentReductionImplCPU,
  stridedSliceImpl: stridedSliceImplCPU,
  stringNGramsImpl: stringNGramsImplCPU,
  stringSplitImpl: stringSplitImplCPU,
  stringToHashBucketFastImpl: stringToHashBucketFastImplCPU,
  subImpl: subImplCPU,
  tileImpl: tileImplCPU,
  topKImpl: topKImplCPU,
  transposeImpl: transposeImplCPU,
  uniqueImpl: uniqueImplCPU
} = shared;

function getVecChannels(e, t) {
  return ["x", "y", "z", "w", "u", "v"].slice(0, t).map(t => "".concat(e, ".").concat(t));
}

function getChannels(e, t) {
  return 1 === t ? [e] : getVecChannels(e, t);
}

function getSourceCoords$2(e, t) {
  if (1 === e) return "rc";
  var n = "";

  for (var r = 0; r < e; r++) {
    n += t[r], r < e - 1 && (n += ",");
  }

  return n;
}

class PackProgram {
  constructor(e) {
    this.variableNames = ["A"], this.packedInputs = !1, this.packedOutput = !0, this.outputShape = e;
    var t = e.length;
    if (0 === t) this.userCode = "\n        void main() {\n          setOutput(vec4(getA(), 0., 0., 0.));\n        }\n      ";else {
      var n = getChannels("rc", t),
          r = getCoordsDataType(t),
          a = getOutOfBoundsCondition(t, e, n),
          s = getSetup(t, e[e.length - 1], e[e.length - 2], n),
          o = getOutput(e, n);
      this.userCode = "\n        void main() {\n          ".concat(r, " rc = getOutputCoords();\n\n          if(").concat(a, ") {\n            setOutput(vec4(0));\n          } else {\n            ").concat(s, "\n\n            setOutput(vec4(").concat(o, "));\n          }\n        }\n      ");
    }
  }

}

function getSourceCoordsArr(e, t) {
  var n = [];

  for (var r = 0; r <= 1; r++) {
    for (var a = 0; a <= 1; a++) {
      var s = "".concat(0 === r ? "r" : "rp1", ", ").concat(0 === a ? "c" : "cp1");

      for (var _n424 = 2; _n424 < e; _n424++) {
        s = "".concat(t[t.length - 1 - _n424], ",") + s;
      }

      n.push(s);
    }
  }

  return n;
}

function getOutOfBoundsCondition(e, t, n) {
  if (1 === e) return "rc > ".concat(t[0]);
  var r = "";

  for (var a = e - 2; a < e; a++) {
    r += "".concat(n[a], " >= ").concat(t[a]), a < e - 1 && (r += "||");
  }

  return r;
}

function getSetup(e, t, n, r) {
  if (1 === e) return "";
  var a = r.slice(-2);
  return "\n    int r = ".concat(a[0], ";\n    int c = ").concat(a[1], ";\n    int rp1 = r + 1;\n    int cp1 = c + 1;\n\n    bool cEdge = cp1 >= ").concat(t, ";\n    bool rEdge = rp1 >= ").concat(n, ";\n  ");
}

function getOutput(e, t) {
  var n = e.length,
      r = getSourceCoordsArr(n, t);
  return 1 === n ? "getA(rc),\n            rc + 1 >= ".concat(e[0], " ? 0. : getA(rc + 1),\n            0, 0") : "getA(".concat(r[0], "),\n          cEdge ? 0. : getA(").concat(r[1], "),\n          rEdge ? 0. : getA(").concat(r[2], "),\n          rEdge || cEdge ? 0. : getA(").concat(r[3], ")");
}

class ReshapePackedProgram {
  constructor(e, t) {
    this.variableNames = ["A"], this.packedInputs = !0, this.packedOutput = !0, this.outputShape = e;
    var n = "";

    for (var _e996 = 0; _e996 < 4; _e996++) {
      var _t683 = "thisRC = rc;";
      _e996 % 2 == 1 && (_t683 += "thisRC.z += 1;"), _e996 > 1 && (_t683 += "thisRC.y += 1;"), n += "\n        ".concat(_t683, "\n        ").concat(_e996 > 0 ? "if(thisRC.y < rows && thisRC.z < cols){" : "", "\n          int flatIndex = getFlatIndex(thisRC);\n\n          ivec3 inputRC = inputCoordsFromReshapedOutCoords(flatIndex);\n          vec2 inputRCInnerDims = vec2(float(inputRC.y),float(inputRC.z));\n\n          result[").concat(_e996, "] =\n            getChannel(getA(inputRC.x, inputRC.y, inputRC.z), inputRCInnerDims);\n        ").concat(_e996 > 0 ? "}" : "", "\n      ");
    }

    this.userCode = "\n      ".concat(getReshapedInputCoords(t), "\n      ").concat(getFlatIndexFrom3D(e), "\n\n      void main() {\n        ivec3 rc = getOutputCoords();\n\n        vec4 result = vec4(0.);\n\n        ivec3 thisRC;\n        int rows = ").concat(e[1], ";\n        int cols = ").concat(e[2], ";\n\n        ").concat(n, "\n\n        setOutput(result);\n      }\n    ");
  }

}

function getReshapedInputCoords(e) {
  return "\n    ivec3 inputCoordsFromReshapedOutCoords(int index) {\n      ".concat(getLogicalCoordinatesFromFlatIndex(["r", "c", "d"], e), "\n      return ivec3(r, c, d);\n    }\n  ");
}

class TextureManager {
  constructor(e) {
    this.gpgpu = e, this.numUsedTextures = 0, this.numFreeTextures = 0, this._numBytesAllocated = 0, this._numBytesFree = 0, this.freeTextures = {}, this.logEnabled = !1, this.usedTextures = {};
  }

  acquireTexture(e, t, n) {
    var r = getPhysicalFromLogicalTextureType(t, n),
        a = getKeyFromTextureShape(e, r, n);
    a in this.freeTextures || (this.freeTextures[a] = []), a in this.usedTextures || (this.usedTextures[a] = []);
    var s = computeBytes(e, r, this.gpgpu.gl, this.gpgpu.textureConfig, n);

    if (this.freeTextures[a].length > 0) {
      this.numFreeTextures--, this.numUsedTextures++, this._numBytesFree -= s, this.log();

      var _e997 = this.freeTextures[a].shift();

      return this.usedTextures[a].push(_e997), _e997;
    }

    var o;
    return r === PhysicalTextureType.PACKED_2X2_FLOAT32 ? o = this.gpgpu.createPackedMatrixTexture(e[0], e[1]) : r === PhysicalTextureType.PACKED_2X2_FLOAT16 ? o = this.gpgpu.createFloat16PackedMatrixTexture(e[0], e[1]) : r === PhysicalTextureType.UNPACKED_FLOAT32 ? o = this.gpgpu.createFloat32MatrixTexture(e[0], e[1]) : r === PhysicalTextureType.UNPACKED_FLOAT16 ? o = this.gpgpu.createFloat16MatrixTexture(e[0], e[1]) : r === PhysicalTextureType.PACKED_4X1_UNSIGNED_BYTE && (o = this.gpgpu.createUnsignedBytesMatrixTexture(e[0], e[1])), this.usedTextures[a].push(o), this.numUsedTextures++, this._numBytesAllocated += s, this.log(), o;
  }

  releaseTexture(e, t, n, r) {
    if (null == this.freeTextures) return;
    var a = getPhysicalFromLogicalTextureType(n, r),
        s = getKeyFromTextureShape(t, a, r);
    s in this.freeTextures || (this.freeTextures[s] = []);
    var o = computeBytes(t, a, this.gpgpu.gl, this.gpgpu.textureConfig, r),
        i = env().get("WEBGL_DELETE_TEXTURE_THRESHOLD");
    -1 !== i && this._numBytesAllocated > i ? (this.gpgpu.deleteMatrixTexture(e), this._numBytesAllocated -= o) : (this.freeTextures[s].push(e), this.numFreeTextures++, this._numBytesFree += o), this.numUsedTextures--;
    var l = this.usedTextures[s],
        u = l.indexOf(e);
    if (u < 0) throw new Error("Cannot release a texture that was never provided by this texture manager");
    l.splice(u, 1), this.log();
  }

  log() {
    if (!this.logEnabled) return;
    console.log("Free/Used", "".concat(this.numFreeTextures, " / ").concat(this.numUsedTextures), "(".concat(this.numFreeTextures + this.numUsedTextures, ")"));
    var e = this._numBytesFree / this._numBytesAllocated;
    console.log("Bytes allocated: ".concat(this._numBytesAllocated)), console.log("Bytes unused: ".concat(this._numBytesFree, " (").concat(Math.round(100 * e), "%)"));
  }

  get numBytesAllocated() {
    return this._numBytesAllocated;
  }

  get numBytesFree() {
    return this._numBytesFree;
  }

  getNumUsedTextures() {
    return this.numUsedTextures;
  }

  getNumFreeTextures() {
    return this.numFreeTextures;
  }

  dispose() {
    if (null != this.freeTextures) {
      for (var _e998 in this.freeTextures) {
        this.freeTextures[_e998].forEach(e => {
          this.gpgpu.deleteMatrixTexture(e);
        });
      }

      for (var _e999 in this.usedTextures) {
        this.usedTextures[_e999].forEach(e => {
          this.gpgpu.deleteMatrixTexture(e);
        });
      }

      this.freeTextures = null, this.usedTextures = null, this.numUsedTextures = 0, this.numFreeTextures = 0, this._numBytesAllocated = 0, this._numBytesFree = 0;
    }
  }

}

function numBytesForInternalFormat(e, t) {
  if (t === e.R32F) return 4;
  if (t === e.R16F) return 2;
  if (t === e.RGBA32F) return 16;
  if (t === e.RGBA) return 16;
  if (t === e.RGBA16F) return 8;
  throw new Error("Unknown internal format ".concat(t));
}

function computeBytes(e, t, n, r, a) {
  var s = internalFormatForPhysicalTexType(t, r);
  var o;

  if (a) {
    var [_t684, _n425] = getPackedMatrixTextureShapeWidthHeight(e[0], e[1]);
    o = _t684 * _n425;
  } else {
    var [_t685, _n426] = getUnpackedMatrixTextureShapeWidthHeight(e[0], e[1]);
    o = _t685 * _n426;
  }

  return o * numBytesForInternalFormat(n, s);
}

function internalFormatForPhysicalTexType(e, t) {
  switch (e) {
    case PhysicalTextureType.PACKED_2X2_FLOAT32:
      return getInternalFormatForPackedMatrixTexture(t);

    case PhysicalTextureType.PACKED_2X2_FLOAT16:
      return getInternalFormatForFloat16PackedMatrixTexture(t);

    case PhysicalTextureType.UNPACKED_FLOAT32:
      return getInternalFormatForFloat32MatrixTexture(t);

    case PhysicalTextureType.UNPACKED_FLOAT16:
      return getInternalFormatForFloat16MatrixTexture(t);

    case PhysicalTextureType.PACKED_4X1_UNSIGNED_BYTE:
      return getInternalFormatForUnsignedBytesMatrixTexture(t);

    default:
      throw new Error("Unknown physical texture type ".concat(e));
  }
}

function getPhysicalTextureForRendering(e) {
  return env().getBool("WEBGL_RENDER_FLOAT32_ENABLED") ? e ? PhysicalTextureType.PACKED_2X2_FLOAT32 : PhysicalTextureType.UNPACKED_FLOAT32 : e ? PhysicalTextureType.PACKED_2X2_FLOAT16 : PhysicalTextureType.UNPACKED_FLOAT16;
}

function getPhysicalFromLogicalTextureType(e, t) {
  if (e === TextureUsage.UPLOAD) return PhysicalTextureType.PACKED_2X2_FLOAT32;
  if (e === TextureUsage.RENDER || null == e) return getPhysicalTextureForRendering(t);
  if (e === TextureUsage.DOWNLOAD || e === TextureUsage.PIXELS) return PhysicalTextureType.PACKED_4X1_UNSIGNED_BYTE;
  throw new Error("Unknown logical texture type ".concat(e));
}

function getKeyFromTextureShape(e, t, n) {
  return "".concat(e[0], "_").concat(e[1], "_").concat(t, "_").concat(n);
}

class UnaryOpProgram {
  constructor(e, t) {
    this.variableNames = ["A"], this.outputShape = e, this.enableShapeUniforms = useShapeUniforms(this.outputShape.length), this.userCode = "\n      float unaryOperation(float x) {\n        ".concat(t, "\n      }\n\n      void main() {\n        float x = getAAtOutCoords();\n        float y = unaryOperation(x);\n\n        setOutput(y);\n      }\n    ");
  }

}

var CHECK_NAN_SNIPPET$2 = "if (isnan(x)) return x;",
    LINEAR$1 = "return x;",
    ABS$1 = "return abs(x);",
    ELU$2 = "return (x >= 0.0) ? x : (exp(x) - 1.0);",
    RELU$2 = CHECK_NAN_SNIPPET$2 + "\n  return (x < 0.0) ? 0.0 : x;\n",
    RELU6$2 = CHECK_NAN_SNIPPET$2 + "\n  return (x < 0.0) ? 0.0 : min(6.0, x);\n",
    CLONE = "return x;",
    SIGMOID$2 = "return 1.0 / (1.0 + exp(-1.0 * x));",
    LINEAR = "return x;",
    ELU$1 = "\n  vec4 result;\n\n  result.r = (x.r >= 0.0) ? x.r : (exp(x.r) - 1.0);\n  result.g = (x.g >= 0.0) ? x.g : (exp(x.g) - 1.0);\n  result.b = (x.b >= 0.0) ? x.b : (exp(x.b) - 1.0);\n  result.a = (x.a >= 0.0) ? x.a : (exp(x.a) - 1.0);\n\n  return result;\n",
    RELU$1 = "\n  vec4 result = x * vec4(greaterThanEqual(x, vec4(0.0)));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n",
    RELU6$1 = "\n  vec4 result = min(x, vec4(6.)) * vec4(greaterThanEqual(x, vec4(0.0)));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n",
    SIGMOID$1 = "return 1.0 / (1.0 + exp(-1.0 * x));";

class UnaryOpPackedProgram {
  constructor(e, t) {
    this.variableNames = ["A"], this.packedInputs = !0, this.packedOutput = !0, this.outputShape = e, this.enableShapeUniforms = useShapeUniforms(this.outputShape.length), this.userCode = "\n      vec4 unaryOperation(vec4 x) {\n        ".concat(t, "\n      }\n\n      void main() {\n        vec4 x = getAAtOutCoords();\n        vec4 y = unaryOperation(x);\n\n        setOutput(y);\n      }\n    ");
  }

}

class UnpackProgram {
  constructor(e) {
    this.variableNames = ["A"], this.packedInputs = !0, this.packedOutput = !1, this.outputShape = e;
    var t = e.length,
        n = getChannels("rc", t),
        r = getCoordsDataType(t),
        a = getSourceCoords$2(t, n),
        s = n.slice(-2),
        o = t <= 1 ? "rc" : "vec2(".concat(s.join(","), ")");
    this.userCode = "\n      void main() {\n        ".concat(r, " rc = getOutputCoords();\n        vec4 packedInput = getA(").concat(a, ");\n\n        setOutput(getChannel(packedInput, ").concat(o, "));\n      }\n    ");
  }

}

var whereImpl = whereImpl$2,
    EPSILON_FLOAT32 = 1e-7,
    EPSILON_FLOAT16 = 1e-4,
    binaryCaches = {};

function getBinaryCache(e) {
  return e in binaryCaches || (binaryCaches[e] = {}), binaryCaches[e];
}

var CPU_HANDOFF_SIZE_THRESHOLD = env().getNumber("CPU_HANDOFF_SIZE_THRESHOLD"),
    BEFORE_PAGING_CONSTANT = 600;

function numMBBeforeWarning() {
  return null == env().global.screen ? 1024 : env().global.screen.height * env().global.screen.width * window.devicePixelRatio * BEFORE_PAGING_CONSTANT / 1024 / 1024;
}

class MathBackendWebGL extends KernelBackend {
  constructor(e) {
    if (super(), this.pendingRead = new WeakMap(), this.pendingDisposal = new WeakSet(), this.dataRefCount = new WeakMap(), this.numBytesInGPU = 0, this.uploadWaitMs = 0, this.downloadWaitMs = 0, this.lastGlFlushTime = 0, this.warnedAboutMemory = !1, this.pendingDeletes = 0, this.disposed = !1, !env().getBool("HAS_WEBGL")) throw new Error("WebGL is not supported on this device");

    if (null == e) {
      var _e1000 = getWebGLContext(env().getNumber("WEBGL_VERSION"));

      this.binaryCache = getBinaryCache(env().getNumber("WEBGL_VERSION")), this.gpgpu = new GPGPUContext(_e1000), this.canvas = _e1000.canvas, this.gpgpuCreatedLocally = !0;
    } else this.gpgpu = e, this.binaryCache = {}, this.gpgpuCreatedLocally = !1, this.canvas = e.gl.canvas;

    this.textureManager = new TextureManager(this.gpgpu), this.numMBBeforeWarning = numMBBeforeWarning(), this.texData = new DataStorage(this, engine());
  }

  nextDataId() {
    return MathBackendWebGL.nextDataId++;
  }

  numDataIds() {
    return this.texData.numDataIds() - this.pendingDeletes;
  }

  write(e, t, n) {
    if ((env().getBool("WEBGL_CHECK_NUMERICAL_PROBLEMS") || env().getBool("DEBUG")) && this.checkNumericalProblems(e), "complex64" === n && null != e) throw new Error("Cannot write to a complex64 dtype. Please use tf.complex(real, imag).");
    var r = {
      id: this.nextDataId()
    };
    return this.texData.set(r, {
      shape: t,
      dtype: n,
      values: e,
      usage: TextureUsage.UPLOAD,
      refCount: 1
    }), r;
  }

  refCount(e) {
    return this.texData.has(e) ? this.texData.get(e).refCount : 0;
  }

  incRef(e) {
    this.texData.get(e).refCount++;
  }

  decRef(e) {
    this.texData.has(e) && this.texData.get(e).refCount--;
  }

  move(e, t, n, r, a) {
    if (env().getBool("DEBUG") && this.checkNumericalProblems(t), "complex64" === r) throw new Error("Cannot write to a complex64 dtype. Please use tf.complex(real, imag).");
    this.texData.set(e, {
      shape: n,
      dtype: r,
      values: t,
      usage: TextureUsage.UPLOAD,
      refCount: a
    });
  }

  disposeIntermediateTensorInfo(e) {
    this.disposeData(e.dataId);
  }

  readSync(e) {
    var t = this.texData.get(e),
        {
      values: n,
      dtype: r,
      complexTensorInfos: a,
      slice: s,
      shape: o,
      isPacked: i
    } = t;

    if (null != s) {
      var _t686;

      _t686 = i ? new UnaryOpPackedProgram(o, CLONE) : new UnaryOpProgram(o, CLONE);

      var _n427 = this.runWebGLProgram(_t686, [{
        dataId: e,
        shape: o,
        dtype: r
      }], r),
          _a297 = this.readSync(_n427.dataId);

      return this.disposeIntermediateTensorInfo(_n427), _a297;
    }

    if (null != n) return this.convertAndCacheOnCPU(e);
    if ("string" === r) return n;
    var l = null != this.activeTimers;
    var u, c;
    return l && (u = now()), c = "complex64" === r ? mergeRealAndImagArrays(this.readSync(a.real.dataId), this.readSync(a.imag.dataId)) : this.getValuesFromTexture(e), l && (this.downloadWaitMs += now() - u), this.convertAndCacheOnCPU(e, c);
  }

  read(e) {
    var _this216 = this;

    return _asyncToGenerator(function* () {
      if (_this216.pendingRead.has(e)) {
        var _t687 = _this216.pendingRead.get(e);

        return new Promise(e => _t687.push(e));
      }

      var t = _this216.texData.get(e),
          {
        values: n,
        shape: r,
        slice: a,
        dtype: s,
        complexTensorInfos: o,
        isPacked: i
      } = t;

      if (null != a) {
        var _t688;

        _t688 = i ? new UnaryOpPackedProgram(r, CLONE) : new UnaryOpProgram(r, CLONE);

        var _n428 = _this216.runWebGLProgram(_t688, [{
          dataId: e,
          shape: r,
          dtype: s
        }], s),
            _a298 = _this216.read(_n428.dataId);

        return _this216.disposeIntermediateTensorInfo(_n428), _a298;
      }

      if (null != n) return _this216.convertAndCacheOnCPU(e);
      if (!env().getBool("WEBGL_DOWNLOAD_FLOAT_ENABLED") && 2 === env().getNumber("WEBGL_VERSION")) throw new Error("tensor.data() with WEBGL_DOWNLOAD_FLOAT_ENABLED=false and WEBGL_VERSION=2 not yet supported.");
      var l,
          u,
          c = null;

      if ("complex64" !== s && env().get("WEBGL_BUFFER_SUPPORTED")) {
        l = _this216.decode(e);

        var _t689 = _this216.texData.get(l.dataId);

        c = _this216.gpgpu.createBufferFromTexture(_t689.texture, ...getDenseTexShape(r));
      }

      if (_this216.pendingRead.set(e, []), "complex64" !== s && (yield _this216.gpgpu.createAndWaitForFence()), "complex64" === s) {
        var _e1001 = yield Promise.all([_this216.read(o.real.dataId), _this216.read(o.imag.dataId)]);

        u = mergeRealAndImagArrays(_e1001[0], _e1001[1]);
      } else if (null == c) u = _this216.getValuesFromTexture(e);else {
        var _e1002 = sizeFromShape(r);

        u = _this216.gpgpu.downloadFloat32MatrixFromBuffer(c, _e1002);
      }

      if (null != l && _this216.disposeIntermediateTensorInfo(l), null != c) {
        var _e1003 = _this216.gpgpu.gl;
        callAndCheck(_e1003, () => _e1003.deleteBuffer(c));
      }

      var p = _this216.convertAndCacheOnCPU(e, u),
          d = _this216.pendingRead.get(e);

      return _this216.pendingRead.delete(e), d.forEach(e => e(p)), _this216.pendingDisposal.has(e) && (_this216.pendingDisposal.delete(e), _this216.disposeData(e) && engine().removeDataId(e, _this216), _this216.pendingDeletes--), p;
    })();
  }

  bufferSync(e) {
    var t = this.readSync(e.dataId);
    var n = t;
    if ("string" === e.dtype) try {
      n = t.map(e => decodeString(e));
    } catch (e) {
      throw new Error("Failed to decode encoded string bytes into utf-8");
    }
    return buffer(e.shape, e.dtype, n);
  }

  checkNumericalProblems(e) {
    if (null != e) for (var t = 0; t < e.length; t++) {
      var n = e[t];

      if (!canBeRepresented(n)) {
        if (env().getBool("WEBGL_RENDER_FLOAT32_CAPABLE")) throw Error("The value ".concat(n, " cannot be represented with your current settings. Consider enabling float32 rendering: 'tf.env().set('WEBGL_RENDER_FLOAT32_ENABLED', true);'"));
        throw Error("The value ".concat(n, " cannot be represented on this device."));
      }
    }
  }

  getValuesFromTexture(e) {
    var {
      shape: t,
      dtype: n,
      isPacked: r
    } = this.texData.get(e),
        a = sizeFromShape(t);

    if (env().getBool("WEBGL_DOWNLOAD_FLOAT_ENABLED")) {
      var _n429 = this.decode(e),
          _r409 = this.texData.get(_n429.dataId),
          _s210 = this.gpgpu.downloadMatrixFromPackedTexture(_r409.texture, ...getDenseTexShape(t)).subarray(0, a);

      return this.disposeIntermediateTensorInfo(_n429), _s210;
    }

    var s = env().getBool("WEBGL_PACK") && !0 === r,
        o = s ? getShapeAs3D(t) : t,
        i = s ? new EncodeFloatPackedProgram(o) : new EncodeFloatProgram(o),
        l = this.runWebGLProgram(i, [{
      shape: o,
      dtype: n,
      dataId: e
    }], "float32"),
        u = this.texData.get(l.dataId),
        c = this.gpgpu.downloadByteEncodedFloatMatrixFromOutputTexture(u.texture, u.texShape[0], u.texShape[1]).subarray(0, a);
    return this.disposeIntermediateTensorInfo(l), c;
  }

  timerAvailable() {
    return env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0;
  }

  time(e) {
    var _this217 = this;

    return _asyncToGenerator(function* () {
      var t = _this217.activeTimers,
          n = [];
      var r = !1;
      null == _this217.programTimersStack ? (_this217.programTimersStack = n, r = !0) : _this217.activeTimers.push(n), _this217.activeTimers = n, e();
      var a = flatten$3(_this217.activeTimers.map(e => e.query)).filter(e => null != e),
          s = flatten$3(_this217.activeTimers.map(e => e.name)).filter(e => null != e);
      _this217.activeTimers = t, r && (_this217.programTimersStack = null);
      var o = {
        uploadWaitMs: _this217.uploadWaitMs,
        downloadWaitMs: _this217.downloadWaitMs,
        kernelMs: null,
        wallMs: null
      };

      if (env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0) {
        var _e1004 = yield Promise.all(a);

        o.kernelMs = sum$3(_e1004), o.getExtraProfileInfo = () => _e1004.map((e, t) => ({
          name: s[t],
          ms: e
        })).map(e => "".concat(e.name, ": ").concat(e.ms)).join(", ");
      } else o.kernelMs = {
        error: "WebGL query timers are not supported in this environment."
      };

      return _this217.uploadWaitMs = 0, _this217.downloadWaitMs = 0, o;
    })();
  }

  memory() {
    return {
      unreliable: !1,
      numBytesInGPU: this.numBytesInGPU,
      numBytesInGPUAllocated: this.textureManager.numBytesAllocated,
      numBytesInGPUFree: this.textureManager.numBytesFree
    };
  }

  startTimer() {
    return env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0 ? this.gpgpu.beginQuery() : {
      startMs: now(),
      endMs: null
    };
  }

  endTimer(e) {
    return env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0 ? (this.gpgpu.endQuery(), e) : (e.endMs = now(), e);
  }

  getQueryTime(e) {
    var _this218 = this;

    return _asyncToGenerator(function* () {
      return env().getNumber("WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE") > 0 ? _this218.gpgpu.waitForQueryAndGetTime(e) : e.endMs - e.startMs;
    })();
  }

  disposeData(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;
    if (this.pendingDisposal.has(e)) return !1;
    if (!this.texData.has(e)) return !0;
    if (t ? this.texData.get(e).refCount = 0 : this.texData.get(e).refCount--, !t && this.texData.get(e).refCount > 0) return !1;
    if (this.pendingRead.has(e)) return this.pendingDisposal.add(e), this.pendingDeletes++, !1;
    this.releaseGPUData(e);
    var {
      complexTensorInfos: n
    } = this.texData.get(e);
    return null != n && (this.disposeData(n.real.dataId, t), this.disposeData(n.imag.dataId, t)), this.texData.delete(e), !0;
  }

  releaseGPUData(e) {
    var {
      texture: t,
      dtype: n,
      texShape: r,
      usage: a,
      isPacked: s,
      slice: o
    } = this.texData.get(e),
        i = o && o.origDataId || e,
        l = this.dataRefCount.get(i);
    l > 1 ? this.dataRefCount.set(i, l - 1) : (this.dataRefCount.delete(i), null != t && (this.numBytesInGPU -= this.computeBytes(r, n), this.textureManager.releaseTexture(t, r, a, s)));
    var u = this.texData.get(e);
    u.texture = null, u.texShape = null, u.isPacked = !1, u.slice = null;
  }

  getTexture(e) {
    return this.uploadToGPU(e), this.texData.get(e).texture;
  }

  getDataInfo(e) {
    return this.texData.get(e);
  }

  shouldExecuteOnCPU(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : CPU_HANDOFF_SIZE_THRESHOLD;
    return env().getBool("WEBGL_CPU_FORWARD") && e.every(e => null == this.texData.get(e.dataId).texture && sizeFromShape(e.shape) < t);
  }

  getGPGPUContext() {
    return this.gpgpu;
  }

  where(e) {
    warn("tf.where() in webgl locks the UI thread. Call tf.whereAsync() instead");
    var t = e.dataSync();
    return whereImpl(e.shape, t);
  }

  packedUnaryOp(e, t, n) {
    var r = new UnaryOpPackedProgram(e.shape, t),
        a = this.compileAndRun(r, [e], n);
    return engine().makeTensorFromDataId(a.dataId, a.shape, a.dtype);
  }

  abs(e) {
    if (this.shouldExecuteOnCPU([e]) && "complex64" !== e.dtype) {
      var _t690 = simpleAbsImplCPU(this.texData.get(e.dataId).values);

      return this.makeOutput(e.shape, e.dtype, _t690);
    }

    if (env().getBool("WEBGL_PACK_UNARY_OPERATIONS")) return this.packedUnaryOp(e, ABS$1, e.dtype);
    var t = new UnaryOpProgram(e.shape, ABS$1),
        n = this.compileAndRun(t, [e]);
    return engine().makeTensorFromDataId(n.dataId, n.shape, n.dtype);
  }

  makeTensorInfo(e, t, n) {
    var r;

    if ("string" === t && null != n && n.length > 0 && isString(n[0])) {
      var a = n.map(e => encodeString(e));
      r = this.write(a, e, t);
    } else r = this.write(n, e, t);

    return this.texData.get(r).usage = null, {
      dataId: r,
      shape: e,
      dtype: t
    };
  }

  makeOutput(e, t, n) {
    var {
      dataId: r
    } = this.makeTensorInfo(e, t, n);
    return engine().makeTensorFromDataId(r, e, t, this);
  }

  unpackTensor(e) {
    var t = new UnpackProgram(e.shape);
    return this.runWebGLProgram(t, [e], e.dtype);
  }

  packTensor(e) {
    var t = new PackProgram(e.shape);
    return this.runWebGLProgram(t, [e], e.dtype, null, !0);
  }

  packedReshape(e, t) {
    var n = [getBatchDim(e.shape), ...getRowsCols(e.shape)],
        r = {
      dtype: e.dtype,
      shape: n,
      dataId: e.dataId
    },
        a = [getBatchDim(t), ...getRowsCols(t)],
        s = new ReshapePackedProgram(a, n),
        o = this.runWebGLProgram(s, [r], e.dtype, null, !0);
    return {
      dataId: o.dataId,
      shape: t,
      dtype: o.dtype
    };
  }

  decode(e) {
    var t = this.texData.get(e),
        {
      isPacked: n,
      shape: r,
      dtype: a
    } = t,
        s = getShapeAs3D(r);
    var o;
    return o = n ? new DecodeMatrixPackedProgram(s) : new DecodeMatrixProgram(s), {
      dtype: a,
      shape: r,
      dataId: this.runWebGLProgram(o, [{
        shape: s,
        dtype: a,
        dataId: e
      }], a, null, !0).dataId
    };
  }

  runWebGLProgram(e, t, n, r) {
    var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;
    var s = this.makeTensorInfo(e.outputShape, n),
        o = this.texData.get(s.dataId);

    if (e.packedOutput && (o.isPacked = !0), e.outPackingScheme === PackingScheme.DENSE) {
      var _t691 = getDenseTexShape(e.outputShape);

      o.texShape = _t691.map(e => 2 * e);
    }

    if (null != e.outTexUsage && (o.usage = e.outTexUsage), 0 === sizeFromShape(s.shape)) return o.values = getTypedArrayFromDType(s.dtype, 0), s;
    var i = [],
        l = t.map(t => {
      if ("complex64" === t.dtype) throw new Error("GPGPUProgram does not support complex64 input. For complex64 dtypes, please separate the program into real and imaginary parts.");
      var n = this.texData.get(t.dataId);

      if (null == n.texture) {
        if (!e.packedInputs && sizeFromShape(t.shape) <= env().getNumber("WEBGL_SIZE_UPLOAD_UNIFORM")) return {
          shape: t.shape,
          texData: null,
          isUniform: !0,
          uniformValues: n.values
        };
        e.packedInputs && (n.isPacked = !0, n.shape = t.shape);
      } else if (!!n.isPacked != !!e.packedInputs) t = n.isPacked ? this.unpackTensor(t) : this.packTensor(t), i.push(t), n = this.texData.get(t.dataId);else if (n.isPacked && !isReshapeFree(n.shape, t.shape)) {
        var _e1005 = t,
            _r410 = t.shape;
        t.shape = n.shape, t = this.packedReshape(t, _r410), i.push(t), n = this.texData.get(t.dataId), _e1005.shape = _r410;
      }

      return this.uploadToGPU(t.dataId), {
        shape: t.shape,
        texData: n,
        isUniform: !1
      };
    });
    this.uploadToGPU(s.dataId);
    var u = {
      shape: s.shape,
      texData: o,
      isUniform: !1
    },
        c = makeShaderKey(e, l, u),
        p = this.getAndSaveBinary(c, () => compileProgram(this.gpgpu, e, l, u)),
        d = null != this.activeTimers;
    var h;
    d && (h = this.startTimer()), runProgram(this.gpgpu, p, l, u, r), i.forEach(e => this.disposeIntermediateTensorInfo(e)), d && (h = this.endTimer(h), this.activeTimers.push({
      name: e.constructor.name,
      query: this.getQueryTime(h)
    }));
    var m = env().get("WEBGL_FLUSH_THRESHOLD");

    if (m > 0) {
      var _e1006 = now();

      _e1006 - this.lastGlFlushTime > m && (this.gpgpu.gl.flush(), this.lastGlFlushTime = _e1006);
    }

    if (!env().getBool("WEBGL_LAZILY_UNPACK") && o.isPacked && !1 === a) {
      var _e1007 = this.unpackTensor(s);

      return this.disposeIntermediateTensorInfo(s), _e1007;
    }

    return s;
  }

  compileAndRun(e, t, n, r) {
    var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;
    return this.runWebGLProgram(e, t, n = n || t[0].dtype, r, a);
  }

  getAndSaveBinary(e, t) {
    return e in this.binaryCache || (this.binaryCache[e] = t()), this.binaryCache[e];
  }

  getTextureManager() {
    return this.textureManager;
  }

  dispose() {
    this.disposed || (env().getBool("IS_TEST") || Object.keys(this.binaryCache).forEach(e => {
      this.gpgpu.deleteProgram(this.binaryCache[e].webGLProgram), delete this.binaryCache[e];
    }), this.textureManager.dispose(), null != this.canvas && "undefined" != typeof HTMLCanvasElement && this.canvas instanceof HTMLCanvasElement ? this.canvas.remove() : this.canvas = null, this.gpgpuCreatedLocally && (this.gpgpu.program = null, this.gpgpu.dispose()), this.disposed = !0);
  }

  floatPrecision() {
    return null == this.floatPrecisionValue && (this.floatPrecisionValue = tidy(() => {
      if (!env().get("WEBGL_RENDER_FLOAT32_ENABLED")) {
        var _e1008 = env().getBool("DEBUG");

        env().set("DEBUG", !1);
        var t = this.abs(scalar(1e-8)).dataSync()[0];
        if (env().set("DEBUG", _e1008), t > 0) return 32;
      }

      return 16;
    })), this.floatPrecisionValue;
  }

  epsilon() {
    return 32 === this.floatPrecision() ? EPSILON_FLOAT32 : EPSILON_FLOAT16;
  }

  uploadToGPU(e) {
    var t = this.texData.get(e),
        {
      shape: n,
      dtype: r,
      values: a,
      texture: s,
      usage: o,
      isPacked: i
    } = t;
    if (null != s) return;
    var l = null != this.activeTimers;
    var u;
    l && (u = now());
    var c = t.texShape;

    if (null == c && (c = getTextureShapeFromLogicalShape(n, i), t.texShape = c), null != a) {
      var _e1009 = getShapeAs3D(n);

      var _s211,
          _o146 = c[1],
          _p36 = c[0];

      var d = a instanceof Uint8Array;
      i ? ([_o146, _p36] = getPackedMatrixTextureShapeWidthHeight(c[0], c[1]), _s211 = new EncodeMatrixPackedProgram(_e1009, [_p36, _o146], d)) : _s211 = new EncodeMatrixProgram(_e1009, [_p36, _o146], d);
      var h = this.makeTensorInfo([_p36, _o146], r);
      this.texData.get(h.dataId).usage = d ? TextureUsage.PIXELS : TextureUsage.UPLOAD, this.gpgpu.uploadDenseMatrixToTexture(this.getTexture(h.dataId), _o146, _p36, a);
      var m = this.runWebGLProgram(_s211, [h], r, null, !0),
          f = this.texData.get(m.dataId);
      t.texture = f.texture, t.texShape = f.texShape, t.isPacked = f.isPacked, t.usage = f.usage, this.disposeIntermediateTensorInfo(h), this.texData.delete(m.dataId), t.values = null, l && (this.uploadWaitMs += now() - u);
    } else {
      var _e1010 = this.acquireTexture(c, o, r, i);

      t.texture = _e1010;
    }
  }

  convertAndCacheOnCPU(e, t) {
    var n = this.texData.get(e),
        {
      dtype: r
    } = n;
    return this.releaseGPUData(e), null != t && (n.values = float32ToTypedArray(t, r)), n.values;
  }

  acquireTexture(e, t, n, r) {
    if (this.numBytesInGPU += this.computeBytes(e, n), !this.warnedAboutMemory && this.numBytesInGPU > 1024 * this.numMBBeforeWarning * 1024) {
      var _e1011 = (this.numBytesInGPU / 1024 / 1024).toFixed(2);

      this.warnedAboutMemory = !0, console.warn("High memory usage in GPU: ".concat(_e1011, " MB, most likely due to a memory leak"));
    }

    return this.textureManager.acquireTexture(e, t, r);
  }

  computeBytes(e, t) {
    return e[0] * e[1] * bytesPerElement(t);
  }

}

function float32ToTypedArray(e, t) {
  if ("float32" === t || "complex64" === t) return e;

  if ("int32" === t || "bool" === t) {
    var n = "int32" === t ? new Int32Array(e.length) : new Uint8Array(e.length);

    for (var _t692 = 0; _t692 < n.length; ++_t692) {
      n[_t692] = Math.round(e[_t692]);
    }

    return n;
  }

  throw new Error("Unknown dtype ".concat(t));
}

MathBackendWebGL.nextDataId = 0;
var version$2 = "3.8.0";
isBrowser() && registerBackend("webgl", () => new MathBackendWebGL(), 2);
var CHECK_NAN_SNIPPET$1 = "\n  if (isnan(a)) return a;\n  if (isnan(b)) return b;\n";

class BinaryOpProgram {
  constructor(e, t, n) {
    this.variableNames = ["A", "B"], this.outputShape = assertAndGetBroadcastShape(t, n), this.enableShapeUniforms = useShapeUniforms(this.outputShape.length), this.userCode = "\n      float binaryOperation(float a, float b) {\n        ".concat(e, "\n      }\n\n      void main() {\n        float a = getAAtOutCoords();\n        float b = getBAtOutCoords();\n        setOutput(binaryOperation(a, b));\n      }\n    ");
  }

}

var CHECK_NAN_SNIPPET = "\n  result.r = isNaN.r > 0. ? NAN : result.r;\n  result.g = isNaN.g > 0. ? NAN : result.g;\n  result.b = isNaN.b > 0. ? NAN : result.b;\n  result.a = isNaN.a > 0. ? NAN : result.a;\n";

class BinaryOpPackedProgram {
  constructor(e, t, n) {
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
    this.variableNames = ["A", "B"], this.supportsBroadcasting = !0, this.packedInputs = !0, this.packedOutput = !0, this.outputShape = assertAndGetBroadcastShape(t, n);
    var a = this.outputShape.length;
    this.enableShapeUniforms = useShapeUniforms(a);
    var s = "";
    if (r) if (0 === a || 1 === sizeFromShape(this.outputShape)) s = "\n          result.y = 0.;\n          result.z = 0.;\n          result.w = 0.;\n        ";else if (s = "\n          ".concat(getCoordsDataType(a), " coords = getOutputCoords();\n        "), 1 === a) s += this.enableShapeUniforms ? "\n            result.y = (coords + 1) >= outShape ? 0. : result.y;\n            result.z = 0.;\n            result.w = 0.;\n          " : "\n            result.y = (coords + 1) >= ".concat(this.outputShape[0], " ? 0. : result.y;\n            result.z = 0.;\n            result.w = 0.;\n          ");else {
      var _e1012 = getChannels("coords", a);

      s += this.enableShapeUniforms ? "\n            bool nextRowOutOfBounds =\n              (".concat(_e1012[a - 2], " + 1) >= outShape[").concat(a, " - 2];\n            bool nextColOutOfBounds =\n              (").concat(_e1012[a - 1], " + 1) >= outShape[").concat(a, " - 1];\n            result.y = nextColOutOfBounds ? 0. : result.y;\n            result.z = nextRowOutOfBounds ? 0. : result.z;\n            result.w = nextColOutOfBounds || nextRowOutOfBounds ? 0. : result.w;\n          ") : "\n            bool nextRowOutOfBounds =\n              (".concat(_e1012[a - 2], " + 1) >= ").concat(this.outputShape[a - 2], ";\n            bool nextColOutOfBounds =\n              (").concat(_e1012[a - 1], " + 1) >= ").concat(this.outputShape[a - 1], ";\n            result.y = nextColOutOfBounds ? 0. : result.y;\n            result.z = nextRowOutOfBounds ? 0. : result.z;\n            result.w = nextColOutOfBounds || nextRowOutOfBounds ? 0. : result.w;\n          ");
    }
    this.userCode = "\n      vec4 binaryOperation(vec4 a, vec4 b) {\n        ".concat(e, "\n      }\n\n      void main() {\n        vec4 a = getAAtOutCoords();\n        vec4 b = getBAtOutCoords();\n\n        vec4 result = binaryOperation(a, b);\n        ").concat(s, "\n\n        setOutput(result);\n      }\n    ");
  }

}

function identity(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    x: r
  } = t;
  return n.incRef(r.dataId), {
    dataId: r.dataId,
    shape: r.shape,
    dtype: r.dtype
  };
}

var identityConfig = {
  kernelName: Identity$1,
  backendName: "webgl",
  kernelFunc: identity
};

function complex(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    real: r,
    imag: a
  } = t,
      s = n.makeTensorInfo(r.shape, "complex64"),
      o = n.texData.get(s.dataId),
      i = identity({
    inputs: {
      x: r
    },
    backend: n
  }),
      l = identity({
    inputs: {
      x: a
    },
    backend: n
  });
  return o.complexTensorInfos = {
    real: i,
    imag: l
  }, s;
}

var complexConfig = {
  kernelName: Complex,
  backendName: "webgl",
  kernelFunc: complex
},
    LEAKYRELU = "return (a < 0.) ? b * a : a;",
    LEAKYRELU_PACKED = "\n  vec4 aLessThanZero = vec4(lessThan(a, vec4(0.)));\n  return (aLessThanZero * (b * a)) + ((vec4(1.0) - aLessThanZero) * a);\n";

function leakyRelu(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    alpha: s
  } = r,
      o = n.makeTensorInfo([], "float32", createScalarValue(s, "float32")),
      i = env().getBool("WEBGL_PACK_BINARY_OPERATIONS") ? new BinaryOpPackedProgram(LEAKYRELU_PACKED, a.shape, o.shape) : new BinaryOpProgram(LEAKYRELU, a.shape, o.shape),
      l = n.runWebGLProgram(i, [a, o], a.dtype);
  return n.disposeIntermediateTensorInfo(o), l;
}

var leakyReluConfig = {
  kernelName: LeakyRelu,
  backendName: "webgl",
  kernelFunc: leakyRelu
},
    PRELU = "return (a < 0.) ? b * a : a;",
    PRELU_PACKED = "\n  vec4 aLessThanZero = vec4(lessThan(a, vec4(0.)));\n  return (aLessThanZero * (b * a)) + ((vec4(1.0) - aLessThanZero) * a);\n";

function prelu(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    x: r,
    alpha: a
  } = t,
      s = env().getBool("WEBGL_PACK_BINARY_OPERATIONS") ? new BinaryOpPackedProgram(PRELU_PACKED, r.shape, a.shape) : new BinaryOpProgram(PRELU, r.shape, a.shape);
  return n.runWebGLProgram(s, [r, a], r.dtype);
}

var preluConfig = {
  kernelName: Prelu,
  backendName: "webgl",
  kernelFunc: prelu
},
    CHECK_NAN_SNIPPET_UNARY = "if (isnan(x)) return x;",
    CHECK_NAN_SNIPPET_BINARY = "\n  if (isnan(a)) return a;\n  if (isnan(b)) return b;\n",
    CHECK_NAN_SNIPPET_BINARY_PACKED = "\n  result.r = isNaN.r > 0. ? NAN : result.r;\n  result.g = isNaN.g > 0. ? NAN : result.g;\n  result.b = isNaN.b > 0. ? NAN : result.b;\n  result.a = isNaN.a > 0. ? NAN : result.a;\n";

function unaryKernelFunc(_ref61) {
  var {
    opSnippet: e,
    packedOpSnippet: t,
    cpuKernelImpl: n,
    dtype: r
  } = _ref61;
  return _ref62 => {
    var {
      inputs: a,
      backend: s
    } = _ref62;
    var {
      x: o
    } = a,
        i = s,
        l = r || o.dtype;

    if (i.shouldExecuteOnCPU([o]) && null != n) {
      var _e1013 = i.texData.get(o.dataId),
          _t693 = n(_e1013.values, l);

      return i.makeTensorInfo(o.shape, l, _t693);
    }

    var u;
    return u = env().getBool("WEBGL_PACK_UNARY_OPERATIONS") && null != t ? new UnaryOpPackedProgram(o.shape, t) : new UnaryOpProgram(o.shape, e), i.runWebGLProgram(u, [o], l);
  };
}

function binaryKernelFunc(_ref63) {
  var {
    opSnippet: e,
    packedOpSnippet: t,
    checkOutOfBounds: n = !1,
    supportsComplex: r = !1,
    cpuKernelImpl: a,
    dtype: s
  } = _ref63;
  return _ref64 => {
    var {
      inputs: o,
      backend: i
    } = _ref64;
    var {
      a: l,
      b: u
    } = o,
        c = i;

    if (r && "complex64" === l.dtype) {
      var _t694 = c.texData.get(l.dataId),
          _n430 = c.texData.get(u.dataId),
          [_r411, _a299] = [[_t694.complexTensorInfos.real, _n430.complexTensorInfos.real], [_t694.complexTensorInfos.imag, _n430.complexTensorInfos.imag]].map(t => {
        var [n, r] = t,
            a = {
          dataId: n.dataId,
          dtype: n.dtype,
          shape: l.shape
        },
            s = {
          dataId: r.dataId,
          dtype: r.dtype,
          shape: u.shape
        },
            o = new BinaryOpProgram(e, l.shape, u.shape);
        return c.runWebGLProgram(o, [a, s], upcastType(n.dtype, r.dtype));
      }),
          _s212 = complex({
        inputs: {
          real: _r411,
          imag: _a299
        },
        backend: c
      });

      return c.disposeIntermediateTensorInfo(_r411), c.disposeIntermediateTensorInfo(_a299), _s212;
    }

    var p = s || upcastType(l.dtype, u.dtype);

    if (("string" === l.dtype || "string" === u.dtype || c.shouldExecuteOnCPU([l, u])) && null != a) {
      var _e1014 = c.texData.get(l.dataId).values,
          _t695 = c.texData.get(u.dataId).values,
          _n431 = "string" === l.dtype ? fromUint8ToStringArray(_e1014) : _e1014,
          _r412 = "string" === l.dtype ? fromUint8ToStringArray(_t695) : _t695,
          [_s213, _o147] = a(l.shape, u.shape, _n431, _r412, p),
          _i82 = c.makeTensorInfo(_o147, p);

      return c.texData.get(_i82.dataId).values = _s213, _i82;
    }

    var d;
    return d = env().getBool("WEBGL_PACK_BINARY_OPERATIONS") && null != t ? new BinaryOpPackedProgram(t, l.shape, u.shape, n) : new BinaryOpProgram(e, l.shape, u.shape), c.runWebGLProgram(d, [l, u], p);
  };
}

function mapActivationToShaderProgram(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;
  if ("linear" === e) return t ? LINEAR : LINEAR$1;
  if ("relu" === e) return t ? RELU$1 : RELU$2;
  if ("elu" === e) return t ? ELU$1 : ELU$2;
  if ("relu6" === e) return t ? RELU6$1 : RELU6$2;
  if ("prelu" === e) return t ? PRELU_PACKED : PRELU;
  if ("leakyrelu" === e) return t ? LEAKYRELU_PACKED : LEAKYRELU;
  if ("sigmoid" === e) return t ? SIGMOID$1 : SIGMOID$2;
  throw new Error("Activation ".concat(e, " has not been implemented for the WebGL backend."));
}

class MatMulPackedProgram {
  constructor(e, t, n) {
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
    var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;
    var s = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : !1;
    var o = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : null;
    var i = arguments.length > 7 && arguments[7] !== undefined ? arguments[7] : !1;
    var l = arguments.length > 8 && arguments[8] !== undefined ? arguments[8] : !1;
    this.variableNames = ["matrixA", "matrixB"], this.packedInputs = !0, this.packedOutput = !0, this.outputShape = n;
    var u = Math.ceil((r ? e[1] : e[2]) / 2),
        c = r ? "i * 2, rc.y" : "rc.y, i * 2",
        p = a ? "rc.z, i * 2" : "i * 2, rc.z",
        d = r ? ["a.xxyy", "a.zzww"] : ["a.xxzz", "a.yyww"],
        h = a ? ["b.xzxz", "b.ywyw"] : ["b.xyxy", "b.zwzw"];
    var m = "",
        f = "";
    o && (m = i ? "vec4 activation(vec4 a) {\n          vec4 b = getPreluActivationWeightsAtOutCoords();\n          ".concat(o, "\n        }") : l ? "vec4 activation(vec4 a) {\n          vec4 b = getLeakyreluAlphaAtOutCoords();\n          ".concat(o, "\n        }") : "vec4 activation(vec4 x) {\n          ".concat(o, "\n        }"), f = "result = activation(result);");
    var g = s ? "result += getBiasAtOutCoords();" : "";
    s && this.variableNames.push("bias"), i && this.variableNames.push("preluActivationWeights"), l && this.variableNames.push("leakyreluAlpha");
    var $ = "rc.x",
        y = "rc.x";
    e[0] < t[0] ? $ = "int(min(float(rc.x), ".concat(e[0] - 1, ".))") : t[0] < e[0] && (y = "int(min(float(rc.x), ".concat(t[0] - 1, ".))")), this.userCode = "\n      ".concat(m, "\n\n      const float sharedDimension = ").concat(u, ".0;\n\n      vec4 dot2x2ARowBCol(ivec3 rc) {\n        vec4 result = vec4(0);\n        for (int i = 0; i < ").concat(u, "; i++) {\n          int batchA = ").concat($, ";\n          int batchB = ").concat(y, ";\n          vec4 a = getMatrixA(batchA, ").concat(c, ");\n          vec4 b = getMatrixB(batchB, ").concat(p, ");\n\n          // These swizzled products need to be separately added.\n          // See: https://github.com/tensorflow/tfjs/issues/1735\n          result += (").concat(d[0], " * ").concat(h[0], ");\n          result += (").concat(d[1], " * ").concat(h[1], ");\n        }\n        return result;\n      }\n\n      void main() {\n        ivec3 rc = getOutputCoords();\n        vec4 result = dot2x2ARowBCol(rc);\n\n        ").concat(g, "\n\n        ").concat(f, "\n\n        setOutput(result);\n      }\n    ");
  }

}

var COMPLEX_MULTIPLY = {
  REAL: "return areal * breal - aimag * bimag;",
  IMAG: "return areal * bimag + aimag * breal;"
};

class BinaryOpComplexProgram {
  constructor(e, t, n) {
    this.variableNames = ["AReal", "AImag", "BReal", "BImag"], this.outputShape = assertAndGetBroadcastShape(t, n), this.userCode = "\n      float binaryOpComplex(\n          float areal, float aimag, float breal, float bimag) {\n        ".concat(e, "\n      }\n\n      void main() {\n        float areal = getARealAtOutCoords();\n        float aimag = getAImagAtOutCoords();\n        float breal = getBRealAtOutCoords();\n        float bimag = getBImagAtOutCoords();\n        setOutput(binaryOpComplex(areal, aimag, breal, bimag));\n      }\n    ");
  }

}

var MUL = "return a * b;";

function multiply(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    a: r,
    b: a
  } = t,
      s = upcastType(r.dtype, a.dtype);

  if ("complex64" === r.dtype) {
    var _e1015 = n.texData.get(r.dataId),
        _t696 = n.texData.get(a.dataId),
        _s214 = new BinaryOpComplexProgram(COMPLEX_MULTIPLY.REAL, r.shape, a.shape),
        _o148 = new BinaryOpComplexProgram(COMPLEX_MULTIPLY.IMAG, r.shape, a.shape),
        i = [{
      dataId: _e1015.complexTensorInfos.real.dataId,
      dtype: _e1015.complexTensorInfos.real.dtype,
      shape: r.shape
    }, {
      dataId: _e1015.complexTensorInfos.imag.dataId,
      dtype: _e1015.complexTensorInfos.imag.dtype,
      shape: r.shape
    }, {
      dataId: _t696.complexTensorInfos.real.dataId,
      dtype: _t696.complexTensorInfos.real.dtype,
      shape: a.shape
    }, {
      dataId: _t696.complexTensorInfos.imag.dataId,
      dtype: _t696.complexTensorInfos.imag.dtype,
      shape: a.shape
    }],
        l = n.runWebGLProgram(_s214, i, "float32"),
        u = n.runWebGLProgram(_o148, i, "float32"),
        c = complex({
      inputs: {
        real: l,
        imag: u
      },
      backend: n
    });

    return n.disposeIntermediateTensorInfo(l), n.disposeIntermediateTensorInfo(u), c;
  }

  if (n.shouldExecuteOnCPU([r, a])) {
    var _e1016 = n.texData.get(r.dataId),
        _t697 = n.texData.get(a.dataId),
        [_o149, _i83] = multiplyImplCPU(r.shape, a.shape, _e1016.values, _t697.values, s),
        _l64 = n.makeTensorInfo(_i83, s);

    return n.texData.get(_l64.dataId).values = _o149, _l64;
  }

  var o;
  return o = env().getBool("WEBGL_PACK_BINARY_OPERATIONS") ? new BinaryOpPackedProgram(MUL, r.shape, a.shape) : new BinaryOpProgram(MUL, r.shape, a.shape), n.runWebGLProgram(o, [r, a], s);
}

var multiplyConfig = {
  kernelName: Multiply$1,
  backendName: "webgl",
  kernelFunc: multiply
};

function packedReshape(e, t, n) {
  var r = [getBatchDim(e.shape), ...getRowsCols(e.shape)],
      a = {
    dtype: e.dtype,
    shape: r,
    dataId: e.dataId
  },
      s = [getBatchDim(t), ...getRowsCols(t)],
      o = new ReshapePackedProgram(s, r),
      i = n.runWebGLProgram(o, [a], e.dtype, null, !0);
  return {
    dataId: i.dataId,
    shape: t,
    dtype: i.dtype
  };
}

function reshape(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    shape: s
  } = r,
      o = n,
      i = sizeFromShape(a.shape),
      l = inferFromImplicitShape(s, i),
      u = sizeFromShape(l);
  assert$4(i === u, () => "The new shape (".concat(l, ") has ").concat(u, " elements and the old shape (").concat(a.shape, ") has ").concat(i, " elements. The new shape and old shape must have the same number of elements."));
  var c = o.texData.get(a.dataId);
  return !c.isPacked || isReshapeFree(a.shape, l) || null !== c.texture && isReshapeFree(c.shape, l) ? (o.incRef(a.dataId), {
    dataId: a.dataId,
    shape: l,
    dtype: a.dtype
  }) : packedReshape(a, l, o);
}

var reshapeConfig = {
  kernelName: Reshape$1,
  backendName: "webgl",
  kernelFunc: reshape
};

class MeanProgram {
  constructor(e, t) {
    this.variableNames = ["x"];
    var {
      windowSize: n,
      batchSize: r,
      inSize: a,
      outSize: s
    } = e;
    this.outputShape = [r, s];
    var o = 4 * Math.floor(n / 4),
        i = n % 4;
    var l = "sumValue += dot(values, ones);";

    if (null != t) {
      var _e1017 = 1 / t;

      l = "sumValue += dot(values * ".concat(isInt(_e1017) ? _e1017.toPrecision(2) : _e1017, ", ones);");
    }

    var u = "";
    a % n > 0 && (u = "\n        if (inIdx < 0 || inIdx >= ".concat(a, ") {\n          return 0.0;\n        }\n      ")), this.userCode = "\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\n\n      float getValue(int batch, int inIdx) {\n        ".concat(u, "\n        return getX(batch, inIdx);\n      }\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n        int outIdx = coords[1];\n        int inOffset = outIdx * ").concat(n, ";\n\n        float sumValue = 0.0;\n\n        for (int i = 0; i < ").concat(o, "; i += 4) {\n          int inIdx = inOffset + i;\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            getValue(batch, inIdx + 3)\n          );\n\n          ").concat(l, "\n        }\n\n        int inIdx = inOffset + ").concat(o, ";\n        if (").concat(1 === i, ") {\n          vec4 values = vec4(getValue(batch, inIdx), 0.0, 0.0, 0.0);\n\n          ").concat(l, "\n        } else if (").concat(2 === i, ") {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1), 0.0, 0.0);\n\n          ").concat(l, "\n        } else if (").concat(3 === i, ") {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2), 0.0);\n\n          ").concat(l, "\n        }\n        setOutput(sumValue);\n      }\n    ");
  }

}

class ReduceProgram {
  constructor(e, t) {
    this.variableNames = ["x"];
    var {
      windowSize: n,
      batchSize: r,
      inSize: a,
      outSize: s
    } = e;
    this.outputShape = [r, s];
    var o = "0.0",
        i = "";
    "prod" === t ? o = "1.0" : "min" === t ? (o = "1.0 / 1e-20", i = "min") : "max" === t && (o = "-1.0 / 1e-20", i = "max");
    var l = "".concat(t, "(").concat(t, "(").concat(t, "(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])");
    "sum" === t ? l = "sumValue" : "prod" === t ? l = "prodValue" : "all" === t ? l = "allValue" : "any" === t && (l = "anyValue");
    var u = 4 * Math.floor(n / 4),
        c = n % 4;
    var p = "\n      if (".concat("sum" === t, ") {\n        sumValue += dot(values, ones);\n      } else if (").concat("prod" === t, ") {\n        vec2 tmp = vec2(values[0], values[1]) * vec2(values[2], values[3]);\n        prodValue *= tmp[0] * tmp[1];\n      } else {\n        minMaxValue = ").concat(i, "(values, minMaxValue);\n        if (").concat("min" === t, " || ").concat("max" === t, ") {\n          minMaxValue = ").concat(i, "(values, minMaxValue);\n          bvec4 isNaN = isnan(values);\n          if (isNaN.r || isNaN.g || isNaN.b || isNaN.a) {\n            minMaxValue = vec4(NAN);\n          }\n        }\n      }\n    "),
        d = "vec4";
    "all" === t ? (o = "1.0", p = "\n        bool reducedAllValue = all(values);\n        float floatedReducedAllValue = float(reducedAllValue);\n        allValue = float(allValue >= 1.0 && floatedReducedAllValue >= 1.0);\n      ", d = "bvec4") : "any" === t && (o = "0.0", p = "\n        bool reducedAnyValue = any(values);\n        float floatedReducedAnyValue = float(reducedAnyValue);\n        anyValue = float(anyValue >= 1.0 || floatedReducedAnyValue >= 1.0);\n      ", d = "bvec4");
    var h = "";
    a % n > 0 && (h = "\n        if (inIdx < 0 || inIdx >= ".concat(a, ") {\n          return initializationValue;\n        }\n      ")), this.userCode = "\n      const float initializationValue = ".concat(o, ";\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\n\n      float getValue(int batch, int inIdx) {\n        ").concat(h, "\n        return getX(batch, inIdx);\n      }\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n        int outIdx = coords[1];\n        int inOffset = outIdx * ").concat(n, ";\n\n        vec4 minMaxValue = vec4(").concat(o, ");\n        float prodValue = 1.0;\n        float sumValue = 0.0;\n        float allValue = 1.0;\n        float anyValue = 0.0;\n\n        for (int i = 0; i < ").concat(u, "; i += 4) {\n          int inIdx = inOffset + i;\n          ").concat(d, " values = ").concat(d, "(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            getValue(batch, inIdx + 3)\n          );\n\n          ").concat(p, "\n        }\n\n        int inIdx = inOffset + ").concat(u, ";\n        if (").concat(1 === c, ") {\n          ").concat(d, " values = ").concat(d, "(\n            getValue(batch, inIdx),\n            initializationValue,\n            initializationValue,\n            initializationValue\n          );\n\n          ").concat(p, "\n        } else if (").concat(2 === c, ") {\n          ").concat(d, " values = ").concat(d, "(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            initializationValue,\n            initializationValue\n          );\n\n          ").concat(p, "\n        } else if (").concat(3 === c, ") {\n          ").concat(d, " values = ").concat(d, "(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            initializationValue\n          );\n\n          ").concat(p, "\n        }\n        setOutput(").concat(l, ");\n      }\n    ");
  }

}

function getReductionStages(e) {
  var t = [];

  for (; 0 === t.length || 1 !== t[t.length - 1].outSize;) {
    var n = t.length ? t[t.length - 1].outSize : e[1],
        r = computeOptimalWindowSize(n);
    t.push({
      inSize: n,
      windowSize: r,
      outSize: Math.ceil(n / r)
    });
  }

  return t;
}

function reduce(e, t, n, r) {
  var a = getReductionStages(e.shape);
  var s = e;

  for (var o = 0; o < a.length; o++) {
    var {
      inSize: i,
      windowSize: l,
      outSize: u
    } = a[o];

    var c = void 0,
        _p37 = void 0;

    c = "mean" === n ? 0 === o ? new MeanProgram({
      windowSize: l,
      inSize: i,
      batchSize: e.shape[0],
      outSize: u
    }, i) : new MeanProgram({
      windowSize: l,
      inSize: i,
      batchSize: e.shape[0],
      outSize: u
    }) : new ReduceProgram({
      windowSize: l,
      inSize: i,
      batchSize: e.shape[0],
      outSize: u
    }, n), _p37 = s, s = r.runWebGLProgram(c, [s], t), _p37.dataId !== e.dataId && r.disposeIntermediateTensorInfo(_p37);
  }

  return s;
}

class TransposeProgram {
  constructor(e, t) {
    this.variableNames = ["A"];
    var n = new Array(e.length);

    for (var _r413 = 0; _r413 < n.length; _r413++) {
      n[_r413] = e[t[_r413]];
    }

    this.outputShape = n, this.rank = n.length;
    var r = getCoordsDataType(this.rank),
        a = getSwitchedCoords(t);
    this.userCode = "\n    void main() {\n      ".concat(r, " resRC = getOutputCoords();\n      setOutput(getA(").concat(a, "));\n    }\n    ");
  }

}

function getSwitchedCoords(e) {
  var t = e.length;
  if (t > 6) throw Error("Transpose for rank ".concat(t, " is not yet supported"));
  var n = ["resRC.x", "resRC.y", "resRC.z", "resRC.w", "resRC.u", "resRC.v"],
      r = new Array(t);

  for (var _t698 = 0; _t698 < e.length; _t698++) {
    r[e[_t698]] = n[_t698];
  }

  return r.join();
}

class TransposePackedProgram {
  constructor(e, t) {
    this.variableNames = ["A"], this.packedInputs = !0, this.packedOutput = !0;
    var n = new Array(e.length);

    for (var _r414 = 0; _r414 < n.length; _r414++) {
      n[_r414] = e[t[_r414]];
    }

    if (this.outputShape = n, this.rank = n.length, this.rank > 6) throw Error("Packed transpose for rank ".concat(this.rank, " is not yet supported."));
    var r = getCoordsDataType(this.rank),
        a = getVecChannels("rc", this.rank),
        s = new Array(this.rank);

    for (var _e1018 = 0; _e1018 < t.length; _e1018++) {
      s[t[_e1018]] = a[_e1018];
    }

    var o = "vec2(".concat(s.slice(-2).join(), ")"),
        i = "++".concat(a[this.rank - 1], " < ").concat(n[this.rank - 1]),
        l = "getChannel(getA(".concat(s.join(), "), ").concat(o, ")");
    this.userCode = "\n    void main() {\n      ".concat(r, " rc = getOutputCoords();\n      vec4 result = vec4(0.);\n      result[0] = ").concat(l, ";\n      if(").concat(i, ") {\n        result[1] = ").concat(l, ";\n      }\n      --").concat(a[this.rank - 1], ";\n      if(++").concat(a[this.rank - 2], " < ").concat(n[this.rank - 2], ") {\n        result[2] = ").concat(l, ";\n        if(").concat(i, ") {\n          result[3] = ").concat(l, ";\n        }\n      }\n      setOutput(result);\n    }\n    ");
  }

}

function transposeImpl(e, t, n) {
  var r = env().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new TransposePackedProgram(e.shape, t) : new TransposeProgram(e.shape, t);
  return n.runWebGLProgram(r, [e], e.dtype);
}

function sumImpl(e, t, n, r) {
  var a = e.shape.length,
      s = parseAxisParam(t, e.shape);
  var o = s;
  var i = getAxesPermutation(o, a),
      l = null != i;
  var u = e;
  l && (u = transposeImpl(e, i, r), o = getInnerMostAxes(o.length, a)), assertAxesAreInnerMostDims("sum", o, a);
  var [c, p] = computeOutAndReduceShapes(u.shape, o);
  var d = c;
  n && (d = expandShapeToKeepDim(c, s));
  var h = sizeFromShape(p),
      m = reshape({
    inputs: {
      x: u
    },
    attrs: {
      shape: [sizeFromShape(e.shape) / h, h]
    },
    backend: r
  }),
      f = reduce(m, sumOutType(e.dtype), "sum", r),
      g = reshape({
    inputs: {
      x: f
    },
    attrs: {
      shape: d
    },
    backend: r
  });
  return r.disposeIntermediateTensorInfo(m), r.disposeIntermediateTensorInfo(f), l && r.disposeIntermediateTensorInfo(u), g;
}

function sum(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    axis: s,
    keepDims: o
  } = r;
  return sumImpl(a, s, o, n);
}

var sumConfig = {
  kernelName: Sum,
  backendName: "webgl",
  kernelFunc: sum
};

function transpose(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    perm: s
  } = r,
      o = n,
      i = new Array(a.shape.length);

  for (var _e1019 = 0; _e1019 < i.length; _e1019++) {
    i[_e1019] = a.shape[s[_e1019]];
  }

  var l;

  if (o.shouldExecuteOnCPU([a])) {
    var _e1020 = o.texData.get(a.dataId),
        _t699 = transposeImplCPU(_e1020.values, a.shape, a.dtype, s, i);

    l = o.makeTensorInfo(i, a.dtype), o.texData.get(l.dataId).values = _t699;
  } else l = transposeImpl(a, s, o);

  return l;
}

var transposeConfig = {
  kernelName: Transpose,
  backendName: "webgl",
  kernelFunc: transpose
},
    MATMUL_SHARED_DIM_THRESHOLD = 1e3;

function batchMatMulImpl(_ref65) {
  var {
    a: e,
    b: t,
    transposeA: n,
    transposeB: r,
    backend: a,
    bias: s = null,
    preluActivationWeights: o = null,
    leakyreluAlpha: i = 0,
    activation: l = null
  } = _ref65;
  var u = e.shape.length,
      c = t.shape.length,
      p = n ? e.shape[u - 2] : e.shape[u - 1],
      d = r ? t.shape[c - 1] : t.shape[c - 2],
      h = n ? e.shape[u - 1] : e.shape[u - 2],
      m = r ? t.shape[c - 2] : t.shape[c - 1],
      f = e.shape.slice(0, -2),
      g = t.shape.slice(0, -2),
      $ = sizeFromShape(f),
      y = sizeFromShape(g);
  assert$4(u >= 2 && c >= 2 && ($ === y || 1 === $ || 1 === y), () => "Error in matMul: the input batch dimensions must either be the same or at least one input batch dimension must be 1. Got input batch dimensions of (".concat(f, ") and (").concat(g, ")."));
  var b = ($ > y ? e.shape.slice(0, -2) : t.shape.slice(0, -2)).concat([h, m]);
  assert$4(p === d, () => "Error in matMul: inner shapes (".concat(p, ") and (").concat(d, ") of Tensors with shapes ").concat(e.shape, " and ").concat(t.shape, " and transposeA=").concat(n, " and transposeB=").concat(r, " must match."));
  var x = n ? [$, p, h] : [$, h, p],
      v = r ? [y, m, d] : [y, d, m],
      I = reshape({
    inputs: {
      x: e
    },
    backend: a,
    attrs: {
      shape: x
    }
  }),
      C = reshape({
    inputs: {
      x: t
    },
    backend: a,
    attrs: {
      shape: v
    }
  }),
      S = [I, C],
      k = Math.max($, y),
      T = n ? I.shape[1] : I.shape[2],
      N = null != s,
      w = null != o,
      E = "leakyrelu" === l,
      A = null != l ? mapActivationToShaderProgram(l, !0) : null;
  var D;

  if ((1 === h || 1 === m) && T > MATMUL_SHARED_DIM_THRESHOLD && !1 === (N || w || E || null != A)) {
    var _e1021 = I,
        _t700 = C;
    n && (_e1021 = transpose({
      inputs: {
        x: I
      },
      backend: a,
      attrs: {
        perm: [0, 2, 1]
      }
    }), S.push(_e1021)), r && (_t700 = transpose({
      inputs: {
        x: C
      },
      backend: a,
      attrs: {
        perm: [0, 2, 1]
      }
    }), S.push(_t700));

    var _s215 = 1 === m;

    var _o150 = _e1021;
    1 !== m && (_o150 = reshape({
      inputs: {
        x: _e1021
      },
      backend: a,
      attrs: {
        shape: [k, T, 1]
      }
    }), S.push(_o150));

    var _i84 = 1 === m ? 2 : 1;

    var _l65 = _t700;
    _s215 && (_l65 = reshape({
      inputs: {
        x: _t700
      },
      backend: a,
      attrs: {
        shape: [k, 1, T]
      }
    }), S.push(_l65));

    var _u57 = multiply({
      inputs: {
        a: _o150,
        b: _l65
      },
      backend: a
    });

    D = sum({
      inputs: {
        x: _u57
      },
      backend: a,
      attrs: {
        axis: _i84,
        keepDims: !0
      }
    }), S.push(_u57);
  } else {
    var _l66 = upcastType(e.dtype, t.dtype),
        _u58 = new MatMulPackedProgram(x, v, [k, h, m], n, r, N, A, w, E),
        _c38 = [I, C];

    if (null != s && _c38.push(s), w && _c38.push(o), E) {
      var _e1022 = a.makeTensorInfo([], "float32", createScalarValue(i, "float32"));

      _c38.push(_e1022), S.push(_e1022);
    }

    D = a.runWebGLProgram(_u58, _c38, _l66);
  }

  var R = reshape({
    inputs: {
      x: D
    },
    backend: a,
    attrs: {
      shape: b
    }
  });
  S.push(D);

  for (var _e1023 of S) {
    a.disposeIntermediateTensorInfo(_e1023);
  }

  return R;
}

function _fusedMatMul(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    a,
    b: s,
    bias: o,
    preluActivationWeights: i
  } = t,
      {
    transposeA: l,
    transposeB: u,
    activation: c,
    leakyreluAlpha: p
  } = r;
  return batchMatMulImpl({
    a,
    b: s,
    transposeA: l,
    transposeB: u,
    backend: n,
    bias: o,
    preluActivationWeights: i,
    leakyreluAlpha: p,
    activation: c
  });
}

var _fusedMatMulConfig = {
  kernelName: _FusedMatMul,
  backendName: "webgl",
  kernelFunc: _fusedMatMul
},
    ABS = "return abs(x);";

function abs(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    x: r
  } = t;

  if (n.shouldExecuteOnCPU([r]) && "complex64" !== r.dtype) {
    var _e1024 = n.texData.get(r.dataId),
        _t701 = simpleAbsImplCPU(_e1024.values);

    return n.makeTensorInfo(r.shape, r.dtype, _t701);
  }

  var a;
  return a = env().getBool("WEBGL_PACK_UNARY_OPERATIONS") ? new UnaryOpPackedProgram(r.shape, ABS) : new UnaryOpProgram(r.shape, ABS), n.runWebGLProgram(a, [r], r.dtype);
}

var absConfig = {
  kernelName: Abs,
  backendName: "webgl",
  kernelFunc: abs
},
    ACOS = CHECK_NAN_SNIPPET$2 + "\n  if (abs(x) > 1.) {\n    return NAN;\n  }\n  return acos(x);\n",
    acos = unaryKernelFunc({
  opSnippet: ACOS
}),
    acosConfig = {
  kernelName: Acos,
  backendName: "webgl",
  kernelFunc: acos
},
    ACOSH = CHECK_NAN_SNIPPET$2 + "\n  if (x < 1.0) return NAN;\nreturn log(x + sqrt(x * x - 1.0));",
    acosh = unaryKernelFunc({
  opSnippet: ACOSH
}),
    acoshConfig = {
  kernelName: Acosh,
  backendName: "webgl",
  kernelFunc: acosh
},
    ADD = "return a + b;",
    addKernelFunc = binaryKernelFunc({
  opSnippet: ADD,
  packedOpSnippet: ADD,
  supportsComplex: !0,
  cpuKernelImpl: addImplCPU
}),
    addConfig = {
  kernelName: Add$1,
  backendName: "webgl",
  kernelFunc: addKernelFunc
};

class AddNProgram {
  constructor(e, t) {
    this.outputShape = [], this.outputShape = e, this.variableNames = t.map((e, t) => "T".concat(t));
    var n = [];
    this.variableNames.forEach(e => {
      n.push("float v".concat(e, " = get").concat(e, "AtOutCoords();"));
    });
    var r = this.variableNames.map(e => "v".concat(e)).join(" + ");
    this.userCode = "\n      void main() {\n        ".concat(n.join("\n        "), "\n\n        float result = ").concat(r, ";\n        setOutput(result);\n      }\n    ");
  }

}

class AddNPackedProgram {
  constructor(e, t) {
    this.outputShape = [], this.packedInputs = !0, this.packedOutput = !0, this.outputShape = e, this.variableNames = t.map((e, t) => "T".concat(t));
    var n = [];
    this.variableNames.forEach(e => {
      n.push("vec4 v".concat(e, " = get").concat(e, "AtOutCoords();"));
    });
    var r = this.variableNames.map(e => "v".concat(e)).join(" + ");
    this.userCode = "\n      void main() {\n        ".concat(n.join("\n        "), "\n\n        vec4 result = ").concat(r, ";\n        setOutput(result);\n      }\n    ");
  }

}

function addN(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      r = t;
  if (1 === r.length) return identity({
    inputs: {
      x: r[0]
    },
    backend: n
  });

  if (r.length > env().get("WEBGL_MAX_TEXTURES_IN_SHADER")) {
    var _e1025 = Math.floor(r.length / 2),
        _t702 = addN({
      inputs: r.slice(0, _e1025),
      backend: n
    }),
        _a300 = addN({
      inputs: r.slice(_e1025),
      backend: n
    });

    return addN({
      inputs: [_t702, _a300],
      backend: n
    });
  }

  var a = r.map(e => e.dtype).reduce((e, t) => upcastType(e, t)),
      s = r.map(e => e.shape),
      o = env().getBool("WEBGL_PACK") ? new AddNPackedProgram(r[0].shape, s) : new AddNProgram(r[0].shape, s);
  return n.runWebGLProgram(o, r, a);
}

var addNConfig = {
  kernelName: AddN,
  backendName: "webgl",
  kernelFunc: addN
};

function all(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    axis: s,
    keepDims: o
  } = r,
      i = a.shape.length,
      l = parseAxisParam(s, a.shape);
  var u = l;
  var c = getAxesPermutation(u, i);
  var p = a;
  null != c && (p = transpose({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      perm: c
    }
  }), u = getInnerMostAxes(u.length, i)), assertAxesAreInnerMostDims("all", u, i);
  var [d, h] = computeOutAndReduceShapes(p.shape, u),
      m = reshape({
    inputs: {
      x: p
    },
    backend: n,
    attrs: {
      shape: [-1, sizeFromShape(h)]
    }
  }),
      f = reduce(m, m.dtype, "all", n);
  var g;
  return g = reshape(o ? {
    inputs: {
      x: f
    },
    backend: n,
    attrs: {
      shape: expandShapeToKeepDim(d, l)
    }
  } : {
    inputs: {
      x: f
    },
    backend: n,
    attrs: {
      shape: d
    }
  }), n.disposeIntermediateTensorInfo(m), n.disposeIntermediateTensorInfo(f), null != c && n.disposeIntermediateTensorInfo(p), g;
}

var allConfig = {
  kernelName: All,
  backendName: "webgl",
  kernelFunc: all
};

function any(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    axis: s,
    keepDims: o
  } = r,
      i = a.shape.length,
      l = parseAxisParam(s, a.shape);
  var u = l;
  var c = getAxesPermutation(u, i);
  var p = a;
  null != c && (p = transpose({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      perm: c
    }
  }), u = getInnerMostAxes(u.length, i)), assertAxesAreInnerMostDims("any", u, i);
  var [d, h] = computeOutAndReduceShapes(p.shape, u),
      m = reshape({
    inputs: {
      x: p
    },
    backend: n,
    attrs: {
      shape: [-1, sizeFromShape(h)]
    }
  }),
      f = reduce(m, m.dtype, "any", n);
  var g;
  return g = reshape(o ? {
    inputs: {
      x: f
    },
    backend: n,
    attrs: {
      shape: expandShapeToKeepDim(d, l)
    }
  } : {
    inputs: {
      x: f
    },
    backend: n,
    attrs: {
      shape: d
    }
  }), n.disposeIntermediateTensorInfo(m), n.disposeIntermediateTensorInfo(f), null != c && n.disposeIntermediateTensorInfo(p), g;
}

var anyConfig = {
  kernelName: Any,
  backendName: "webgl",
  kernelFunc: any
};

class ArgMinMaxProgram {
  constructor(e, t, n) {
    this.variableNames = ["A"];
    var {
      windowSize: r,
      batchSize: a,
      outSize: s
    } = e;
    n || this.variableNames.push("bestIndicesA"), this.outputShape = [a, s], this.userCode = "\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n        int outIdx = coords[1];\n        int inOffset = outIdx * ".concat(r, ";\n\n        int bestIndex = inOffset;\n        float bestValue = getA(batch, bestIndex);\n\n        for (int i = 0; i < ").concat(r, "; i++) {\n          int inIdx = ").concat(n ? "inOffset + i;" : "round(getBestIndicesA(batch, inOffset + i));", ";\n          float candidate = getA(batch, inIdx);\n          if (candidate ").concat("max" === t ? ">" : "<", " bestValue) {\n            bestValue = candidate;\n            bestIndex = inIdx;\n          }\n        }\n        setOutput(float(bestIndex));\n      }\n    ");
  }

}

class ArgMinMaxPackedProgram {
  constructor(e, t, n, r) {
    this.variableNames = ["A"], this.packedInputs = !0, this.packedOutput = !0, assert$4(e.length > 2, () => "Packed arg".concat(n.charAt(0).toUpperCase() + n.slice(1), " supports only inputs with rank above 2."));
    var a = Math.ceil(e[e.length - 1] / t);
    this.outputShape = e.slice(0, -1), a > 1 && this.outputShape.push(a), r || this.variableNames.push("bestIndicesA");
    var s = this.outputShape,
        o = s.length,
        i = getCoordsDataType(o),
        l = getChannels("coords", o);
    var u, c;

    if (1 === a) {
      c = o + 1;

      var _e1026 = getCoordsDataType(c);

      u = "\n        ".concat(_e1026, " sourceLocR = ").concat(_e1026, "(").concat(l.join(), ", 0);\n        ++").concat(l[o - 1], ";\n        ").concat(_e1026, " sourceLocG = ").concat(_e1026, "(").concat(l.join(), ", 0);\n        ++").concat(l[o - 2], ";\n        ").concat(_e1026, " sourceLocA = ").concat(_e1026, "(").concat(l.join(), ", 0);\n        --").concat(l[o - 1], ";\n        ").concat(_e1026, " sourceLocB = ").concat(_e1026, "(").concat(l.join(), ", 0);\n        --").concat(l[o - 2], ";");
    } else c = o, u = "\n        ".concat(i, " sourceLocR = coords;\n        ++").concat(l[o - 1], ";\n        ").concat(i, " sourceLocG = coords;\n        ++").concat(l[o - 2], ";\n        ").concat(i, " sourceLocA = coords;\n        --").concat(l[o - 1], ";\n        ").concat(i, " sourceLocB = coords;\n        --").concat(l[o - 2], ";");

    var p = ["x", "y", "z", "w", "u", "v"].slice(0, c),
        d = "." + p[c - 1],
        h = p.map(e => "int " + e),
        m = getChannels("sourceLocR", c - 1).concat("inIdx.r"),
        f = getChannels("sourceLocG", c - 1).concat("inIdx.g"),
        g = getChannels("sourceLocB", c - 1).concat("inIdx.b"),
        $ = getChannels("sourceLocA", c - 1).concat("inIdx.a"),
        y = "max" === n ? "greaterThan" : "lessThan",
        b = r ? "" : "\n          inIdx = round(vec4(getBestIndicesAChannel(".concat(m.join(), "),\n                             getBestIndicesAChannel(").concat(f.join(), "),\n                             getBestIndicesAChannel(").concat(g.join(), "),\n                             getBestIndicesAChannel(").concat($.join(), ")));"),
        x = "vec4(\n            getAChannel(".concat(m.join(), "),\n            hasNextCol ? getAChannel(").concat(f.join(), ") : 0.,\n            hasNextRow ? getAChannel(").concat(g.join(), ") : 0.,\n            hasNextRow && hasNextCol ? getAChannel(").concat($.join(), ") : 0.)"),
        v = r ? "" : "\n      float getBestIndicesAChannel(".concat(h.join(), ") {\n        return getChannel(getBestIndicesA(").concat(p.join(), "),\n                                          vec2(").concat(p.slice(-2).join(), "));\n      }");
    this.userCode = "\n      float getAChannel(".concat(h.join(), ") {\n        return getChannel(getA(").concat(p.join(), "),\n                               vec2(").concat(p.slice(-2).join(), "));\n      }\n      ").concat(v, "\n      void main() {\n        ").concat(i, " coords = getOutputCoords();\n        bool hasNextCol = ").concat(l[o - 1], " < ").concat(s[o - 1] - 1, ";\n        bool hasNextRow = ").concat(l[o - 2], " < ").concat(s[o - 2] - 1, ";\n        ").concat(u, "\n        ivec4 srcIdx = ivec4(sourceLocR").concat(d, ", sourceLocG").concat(d, ",\n          sourceLocB").concat(d, ", sourceLocA").concat(d, ") * ").concat(t, ";\n        ivec4 inIdx = srcIdx;\n        vec4 bestIndex = vec4(inIdx);\n        vec4 bestValue = ").concat(x, ";\n\n        for (int i = 0; i < ").concat(t, "; i++) {\n          inIdx = srcIdx;\n          ").concat(b, "\n          vec4 candidate = ").concat(x, ";\n          bvec4 nan = isnan(candidate);\n          bvec4 replace = bvec4(\n            vec4(").concat(y, "(candidate, bestValue)) * (vec4(1.0) - vec4(nan)));\n\n          bestValue = vec4(replace.x  ? candidate.x : bestValue.x,\n                           replace.y  ? candidate.y : bestValue.y,\n                           replace.z  ? candidate.z : bestValue.z,\n                           replace.w  ? candidate.w : bestValue.w);\n          bestIndex = mix(bestIndex, vec4(inIdx), vec4(replace));\n          srcIdx++;\n        }\n        setOutput(bestIndex);\n      }\n    ");
  }

}

function argReduce(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : null;
  var a = t.shape[0],
      s = t.shape[1];
  null != r && (a = r.shape[0], s = r.shape[1]);
  var o = computeOptimalWindowSize(s),
      i = {
    windowSize: o,
    inSize: s,
    batchSize: a,
    outSize: Math.ceil(s / o)
  },
      l = new ArgMinMaxProgram(i, n, null == r),
      u = [t];
  null != r && u.push(r);
  var c = e.runWebGLProgram(l, u, "int32");
  if (1 === c.shape[1]) return c;
  var p = argReduce(e, t, n, c);
  return e.disposeIntermediateTensorInfo(c), p;
}

function argReducePacked(e, t, n) {
  var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : null;
  var a = null != r ? r.shape : t.shape,
      s = computeOptimalWindowSize(a[a.length - 1]),
      o = new ArgMinMaxPackedProgram(a, s, n, null == r),
      i = e.runWebGLProgram(o, null == r ? [t] : [t, r], "int32");

  if (i.shape.length === t.shape.length) {
    var _r415 = argReducePacked(e, t, n, i);

    return e.disposeIntermediateTensorInfo(i), _r415;
  }

  return i;
}

function argMinMaxReduce(e, t, n, r) {
  var a = [n];

  if (assertAxesAreInnerMostDims("arg" + r.charAt(0).toUpperCase() + r.slice(1), a, t.shape.length), !env().getBool("WEBGL_PACK_REDUCE") || t.shape.length <= 2) {
    var _n432 = [],
        [s, o] = computeOutAndReduceShapes(t.shape, a),
        i = sizeFromShape(o),
        l = reshape({
      inputs: {
        x: t
      },
      backend: e,
      attrs: {
        shape: [-1, i]
      }
    });

    _n432.push(l);

    var u = argReduce(e, l, r);

    _n432.push(u);

    var c = reshape({
      inputs: {
        x: u
      },
      backend: e,
      attrs: {
        shape: s
      }
    });
    return _n432.forEach(t => e.disposeIntermediateTensorInfo(t)), c;
  }

  return argReducePacked(e, t, r);
}

function argMax(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    axis: s
  } = r;
  var o = parseAxisParam(s, a.shape);
  var i = getAxesPermutation(o, a.shape.length);
  var l = a;
  var u = [];
  null != i && (l = transpose({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      perm: i
    }
  }), u.push(l), o = getInnerMostAxes(o.length, l.shape.length)), assertAxesAreInnerMostDims("argMax", [o[0]], l.shape.length);
  var c = argMinMaxReduce(n, l, o[0], "max");
  return u.forEach(e => n.disposeIntermediateTensorInfo(e)), c;
}

var argMaxConfig = {
  kernelName: ArgMax,
  backendName: "webgl",
  kernelFunc: argMax
};

function argMin(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    axis: s
  } = r;
  var o = parseAxisParam(s, a.shape);
  var i = getAxesPermutation(o, a.shape.length);
  var l = a;
  var u = [];
  null != i && (l = transpose({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      perm: i
    }
  }), u.push(l), o = getInnerMostAxes(o.length, l.shape.length)), assertAxesAreInnerMostDims("argMin", [o[0]], l.shape.length);
  var c = argMinMaxReduce(n, l, o[0], "min");
  return u.forEach(e => n.disposeIntermediateTensorInfo(e)), c;
}

var argMinConfig = {
  kernelName: ArgMin,
  backendName: "webgl",
  kernelFunc: argMin
},
    ASIN = CHECK_NAN_SNIPPET$2 + "\n  if (abs(x) > 1.) {\n    return NAN;\n  }\n  return asin(x);\n",
    asin = unaryKernelFunc({
  opSnippet: ASIN
}),
    asinConfig = {
  kernelName: Asin,
  backendName: "webgl",
  kernelFunc: asin
},
    ASINH = CHECK_NAN_SNIPPET$2 + "return log(x + sqrt(x * x + 1.0));",
    asinh = unaryKernelFunc({
  opSnippet: ASINH
}),
    asinhConfig = {
  kernelName: Asinh,
  backendName: "webgl",
  kernelFunc: asinh
},
    ATAN = CHECK_NAN_SNIPPET$2 + "\n  return atan(x);\n",
    atan = unaryKernelFunc({
  opSnippet: ATAN
}),
    atanConfig = {
  kernelName: Atan,
  backendName: "webgl",
  kernelFunc: atan
},
    ATAN2 = CHECK_NAN_SNIPPET_BINARY + "\n  return atan(a, b);\n",
    ATAN2_PACKED = "\n  vec4 result = atan(a, b);\n  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));\n  " + CHECK_NAN_SNIPPET_BINARY_PACKED + "\n  return result;\n",
    atan2 = binaryKernelFunc({
  opSnippet: ATAN2,
  packedOpSnippet: ATAN2_PACKED
}),
    atan2Config = {
  kernelName: Atan2,
  backendName: "webgl",
  kernelFunc: atan2
},
    ATANH = CHECK_NAN_SNIPPET$2 + "\n  if ((x < -1.0) || (x > 1.0)) return NAN;\nreturn (log(1.0 + x) - log(1.0 - x)) / 2.0;",
    atanh = unaryKernelFunc({
  opSnippet: ATANH
}),
    atanhConfig = {
  kernelName: Atanh,
  backendName: "webgl",
  kernelFunc: atanh
};

class Pool2DProgram {
  constructor(e, t, n) {
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
    var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;
    if (this.variableNames = ["x"], "avg" === t && n) throw new Error("Cannot compute positions for average pool.");
    var s = e.filterWidth,
        o = e.strideHeight,
        i = e.strideWidth,
        l = e.dilationHeight,
        u = e.dilationWidth,
        c = e.effectiveFilterHeight,
        p = e.effectiveFilterWidth,
        d = e.padInfo.top,
        h = e.padInfo.left;
    this.outputShape = e.outShape;
    var m = "avg" === t;
    var f = "0.0";
    if (m || (f = "-1.0 / 1e-20"), n) return void (this.userCode = "\n        const ivec2 strides = ivec2(".concat(o, ", ").concat(i, ");\n        const ivec2 pads = ivec2(").concat(d, ", ").concat(h, ");\n\n        void main() {\n          ivec4 coords = getOutputCoords();\n          int batch = coords[0];\n          int d = coords[3];\n\n          ivec2 xRCCorner = coords.yz * strides - pads;\n          int xRCorner = xRCCorner.x;\n          int xCCorner = xRCCorner.y;\n\n          // max/min x(?, ?, d) to get y(yR, yC, d).\n          // ? = to be determined\n          float minMaxValue = 0.0;\n          float minMaxValueFound = 0.0;\n          int minMaxPosition = 0;\n          float avgValue = 0.0;\n\n          for (int wR = 0; wR < ").concat(c, ";\n              wR += ").concat(l, ") {\n            int xR = xRCorner + wR;\n\n            if (xR < 0 || xR >= ").concat(e.inHeight, ") {\n              continue;\n            }\n\n            for (int wC = 0; wC < ").concat(p, ";\n                wC += ").concat(u, ") {\n              int xC = xCCorner + wC;\n\n              if (xC < 0 || xC >= ").concat(e.inWidth, ") {\n                continue;\n              }\n\n              float value = getX(batch, xR, xC, d);\n\n              // If a min / max value has already been found, use it. If not,\n              // use the current value.\n              float currMinMaxValue = mix(\n                  value, minMaxValue, minMaxValueFound);\n              if (value >= currMinMaxValue) {\n                minMaxValue = value;\n                minMaxValueFound = 1.0;\n                minMaxPosition = ").concat(r ? a ? "((batch  * ".concat(e.inHeight, " + xR) * ").concat(e.inWidth, " + xC) * ").concat(e.inChannels, " + d") : "(xR * ".concat(e.inWidth, " + xC) * ").concat(e.inChannels, " + d") : "wR * ".concat(p, " + wC"), ";\n              }\n            }\n          }\n          setOutput(float(minMaxPosition));\n        }\n      "));
    var g = "".concat(t, "(").concat(t, "(").concat(t, "(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])");
    "avg" === t && (g = "avgValue / count");
    var $ = 4 * Math.floor(s / 4),
        y = s % 4,
        b = "\n      if (".concat(m, ") {\n        avgValue += dot(values, ones);\n      } else {\n        minMaxValue = max(values, minMaxValue);\n      }\n    ");
    this.userCode = "\n      const ivec2 strides = ivec2(".concat(o, ", ").concat(i, ");\n      const ivec2 pads = ivec2(").concat(d, ", ").concat(h, ");\n      const float initializationValue = ").concat(f, ";\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\n\n      float count = 0.0;\n\n      float getValue(int batch, int xR, int xC, int d) {\n        if (xC < 0 || xC >= ").concat(e.inWidth, ") {\n          return initializationValue;\n        }\n        count += 1.0;\n        return getX(batch, xR, xC, d);\n      }\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d = coords[3];\n\n        ivec2 xRCCorner = coords.yz * strides - pads;\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        // max/min x(?, ?, d) to get y(yR, yC, d).\n        // ? = to be determined\n        vec4 minMaxValue = vec4(").concat(f, ");\n        float avgValue = 0.0;\n        count = 0.0;\n\n        for (int wR = 0; wR < ").concat(c, ";\n            wR += ").concat(l, ") {\n          int xR = xRCorner + wR;\n\n          if (xR < 0 || xR >= ").concat(e.inHeight, ") {\n            continue;\n          }\n\n          for (int wC = 0; wC < ").concat($, "; wC += 4) {\n            int xC = xCCorner + wC * ").concat(u, ";\n\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              getValue(batch, xR, xC + ").concat(u, ", d),\n              getValue(batch, xR, xC + 2 * ").concat(u, ", d),\n              getValue(batch, xR, xC + 3 * ").concat(u, ", d)\n            );\n\n            ").concat(b, "\n          }\n\n          int xC = xCCorner + ").concat($, ";\n          if (").concat(1 === y, ") {\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              initializationValue,\n              initializationValue,\n              initializationValue\n            );\n\n            ").concat(b, "\n          } else if (").concat(2 === y, ") {\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              getValue(batch, xR, xC + ").concat(u, ", d),\n              initializationValue,\n              initializationValue\n            );\n\n            ").concat(b, "\n          } else if (").concat(3 === y, ") {\n            vec4 values = vec4(\n              getValue(batch, xR, xC, d),\n              getValue(batch, xR, xC + ").concat(u, ", d),\n              getValue(batch, xR, xC + 2 * ").concat(u, ", d),\n              initializationValue\n            );\n\n            ").concat(b, "\n          }\n        }\n        setOutput(").concat(g, ");\n      }\n    ");
  }

}

class Pool3DProgram {
  constructor(e, t, n) {
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
    var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;
    if (this.variableNames = ["x"], "avg" === t && n) throw new Error("Cannot compute positions for average pool.");
    var s = e.filterWidth,
        o = e.strideDepth,
        i = e.strideHeight,
        l = e.strideWidth,
        u = e.dilationDepth,
        c = e.dilationHeight,
        p = e.dilationWidth,
        d = e.effectiveFilterDepth,
        h = e.effectiveFilterHeight,
        m = e.effectiveFilterWidth,
        f = e.padInfo.front,
        g = e.padInfo.top,
        $ = e.padInfo.left;
    this.outputShape = e.outShape;
    var y = "avg" === t;
    var b = "0.0";
    if (y || (b = "-1.0 / 1e-20"), n) return void (this.userCode = "\n        const ivec3 strides =\n            ivec3(".concat(o, ", ").concat(i, ", ").concat(l, ");\n        const ivec3 pads = ivec3(").concat(f, ", ").concat(g, ", ").concat($, ");\n\n        void main() {\n          ivec5 coords = getOutputCoords();\n          int batch = coords.x;\n          int ch = coords.u;\n\n          ivec3 xCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\n          int xDCorner = xCorner.x;\n          int xRCorner = xCorner.y;\n          int xCCorner = xCorner.z;\n\n          // max/min x(?, ?, ?, ch) to get y(yD, yR, yC, ch).\n          // ? = to be determined\n          float minMaxValue = 0.0;\n          float minMaxValueFound = 0.0;\n          int minMaxPosition = 0;\n\n          for (int wD = 0; wD < ").concat(d, ";\n              wD += ").concat(u, ") {\n            int xD = xDCorner + wD;\n\n            if (xD < 0 || xD >= ").concat(e.inDepth, ") {\n              continue;\n            }\n\n            for (int wR = 0; wR < ").concat(h, ";\n                wR += ").concat(c, ") {\n              int xR = xRCorner + wR;\n\n              if (xR < 0 || xR >= ").concat(e.inHeight, ") {\n                continue;\n              }\n\n              for (int wC = 0; wC < ").concat(m, ";\n                  wC += ").concat(p, ") {\n                int xC = xCCorner + wC;\n\n                if (xC < 0 || xC >= ").concat(e.inWidth, ") {\n                  continue;\n                }\n\n                float value = getX(batch, xD, xR, xC, ch);\n\n                // If a min / max value has already been found, use it. If not,\n                // use the current value.\n                float currMinMaxValue = mix(\n                    value, minMaxValue, minMaxValueFound);\n                if (value >= currMinMaxValue) {\n                  minMaxValue = value;\n                  minMaxValueFound = 1.0;\n                  minMaxPosition = ").concat(r ? a ? "(((batch * ".concat(e.inDepth, " + xD) * ").concat(e.inHeight, " + xR) * ").concat(e.inWidth, " + xC) * ").concat(e.inChannels, " + ch") : "((xD * ".concat(e.inHeight, " + xR) * ").concat(e.inWidth, " + xC) * ").concat(e.inChannels, " + ch") : "wD * ".concat(h, " * ").concat(m, " +\n                      wR * ").concat(m, " + wC"), ";\n                }\n              }\n            }\n          }\n          setOutput(float(minMaxPosition));\n        }\n      "));
    var x = "".concat(t, "(").concat(t, "(").concat(t, "(minMaxValue[0], minMaxValue[1]), minMaxValue[2]), minMaxValue[3])");
    "avg" === t && (x = "avgValue / count");
    var v = 4 * Math.floor(s / 4),
        I = s % 4,
        C = "\n      if (".concat(y, ") {\n        avgValue += dot(values, ones);\n      } else {\n        minMaxValue = max(values, minMaxValue);\n      }\n    ");
    this.userCode = "\n      const ivec3 strides =\n        ivec3(".concat(o, ", ").concat(i, ", ").concat(l, ");\n      const ivec3 pads = ivec3(").concat(f, ", ").concat(g, ", ").concat($, ");\n      const float initializationValue = ").concat(b, ";\n      const vec4 ones = vec4(1.0, 1.0, 1.0, 1.0);\n\n      float count = 0.0;\n\n      float getValue(int batch, int xD, int xR, int xC, int ch) {\n        if (xC < 0 || xC >= ").concat(e.inWidth, ") {\n          return initializationValue;\n        }\n        count += 1.0;\n        return getX(batch, xD, xR, xC, ch);\n      }\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int ch = coords.u;\n\n        ivec3 xCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\n        int xDCorner = xCorner.x;\n        int xRCorner = xCorner.y;\n        int xCCorner = xCorner.z;\n\n        // max/min x(?, ?, ?, d) to get y(yD, yR, yC, ch).\n        // ? = to be determined\n        vec4 minMaxValue = vec4(").concat(b, ");\n        float avgValue = 0.0;\n        count = 0.0;\n\n        for (int wD = 0; wD < ").concat(d, ";\n            wD += ").concat(u, ") {\n          int xD = xDCorner + wD;\n\n          if (xD < 0 || xD >= ").concat(e.inDepth, ") {\n            continue;\n          }\n\n          for (int wR = 0; wR < ").concat(h, ";\n            wR += ").concat(c, ") {\n            int xR = xRCorner + wR;\n\n            if (xR < 0 || xR >= ").concat(e.inHeight, ") {\n              continue;\n            }\n\n            for (int wC = 0; wC < ").concat(v, "; wC += 4) {\n              int xC = xCCorner + wC * ").concat(p, ";\n\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                getValue(batch, xD, xR, xC + ").concat(p, ", ch),\n                getValue(batch, xD, xR, xC + 2 * ").concat(p, ", ch),\n                getValue(batch, xD, xR, xC + 3 * ").concat(p, ", ch)\n              );\n\n              ").concat(C, "\n            }\n\n            int xC = xCCorner + ").concat(v, ";\n            if (").concat(1 === I, ") {\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                initializationValue,\n                initializationValue,\n                initializationValue\n              );\n\n              ").concat(C, "\n            } else if (").concat(2 === I, ") {\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                getValue(batch, xD, xR, xC + ").concat(p, ", ch),\n                initializationValue,\n                initializationValue\n              );\n\n              ").concat(C, "\n            } else if (").concat(3 === I, ") {\n              vec4 values = vec4(\n                getValue(batch, xD, xR, xC, ch),\n                getValue(batch, xD, xR, xC + ").concat(p, ", ch),\n                getValue(batch, xD, xR, xC + 2 * ").concat(p, ", ch),\n                initializationValue\n              );\n\n              ").concat(C, "\n            }\n          }\n          setOutput(").concat(x, ");\n        }\n      }\n    ");
  }

}

function avgPool(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t;
  assertNotComplex(a, "avgPool");
  var {
    filterSize: s,
    strides: o,
    pad: i,
    dimRoundingMode: l
  } = r;
  assert$4(eitherStridesOrDilationsAreOne(o, 1), () => "Error in avgPool: Either strides or dilations must be 1. Got strides ".concat(o, " and dilations '1'"));
  var u = computePool2DInfo(a.shape, s, o, 1, i, l);
  if (1 === u.filterWidth && 1 === u.filterHeight && arraysEqual(u.inShape, u.outShape)) return identity({
    inputs: {
      x: a
    },
    backend: n
  });
  var c = new Pool2DProgram(u, "avg", !1);
  return n.runWebGLProgram(c, [a], "float32");
}

var avgPoolConfig = {
  kernelName: AvgPool,
  backendName: "webgl",
  kernelFunc: avgPool
};

function avgPool3D(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    filterSize: s,
    strides: o,
    pad: i,
    dimRoundingMode: l,
    dataFormat: u
  } = r,
      c = computePool3DInfo(a.shape, s, o, [1, 1, 1], i, l, u),
      p = new Pool3DProgram(c, "avg", !1);
  return n.runWebGLProgram(p, [a], "float32");
}

var avgPool3DConfig = {
  kernelName: AvgPool3D,
  backendName: "webgl",
  kernelFunc: avgPool3D
};

class AvgPool2DBackpropProgram {
  constructor(e) {
    this.variableNames = ["dy"], this.outputShape = e.inShape;
    var t = e.effectiveFilterHeight,
        n = e.effectiveFilterWidth;
    this.userCode = "\n      const ivec2 pads = ivec2(".concat(t - 1 - e.padInfo.top, ", ").concat(n - 1 - e.padInfo.left, ");\n      const float avgMultiplier = float(").concat(1 / (e.filterHeight * e.filterWidth), ");\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n\n        ivec2 dyRCCorner = coords.yz - pads;\n        int dyRCorner = dyRCCorner.x;\n        int dyCCorner = dyRCCorner.y;\n\n        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ").concat(t, ";\n            wR += ").concat(e.dilationHeight, ") {\n          float dyR = float(dyRCorner + wR) / ").concat(e.strideHeight, ".0;\n\n          if (dyR < 0.0 || dyR >= ").concat(e.outHeight, ".0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          for (int wC = 0; wC < ").concat(n, ";\n            wC+= ").concat(e.dilationWidth, ") {\n            float dyC = float(dyCCorner + wC) / ").concat(e.strideWidth, ".0;\n\n            if (dyC < 0.0 || dyC >= ").concat(e.outWidth, ".0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            float dyValue = getDy(b, idyR, idyC, d);\n\n            dotProd += dyValue * avgMultiplier;\n          }\n        }\n        setOutput(dotProd);\n      }\n    ");
  }

}

class AvgPool3DBackpropProgram {
  constructor(e) {
    this.variableNames = ["dy"], this.outputShape = e.inShape;
    var t = e.effectiveFilterDepth,
        n = e.effectiveFilterHeight,
        r = e.effectiveFilterWidth;
    this.userCode = "\n      const ivec3 pads = ivec3(".concat(t - 1 - e.padInfo.front, ", ").concat(n - 1 - e.padInfo.top, ", ").concat(r - 1 - e.padInfo.left, ");\n      const float avgMultiplier = float(").concat(1 / (e.filterDepth * e.filterHeight * e.filterWidth), ");\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int ch = coords.u;\n\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\n        int dyDCorner = dyCorner.x;\n        int dyRCorner = dyCorner.y;\n        int dyCCorner = dyCorner.z;\n\n        // Convolve dy(?, ?, ?, d) with pos mask(:, :, :, ch) to get\n        // dx(xD, xR, xC, ch).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n\n        for (int wD = 0; wD < ").concat(t, ";\n            wD += ").concat(e.dilationDepth, ") {\n          float dyD = float(dyDCorner + wD) / ").concat(e.strideDepth, ".0;\n\n          if (dyD < 0.0 || dyD >= ").concat(e.outDepth, ".0 || fract(dyD) > 0.0) {\n            continue;\n          }\n          int idyD = int(dyD);\n\n          for (int wR = 0; wR < ").concat(n, ";\n              wR += ").concat(e.dilationHeight, ") {\n            float dyR = float(dyRCorner + wR) / ").concat(e.strideHeight, ".0;\n\n            if (dyR < 0.0 || dyR >= ").concat(e.outHeight, ".0 ||\n                fract(dyR) > 0.0) {\n              continue;\n            }\n            int idyR = int(dyR);\n\n            for (int wC = 0; wC < ").concat(r, ";\n                wC += ").concat(e.dilationWidth, ") {\n              float dyC = float(dyCCorner + wC) / ").concat(e.strideWidth, ".0;\n\n              if (dyC < 0.0 || dyC >= ").concat(e.outWidth, ".0 ||\n                  fract(dyC) > 0.0) {\n                continue;\n              }\n              int idyC = int(dyC);\n\n              float dyValue = getDy(batch, idyD, idyR, idyC, ch);\n\n              dotProd += dyValue * avgMultiplier;\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    ");
  }

}

function avgPool3DGrad(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    dy: a,
    input: s
  } = t,
      o = s,
      {
    filterSize: i,
    strides: l,
    pad: u,
    dimRoundingMode: c
  } = r,
      p = computePool3DInfo(o.shape, i, l, [1, 1, 1], u, c),
      d = new AvgPool3DBackpropProgram(p);
  return n.runWebGLProgram(d, [a], o.dtype);
}

var avgPoolGrad3DConfig = {
  kernelName: AvgPool3DGrad,
  backendName: "webgl",
  kernelFunc: avgPool3DGrad
};

function avgPoolGrad(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    dy: a,
    input: s
  } = t,
      o = s;
  assertNotComplex([a, s], "avgPoolGrad");
  var {
    filterSize: i,
    strides: l,
    pad: u
  } = r,
      c = computePool2DInfo(o.shape, i, l, 1, u),
      p = new AvgPool2DBackpropProgram(c);
  return n.runWebGLProgram(p, [a], o.dtype);
}

var avgPoolGradConfig = {
  kernelName: AvgPoolGrad,
  backendName: "webgl",
  kernelFunc: avgPoolGrad
};

function batchMatMul(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    a,
    b: s
  } = t,
      {
    transposeA: o,
    transposeB: i
  } = r;
  return batchMatMulImpl({
    a,
    b: s,
    transposeA: o,
    transposeB: i,
    backend: n
  });
}

var batchMatMulConfig = {
  kernelName: BatchMatMul,
  backendName: "webgl",
  kernelFunc: batchMatMul
};

class BatchNormProgram {
  constructor(e, t, n, r, a, s) {
    this.outputShape = [], this.variableNames = ["x", "mean", "variance"], assertAndGetBroadcastShape(e, t), assertAndGetBroadcastShape(e, n);
    var o = "0.0";
    null != r && (assertAndGetBroadcastShape(e, r), this.variableNames.push("offset"), o = "getOffsetAtOutCoords()");
    var i = "1.0";
    null != a && (assertAndGetBroadcastShape(e, a), this.variableNames.push("scale"), i = "getScaleAtOutCoords()"), this.outputShape = e, this.userCode = "\n      void main() {\n        float x = getXAtOutCoords();\n        float mean = getMeanAtOutCoords();\n        float variance = getVarianceAtOutCoords();\n        float offset = ".concat(o, ";\n        float scale = ").concat(i, ";\n        float inv = scale * inversesqrt(variance + float(").concat(s, "));\n        setOutput(dot(vec3(x, -mean, offset), vec3(inv, inv, 1)));\n      }\n    ");
  }

}

class BatchNormPackedProgram {
  constructor(e, t, n, r, a, s) {
    this.packedInputs = !0, this.packedOutput = !0, this.variableNames = ["x", "mean", "variance"], assertAndGetBroadcastShape(e, t), assertAndGetBroadcastShape(e, n);
    var o = "vec4(0.0)";
    null != r && (assertAndGetBroadcastShape(e, r), this.variableNames.push("offset"), o = "getOffsetAtOutCoords()");
    var i = "vec4(1.0)";
    null != a && (assertAndGetBroadcastShape(e, a), this.variableNames.push("scale"), i = "getScaleAtOutCoords()"), this.outputShape = e, this.userCode = "\n      void main() {\n        vec4 offset = ".concat(o, ";\n        vec4 scale = ").concat(i, ";\n\n        vec4 x = getXAtOutCoords();\n        vec4 mean = getMeanAtOutCoords();\n        vec4 variance = getVarianceAtOutCoords();\n\n        vec4 inv = scale * inversesqrt(variance + vec4(").concat(s, "));\n\n        setOutput((x - mean) * inv + offset);\n      }\n    ");
  }

}

var batchNorm = _ref66 => {
  var {
    inputs: e,
    backend: t,
    attrs: n
  } = _ref66;
  var {
    x: r,
    mean: a,
    variance: s,
    offset: o,
    scale: i
  } = e;
  assert$4(a.shape.length === s.shape.length, () => "Batch normalization gradient requires mean and variance to have equal ranks."), assert$4(null == o || a.shape.length === o.shape.length, () => "Batch normalization gradient requires mean and offset to have equal ranks."), assert$4(null == i || a.shape.length === i.shape.length, () => "Batch normalization gradient requires mean and scale to have equal ranks.");
  var {
    varianceEpsilon: l
  } = n;
  null == l && (l = .001);
  var u = [r, a, s];
  var c = null;
  null != o && (c = o.shape, u.push(o));
  var p = null;
  null != i && (p = i.shape, u.push(i));
  var d = env().getBool("WEBGL_PACK_NORMALIZATION") ? new BatchNormPackedProgram(r.shape, a.shape, s.shape, c, p, l) : new BatchNormProgram(r.shape, a.shape, s.shape, c, p, l);
  return t.runWebGLProgram(d, u, u[0].dtype);
},
    batchNormConfig = {
  kernelName: FusedBatchNorm,
  backendName: "webgl",
  kernelFunc: batchNorm
};

class SliceProgram {
  constructor(e) {
    this.variableNames = ["source"], this.outputShape = e, this.rank = e.length;
    var t = getCoordsDataType(this.rank);
    this.customUniforms = [{
      name: "start",
      arrayIndex: this.rank,
      type: "int"
    }];
    var n = getCoords$1(this.rank);
    var r;
    r = "\n        ".concat(t, " sourceLoc;\n        ").concat(t, " coords = getOutputCoords();\n        ").concat(e.map((e, t) => "sourceLoc.".concat(coords[t], " = start[").concat(t, "] + coords.").concat(coords[t], ";")).join("\n"), "\n      "), this.userCode = "\n      void main() {\n        ".concat(r, "\n        setOutput(getSource(").concat(n, "));\n      }\n    ");
  }

}

var coords = ["x", "y", "z", "w", "u", "v"];

function getCoords$1(e) {
  if (1 === e) return "sourceLoc";
  if (e <= 6) return coords.slice(0, e).map(e => "sourceLoc." + e).join(",");
  throw Error("Slicing for rank ".concat(e, " is not yet supported"));
}

class SlicePackedProgram {
  constructor(e) {
    this.variableNames = ["source"], this.packedInputs = !0, this.packedOutput = !0, this.outputShape = e, this.rank = e.length, this.customUniforms = [{
      name: "start",
      arrayIndex: this.rank,
      type: "int"
    }];
    var t = getCoordsDataType(this.rank),
        n = getChannels("coords", this.rank),
        r = getChannels("sourceLoc", this.rank),
        a = 1 === this.rank ? "sourceLoc" : "vec2(".concat(r.slice(-2).join(), ")"),
        s = "getChannel(getSource(".concat(r.join(), "), ").concat(a, ")"),
        o = "\n      result.x = ".concat(s, ";\n      if (++").concat(n[this.rank - 1], " < ").concat(e[this.rank - 1], ") {\n        ++").concat(r[this.rank - 1], ";\n        result.y = ").concat(s, ";\n        --").concat(r[this.rank - 1], ";\n      }\n    "),
        i = 1 === this.rank ? "" : "\n      --".concat(n[this.rank - 1], ";\n      if (++").concat(n[this.rank - 2], " < ").concat(e[this.rank - 2], ") {\n        ++").concat(r[this.rank - 2], ";\n        result.z = ").concat(s, ";\n        if (++").concat(n[this.rank - 1], " < ").concat(e[this.rank - 1], ") {\n          ++").concat(r[this.rank - 1], ";\n          result.w = ").concat(s, ";\n        }\n      }\n    "),
        l = this.rank <= 4 ? "sourceLoc = coords +\n            ".concat(t, "(").concat(e.map((e, t) => "start[".concat(t, "]")).join(), ");") : e.map((e, t) => "".concat(r[t], " = ").concat(n[t], " + start[").concat(t, "];")).join("\n");
    this.userCode = "\n      void main() {\n        ".concat(t, " coords = getOutputCoords();\n        ").concat(t, " sourceLoc;\n        ").concat(l, "\n        vec4 result = vec4(0.);\n        ").concat(o, "\n        ").concat(i, "\n        setOutput(result);\n      }\n    ");
  }

}

function shallowSlice(e, t, n, r) {
  var a = r.texData.get(e.dataId),
      s = r.makeTensorInfo(n, e.dtype),
      o = r.texData.get(s.dataId);
  Object.assign(o, a), o.refCount = 1, o.shape = n, o.dtype = e.dtype;
  var i = computeFlatOffset(t, computeStrides(e.shape));
  a.slice && (i += a.slice.flatOffset), o.slice = {
    flatOffset: i,
    origDataId: a.slice && a.slice.origDataId || e.dataId
  };
  var l = r.dataRefCount.get(o.slice.origDataId) || 1;
  return r.dataRefCount.set(o.slice.origDataId, l + 1), s;
}

function slice(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    begin: s,
    size: o
  } = r,
      [i, l] = parseSliceParams(a, s, o);
  if (assertParamsValid(a, i, l), 0 === sizeFromShape(l)) return n.makeTensorInfo(l, a.dtype, []);

  if (n.shouldExecuteOnCPU([a]) || "string" === a.dtype) {
    var _e1027 = n.texData.get(a.dataId),
        _t703 = sliceImplCPU(_e1027.values, i, l, a.shape, a.dtype);

    return n.makeTensorInfo(l, a.dtype, _t703);
  }

  var {
    isPacked: u
  } = n.texData.get(a.dataId),
      c = isSliceContinous(a.shape, i, l);

  if (u || !c) {
    var _e1028 = env().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new SlicePackedProgram(l) : new SliceProgram(l);

    return n.runWebGLProgram(_e1028, [a], a.dtype, [i]);
  }

  return n.uploadToGPU(a.dataId), shallowSlice(a, i, l, n);
}

var sliceConfig = {
  kernelName: Slice,
  backendName: "webgl",
  kernelFunc: slice
},
    batchToSpaceND = e => {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    blockShape: s,
    crops: o
  } = r;
  assert$4(a.shape.length <= 4, () => "batchToSpaceND for rank > 4 with a WebGL backend not implemented yet");
  var i = s.reduce((e, t) => e * t),
      l = getReshaped(a.shape, s, i),
      u = getPermuted(l.length, s.length),
      c = getReshapedPermuted(a.shape, s, i),
      p = getSliceBeginCoords(o, s.length),
      d = getSliceSize(c, o, s.length),
      h = [],
      m = reshape({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      shape: l
    }
  }),
      f = transpose({
    inputs: {
      x: m
    },
    backend: n,
    attrs: {
      perm: u
    }
  }),
      g = reshape({
    inputs: {
      x: f
    },
    backend: n,
    attrs: {
      shape: c
    }
  }),
      $ = slice({
    inputs: {
      x: g
    },
    backend: n,
    attrs: {
      begin: p,
      size: d
    }
  });
  return h.push(m), h.push(f), h.push(g), h.forEach(e => n.disposeIntermediateTensorInfo(e)), $;
},
    batchToSpaceNDConfig = {
  kernelName: BatchToSpaceND,
  backendName: "webgl",
  kernelFunc: batchToSpaceND
};

function bincount(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    weights: s
  } = t,
      {
    size: o
  } = r,
      i = n.readSync(a.dataId),
      l = n.readSync(s.dataId),
      u = bincountImplCPU(i, l, s.dtype, s.shape, o);
  return n.makeTensorInfo([o], s.dtype, u);
}

var bincountConfig = {
  kernelName: Bincount,
  backendName: "webgl",
  kernelFunc: bincount
},
    NOT_EQUAL = "return float(a != b);",
    notEqual = binaryKernelFunc({
  opSnippet: NOT_EQUAL,
  cpuKernelImpl: notEqualImplCPU,
  dtype: "bool"
}),
    notEqualConfig = {
  kernelName: NotEqual,
  backendName: "webgl",
  kernelFunc: notEqual
};

function real(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    input: r
  } = t;
  return identity({
    inputs: {
      x: n.texData.get(r.dataId).complexTensorInfos.real
    },
    backend: n
  });
}

var realConfig = {
  kernelName: Real,
  backendName: "webgl",
  kernelFunc: real
},
    TO_INT = "return float(int(x));";

function int(e, t) {
  var n = new UnaryOpProgram(e.shape, TO_INT),
      r = t.runWebGLProgram(n, [e], "int32");
  return {
    dataId: r.dataId,
    shape: r.shape,
    dtype: r.dtype
  };
}

function cast(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    dtype: s
  } = r;

  if ("complex64" === s) {
    if ("complex64" === a.dtype) return identity({
      inputs: {
        x: a
      },
      backend: n
    });

    var _e1029 = zeros$2(a.shape),
        _t704 = cast({
      inputs: {
        x: a
      },
      backend: n,
      attrs: {
        dtype: "float32"
      }
    }),
        _r416 = complex({
      inputs: {
        real: _t704,
        imag: _e1029
      },
      backend: n
    });

    return _e1029.dispose(), n.disposeIntermediateTensorInfo(_t704), _r416;
  }

  if ("complex64" === a.dtype) {
    var _e1030 = real({
      inputs: {
        input: a
      },
      backend: n
    }),
        _t705 = cast({
      inputs: {
        x: _e1030
      },
      backend: n,
      attrs: {
        dtype: s
      }
    });

    return n.disposeIntermediateTensorInfo(_e1030), _t705;
  }

  if (!hasEncodingLoss(a.dtype, s)) {
    var _e1031 = identity({
      inputs: {
        x: a
      },
      backend: n
    });

    return {
      dataId: _e1031.dataId,
      shape: _e1031.shape,
      dtype: s
    };
  }

  if ("int32" === s) return int(a, n);

  if ("bool" === s) {
    var _e1032 = n.makeTensorInfo([], "bool", getTypedArrayFromDType("bool", 1)),
        _t706 = notEqual({
      inputs: {
        a,
        b: _e1032
      },
      backend: n
    });

    return n.disposeIntermediateTensorInfo(_e1032), _t706;
  }

  throw new Error("Error in Cast: failed to cast ".concat(a.dtype, " to ").concat(s));
}

var castConfig = {
  kernelName: Cast,
  backendName: "webgl",
  kernelFunc: cast
},
    CEIL = "return ceil(x);",
    ceil = unaryKernelFunc({
  opSnippet: CEIL,
  packedOpSnippet: CEIL,
  cpuKernelImpl: ceilImplCPU
}),
    ceilConfig = {
  kernelName: Ceil,
  backendName: "webgl",
  kernelFunc: ceil
};

class ClipProgram {
  constructor(e) {
    this.variableNames = ["A"], this.customUniforms = [{
      name: "minVal",
      type: "float"
    }, {
      name: "maxVal",
      type: "float"
    }], this.outputShape = e, this.userCode = "\n\n      void main() {\n        float value = getAAtOutCoords();\n        if (isnan(value)) {\n          setOutput(value);\n          return;\n        }\n\n        setOutput(clamp(value, minVal, maxVal));\n      }\n    ";
  }

}

class ClipPackedProgram {
  constructor(e) {
    this.variableNames = ["A"], this.packedInputs = !0, this.packedOutput = !0, this.customUniforms = [{
      name: "minVal",
      type: "float"
    }, {
      name: "maxVal",
      type: "float"
    }], this.outputShape = e, this.userCode = "\n      void main() {\n        vec4 value = getAAtOutCoords();\n\n        if (any(isnan(value))) {\n          setOutput(value);\n          return;\n        }\n\n        setOutput(clamp(value, vec4(minVal), vec4(maxVal)));\n      }\n    ";
  }

}

function clipByValue(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    clipValueMin: s,
    clipValueMax: o
  } = r;
  var i;
  return i = env().getBool("WEBGL_PACK_CLIP") ? new ClipPackedProgram(a.shape) : new ClipProgram(a.shape), n.runWebGLProgram(i, [a], a.dtype, [[s], [o]]);
}

var clipByValueConfig = {
  kernelName: ClipByValue,
  backendName: "webgl",
  kernelFunc: clipByValue
};

class ComplexAbsProgram {
  constructor(e) {
    this.variableNames = ["real", "imag"], this.outputShape = e, this.userCode = "\n      void main() {\n        float re = abs(getRealAtOutCoords());\n        float im = abs(getImagAtOutCoords());\n        float mx = max(re, im);\n\n        // sadly the length function in glsl is not underflow-safe\n        // (at least not on Intel GPUs). So the safe solution is\n        // to ensure underflow-safety in all cases.\n        setOutput(\n          mx == 0.0 ? 0.0 : mx * length(vec2(1, min(re, im)/mx))\n        );\n      }\n    ";
  }

}

function makeComplexComponentTensorInfo(e, t) {
  return {
    dataId: t.dataId,
    dtype: t.dtype,
    shape: e.shape
  };
}

function complexAbs(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    x: r
  } = t,
      a = n.texData.get(r.dataId),
      s = new ComplexAbsProgram(r.shape),
      o = [makeComplexComponentTensorInfo(r, a.complexTensorInfos.real), makeComplexComponentTensorInfo(r, a.complexTensorInfos.imag)];
  return n.runWebGLProgram(s, o, o[0].dtype);
}

var complexAbsConfig = {
  kernelName: ComplexAbs,
  backendName: "webgl",
  kernelFunc: complexAbs
};

class ConcatProgram {
  constructor(e) {
    this.outputShape = [], this.outputShape = computeOutShape$1(e, 1), this.variableNames = e.map((e, t) => "T".concat(t));
    var t = new Array(e.length - 1);
    t[0] = e[0][1];

    for (var _n433 = 1; _n433 < t.length; _n433++) {
      t[_n433] = t[_n433 - 1] + e[_n433][1];
    }

    var n = ["if (yC < ".concat(t[0], ") setOutput(getT0(yR, yC));")];

    for (var _e1033 = 1; _e1033 < t.length; _e1033++) {
      n.push("else if (yC < ".concat(t[_e1033], ") setOutput(getT").concat(_e1033, "(yR, yC-").concat(t[_e1033 - 1], "));"));
    }

    n.push("else setOutput(getT".concat(t.length, "(yR, yC-").concat(t[t.length - 1], "));")), this.userCode = "\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int yR = coords.x;\n        int yC = coords.y;\n\n        ".concat(n.join("\n        "), "\n      }\n    ");
  }

}

class ConcatPackedProgram {
  constructor(e, t) {
    this.packedInputs = !0, this.packedOutput = !0, this.outputShape = [], this.outputShape = computeOutShape$1(e, t);
    var n = this.outputShape,
        r = n.length,
        a = getCoordsDataType(r),
        s = getChannels("coords", r),
        o = ["x", "y", "z", "w", "u", "v"].slice(0, r);
    this.variableNames = e.map((e, t) => "T".concat(t));
    var i = new Array(e.length - 1);
    i[0] = e[0][t];

    for (var _n434 = 1; _n434 < i.length; _n434++) {
      i[_n434] = i[_n434 - 1] + e[_n434][t];
    }

    var l = o[t],
        u = o.slice(-2),
        c = o.join();
    var p = "if (".concat(l, " < ").concat(i[0], ") {\n        return getChannel(\n            getT0(").concat(c, "), vec2(").concat(u.join(), "));\n        }");

    for (var _e1034 = 1; _e1034 < i.length; _e1034++) {
      var _t707 = i[_e1034 - 1];
      p += "\n        if (".concat(l, " < ").concat(i[_e1034], "  && ").concat(l, " >= ").concat(i[_e1034 - 1], ") {\n          return getChannel(\n            getT").concat(_e1034, "(").concat(shiftedChannels(o, l, _t707), "),\n            vec2(").concat(shiftedChannels(u, l, _t707), "));\n        }");
    }

    var d = i[i.length - 1];
    p += "\n        return getChannel(\n          getT".concat(i.length, "(").concat(shiftedChannels(o, l, d), "),\n          vec2(").concat(shiftedChannels(u, l, d), "));"), this.userCode = "\n      float getValue(".concat(o.map(e => "int " + e), ") {\n        ").concat(p, "\n      }\n\n      void main() {\n        ").concat(a, " coords = getOutputCoords();\n        vec4 result = vec4(getValue(").concat(s, "), 0., 0., 0.);\n\n        ").concat(s[r - 1], " = ").concat(s[r - 1], " + 1;\n        if (").concat(s[r - 1], " < ").concat(n[r - 1], ") {\n          result.g = getValue(").concat(s, ");\n        }\n\n        ").concat(s[r - 2], " = ").concat(s[r - 2], " + 1;\n        if (").concat(s[r - 2], " < ").concat(n[r - 2], ") {\n          result.a = getValue(").concat(s, ");\n        }\n\n        ").concat(s[r - 1], " = ").concat(s[r - 1], " - 1;\n        if (").concat(s[r - 2], " < ").concat(n[r - 2], " &&\n            ").concat(s[r - 1], " < ").concat(n[r - 1], ") {\n          result.b = getValue(").concat(s, ");\n        }\n        setOutput(result);\n      }\n    ");
  }

}

function shiftedChannels(e, t, n) {
  var r = e.indexOf(t);
  return e.map((e, t) => t === r ? "".concat(e, " - ").concat(n) : e).join();
}

function imag(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    input: r
  } = t;
  return identity({
    inputs: {
      x: n.texData.get(r.dataId).complexTensorInfos.imag
    },
    backend: n
  });
}

var imagConfig = {
  kernelName: Imag,
  backendName: "webgl",
  kernelFunc: imag
};

function concatImpl(e, t, n) {
  var r = e[0].dtype;

  if ("complex64" === r) {
    var _r417 = e.map(e => real({
      inputs: {
        input: e
      },
      backend: n
    })),
        _a301 = e.map(e => imag({
      inputs: {
        input: e
      },
      backend: n
    })),
        _s216 = concatImpl(_r417, t, n),
        _o151 = concatImpl(_a301, t, n),
        _i85 = complex({
      inputs: {
        real: _s216,
        imag: _o151
      },
      backend: n
    });

    return _r417.forEach(e => n.disposeIntermediateTensorInfo(e)), _a301.forEach(e => n.disposeIntermediateTensorInfo(e)), n.disposeIntermediateTensorInfo(_s216), n.disposeIntermediateTensorInfo(_o151), _i85;
  }

  var a = n.shouldExecuteOnCPU(e);

  if ("string" === r && (a = !0), a) {
    var _a302 = e.map(e => {
      var r = sizeFromShape(e.shape.slice(t));
      return reshape({
        inputs: {
          x: e
        },
        backend: n,
        attrs: {
          shape: [-1, r]
        }
      });
    }),
        _s217 = _a302.map(e => ({
      vals: n.readSync(e.dataId),
      shape: e.shape
    })),
        _o152 = computeOutShape$1(_a302.map(e => e.shape), 1),
        _i86 = concatImplCPU(_s217, _o152, r, 1 === _a302[0].shape[0]),
        _l67 = computeOutShape$1(e.map(e => e.shape), t),
        _u59 = n.makeTensorInfo(_l67, r, _i86);

    return _a302.forEach(e => n.disposeIntermediateTensorInfo(e)), _u59;
  }

  if (e.length > env().getNumber("WEBGL_MAX_TEXTURES_IN_SHADER")) {
    var _r418 = Math.floor(e.length / 2),
        _a303 = concatImpl(e.slice(0, _r418), t, n),
        _s218 = concatImpl(e.slice(_r418), t, n),
        _o153 = concatImpl([_a303, _s218], t, n);

    return n.disposeIntermediateTensorInfo(_a303), n.disposeIntermediateTensorInfo(_s218), _o153;
  }

  if (env().getBool("WEBGL_PACK_ARRAY_OPERATIONS") && e[0].shape.length > 1) {
    var _a304 = new ConcatPackedProgram(e.map(e => e.shape), t);

    return n.runWebGLProgram(_a304, e, r);
  }

  var {
    tensors2D: s,
    outShape: o
  } = computeTensors2D(e, t, n),
      i = new ConcatProgram(s.map(e => e.shape)),
      l = n.runWebGLProgram(i, s, r);
  s.forEach(e => n.disposeIntermediateTensorInfo(e));
  var u = reshape({
    inputs: {
      x: l
    },
    attrs: {
      shape: o
    },
    backend: n
  });
  return n.disposeIntermediateTensorInfo(l), u;
}

function computeTensors2D(e, t, n) {
  var r = computeOutShape$1(e.map(e => e.shape), t);
  return {
    tensors2D: e.map(e => reshape({
      inputs: {
        x: e
      },
      attrs: {
        shape: [-1, sizeFromShape(e.shape.slice(t))]
      },
      backend: n
    })),
    outShape: r
  };
}

function concat(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    axis: a
  } = r,
      s = parseAxisParam(a, t[0].shape)[0],
      o = computeOutShape$1(t.map(e => e.shape), s);
  if (0 === sizeFromShape(o)) return n.makeTensorInfo(o, t[0].dtype, []);
  var i = t.filter(e => sizeFromShape(e.shape) > 0);
  return 1 === i.length ? identity({
    inputs: {
      x: i[0]
    },
    backend: n
  }) : (assertParamsConsistent(i.map(e => e.shape), s), concatImpl(i, s, n));
}

var concatConfig = {
  kernelName: Concat,
  backendName: "webgl",
  kernelFunc: concat
};

class Conv2DProgram {
  constructor(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
    var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;
    this.variableNames = ["x", "W"], this.outputShape = e.outShape;
    var s = e.padInfo.top,
        o = e.padInfo.left,
        i = e.strideHeight,
        l = e.strideWidth,
        u = e.dilationHeight,
        c = e.dilationWidth,
        p = e.filterHeight,
        d = e.filterWidth,
        h = 4 * Math.floor(e.inChannels / 4),
        m = e.inChannels % 4,
        f = "channelsLast" === e.dataFormat,
        g = f ? 1 : 2,
        $ = f ? 2 : 3,
        y = f ? 3 : 1;
    var b = "",
        x = "";
    n && (b = r ? "float activation(float a) {\n          float b = getPreluActivationWeightsAtOutCoords();\n          ".concat(n, "\n        }") : a ? "float activation(float a) {\n          float b = getLeakyreluAlphaAtOutCoords();\n          ".concat(n, "\n        }") : "\n          float activation(float x) {\n            ".concat(n, "\n          }\n        "), x = "result = activation(result);");
    var v = t ? "result += getBiasAtOutCoords();" : "";
    t && this.variableNames.push("bias"), r && this.variableNames.push("preluActivationWeights"), a && this.variableNames.push("leakyreluAlpha"), this.userCode = "\n      ".concat(b, "\n\n      const ivec2 strides = ivec2(").concat(i, ", ").concat(l, ");\n      const ivec2 pads = ivec2(").concat(s, ", ").concat(o, ");\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d2 = coords[").concat(y, "];\n\n        ivec2 xRCCorner =\n            ivec2(coords[").concat(g, "], coords[").concat($, "]) * strides - pads;\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        // Convolve x(?, ?, d1) with w(:, :, d1, d2) to get y(yR, yC, d2).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ").concat(p, "; wR++) {\n          int xR = xRCorner + wR * ").concat(u, ";\n\n          if (xR < 0 || xR >= ").concat(e.inHeight, ") {\n            continue;\n          }\n\n          for (int wC = 0; wC < ").concat(d, "; wC++) {\n            int xC = xCCorner + wC * ").concat(c, ";\n\n            if (xC < 0 || xC >= ").concat(e.inWidth, ") {\n              continue;\n            }\n\n            for (int d1 = 0; d1 < ").concat(h, "; d1 += 4) {\n              vec4 wValues = vec4(\n                getW(wR, wC, d1, d2),\n                getW(wR, wC, d1 + 1, d2),\n                getW(wR, wC, d1 + 2, d2),\n                getW(wR, wC, d1 + 3, d2)\n              );\n\n              if (").concat(f, ") {\n                vec4 xValues = vec4(\n                  getX(batch, xR, xC, d1),\n                  getX(batch, xR, xC, d1 + 1),\n                  getX(batch, xR, xC, d1 + 2),\n                  getX(batch, xR, xC, d1 + 3)\n                );\n                dotProd += dot(xValues, wValues);\n              } else {\n                vec4 xValues = vec4(\n                  getX(batch, d1, xR, xC),\n                  getX(batch, d1 + 1, xR, xC),\n                  getX(batch, d1 + 2, xR, xC),\n                  getX(batch, d1 + 3, xR, xC)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n            }\n\n            if (").concat(1 === m, ") {\n\n              if (").concat(f, ") {\n                dotProd +=\n                    getX(batch, xR, xC, ").concat(h, ") *\n                    getW(wR, wC, ").concat(h, ", d2);\n              } else {\n                dotProd +=\n                    getX(batch, ").concat(h, ", xR, xC) *\n                    getW(wR, wC, ").concat(h, ", d2);\n              }\n\n            } else if (").concat(2 === m, ") {\n              vec2 wValues = vec2(\n                getW(wR, wC, ").concat(h, ", d2),\n                getW(wR, wC, ").concat(h, " + 1, d2)\n              );\n\n              if (").concat(f, ") {\n                vec2 xValues = vec2(\n                  getX(batch, xR, xC, ").concat(h, "),\n                  getX(batch, xR, xC, ").concat(h, " + 1)\n                );\n                dotProd += dot(xValues, wValues);\n              } else {\n                vec2 xValues = vec2(\n                  getX(batch, ").concat(h, ", xR, xC),\n                  getX(batch, ").concat(h, " + 1, xR, xC)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n\n            } else if (").concat(3 === m, ") {\n              vec3 wValues = vec3(\n                getW(wR, wC, ").concat(h, ", d2),\n                getW(wR, wC, ").concat(h, " + 1, d2),\n                getW(wR, wC, ").concat(h, " + 2, d2)\n              );\n\n              if (").concat(f, ") {\n                vec3 xValues = vec3(\n                  getX(batch, xR, xC, ").concat(h, "),\n                  getX(batch, xR, xC, ").concat(h, " + 1),\n                  getX(batch, xR, xC, ").concat(h, " + 2)\n                );\n                dotProd += dot(xValues, wValues);\n              } else {\n                vec3 xValues = vec3(\n                  getX(batch, ").concat(h, ", xR, xC),\n                  getX(batch, ").concat(h, " + 1, xR, xC),\n                  getX(batch, ").concat(h, " + 2, xR, xC)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n\n            }\n          }\n        }\n\n        float result = dotProd;\n        ").concat(v, "\n        ").concat(x, "\n        setOutput(result);\n      }\n    ");
  }

}

class Conv3DProgram {
  constructor(e) {
    this.variableNames = ["x", "W"], this.outputShape = e.outShape;
    var t = e.padInfo.front,
        n = e.padInfo.top,
        r = e.padInfo.left,
        a = e.strideDepth,
        s = e.strideHeight,
        o = e.strideWidth,
        i = e.dilationDepth,
        l = e.dilationHeight,
        u = e.dilationWidth,
        c = e.filterDepth,
        p = e.filterHeight,
        d = e.filterWidth,
        h = 4 * Math.floor(e.inChannels / 4),
        m = e.inChannels % 4;
    this.userCode = "\n      const ivec3 strides = ivec3(".concat(a, ", ").concat(s, ", ").concat(o, ");\n      const ivec3 pads = ivec3(").concat(t, ", ").concat(n, ", ").concat(r, ");\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int d2 = coords.u;\n\n        ivec3 xFRCCorner = ivec3(coords.y, coords.z, coords.w) * strides - pads;\n        int xFCorner = xFRCCorner.x;\n        int xRCorner = xFRCCorner.y;\n        int xCCorner = xFRCCorner.z;\n\n        // Convolve x(?, ?, ?, d1) with w(:, :, :, d1, d2) to get\n        // y(yF, yR, yC, d2). ? = to be determined. : = across all\n        // values in that axis.\n        float dotProd = 0.0;\n        for (int wF = 0; wF < ").concat(c, "; wF++) {\n          int xF = xFCorner + wF * ").concat(i, ";\n\n          if (xF < 0 || xF >= ").concat(e.inDepth, ") {\n            continue;\n          }\n\n          for (int wR = 0; wR < ").concat(p, "; wR++) {\n            int xR = xRCorner + wR * ").concat(l, ";\n\n            if (xR < 0 || xR >= ").concat(e.inHeight, ") {\n              continue;\n            }\n\n            for (int wC = 0; wC < ").concat(d, "; wC++) {\n              int xC = xCCorner + wC * ").concat(u, ";\n\n              if (xC < 0 || xC >= ").concat(e.inWidth, ") {\n                continue;\n              }\n\n              for (int d1 = 0; d1 < ").concat(h, "; d1 += 4) {\n                vec4 xValues = vec4(\n                  getX(batch, xF, xR, xC, d1),\n                  getX(batch, xF, xR, xC, d1 + 1),\n                  getX(batch, xF, xR, xC, d1 + 2),\n                  getX(batch, xF, xR, xC, d1 + 3)\n                );\n                vec4 wValues = vec4(\n                  getW(wF, wR, wC, d1, d2),\n                  getW(wF, wR, wC, d1 + 1, d2),\n                  getW(wF, wR, wC, d1 + 2, d2),\n                  getW(wF, wR, wC, d1 + 3, d2)\n                );\n\n                dotProd += dot(xValues, wValues);\n              }\n\n              if (").concat(1 === m, ") {\n                dotProd +=\n                  getX(batch, xF, xR, xC, ").concat(h, ") *\n                  getW(wF, wR, wC, ").concat(h, ", d2);\n              } else if (").concat(2 === m, ") {\n                vec2 xValues = vec2(\n                  getX(batch, xF, xR, xC, ").concat(h, "),\n                  getX(batch, xF, xR, xC, ").concat(h, " + 1)\n                );\n                vec2 wValues = vec2(\n                  getW(wF, wR, wC, ").concat(h, ", d2),\n                  getW(wF, wR, wC, ").concat(h, " + 1, d2)\n                );\n                dotProd += dot(xValues, wValues);\n              } else if (").concat(3 === m, ") {\n                vec3 xValues = vec3(\n                  getX(batch, xF, xR, xC, ").concat(h, "),\n                  getX(batch, xF, xR, xC, ").concat(h, " + 1),\n                  getX(batch, xF, xR, xC, ").concat(h, " + 2)\n                );\n                vec3 wValues = vec3(\n                  getW(wF, wR, wC, ").concat(h, ", d2),\n                  getW(wF, wR, wC, ").concat(h, " + 1, d2),\n                  getW(wF, wR, wC, ").concat(h, " + 2, d2)\n                );\n                dotProd += dot(xValues, wValues);\n              }\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    ");
  }

}

class Im2ColPackedProgram {
  constructor(e, t, n) {
    this.variableNames = ["A"], this.packedInputs = !0, this.packedOutput = !0, this.outputShape = e;
    var {
      filterWidth: r,
      inChannels: a,
      strideWidth: s,
      strideHeight: o,
      padInfo: i,
      outWidth: l,
      dilationWidth: u,
      dilationHeight: c,
      dataFormat: p
    } = n,
        {
      left: d,
      top: h
    } = i,
        m = a * r,
        f = getGlslDifferences(),
        g = "channelsLast" === p,
        $ = g ? 0 : 1,
        y = g ? 1 : 2;
    var b = "";

    for (var _n435 = 0; _n435 <= 1; _n435++) {
      for (var _r419 = 0; _r419 <= 1; _r419++) {
        b += "\n          blockIndex = rc.y + ".concat(_r419, ";\n          pos = rc.x + ").concat(_n435, ";\n\n          if(blockIndex < ").concat(e[1], " && pos < ").concat(e[0], ") {\n            offsetY = int(blockIndex / (").concat(l, ")) * ").concat(o, " - ").concat(h, ";\n            d0 = offsetY + ").concat(c, " * (pos / ").concat(m, ");\n\n            if(d0 < ").concat(t[$], " && d0 >= 0) {\n\n              offsetX = int(mod(float(blockIndex), ").concat(l, ".) * ").concat(s, ". - ").concat(d, ".);\n              d1 = offsetX + ").concat(u, " * (int(mod(float(pos), ").concat(m, ".) / ").concat(a, ".));\n\n              if(d1 < ").concat(t[y], " && d1 >= 0) {\n\n                ch = int(mod(float(pos), ").concat(a, ".));\n\n                if (").concat(g, ") {\n                  innerDims = vec2(d1, ch);\n                  result[").concat(2 * _n435 + _r419, "] = getChannel(\n                    getA(d0, int(innerDims.x),\n                    int(innerDims.y)), innerDims);\n                } else {\n                  innerDims = vec2(d0, d1);\n                  result[").concat(2 * _n435 + _r419, "] = getChannel(\n                    getA(ch, int(innerDims.x),\n                    int(innerDims.y)), innerDims);\n                }\n              }\n            }\n          }\n        ");
      }
    }

    this.userCode = "\n      void main() {\n        ivec2 rc = getOutputCoords();\n\n        vec4 result = vec4(0);\n\n        int blockIndex, pos, offsetY, d0, offsetX, d1, ch;\n        vec2 innerDims;\n\n        ".concat(b, "\n\n        ").concat(f.output, " = result;\n      }\n    ");
  }

}

function conv2dByMatMul(_ref67) {
  var {
    x: e,
    filter: t,
    convInfo: n,
    backend: r,
    bias: a = null,
    preluActivationWeights: s = null,
    leakyreluAlpha: o = 0,
    activation: i = null
  } = _ref67;
  var l = e.shape,
      u = r.texData.get(e.dataId),
      c = "channelsLast" === n.dataFormat;
  var p;
  var d = [],
      h = l[2] % 2 != 0 && !!u.isPacked;

  if ((1 != l[0] * l[1] * l[2] && 1 !== n.outChannels || !(n.inChannels > MATMUL_SHARED_DIM_THRESHOLD)) && env().getBool("WEBGL_LAZILY_UNPACK") && env().getBool("WEBGL_PACK_BINARY_OPERATIONS") && h) {
    var _h23 = {
      dataId: e.dataId,
      shape: [1, c ? l[0] * l[1] * (l[2] + 1) : l[0] * l[2] * (l[3] + 1), n.inChannels],
      dtype: e.dtype
    },
        m = u.shape;
    u.shape = u.shape.slice(), u.shape[u.shape.length - 2]++, assert$4(isReshapeFree(u.shape, _h23.shape), () => "packed reshape ".concat(u.shape, " to ").concat(_h23.shape, " isn't free"));
    var f = reshape({
      inputs: {
        x: t
      },
      backend: r,
      attrs: {
        shape: [1, n.inChannels, n.outChannels]
      }
    });
    d.push(f);
    var g = batchMatMulImpl({
      a: _h23,
      b: f,
      backend: r,
      transposeA: !1,
      transposeB: !1,
      bias: a,
      activation: i,
      preluActivationWeights: s,
      leakyreluAlpha: o
    }),
        $ = r.texData.get(g.dataId);
    assert$4($.isPacked, () => "batchMatMul result is expected to be packed"), u.shape = m, $.shape = n.outShape, p = identity({
      inputs: {
        x: g
      },
      backend: r
    }), p.shape = n.outShape, d.push(g);
  } else {
    var _u60 = reshape({
      inputs: {
        x: e
      },
      backend: r,
      attrs: {
        shape: [1, c ? l[0] * l[1] * l[2] : l[0] * l[2] * l[3], n.inChannels]
      }
    }),
        _h24 = reshape({
      inputs: {
        x: t
      },
      backend: r,
      attrs: {
        shape: [1, n.inChannels, n.outChannels]
      }
    }),
        _m10 = batchMatMulImpl({
      a: _u60,
      b: _h24,
      transposeA: !1,
      transposeB: !1,
      backend: r,
      bias: a,
      activation: i,
      preluActivationWeights: s,
      leakyreluAlpha: o
    });

    p = reshape({
      inputs: {
        x: _m10
      },
      backend: r,
      attrs: {
        shape: n.outShape
      }
    }), d.push(_u60), d.push(_h24), d.push(_m10);
  }

  for (var _e1035 of d) {
    r.disposeIntermediateTensorInfo(_e1035);
  }

  return p;
}

function conv2dWithIm2Row(_ref68) {
  var {
    x: e,
    filter: t,
    convInfo: n,
    backend: r,
    bias: a = null,
    preluActivationWeights: s = null,
    leakyreluAlpha: o = 0,
    activation: i = null
  } = _ref68;
  var {
    filterWidth: l,
    filterHeight: u,
    inChannels: c,
    outWidth: p,
    outHeight: d,
    dataFormat: h
  } = n,
      m = "channelsLast" === h,
      f = l * u * c,
      g = d * p,
      $ = [f, g],
      y = [],
      b = reshape({
    inputs: {
      x: e
    },
    backend: r,
    attrs: {
      shape: e.shape.slice(1)
    }
  }),
      x = reshape({
    inputs: {
      x: t
    },
    backend: r,
    attrs: {
      shape: [1, f, sizeFromShape(t.shape) / f]
    }
  });
  y.push(b), y.push(x);
  var v = new Im2ColPackedProgram($, b.shape, n),
      I = r.runWebGLProgram(v, [b], "float32"),
      C = reshape({
    inputs: {
      x: I
    },
    backend: r,
    attrs: {
      shape: [1, $[0], $[1]]
    }
  });
  y.push(I), y.push(C);
  var S = null != a,
      k = null != s,
      T = "leakyrelu" === i,
      N = i ? mapActivationToShaderProgram(i, !0) : null,
      w = new MatMulPackedProgram(C.shape, x.shape, [1, g, n.outChannels], !0, !1, S, N, k, T),
      E = [C, x];

  if (a && E.push(a), k && E.push(s), T) {
    var _e1036 = r.makeTensorInfo([], "float32", createScalarValue(o, "float32"));

    E.push(_e1036), y.push(_e1036);
  }

  var A = r.runWebGLProgram(w, E, "float32"),
      D = reshape({
    inputs: {
      x: A
    },
    backend: r,
    attrs: {
      shape: m ? [1, d, p, n.outChannels] : [1, n.outChannels, d, p]
    }
  });
  y.push(A);

  for (var _e1037 of y) {
    r.disposeIntermediateTensorInfo(_e1037);
  }

  return D;
}

function conv2d(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    filter: s
  } = t,
      {
    strides: o,
    pad: i,
    dataFormat: l,
    dilations: u,
    dimRoundingMode: c
  } = r,
      p = convertConv2DDataFormat(l),
      d = computeConv2DInfo(a.shape, s.shape, o, u, i, c, !1, p);
  var h;
  if (1 !== d.filterHeight || 1 !== d.filterWidth || 1 !== d.dilationHeight || 1 !== d.dilationWidth || 1 !== d.strideHeight || 1 !== d.strideWidth || "SAME" !== d.padInfo.type && "VALID" !== d.padInfo.type) {
    if (env().getBool("WEBGL_CONV_IM2COL") && 1 === a.shape[0]) h = conv2dWithIm2Row({
      x: a,
      filter: s,
      convInfo: d,
      backend: n
    });else {
      var _e1038 = new Conv2DProgram(d);

      h = n.runWebGLProgram(_e1038, [a, s], "float32");
    }
  } else h = conv2dByMatMul({
    x: a,
    filter: s,
    convInfo: d,
    backend: n
  });
  var m = reshape({
    inputs: {
      x: h
    },
    backend: n,
    attrs: {
      shape: d.outShape
    }
  });
  return n.disposeIntermediateTensorInfo(h), m;
}

var conv2DConfig = {
  kernelName: Conv2D$1,
  backendName: "webgl",
  kernelFunc: conv2d
};

class Conv2DDerFilterProgram {
  constructor(e) {
    this.variableNames = ["x", "dy"], this.outputShape = e.filterShape, this.userCode = "\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int wR = coords.x;\n        int wC = coords.y;\n        int d1 = coords.z;\n        int d2 = coords.w;\n\n        // Convolve x(?, ?, d1) with dy(:, :, d2) to get dw(wR, wC, d1, d2).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n\n        for (int b = 0; b < ".concat(e.batchSize, "; b++) {\n          for (int yR = 0; yR < ").concat(e.outHeight, "; yR++) {\n            int xR = wR + yR * ").concat(e.strideHeight, " - ").concat(e.padInfo.top, ";\n\n            if (xR < 0 || xR >= ").concat(e.inHeight, ") {\n              continue;\n            }\n\n            for (int yC = 0; yC < ").concat(e.outWidth, "; yC++) {\n              int xC = wC + yC * ").concat(e.strideWidth, " - ").concat(e.padInfo.left, ";\n\n              if (xC < 0 || xC >= ").concat(e.inWidth, ") {\n                continue;\n              }\n\n              if (").concat("channelsLast" === e.dataFormat, ") {\n                float dyValue = getDy(b, yR, yC, d2);\n                float xValue = getX(b, xR, xC, d1);\n                dotProd += (xValue * dyValue);\n              } else {\n                float dyValue = getDy(b, d2, yR, yC);\n                float xValue = getX(b, d1, xR, xC);\n                dotProd += (xValue * dyValue);\n              }\n\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    ");
  }

}

class Conv2DDerInputProgram {
  constructor(e) {
    this.variableNames = ["dy", "W"], this.outputShape = e.inShape;
    var t = e.filterHeight,
        n = e.filterWidth,
        r = "channelsLast" === e.dataFormat;
    this.userCode = "\n      const ivec2 pads = ivec2(".concat(t - 1 - e.padInfo.top, ", ").concat(n - 1 - e.padInfo.left, ");\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d1 = coords[").concat(r ? 3 : 1, "];\n\n        ivec2 dyCorner = ivec2(coords[").concat(r ? 1 : 2, "], coords[").concat(r ? 2 : 3, "]) - pads;\n        int dyRCorner = dyCorner.x;\n        int dyCCorner = dyCorner.y;\n\n        // Convolve dy(?, ?, d2) with w(:, :, d1, d2) to compute dx(xR, xC, d1).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ").concat(t, "; wR++) {\n          float dyR = float(dyRCorner + wR) / ").concat(e.strideHeight, ".0;\n\n          if (dyR < 0.0 || dyR >= ").concat(e.outHeight, ".0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          int wRPerm = ").concat(t, " - 1 - wR;\n\n          for (int wC = 0; wC < ").concat(n, "; wC++) {\n            float dyC = float(dyCCorner + wC) / ").concat(e.strideWidth, ".0;\n\n            if (dyC < 0.0 || dyC >= ").concat(e.outWidth, ".0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            int wCPerm = ").concat(n, " - 1 - wC;\n\n            for (int d2 = 0; d2 < ").concat(e.outChannels, "; d2++) {\n\n              if (").concat(r, ") {\n                float xValue = getDy(batch, idyR, idyC, d2);\n                float wValue = getW(wRPerm, wCPerm, d1, d2);\n                dotProd += xValue * wValue;\n              } else {\n                float xValue = getDy(batch, d2, idyR, idyC);\n                float wValue = getW(wRPerm, wCPerm, d1, d2);\n                dotProd += xValue * wValue;\n              }\n\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    ");
  }

}

class Conv3DDerFilterProgram {
  constructor(e) {
    this.variableNames = ["x", "dy"], this.outputShape = e.filterShape, this.userCode = "\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int wF = coords.x;\n        int wR = coords.y;\n        int wC = coords.z;\n        int d1 = coords.w;\n        int d2 = coords.u;\n\n        float dotProd = 0.0;\n\n        for (int b = 0; b < ".concat(e.batchSize, "; b++) {\n          for (int yF = 0; yF < ").concat(e.outDepth, "; yF++) {\n            int xF = wF + yF * ").concat(e.strideDepth, " - ").concat(e.padInfo.front, ";\n\n            if (xF < 0 || xF >= ").concat(e.inDepth, ") {\n              continue;\n            }\n\n            for (int yR = 0; yR < ").concat(e.outHeight, "; yR++) {\n              int xR = wR + yR * ").concat(e.strideHeight, " - ").concat(e.padInfo.top, ";\n\n              if (xR < 0 || xR >= ").concat(e.inHeight, ") {\n                continue;\n              }\n\n              for (int yC = 0; yC < ").concat(e.outWidth, "; yC++) {\n                int xC = wC + yC * ").concat(e.strideWidth, " - ").concat(e.padInfo.left, ";\n\n                if (xC < 0 || xC >= ").concat(e.inWidth, ") {\n                  continue;\n                }\n\n                float dyValue = getDy(b, yF, yR, yC, d2);\n                float xValue = getX(b, xF, xR, xC, d1);\n                dotProd += (xValue * dyValue);\n              }\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    ");
  }

}

class Conv3DDerInputProgram {
  constructor(e) {
    this.variableNames = ["dy", "W"], this.outputShape = e.inShape;
    var t = e.filterDepth,
        n = e.filterHeight,
        r = e.filterWidth;
    this.userCode = "\n      const ivec3 pads = ivec3(".concat(t - 1 - e.padInfo.front, ", ").concat(n - 1 - e.padInfo.top, ", ").concat(r - 1 - e.padInfo.left, ");\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int d1 = coords.u;\n\n\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\n        int dyFCorner = dyCorner.x;\n        int dyRCorner = dyCorner.y;\n        int dyCCorner = dyCorner.z;\n\n        float dotProd = 0.0;\n        for (int wF = 0; wF < ").concat(t, "; wF++) {\n          float dyF = float(dyFCorner + wF) / ").concat(e.strideDepth, ".0;\n\n          if (dyF < 0.0 || dyF >= ").concat(e.outDepth, ".0 || fract(dyF) > 0.0) {\n            continue;\n          }\n          int idyF = int(dyF);\n\n          int wFPerm = ").concat(t, " - 1 - wF;\n\n          for (int wR = 0; wR < ").concat(n, "; wR++) {\n            float dyR = float(dyRCorner + wR) / ").concat(e.strideHeight, ".0;\n\n            if (dyR < 0.0 || dyR >= ").concat(e.outHeight, ".0 ||\n              fract(dyR) > 0.0) {\n              continue;\n            }\n            int idyR = int(dyR);\n\n            int wRPerm = ").concat(n, " - 1 - wR;\n\n            for (int wC = 0; wC < ").concat(r, "; wC++) {\n              float dyC = float(dyCCorner + wC) / ").concat(e.strideWidth, ".0;\n\n              if (dyC < 0.0 || dyC >= ").concat(e.outWidth, ".0 ||\n                  fract(dyC) > 0.0) {\n                continue;\n              }\n              int idyC = int(dyC);\n\n              int wCPerm = ").concat(r, " - 1 - wC;\n\n              for (int d2 = 0; d2 < ").concat(e.outChannels, "; d2++) {\n                float xValue = getDy(batch, idyF, idyR, idyC, d2);\n                float wValue = getW(wFPerm, wRPerm, wCPerm, d1, d2);\n                dotProd += xValue * wValue;\n              }\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    ");
  }

}

function conv2DBackpropFilter(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    dy: s
  } = t,
      {
    strides: o,
    pad: i,
    dataFormat: l,
    dimRoundingMode: u,
    filterShape: c
  } = r,
      p = convertConv2DDataFormat(l),
      d = computeConv2DInfo(a.shape, c, o, 1, i, u, !1, p),
      h = new Conv2DDerFilterProgram(d);
  return n.runWebGLProgram(h, [a, s], "float32");
}

var conv2DBackpropFilterConfig = {
  kernelName: Conv2DBackpropFilter,
  backendName: "webgl",
  kernelFunc: conv2DBackpropFilter
};

function conv2DBackpropInput(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    dy: a,
    filter: s
  } = t,
      {
    inputShape: o,
    strides: i,
    pad: l,
    dataFormat: u,
    dimRoundingMode: c
  } = r,
      p = convertConv2DDataFormat(u),
      d = computeConv2DInfo(o, s.shape, i, 1, l, c, !1, p),
      h = new Conv2DDerInputProgram(d);
  return n.runWebGLProgram(h, [a, s], "float32");
}

var conv2DBackpropInputConfig = {
  kernelName: Conv2DBackpropInput,
  backendName: "webgl",
  kernelFunc: conv2DBackpropInput
};

function conv3D(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    filter: s
  } = t,
      {
    strides: o,
    pad: i,
    dilations: l
  } = r,
      u = computeConv3DInfo(a.shape, s.shape, o, l, i),
      c = new Conv3DProgram(u);
  return n.runWebGLProgram(c, [a, s], "float32");
}

var conv3DConfig = {
  kernelName: Conv3D$1,
  backendName: "webgl",
  kernelFunc: conv3D
};

function conv3DBackpropFilterV2(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    dy: s
  } = t,
      {
    strides: o,
    pad: i,
    filterShape: l
  } = r,
      u = computeConv3DInfo(a.shape, l, o, 1, i),
      c = new Conv3DDerFilterProgram(u);
  return n.runWebGLProgram(c, [a, s], "float32");
}

var conv3DBackpropFilterV2Config = {
  kernelName: Conv3DBackpropFilterV2,
  backendName: "webgl",
  kernelFunc: conv3DBackpropFilterV2
};

function conv3DBackpropInput(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    dy: a,
    filter: s
  } = t,
      {
    pad: o,
    strides: i,
    inputShape: l
  } = r,
      u = computeConv3DInfo(l, s.shape, i, 1, o),
      c = new Conv3DDerInputProgram(u);
  return n.runWebGLProgram(c, [a, s], "float32");
}

var conv3DBackpropInputConfig = {
  kernelName: Conv3DBackpropInputV2,
  backendName: "webgl",
  kernelFunc: conv3DBackpropInput
},
    COS = CHECK_NAN_SNIPPET_UNARY + "\n  return cos(x);\n",
    cos = unaryKernelFunc({
  opSnippet: COS
}),
    cosConfig = {
  kernelName: Cos,
  backendName: "webgl",
  kernelFunc: cos
},
    COSH = "\n  float e2x = exp(-x);\n  return (e2x + 1.0 / e2x) / 2.0;\n",
    cosh = unaryKernelFunc({
  opSnippet: COSH
}),
    coshConfig = {
  kernelName: Cosh,
  backendName: "webgl",
  kernelFunc: cosh
};

class CropAndResizeProgram {
  constructor(e, t, n, r, a) {
    this.variableNames = ["Image", "Boxes", "BoxInd"], this.outputShape = [];
    var [s, o, i, l] = e,
        [u] = t,
        [c, p] = n;
    this.outputShape = [u, c, p, l];
    var d = "bilinear" === r ? 1 : 0,
        [h, m] = [o - 1 + ".0", i - 1 + ".0"],
        [f, g, $] = c > 1 ? ["" + (o - 1) / (c - 1), "(y2-y1) * height_ratio", "y1*".concat(h, " + float(y)*(height_scale)")] : ["0.0", "0.0", "0.5 * (y1+y2) * ".concat(h)],
        [y, b, x] = p > 1 ? ["" + (i - 1) / (p - 1), "(x2-x1) * width_ratio", "x1*".concat(m, " + float(x)*(width_scale)")] : ["0.0", "0.0", "0.5 * (x1+x2) * ".concat(m)];
    this.userCode = "\n      const float height_ratio = float(".concat(f, ");\n      const float width_ratio = float(").concat(y, ");\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int y = coords[1];\n        int x = coords[2];\n        int d = coords[3];\n\n        // get box vals\n        float y1 = getBoxes(b,0);\n        float x1 = getBoxes(b,1);\n        float y2 = getBoxes(b,2);\n        float x2 = getBoxes(b,3);\n\n        // get image in batch index\n        int bInd = round(getBoxInd(b));\n        if(bInd < 0 || bInd >= ").concat(s, ") {\n          return;\n        }\n\n        float height_scale = ").concat(g, ";\n        float width_scale = ").concat(b, ";\n\n        float in_y = ").concat($, ";\n        if( in_y < 0.0 || in_y > ").concat(h, " ) {\n          setOutput(float(").concat(a, "));\n          return;\n        }\n        float in_x = ").concat(x, ";\n        if( in_x < 0.0 || in_x > ").concat(m, " ) {\n          setOutput(float(").concat(a, "));\n          return;\n        }\n\n        vec2 sourceFracIndexCR = vec2(in_x,in_y);\n        if(").concat(d, " == 1) {\n          // Compute the four integer indices.\n          ivec2 sourceFloorCR = ivec2(sourceFracIndexCR);\n          ivec2 sourceCeilCR = ivec2(ceil(sourceFracIndexCR));\n\n          float topLeft = getImage(b, sourceFloorCR.y, sourceFloorCR.x, d);\n          float bottomLeft = getImage(b, sourceCeilCR.y, sourceFloorCR.x, d);\n          float topRight = getImage(b, sourceFloorCR.y, sourceCeilCR.x, d);\n          float bottomRight = getImage(b, sourceCeilCR.y, sourceCeilCR.x, d);\n\n          vec2 fracCR = sourceFracIndexCR - vec2(sourceFloorCR);\n\n          float top = topLeft + (topRight - topLeft) * fracCR.x;\n          float bottom = bottomLeft + (bottomRight - bottomLeft) * fracCR.x;\n          float newValue = top + (bottom - top) * fracCR.y;\n          setOutput(newValue);\n        } else {\n          // Compute the coordinators of nearest neighbor point.\n          ivec2 sourceNearestCR = ivec2(floor(\n            sourceFracIndexCR + vec2(0.5,0.5)));\n          float newValue = getImage(b, sourceNearestCR.y, sourceNearestCR.x, d);\n          setOutput(newValue);\n        }\n      }\n    ");
  }

}

var cropAndResize = e => {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    image: a,
    boxes: s,
    boxInd: o
  } = t,
      {
    cropSize: i,
    method: l,
    extrapolationValue: u
  } = r,
      c = new CropAndResizeProgram(a.shape, s.shape, i, l, u);
  return n.runWebGLProgram(c, [a, s, o], "float32");
},
    cropAndResizeConfig = {
  kernelName: CropAndResize,
  backendName: "webgl",
  kernelFunc: cropAndResize
};

class CumSumProgram {
  constructor(e, t, n) {
    this.variableNames = ["x"], this.customUniforms = [{
      name: "index",
      type: "float"
    }], this.outputShape = e;
    var r = e.length,
        a = t ? "0.0" : "getX(".concat(getCoords(r, "coords"), ")"),
        s = e[e.length - 1];
    var o = "",
        i = "";
    t ? (o = n ? "end != " + (s - 1) : "end != 0", i = n ? "end + 1" : "end - 1") : (o = n ? "end + pow2 < ".concat(s) : "end >= pow2", i = n ? "end + pow2" : "end - pow2"), this.userCode = "\n      void main() {\n        ".concat(getCoordsDataType(r), " coords = getOutputCoords();\n        int end = ").concat(getFinalCoord(r, "coords"), ";\n        float val = ").concat(a, ";\n        int pow2 = int(pow(2.0, index));\n        if (").concat(o, ") {\n          int idx = ").concat(i, ";\n          ").concat(getFinalCoord(r, "coords"), " = idx;\n          val += getX(").concat(getCoords(r, "coords"), ");\n        }\n        setOutput(val);\n      }\n    ");
  }

}

function getCoords(e, t) {
  if (1 === e) return "".concat(t);
  if (2 === e) return "".concat(t, ".x, ").concat(t, ".y");
  if (3 === e) return "".concat(t, ".x, ").concat(t, ".y, ").concat(t, ".z");
  if (4 === e) return "".concat(t, ".x, ").concat(t, ".y, ").concat(t, ".z, ").concat(t, ".w");
  throw Error("Cumulative sum for rank ".concat(e, " is not yet supported"));
}

function getFinalCoord(e, t) {
  if (1 === e) return "".concat(t);
  if (2 === e) return "".concat(t, ".y");
  if (3 === e) return "".concat(t, ".z");
  if (4 === e) return "".concat(t, ".w");
  throw Error("Cumulative sum for rank ".concat(e, " is not yet supported"));
}

function cumsum(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    axis: s,
    exclusive: o,
    reverse: i
  } = r,
      l = a.shape.length,
      u = getAxesPermutation([s], l);
  var c = a;
  null != u && (c = transpose({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      perm: u
    }
  }));
  var p = getInnerMostAxes(1, l)[0];
  if (p !== l - 1) throw new Error("WebGL cumsum shader expects an inner-most axis=".concat(a.shape.length - 1, " but got axis=").concat(s));
  var d = c.shape[p];
  var h = identity({
    inputs: {
      x: c
    },
    backend: n
  });

  for (var _e1039 = 0; _e1039 <= Math.ceil(Math.log2(d)) - 1; _e1039++) {
    var _t708 = new CumSumProgram(c.shape, !1, i),
        _r420 = h;

    h = n.runWebGLProgram(_t708, [h], h.dtype, [[_e1039]]), n.disposeIntermediateTensorInfo(_r420);
  }

  if (o) {
    var _e1040 = new CumSumProgram(c.shape, o, i),
        _t709 = h;

    h = n.runWebGLProgram(_e1040, [h], h.dtype), n.disposeIntermediateTensorInfo(_t709);
  }

  if (null != u) {
    var _e1041 = transpose({
      inputs: {
        x: h
      },
      backend: n,
      attrs: {
        perm: getUndoAxesPermutation(u)
      }
    });

    return n.disposeIntermediateTensorInfo(h), n.disposeIntermediateTensorInfo(c), _e1041;
  }

  return h;
}

var cumsumConfig = {
  kernelName: Cumsum,
  backendName: "webgl",
  kernelFunc: cumsum
};

function denseBincount(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    weights: s
  } = t,
      {
    size: o,
    binaryOutput: i
  } = r;

  if (1 === a.shape.length) {
    var _e1042 = n.readSync(a.dataId),
        _t710 = n.readSync(s.dataId),
        _r421 = bincountImplCPU(_e1042, _t710, s.dtype, s.shape, o);

    return n.makeTensorInfo([o], s.dtype, _r421);
  }

  if (2 === a.shape.length) {
    var _e1043 = n.bufferSync(a),
        _t711 = n.bufferSync(s),
        _r422 = bincountReduceImplCPU(_e1043, _t711, o, i);

    return n.makeTensorInfo(_r422.shape, s.dtype, _r422.values);
  }

  throw new Error("Error in denseBincount: input must be at most rank 2, but got rank".concat(a.shape.length, "."));
}

var denseBincountConfig = {
  kernelName: DenseBincount,
  backendName: "webgl",
  kernelFunc: denseBincount
};

class DepthToSpaceProgram {
  constructor(e, t, n) {
    this.variableNames = ["x"], this.outputShape = [], this.outputShape = e, this.blockSize = t, this.dataFormat = n, this.userCode = "\n    void main() {\n      ivec4 coords = getOutputCoords();\n      int b = coords[0];\n      int h = ".concat(this.getHeightCoordString(), ";\n      int w = ").concat(this.getWidthCoordString(), ";\n      int d = ").concat(this.getDepthCoordString(), ";\n\n      int in_h = h / ").concat(t, ";\n      int offset_h = imod(h, ").concat(t, ");\n      int in_w = w / ").concat(t, ";\n      int offset_w = imod(w, ").concat(t, ");\n      int offset_d = (offset_h * ").concat(t, " + offset_w) *\n        ").concat(this.getOutputDepthSize(), ";\n      int in_d = d + offset_d;\n\n      float result = ").concat(this.getInputSamplingString(), ";\n      setOutput(result);\n    }\n  ");
  }

  getHeightCoordString() {
    return "NHWC" === this.dataFormat ? "coords[1]" : "coords[2]";
  }

  getWidthCoordString() {
    return "NHWC" === this.dataFormat ? "coords[2]" : "coords[3]";
  }

  getDepthCoordString() {
    return "NHWC" === this.dataFormat ? "coords[3]" : "coords[1]";
  }

  getOutputDepthSize() {
    return "NHWC" === this.dataFormat ? this.outputShape[3] : this.outputShape[1];
  }

  getInputSamplingString() {
    return "NHWC" === this.dataFormat ? "getX(b, in_h, in_w, in_d)" : "getX(b, in_d, in_h, in_w)";
  }

}

function depthToSpace(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    blockSize: s,
    dataFormat: o
  } = r;
  assert$4(s > 1, () => "blockSize should be > 1 for depthToSpace, but was: ".concat(s));
  var i = a.shape[0],
      l = ("NHWC" === o ? a.shape[1] : a.shape[2]) * s,
      u = ("NHWC" === o ? a.shape[2] : a.shape[3]) * s,
      c = ("NHWC" === o ? a.shape[3] : a.shape[1]) / (s * s),
      p = new DepthToSpaceProgram("NHWC" === o ? [i, l, u, c] : [i, c, l, u], s, o);
  return n.runWebGLProgram(p, [a], a.dtype);
}

var depthToSpaceConfig = {
  kernelName: DepthToSpace,
  backendName: "webgl",
  kernelFunc: depthToSpace
};

class DepthwiseConv2DProgram {
  constructor(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
    var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;
    this.variableNames = ["x", "W"], this.outputShape = e.outShape;
    var s = e.inHeight,
        o = e.inWidth,
        i = e.padInfo.top,
        l = e.padInfo.left,
        u = e.strideHeight,
        c = e.strideWidth,
        p = e.dilationHeight,
        d = e.dilationWidth,
        h = e.filterHeight,
        m = e.filterWidth,
        f = e.outChannels / e.inChannels;
    var g = "",
        $ = "";
    n && (g = r ? "float activation(float a) {\n          float b = getPreluActivationWeightsAtOutCoords();\n          ".concat(n, "\n        }") : a ? "float activation(float a) {\n          float b = getLeakyreluAlphaAtOutCoords();\n          ".concat(n, "\n        }") : "\n          float activation(float x) {\n            ".concat(n, "\n          }\n        "), $ = "result = activation(result);");
    var y = t ? "result += getBiasAtOutCoords();" : "";
    t && this.variableNames.push("bias"), r && this.variableNames.push("preluActivationWeights"), a && this.variableNames.push("leakyreluAlpha"), this.userCode = "\n      ".concat(g, "\n\n      const ivec2 strides = ivec2(").concat(u, ", ").concat(c, ");\n      const ivec2 pads = ivec2(").concat(i, ", ").concat(l, ");\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords.x;\n        ivec2 xRCCorner = coords.yz * strides - pads;\n        int d2 = coords.w;\n        int d1 = d2 / ").concat(f, ";\n        int q = d2 - d1 * ").concat(f, ";\n\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        // Convolve x(?, ?, d1) with w(:, :, d1, q) to get y(yR, yC, d2).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        // TO DO(dsmilkov): Flatten the two for loops and vec4 the operations.\n        for (int wR = 0; wR < ").concat(h, "; wR++) {\n          int xR = xRCorner + wR * ").concat(p, ";\n\n          if (xR < 0 || xR >= ").concat(s, ") {\n            continue;\n          }\n\n          for (int wC = 0; wC < ").concat(m, "; wC++) {\n            int xC = xCCorner + wC * ").concat(d, ";\n\n            if (xC < 0 || xC >= ").concat(o, ") {\n              continue;\n            }\n\n            float xVal = getX(batch, xR, xC, d1);\n            float wVal = getW(wR, wC, d1, q);\n            dotProd += xVal * wVal;\n          }\n        }\n\n        float result = dotProd;\n        ").concat(y, "\n        ").concat($, "\n        setOutput(result);\n      }\n    ");
  }

}

class DepthwiseConvPacked2DProgram {
  constructor(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
    var a = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : !1;
    this.variableNames = ["x", "W"], this.packedInputs = !0, this.packedOutput = !0, this.outputShape = e.outShape;
    var s = e.outChannels / e.inChannels,
        o = e.inHeight,
        i = e.inWidth,
        l = e.padInfo.top,
        u = e.padInfo.left,
        c = e.strideHeight,
        p = e.strideWidth,
        d = e.dilationHeight,
        h = e.dilationWidth,
        m = e.filterHeight,
        f = e.filterWidth,
        g = f;
    var $ = "\n      int xR; int xC; int xCOffset;\n      vec4 wTexel; vec4 previous; vec4 final;";

    for (var _e1044 = 0; _e1044 < f; _e1044++) {
      $ += "\n          vec4 xTexelC".concat(2 * _e1044, ";\n          int xTexelC").concat(2 * _e1044, "Ready;\n          vec4 xTexelC").concat(2 * _e1044 + 1, ";\n          int xTexelC").concat(2 * _e1044 + 1, "Ready;\n          vec4 xC").concat(_e1044, ";");
    }

    for (var _e1045 = 0; _e1045 < m; _e1045++) {
      for (var _e1046 = 0; _e1046 < f; _e1046++) {
        $ += "\n          xTexelC".concat(2 * _e1046, " = vec4(0.0);\n          xTexelC").concat(2 * _e1046, "Ready = 0;\n          xTexelC").concat(2 * _e1046 + 1, " = vec4(0.0);\n          xTexelC").concat(2 * _e1046 + 1, "Ready = 0;\n          xC").concat(_e1046, " = vec4(0.0);");
      }

      $ += "\n        xR = xRCorner + ".concat(_e1045 * d, ";\n        if (xR >=0 && xR < ").concat(o, ") {\n      ");

      for (var _t712 = 0; _t712 < (g + 1) / 2; _t712++) {
        var _n436 = 2 * _t712,
            _r423 = _n436 * h;

        if ($ += "\n          xC = xCCorner + ".concat(_r423, ";\n          "), 1 === p) {
          if (_n436 < f && (u % 2 == 1 ? ($ += "\n                xCOffset = xC + 1;\n                if (xCOffset >= 0 && xCOffset < ".concat(i, " && xTexelC").concat(_n436, "Ready == 0) {\n                  xTexelC").concat(_n436, " = getX(batch, xR, xCOffset, d1);\n\n                  // Need to manually clear unused channels in case\n                  // we're reading from recycled texture.\n                  if (xCOffset + 1 >= ").concat(i, ") {\n                    xTexelC").concat(_n436, ".zw = vec2(0.0);\n                  }\n                  xTexelC").concat(_n436, "Ready = 1;\n                }\n              "), $ += 1 === h && _r423 > 0 ? "\n                xC".concat(_n436, " = vec4(xTexelC").concat(_n436 - 2, ".zw, xTexelC").concat(_n436, ".xy);\n                ") : "\n                  xCOffset = xC + 1 - 2;\n\n                  if (xCOffset >= 0 && xCOffset < ".concat(i, ") {\n                    previous = getX(batch, xR, xCOffset, d1);\n\n                    // Need to manually clear unused channels in case\n                    // we're reading from recycled texture.\n                    if (xCOffset + 1 >= ").concat(i, ") {\n                      previous.zw = vec2(0.0);\n                    }\n\n                    xC").concat(_n436, " = vec4(previous.zw, xTexelC").concat(_n436, ".xy);\n                  } else {\n                    xC").concat(_n436, " = vec4(0.0, 0.0, xTexelC").concat(_n436, ".xy);\n                  }\n                  ")) : $ += "\n                if (xC >= 0 && xC < ".concat(i, " && xTexelC").concat(_n436, "Ready == 0) {\n                  xTexelC").concat(_n436, " = getX(batch, xR, xC, d1);\n                  if (xC + 1 >= ").concat(i, ") {\n                    xTexelC").concat(_n436, ".zw = vec2(0.0);\n                  }\n                  xTexelC").concat(_n436, "Ready = 1;\n                }\n\n                xC").concat(_n436, " = xTexelC").concat(_n436, ";\n                "), _r423 + 1 < f)) {
            var _e1047 = u % 2 == 0 ? nearestLargerEven(h) : h;

            h % 2 == 0 && u % 2 == 1 || h % 2 != 0 && u % 2 != 1 ? ($ += "\n                  xCOffset = xC + ".concat(u % 2, " + ").concat(_e1047, ";\n\n                  if (xCOffset >= 0 && xCOffset < ").concat(i, " && xTexelC").concat(_n436 + 1, "Ready == 0) {\n                    xTexelC").concat(_n436 + 1, " = getX(batch, xR, xCOffset, d1);\n\n                    // Need to manually clear unused channels in case\n                    // we're reading from recycled texture.\n                    if (xCOffset + 1 >= ").concat(i, ") {\n                      xTexelC").concat(_n436 + 1, ".zw = vec2(0.0);\n                    }\n                    xTexelC").concat(_n436 + 1, "Ready = 1;\n                  }\n                  "), h > 1 && ($ += "\n                    xCOffset -= 2;\n                    if (xCOffset >= 0 && xCOffset < ".concat(i, " && xTexelC").concat(_n436, "Ready == 0) {\n                      xTexelC").concat(_n436, " = getX(batch, xR, xCOffset, d1);\n                      xTexelC").concat(_n436, "Ready = 1;\n                    }\n                    ")), $ += "\n                  xC".concat(_n436 + 1, " = vec4(xTexelC").concat(_n436, ".zw, xTexelC").concat(_n436 + 1, ".xy);\n                  ")) : $ += 1 === _e1047 ? "\n                    xC".concat(_n436 + 1, " = xTexelC").concat(_n436, ";\n                    ") : "\n                    xCOffset = xC + ".concat(_e1047, ";\n\n                    if (xCOffset >= 0 && xCOffset < ").concat(i, " && xTexelC").concat(_n436 + 1, "Ready == 0) {\n                      xTexelC").concat(_n436 + 1, " = getX(batch, xR, xCOffset, d1);\n                      if (xCOffset + 1 >= ").concat(i, ") {\n                        xTexelC").concat(_n436 + 1, ".zw = vec2(0.0);\n                      }\n                      xTexelC").concat(_n436 + 1, "Ready = 1;\n                    }\n\n                    xC").concat(_n436 + 1, " = xTexelC").concat(_n436 + 1, ";\n                    ");
          }
        } else _r423 < f && (u % 2 == 1 ? ($ += "\n                xCOffset = xC + 1 - ".concat(p, ";\n                if(xCOffset >= 0 && xCOffset < ").concat(i, " && xTexelC").concat(_n436, "Ready == 0) {\n                  xTexelC").concat(_n436, " = getX(batch, xR, xCOffset, d1);\n                  // Need to manually clear unused channels in case\n                  // we're reading from recycled texture.\n                  if (xCOffset + 1 >= ").concat(i, ") {\n                    xTexelC").concat(_n436, ".zw = vec2(0.0);\n                  }\n                  xTexelC").concat(_n436, "Ready = 1;\n                }\n\n                if(xC + 1 >= 0 && xC + 1 < ").concat(i, " && xTexelC").concat(_n436 + 1, "Ready == 0) {\n                  xTexelC").concat(_n436 + 1, " = getX(batch, xR, xC + 1, d1);\n                  // Need to manually clear unused channels in case\n                  // we're reading from recycled texture.\n                  if (xC + 2 >= ").concat(i, ") {\n                    xTexelC").concat(_n436 + 1, ".zw = vec2(0.0);\n                  }\n                  xTexelC").concat(_n436 + 1, "Ready = 1;\n                }\n\n                xC").concat(_n436, " = vec4(xTexelC").concat(_n436, ".zw, xTexelC").concat(_n436 + 1, ".zw);\n              "), _r423 + 1 < f && ($ += "\n                  final = vec4(0.0);\n                  xCOffset = xC + 1 + ".concat(p, ";\n                  if(xCOffset >= 0 && xCOffset < ").concat(i, ") {\n                    final = getX(batch, xR, xCOffset, d1);\n                  }\n                  xC").concat(_n436 + 1, " = vec4(xTexelC").concat(_n436 + 1, ".xy, final.xy);\n                "))) : ($ += "\n                if(xC >= 0 && xC < ".concat(i, " && xTexelC").concat(_n436, "Ready == 0) {\n                  xTexelC").concat(_n436, " = getX(batch, xR, xC, d1);\n                  if (xC + 1 >= ").concat(i, ") {\n                    xTexelC").concat(_n436, ".zw = vec2(0.0);\n                  }\n                  xTexelC").concat(_n436, "Ready = 1;\n                }\n\n                xCOffset = xC + ").concat(p, ";\n                if(xCOffset >= 0 && xCOffset < ").concat(i, " && xTexelC").concat(_n436 + 1, "Ready == 0) {\n                  xTexelC").concat(_n436 + 1, " = getX(batch, xR, xCOffset, d1);\n                  if (xCOffset + 1 >= ").concat(i, ") {\n                    xTexelC").concat(_n436 + 1, ".zw = vec2(0.);\n                  }\n                  xTexelC").concat(_n436 + 1, "Ready = 1;\n                }\n\n                xC").concat(_n436, " = vec4(\n                  xTexelC").concat(_n436, ".xy, xTexelC").concat(_n436 + 1, ".xy);\n              "), _r423 + 1 < f && ($ += "\n                  xC".concat(_n436 + 1, " = vec4(xTexelC").concat(_n436, ".zw, xTexelC").concat(_n436 + 1, ".zw);\n                "))));

        _n436 < f && ($ += "\n            wTexel = getW(".concat(_e1045, ", ").concat(_r423, ", d1, q);\n            dotProd += xC").concat(_n436, " * vec4(wTexel.xz, wTexel.xz);\n          "), _r423 + 1 < f && ($ += "\n              wTexel = getW(".concat(_e1045, ", ").concat(_r423 + 1, ", d1, q);\n              dotProd += xC").concat(_n436 + 1, " * vec4(wTexel.xz, wTexel.xz);\n            ")));
      }

      $ += "\n        }\n      ";
    }

    var y = "",
        b = "";
    n && (y = r ? "vec4 activation(vec4 a) {\n          vec4 b = getPreluActivationWeightsAtOutCoords();\n          ".concat(n, "\n        }") : a ? "vec4 activation(vec4 a) {\n          vec4 b = getLeakyreluAlphaAtOutCoords();\n          ".concat(n, "\n        }") : "vec4 activation(vec4 x) {\n          ".concat(n, "\n        }"), b = "result = activation(result);");
    var x = t ? "result += getBiasAtOutCoords();" : "";
    t && this.variableNames.push("bias"), r && this.variableNames.push("preluActivationWeights"), a && this.variableNames.push("leakyreluAlpha"), this.userCode = "\n      ".concat(y, "\n\n      const ivec2 strides = ivec2(").concat(c, ", ").concat(p, ");\n      const ivec2 pads = ivec2(").concat(l, ", ").concat(u, ");\n\n      void main() {\n\n        ivec4 coords = getOutputCoords();\n        int batch = coords.x;\n        ivec2 xRCCorner = coords.yz * strides - pads;\n        int d2 = coords.w;\n        int d1 = d2 / ").concat(s, ";\n        int q = d2 - d1 * ").concat(s, ";\n        int xRCorner = xRCCorner.x;\n        int xCCorner = xRCCorner.y;\n\n        //intialize dotProd with a small epsilon seems to reduce GPU accuracy loss.\n        vec4 dotProd = vec4(0.000000000000001);\n\n        ").concat($, "\n\n        vec4 result = dotProd - vec4(0.000000000000001);\n        ").concat(x, "\n        ").concat(b, "\n        setOutput(result);\n      }\n    ");
  }

}

function depthwiseConv2dNative(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    filter: s
  } = t,
      {
    strides: o,
    pad: i,
    dilations: l,
    dimRoundingMode: u
  } = r;
  var c = l;
  null == c && (c = [1, 1]), assert$4(eitherStridesOrDilationsAreOne(o, c), () => "Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ".concat(o, " and dilations '").concat(c, "'"));
  var p = computeConv2DInfo(a.shape, s.shape, o, c, i, u, !0);
  var d;
  return d = env().getBool("WEBGL_PACK_DEPTHWISECONV") && p.strideWidth <= 2 && p.outChannels / p.inChannels == 1 ? new DepthwiseConvPacked2DProgram(p) : new DepthwiseConv2DProgram(p), n.runWebGLProgram(d, [a, s], "float32");
}

var depthwiseConv2dNativeConfig = {
  kernelName: DepthwiseConv2dNative,
  backendName: "webgl",
  kernelFunc: depthwiseConv2dNative
};

class DepthwiseConv2DDerFilterProgram {
  constructor(e) {
    this.variableNames = ["x", "dy"], this.outputShape = e.filterShape, this.userCode = "\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int wR = coords.x;\n        int wC = coords.y;\n        int d1 = coords.z;\n        int dm = coords.w;\n        int d2 = d1 * ".concat(e.outChannels / e.inChannels, " + dm;\n\n        float dotProd = 0.0;\n\n        // TO DO: Vec4 over the batch size\n        for (int b = 0; b < ").concat(e.batchSize, "; b++) {\n          for (int yR = 0; yR < ").concat(e.outHeight, "; yR++) {\n            int xR = wR + yR * ").concat(e.strideHeight, " - ").concat(e.padInfo.top, ";\n\n            if (xR < 0 || xR >= ").concat(e.inHeight, ") {\n              continue;\n            }\n\n            for (int yC = 0; yC < ").concat(e.outWidth, "; yC++) {\n              int xC = wC + yC * ").concat(e.strideWidth, " - ").concat(e.padInfo.left, ";\n\n              if (xC < 0 || xC >= ").concat(e.inWidth, ") {\n                continue;\n              }\n\n              float dyValue = getDy(b, yR, yC, d2);\n              float xValue = getX(b, xR, xC, d1);\n              dotProd += (xValue * dyValue);\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    ");
  }

}

class DepthwiseConv2DDerInputProgram {
  constructor(e) {
    this.variableNames = ["dy", "W"], this.outputShape = e.inShape;
    var t = e.filterHeight,
        n = e.filterWidth,
        r = e.outChannels / e.inChannels;
    this.userCode = "\n      const ivec2 pads = ivec2(".concat(t - 1 - e.padInfo.top, ", ").concat(n - 1 - e.padInfo.left, ");\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords[0];\n        int d1 = coords[3];\n        ivec2 dyCorner = coords.yz - pads;\n        int dyRCorner = dyCorner.x;\n        int dyCCorner = dyCorner.y;\n\n        float dotProd = 0.0;\n\n        for (int wR = 0; wR < ").concat(t, "; wR++) {\n          float dyR = float(dyRCorner + wR) / ").concat(e.strideHeight, ".0;\n\n          if (dyR < 0.0 || dyR >= ").concat(e.outHeight, ".0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          int wRPerm = ").concat(t, " - 1 - wR;\n\n          for (int wC = 0; wC < ").concat(n, "; wC++) {\n            float dyC = float(dyCCorner + wC) / ").concat(e.strideWidth, ".0;\n\n            if (dyC < 0.0 || dyC >= ").concat(e.outWidth, ".0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            int wCPerm = ").concat(n, " - 1 - wC;\n\n            // TO DO: Vec4 over the channelMul\n            for (int dm = 0; dm < ").concat(r, "; dm++) {\n              int d2 = d1 * ").concat(r, " + dm;\n              float xValue = getDy(batch, idyR, idyC, d2);\n              float wValue = getW(wRPerm, wCPerm, d1, dm);\n              dotProd += xValue * wValue;\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    ");
  }

}

function depthwiseConv2dNativeBackpropFilter(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    dy: s
  } = t,
      {
    strides: o,
    dilations: i,
    pad: l,
    dimRoundingMode: u,
    filterShape: c
  } = r,
      p = computeConv2DInfo(a.shape, c, o, i, l, u, !0),
      d = new DepthwiseConv2DDerFilterProgram(p);
  return n.runWebGLProgram(d, [a, s], "float32");
}

var depthwiseConv2dNativeBackpropFilterConfig = {
  kernelName: DepthwiseConv2dNativeBackpropFilter,
  backendName: "webgl",
  kernelFunc: depthwiseConv2dNativeBackpropFilter
};

function depthwiseConv2dNativeBackpropInput(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    dy: a,
    filter: s
  } = t,
      {
    strides: o,
    dilations: i,
    pad: l,
    dimRoundingMode: u,
    inputShape: c
  } = r,
      p = computeConv2DInfo(c, s.shape, o, i, l, u, !0),
      d = new DepthwiseConv2DDerInputProgram(p);
  return n.runWebGLProgram(d, [a, s], "float32");
}

var depthwiseConv2dNativeBackpropInputConfig = {
  kernelName: DepthwiseConv2dNativeBackpropInput,
  backendName: "webgl",
  kernelFunc: depthwiseConv2dNativeBackpropInput
};

class DiagProgram {
  constructor(e) {
    this.variableNames = ["X"], this.outputShape = [e, e], this.userCode = "\n      void main() {\n          ivec2 coords = getOutputCoords();\n          float val = coords[0] == coords[1] ? getX(coords[0]) : 0.0;\n          setOutput(val);\n      }\n    ";
  }

}

function diag(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    x: r
  } = t,
      a = [...r.shape, ...r.shape],
      s = sizeFromShape(r.shape),
      o = reshape({
    inputs: {
      x: r
    },
    backend: n,
    attrs: {
      shape: [s]
    }
  }),
      i = new DiagProgram(s),
      l = n.runWebGLProgram(i, [o], o.dtype),
      u = reshape({
    inputs: {
      x: l
    },
    backend: n,
    attrs: {
      shape: a
    }
  });
  return n.disposeIntermediateTensorInfo(o), n.disposeIntermediateTensorInfo(l), u;
}

var diagConfig = {
  kernelName: Diag,
  backendName: "webgl",
  kernelFunc: diag
};

class Dilation2DProgram {
  constructor(e) {
    this.variableNames = ["x", "W"], this.outputShape = e.outShape;
    var {
      inHeight: t,
      inWidth: n,
      padInfo: r,
      strideHeight: a,
      strideWidth: s,
      filterHeight: o,
      filterWidth: i,
      dilationHeight: l,
      dilationWidth: u
    } = e,
        {
      top: c,
      left: p
    } = r;
    this.userCode = "\n      const ivec2 strides = ivec2(".concat(a, ", ").concat(s, ");\n      const ivec2 pads = ivec2(").concat(c, ", ").concat(p, ");\n      const float neg_infinity = -3.4e38;\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int batch = coords.x;\n        int d1 = coords.w;\n        ivec2 outTopLeftCorner =\n            coords.yz * strides - pads;\n        int hBeg = outTopLeftCorner.x;\n        int wBeg = outTopLeftCorner.y;\n\n        float curVal = neg_infinity;\n        for (int h = 0; h < ").concat(o, "; h++) {\n          int hIn = hBeg + h * ").concat(l, ";\n\n          if (hIn >= 0 && hIn < ").concat(t, ") {\n            for (int w = 0; w < ").concat(i, "; w++) {\n              int wIn = wBeg + w * ").concat(u, ";\n\n              if (wIn >= 0 && wIn < ").concat(n, ") {\n                float xVal = getX(batch, hIn, wIn, d1);\n                float wVal = getW(h, w, d1);\n\n                float val = xVal + wVal;\n                if (val > curVal) {\n                  curVal = val;\n                }\n              }\n            }\n          }\n        }\n\n        float result = curVal;\n        setOutput(result);\n      }\n    ");
  }

}

function dilation2D(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    filter: s
  } = t,
      {
    strides: o,
    pad: i,
    dilations: l
  } = r,
      u = computeDilation2DInfo(a.shape, s.shape, o, i, "NHWC", l);
  var c;
  var p = new Dilation2DProgram(u);
  c = n.runWebGLProgram(p, [a, s], "float32");
  var d = reshape({
    inputs: {
      x: c
    },
    backend: n,
    attrs: {
      shape: u.outShape
    }
  });
  return n.disposeIntermediateTensorInfo(c), d;
}

var dilation2DConfig = {
  kernelName: Dilation2D,
  backendName: "webgl",
  kernelFunc: dilation2D
};

function einsum(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    equation: a
  } = r,
      s = t,
      {
    allDims: o,
    summedDims: i,
    idDims: l
  } = decodeEinsumEquation(a, s.length);
  checkEinsumDimSizes(o.length, l, s);
  var {
    path: u,
    steps: c
  } = getEinsumComputePath(i, l),
      p = c.length;
  var d = null,
      h = o.length;
  var m = [];

  for (var _e1048 = 0; _e1048 < p; ++_e1048) {
    for (var _t713 of c[_e1048]) {
      var {
        permutationIndices: _e1049,
        expandDims: _r424
      } = getEinsumPermutation(h, l[_t713]);

      var _a305 = void 0;

      isIdentityPermutation(_e1049) ? _a305 = s[_t713] : (_a305 = transpose({
        inputs: {
          x: s[_t713]
        },
        backend: n,
        attrs: {
          perm: _e1049
        }
      }), m.push(_a305));

      var _o154 = _a305.shape.slice();

      for (var _e1050 = 0; _e1050 < _r424.length; ++_e1050) {
        _o154.splice(_r424[_e1050], 0, 1);
      }

      arraysEqual(_a305.shape, _o154) || (_a305 = reshape({
        inputs: {
          x: _a305
        },
        backend: n,
        attrs: {
          shape: _o154
        }
      }), m.push(_a305)), null === d ? d = _a305 : (d = multiply({
        inputs: {
          a: _a305,
          b: d
        },
        backend: n
      }), m.push(d));
    }

    _e1048 < p - 1 && (u[_e1048] >= 0 && (d = sum({
      inputs: {
        x: d
      },
      backend: n,
      attrs: {
        axis: u[_e1048] - (o.length - h),
        keepDims: !1
      }
    }), m.push(d)), h--);
  }

  for (var _e1051 of m) {
    _e1051 !== d && n.disposeIntermediateTensorInfo(_e1051);
  }

  return d;
}

var einsumConfig = {
  kernelName: Einsum,
  backendName: "webgl",
  kernelFunc: einsum
},
    ELU = "return (x >= 0.0) ? x : (exp(x) - 1.0);",
    ELU_PACKED = "\n  vec4 result;\n\n  result.r = (x.r >= 0.0) ? x.r : (exp(x.r) - 1.0);\n  result.g = (x.g >= 0.0) ? x.g : (exp(x.g) - 1.0);\n  result.b = (x.b >= 0.0) ? x.b : (exp(x.b) - 1.0);\n  result.a = (x.a >= 0.0) ? x.a : (exp(x.a) - 1.0);\n\n  return result;\n",
    elu = unaryKernelFunc({
  opSnippet: ELU,
  packedOpSnippet: ELU_PACKED
}),
    eluConfig = {
  kernelName: Elu$1,
  backendName: "webgl",
  kernelFunc: elu
},
    ELU_DER = "return (b >= 1.0) ? a : a * (b + 1.0);",
    ELU_DER_PACKED = "\n  vec4 bGTEZero = vec4(greaterThanEqual(b, vec4(0.)));\n  return (bGTEZero * a) + ((vec4(1.0) - bGTEZero) * (a * (b + vec4(1.0))));\n",
    eluGrad = e => {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    dy: r,
    y: a
  } = t,
      s = env().getBool("WEBGL_PACK_BINARY_OPERATIONS") ? new BinaryOpPackedProgram(ELU_DER_PACKED, r.shape, a.shape) : new BinaryOpProgram(ELU_DER, r.shape, a.shape);
  return n.runWebGLProgram(s, [r, a], r.dtype);
},
    eluGradConfig = {
  kernelName: EluGrad,
  backendName: "webgl",
  kernelFunc: eluGrad
},
    PACKED_EQUAL = "\n  return vec4(equal(a, b));\n",
    EQUAL = "return float(a == b);",
    equal = binaryKernelFunc({
  opSnippet: EQUAL,
  packedOpSnippet: PACKED_EQUAL,
  dtype: "bool",
  cpuKernelImpl: equalImplCPU
}),
    equalConfig = {
  kernelName: Equal,
  backendName: "webgl",
  kernelFunc: equal
},
    ERF = "\n  // Error function is calculated approximately with elementary function.\n  // See \"Handbook of Mathematical Functions with Formulas,\n  // Graphs, and Mathematical Tables\", Abramowitz and Stegun.\n  float p = ".concat(ERF_P, ";\n  float a1 = ").concat(ERF_A1, ";\n  float a2 = ").concat(ERF_A2, ";\n  float a3 = ").concat(ERF_A3, ";\n  float a4 = ").concat(ERF_A4, ";\n  float a5 = ").concat(ERF_A5, ";\n\n  float sign = sign(x);\n  x = abs(x);\n  float t = 1.0 / (1.0 + p * x);\n  return sign * (1.0 - (((((a5*t + a4)*t) + a3)*t + a2)*t + a1)*t*exp(-x*x));\n"),
    erf = unaryKernelFunc({
  opSnippet: ERF
}),
    erfConfig = {
  kernelName: Erf,
  backendName: "webgl",
  kernelFunc: erf
},
    EXP = "return exp(x);",
    exp = unaryKernelFunc({
  opSnippet: EXP,
  packedOpSnippet: EXP,
  cpuKernelImpl: expImplCPU
}),
    expConfig = {
  kernelName: Exp,
  backendName: "webgl",
  kernelFunc: exp
};

function expandDims(e) {
  var {
    inputs: t,
    attrs: n,
    backend: r
  } = e,
      {
    dim: a
  } = n,
      {
    input: s
  } = t,
      o = s.shape.length,
      i = s.shape.slice();
  var l = a;
  return a < 0 && (assert$4(-(o + 1) <= a, () => "Axis must be in the interval [".concat(-(o + 1), ", ").concat(o, "]")), l = o + a + 1), i.splice(l, 0, 1), reshape({
    inputs: {
      x: s
    },
    backend: r,
    attrs: {
      shape: i
    }
  });
}

var expandDimsConfig = {
  kernelName: ExpandDims,
  backendName: "webgl",
  kernelFunc: expandDims
},
    EXPM1 = "return exp(x) - 1.0;",
    expm1 = unaryKernelFunc({
  opSnippet: EXPM1,
  packedOpSnippet: EXPM1,
  cpuKernelImpl: expm1ImplCPU
}),
    expm1Config = {
  kernelName: Expm1,
  backendName: "webgl",
  kernelFunc: expm1
};

class FFTProgram {
  constructor(e, t, n) {
    this.variableNames = ["real", "imag"];
    var r = t[1];
    this.outputShape = t;
    var a = n ? "2.0 * ".concat(Math.PI) : "-2.0 * ".concat(Math.PI),
        s = n ? "".concat(r, ".0") : "1.0";
    var o;
    if ("real" === e) o = "return real * expR - imag * expI;";else {
      if ("imag" !== e) throw new Error("FFT component must be either \"real\" or \"imag\", got ".concat(e, "."));
      o = "return real * expI + imag * expR;";
    }
    this.userCode = "\n      const float exponentMultiplier = ".concat(a, ";\n\n      float unaryOpComplex(float real, float expR, float imag, float expI) {\n        ").concat(o, "\n      }\n\n      float mulMatDFT(int batch, int index) {\n        float indexRatio = float(index) / float(").concat(r, ");\n        float exponentMultiplierTimesIndexRatio =\n            exponentMultiplier * indexRatio;\n\n        float result = 0.0;\n\n        for (int i = 0; i < ").concat(r, "; i++) {\n          // x = (-2|2 * PI / N) * index * i;\n          float x = exponentMultiplierTimesIndexRatio * float(i);\n          float expR = cos(x);\n          float expI = sin(x);\n          float real = getReal(batch, i);\n          float imag = getImag(batch, i);\n\n          result +=\n              unaryOpComplex(real, expR, imag, expI) / ").concat(s, ";\n        }\n\n        return result;\n      }\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        setOutput(mulMatDFT(coords[0], coords[1]));\n      }\n    ");
  }

}

function fftImpl(e, t, n) {
  var r = n.texData.get(e.dataId),
      a = sizeFromShape(e.shape),
      s = e.shape[e.shape.length - 1],
      o = reshape({
    inputs: {
      x: e
    },
    backend: n,
    attrs: {
      shape: [a / s, s]
    }
  }),
      i = o.shape,
      l = new FFTProgram("real", i, t),
      u = new FFTProgram("imag", i, t),
      c = [{
    dataId: r.complexTensorInfos.real.dataId,
    dtype: r.complexTensorInfos.real.dtype,
    shape: i
  }, {
    dataId: r.complexTensorInfos.imag.dataId,
    dtype: r.complexTensorInfos.imag.dtype,
    shape: i
  }],
      p = n.runWebGLProgram(l, c, "float32"),
      d = n.runWebGLProgram(u, c, "float32"),
      h = complex({
    inputs: {
      real: p,
      imag: d
    },
    backend: n
  });
  n.disposeIntermediateTensorInfo(p), n.disposeIntermediateTensorInfo(d);
  var m = reshape({
    inputs: {
      x: h
    },
    backend: n,
    attrs: {
      shape: e.shape
    }
  });
  return n.disposeIntermediateTensorInfo(o), n.disposeIntermediateTensorInfo(h), m;
}

function fft(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    input: r
  } = t;
  return fftImpl(r, !1, n);
}

var fftConfig = {
  kernelName: FFT,
  backendName: "webgl",
  kernelFunc: fft
};

class FillProgram {
  constructor(e, t) {
    this.outputShape = [], this.customUniforms = [{
      name: "value",
      type: "float"
    }], this.variableNames = ["x"], this.outputShape = e, this.userCode = "\n      void main() {\n        // Input can be obtained from uniform value.\n        setOutput(value);\n      }\n    ";
  }

}

function fill(e) {
  var {
    backend: t,
    attrs: n
  } = e,
      {
    shape: r,
    value: a
  } = n;
  var {
    dtype: s
  } = n;

  if (s = s || inferDtype(a), "string" === s) {
    var _e1052 = getArrayFromDType(s, sizeFromShape(r));

    return _e1052.fill(a), t.makeTensorInfo(r, s, _e1052);
  }

  {
    var _e1053 = new FillProgram(r, a);

    return t.runWebGLProgram(_e1053, [], s, [[a]]);
  }
}

var fillConfig = {
  kernelName: Fill,
  backendName: "webgl",
  kernelFunc: fill
};

class FlipLeftRightProgram {
  constructor(e) {
    this.variableNames = ["Image"], this.outputShape = [];
    var t = e[2];
    this.outputShape = e, this.userCode = "\n        void main() {\n          ivec4 coords = getOutputCoords();\n          int x = coords[2];\n\n          int coordX = ".concat(t, " - x - 1;\n          float outputValue;\n          if(coordX >= 0 && coordX < ").concat(t, ") {\n            outputValue = getImage(coords[0], coords[1], coordX, coords[3]);\n          } else {\n            outputValue = getImage(coords[0], coords[1], coords[2], coords[3]);\n          }\n          setOutput(outputValue);\n        }\n    ");
  }

}

var flipLeftRightConfig = {
  kernelName: FlipLeftRight,
  backendName: "webgl",
  kernelFunc: _ref69 => {
    var {
      inputs: e,
      backend: t
    } = _ref69;
    var {
      image: n
    } = e,
        r = t,
        a = new FlipLeftRightProgram(n.shape);
    return r.runWebGLProgram(a, [n], n.dtype);
  }
},
    FLOOR = "return floor(x);",
    floor = unaryKernelFunc({
  opSnippet: FLOOR,
  packedOpSnippet: FLOOR,
  cpuKernelImpl: floorImplCPU
}),
    floorConfig = {
  kernelName: Floor,
  backendName: "webgl",
  kernelFunc: floor
},
    INT_DIV = "\n  float s = sign(a) * sign(b);\n  int ia = round(a);\n  int ib = round(b);\n  if (ib != 0) {\n    // Windows (D3D) wants guaranteed non-zero int division at compile-time.\n    return float(idiv(ia, ib, s));\n  } else {\n    return NAN;\n  }\n",
    INT_DIV_PACKED = "\n  ivec4 ia = round(a);\n  ivec4 ib = round(b);\n  bvec4 cond = notEqual(ib, ivec4(0));\n  ivec4 result = ivec4(0);\n  vec4 s = sign(a) * sign(b);\n\n  // Windows (D3D) wants guaranteed non-zero int division at compile-time.\n  if (cond[0]) {\n    result[0] = idiv(ia[0], ib[0], s[0]);\n  }\n  if (cond[1]) {\n    result[1] = idiv(ia[1], ib[1], s[1]);\n  }\n  if (cond[2]) {\n    result[2] = idiv(ia[2], ib[2], s[2]);\n  }\n  if (cond[3]) {\n    result[3] = idiv(ia[3], ib[3], s[3]);\n  }\n  return vec4(result);\n",
    floorDiv = binaryKernelFunc({
  opSnippet: INT_DIV,
  packedOpSnippet: INT_DIV_PACKED,
  dtype: "int32"
}),
    floorDivConfig = {
  kernelName: FloorDiv,
  backendName: "webgl",
  kernelFunc: floorDiv
};

class FromPixelsProgram {
  constructor(e) {
    this.variableNames = ["A"];
    var t = getGlslDifferences(),
        [n, r] = e;
    this.outputShape = e, this.userCode = "\n      void main() {\n        ivec3 coords = getOutputCoords();\n        int texR = coords[0];\n        int texC = coords[1];\n        int depth = coords[2];\n        vec2 uv = (vec2(texC, texR) + halfCR) / vec2(".concat(r, ".0, ").concat(n, ".0);\n\n        vec4 values = ").concat(t.texture2D, "(A, uv);\n        float value;\n        if (depth == 0) {\n          value = values.r;\n        } else if (depth == 1) {\n          value = values.g;\n        } else if (depth == 2) {\n          value = values.b;\n        } else if (depth == 3) {\n          value = values.a;\n        }\n\n        setOutput(floor(value * 255.0 + 0.5));\n      }\n    ");
  }

}

class FromPixelsPackedProgram {
  constructor(e) {
    this.variableNames = ["A"], this.packedInputs = !1, this.packedOutput = !0;
    var t = getGlslDifferences(),
        [n, r] = e;
    this.outputShape = e, this.userCode = "\n      void main() {\n        ivec3 coords = getOutputCoords();\n        int texR = coords[0];\n        int texC = coords[1];\n        int depth = coords[2];\n\n        vec4 result = vec4(0.);\n\n        for(int row=0; row<=1; row++) {\n          for(int col=0; col<=1; col++) {\n            texC = coords[1] + row;\n            depth = coords[2] + col;\n\n            vec2 uv = (vec2(texC, texR) + halfCR) /\n                       vec2(".concat(r, ".0, ").concat(n, ".0);\n            vec4 values = ").concat(t.texture2D, "(A, uv);\n            float value;\n            if (depth == 0) {\n              value = values.r;\n            } else if (depth == 1) {\n              value = values.g;\n            } else if (depth == 2) {\n              value = values.b;\n            } else if (depth == 3) {\n              value = values.a;\n            }\n\n            result[row * 2 + col] = floor(value * 255.0 + 0.5);\n          }\n        }\n\n        ").concat(t.output, " = result;\n      }\n    ");
  }

}

var fromPixelsConfig = {
  kernelName: FromPixels,
  backendName: "webgl",
  kernelFunc: fromPixels
};
var fromPixels2DContext;

function fromPixels(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e;
  var {
    pixels: a
  } = t;
  var {
    numChannels: s
  } = r,
      o = "undefined" != typeof HTMLVideoElement && a instanceof HTMLVideoElement,
      i = "undefined" != typeof HTMLImageElement && a instanceof HTMLImageElement,
      [l, u] = o ? [a.videoWidth, a.videoHeight] : [a.width, a.height],
      c = [u, l],
      p = [u, l, s];
  (i || o) && (null == fromPixels2DContext && (fromPixels2DContext = document.createElement("canvas").getContext("2d")), fromPixels2DContext.canvas.width = l, fromPixels2DContext.canvas.height = u, fromPixels2DContext.drawImage(a, 0, 0, l, u), a = fromPixels2DContext.canvas);
  var d = n.makeTensorInfo(c, "int32");
  n.texData.get(d.dataId).usage = TextureUsage.PIXELS, n.gpgpu.uploadPixelDataToTexture(n.getTexture(d.dataId), a);
  var h = env().getBool("WEBGL_PACK") ? new FromPixelsPackedProgram(p) : new FromPixelsProgram(p),
      m = n.runWebGLProgram(h, [d], "int32");
  return n.disposeData(d.dataId), m;
}

function fusedConv2d(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    filter: s,
    bias: o,
    preluActivationWeights: i
  } = t,
      {
    strides: l,
    pad: u,
    dataFormat: c,
    dilations: p,
    dimRoundingMode: d,
    activation: h,
    leakyreluAlpha: m
  } = r,
      f = convertConv2DDataFormat(c),
      g = computeConv2DInfo(a.shape, s.shape, l, p, u, d, !1, f);
  var $;
  var y = [];
  if (1 !== g.filterHeight || 1 !== g.filterWidth || 1 !== g.dilationHeight || 1 !== g.dilationWidth || 1 !== g.strideHeight || 1 !== g.strideWidth || "SAME" !== g.padInfo.type && "VALID" !== g.padInfo.type) {
    if (env().getBool("WEBGL_CONV_IM2COL") && 1 === a.shape[0]) $ = conv2dWithIm2Row({
      x: a,
      filter: s,
      convInfo: g,
      backend: n,
      bias: o,
      activation: h,
      preluActivationWeights: i,
      leakyreluAlpha: m
    });else {
      var _e1054 = null != o,
          _t714 = null != i,
          _r425 = "leakyrelu" === h,
          _l68 = h ? mapActivationToShaderProgram(h, !1) : null,
          _u61 = new Conv2DProgram(g, _e1054, _l68, _t714, _r425),
          _c39 = [a, s];

      if (o && _c39.push(o), i && _c39.push(i), _r425) {
        var _e1055 = n.makeTensorInfo([], "float32", createScalarValue(m, "float32"));

        _c39.push(_e1055), y.push(_e1055);
      }

      $ = n.runWebGLProgram(_u61, _c39, "float32");
    }
  } else $ = conv2dByMatMul({
    x: a,
    filter: s,
    convInfo: g,
    backend: n,
    bias: o,
    activation: h,
    preluActivationWeights: i,
    leakyreluAlpha: m
  });
  var b = reshape({
    inputs: {
      x: $
    },
    backend: n,
    attrs: {
      shape: g.outShape
    }
  });
  return y.push($), y.forEach(e => n.disposeIntermediateTensorInfo(e)), b;
}

var fusedConv2DConfig = {
  kernelName: FusedConv2D,
  backendName: "webgl",
  kernelFunc: fusedConv2d
};

function fusedDepthwiseConv2D(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    filter: s,
    bias: o,
    preluActivationWeights: i
  } = t,
      {
    strides: l,
    pad: u,
    dilations: c,
    dimRoundingMode: p,
    activation: d,
    leakyreluAlpha: h
  } = r,
      m = [];
  var f = c;
  null == f && (f = [1, 1]), assert$4(eitherStridesOrDilationsAreOne(l, f), () => "Error in depthwiseConv2d: Either strides or dilations must be 1. Got strides ".concat(l, " and dilations '").concat(f, "'"));
  var g = computeConv2DInfo(a.shape, s.shape, l, f, u, p, !0),
      $ = env().getBool("WEBGL_PACK_DEPTHWISECONV") && g.strideWidth <= 2 && g.outChannels / g.inChannels == 1,
      y = d ? mapActivationToShaderProgram(d, $) : null,
      b = [a, s],
      x = null != o,
      v = null != i,
      I = "leakyrelu" === d;

  if (x && b.push(o), v && b.push(i), I) {
    var _e1056 = n.makeTensorInfo([], "float32", createScalarValue(h, "float32"));

    b.push(_e1056), m.push(_e1056);
  }

  var C;
  C = $ ? new DepthwiseConvPacked2DProgram(g, x, y, v, I) : new DepthwiseConv2DProgram(g, x, y, v, I);
  var S = n.runWebGLProgram(C, b, "float32");
  return m.forEach(e => n.disposeIntermediateTensorInfo(e)), S;
}

var fusedDepthwiseConv2DConfig = {
  kernelName: FusedDepthwiseConv2D,
  backendName: "webgl",
  kernelFunc: fusedDepthwiseConv2D
};

class GatherNDProgram {
  constructor(e, t, n) {
    this.sliceDim = e, this.strides = t, this.variableNames = ["x", "indices"], this.outputShape = n;
    var r = getCoordsDataType(t.length),
        a = getCoordsDataType(n.length);
    this.userCode = "\n        ".concat(r, " strides = ").concat(r, "(").concat(this.strides, ");\n         void main() {\n          ").concat(a, " coords = getOutputCoords();\n          int flattenIndex = 0;\n          for (int j = 0; j < ").concat(this.sliceDim, "; j++) {\n            int index = round(getIndices(coords[0], j));\n            flattenIndex += index * ").concat(this.sliceDim > 1 ? "strides[j]" : "strides", ";\n          }\n          setOutput(getX(flattenIndex, coords[1]));\n        }\n      ");
  }

}

function gatherNd(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    params: r,
    indices: a
  } = t,
      s = a.shape,
      o = s[s.length - 1],
      i = sizeFromShape(r.shape),
      [l, u, c, p] = prepareAndValidate(r, a),
      d = reshape({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      shape: [u, o]
    }
  }),
      h = reshape({
    inputs: {
      x: r
    },
    backend: n,
    attrs: {
      shape: [sizeFromShape(r.shape) / c, c]
    }
  });

  if (n.shouldExecuteOnCPU([r, a]) || "string" === r.dtype) {
    var _e1057 = n.readSync(a.dataId),
        _t715 = n.bufferSync(r),
        _s219 = gatherNdImplCPU(_e1057, _t715, r.dtype, u, o, c, p, r.shape, i);

    return n.makeTensorInfo(l, r.dtype, _s219.values);
  }

  var m = new GatherNDProgram(o, p, [u, c]),
      f = n.runWebGLProgram(m, [h, d], h.dtype),
      g = reshape({
    inputs: {
      x: f
    },
    backend: n,
    attrs: {
      shape: l
    }
  });
  return n.disposeIntermediateTensorInfo(d), n.disposeIntermediateTensorInfo(h), n.disposeIntermediateTensorInfo(f), g;
}

var gatherNdConfig = {
  kernelName: GatherNd,
  backendName: "webgl",
  kernelFunc: gatherNd
};

class GatherProgram {
  constructor(e, t) {
    this.variableNames = ["A", "indices"], this.outputShape = t, this.rank = t.length;
    var n = getCoordsDataType(this.rank),
        r = getSourceCoords$1(e);
    this.userCode = "\n      void main() {\n        ".concat(n, " resRC = getOutputCoords();\n        setOutput(getA(").concat(r, "));\n      }\n    ");
  }

}

function getSourceCoords$1(e, t) {
  var n = ["resRC.x", "resRC.y", "resRC.z", "resRC.w"],
      r = [];

  for (var _t716 = 0; _t716 < e.length; _t716++) {
    r.push(2 === _t716 ? "int(getIndices(resRC.x, resRC.z))" : "".concat(n[_t716]));
  }

  return r.join();
}

function gatherV2(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    indices: s
  } = t,
      {
    axis: o,
    batchDims: i
  } = r,
      l = collectGatherOpShapeInfo(a, s, parseAxisParam(o, a.shape)[0], i),
      u = sizeFromShape(s.shape),
      c = [],
      p = reshape({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      shape: [l.batchSize, l.outerSize, l.dimSize, l.sliceSize]
    }
  }),
      d = reshape({
    inputs: {
      x: s
    },
    backend: n,
    attrs: {
      shape: [l.batchSize, u / l.batchSize]
    }
  });
  c.push(p), c.push(d);
  var h = [l.batchSize, l.outerSize, u / l.batchSize, l.sliceSize];

  if (n.shouldExecuteOnCPU([a, s]) || "string" === a.dtype) {
    var _e1058 = n.bufferSync(d),
        _t717 = n.bufferSync(p),
        _r426 = gatherV2ImplCPU(_t717, _e1058, h);

    return c.forEach(e => n.disposeIntermediateTensorInfo(e)), n.makeTensorInfo(l.outputShape, _r426.dtype, _r426.values);
  }

  var m = new GatherProgram(p.shape, h),
      f = n.runWebGLProgram(m, [p, d], p.dtype);
  c.push(f);
  var g = reshape({
    inputs: {
      x: f
    },
    backend: n,
    attrs: {
      shape: l.outputShape
    }
  });
  return c.forEach(e => n.disposeIntermediateTensorInfo(e)), g;
}

var gatherV2Config = {
  kernelName: GatherV2,
  backendName: "webgl",
  kernelFunc: gatherV2
},
    GREATER = "return float(a > b);",
    GREATER_PACKED = "\n  return vec4(greaterThan(a, b));\n",
    greater = binaryKernelFunc({
  opSnippet: GREATER,
  packedOpSnippet: GREATER_PACKED,
  cpuKernelImpl: greaterImplCPU,
  dtype: "bool"
}),
    greaterConfig = {
  kernelName: Greater,
  backendName: "webgl",
  kernelFunc: greater
},
    GREATER_EQUAL = "return float(a >= b);",
    GREATER_EQUAL_PACKED = "\n  return vec4(greaterThanEqual(a, b));\n",
    greaterEqual = binaryKernelFunc({
  opSnippet: GREATER_EQUAL,
  packedOpSnippet: GREATER_EQUAL_PACKED,
  dtype: "bool",
  cpuKernelImpl: greaterEqualImplCPU
}),
    greaterEqualConfig = {
  kernelName: GreaterEqual,
  backendName: "webgl",
  kernelFunc: greaterEqual
};

function ifft(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    input: r
  } = t;
  return fftImpl(r, !0, n);
}

var ifftConfig = {
  kernelName: IFFT,
  backendName: "webgl",
  kernelFunc: ifft
},
    IS_FINITE = "return float(!isnan(x) && !isinf(x));",
    isFinite$1 = unaryKernelFunc({
  opSnippet: IS_FINITE,
  dtype: "bool"
}),
    isFiniteConfig = {
  kernelName: IsFinite,
  backendName: "webgl",
  kernelFunc: isFinite$1
},
    IS_INF = "return float(isinf(x));",
    isInf = unaryKernelFunc({
  opSnippet: IS_INF,
  dtype: "bool"
}),
    isInfConfig = {
  kernelName: IsInf,
  backendName: "webgl",
  kernelFunc: isInf
},
    IS_NAN = "return float(isnan(x));",
    isNaN$1 = unaryKernelFunc({
  opSnippet: IS_NAN,
  dtype: "bool"
}),
    isNaNConfig = {
  kernelName: IsNan,
  backendName: "webgl",
  kernelFunc: isNaN$1
},
    LESS = "return float(a < b);",
    LESS_PACKED = "\n  return vec4(lessThan(a, b));\n",
    less = binaryKernelFunc({
  opSnippet: LESS,
  packedOpSnippet: LESS_PACKED,
  cpuKernelImpl: lessImplCPU,
  dtype: "bool"
}),
    lessConfig = {
  kernelName: Less,
  backendName: "webgl",
  kernelFunc: less
},
    LESS_EQUAL = "return float(a <= b);",
    LESS_EQUAL_PACKED = "\n  return vec4(lessThanEqual(a, b));\n",
    lessEqual = binaryKernelFunc({
  opSnippet: LESS_EQUAL,
  packedOpSnippet: LESS_EQUAL_PACKED,
  cpuKernelImpl: lessEqualImplCPU,
  dtype: "bool"
}),
    lessEqualConfig = {
  kernelName: LessEqual,
  backendName: "webgl",
  kernelFunc: lessEqual
};

function linSpace(e) {
  var {
    backend: t,
    attrs: n
  } = e,
      {
    start: r,
    stop: a,
    num: s
  } = n,
      o = linSpaceImplCPU(r, a, s);
  return t.makeTensorInfo([o.length], "float32", o);
}

var linSpaceConfig = {
  kernelName: LinSpace,
  backendName: "webgl",
  kernelFunc: linSpace
},
    LOG = "if (x < 0.0) return NAN;\n  return log(x);",
    LOG_PACKED = "\n  vec4 result = log(x);\n  vec4 isNaN = vec4(lessThan(x, vec4(0.0)));\n  result.r = isNaN.r == 1.0 ? NAN : result.r;\n  result.g = isNaN.g == 1.0 ? NAN : result.g;\n  result.b = isNaN.b == 1.0 ? NAN : result.b;\n  result.a = isNaN.a == 1.0 ? NAN : result.a;\n\n  return result;\n",
    log = unaryKernelFunc({
  opSnippet: LOG,
  packedOpSnippet: LOG_PACKED,
  cpuKernelImpl: logImplCPU
}),
    logConfig = {
  kernelName: Log,
  backendName: "webgl",
  kernelFunc: log
},
    LOG1P = "return log(1.0 + x);",
    log1p = unaryKernelFunc({
  opSnippet: LOG1P
}),
    log1pConfig = {
  kernelName: Log1p,
  backendName: "webgl",
  kernelFunc: log1p
},
    LOGICAL_AND = "return float(a >= 1.0 && b >= 1.0);",
    LOGICAL_AND_PACKED = "\n  return vec4(\n    vec4(greaterThanEqual(a, vec4(1.0))) *\n    vec4(greaterThanEqual(b, vec4(1.0))));\n",
    logicalAnd = binaryKernelFunc({
  opSnippet: LOGICAL_AND,
  packedOpSnippet: LOGICAL_AND_PACKED,
  dtype: "bool"
}),
    logicalAndConfig = {
  kernelName: LogicalAnd,
  backendName: "webgl",
  kernelFunc: logicalAnd
},
    LOGICAL_NOT = "return float(!(x >= 1.0));",
    logicalNot = unaryKernelFunc({
  opSnippet: LOGICAL_NOT
}),
    logicalNotConfig = {
  kernelName: LogicalNot,
  backendName: "webgl",
  kernelFunc: logicalNot
},
    LOGICAL_OR = "return float(a >= 1.0 || b >= 1.0);",
    LOGICAL_OR_PACKED = "\n  return min(\n    vec4(greaterThanEqual(a, vec4(1.0))) +\n    vec4(greaterThanEqual(b, vec4(1.0))),\n    vec4(1.0));\n",
    logicalOr = binaryKernelFunc({
  opSnippet: LOGICAL_OR,
  packedOpSnippet: LOGICAL_OR_PACKED,
  dtype: "bool"
}),
    logicalOrConfig = {
  kernelName: LogicalOr,
  backendName: "webgl",
  kernelFunc: logicalOr
};

class LRNProgram {
  constructor(e, t, n, r, a) {
    this.variableNames = ["x"], this.outputShape = [];
    var s = t,
        o = e[3] - 1;
    var i;
    this.outputShape = e;
    var l = "float(".concat(n, ") + float(").concat(r, ") * sum");
    i = .5 === a ? "inversesqrt(".concat(l, ")") : 1 === a ? "1.0/(".concat(l, ")") : "exp(log(".concat(l, ") * float(-").concat(a, "));"), this.userCode = "\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int r = coords[1];\n        int c = coords[2];\n        int d = coords[3];\n        float x = getX(b, r, c, d);\n        float sum = 0.0;\n        for (int j = -".concat(s, "; j <= ").concat(s, "; j++) {\n          int idx = d + j;\n          if (idx >= 0 && idx <=  ").concat(o, ") {\n            float z = getX(b, r, c, idx);\n            sum += z * z;\n          }\n        }\n        float val = x * ").concat(i, ";\n        setOutput(val);\n      }\n    ");
  }

}

class LRNPackedProgram {
  constructor(e, t, n, r, a) {
    this.variableNames = ["x"], this.outputShape = [], this.packedInputs = !0, this.packedOutput = !0;
    var s = t,
        o = e[3] - 1;
    var i;
    this.outputShape = e;
    var l = "float(".concat(n, ") + float(").concat(r, ") * sum");
    i = .5 === a ? "inversesqrt(".concat(l, ")") : 1 === a ? "1.0/(".concat(l, ")") : "exp(log(".concat(l, ") * float(-").concat(a, "));"), this.userCode = "\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords.x;\n        int r = coords.y;\n        int c = coords.z;\n        int d = coords.w;\n\n        bool hasNextCol = d < ".concat(this.outputShape[3], ";\n        bool hasNextRow = c < ").concat(this.outputShape[2], ";\n\n        vec4 sum = vec4(0.);\n        vec4 xFragAtOutputCoords = getX(b, r, c, d);\n\n        vec4 xAtOutputCoords = vec4(\n          getChannel(xFragAtOutputCoords, vec2(c, d)),\n          hasNextCol ?\n            getChannel(xFragAtOutputCoords, vec2(c, d + 1)) : 0.0,\n          hasNextRow ?\n            getChannel(xFragAtOutputCoords , vec2(c + 1, d)) : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getChannel(xFragAtOutputCoords, vec2(c + 1, d + 1)) : 0.0\n        );\n\n        int firstChannel = d - ").concat(s, ";\n        vec2 cache = vec2(0.);\n        if(firstChannel >= 0){\n          vec4 firstChannelFrag = getX(b, r, c, firstChannel);\n          cache.x = getChannel(firstChannelFrag, vec2(c, firstChannel));\n            if(hasNextRow){\n              cache.y = getChannel(firstChannelFrag, vec2(c + 1, firstChannel));\n            }\n        }\n\n        ivec2 depth = ivec2(d, d + 1);\n        for (int j = - ").concat(s, "; j <= ").concat(s, "; j++) {\n          ivec2 idx = depth + j;\n          bvec2 aboveLowerBound = greaterThanEqual(idx, ivec2(0));\n          bvec2 belowUpperBound = lessThanEqual(idx, ivec2(").concat(o, "));\n\n          bool depthInRange = aboveLowerBound.x && belowUpperBound.x;\n          bool depthPlusOneInRange = aboveLowerBound.y && belowUpperBound.y;\n\n          if(depthInRange || depthPlusOneInRange){\n            vec4 z = vec4(0.);\n            vec4 xFragAtCurrentDepth;\n            z.xz = cache.xy;\n            if(depthPlusOneInRange && hasNextCol){\n              xFragAtCurrentDepth = idx.y != d ?\n                getX(b, r, c, idx.y) : xFragAtOutputCoords;\n              z.y = getChannel(xFragAtCurrentDepth, vec2(c, idx.y));\n              if(hasNextRow){\n                z.w = getChannel(xFragAtCurrentDepth, vec2(c + 1, idx.y));\n              }\n            }\n            cache.xy = z.yw;\n            sum += z * z;\n          }\n        }\n        vec4 result = xAtOutputCoords * ").concat(i, ";\n        setOutput(result);\n      }\n    ");
  }

}

var lrn = e => {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    depthRadius: s,
    bias: o,
    alpha: i,
    beta: l
  } = r,
      u = env().getBool("WEBGL_PACK_NORMALIZATION") ? new LRNPackedProgram(a.shape, s, o, i, l) : new LRNProgram(a.shape, s, o, i, l);
  return n.runWebGLProgram(u, [a], a.dtype);
},
    LRNConfig = {
  kernelName: LRN,
  backendName: "webgl",
  kernelFunc: lrn
};

class LRNGradProgram {
  constructor(e, t, n, r, a) {
    this.variableNames = ["inputImage", "outputImage", "dy"], this.outputShape = [], this.outputShape = e, this.depth = e[3], this.depthRadius = t, this.bias = n, this.alpha = r, this.beta = a, this.userCode = "\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int r = coords[1];\n        int c = coords[2];\n\n        float result = 0.0;\n        for (int d = 0; d < ".concat(this.depth, "; ++d) {\n          int depthBegin = int(max(0.0, float(d - ").concat(t, ")));\n          int depthEnd = int(min(float(").concat(this.depth, "),\n              float(d + ").concat(t, " + 1)));\n\n          const int MIN_DEPTH_BEGIN = 0;\n          const int MAX_DEPTH_END = ").concat(this.depth, ";\n\n          float norm = 0.0;\n          for (int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k) {\n            if (k < depthBegin){\n              continue;\n            }\n            else if (k >= depthBegin && k < depthEnd) {\n              norm += getInputImage(b, r, c, k) * getInputImage(b, r, c, k);\n            }\n            else {\n              break;\n            }\n          }\n\n          norm = float(").concat(r, ") * norm + float(").concat(n, ");\n\n          for(int k = MIN_DEPTH_BEGIN; k < MAX_DEPTH_END; ++k){\n            if (k < depthBegin){\n              continue;\n            }\n            else if (k >= depthBegin && k < depthEnd){\n              float dyi = -2.0 * float(").concat(r, ")\n                * float(").concat(a, ")\n                * getInputImage(b ,r ,c, k) * getOutputImage(b, r, c, d)\n                / norm;\n              if (k == d) {\n                dyi += pow(norm, -1.0 * ").concat(a, ");\n              }\n              if (k == coords[3]) {\n                dyi *= getDy(b, r, c, d);\n                result += dyi;\n              }\n            }\n            else {\n              break;\n            }\n          }\n      }\n      setOutput(result);\n      }\n    ");
  }

}

var lrnGrad = e => {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    y: s,
    dy: o
  } = t,
      {
    depthRadius: i,
    bias: l,
    alpha: u,
    beta: c
  } = r,
      p = new LRNGradProgram(a.shape, i, l, u, c);
  return n.runWebGLProgram(p, [a, s, o], a.dtype);
},
    LRNGradConfig = {
  kernelName: LRNGrad,
  backendName: "webgl",
  kernelFunc: lrnGrad
};

function maxImpl(e, t, n, r) {
  var a = sizeFromShape(t),
      s = reshape({
    inputs: {
      x: e
    },
    attrs: {
      shape: [sizeFromShape(e.shape) / a, a]
    },
    backend: r
  }),
      o = reduce(s, e.dtype, "max", r),
      i = reshape({
    inputs: {
      x: o
    },
    attrs: {
      shape: n
    },
    backend: r
  });
  return r.disposeIntermediateTensorInfo(s), r.disposeIntermediateTensorInfo(o), i;
}

function max(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    reductionIndices: s,
    keepDims: o
  } = r,
      i = a.shape.length,
      l = parseAxisParam(s, a.shape);
  var u = l;
  var c = getAxesPermutation(u, i),
      p = null != c,
      d = n.shouldExecuteOnCPU([a]);
  var h = a;

  if (p) {
    if (d) {
      var _e1059 = n.texData.get(h.dataId).values,
          _t718 = new Array(i);

      for (var _e1060 = 0; _e1060 < _t718.length; _e1060++) {
        _t718[_e1060] = a.shape[c[_e1060]];
      }

      var _r427 = transposeImplCPU(_e1059, a.shape, a.dtype, c, _t718);

      h = n.makeTensorInfo(_t718, a.dtype), n.texData.get(h.dataId).values = _r427;
    } else h = transposeImpl(a, c, n);

    u = getInnerMostAxes(u.length, i);
  }

  assertAxesAreInnerMostDims("max", u, i);
  var [m, f] = computeOutAndReduceShapes(h.shape, u);
  var g,
      $ = m;

  if (o && ($ = expandShapeToKeepDim(m, l)), d) {
    var _e1061 = n.texData.get(h.dataId),
        _t719 = maxImplCPU(_e1061.values, sizeFromShape(f), $, a.dtype);

    g = n.makeTensorInfo($, a.dtype), n.texData.get(g.dataId).values = _t719;
  } else g = maxImpl(h, f, $, n);

  return p && n.disposeIntermediateTensorInfo(h), g;
}

var maxConfig = {
  kernelName: Max,
  backendName: "webgl",
  kernelFunc: max
},
    MAXIMUM = CHECK_NAN_SNIPPET$1 + "\n  return max(a, b);\n",
    MAXIMUM_PACKED = "\n  vec4 result = vec4(max(a, b));\n  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));\n  " + CHECK_NAN_SNIPPET + "\n  return result;\n",
    maximum = binaryKernelFunc({
  opSnippet: MAXIMUM,
  packedOpSnippet: MAXIMUM_PACKED,
  cpuKernelImpl: maximumImplCPU
}),
    maximumConfig = {
  kernelName: Maximum$1,
  backendName: "webgl",
  kernelFunc: maximum
};

function maxPool(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t;
  assertNotComplex(a, "maxPool");
  var {
    filterSize: s,
    strides: o,
    pad: i,
    dimRoundingMode: l
  } = r;
  assert$4(eitherStridesOrDilationsAreOne(o, 1), () => "Error in maxPool: Either strides or dilations must be 1. Got strides ".concat(o, " and dilations '1'"));
  var u = computePool2DInfo(a.shape, s, o, 1, i, l);
  if (1 === u.filterWidth && 1 === u.filterHeight && arraysEqual(u.inShape, u.outShape)) return identity({
    inputs: {
      x: a
    },
    backend: n
  });
  var c = new Pool2DProgram(u, "max", !1);
  return n.runWebGLProgram(c, [a], a.dtype);
}

var maxPoolConfig = {
  kernelName: MaxPool,
  backendName: "webgl",
  kernelFunc: maxPool
};

function maxPool3d(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    filterSize: s,
    strides: o,
    pad: i,
    dataFormat: l,
    dimRoundingMode: u
  } = r,
      c = computePool3DInfo(a.shape, s, o, [1, 1, 1], i, u, l),
      p = new Pool3DProgram(c, "max", !1);
  return n.runWebGLProgram(p, [a], a.dtype);
}

var maxPool3DConfig = {
  kernelName: MaxPool3D,
  backendName: "webgl",
  kernelFunc: maxPool3d
};

class MaxPool2DBackpropProgram {
  constructor(e) {
    this.variableNames = ["dy", "maxPos"], this.outputShape = e.inShape;
    var t = e.effectiveFilterHeight,
        n = e.effectiveFilterWidth;
    this.userCode = "\n      const ivec2 pads = ivec2(".concat(t - 1 - e.padInfo.top, ", ").concat(n - 1 - e.padInfo.left, ");\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n\n        ivec2 dyRCCorner = coords.yz - pads;\n        int dyRCorner = dyRCCorner.x;\n        int dyCCorner = dyRCCorner.y;\n\n        // Convolve dy(?, ?, d) with pos mask(:, :, d) to get dx(xR, xC, d).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n        for (int wR = 0; wR < ").concat(t, ";\n          wR += ").concat(e.dilationHeight, ") {\n          float dyR = float(dyRCorner + wR) / ").concat(e.strideHeight, ".0;\n\n          if (dyR < 0.0 || dyR >= ").concat(e.outHeight, ".0 || fract(dyR) > 0.0) {\n            continue;\n          }\n          int idyR = int(dyR);\n\n          for (int wC = 0; wC < ").concat(n, "; wC++) {\n            float dyC = float(dyCCorner + wC) / ").concat(e.strideWidth, ".0;\n\n            if (dyC < 0.0 || dyC >= ").concat(e.outWidth, ".0 ||\n                fract(dyC) > 0.0) {\n              continue;\n            }\n            int idyC = int(dyC);\n\n            float dyValue = getDy(b, idyR, idyC, d);\n            int maxPosValue = ").concat(t * n - 1, " - int(getMaxPos(b, idyR, idyC, d));\n\n            // Get the current value, check it against the value from the\n            // position matrix.\n            int curPosValue = wR * ").concat(n, " + wC;\n            float mask = float(maxPosValue == curPosValue ? 1.0 : 0.0);\n\n            dotProd += dyValue * mask;\n          }\n        }\n        setOutput(dotProd);\n      }\n    ");
  }

}

class MaxPool3DBackpropProgram {
  constructor(e) {
    this.variableNames = ["dy", "maxPos"], this.outputShape = e.inShape;
    var t = e.effectiveFilterDepth,
        n = e.effectiveFilterHeight,
        r = e.effectiveFilterWidth;
    this.userCode = "\n      const ivec3 pads = ivec3(".concat(t - 1 - e.padInfo.front, ", ").concat(n - 1 - e.padInfo.top, ", ").concat(r - 1 - e.padInfo.left, ");\n\n      void main() {\n        ivec5 coords = getOutputCoords();\n        int batch = coords.x;\n        int ch = coords.u;\n\n        ivec3 dyCorner = ivec3(coords.y, coords.z, coords.w) - pads;\n        int dyDCorner = dyCorner.x;\n        int dyRCorner = dyCorner.y;\n        int dyCCorner = dyCorner.z;\n\n        // Convolve dy(?, ?, ?, ch) with pos mask(:, :, :, d) to get\n        // dx(xD, xR, xC, ch).\n        // ? = to be determined. : = across all values in that axis.\n        float dotProd = 0.0;\n\n        for (int wD = 0; wD < ").concat(t, ";\n           wD += ").concat(e.dilationDepth, ") {\n          float dyD = float(dyDCorner + wD) / ").concat(e.strideDepth, ".0;\n\n          if (dyD < 0.0 || dyD >= ").concat(e.outDepth, ".0 || fract(dyD) > 0.0) {\n            continue;\n          }\n          int idyD = int(dyD);\n\n          for (int wR = 0; wR < ").concat(n, ";\n              wR += ").concat(e.dilationHeight, ") {\n            float dyR = float(dyRCorner + wR) / ").concat(e.strideHeight, ".0;\n\n            if (dyR < 0.0 || dyR >= ").concat(e.outHeight, ".0 ||\n                fract(dyR) > 0.0) {\n              continue;\n            }\n            int idyR = int(dyR);\n\n            for (int wC = 0; wC < ").concat(r, ";\n                wC += ").concat(e.dilationWidth, ") {\n              float dyC = float(dyCCorner + wC) / ").concat(e.strideWidth, ".0;\n\n              if (dyC < 0.0 || dyC >= ").concat(e.outWidth, ".0 ||\n                  fract(dyC) > 0.0) {\n                continue;\n              }\n              int idyC = int(dyC);\n\n              float dyValue = getDy(batch, idyD, idyR, idyC, ch);\n              int maxPosValue = ").concat(t * n * r - 1, " -\n                  int(getMaxPos(batch, idyD, idyR, idyC, ch));\n\n              // Get the current value, check it against the value from the\n              // position matrix.\n              int curPosValue =\n                  wD * ").concat(n, " * ").concat(r, " +\n                  wR * ").concat(r, " + wC;\n              float mask = float(maxPosValue == curPosValue ? 1.0 : 0.0);\n\n              dotProd += dyValue * mask;\n            }\n          }\n        }\n        setOutput(dotProd);\n      }\n    ");
  }

}

function maxPool3DGrad(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    dy: a,
    input: s
  } = t,
      o = s,
      {
    filterSize: i,
    strides: l,
    pad: u,
    dimRoundingMode: c
  } = r,
      p = computePool3DInfo(o.shape, i, l, [1, 1, 1], u, c),
      d = new Pool3DProgram(p, "max", !0),
      h = n.runWebGLProgram(d, [o], o.dtype),
      m = new MaxPool3DBackpropProgram(p),
      f = n.runWebGLProgram(m, [a, h], o.dtype);
  return n.disposeIntermediateTensorInfo(h), f;
}

var maxPoolGrad3DConfig = {
  kernelName: MaxPool3DGrad,
  backendName: "webgl",
  kernelFunc: maxPool3DGrad
};

function maxPoolGrad(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    dy: a,
    input: s,
    output: o
  } = t,
      i = s;
  assertNotComplex([s, o], "maxPoolGrad");
  var {
    filterSize: l,
    strides: u,
    pad: c,
    dimRoundingMode: p
  } = r,
      d = computePool2DInfo(i.shape, l, u, 1, c, p),
      h = new Pool2DProgram(d, "max", !0),
      m = n.runWebGLProgram(h, [i], i.dtype),
      f = new MaxPool2DBackpropProgram(d),
      g = n.runWebGLProgram(f, [a, m], i.dtype);
  return n.disposeIntermediateTensorInfo(m), g;
}

var maxPoolGradConfig = {
  kernelName: MaxPoolGrad,
  backendName: "webgl",
  kernelFunc: maxPoolGrad
};

function maxPoolWithArgmaxImpl(e, t, n, r) {
  var a = new Pool2DProgram(n, "max", !1);
  var s = r.runWebGLProgram(a, [e], "float32");
  return a = new Pool2DProgram(n, "max", !0, !0, t), [s, r.runWebGLProgram(a, [e], "float32")];
}

var maxPoolWithArgmaxConfig = {
  kernelName: MaxPoolWithArgmax,
  backendName: "webgl",
  kernelFunc: _ref70 => {
    var {
      inputs: e,
      attrs: t,
      backend: n
    } = _ref70;
    var {
      x: r
    } = e,
        {
      filterSize: a,
      strides: s,
      pad: o,
      includeBatchInIndex: i
    } = t,
        l = n;
    assert$4(4 === r.shape.length, () => "Error in maxPool: input must be rank 4 but got rank ".concat(r.shape.length, "."));
    var u = [1, 1];
    assert$4(eitherStridesOrDilationsAreOne(s, u), () => "Error in maxPool: Either strides or dilations must be 1. Got strides ".concat(s, " and dilations '").concat(u, "'"));
    var c = computePool2DInfo(r.shape, a, s, u, o),
        [p, d] = maxPoolWithArgmaxImpl(r, i, c, l);
    return [p, d];
  }
};

function meanImpl(e, t, n, r) {
  var a = sizeFromShape(t),
      s = reshape({
    inputs: {
      x: e
    },
    attrs: {
      shape: [sizeFromShape(e.shape) / a, a]
    },
    backend: r
  }),
      o = reduce(s, "float32", "mean", r),
      i = reshape({
    inputs: {
      x: o
    },
    attrs: {
      shape: n
    },
    backend: r
  });
  return r.disposeIntermediateTensorInfo(s), r.disposeIntermediateTensorInfo(o), i;
}

var meanConfig = {
  kernelName: Mean,
  backendName: "webgl",
  kernelFunc: _ref71 => {
    var {
      inputs: e,
      attrs: t,
      backend: n
    } = _ref71;
    var {
      x: r
    } = e,
        {
      keepDims: a,
      axis: s
    } = t,
        o = n,
        i = r.shape.length,
        l = parseAxisParam(s, r.shape);
    var u = l;
    var c = getAxesPermutation(u, i),
        p = null != c,
        d = o.shouldExecuteOnCPU([r]),
        h = [];
    var m = r;

    if (p) {
      if (d) {
        var _e1062 = o.texData.get(m.dataId).values,
            _t720 = new Array(i);

        for (var _e1063 = 0; _e1063 < _t720.length; _e1063++) {
          _t720[_e1063] = r.shape[c[_e1063]];
        }

        var _n437 = transposeImplCPU(_e1062, r.shape, r.dtype, c, _t720);

        m = o.makeTensorInfo(_t720, r.dtype), o.texData.get(m.dataId).values = _n437;
      } else m = transposeImpl(r, c, o);

      h.push(m), u = getInnerMostAxes(u.length, i);
    }

    assertAxesAreInnerMostDims("sum", u, i);
    var [f, g] = computeOutAndReduceShapes(m.shape, u);
    var $ = f;
    a && ($ = expandShapeToKeepDim(f, l));
    var y = meanImpl(m, g, $, o);

    for (var _e1064 of h) {
      o.disposeIntermediateTensorInfo(_e1064);
    }

    return y;
  }
};

function min(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    axis: s,
    keepDims: o
  } = r,
      i = a.shape.length,
      l = parseAxisParam(s, a.shape);
  var u = l;
  var c = getAxesPermutation(u, i);
  var p = a;
  null != c && (p = transpose({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      perm: c
    }
  }), u = getInnerMostAxes(u.length, a.shape.length)), assertAxesAreInnerMostDims("min", u, i);
  var [d, h] = computeOutAndReduceShapes(p.shape, u),
      m = reshape({
    inputs: {
      x: p
    },
    backend: n,
    attrs: {
      shape: [-1, sizeFromShape(h)]
    }
  }),
      f = reduce(m, m.dtype, "min", n);
  var g;
  return g = reshape(o ? {
    inputs: {
      x: f
    },
    backend: n,
    attrs: {
      shape: expandShapeToKeepDim(d, l)
    }
  } : {
    inputs: {
      x: f
    },
    backend: n,
    attrs: {
      shape: d
    }
  }), n.disposeIntermediateTensorInfo(m), n.disposeIntermediateTensorInfo(f), null != c && n.disposeIntermediateTensorInfo(p), g;
}

var minConfig = {
  kernelName: Min,
  backendName: "webgl",
  kernelFunc: min
},
    MINIMUM = CHECK_NAN_SNIPPET$1 + "\n  return min(a, b);\n",
    MINIMUM_PACKED = "\n  vec4 result = vec4(min(a, b));\n  vec4 isNaN = min(vec4(isnan(a)) + vec4(isnan(b)), vec4(1.0));\n  " + CHECK_NAN_SNIPPET + "\n  return result;\n",
    minimum = binaryKernelFunc({
  opSnippet: MINIMUM,
  packedOpSnippet: MINIMUM_PACKED,
  cpuKernelImpl: minimumImplCPU
}),
    minimumConfig = {
  kernelName: Minimum$1,
  backendName: "webgl",
  kernelFunc: minimum
};

class MirrorPadProgram {
  constructor(e, t, n) {
    this.variableNames = ["x"], this.outputShape = t.map((t, n) => t[0] + e[n] + t[1]);
    var r = e.length,
        a = getCoordsDataType(r),
        s = t.map(e => e[0]).join(","),
        o = t.map((t, n) => t[0] + e[n]).join(","),
        i = ["coords[0]", "coords[1]", "coords[2]", "coords[3]"].slice(0, r),
        l = "reflect" === n ? 0 : 1;
    this.userCode = 1 !== r ? "\n      ".concat(a, " start = ").concat(a, "(").concat(s, ");\n      ").concat(a, " end = ").concat(a, "(").concat(o, ");\n\n      void main() {\n        ").concat(a, " outC = getOutputCoords();\n        for (int i = 0; i < ").concat(r, "; i++) {\n          if (outC[i] < start[i]) {\n            outC[i] = start[i] * 2 - outC[i] - ").concat(l, ";\n          } else if(outC[i] >= end[i]) {\n            outC[i] = (end[i] - 1) * 2 - outC[i] + ").concat(l, ";\n          }\n        }\n        ").concat(a, " coords = outC - start;\n        setOutput(getX(").concat(i, "));\n      }\n    ") : "\n        int start = ".concat(s, ";\n        int end = ").concat(o, ";\n\n        void main() {\n          int outC = getOutputCoords();\n          if (outC < start) {\n            outC = start * 2 - outC - ").concat(l, ";\n          } else if(outC >= end) {\n            outC = (end - 1) * 2 - outC + ").concat(l, ";\n          }\n          setOutput(getX(outC - start));\n        }\n      ");
  }

}

class MirrorPadPackedProgram {
  constructor(e, t, n) {
    this.variableNames = ["x"], this.packedInputs = !0, this.packedOutput = !0, this.outputShape = t.map((t, n) => t[0] + e[n] + t[1]);
    var r = e.length,
        a = getCoordsDataType(r),
        s = t.map(e => e[0]).join(","),
        o = t.map((t, n) => t[0] + e[n]).join(","),
        i = getChannels("rc", r),
        l = getChannels("source", r),
        u = "".concat(i[r - 1], " < ").concat(this.outputShape[r - 1]),
        c = 1 === r ? "source" : "vec2(".concat(l.slice(-2).join(), ")"),
        p = "reflect" === n ? 0 : 1;
    var d = "";

    if (1 === r) {
      var _e1065 = "\n        ".concat(a, " source = rc;\n        if (source < start) {\n          source = start * 2 - source - ").concat(p, ";\n        } else if (source >= end) {\n          source = (end - 1) * 2 - source + ").concat(p, ";\n        }\n        source -= start;\n      ");

      d = "\n        ".concat(a, " rc = outputLoc;\n        ").concat(_e1065, "\n        result[0] = getChannel(getX(").concat(l.join(), "), ").concat(c, ");\n        ").concat(i[r - 1], " += 1;\n        if(").concat(u, ") {\n          ").concat(_e1065, "\n          result[1] = getChannel(getX(").concat(l.join(), "), ").concat(c, ");\n        }\n      ");
    } else {
      var _e1066 = "\n        ".concat(a, " source = rc;\n        ").concat(a, " lt = ").concat(a, "(lessThan(source, start));\n        ").concat(a, " gte = ").concat(a, "(greaterThanEqual(source, end));\n        ").concat(a, " orig = 1 - (lt + gte);\n        source = orig * source +\n                lt * (start * 2 - source - ").concat(p, ") +\n                gte * ((end - 1) * 2 - source + ").concat(p, ");\n        source -= start;\n      ");

      d = "\n        ".concat(a, " rc = outputLoc;\n        ").concat(_e1066, "\n        result[0] = getChannel(getX(").concat(l.join(), "), ").concat(c, ");\n        ").concat(i[r - 1], " += 1;\n        if(").concat(u, ") {\n          ").concat(_e1066, "\n          result[1] = getChannel(getX(").concat(l.join(), "), ").concat(c, ");\n        }\n        rc = outputLoc;\n        ").concat(i[r - 2], " += 1;\n        if(").concat(i[r - 2], " < ").concat(this.outputShape[r - 2], ") {\n          ").concat(_e1066, "\n          result[2] = getChannel(getX(").concat(l.join(), "), ").concat(c, ");\n          ").concat(i[r - 1], " += 1;\n          if(").concat(u, ") {\n            ").concat(_e1066, "\n            result[3] = getChannel(getX(").concat(l.join(), "), ").concat(c, ");\n          }\n        }\n      ");
    }

    this.userCode = "\n      const ".concat(a, " start = ").concat(a, "(").concat(s, ");\n      const ").concat(a, " end = ").concat(a, "(").concat(o, ");\n\n      void main() {\n        ").concat(a, " outputLoc = getOutputCoords();\n        vec4 result = vec4(0.);\n        ").concat(d, "\n        setOutput(result);\n      }\n    ");
  }

}

var mirrorPadKernelFunc = _ref72 => {
  var {
    inputs: e,
    backend: t,
    attrs: n
  } = _ref72;
  var {
    x: r
  } = e,
      {
    paddings: a,
    mode: s
  } = n,
      o = env().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new MirrorPadPackedProgram(r.shape, a, s) : new MirrorPadProgram(r.shape, a, s);
  return t.runWebGLProgram(o, [r], r.dtype);
},
    mirrorPadConfig = {
  kernelName: MirrorPad,
  backendName: "webgl",
  kernelFunc: mirrorPadKernelFunc
},
    MOD = "if (b == 0.0) return NAN;\n  return mod(a, b);",
    MOD_PACKED = "\n  vec4 result = mod(a, b);\n  vec4 isNaN = vec4(equal(b, vec4(0.0)));\n  " + CHECK_NAN_SNIPPET + "\n  return result;\n",
    mod = binaryKernelFunc({
  opSnippet: MOD,
  packedOpSnippet: MOD_PACKED
}),
    modConfig = {
  kernelName: Mod,
  backendName: "webgl",
  kernelFunc: mod
};

class MultinomialProgram {
  constructor(e, t, n) {
    this.variableNames = ["probs"], this.customUniforms = [{
      name: "seed",
      type: "float"
    }], this.outputShape = [e, n], this.userCode = "\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n\n        float r = random(seed);\n        float cdf = 0.0;\n\n        for (int i = 0; i < ".concat(t - 1, "; i++) {\n          cdf += getProbs(batch, i);\n\n          if (r < cdf) {\n            setOutput(float(i));\n            return;\n          }\n        }\n\n        // If no other event happened, last event happened.\n        setOutput(float(").concat(t - 1, "));\n      }\n    ");
  }

}

var DIV = "\nif (a == b) {\n  return 1.0;\n};\nreturn a / b;",
    DIV_PACKED = "\n  // vec4 one = vec4(equal(a, b));\n  // return one + (vec4(1.0) - one) * a / b;\n  vec4 result = a / b;\n  if(a.x == b.x) {\n    result.x = 1.;\n  }\n  if(a.y == b.y) {\n    result.y = 1.;\n  }\n  if(a.z == b.z) {\n    result.z = 1.;\n  }\n  if(a.w == b.w) {\n    result.w = 1.;\n  }\n\n  return result;\n",
    realDiv = binaryKernelFunc({
  opSnippet: DIV,
  packedOpSnippet: DIV_PACKED,
  checkOutOfBounds: !0
}),
    realDivConfig = {
  kernelName: RealDiv,
  backendName: "webgl",
  kernelFunc: realDiv
},
    SUB = "return a - b;",
    sub = binaryKernelFunc({
  opSnippet: SUB,
  packedOpSnippet: SUB,
  supportsComplex: !0,
  cpuKernelImpl: subImplCPU
}),
    subConfig = {
  kernelName: Sub,
  backendName: "webgl",
  kernelFunc: sub
};

function softmax(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    logits: a
  } = t,
      {
    dim: s
  } = r,
      o = parseAxisParam([s], a.shape),
      i = max({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      reductionIndices: o,
      keepDims: !1
    }
  }),
      l = expandShapeToKeepDim(i.shape, o),
      u = reshape({
    inputs: {
      x: i
    },
    backend: n,
    attrs: {
      shape: l
    }
  }),
      c = sub({
    inputs: {
      a,
      b: u
    },
    backend: n
  }),
      p = exp({
    inputs: {
      x: c
    },
    backend: n
  }),
      d = sum({
    inputs: {
      x: p
    },
    backend: n,
    attrs: {
      axis: o,
      keepDims: !1
    }
  }),
      h = reshape({
    inputs: {
      x: d
    },
    backend: n,
    attrs: {
      shape: l
    }
  }),
      m = realDiv({
    inputs: {
      a: p,
      b: h
    },
    backend: n
  });
  return n.disposeIntermediateTensorInfo(i), n.disposeIntermediateTensorInfo(u), n.disposeIntermediateTensorInfo(c), n.disposeIntermediateTensorInfo(p), n.disposeIntermediateTensorInfo(d), n.disposeIntermediateTensorInfo(h), m;
}

var softmaxConfig = {
  kernelName: Softmax$2,
  backendName: "webgl",
  kernelFunc: softmax
};

function multinomial(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    logits: a
  } = t,
      {
    numSamples: s,
    seed: o,
    normalized: i
  } = r,
      l = i ? a : softmax({
    inputs: {
      logits: a
    },
    backend: n,
    attrs: {
      dim: a.shape.length - 1
    }
  }),
      u = new MultinomialProgram(l.shape[0], l.shape[1], s),
      c = n.runWebGLProgram(u, [l], "int32", [[o]]);
  return i || n.disposeIntermediateTensorInfo(l), c;
}

var multinomialConfig = {
  kernelName: Multinomial,
  backendName: "webgl",
  kernelFunc: multinomial
},
    NEG = "return -x;";

function neg(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    x: r
  } = t;

  if (n.shouldExecuteOnCPU([r])) {
    var _e1067 = n.texData.get(r.dataId),
        [_t721, _a306] = negImplCPU(_e1067.values, r.shape, r.dtype);

    return n.makeTensorInfo(_a306, r.dtype, _t721);
  }

  var a;
  return a = env().getBool("WEBGL_PACK_UNARY_OPERATIONS") ? new UnaryOpPackedProgram(r.shape, NEG) : new UnaryOpProgram(r.shape, NEG), n.runWebGLProgram(a, [r], r.dtype);
}

var negConfig = {
  kernelName: Neg,
  backendName: "webgl",
  kernelFunc: neg
},
    nonMaxSuppressionV3Impl = nonMaxSuppressionV3Impl$2;

function nonMaxSuppressionV3(e) {
  warn("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    boxes: a,
    scores: s
  } = t,
      {
    maxOutputSize: o,
    iouThreshold: i,
    scoreThreshold: l
  } = r,
      u = n.readSync(a.dataId),
      c = n.readSync(s.dataId),
      {
    selectedIndices: p
  } = nonMaxSuppressionV3Impl(u, c, o, i, l);
  return n.makeTensorInfo([p.length], "int32", new Int32Array(p));
}

var nonMaxSuppressionV3Config = {
  kernelName: NonMaxSuppressionV3,
  backendName: "webgl",
  kernelFunc: nonMaxSuppressionV3
},
    nonMaxSuppressionV4Impl = nonMaxSuppressionV4Impl$2;

function nonMaxSuppressionV4(e) {
  warn("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    boxes: a,
    scores: s
  } = t,
      {
    maxOutputSize: o,
    iouThreshold: i,
    scoreThreshold: l,
    padToMaxOutputSize: u
  } = r,
      c = n.readSync(a.dataId),
      p = n.readSync(s.dataId),
      {
    selectedIndices: d,
    validOutputs: h
  } = nonMaxSuppressionV4Impl(c, p, o, i, l, u);
  return [n.makeTensorInfo([d.length], "int32", new Int32Array(d)), n.makeTensorInfo([], "int32", new Int32Array([h]))];
}

var nonMaxSuppressionV4Config = {
  kernelName: NonMaxSuppressionV4,
  backendName: "webgl",
  kernelFunc: nonMaxSuppressionV4
},
    nonMaxSuppressionV5Impl = nonMaxSuppressionV5Impl$2;

function nonMaxSuppressionV5(e) {
  warn("tf.nonMaxSuppression() in webgl locks the UI thread. Call tf.nonMaxSuppressionAsync() instead");
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    boxes: a,
    scores: s
  } = t,
      {
    maxOutputSize: o,
    iouThreshold: i,
    scoreThreshold: l,
    softNmsSigma: u
  } = r,
      c = n.readSync(a.dataId),
      p = n.readSync(s.dataId),
      d = o,
      h = i,
      m = l,
      f = u,
      {
    selectedIndices: g,
    selectedScores: $
  } = nonMaxSuppressionV5Impl(c, p, d, h, m, f);
  return [n.makeTensorInfo([g.length], "int32", new Int32Array(g)), n.makeTensorInfo([$.length], "float32", new Float32Array($))];
}

var nonMaxSuppressionV5Config = {
  kernelName: NonMaxSuppressionV5,
  backendName: "webgl",
  kernelFunc: nonMaxSuppressionV5
};

class OneHotProgram {
  constructor(e, t, n, r) {
    this.variableNames = ["indices"], this.outputShape = [e, t], this.userCode = "\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int index = round(getIndices(coords.x));\n        setOutput(mix(float(".concat(r, "), float(").concat(n, "),\n                      float(index == coords.y)));\n      }\n    ");
  }

}

var oneHot = e => {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    indices: a
  } = t,
      {
    depth: s,
    onValue: o,
    offValue: i
  } = r,
      l = sizeFromShape(a.shape),
      u = new OneHotProgram(l, s, o, i),
      c = reshape({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      shape: [l]
    }
  }),
      p = n.runWebGLProgram(u, [c], a.dtype);
  n.disposeIntermediateTensorInfo(c);
  var d = reshape({
    inputs: {
      x: p
    },
    backend: n,
    attrs: {
      shape: [...a.shape, s]
    }
  });
  return n.disposeIntermediateTensorInfo(p), d;
},
    oneHotConfig = {
  kernelName: OneHot,
  backendName: "webgl",
  kernelFunc: oneHot
};

function zerosLike(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    x: r
  } = t;

  if ("complex64" === r.dtype) {
    var _e1068 = real({
      inputs: {
        input: r
      },
      backend: n
    }),
        _t722 = zerosLike({
      inputs: {
        x: _e1068
      },
      backend: n
    }),
        a = imag({
      inputs: {
        input: r
      },
      backend: n
    }),
        s = zerosLike({
      inputs: {
        x: a
      },
      backend: n
    }),
        o = complex({
      inputs: {
        real: _t722,
        imag: s
      },
      backend: n
    });

    return n.disposeIntermediateTensorInfo(_e1068), n.disposeIntermediateTensorInfo(_t722), n.disposeIntermediateTensorInfo(a), n.disposeIntermediateTensorInfo(s), o;
  }

  return fill({
    attrs: {
      shape: r.shape,
      dtype: r.dtype,
      value: "string" === r.dtype ? "" : 0
    },
    backend: n
  });
}

var zerosLikeConfig = {
  kernelName: ZerosLike,
  backendName: "webgl",
  kernelFunc: zerosLike
};

function onesLike(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    x: r
  } = t;
  if ("string" === r.dtype) throw new Error("onesLike is not supported under string dtype");

  if ("complex64" === r.dtype) {
    var _e1069 = real({
      inputs: {
        input: r
      },
      backend: n
    }),
        _t723 = onesLike({
      inputs: {
        x: _e1069
      },
      backend: n
    }),
        a = imag({
      inputs: {
        input: r
      },
      backend: n
    }),
        s = zerosLike({
      inputs: {
        x: a
      },
      backend: n
    }),
        o = complex({
      inputs: {
        real: _t723,
        imag: s
      },
      backend: n
    });

    return n.disposeIntermediateTensorInfo(_e1069), n.disposeIntermediateTensorInfo(_t723), n.disposeIntermediateTensorInfo(a), n.disposeIntermediateTensorInfo(s), o;
  }

  return fill({
    attrs: {
      shape: r.shape,
      dtype: r.dtype,
      value: 1
    },
    backend: n
  });
}

var onesLikeConfig = {
  kernelName: OnesLike,
  backendName: "webgl",
  kernelFunc: onesLike
};

function pack(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    axis: a
  } = r;
  if (1 === t.length) return expandDims({
    inputs: {
      input: t[0]
    },
    backend: n,
    attrs: {
      dim: a
    }
  });
  var s = t[0].shape,
      o = t[0].dtype;
  t.forEach(e => {
    assertShapesMatch(s, e.shape, "All tensors passed to stack must have matching shapes"), assert$4(o === e.dtype, () => "All tensors passed to stack must have matching dtypes");
  });
  var i = [],
      l = concat({
    inputs: t.map(e => {
      var t = expandDims({
        inputs: {
          input: e
        },
        backend: n,
        attrs: {
          dim: a
        }
      });
      return i.push(t), t;
    }),
    backend: n,
    attrs: {
      axis: a
    }
  });
  return i.forEach(e => n.disposeIntermediateTensorInfo(e)), l;
}

var packConfig = {
  kernelName: Pack,
  backendName: "webgl",
  kernelFunc: pack
};

class PadProgram {
  constructor(e, t, n) {
    this.variableNames = ["x"], this.customUniforms = [{
      name: "value",
      type: "float"
    }], this.outputShape = t.map((t, n) => t[0] + e[n] + t[1]);
    var r = e.length,
        a = getCoordsDataType(r),
        s = t.map(e => e[0]).join(","),
        o = t.map((t, n) => t[0] + e[n]).join(","),
        i = ["coords[0]", "coords[1]", "coords[2]", "coords[3]"].slice(0, r);
    this.userCode = 1 !== r ? "\n      ".concat(a, " start = ").concat(a, "(").concat(s, ");\n      ").concat(a, " end = ").concat(a, "(").concat(o, ");\n\n      void main() {\n        ").concat(a, " outC = getOutputCoords();\n        if (any(lessThan(outC, start)) || any(greaterThanEqual(outC, end))) {\n          setOutput(value);\n        } else {\n          ").concat(a, " coords = outC - start;\n          setOutput(getX(").concat(i, "));\n        }\n      }\n    ") : "\n        int start = ".concat(s, ";\n        int end = ").concat(o, ";\n\n        void main() {\n          int outC = getOutputCoords();\n          if (outC < start || outC >= end) {\n            setOutput(value);\n          } else {\n            setOutput(getX(outC - start));\n          }\n        }\n      ");
  }

}

class PadPackedProgram {
  constructor(e, t, n) {
    this.variableNames = ["x"], this.packedInputs = !0, this.packedOutput = !0, this.customUniforms = [{
      name: "value",
      type: "float"
    }], this.outputShape = t.map((t, n) => t[0] + e[n] + t[1]);
    var r = e.length,
        a = getCoordsDataType(r),
        s = t.map(e => e[0]).join(","),
        o = t.map((t, n) => t[0] + e[n]).join(","),
        i = getChannels("rc", r),
        l = getChannels("source", r),
        u = "".concat(i[r - 1], " < ").concat(this.outputShape[r - 1]),
        c = 1 === r ? "source" : "vec2(".concat(l.slice(-2).join(), ")"),
        p = ["".concat(a, " rc = outputLoc;"), "".concat(i[r - 1], " += 1;\n       if(").concat(u, ") {\n      "), 1 === r ? "" : "}\n       rc = outputLoc;\n       ".concat(i[r - 2], " += 1;\n       if(").concat(i[r - 2], " < ").concat(this.outputShape[r - 2], ") {"), 1 === r ? "" : "  ".concat(i[r - 1], " += 1;\n         if(").concat(u, ") {")],
        d = 1 === r ? "rc < start || rc >= end" : "any(lessThan(rc, start)) || any(greaterThanEqual(rc, end))";
    var h = "";

    for (var _e1070 = 0, _t724 = 1 === r ? 2 : 4; _e1070 < _t724; _e1070++) {
      h += "\n        ".concat(p[_e1070], "\n        if (").concat(d, ") {\n          result[").concat(_e1070, "] = float(value);\n        } else {\n          ").concat(a, " source = rc - start;\n          result[").concat(_e1070, "] = getChannel(getX(").concat(l.join(), "), ").concat(c, ");\n        }\n      ");
    }

    h += 1 === r ? "} " : "}}", this.userCode = "\n      const ".concat(a, " start = ").concat(a, "(").concat(s, ");\n      const ").concat(a, " end = ").concat(a, "(").concat(o, ");\n\n      void main() {\n        ").concat(a, " outputLoc = getOutputCoords();\n        vec4 result = vec4(0.);\n        ").concat(h, "\n        setOutput(result);\n      }\n    ");
  }

}

var padV2 = e => {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    paddings: s,
    constantValue: o
  } = r,
      i = env().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new PadPackedProgram(a.shape, s, o) : new PadProgram(a.shape, s, o);
  return n.runWebGLProgram(i, [a], a.dtype, [[o]]);
},
    padV2Config = {
  kernelName: PadV2,
  backendName: "webgl",
  kernelFunc: padV2
},
    POW = "\n  if(a < 0.0 && floor(b) < b){\n    return NAN;\n  }\n  if (b == 0.0) {\n    return 1.0;\n  }\n  return (round(mod(b, 2.0)) != 1) ?\n      pow(abs(a), b) : sign(a) * pow(abs(a), b);\n",
    POW_PACKED = "\n  // isModRound1 has 1 for components with round(mod(b, 2.0)) == 1, 0 otherwise.\n  vec4 isModRound1 = vec4(equal(round(mod(b, 2.0)), ivec4(1)));\n  vec4 multiplier = sign(a) * isModRound1 + (vec4(1.0) - isModRound1);\n  vec4 result = multiplier * pow(abs(a), b);\n\n  // Ensure that a^0 = 1, including 0^0 = 1 as this correspond to TF and JS\n  bvec4 isExpZero = equal(b, vec4(0.0));\n  result.r = isExpZero.r ? 1.0 : result.r;\n  result.g = isExpZero.g ? 1.0 : result.g;\n  result.b = isExpZero.b ? 1.0 : result.b;\n  result.a = isExpZero.a ? 1.0 : result.a;\n\n  vec4 isNaN = vec4(lessThan(a, vec4(0.0))) * vec4(lessThan(floor(b), b));\n  " + CHECK_NAN_SNIPPET + "\n  return result;\n",
    pow = binaryKernelFunc({
  opSnippet: POW,
  packedOpSnippet: POW_PACKED
}),
    powConfig = {
  kernelName: Pow,
  backendName: "webgl",
  kernelFunc: pow
};

function prod(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    axis: s,
    keepDims: o
  } = r,
      i = a.shape.length,
      l = [],
      u = parseAxisParam(s, a.shape);
  var c = u;
  var p = getAxesPermutation(c, i);
  var d,
      h = a;

  if (null != p && (h = transpose({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      perm: p
    }
  }), c = getInnerMostAxes(c.length, i), l.push(h)), assertAxesAreInnerMostDims("prod", c, i), n.shouldExecuteOnCPU([h])) {
    var _e1071 = n.texData.get(h.dataId).values,
        {
      outVals: _t725,
      outShape: _r428,
      outDtype: _a307
    } = prodImplCPU(h.shape, h.dtype, _e1071, c);
    d = n.makeTensorInfo(_r428, _a307, _t725);
  } else {
    var [_e1072, _t726] = computeOutAndReduceShapes(h.shape, c),
        _r429 = sizeFromShape(_t726),
        _s220 = reshape({
      inputs: {
        x: h
      },
      backend: n,
      attrs: {
        shape: [-1, _r429]
      }
    }),
        _o155 = reduce(_s220, sumOutType(a.dtype), "prod", n);

    d = reshape({
      inputs: {
        x: _o155
      },
      backend: n,
      attrs: {
        shape: _e1072
      }
    }), l.push(_s220), l.push(_o155);
  }

  if (o) {
    l.push(d);

    var _e1073 = expandShapeToKeepDim(d.shape, u);

    d = reshape({
      inputs: {
        x: d
      },
      backend: n,
      attrs: {
        shape: _e1073
      }
    });
  }

  return l.forEach(e => n.disposeIntermediateTensorInfo(e)), d;
}

var prodConfig = {
  kernelName: Prod,
  backendName: "webgl",
  kernelFunc: prod
},
    range$1 = e => {
  var {
    backend: t,
    attrs: n
  } = e,
      {
    start: r,
    stop: a,
    step: s,
    dtype: o
  } = n,
      i = rangeImplCPU(r, a, s, o);
  return t.makeTensorInfo([i.length], o, i);
},
    rangeConfig = {
  kernelName: Range,
  backendName: "webgl",
  kernelFunc: range$1
},
    RECIPROCAL = "return 1.0 / x;",
    reciprocal = unaryKernelFunc({
  opSnippet: RECIPROCAL
}),
    reciprocalConfig = {
  kernelName: Reciprocal,
  backendName: "webgl",
  kernelFunc: reciprocal
},
    RELU = CHECK_NAN_SNIPPET$2 + "\n  return (x < 0.0) ? 0.0 : x;\n",
    RELU_PACKED = "\n  vec4 result = x * vec4(greaterThanEqual(x, vec4(0.0)));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n",
    relu$1 = unaryKernelFunc({
  opSnippet: RELU,
  packedOpSnippet: RELU_PACKED
}),
    reluConfig = {
  kernelName: Relu$1,
  backendName: "webgl",
  kernelFunc: relu$1
},
    RELU6 = CHECK_NAN_SNIPPET$2 + "\n  return (x < 0.0) ? 0.0 : min(6.0, x);\n",
    RELU6_PACKED = "\n  vec4 result = min(x, vec4(6.)) * vec4(greaterThanEqual(x, vec4(0.0)));\n  bvec4 isNaN = isnan(x);\n\n  result.r = isNaN.r ? x.r : result.r;\n  result.g = isNaN.g ? x.g : result.g;\n  result.b = isNaN.b ? x.b : result.b;\n  result.a = isNaN.a ? x.a : result.a;\n\n  return result;\n",
    relu6 = unaryKernelFunc({
  opSnippet: RELU6,
  packedOpSnippet: RELU6_PACKED
}),
    relu6Config = {
  kernelName: Relu6$1,
  backendName: "webgl",
  kernelFunc: relu6
};

class ResizeBilinearProgram {
  constructor(e, t, n, r, a) {
    this.variableNames = ["A"], this.outputShape = [];
    var [s, o, i, l] = e;
    this.outputShape = [s, t, n, l];
    var u = [r && t > 1 ? o - 1 : o, r && n > 1 ? i - 1 : i],
        c = [r && t > 1 ? t - 1 : t, r && n > 1 ? n - 1 : n];
    var p;
    p = a ? "(vec2(yRC) + vec2(0.5)) * effectiveInputOverOutputRatioRC - vec2(0.5)" : "vec2(yRC) * effectiveInputOverOutputRatioRC", this.userCode = "\n      const vec2 effectiveInputOverOutputRatioRC = vec2(\n          ".concat(u[0] / c[0], ",\n          ").concat(u[1] / c[1], ");\n      const vec2 inputShapeRC = vec2(").concat(o, ".0, ").concat(i, ".0);\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        ivec2 yRC = coords.yz;\n\n        // Fractional source index.\n        vec2 sourceFracIndexRC = ").concat(p, ";\n\n        // Compute the four integer indices.\n        ivec2 sourceFloorRC = ivec2(max(sourceFracIndexRC, vec2(0.0)));\n        ivec2 sourceCeilRC = ivec2(\n          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));\n\n        float topLeft = getA(b, sourceFloorRC.x, sourceFloorRC.y, d);\n        float bottomLeft = getA(b, sourceCeilRC.x, sourceFloorRC.y, d);\n        float topRight = getA(b, sourceFloorRC.x, sourceCeilRC.y, d);\n        float bottomRight = getA(b, sourceCeilRC.x, sourceCeilRC.y, d);\n\n        vec2 fracRC = sourceFracIndexRC - vec2(sourceFloorRC);\n\n        float top = topLeft + (topRight - topLeft) * fracRC.y;\n        float bottom = bottomLeft + (bottomRight - bottomLeft) * fracRC.y;\n        float newValue = top + (bottom - top) * fracRC.x;\n\n        setOutput(newValue);\n      }\n    ");
  }

}

class ResizeBilinearPackedProgram {
  constructor(e, t, n, r, a) {
    this.variableNames = ["A"], this.packedInputs = !0, this.packedOutput = !0, this.outputShape = [];
    var [s, o, i, l] = e;
    this.outputShape = [s, t, n, l];
    var u = [r && t > 1 ? o - 1 : o, r && n > 1 ? i - 1 : i],
        c = [r && t > 1 ? t - 1 : t, r && n > 1 ? n - 1 : n];
    var p;
    p = a ? "(vec3(yRC) + vec3(0.5)) * effectiveInputOverOutputRatioRC - vec3(0.5)" : "vec3(yRC) * effectiveInputOverOutputRatioRC", this.userCode = "\n      const vec3 effectiveInputOverOutputRatioRC = vec3(\n          ".concat(u[0] / c[0], ",\n          ").concat(u[1] / c[1], ",\n          ").concat(u[1] / c[1], ");\n      const vec3 inputShapeRC = vec3(").concat(o, ".0, ").concat(i, ".0,\n                                     ").concat(i, ".0);\n\n      float getAValue(int b, int r, int c, int d) {\n        return getChannel(getA(b, r, c, d), vec2(c, d));\n      }\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        // Calculate values for next column in yRC.z.\n        ivec3 yRC = coords.yzz + ivec3(0, 0, 1);\n\n        // Fractional source index.\n        vec3 sourceFracIndexRC = ").concat(p, ";\n\n        // Compute the four integer indices.\n        ivec3 sourceFloorRC = ivec3(max(sourceFracIndexRC, vec3(0.0)));\n        ivec3 sourceCeilRC = ivec3(\n          min(inputShapeRC - 1.0, ceil(sourceFracIndexRC)));\n\n        // Should we calculate next column and row elements in 2x2 packed cell.\n        bool hasNextCol = d < ").concat(l - 1, ";\n        bool hasNextRow = coords.z < ").concat(n - 1, ";\n\n        // In parallel, construct four corners for all four components in\n        // packed 2x2 cell.\n        vec4 topLeft = vec4(\n          getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d),\n          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceFloorRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceFloorRC.x, sourceFloorRC.z, d + 1) : 0.0);\n\n        vec4 bottomLeft = vec4(\n          getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d),\n          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceFloorRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceCeilRC.x, sourceFloorRC.z, d + 1) : 0.0);\n\n        vec4 topRight = vec4(\n          getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d),\n          hasNextCol ? getAValue(b, sourceFloorRC.x, sourceCeilRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceFloorRC.x, sourceCeilRC.z, d + 1) : 0.0);\n\n        vec4 bottomRight = vec4(\n          getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d),\n          hasNextCol ? getAValue(b, sourceCeilRC.x, sourceCeilRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceCeilRC.x, sourceCeilRC.z, d + 1) : 0.0);\n\n        vec3 fracRC = sourceFracIndexRC - vec3(sourceFloorRC);\n\n        vec4 top = mix(topLeft, topRight, fracRC.yyzz);\n        vec4 bottom = mix(bottomLeft, bottomRight, fracRC.yyzz);\n        vec4 newValue = mix(top, bottom, fracRC.x);\n\n        setOutput(newValue);\n      }\n    ");
  }

}

function resizeBilinear(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    images: a
  } = t,
      {
    alignCorners: s,
    halfPixelCenters: o,
    size: i
  } = r,
      [l, u] = i,
      c = env().getBool("WEBGL_PACK_IMAGE_OPERATIONS") ? new ResizeBilinearPackedProgram(a.shape, l, u, s, o) : new ResizeBilinearProgram(a.shape, l, u, s, o);
  return n.runWebGLProgram(c, [a], "float32");
}

var resizeBilinearConfig = {
  kernelName: ResizeBilinear,
  backendName: "webgl",
  kernelFunc: resizeBilinear
};

class ResizeBilinearBackpropProgram {
  constructor(e, t, n) {
    this.variableNames = ["dy"], this.outputShape = [], this.outputShape = t;
    var [, r, a] = t,
        [, s, o] = e,
        i = [n && s > 1 ? r - 1 : r, n && o > 1 ? a - 1 : a],
        l = [n && s > 1 ? s - 1 : s, n && o > 1 ? o - 1 : o],
        u = i[0] / l[0],
        c = i[1] / l[1],
        p = 1 / u,
        d = 1 / c,
        h = 2 * Math.ceil(p) + 2,
        m = 2 * Math.ceil(d) + 2;
    this.userCode = "\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        int r = coords[1];\n        int c = coords[2];\n\n        float accumulator = 0.0;\n\n        const float heightScale = float(".concat(u, ");\n        const float widthScale = float(").concat(c, ");\n\n        const float invHeightScale = float(").concat(p, ");\n        const float invWidthScale = float(").concat(d, ");\n\n        const int winHeight = int(").concat(h, ");\n        const int winWidth = int(").concat(m, ");\n\n        // Compute bounds for where in dy we will look\n        float startRLerp = floor(float(r) * invHeightScale);\n        int startDyR = int(startRLerp - float(winHeight / 2));\n\n        float startCLerp = floor(float(c) * invWidthScale);\n        int startDyC = int(startCLerp - float(winWidth / 2));\n\n        // Loop over dy\n        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {\n          int dyR = dyROffset + startDyR;\n\n          // Guard against the window exceeding the bounds of dy\n          if (dyR < 0 || dyR >= ").concat(s, ") {\n            continue;\n          }\n\n          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {\n            int dyC = dyCOffset + startDyC;\n\n            // Guard against the window exceeding the bounds of dy\n            if (dyC < 0 || dyC >= ").concat(o, ") {\n              continue;\n            }\n\n            float dxR = float(dyR) * heightScale;\n            int topDxRIndex = int(floor(dxR));\n            int bottomDxRIndex = int(min(ceil(dxR), ").concat(r - 1, ".0));\n            float dxRLerp = dxR - float(topDxRIndex);\n            float inverseDxRLerp = 1.0 - dxRLerp;\n\n            float dxC = float(dyC) * widthScale;\n            int leftDxCIndex = int(floor(dxC));\n            int rightDxCIndex = int(min(ceil(dxC), ").concat(a - 1, ".0));\n            float dxCLerp = dxC - float(leftDxCIndex);\n            float inverseDxCLerp = 1.0 - dxCLerp;\n\n            if (r == topDxRIndex && c == leftDxCIndex) {\n              // topLeft\n              accumulator +=\n                getDy(b, dyR, dyC, d) * inverseDxRLerp * inverseDxCLerp;\n            }\n\n            if (r == topDxRIndex && c == rightDxCIndex) {\n              // topRight\n              accumulator += getDy(b, dyR, dyC, d) * inverseDxRLerp * dxCLerp;\n            }\n\n            if (r == bottomDxRIndex && c == leftDxCIndex) {\n              // bottomLeft\n              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * inverseDxCLerp;\n            }\n\n            if (r == bottomDxRIndex && c == rightDxCIndex) {\n              // bottomRight\n              accumulator += getDy(b, dyR, dyC, d) * dxRLerp * dxCLerp;\n            }\n          }\n        }\n        // End loop over dy\n\n        setOutput(accumulator);\n      }\n    ");
  }

}

function resizeBilinearGrad(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    images: a,
    dy: s
  } = t,
      {
    alignCorners: o
  } = r,
      i = new ResizeBilinearBackpropProgram(s.shape, a.shape, o);
  return n.runWebGLProgram(i, [s], s.dtype);
}

var resizeBilinearGradConfig = {
  kernelName: ResizeBilinearGrad,
  backendName: "webgl",
  kernelFunc: resizeBilinearGrad
};

class ResizeNearestNeighborProgram {
  constructor(e, t, n, r, a) {
    this.variableNames = ["A"], this.outputShape = [];
    var [s, o, i, l] = e;
    this.outputShape = [s, t, n, l];
    var u = [r && t > 1 ? o - 1 : o, r && n > 1 ? i - 1 : i],
        c = [r && t > 1 ? t - 1 : t, r && n > 1 ? n - 1 : n];
    var p;
    p = a ? "max((vec2(yRC) + vec2(0.5)) * effectiveInputOverOutputRatioRC, vec2(0.0))" : "vec2(yRC) * effectiveInputOverOutputRatioRC", this.userCode = "\n      const vec2 effectiveInputOverOutputRatioRC = vec2(\n          ".concat(u[0] / c[0], ",\n          ").concat(u[1] / c[1], ");\n      const vec2 inputShapeRC = vec2(").concat(o, ".0, ").concat(i, ".0);\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        ivec2 yRC = coords.yz;\n\n        // Fractional source index.\n        vec2 sourceFracIndexRC = ").concat(p, ";\n\n        // Compute the coordinators of nearest neighbor point.\n        ivec2 sourceNearestRC = ivec2(\n          min(inputShapeRC - 1.0, floor(sourceFracIndexRC + ").concat(r ? "0.5" : "0.0", ")));\n        float newValue = getA(b, sourceNearestRC.x, sourceNearestRC.y, d);\n\n        setOutput(newValue);\n      }\n    ");
  }

}

class ResizeNearestNeighborPackedProgram {
  constructor(e, t, n, r, a) {
    this.variableNames = ["A"], this.packedInputs = !0, this.packedOutput = !0, this.outputShape = [];
    var [s, o, i, l] = e;
    this.outputShape = [s, t, n, l];
    var u = [r && t > 1 ? o - 1 : o, r && n > 1 ? i - 1 : i],
        c = [r && t > 1 ? t - 1 : t, r && n > 1 ? n - 1 : n];
    var p;
    p = a ? "max((vec3(yRC) + vec3(0.5)) * effectiveInputOverOutputRatioRC, vec3(0.0))" : "vec3(yRC) * effectiveInputOverOutputRatioRC", this.userCode = "\n      const vec3 effectiveInputOverOutputRatioRC = vec3(\n          ".concat(u[0] / c[0], ",\n          ").concat(u[1] / c[1], ",\n          ").concat(u[1] / c[1], ");\n      const vec3 inputShapeRC = vec3(").concat(o, ".0, ").concat(i, ".0,\n                                     ").concat(i, ".0);\n\n      float getAValue(int b, int r, int c, int d) {\n        return getChannel(getA(b, r, c, d), vec2(c, d));\n      }\n\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        // Calculate values for next column in yRC.z.\n        ivec3 yRC = coords.yzz + ivec3(0, 0, 1);\n\n        // Fractional source index.\n        vec3 sourceFracIndexRC = ").concat(p, ";\n\n        // Compute the coordinators of nearest neighbor point.\n        ivec3 sourceNearestRC = ivec3(\n          min(inputShapeRC - 1.0, floor(sourceFracIndexRC + ").concat(r ? "0.5" : "0.0", ")));\n\n        // Should we calculate next column and row elements in 2x2 packed cell.\n        bool hasNextCol = d < ").concat(l - 1, ";\n        bool hasNextRow = coords.z < ").concat(n - 1, ";\n\n        vec4 newValue = vec4(\n          getAValue(b, sourceNearestRC.x, sourceNearestRC.y, d),\n          hasNextCol ? getAValue(b, sourceNearestRC.x, sourceNearestRC.y, d + 1)\n                     : 0.0,\n          hasNextRow ? getAValue(b, sourceNearestRC.x, sourceNearestRC.z, d)\n                     : 0.0,\n          (hasNextRow && hasNextCol) ?\n            getAValue(b, sourceNearestRC.x, sourceNearestRC.z, d + 1) : 0.0);\n\n        setOutput(newValue);\n      }\n    ");
  }

}

function resizeNearestNeighbor(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    images: a
  } = t,
      {
    alignCorners: s,
    halfPixelCenters: o,
    size: i
  } = r,
      [l, u] = i,
      c = env().getBool("WEBGL_PACK_IMAGE_OPERATIONS") ? new ResizeNearestNeighborPackedProgram(a.shape, l, u, s, o) : new ResizeNearestNeighborProgram(a.shape, l, u, s, o);
  return n.runWebGLProgram(c, [a], a.dtype);
}

var resizeNearestNeighborConfig = {
  kernelName: ResizeNearestNeighbor,
  backendName: "webgl",
  kernelFunc: resizeNearestNeighbor
};

class ResizeNearestNeigborBackpropProgram {
  constructor(e, t, n) {
    this.variableNames = ["dy"], this.outputShape = [], this.outputShape = t;
    var [, r, a] = t,
        [, s, o] = e,
        i = [n && s > 1 ? r - 1 : r, n && o > 1 ? a - 1 : a],
        l = [n && s > 1 ? s - 1 : s, n && o > 1 ? o - 1 : o],
        u = i[0] / l[0],
        c = i[1] / l[1],
        p = 1 / u,
        d = 1 / c,
        h = 2 * Math.ceil(p) + 2,
        m = 2 * Math.ceil(d) + 2;
    this.userCode = "\n      void main() {\n        ivec4 coords = getOutputCoords();\n        int b = coords[0];\n        int d = coords[3];\n        int r = coords[1];\n        int c = coords[2];\n\n        float accumulator = 0.0;\n\n        const float heightScale = float(".concat(u, ");\n        const float widthScale = float(").concat(c, ");\n\n        const float invHeightScale = float(").concat(p, ");\n        const float invWidthScale = float(").concat(d, ");\n\n        const int winHeight = int(").concat(h, ");\n        const int winWidth = int(").concat(m, ");\n\n        // Compute bounds for where in dy we will look\n        float startRLerp = floor(float(r) * invHeightScale);\n        int startDyR = int(floor(startRLerp - float(winHeight / 2)));\n\n        float startCLerp = floor(float(c) * invWidthScale);\n        int startDyC = int(floor(startCLerp - float(winWidth / 2)));\n\n        // Loop over dy\n        for (int dyROffset = 0; dyROffset < winHeight; dyROffset++) {\n          int dyR = dyROffset + startDyR;\n\n          // Guard against the window exceeding the bounds of dy\n          if (dyR < 0 || dyR >= ").concat(s, ") {\n            continue;\n          }\n\n          for (int dyCOffset = 0; dyCOffset < winWidth; dyCOffset++) {\n            int dyC = dyCOffset + startDyC;\n\n            // Guard against the window exceeding the bounds of dy\n            if (dyC < 0 || dyC >= ").concat(o, ") {\n              continue;\n            }\n\n            float sourceFracRow =\n              float(").concat(i[0], ") *\n                (float(dyR) / float(").concat(l[0], "));\n\n            float sourceFracCol =\n                float(").concat(i[1], ") *\n                  (float(dyC) / float(").concat(l[1], "));\n\n            int sourceNearestRow = int(min(\n                float(int(").concat(r, ") - 1),\n                ").concat(n, " ? float(round(sourceFracRow)) :\n                                  float(floor(sourceFracRow))));\n\n            int sourceNearestCol = int(min(\n                float(int(").concat(a, ") - 1),\n                ").concat(n, " ? float(round(sourceFracCol)) :\n                                  float(floor(sourceFracCol))));\n\n            if (r == sourceNearestRow && c == sourceNearestCol) {\n              accumulator += getDy(b, dyR, dyC, d);\n            }\n          }\n        }\n        // End loop over dy\n\n        setOutput(accumulator);\n      }\n    ");
  }

}

function resizeNearestNeighborGrad(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    images: a,
    dy: s
  } = t,
      {
    alignCorners: o
  } = r,
      i = new ResizeNearestNeigborBackpropProgram(s.shape, a.shape, o);
  return n.runWebGLProgram(i, [s], s.dtype);
}

var resizeNearestNeighborGradConfig = {
  kernelName: ResizeNearestNeighborGrad,
  backendName: "webgl",
  kernelFunc: resizeNearestNeighborGrad
};

class ReverseProgram {
  constructor(e, t) {
    this.variableNames = ["x"];
    var n = e.length;
    if (n > 4) throw new Error("WebGL backend: Reverse of rank-".concat(n, " tensor is not yet supported"));
    if (this.outputShape = e, 1 === n) return void (this.userCode = "\n        void main() {\n          int coord = getOutputCoords();\n          setOutput(getX(".concat(e[0], " - coord - 1));\n        }\n      "));
    var r = e.map((n, r) => (n => -1 !== t.indexOf(n) && 1 !== e[n] ? "".concat(e[n], " - coords[").concat(n, "] - 1") : "coords[".concat(n, "]"))(r)).join(","),
        a = getCoordsDataType(n);
    this.userCode = "\n      void main() {\n        ".concat(a, " coords = getOutputCoords();\n        setOutput(getX(").concat(r, "));\n      }\n    ");
  }

}

class ReversePackedProgram {
  constructor(e, t) {
    this.variableNames = ["x"], this.packedInputs = !0, this.packedOutput = !0;
    var n = e.length;
    if (n > 4) throw new Error("WebGL backend: Reverse of rank-".concat(n, " tensor is not yet supported"));
    this.outputShape = e;
    var r = getChannels("rc", n),
        a = "".concat(r[n - 1], " + 1 < ").concat(this.outputShape[n - 1]),
        s = "".concat(r[n - 2], " + 1 < ").concat(this.outputShape[n - 2]),
        o = getCoordsDataType(n);

    function i(n) {
      var r = e.map((r, a) => function (n, r) {
        return -1 !== t.indexOf(n) && 1 !== e[n] ? "".concat(e[n], " - ").concat(r[n], " - 1") : "".concat(r[n]);
      }(a, n));
      return "getChannel(getX(".concat(r.join(","), "), vec2(").concat(r.slice(-2).join(","), "))");
    }

    this.userCode = 1 === n ? "\n        void main(){\n          int rc = getOutputCoords();\n          vec4 result = vec4(0.);\n          result.r = getChannel(getX(".concat(e[0], " - rc - 1),\n            ").concat(e[0], " - rc - 1);\n          if(").concat(a, "){\n              result.g = getChannel(getX(").concat(e[0], " - (rc  + 1) - 1),\n                ").concat(e[0], " - (rc  + 1) - 1);\n          }\n          setOutput(result);\n        }\n      ") : "\n        void main() {\n          ".concat(o, " rc = getOutputCoords();\n          vec4 result = vec4(0.);\n          result.r = ").concat(function (e) {
      return i(e);
    }(r.slice()), ";\n          if(").concat(a, "){\n            result.g = ").concat(function (e) {
      return e[n - 1] = "(" + e[n - 1] + " + 1)", i(e);
    }(r.slice()), ";\n          }\n          if(").concat(s, ") {\n            result.b = ").concat(function (e) {
      return e[n - 2] = "(" + e[n - 2] + " + 1)", i(e);
    }(r.slice()), ";\n            if(").concat(a, ") {\n              result.a = ").concat(function (e) {
      return e[n - 1] = "(" + e[n - 1] + " + 1)", e[n - 2] = "(" + e[n - 2] + " + 1)", i(e);
    }(r.slice()), ";\n            }\n          }\n          setOutput(result);\n        }\n    ");
  }

}

function reverse(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    dims: s
  } = r,
      o = a.shape.length,
      i = parseAxisParam(s, a.shape);
  if (0 === o) return identity({
    inputs: {
      x: a
    },
    backend: n
  });
  var l = env().getBool("WEBGL_PACK_ARRAY_OPERATIONS") ? new ReversePackedProgram(a.shape, i) : new ReverseProgram(a.shape, i);
  return n.runWebGLProgram(l, [a], a.dtype);
}

var reverseConfig = {
  kernelName: Reverse,
  backendName: "webgl",
  kernelFunc: reverse
};

class RotateProgram {
  constructor(e, t) {
    this.variableNames = ["Image"], this.outputShape = [], this.customUniforms = [{
      name: "params",
      type: "vec4"
    }];
    var n = e[1],
        r = e[2];
    this.outputShape = e;
    var a = "";
    a = "number" == typeof t ? "float outputValue = ".concat(t.toFixed(2), ";") : "\n        vec3 fill = vec3(".concat(t.join(","), ");\n        float outputValue = fill[coords[3]];"), this.userCode = "\n        void main() {\n          ivec4 coords = getOutputCoords();\n          int x = coords[2];\n          int y = coords[1];\n          float coordXFloat = (float(x) - params[0]) * params[3] -\n            (float(y) - params[1]) * params[2];\n          float coordYFloat = (float(x) - params[0]) * params[2] +\n            (float(y) - params[1]) * params[3];\n          int coordX = int(round(coordXFloat + params[0]));\n          int coordY = int(round(coordYFloat + params[1]));\n          ".concat(a, "\n          if(coordX >= 0 && coordX < ").concat(r, " && coordY >= 0 && coordY < ").concat(n, ") {\n            outputValue = getImage(coords[0], coordY, coordX, coords[3]);\n          }\n          setOutput(outputValue);\n        }\n    ");
  }

}

var rotateWithOffsetConfig = {
  kernelName: RotateWithOffset,
  backendName: "webgl",
  kernelFunc: _ref73 => {
    var {
      inputs: e,
      attrs: t,
      backend: n
    } = _ref73;
    var {
      image: r
    } = e,
        {
      radians: a,
      fillValue: s,
      center: o
    } = t,
        i = n,
        l = new RotateProgram(r.shape, s),
        [u, c] = getImageCenter(o, r.shape[1], r.shape[2]),
        p = [[u, c, Math.sin(a), Math.cos(a)]];
    return i.runWebGLProgram(l, [r], r.dtype, p);
  }
},
    ROUND = "\n  // OpenGL ES does not support round function.\n  // The algorithm is based on banker's rounding.\n  float base = floor(x);\n  if ((x - base) < 0.5) {\n    return floor(x);\n  } else if ((x - base) > 0.5) {\n    return ceil(x);\n  } else {\n    if (mod(base, 2.0) == 0.0) {\n      return base;\n    } else {\n      return base + 1.0;\n    }\n  }\n",
    round = unaryKernelFunc({
  opSnippet: ROUND
}),
    roundConfig = {
  kernelName: Round,
  backendName: "webgl",
  kernelFunc: round
},
    RSQRT = "return inversesqrt(x);",
    rsqrt = unaryKernelFunc({
  opSnippet: RSQRT,
  cpuKernelImpl: rsqrtImplCPU
}),
    rsqrtConfig = {
  kernelName: Rsqrt,
  backendName: "webgl",
  kernelFunc: rsqrt
};

class ScatterProgram {
  constructor(e, t, n, r, a, s) {
    var o = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : !0;
    this.variableNames = ["updates", "indices", "defaultValue"], this.outputShape = s;
    var i = getCoordsDataType(a.length),
        l = getCoordsDataType(s.length);
    var u = "";
    1 === n ? u = "i" : 2 === n && (u = "i, j");
    var c = "";
    1 === r ? c = "i" : 2 === r && (c = "i, coords[1]"), this.userCode = "\n        ".concat(i, " strides = ").concat(i, "(").concat(a, ");\n\n        void main() {\n          ").concat(l, " coords = getOutputCoords();\n          float sum = 0.0;\n          bool found = false;\n          for (int i = 0; i < ").concat(e, "; i++) {\n            int flattenedIndex = 0;\n            for (int j = 0; j < ").concat(t, "; j++) {\n              int index = round(getIndices(").concat(u, "));\n              flattenedIndex += index * ").concat(t > 1 ? "strides[j]" : "strides", ";\n            }\n            if (flattenedIndex == coords[0]) {\n              sum += getUpdates(").concat(c, ");\n              found = true;\n            }\n          }\n          setOutput(mix(getDefaultValue(), sum, float(found)));\n        }\n      ");
  }

}

function scatterNd(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    indices: a,
    updates: s
  } = t,
      {
    shape: o
  } = r,
      {
    sliceRank: i,
    numUpdates: l,
    sliceSize: u,
    strides: c,
    outputSize: p
  } = calculateShapes(s, a, o),
      d = [p / u, u];
  if (0 === p) return n.makeTensorInfo(o, a.dtype);
  var h = reshape({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      shape: [l, i]
    }
  }),
      m = reshape({
    inputs: {
      x: s
    },
    backend: n,
    attrs: {
      shape: [l, u]
    }
  }),
      f = n.makeTensorInfo([], "float32", new Float32Array([0])),
      g = new ScatterProgram(l, i, h.shape.length, m.shape.length, c, d),
      $ = n.runWebGLProgram(g, [m, h, f], m.dtype),
      y = reshape({
    inputs: {
      x: $
    },
    backend: n,
    attrs: {
      shape: o
    }
  });
  return n.disposeIntermediateTensorInfo(h), n.disposeIntermediateTensorInfo(m), n.disposeIntermediateTensorInfo($), n.disposeIntermediateTensorInfo(f), y;
}

var scatterNdConfig = {
  kernelName: ScatterNd,
  backendName: "webgl",
  kernelFunc: scatterNd
};

class SelectProgram {
  constructor(e, t, n) {
    var r, a;
    if (this.variableNames = ["c", "a", "b"], this.outputShape = t, n > 4) throw Error("Where for rank ".concat(n, " is not yet supported"));
    if (1 === n) a = "resRC", r = "resRC";else {
      var _n438 = ["resRC.x", "resRC.y", "resRC.z", "resRC.w"],
          _s221 = [],
          o = [];

      for (var _r430 = 0; _r430 < t.length; _r430++) {
        o.push("".concat(_n438[_r430])), _r430 < e && _s221.push("".concat(_n438[_r430]));
      }

      r = _s221.join(), a = o.join();
    }
    var s = getCoordsDataType(n);
    this.userCode = "\n      void main() {\n        ".concat(s, " resRC = getOutputCoords();\n        float cVal = getC(").concat(r, ");\n        if (cVal >= 1.0) {\n          setOutput(getA(").concat(a, "));\n        } else {\n          setOutput(getB(").concat(a, "));\n        }\n      }\n    ");
  }

}

function select(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    condition: r,
    t: a,
    e: s
  } = t,
      o = new SelectProgram(r.shape.length, a.shape, a.shape.length);
  return n.runWebGLProgram(o, [r, a, s], upcastType(a.dtype, s.dtype));
}

var selectConfig = {
  kernelName: Select,
  backendName: "webgl",
  kernelFunc: select
},
    SELU = "\n  // Stable and Attracting Fixed Point (0, 1) for Normalized Weights.\n  // see: https://arxiv.org/abs/1706.02515\n  float scaleAlpha = ".concat(SELU_SCALEALPHA, ";\n  float scale = ").concat(SELU_SCALE, ";\n  return (x >= 0.0) ? scale * x : scaleAlpha * (exp(x) - 1.0);\n"),
    selu = unaryKernelFunc({
  opSnippet: SELU
}),
    seluConfig = {
  kernelName: Selu$1,
  backendName: "webgl",
  kernelFunc: selu
},
    SIGMOID = "return 1.0 / (1.0 + exp(-1.0 * x));",
    sigmoid = unaryKernelFunc({
  opSnippet: SIGMOID
}),
    sigmoidConfig = {
  kernelName: Sigmoid$1,
  backendName: "webgl",
  kernelFunc: sigmoid
},
    SIGN = "\n  if (isnan(x)) { return 0.0; }\n  return sign(x);\n",
    sign = unaryKernelFunc({
  opSnippet: SIGN
}),
    signConfig = {
  kernelName: Sign,
  backendName: "webgl",
  kernelFunc: sign
},
    SIN = CHECK_NAN_SNIPPET_UNARY + "\n  return sin(x);\n",
    sin = unaryKernelFunc({
  opSnippet: SIN
}),
    sinConfig = {
  kernelName: Sin,
  backendName: "webgl",
  kernelFunc: sin
},
    SINH = "\n  float e2x = exp(x);\n  return (e2x - 1.0 / e2x) / 2.0;\n",
    sinh = unaryKernelFunc({
  opSnippet: SINH
}),
    sinhConfig = {
  kernelName: Sinh,
  backendName: "webgl",
  kernelFunc: sinh
},
    SOFTPLUS = "\n  float epsilon = 1.1920928955078125e-7;\n  float threshold = log(epsilon) + 2.0;\n\n  bool too_large = x > -threshold;\n  bool too_small = x < threshold;\n\n  float result;\n  float exp_x = exp(x);\n\n  if (too_large){\n    result = x;\n  }\n  else if (too_small){\n    result = exp_x;\n  }\n  else{\n    result = log(exp_x + 1.0);\n  }\n  return result;\n",
    softplus = unaryKernelFunc({
  opSnippet: SOFTPLUS
}),
    softplusConfig = {
  kernelName: Softplus$1,
  backendName: "webgl",
  kernelFunc: softplus
},
    spaceToBatchND = e => {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    blockShape: s,
    paddings: o
  } = r;
  assert$4(a.shape.length <= 4, () => "spaceToBatchND for rank > 4 with a WebGL backend not implemented yet");
  var i = s.reduce((e, t) => e * t),
      l = [[0, 0]];
  l.push(...o);

  for (var _e1074 = 1 + s.length; _e1074 < a.shape.length; ++_e1074) {
    l.push([0, 0]);
  }

  var u = [],
      c = padV2({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      paddings: l,
      constantValue: 0
    }
  }),
      p = getReshaped(c.shape, s, i, !1),
      d = getPermuted(p.length, s.length, !1),
      h = getReshapedPermuted(c.shape, s, i, !1),
      m = reshape({
    inputs: {
      x: c
    },
    backend: n,
    attrs: {
      shape: p
    }
  }),
      f = transpose({
    inputs: {
      x: m
    },
    backend: n,
    attrs: {
      perm: d
    }
  }),
      g = reshape({
    inputs: {
      x: f
    },
    backend: n,
    attrs: {
      shape: h
    }
  });
  return u.push(c), u.push(m), u.push(f), u.forEach(e => n.disposeIntermediateTensorInfo(e)), g;
},
    spaceToBatchNDConfig = {
  kernelName: SpaceToBatchND,
  backendName: "webgl",
  kernelFunc: spaceToBatchND
};

function sparseFillEmptyRows(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    indices: r,
    values: a,
    denseShape: s,
    defaultValue: o
  } = t;
  if (1 !== s.shape.length) throw new Error("Dense shape must be a vector, saw:\n         ".concat(s.shape));
  if (2 !== r.shape.length) throw new Error("Indices must be a matrix, saw:\n         ".concat(r.shape));
  if (1 !== a.shape.length) throw new Error("Values must be a vector, saw:\n         ".concat(a.shape));
  if (0 !== o.shape.length) throw new Error("Default value must be a scalar, saw:\n        ".concat(o.shape));
  var i = n.readSync(r.dataId),
      l = n.readSync(a.dataId),
      u = n.readSync(s.dataId),
      c = n.readSync(o.dataId)[0],
      [p, d, h, m, f] = sparseFillEmptyRowsImplCPU(i, r.shape, r.dtype, l, a.dtype, u, c);
  return [n.makeTensorInfo(d, r.dtype, p), n.makeTensorInfo([d[0]], a.dtype, h), n.makeTensorInfo([m.length], "bool", new Uint8Array(m.map(e => Number(e)))), n.makeTensorInfo([f.length], r.dtype, new Int32Array(f))];
}

var sparseFillEmptyRowsConfig = {
  kernelName: SparseFillEmptyRows,
  backendName: "webgl",
  kernelFunc: sparseFillEmptyRows
};

function sparseReshape(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    inputIndices: r,
    inputShape: a,
    newShape: s
  } = t;
  if (2 !== r.shape.length) throw new Error("Input indices should be a matrix but received shape ".concat(r.shape));
  if (1 !== a.shape.length) throw new Error("Input shape should be a vector but received shape ".concat(a.shape));
  if (1 !== s.shape.length) throw new Error("Target shape should be a vector but received shape ".concat(s.shape));
  var o = Array.from(n.readSync(a.dataId)),
      i = n.readSync(r.dataId),
      l = Array.from(n.readSync(s.dataId)),
      [u, c, p] = sparseReshapeImplCPU(i, r.shape, r.dtype, o, l);
  return [n.makeTensorInfo(c, r.dtype, u), n.makeTensorInfo([p.length], s.dtype, new Int32Array(p))];
}

var sparseReshapeConfig = {
  kernelName: SparseReshape,
  backendName: "webgl",
  kernelFunc: sparseReshape
};

function sparseSegmentMean(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    data: r,
    indices: a,
    segmentIds: s
  } = t;
  if (r.shape.length < 1) throw new Error("Data should be at least 1 dimensional but received scalar");
  if (1 !== a.shape.length) throw new Error("Indices should be a vector but received shape\n              ".concat(a.shape));
  if (1 !== s.shape.length) throw new Error("Segment ids should be a vector but received shape\n              ".concat(s.shape));
  var o = n.readSync(r.dataId),
      i = n.readSync(a.dataId),
      l = n.readSync(s.dataId),
      [u, c] = sparseSegmentReductionImplCPU(o, r.shape, r.dtype, i, l, !0);
  return n.makeTensorInfo(c, r.dtype, u);
}

var sparseSegmentMeanConfig = {
  kernelName: SparseSegmentMean,
  backendName: "webgl",
  kernelFunc: sparseSegmentMean
};

function sparseSegmentSum(e) {
  var {
    inputs: t,
    backend: n
  } = e,
      {
    data: r,
    indices: a,
    segmentIds: s
  } = t;
  if (r.shape.length < 1) throw new Error("Data should be at least 1 dimensional but received scalar");
  if (1 !== a.shape.length) throw new Error("Indices should be a vector but received shape\n             ".concat(a.shape));
  if (1 !== s.shape.length) throw new Error("Segment ids should be a vector but received shape\n             ".concat(s.shape));
  var o = n.readSync(r.dataId),
      i = n.readSync(a.dataId),
      l = n.readSync(s.dataId),
      [u, c] = sparseSegmentReductionImplCPU(o, r.shape, r.dtype, i, l);
  return n.makeTensorInfo(c, r.dtype, u);
}

var sparseSegmentSumConfig = {
  kernelName: SparseSegmentSum,
  backendName: "webgl",
  kernelFunc: sparseSegmentSum
};

function sparseToDense(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    sparseIndices: a,
    sparseValues: s,
    defaultValue: o
  } = t,
      {
    outputShape: i
  } = r,
      {
    sliceRank: l,
    numUpdates: u,
    strides: c,
    outputSize: p
  } = calculateShapes(s, a, i),
      d = new ScatterProgram(u, l, a.shape.length, s.shape.length, c, [p, 1], !1),
      h = n.runWebGLProgram(d, [s, a, o], s.dtype),
      m = reshape({
    inputs: {
      x: h
    },
    backend: n,
    attrs: {
      shape: i
    }
  });
  return n.disposeIntermediateTensorInfo(h), m;
}

var sparseToDenseConfig = {
  kernelName: SparseToDense,
  backendName: "webgl",
  kernelFunc: sparseToDense
};

function splitV(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    numOrSizeSplits: s,
    axis: o
  } = r,
      i = parseAxisParam(o, a.shape)[0],
      l = prepareSplitSize(a, s, i),
      u = new Array(a.shape.length).fill(0),
      c = a.shape.slice();
  return l.map(e => {
    var t = [...c];
    t[i] = e;
    var r = slice({
      inputs: {
        x: a
      },
      backend: n,
      attrs: {
        begin: u,
        size: t
      }
    });
    return u[i] += e, r;
  });
}

var splitVConfig = {
  kernelName: SplitV,
  backendName: "webgl",
  kernelFunc: splitV
},
    SQRT = "return sqrt(x);",
    sqrt = unaryKernelFunc({
  opSnippet: SQRT
}),
    sqrtConfig = {
  kernelName: Sqrt,
  backendName: "webgl",
  kernelFunc: sqrt
},
    SQUARE = "return x * x;",
    square = unaryKernelFunc({
  opSnippet: SQUARE
}),
    squareConfig = {
  kernelName: Square,
  backendName: "webgl",
  kernelFunc: square
},
    SQUARED_DIFFERENCE = "return (a - b) * (a - b);",
    squaredDifference = binaryKernelFunc({
  opSnippet: SQUARED_DIFFERENCE,
  packedOpSnippet: SQUARED_DIFFERENCE
}),
    squaredDifferenceConfig = {
  kernelName: SquaredDifference,
  backendName: "webgl",
  kernelFunc: squaredDifference
};

function step(_ref74) {
  var {
    inputs: e,
    attrs: t,
    backend: n
  } = _ref74;
  var {
    x: r
  } = e,
      a = new UnaryOpProgram(r.shape, CHECK_NAN_SNIPPET$2 + "\n    return x > 0.0 ? 1.0 : float(".concat(t.alpha, ");\n  "));
  return n.runWebGLProgram(a, [r], r.dtype);
}

var stepConfig = {
  kernelName: Step,
  backendName: "webgl",
  kernelFunc: step
};

class StridedSliceProgram {
  constructor(e, t, n) {
    this.variableNames = ["x"], this.outputShape = n;
    var r = n.length,
        a = getCoordsDataType(n.length),
        s = getCoordsDataType(n.length);
    var o = "";
    if (1 === r) o = "coords * strides + begin";else {
      var _e1075 = 0;
      o = n.map((t, r) => (_e1075++, 1 === n.length ? "coords * strides[".concat(r, "] + begin[").concat(r, "]") : "coords[".concat(_e1075 - 1, "] * strides[").concat(r, "] + begin[").concat(r, "]"))).join(",");
    }
    this.userCode = "\n      ".concat(a, " begin = ").concat(a, "(").concat(e, ");\n      ").concat(a, " strides = ").concat(a, "(").concat(t, ");\n\n      void main() {\n        ").concat(s, " coords = getOutputCoords();\n        setOutput(getX(").concat(o, "));\n      }\n    ");
  }

}

function stridedSlice(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    begin: s,
    end: o,
    strides: i,
    beginMask: l,
    endMask: u,
    ellipsisMask: c,
    newAxisMask: p,
    shrinkAxisMask: d
  } = r,
      {
    nonStrided: h,
    $begin: m,
    $strides: f,
    size: g,
    newShape: $,
    outShape: y
  } = sliceInfo(a.shape, s, o, i, l, u, c, p, d),
      b = reshape({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      shape: $
    }
  });
  var x;

  if (h) {
    var _e1076 = slice({
      inputs: {
        x: b
      },
      backend: n,
      attrs: {
        begin: m,
        size: g
      }
    });

    x = reshape({
      inputs: {
        x: _e1076
      },
      backend: n,
      attrs: {
        shape: y
      }
    }), n.disposeIntermediateTensorInfo(_e1076);
  } else if (y.some(e => 0 === e)) x = n.makeTensorInfo(y, a.dtype, []);else if (n.shouldExecuteOnCPU([b])) {
    var _e1077 = n.texData.get(b.dataId),
        _t727 = buffer(b.shape, b.dtype, _e1077.values),
        _r431 = stridedSliceImplCPU(y, _t727, f, m);

    x = n.makeTensorInfo(y, b.dtype, _r431.values);
  } else {
    var _e1078 = new StridedSliceProgram(m, f, y);

    x = n.runWebGLProgram(_e1078, [b], b.dtype);
  }

  var v = reshape({
    inputs: {
      x
    },
    backend: n,
    attrs: {
      shape: y
    }
  });
  return n.disposeIntermediateTensorInfo(b), n.disposeIntermediateTensorInfo(x), v;
}

var stridedSliceConfig = {
  kernelName: StridedSlice,
  backendName: "webgl",
  kernelFunc: stridedSlice
};

function stringNGrams(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    separator: a,
    nGramWidths: s,
    leftPad: o,
    rightPad: i,
    padWidth: l,
    preserveShortSequences: u
  } = r,
      {
    data: c,
    dataSplits: p
  } = t,
      d = n.readSync(c.dataId),
      h = n.readSync(p.dataId),
      [m, f] = stringNGramsImplCPU(d, h, a, s, o, i, l, u);
  return [n.makeTensorInfo([m.length], "string", m), n.makeTensorInfo(p.shape, "int32", f)];
}

var stringNGramsConfig = {
  kernelName: StringNGrams,
  backendName: "webgl",
  kernelFunc: stringNGrams
};

function stringSplit(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    skipEmpty: a
  } = r,
      {
    input: s,
    delimiter: o
  } = t;
  if ("string" !== s.dtype) throw new Error("Input must be of datatype string");
  if (1 !== s.shape.length) throw new Error("Input must be a vector, got shape: ".concat(s.shape));
  if (0 !== o.shape.length) throw new Error("Delimiter must be a scalar, got shape: ".concat(o.shape));
  var i = n.readSync(s.dataId),
      l = n.readSync(o.dataId)[0],
      [u, c, p] = stringSplitImplCPU(i, l, a),
      d = c.length;
  return [n.makeTensorInfo([d, 2], "int32", u), n.makeTensorInfo([d], "string", c), n.makeTensorInfo([2], "int32", new Int32Array(p))];
}

var stringSplitConfig = {
  kernelName: StringSplit,
  backendName: "webgl",
  kernelFunc: stringSplit
};

function stringToHashBucketFast(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    numBuckets: a
  } = r,
      {
    input: s
  } = t;
  if ("string" !== s.dtype) throw new Error("Input must be of datatype string");
  if (a <= 0) throw new Error("Number of buckets must be at least 1");
  var o = n.readSync(s.dataId),
      i = stringToHashBucketFastImplCPU(o, a);
  return n.makeTensorInfo(s.shape, "int32", i);
}

var stringToHashBucketFastConfig = {
  kernelName: StringToHashBucketFast,
  backendName: "webgl",
  kernelFunc: stringToHashBucketFast
},
    TAN = "return tan(x);",
    tan = unaryKernelFunc({
  opSnippet: TAN
}),
    tanConfig = {
  kernelName: Tan,
  backendName: "webgl",
  kernelFunc: tan
},
    TANH = "\n  float e2x = exp(-2.0 * abs(x));\n  return sign(x) * (1.0 - e2x) / (1.0 + e2x);\n",
    tanh = unaryKernelFunc({
  opSnippet: TANH
}),
    tanhConfig = {
  kernelName: Tanh$1,
  backendName: "webgl",
  kernelFunc: tanh
};

class TileProgram {
  constructor(e, t) {
    this.variableNames = ["A"];
    var n = new Array(e.length);

    for (var _r432 = 0; _r432 < n.length; _r432++) {
      n[_r432] = e[_r432] * t[_r432];
    }

    this.outputShape = n, this.rank = n.length;
    var r = getCoordsDataType(this.rank),
        a = getSourceCoords(e);
    this.userCode = "\n      void main() {\n        ".concat(r, " resRC = getOutputCoords();\n        setOutput(getA(").concat(a, "));\n      }\n    ");
  }

}

function getSourceCoords(e) {
  var t = e.length;
  if (t > 5) throw Error("Tile for rank ".concat(t, " is not yet supported"));
  if (1 === t) return "imod(resRC, ".concat(e[0], ")");
  var n = ["resRC.x", "resRC.y", "resRC.z", "resRC.w", "resRC.u"],
      r = [];

  for (var _t728 = 0; _t728 < e.length; _t728++) {
    r.push("imod(".concat(n[_t728], ", ").concat(e[_t728], ")"));
  }

  return r.join();
}

function tile(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    reps: s
  } = r;

  if ("string" === a.dtype || a.shape.length > 5) {
    var _e1079 = n.readSync(a.dataId),
        _t729 = "string" === a.dtype ? _e1079.map(e => decodeString(e)) : _e1079,
        _r433 = buffer(a.shape, a.dtype, _t729),
        _o156 = tileImplCPU(_r433, s);

    return n.makeTensorInfo(_o156.shape, _o156.dtype, _o156.values);
  }

  var o = new TileProgram(a.shape, s);
  return n.runWebGLProgram(o, [a], a.dtype);
}

var tileConfig = {
  kernelName: Tile,
  backendName: "webgl",
  kernelFunc: tile
};

class SwapProgram {
  constructor(e) {
    this.variableNames = ["x", "indices"], this.customUniforms = [{
      name: "n",
      type: "int"
    }, {
      name: "firstPass",
      type: "int"
    }, {
      name: "negativeInf",
      type: "float"
    }, {
      name: "dir",
      type: "int"
    }, {
      name: "inc",
      type: "int"
    }], this.outputShape = e, this.userCode = "\n       void main() {\n         ivec2 coords = getOutputCoords();\n         int batch = coords[0];\n         int elemIdx = coords[1];\n\n         // We compare elements pair-wise within a group of size 2 * inc.\n         // The comparing rule for each group alternates between ascending\n         // and descending. Within each group, we compare each pair at\n         // positions i and i+inc. To decide whether an element at position i\n         // is x0 or x1, we mod it by 2 * inc, if the result is smaller than\n         // inc, it is in the first half of the group, we denote it as x0,\n         // otherwise we denote it as x1.\n         // For example, as shown in the Bitonic top K paper referenced above,\n         // Figure5(a) shows that element[1] is in the\n         // second half of the group when group size is 2, but it is in the\n         // first half of the group when group size is 4.\n\n         bool isFirstInPair = imod(elemIdx, 2 * inc) < inc;\n         int i = isFirstInPair ? elemIdx : elemIdx - inc;\n\n         int i0 = firstPass == 1 ? i : int(getIndices(batch, i));\n         int i1 = firstPass == 1 ? i + inc : int(getIndices(batch, i + inc));\n         float x0 = i0 < n ? getX(batch, i0) : negativeInf;\n         float x1 = i1 < n ? getX(batch, i1) : negativeInf;\n\n         // Denotes which direction indices are in (ascending or descending).\n         bool reverse = imod(elemIdx, 2 * dir) >= dir;\n         bool isGreater = x0 > x1 || (x0 == x1 && i1 > i0);\n         if (reverse == isGreater) { // Elements in opposite order of direction\n           int iTemp = i0;\n           i0 = i1;\n           i1 = iTemp;\n         }\n         if (isFirstInPair) {\n            setOutput(float(i0));\n         } else {\n            setOutput(float(i1));\n         }\n       }\n     ";
  }

}

class MergeProgram {
  constructor(e) {
    this.variableNames = ["x", "indices"], this.customUniforms = [{
      name: "n",
      type: "int"
    }, {
      name: "firstPass",
      type: "int"
    }, {
      name: "k",
      type: "int"
    }], this.outputShape = e, this.userCode = "\n    void main() {\n         // Takes max of indices (0, k), (1, k + 1), (2, k + 2) ...\n         ivec2 coords = getOutputCoords();\n         int batch = coords[0];\n         int elemIdx = coords[1];\n\n         // The output size is half of the previous size.\n         // If the previous sequence is | | | | _ _ _ _  | | | |  _ _ _ _ (k=4),\n         // we only need to output the indices at positions |, the indices at\n         // positions _ can be thrown away, see Figure5(b) After Phase 2\n         // (Merge phase) in the Bitonic Top K paper referenced above.\n         // For example, the paper shows we only need to output the orange bars.\n         // The output sequence should look like this | | | | | | | |.\n         // Because the sequence is halved, to map the output index back\n         // to the previous sequence to find the corresponding value,\n         // we need to double the index. When we double the index,\n         // we basically interpolate a position, so 2i looks like\n         // | _ | _ | _ | _ | _ | _ | _. We move the | to the first k position\n         // of each 2k positions by - elemIdx % k. E.g. for output at\n         // index 4,5,6,7, we want to get the corresponding element at\n         // original index 8,9,10,11, for output at index 8,9,10,11,\n         // we want to get the corresponding element at original index\n         // 16,17,18,19, so on and so forth.\n\n         int i = elemIdx < k ? elemIdx : (elemIdx * 2 - imod(elemIdx, k));\n         int i0 = firstPass == 1 ? i : int(getIndices(batch, i));\n         int i1 = firstPass == 1 ? i + k : int(getIndices(batch, i + k));\n\n         float x0 = getX(batch, i0);\n         float x1 = i1 < n ? getX(batch, i1) : x0;\n\n         setOutput(x0 >= x1 ? float(i0) : float(i1));\n       }\n     ";
  }

}

function disposeIntermediateTensorInfoOrNull(e, t) {
  null !== t && e.disposeIntermediateTensorInfo(t);
}

function roundUpToPow2(e) {
  var t = 1;

  for (; t < e;) {
    t *= 2;
  }

  return t;
}

function topK(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a
  } = t,
      {
    k: s,
    sorted: o
  } = r,
      i = env().getNumber("TOPK_LAST_DIM_CPU_HANDOFF_SIZE_THRESHOLD"),
      l = env().getNumber("TOPK_K_CPU_HANDOFF_THRESHOLD"),
      u = a.shape,
      c = u[u.length - 1];

  if (n.shouldExecuteOnCPU([a]) || c < i || s > l) {
    var _e1080 = n.readSync(a.dataId),
        [_t730, _r434] = topKImplCPU(_e1080, u, a.dtype, s, o);

    return [n.makeTensorInfo(_t730.shape, _t730.dtype, _t730.values), n.makeTensorInfo(_r434.shape, _r434.dtype, _r434.values)];
  }

  if (0 === s) return u[u.length - 1] = 0, [n.makeTensorInfo(u, a.dtype, []), n.makeTensorInfo(u, "int32", [])];
  if (1 === c) return [a, fill({
    attrs: {
      shape: u,
      dtype: "int32",
      value: 0
    },
    backend: n
  })];
  var p = n.texData.get(a.dataId),
      d = null !== p && p.isPacked,
      h = d ? n.unpackTensor(a) : a,
      m = sizeFromShape(u) / c,
      f = reshape({
    inputs: {
      x: h
    },
    attrs: {
      shape: [m, c]
    },
    backend: n
  });
  d && disposeIntermediateTensorInfoOrNull(n, h);
  var g = roundUpToPow2(s),
      $ = roundUpToPow2(c);
  var y = null;

  var b = () => null === y ? [f, f] : [f, y],
      x = (e, t, r) => {
    var a = b(),
        s = new SwapProgram(r),
        o = y;
    y = n.runWebGLProgram(s, a, "int32", [[c], [null === y ? 1 : 0], [Number.NEGATIVE_INFINITY], [e], [t]]), disposeIntermediateTensorInfoOrNull(n, o);
  };

  for (var _e1081 = 1; _e1081 < g; _e1081 *= 2) {
    var _t731 = 2 * _e1081;

    for (var _n439 = _e1081; _n439 >= 1; _n439 /= 2) {
      x(_t731, _n439, [m, $]);
    }
  }

  for (var _e1082 = $; _e1082 > g; _e1082 /= 2) {
    var _t732 = b(),
        _r435 = new MergeProgram([m, _e1082 / 2]),
        _a308 = y;

    y = n.runWebGLProgram(_r435, _t732, "int32", [[c], [null === y ? 1 : 0], [g]]), disposeIntermediateTensorInfoOrNull(n, _a308);

    var _s222 = g / 2,
        _o157 = 2 * _s222;

    for (var _e1083 = _s222; _e1083 >= 1; _e1083 /= 2) {
      x(_o157, _e1083, y.shape);
    }
  }

  var v = y;
  y = slice({
    inputs: {
      x: y
    },
    backend: n,
    attrs: {
      begin: 0,
      size: [m, s]
    }
  }), disposeIntermediateTensorInfoOrNull(n, v);
  var I = gatherV2({
    inputs: {
      x: f,
      indices: y
    },
    backend: n,
    attrs: {
      axis: 1,
      batchDims: 1
    }
  });
  disposeIntermediateTensorInfoOrNull(n, f);
  var C = u.slice(0, -1);
  C.push(s), v = y, y = reshape({
    inputs: {
      x: y
    },
    attrs: {
      shape: C
    },
    backend: n
  }), disposeIntermediateTensorInfoOrNull(n, v);
  var S = I;
  return I = reshape({
    inputs: {
      x: I
    },
    attrs: {
      shape: C
    },
    backend: n
  }), disposeIntermediateTensorInfoOrNull(n, S), [I, y];
}

var topKConfig = {
  kernelName: TopK,
  backendName: "webgl",
  kernelFunc: topK
};

class TransformProgram {
  constructor(e, t, n, r, a, s) {
    this.variableNames = ["Image", "Transforms"], this.outputShape = s;
    var o = "nearest" === n ? 1 : 2;
    var i;

    switch (r) {
      case "constant":
      default:
        i = 1;
        break;

      case "reflect":
        i = 2;
        break;

      case "wrap":
        i = 3;
        break;

      case "nearest":
        i = 4;
    }

    this.userCode = "\n            float mapCoord(float outCoord, float len) {\n              float inCoord = outCoord;\n              if(".concat(i, " == 2) {\n                if (inCoord < 0.0) {\n                  if (len <= 1.0) {\n                    inCoord = 0.0;\n                  } else {\n                    float sz2 = 2.0 * len;\n                    if (inCoord < sz2) {\n                      inCoord = sz2 * float(int(float(-inCoord / sz2))) +\n                      inCoord;\n                    }\n                    inCoord = inCoord < -len ? inCoord + sz2 : -inCoord - 1.0;\n                  }\n                } else if (inCoord > len - 1.0) {\n                  if (len <= 1.0) {\n                    inCoord = 0.0;\n                  } else {\n                    float sz2 = 2.0 * len;\n                    inCoord -= sz2 * float(int(float(inCoord / sz2)));\n                    if (inCoord >= len) {\n                      inCoord = sz2 - inCoord - 1.0;\n                    }\n                  }\n                }\n                return clamp(inCoord, 0.0, len - 1.0);\n              } else if (").concat(i, " == 3) {\n                if (inCoord < 0.0) {\n                  if (len <= 1.0) {\n                    inCoord = 0.0;\n                  } else {\n                    float sz = len - 1.0;\n                    inCoord += len * (float(int(float(-inCoord / sz))) + 1.0);\n                  }\n                } else if (inCoord > len - 1.0) {\n                  if (len <= 1.0) {\n                    inCoord = 0.0;\n                  } else {\n                    float sz = len - 1.0;\n                    inCoord -= len * float(int(float(inCoord / sz)));\n                  }\n                }\n                return clamp(inCoord, 0.0, len - 1.0);\n              } else if (").concat(i, " == 4) {\n                return clamp(outCoord, 0.0, len - 1.0);\n              } else {\n                return outCoord;\n              }\n            }\n\n            float readWithFillValue(int batch, int coordY, int coordX,\n              int channel) {\n              float outputValue;\n              if (0 <= coordY && coordY < ").concat(e, " && 0 <= coordX && coordX < ").concat(t, ") {\n                  outputValue = getImage(batch, coordY, coordX, channel);\n              } else {\n                outputValue = float(").concat(a, ");\n              }\n              return outputValue;\n            }\n\n            void main() {\n              ivec4 coords = getOutputCoords();\n              float outputValue;\n              int batch = coords[0];\n              int x = coords[2];\n              int y = coords[1];\n              int channel = coords[3];\n              float xf = float(x);\n              float yf = float(y);\n              float a1 = getTransforms(batch, 0);\n              float a2 = getTransforms(batch, 1);\n              float a3 = getTransforms(batch, 2);\n              float b1 = getTransforms(batch, 3);\n              float b2 = getTransforms(batch, 4);\n              float b3 = getTransforms(batch, 5);\n              float c1 = getTransforms(batch, 6);\n              float c2 = getTransforms(batch, 7);\n              float projection = c1 * xf + c2 * yf + 1.0;\n              if (projection == 0.0) {\n                outputValue = float(").concat(a, ");\n              } else {\n                float inX = (a1 * xf + a2 * yf + a3) / projection;\n                float inY = (b1 * xf + b2 * yf + b3) / projection;\n                float mapX = mapCoord(inX, float(").concat(t, "));\n                float mapY = mapCoord(inY, float(").concat(e, "));\n\n                if (").concat(o, " == 1) {\n                  int coordY = int(round(mapY));\n                  int coordX = int(round(mapX));\n                  outputValue = readWithFillValue(batch, coordY, coordX,\n                    channel);\n                } else {\n                  float yFloor = floor(mapY);\n                  float xFloor = floor(mapX);\n                  float yCeil = yFloor + 1.0;\n                  float xCeil = xFloor + 1.0;\n                  float valueYFloor = (xCeil - mapX) *\n                  readWithFillValue(batch, int(yFloor), int(xFloor), channel) +\n                  (mapX - xFloor) *\n                  readWithFillValue(batch, int(yFloor), int(xCeil), channel);\n                  float valueYCeil = (xCeil - mapX) *\n                  readWithFillValue(batch, int(yCeil), int(xFloor), channel) +\n                  (mapX - xFloor) *\n                  readWithFillValue(batch, int(yCeil), int(xCeil), channel);\n                  outputValue = (yCeil - mapY) * valueYFloor +\n                  (mapY - yFloor) * valueYCeil;\n                }\n              }\n              setOutput(outputValue);\n            }\n        ");
  }

}

function transform(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    image: a,
    transforms: s
  } = t,
      {
    interpolation: o,
    fillMode: i,
    fillValue: l,
    outputShape: u
  } = r,
      [c, p, d, h] = a.shape,
      [m, f] = null != u ? u : [p, d],
      g = new TransformProgram(p, d, o, i, l, [c, m, f, h]);
  return n.runWebGLProgram(g, [a, s], "float32");
}

var transformConfig = {
  kernelName: Transform,
  backendName: "webgl",
  kernelFunc: transform
};

function unique(e) {
  var {
    inputs: t,
    attrs: n,
    backend: r
  } = e,
      {
    axis: a
  } = n,
      {
    x: s
  } = t;
  assertNotComplex(s, "unique"), console.warn("WARNING: ", "UI might be locked temporarily as data is being downloaded");
  var o = r.readSync(s.dataId),
      {
    outputValues: i,
    outputShape: l,
    indices: u
  } = uniqueImplCPU(o, a, s.shape, s.dtype);
  return [r.makeTensorInfo(l, s.dtype, i), r.makeTensorInfo([u.length], "int32", u)];
}

var uniqueConfig = {
  kernelName: Unique,
  backendName: "webgl",
  kernelFunc: unique
};

function unpack(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    value: a
  } = t;
  var {
    axis: s
  } = r;
  s < 0 && (s += a.shape.length);
  var o = a,
      i = o.shape.length,
      l = a.shape[s],
      u = new Array(i - 1);
  var c = 0;

  for (var _e1084 = 0; _e1084 < i; _e1084++) {
    _e1084 !== s && (u[c++] = o.shape[_e1084]);
  }

  var p = [],
      d = new Array(i).fill(0),
      h = o.shape.slice();
  h[s] = 1;
  var m = new Array(l);

  for (var _e1085 = 0; _e1085 < m.length; _e1085++) {
    d[s] = _e1085;

    var _t733 = slice({
      inputs: {
        x: o
      },
      backend: n,
      attrs: {
        begin: d,
        size: h
      }
    }),
        _r436 = reshape({
      inputs: {
        x: _t733
      },
      backend: n,
      attrs: {
        shape: u
      }
    });

    m[_e1085] = _r436, p.push(_t733);
  }

  return p.forEach(e => n.disposeIntermediateTensorInfo(e)), m;
}

var unpackConfig = {
  kernelName: Unpack,
  backendName: "webgl",
  kernelFunc: unpack
};

class SegmentOpProgram {
  constructor(e, t) {
    this.variableNames = ["x", "segmentIds"];
    var n = e.windowSize,
        r = e.batchSize,
        a = e.inSize,
        s = e.numSegments,
        o = s * Math.ceil(a / n);
    this.outputShape = [r, o];
    var i = 4 * Math.floor(n / 4),
        l = n % 4,
        u = "\n        sumValue += dot(values, segFilter);\n    ";
    var c = "";
    a % n > 0 && (c = "\n        if (inIdx < 0 || inIdx >= ".concat(a, ") {\n          return initializationValue;\n        }\n      "));
    var p = "";
    a % n > 0 && (p = "\n        if (inIdx < 0 || inIdx >= ".concat(a, ") {\n          return -1.0;\n        }\n      ")), this.userCode = "\n      const float initializationValue = 0.0;\n\n      float getValue(int batch, int inIdx) {\n        ".concat(c, "\n        return getX(batch, inIdx);\n      }\n\n      float getSegmentIdAtIndex(int inIdx) {\n        ").concat(p, "\n        return getSegmentIds(inIdx);\n      }\n\n      void main() {\n        ivec2 coords = getOutputCoords();\n        int batch = coords[0];\n        int outIdx = coords[1];\n        int inOffset = int(floor(float(outIdx) / float(\n          ").concat(s, ")) * float(").concat(n, "));\n        int currentSeg = int(mod(float(outIdx), float(").concat(s, ")));\n\n        float sumValue = 0.0;\n\n        for (int i = 0; i < ").concat(i, "; i += 4) {\n          int inIdx = inOffset + i;\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            getValue(batch, inIdx + 3)\n          );\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 3)) == currentSeg ? 1 : 0\n          );\n\n          ").concat(u, "\n        }\n\n        int inIdx = inOffset + ").concat(i, ";\n        if (").concat(1 === l, ") {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            initializationValue,\n            initializationValue,\n            initializationValue\n          );\n\n          int inIdxSeg = int(getSegmentIdAtIndex(inIdx));\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            0,\n            0,\n            0\n          );\n\n          ").concat(u, "\n        } else if (").concat(2 === l, ") {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            initializationValue,\n            initializationValue\n          );\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\n              0,\n              0\n          );\n\n          ").concat(u, "\n        } else if (").concat(3 === l, ") {\n          vec4 values = vec4(\n            getValue(batch, inIdx),\n            getValue(batch, inIdx + 1),\n            getValue(batch, inIdx + 2),\n            initializationValue\n          );\n\n          vec4 segFilter = vec4(\n            int(getSegmentIdAtIndex(inIdx)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 1)) == currentSeg ? 1 : 0,\n            int(getSegmentIdAtIndex(inIdx + 2)) == currentSeg ? 1 : 0,\n            0\n          );\n\n          ").concat(u, "\n        }\n        setOutput(sumValue);\n      }\n    ");
  }

}

function unsortedSegmentSum(e) {
  var {
    inputs: t,
    backend: n,
    attrs: r
  } = e,
      {
    x: a,
    segmentIds: s
  } = t,
      {
    numSegments: o
  } = r,
      i = a.shape.length,
      l = [];
  var u = 0;
  var c = getAxesPermutation([u], i);
  var p = a;
  null != c && (p = transpose({
    inputs: {
      x: a
    },
    backend: n,
    attrs: {
      perm: c
    }
  }), l.push(p), u = getInnerMostAxes(1, i)[0]);
  var d = computeOutShape(p.shape, u, o),
      h = sizeFromShape([p.shape[u]]),
      m = reshape({
    inputs: {
      x: p
    },
    backend: n,
    attrs: {
      shape: [-1, h]
    }
  });
  l.push(m);

  var f = sumOutType(a.dtype),
      g = (e, t, r, a, s) => {
    var o = e.shape[0],
        i = e.shape[1],
        u = segOpComputeOptimalWindowSize(i, s),
        c = new SegmentOpProgram({
      windowSize: u,
      inSize: i,
      batchSize: o,
      numSegments: s
    }, t),
        p = n.compileAndRun(c, [e, r], a);
    if (l.push(p), p.shape[1] === s) return p;
    var d = range$1({
      backend: n,
      attrs: {
        start: 0,
        stop: s,
        step: 1,
        dtype: "float32"
      }
    }),
        h = tile({
      inputs: {
        x: d
      },
      backend: n,
      attrs: {
        reps: [i / u]
      }
    });
    return l.push(d), l.push(h), g(p, t, h, a, s);
  },
      $ = reshape({
    inputs: {
      x: g(m, "unsortedSegmentSum", s, f, o)
    },
    backend: n,
    attrs: {
      shape: d
    }
  });

  var y = $;

  if (null != c) {
    l.push($);

    var _e1086 = getUndoAxesPermutation(c);

    y = transpose({
      inputs: {
        x: y
      },
      backend: n,
      attrs: {
        perm: _e1086
      }
    });
  }

  return l.forEach(e => n.disposeIntermediateTensorInfo(e)), y;
}

var unsortedSegmentSumConfig = {
  kernelName: UnsortedSegmentSum,
  backendName: "webgl",
  kernelFunc: unsortedSegmentSum
},
    kernelConfigs = [LRNConfig, LRNGradConfig, _fusedMatMulConfig, absConfig, acosConfig, acoshConfig, addConfig, addNConfig, allConfig, anyConfig, argMaxConfig, argMinConfig, asinConfig, asinhConfig, atan2Config, atanConfig, atanhConfig, avgPool3DConfig, avgPoolConfig, avgPoolGrad3DConfig, avgPoolGradConfig, batchMatMulConfig, batchNormConfig, batchToSpaceNDConfig, bincountConfig, castConfig, ceilConfig, clipByValueConfig, complexAbsConfig, complexConfig, concatConfig, conv2DBackpropFilterConfig, conv2DBackpropInputConfig, conv2DConfig, conv3DBackpropFilterV2Config, conv3DBackpropInputConfig, conv3DConfig, cosConfig, coshConfig, cropAndResizeConfig, cumsumConfig, denseBincountConfig, depthToSpaceConfig, depthwiseConv2dNativeBackpropFilterConfig, depthwiseConv2dNativeBackpropInputConfig, depthwiseConv2dNativeConfig, diagConfig, dilation2DConfig, einsumConfig, eluConfig, eluGradConfig, equalConfig, erfConfig, expConfig, expandDimsConfig, expm1Config, fftConfig, fillConfig, flipLeftRightConfig, floorConfig, floorDivConfig, fromPixelsConfig, fusedConv2DConfig, fusedDepthwiseConv2DConfig, gatherNdConfig, gatherV2Config, greaterConfig, greaterEqualConfig, identityConfig, ifftConfig, imagConfig, isFiniteConfig, isInfConfig, isNaNConfig, leakyReluConfig, lessConfig, lessEqualConfig, linSpaceConfig, log1pConfig, logConfig, logicalAndConfig, logicalNotConfig, logicalOrConfig, maxConfig, maxPool3DConfig, maxPoolConfig, maxPoolGrad3DConfig, maxPoolGradConfig, maxPoolWithArgmaxConfig, maximumConfig, meanConfig, minConfig, minimumConfig, mirrorPadConfig, modConfig, multinomialConfig, multiplyConfig, negConfig, nonMaxSuppressionV3Config, nonMaxSuppressionV4Config, nonMaxSuppressionV5Config, notEqualConfig, oneHotConfig, onesLikeConfig, packConfig, padV2Config, powConfig, preluConfig, prodConfig, rangeConfig, realConfig, realDivConfig, reciprocalConfig, relu6Config, reluConfig, reshapeConfig, resizeBilinearConfig, resizeBilinearGradConfig, resizeNearestNeighborConfig, resizeNearestNeighborGradConfig, reverseConfig, rotateWithOffsetConfig, roundConfig, rsqrtConfig, scatterNdConfig, selectConfig, seluConfig, sigmoidConfig, signConfig, sinConfig, sinhConfig, sliceConfig, softmaxConfig, softplusConfig, spaceToBatchNDConfig, sparseFillEmptyRowsConfig, sparseReshapeConfig, sparseSegmentMeanConfig, sparseSegmentSumConfig, sparseToDenseConfig, splitVConfig, sqrtConfig, squareConfig, squaredDifferenceConfig, stepConfig, stridedSliceConfig, stringNGramsConfig, stringSplitConfig, stringToHashBucketFastConfig, subConfig, sumConfig, tanConfig, tanhConfig, tileConfig, topKConfig, transformConfig, transposeConfig, uniqueConfig, unpackConfig, unsortedSegmentSumConfig, zerosLikeConfig];

for (var _e1087 of kernelConfigs) {
  registerKernel(_e1087);
}

var version$1 = "3.8.0",
    version = {
  "tfjs-core": version$7,
  "tfjs-backend-cpu": version$3,
  "tfjs-backend-webgl": version$2,
  "tfjs-data": version$4,
  "tfjs-layers": version$6,
  "tfjs-converter": version$5,
  tfjs: version$1
};
var dist = {
  __proto__: null,
  data: index,
  version,
  AdadeltaOptimizer,
  AdagradOptimizer,
  AdamOptimizer,
  AdamaxOptimizer,
  MomentumOptimizer,
  Optimizer,
  RMSPropOptimizer,
  SGDOptimizer,
  Tensor,
  TensorBuffer,
  Variable,

  get Rank() {
    return Rank;
  },

  sumOutType,
  upcastType,

  get Reduction() {
    return Reduction;
  },

  customGrad,
  grad,
  grads,
  valueAndGrad,
  valueAndGrads,
  variableGrads,
  Environment,
  env,

  get ENV() {
    return ENV$2;
  },

  nextFrame,
  KernelBackend,
  DataStorage,
  abs: abs$2,
  acos: acos$2,
  acosh: acosh$2,
  add: add$2,
  addN: addN$2,
  all: all$2,
  any: any$2,
  argMax: argMax$2,
  argMin: argMin$2,
  asin: asin$2,
  asinh: asinh$2,
  atan: atan$2,
  atan2: atan2$2,
  atanh: atanh$2,
  avgPool: avgPool$2,
  avgPool3d: avgPool3d$1,
  basicLSTMCell,
  batchToSpaceND: batchToSpaceND$2,
  batchNorm: batchNorm$2,
  batchNorm2d,
  batchNorm3d,
  batchNorm4d,
  bincount: bincount$2,
  broadcastTo,
  buffer,
  cast: cast$3,
  ceil: ceil$2,
  clipByValue: clipByValue$1,
  clone,
  complex: complex$2,
  concat: concat$2,
  concat1d,
  concat2d,
  concat3d,
  concat4d,
  conv1d: conv1d$1,
  conv2d: conv2d$3,
  conv2dTranspose: conv2dTranspose$1,
  conv3d: conv3d$1,
  conv3dTranspose: conv3dTranspose$1,
  cos: cos$2,
  cosh: cosh$2,
  cumsum: cumsum$2,
  denseBincount: denseBincount$2,
  depthToSpace: depthToSpace$2,
  depthwiseConv2d: depthwiseConv2d$3,
  diag: diag$2,
  dilation2d,
  div: div$1,
  divNoNan,
  dot: dot$2,
  einsum: einsum$2,
  elu: elu$4,
  equal: equal$2,
  erf: erf$2,
  exp: exp$2,
  expandDims: expandDims$3,
  expm1: expm1$2,
  eye,
  fill: fill$2,
  floor: floor$2,
  floorDiv: floorDiv$2,
  gather: gather$1,
  greater: greater$3,
  greaterEqual: greaterEqual$2,
  imag: imag$2,
  isFinite: isFinite$3,
  isInf: isInf$2,
  isNaN: isNaN$3,
  leakyRelu: leakyRelu$2,
  less: less$3,
  lessEqual: lessEqual$2,
  linspace,
  localResponseNormalization,
  log: log$3,
  log1p: log1p$2,
  logSigmoid,
  logSoftmax,
  logSumExp,
  logicalAnd: logicalAnd$2,
  logicalNot: logicalNot$2,
  logicalOr: logicalOr$2,
  logicalXor,
  matMul: matMul$1,
  max: max$3,
  maxPool: maxPool$2,
  maxPool3d: maxPool3d$1,
  maxPoolWithArgmax,
  maximum: maximum$3,
  mean: mean$1,
  meshgrid,
  min: min$3,
  minimum: minimum$3,
  mirrorPad: mirrorPad$1,
  mod: mod$2,
  moments,
  mul,
  multiRNNCell,
  multinomial: multinomial$2,
  neg: neg$2,
  notEqual: notEqual$2,
  oneHot: oneHot$2,
  ones: ones$1,
  onesLike: onesLike$2,
  outerProduct,
  pad,
  pad1d,
  pad2d,
  pad3d,
  pad4d,
  pool: pool$1,
  pow: pow$2,
  prelu: prelu$3,
  print,
  prod: prod$2,
  rand,
  randomGamma,
  randomNormal: randomNormal$2,
  randomUniform: randomUniform$1,
  range: range$4,
  real: real$2,
  reciprocal: reciprocal$2,
  relu: relu$3,
  relu6: relu6$2,
  reshape: reshape$3,
  reverse: reverse$2,
  reverse1d,
  reverse2d,
  reverse3d,
  reverse4d,
  round: round$2,
  rsqrt: rsqrt$2,
  scalar,
  selu: selu$2,
  separableConv2d: separableConv2d$1,
  setdiff1dAsync,
  sigmoid: sigmoid$2,
  sign: sign$2,
  sin: sin$2,
  sinh: sinh$2,
  slice: slice$2,
  slice1d,
  slice2d,
  slice3d,
  slice4d,
  softmax: softmax$3,
  softplus: softplus$2,
  spaceToBatchND: spaceToBatchND$2,
  fft: fft$2,
  ifft: ifft$2,
  irfft,
  rfft,
  split: split$2,
  sqrt: sqrt$2,
  square: square$2,
  squaredDifference: squaredDifference$2,
  squeeze,
  stack,
  step: step$2,
  stridedSlice: stridedSlice$2,
  sub: sub$2,
  sum: sum$2,
  tan: tan$2,
  tanh: tanh$2,
  tensor,
  tensor1d,
  tensor2d,
  tensor3d,
  tensor4d,
  tensor5d,
  tensor6d,
  tile: tile$3,
  topk,
  truncatedNormal: truncatedNormal$1,
  unique: unique$3,
  unsortedSegmentSum: unsortedSegmentSum$2,
  unstack,
  variable,
  where,
  whereAsync,
  zeros: zeros$2,
  zerosLike: zerosLike$2,
  op,
  OP_SCOPE_SUFFIX,
  booleanMaskAsync,
  transpose: transpose$2,
  norm,
  movingAverage,
  scatterND,
  sparseToDense: sparseToDense$2,
  gatherND,
  dropout: dropout$2,
  enclosingPowerOfTwo,
  cosineWindow,
  inTopKAsync,
  image: image$1,
  linalg,
  losses,
  spectral: spectral$1,
  fused: fused_ops,
  signal,
  sparse: sparse$1,
  string: string$1,
  train,
  enableProdMode,
  enableDebugMode,
  disableDeprecationWarnings,
  deprecationWarn,
  disposeVariables,
  engine,
  memory,
  profile,
  tidy,
  dispose,
  keep,
  time,
  setBackend,
  ready,
  getBackend,
  removeBackend,
  findBackend,
  findBackendFactory,
  registerBackend,
  backend,
  setPlatform,
  getKernel,
  getGradient,
  getKernelsForBackend,
  registerKernel,
  registerGradient,
  unregisterKernel,
  unregisterGradient,
  copyRegisteredKernels,
  Abs,
  Acos,
  Acosh,
  Add: Add$1,
  AddN,
  All,
  Any,
  ArgMax,
  ArgMin,
  Asin,
  Asinh,
  Atan,
  Atanh,
  Atan2,
  AvgPool,
  AvgPoolGrad,
  AvgPool3D,
  AvgPool3DGrad,
  BatchMatMul,
  BatchToSpaceND,
  Bincount,
  BroadcastTo,
  Cast,
  Ceil,
  ClipByValue,
  Complex,
  ComplexAbs,
  Concat,
  Conv2D: Conv2D$1,
  Conv2DBackpropFilter,
  Conv2DBackpropInput,
  Conv3D: Conv3D$1,
  Conv3DBackpropFilterV2,
  Conv3DBackpropInputV2,
  Cos,
  Cosh,
  Cumsum,
  CropAndResize,
  DenseBincount,
  DepthToSpace,
  DepthwiseConv2dNative,
  DepthwiseConv2dNativeBackpropFilter,
  DepthwiseConv2dNativeBackpropInput,
  Diag,
  Dilation2D,
  Dilation2DBackpropInput,
  Dilation2DBackpropFilter,
  RealDiv,
  Einsum,
  Elu: Elu$1,
  EluGrad,
  Erf,
  Equal,
  Exp,
  ExpandDims,
  Expm1,
  FFT,
  Fill,
  FlipLeftRight,
  Floor,
  FloorDiv,
  FusedBatchNorm,
  GatherV2,
  GatherNd,
  Greater,
  GreaterEqual,
  Identity: Identity$1,
  IFFT,
  Imag,
  IsFinite,
  IsInf,
  IsNan,
  LeakyRelu,
  Less,
  LessEqual,
  LinSpace,
  Log,
  Log1p,
  LogicalAnd,
  LogicalNot,
  LogicalOr,
  LogSoftmax: LogSoftmax$1,
  LRN,
  LRNGrad,
  Max,
  Maximum: Maximum$1,
  MaxPool,
  MaxPoolGrad,
  MaxPool3D,
  MaxPool3DGrad,
  MaxPoolWithArgmax,
  Mean,
  Min,
  Minimum: Minimum$1,
  MirrorPad,
  Mod,
  Multinomial,
  Multiply: Multiply$1,
  Neg,
  NotEqual,
  NonMaxSuppressionV3,
  NonMaxSuppressionV4,
  NonMaxSuppressionV5,
  OnesLike,
  OneHot,
  Pack,
  PadV2,
  Pool,
  Pow,
  Prelu,
  Prod,
  Range,
  Real,
  Reciprocal,
  Relu: Relu$1,
  Reshape: Reshape$1,
  ResizeNearestNeighbor,
  ResizeNearestNeighborGrad,
  ResizeBilinear,
  ResizeBilinearGrad,
  Relu6: Relu6$1,
  Reverse,
  Round,
  Rsqrt,
  ScatterNd,
  Select,
  Selu: Selu$1,
  Slice,
  Sin,
  Sinh,
  Sign,
  Sigmoid: Sigmoid$1,
  Softplus: Softplus$1,
  Sqrt,
  Sum,
  SpaceToBatchND,
  SplitV,
  Softmax: Softmax$2,
  SparseFillEmptyRows,
  SparseReshape,
  SparseSegmentMean,
  SparseSegmentSum,
  SparseToDense,
  SquaredDifference,
  Square,
  StridedSlice,
  StringNGrams,
  StringSplit,
  StringToHashBucketFast,
  Sub,
  Tan,
  Tanh: Tanh$1,
  Tile,
  TopK,
  Transform,
  Transpose,
  Unique,
  Unpack,
  UnsortedSegmentSum,
  ZerosLike,
  Step,
  FromPixels,
  RotateWithOffset,
  _FusedMatMul,
  FusedConv2D,
  FusedDepthwiseConv2D,
  version_core: version$7,
  browser,
  io,
  math,
  serialization,
  test_util,
  util,
  backend_util,
  tensor_util,
  slice_util,
  gather_util: gather_nd_util,
  scatter_util: scatter_nd_util,
  device_util,
  kernel_impls,
  CallbackList,
  CustomCallback,
  History,
  Callback,
  callbacks,
  EarlyStopping,
  InputSpec,
  SymbolicTensor,
  LayersModel,
  input,
  loadLayersModel,
  model,
  registerCallbackConstructor,
  sequential,
  RNN,
  Sequential,
  LayerVariable,
  version_layers: version$6,
  constraints: exports_constraints,
  initializers: exports_initializers,
  layers: exports_layers,
  metrics: exports_metrics,
  models: exports_models,
  regularizers: exports_regularizers,
  GraphModel,
  loadGraphModel,
  deregisterOp,
  registerOp,
  version_converter: version$5
};
var basetable = new Uint16Array(512),
    shifttable = new Uint8Array(512),
    mantissatable = new Uint32Array(2048),
    offsettable = new Uint16Array(64),
    exponenttable = new Uint32Array(64);
var inited = !1;

function init() {
  inited = !0;

  for (var _e1088 = 0; _e1088 < 256; ++_e1088) {
    var t = _e1088 - 127;
    t < -24 ? (basetable[0 | _e1088] = 0, basetable[256 | _e1088] = 32768, shifttable[0 | _e1088] = 24, shifttable[256 | _e1088] = 24) : t < -14 ? (basetable[0 | _e1088] = 1024 >> -t - 14, basetable[256 | _e1088] = 1024 >> -t - 14 | 32768, shifttable[0 | _e1088] = -t - 1, shifttable[256 | _e1088] = -t - 1) : t <= 15 ? (basetable[0 | _e1088] = t + 15 << 10, basetable[256 | _e1088] = t + 15 << 10 | 32768, shifttable[0 | _e1088] = 13, shifttable[256 | _e1088] = 13) : t < 128 ? (basetable[0 | _e1088] = 31744, basetable[256 | _e1088] = 64512, shifttable[0 | _e1088] = 24, shifttable[256 | _e1088] = 24) : (basetable[0 | _e1088] = 31744, basetable[256 | _e1088] = 64512, shifttable[0 | _e1088] = 13, shifttable[256 | _e1088] = 13);
  }

  for (var _t734 = 1; _t734 < 2048; ++_t734) {
    mantissatable[_t734] = _t734 < 1024 ? e(_t734) : 939524096 + (_t734 - 1024 << 13);
  }

  exponenttable[32] = 2147483648, exponenttable[31] = 1199570944, exponenttable[63] = 3347054592;

  for (var _e1089 = 1; _e1089 <= 30; ++_e1089) {
    exponenttable[_e1089] = _e1089 << 23;
  }

  for (var _e1090 = 33; _e1090 <= 62; ++_e1090) {
    exponenttable[_e1090] = 2147483648 + (_e1090 - 32 << 23);
  }

  for (var _e1091 = 1; _e1091 < offsettable.length; ++_e1091) {
    offsettable[_e1091] = 1024;
  }

  function e(e) {
    var t = e << 13,
        n = 0;

    for (; !(8388608 & t);) {
      n -= 8388608, t <<= 1;
    }

    return t &= -8388609, n += 947912704, (t | n) >>> 0;
  }

  offsettable[32] = 0;
}

function float32ToUInt32(e) {
  var t = new Float32Array(1);
  return t[0] = e, new Uint32Array(t.buffer)[0];
}

function float16toUInt16(e) {
  var t = float32ToUInt32(e);
  return inited || init(), basetable[t >> 23 & 511] | (8388607 & t) >> shifttable[t >> 23 & 511];
}

function float16AsUintToFloat(e) {
  inited || init();
  var t = mantissatable[offsettable[e >> 10] + (1023 & e)] + exponenttable[e >> 10],
      n = new Uint32Array(1);
  return n[0] = t, new Float32Array(n.buffer)[0];
}

function assert(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : "Assertion failed";
  if (!e) throw new Error(t);
}

function userError(e) {
  var t = new Error(e);
  throw t.isUserError = !0, t;
}

function lookup(e, t) {
  return e.hasOwnProperty(t) ? e[t] : null;
}

function oops() {
  var e = arguments.length > 0 && arguments[0] !== undefined ? arguments[0] : "OOPS";
  throw new Error(e);
}

function endsWith(e, t) {
  return !(e.length < t.length || 0 != t.length && e.slice(-t.length) != t);
}

function mapMap(e, t) {
  var n = {};
  return Object.keys(e).forEach(r => n[r] = t(r, e[r])), n;
}

function pushRange(e, t) {
  for (var n = 0; n < t.length; ++n) {
    e.push(t[n]);
  }
}

function range(e) {
  var t = [];

  for (var n = 0; n < e; ++n) {
    t.push(n);
  }

  return t;
}

var seed = 218109047;

function randomUint32() {
  var e = seed;
  return e ^= e << 13, e ^= e >>> 17, e ^= e << 5, e >>>= 0, seed = e, e;
}

function randomUFloat() {
  return randomUint32() / 4294967296;
}

function randomSFloat() {
  return 2 * randomUFloat() - 1;
}

function flatClone(e) {
  var t = e,
      n = {};

  for (var _e1092 of Object.keys(t)) {
    n[_e1092] = t[_e1092];
  }

  return n;
}

function lf(e) {
  for (var _len10 = arguments.length, t = new Array(_len10 > 1 ? _len10 - 1 : 0), _key10 = 1; _key10 < _len10; _key10++) {
    t[_key10 - 1] = arguments[_key10];
  }

  return e.replace(/{(\d+)}/g, (e, n) => t[+n]);
}

var badNameError = emitErr("opcode name doesn't match", "<name>");

class Instruction {
  constructor(e, t, n, r, a) {
    this.opcode = n, this.mask = r, this.is32bit = a, this.canBeShared = !1, assert((n & r) == n), this.ei = e, this.code = t.replace(/\s+/g, " "), this.friendlyFmt = t.replace(/\$\w+/g, e => this.ei.encoders[e] ? this.ei.encoders[e].pretty : e);
    var s = tokenize(t);
    this.name = s[0], this.args = s.slice(1);
  }

  emit(e) {
    var t = e.words;
    if (t[0] != this.name) return badNameError;
    var n = this.opcode,
        r = 1,
        a = 0,
        s = [],
        o = null,
        i = null,
        l = null;
    var u = this.ei.is32bit(this) && !this.is32bit;

    for (var c = 0; c < this.args.length; ++c) {
      var _p38 = this.args[c],
          d = t[r++];

      if ("$" == _p38[0]) {
        var _c40 = this.ei.encoders[_p38],
            h = null;

        if (_c40.isRegister) {
          if (h = this.ei.registerNo(d, _c40), null == h) return emitErr("expecting register name", d);
          this.ei.isPush(this.opcode) ? a++ : this.ei.isPop(this.opcode) && a--;
        } else if (_c40.isImmediate) {
          if (d = d.replace(/^#/, ""), h = e.bin.parseOneInt(d), null == h) return emitErr("expecting number", d);
          this.ei.isAddSP(this.opcode) ? a = -h / this.ei.wordSize() : this.ei.isSubSP(this.opcode) && (a = h / this.ei.wordSize());
        } else if (_c40.isRegList) {
          if ("{" != d) return emitErr("expecting {", d);

          for (h = 0; "}" != t[r];) {
            if (d = t[r++], !d) return emitErr("expecting }", t[r - 2]);

            var _e1093 = this.ei.registerNo(d, _c40);

            if (null == _e1093) return emitErr("expecting register name", d);
            if (h & 1 << _e1093) return emitErr("duplicate register name", d);
            h |= 1 << _e1093, this.ei.isPush(this.opcode) ? a++ : this.ei.isPop(this.opcode) && a--, "," == t[r] && r++;
          }

          d = t[r++];
        } else if (_c40.isLabel) {
          if (d = d.replace(/^#/, ""), /^[+-]?\d+$/.test(d)) h = parseInt(d, 10), o = "rel" + h;else if (/^0x[0-9a-fA-F]+$/.test(d)) h = parseInt(d, 16), o = "abs" + h;else {
            var _t735 = 0;

            if (d.indexOf("+") > 0) {
              var _e1094 = /(.*)\+(\d+)$/.exec(d);

              _e1094 && (d = _e1094[1], _t735 = parseInt(_e1094[2]));
            }

            if (o = d, h = this.ei.getAddressFromLabel(e.bin, this, d, _c40.isWordAligned), null == h) {
              if (e.bin.finalEmit) return emitErr("unknown label", d);
              h = 8;
            }

            h += _t735;
          }

          if (u) {
            i = h, l = d;
            continue;
          }
        } else oops();

        if (null == h) return emitErr("didn't understand it", d);
        if (s.push(h), h = _c40.encode(h), null == h) return emitErr("argument out of range or mis-aligned", d);
        assert(0 == (n & h)), n |= h;
      } else if (_p38 != d) return emitErr("expecting " + _p38, d);
    }

    return t[r] ? emitErr("trailing tokens", t[r]) : u ? this.ei.emit32(n, i, e.bin.normalizeExternalLabel(l)) : this.is32bit ? {
      opcode: n >> 16 & 65535 | 32768,
      opcode2: n >> 0 & 65535,
      stack: a,
      numArgs: s,
      labelName: e.bin.normalizeExternalLabel(o)
    } : {
      stack: a,
      opcode: n,
      numArgs: s,
      labelName: e.bin.normalizeExternalLabel(o)
    };
  }

  toString() {
    return this.friendlyFmt;
  }

}

class Line {
  constructor(e, t) {
    this.bin = e, this.text = t;
  }

  getOpExt() {
    return this.instruction ? this.instruction.code : "";
  }

  getOp() {
    return this.instruction ? this.instruction.name : "";
  }

  update(e) {
    this.bin.peepOps++, (e = e.replace(/^\s*/, "")) || this.bin.peepDel++, e && (e += "      "), this.text = (e = "    " + e) + "; WAS: " + this.text.trim(), this.instruction = null, this.numArgs = null, this.words = tokenize(e) || [], 0 == this.words.length ? this.type = "empty" : "@" == this.words[0][0] && (this.type = "directive");
  }

}

class File$1 {
  constructor(e) {
    this.baseOffset = 0, this.checkStack = !0, this.inlineMode = !1, this.normalizeExternalLabel = e => e, this.currLineNo = 0, this.scope = "", this.scopeId = 0, this.errors = [], this.labels = {}, this.equs = {}, this.stackpointers = {}, this.stack = 0, this.commPtr = 0, this.peepOps = 0, this.peepDel = 0, this.peepCounts = {}, this.stats = "", this.throwOnError = !1, this.disablePeepHole = !1, this.stackAtLabel = {}, this.currLine = new Line(this, "<start>"), this.currLine.lineNo = 0, this.ei = e, this.ei.file = this;
  }

  emitShort(e) {
    assert(0 <= e && e <= 65535), this.buf.push(e);
  }

  emitOpCode(e) {
    this.emitShort(e);
  }

  location() {
    return 2 * this.buf.length;
  }

  pc() {
    return this.location() + this.baseOffset;
  }

  parseOneInt(e) {
    if (!e) return null;
    if (/^\d+$/.test(e)) return parseInt(e, 10);
    var t = e.indexOf("-");
    if (t > 0) return this.parseOneInt(e.slice(0, t)) - this.parseOneInt(e.slice(t + 1));
    var n = 1;

    if (e.indexOf("*") >= 0) {
      var _t736 = null;

      for (; _t736 = /^([^\*]*)\*(.*)$/.exec(e);) {
        var _r437 = this.parseOneInt(_t736[1]);

        if (null == _r437) return null;
        n *= _r437, e = _t736[2];
      }
    }

    if ("-" == e[0] ? (n *= -1, e = e.slice(1)) : "+" == e[0] && (e = e.slice(1)), /^\d+$/.test(e)) return n * parseInt(e, 10);
    if (endsWith(e, "|1")) return 1 | this.parseOneInt(e.slice(0, e.length - 2));
    if (endsWith(e, "-1")) return this.parseOneInt(e.slice(0, e.length - 2)) - 1;
    if (endsWith(e, "+1")) return this.parseOneInt(e.slice(0, e.length - 2)) + 1;
    var r = /(.*)>>(\d+)$/.exec(e);

    if (r) {
      var _e1095 = this.parseOneInt(r[1]);

      return _e1095 &= ~(-16777216 & this.baseOffset), _e1095 >> parseInt(r[2]);
    }

    var a = null;
    if ("0" == e[0]) if ("x" == e[1] || "X" == e[1]) {
      var _t737 = /^0x([a-f0-9]+)$/i.exec(e);

      _t737 && (a = parseInt(_t737[1], 16));
    } else if ("b" == e[1] || "B" == e[1]) {
      var _t738 = /^0b([01]+)$/i.exec(e);

      _t738 && (a = parseInt(_t738[1], 2));
    }

    if (e.indexOf("@") >= 0) {
      var _t739 = /^(\w+)@(-?\d+)$/.exec(e);

      _t739 && (1 != n && this.directiveError(lf("multiplication not supported with saved stacks")), this.stackpointers.hasOwnProperty(_t739[1]) ? a = this.ei.wordSize() * this.ei.computeStackOffset(_t739[1], this.stack - this.stackpointers[_t739[1]] + parseInt(_t739[2])) : this.directiveError(lf("saved stack not found"))), _t739 = /^(.*)@(hi|lo|fn)$/.exec(e), _t739 && this.looksLikeLabel(_t739[1]) && (a = this.lookupLabel(_t739[1], !0), null != a && ("fn" == _t739[2] ? a = this.ei.toFnPtr(a, this.baseOffset, _t739[1]) : (a >>= 1, 0 <= a && a <= 65535 ? "hi" == _t739[2] ? a = a >> 8 & 255 : "lo" == _t739[2] ? a &= 255 : oops() : (this.directiveError(lf("@hi/lo out of range")), a = null))));
    }

    return null == a && this.looksLikeLabel(e) && (a = this.lookupLabel(e, !0), null != a && 1 == this.ei.postProcessRelAddress(this, 1) && (a += this.baseOffset)), null == a || isNaN(a) ? null : a * n;
  }

  looksLikeLabel(e) {
    return !/^(r\d|pc|sp|lr)$/i.test(e) && /^[\.a-zA-Z_][\.:\w+]*$/.test(e);
  }

  scopedName(e) {
    return "." == e[0] && this.scope ? this.scope + "$" + e : e;
  }

  lookupLabel(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;
    var n = null,
        r = this.scopedName(e);
    return this.labels.hasOwnProperty(r) ? (n = this.labels[r], n = this.ei.postProcessRelAddress(this, n)) : this.lookupExternalLabel && (n = this.lookupExternalLabel(e), null != n && (n = this.ei.postProcessAbsAddress(this, n))), null == n && this.equs.hasOwnProperty(r) && (n = this.equs[r]), null == n && t && (this.finalEmit ? this.directiveError(lf("unknown label: {0}", e)) : n = 11111), n;
  }

  align(e) {
    for (assert(2 == e || 4 == e || 8 == e || 16 == e); this.location() % e != 0;) {
      this.emitOpCode(0);
    }
  }

  pushError(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : "";
    var n = {
      scope: this.scope,
      message: lf("  -> Line {2} ('{1}'), error: {0}\n{3}", e, this.currLine.text, this.currLine.lineNo, t),
      lineNo: this.currLine.lineNo,
      line: this.currLine.text,
      coremsg: e,
      hints: t
    };
    if (this.errors.push(n), this.throwOnError) throw new Error(n.message);
  }

  directiveError(e) {
    this.pushError(e);
  }

  emitString(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;

    function n(e, t) {
      return 255 & (e.charCodeAt(t) || 0);
    }

    var r,
        a = /^\s*([\w\.]+\s*:\s*)?.\w+\s+(".*")\s*$/.exec(e);
    if (a && null != (r = parseString(a[2]))) {
      if (this.align(2), t) for (var _e1096 = 0; _e1096 < r.length; _e1096++) {
        this.emitShort(r.charCodeAt(_e1096));
      } else for (var _e1097 = 0; _e1097 < r.length + 1; _e1097 += 2) {
        this.emitShort(n(r, _e1097 + 1) << 8 | n(r, _e1097));
      }
    } else this.directiveError(lf("expecting string"));
  }

  parseNumber(e) {
    var t = this.parseOneInt(e.shift());
    return null == t ? null : t;
  }

  parseNumbers(e) {
    e = e.slice(1);
    var t = [];

    for (;;) {
      var n = this.parseNumber(e);

      if (null == n) {
        this.directiveError(lf("cannot parse number at '{0}'", e[0]));
        break;
      }

      if (t.push(n), "," != e[0]) {
        if (null == e[0]) break;
        this.directiveError(lf("expecting number, got '{0}'", e[0]));
        break;
      }

      if (e.shift(), null == e[0]) break;
    }

    return t;
  }

  emitSpace(e) {
    var t = this.parseNumbers(e);
    if (1 == t.length && t.push(0), 2 != t.length) this.directiveError(lf("expecting one or two numbers"));else if (t[0] % 2 != 0) this.directiveError(lf("only even space supported"));else {
      var _e1098 = 255 & t[1];

      _e1098 |= _e1098 << 8;

      for (var n = 0; n < t[0]; n += 2) {
        this.emitShort(_e1098);
      }
    }
  }

  emitBytes(e) {
    var t = this.parseNumbers(e);
    t.length % 2 != 0 && (this.directiveError(".bytes needs an even number of arguments"), t.push(0));

    for (var _e1099 = 0; _e1099 < t.length; _e1099 += 2) {
      var n = t[_e1099],
          r = t[_e1099 + 1];
      0 <= n && r <= 255 && 0 <= r && n <= 255 ? this.emitShort(255 & n | (255 & r) << 8) : this.directiveError(lf("expecting uint8"));
    }
  }

  emitHex(e) {
    e.slice(1).forEach(e => {
      if ("," != e) if (e.length % 4 != 0) this.directiveError(".hex needs an even number of bytes");else if (/^[a-f0-9]+$/i.test(e)) for (var t = 0; t < e.length; t += 4) {
        var n = parseInt(e.slice(t, t + 4), 16);
        n = (255 & n) << 8 | n >> 8 & 255, this.emitShort(n);
      } else this.directiveError(".hex needs a hex number");
    });
  }

  emitFloats(e) {
    e.slice(1).forEach(e => {
      if ("," == e) return;
      var t = parseFloat(e);
      isNaN(t) && this.directiveError("invalid .float");
      var n = float32ToUInt32(t);
      this.emitShort(65535 & n), this.emitShort(n >> 16 & 65535);
    });
  }

  emitFloats16(e) {
    e.slice(1).forEach(e => {
      if ("," == e) return;
      var t = parseFloat(e);
      isNaN(t) && this.directiveError("invalid .float16");
      var n = float16toUInt16(t);
      this.emitShort(65535 & n);
    });
  }

  handleDirective(e) {
    var t,
        n = e.words,
        r = () => {
      2 != n.length && this.directiveError(lf("expecting one argument"));
    };

    switch (n[0]) {
      case ".ascii":
      case ".asciz":
      case ".string":
        this.emitString(e.text);
        break;

      case ".utf16":
        this.emitString(e.text, !0);
        break;

      case ".align":
        if (r(), t = this.parseOneInt(n[1]), null != t) {
          if (0 == t) return;
          t <= 4 ? this.align(1 << t) : this.directiveError(lf("expecting 1, 2, 3 or 4 (for 2, 4, 8, or 16 byte alignment)"));
        } else this.directiveError(lf("expecting number"));

        break;

      case ".balign":
        if (r(), t = this.parseOneInt(n[1]), null != t) {
          if (1 == t) return;
          2 == t || 4 == t || 8 == t || 16 == t ? this.align(t) : this.directiveError(lf("expecting 2, 4, 8, or 16"));
        } else this.directiveError(lf("expecting number"));

        break;

      case ".p2align":
        r(), t = this.parseOneInt(n[1]), null != t ? this.align(1 << t) : this.directiveError(lf("expecting number"));
        break;

      case ".byte":
        this.emitBytes(n);
        break;

      case ".hex":
        this.emitHex(n);
        break;

      case ".float":
        this.emitFloats(n);
        break;

      case ".float16":
        this.emitFloats16(n);
        break;

      case ".hword":
      case ".short":
      case ".2bytes":
        this.parseNumbers(n).forEach(e => {
          -32768 <= e && e <= 65535 ? this.emitShort(65535 & e) : this.directiveError(lf("expecting int16"));
        });
        break;

      case ".word":
      case ".4bytes":
      case ".long":
        this.parseNumbers(n).forEach(e => {
          -2147483648 <= e && e <= 4294967295 ? (this.emitShort(65535 & e), this.emitShort(e >> 16 & 65535)) : this.directiveError(lf("expecting int32"));
        });
        break;

      case ".skip":
      case ".space":
        this.emitSpace(n);
        break;

      case ".set":
      case ".equ":
        /^\w+$/.test(n[1]) || this.directiveError(lf("expecting name"));
        var a = this.parseNumbers(n.slice("," == n[2] || "=" == n[2] ? 2 : 1));
        1 != a.length && this.directiveError(lf("expecting one value")), void 0 !== this.equs[n[1]] && this.equs[n[1]] != a[0] && this.directiveError(lf("redefinition of {0}", n[1])), this.equs[n[1]] = a[0];
        break;

      case ".startaddr":
        this.location() && this.directiveError(lf(".startaddr can be only be specified at the beginning of the file")), r(), this.baseOffset = this.parseOneInt(n[1]);
        break;

      case "@stackmark":
        r(), this.stackpointers[n[1]] = this.stack;
        break;

      case "@stackempty":
        this.checkStack && (null == this.stackpointers[n[1]] ? this.directiveError(lf("no such saved stack")) : this.stackpointers[n[1]] != this.stack && this.directiveError(lf("stack mismatch")));
        break;

      case "@scope":
        this.scope = n[1] || "", this.currLineNo = this.scope ? 0 : this.realCurrLineNo;
        break;

      case ".syntax":
      case "@nostackcheck":
        this.checkStack = !1;
        break;

      case "@dummystack":
        r(), this.stack += this.parseOneInt(n[1]);
        break;

      case ".section":
      case ".global":
        this.stackpointers = {}, this.stack = 0, this.scope = "$S" + this.scopeId++;
        break;

      case ".comm":
        {
          n = n.filter(e => "," != e), n.shift();

          var _e1100 = this.parseOneInt(n[1]),
              _t740 = 0;

          if (_t740 = n[2] ? this.parseOneInt(n[2]) : 4, null == this.lookupLabel(n[0])) {
            for (this.commPtr || (this.commPtr = this.lookupExternalLabel("_pxt_comm_base") || 0, this.commPtr || this.directiveError(lf("PXT_COMM_BASE not defined"))); this.commPtr & _t740 - 1;) {
              this.commPtr++;
            }

            this.labels[this.scopedName(n[0])] = this.commPtr - this.baseOffset, this.commPtr += _e1100;
          }

          break;
        }

      case ".arch":
      case ".thumb":
      case ".file":
      case ".text":
      case ".cpu":
      case ".fpu":
      case ".eabi_attribute":
      case ".code":
      case ".thumb_func":
      case ".type":
      case ".fnstart":
      case ".save":
      case ".size":
      case ".fnend":
      case ".pad":
      case ".globl":
      case ".local":
      case "@":
        break;

      default:
        /^\.cfi_/.test(n[0]) || this.directiveError(lf("unknown directive"));
    }
  }

  handleOneInstruction(e, t) {
    var n = t.emit(e);
    return !n.error && (this.stack += n.stack, this.checkStack && this.stack < 0 && this.pushError(lf("stack underflow")), e.location = this.location(), e.opcode = n.opcode, e.stack = n.stack, this.emitOpCode(n.opcode), null != n.opcode2 && this.emitOpCode(n.opcode2), null != n.opcode3 && this.emitOpCode(n.opcode3), e.instruction = t, e.numArgs = n.numArgs, !0);
  }

  handleInstruction(e) {
    if (e.instruction && this.handleOneInstruction(e, e.instruction)) return;

    var t = e => this.ei.instructions.hasOwnProperty(e) ? this.ei.instructions[e] : [];

    var n = t(e.words[0]);

    for (var _t741 = 0; _t741 < n.length; ++_t741) {
      if (this.handleOneInstruction(e, n[_t741])) return;
    }

    var r = this.ei.stripCondition(e.words[0]);

    if (r && (n = t(r), n.length > 0)) {
      e.words[0] = r;

      for (var _t742 = 0; _t742 < n.length; ++_t742) {
        if (this.handleOneInstruction(e, n[_t742])) return;
      }
    }

    var a = e.words[0].toLowerCase().replace(/s$/, "").replace(/[^a-z]/g, "");
    a = this.ei.stripCondition(a) || a;
    var s = "",
        o = t(a).concat(t(a + "s"));
    o.length > 0 && o.forEach(t => {
      var n = t.emit(e);
      s += lf("   Maybe: {0} ({1} at '{2}')\n", t.toString(), n.error, n.errorAt);
    }), this.pushError(lf("assembly error"), s);
  }

  buildLine(e, t) {
    var n = e => {
      var n = new Line(this, e);
      return n.scope = this.scope, n.lineNo = this.currLineNo, t.push(n), n;
    },
        r = n(e),
        a = tokenize(r.text) || [];

    r.words = a;
    var s = a[0] || "";

    if (":" == s.charAt(s.length - 1)) {
      var _t743 = /^([\.\w]+):$/.exec(a[0]);

      if (_t743) {
        if (r.type = "label", r.text = _t743[1] + ":", r.words = [_t743[1]], !(a.length > 1)) return;
        a.shift(), r = n(e.replace(/^[^:]*:/, "")), r.words = a, s = a[0] || "";
      }
    }

    var o = s.charAt(0);
    "." == o || "@" == o ? (r.type = "directive", "@scope" == r.words[0] && this.handleDirective(r)) : r.type = 0 == r.words.length ? "empty" : "instruction";
  }

  prepLines(e) {
    this.currLineNo = 0, this.realCurrLineNo = 0, this.lines = [], e.split(/\r?\n/).forEach(e => {
      this.errors.length > 10 || (this.currLineNo++, this.realCurrLineNo++, this.buildLine(e, this.lines));
    });
  }

  iterLines() {
    this.stack = 0, this.buf = [], this.scopeId = 0, this.lines.forEach(e => {
      if (!(this.errors.length > 10) && (this.currLine = e, 0 != e.words.length)) if ("label" == e.type) {
        var t = this.scopedName(e.words[0]);

        if (this.prevLabel = t, this.finalEmit) {
          null != this.equs[t] && this.directiveError(lf(".equ redefined as label"));
          var _e1101 = this.labels[t];
          null == _e1101 && oops(), 0 == this.errors.length && _e1101 != this.location() && oops("invalid location: ".concat(this.location(), " != ").concat(_e1101, " at ").concat(t)), assert(this.errors.length > 0 || _e1101 == this.location()), this.reallyFinalEmit && (this.stackAtLabel[t] = this.stack);
        } else this.labels.hasOwnProperty(t) ? this.directiveError(lf("label redefinition")) : this.inlineMode && /^_/.test(t) ? this.directiveError(lf("labels starting with '_' are reserved for the compiler")) : this.labels[t] = this.location();

        e.location = this.location();
      } else "directive" == e.type ? this.handleDirective(e) : "instruction" == e.type ? this.handleInstruction(e) : "empty" == e.type || oops();
    });
  }

  getSource(e) {
    var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 1;
    var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 0;

    var r = 0,
        a = e => {
      var t = this.labels[e] || r,
          n = t - r;
      return r = t, n;
    },
        s = this.buf ? this.location() : 0,
        o = a("_code_end"),
        i = a("_helpers_end"),
        l = a("_vtables_end"),
        u = a("_literals_end"),
        c = r,
        p = s + this.baseOffset & 16777215;

    n && p > n && userError(lf("program too big by {0} bytes!", p - n));
    var d = lf("; total bytes: {0} ({1}% of {2}k flash with {3} free)", p, (100 * p / (n = n || 131072)).toFixed(1), (n / 1024).toFixed(1), n - p),
        h = lf("; generated code sizes (bytes): {0} (incl. {1} user, {2} helpers, {3} vtables, {4} lits); src size {5}\n", c, o, i, l, u, s - c) + lf("; assembly: {0} lines; density: {1} bytes/stmt; ({2} stmts)\n", this.lines.length, Math.round(100 * o / t) / 100, t) + d + "\n" + this.stats + "\n\n",
        m = !1;
    return this.lines.forEach((t, n) => {
      if ("_stored_program" == t.words[0]) return h += '_stored_program: .string "..."\n', void (m = !0);
      if (m) return void (m = !1);
      var r = t.text;

      if (e) {
        if ("@stackempty" == t.words[0] && this.lines[n - 1].text == t.text) return;
        if (r = r.replace(/; WAS: .*/, ""), !r.trim()) return;
      }

      h += r + "\n";
    }), h;
  }

  peepHole() {
    var e = this.lines.filter(e => "empty" != e.type);

    for (var t = 0; t < e.length; ++t) {
      var n = e[t];
      if (/^user/.test(n.scope)) continue;
      var r = e[t + 1];
      if (!r) continue;
      var a = e[t + 2];
      "instruction" == n.type && this.ei.peephole(n, r, a);
    }
  }

  clearLabels() {
    this.labels = {}, this.commPtr = 0;
  }

  peepPass(e) {
    this.peepOps = 0, this.peepDel = 0, this.peepCounts = {}, this.peepHole(), this.throwOnError = !0, this.finalEmit = !1, this.clearLabels(), this.iterLines(), assert(!this.checkStack || 0 == this.stack), this.finalEmit = !0, this.reallyFinalEmit = e || 0 == this.peepOps, this.iterLines(), this.stats += lf("; peep hole pass: {0} instructions removed and {1} updated\n", this.peepDel, this.peepOps - this.peepDel);
  }

  getLabels() {
    return this.userLabelsCache || (this.userLabelsCache = mapMap(this.labels, (e, t) => t + this.baseOffset)), this.userLabelsCache;
  }

  emit(e) {
    if (assert(null == this.buf), this.prepLines(e), !(this.errors.length > 0 || (this.clearLabels(), this.iterLines(), this.checkStack && 0 != this.stack && this.directiveError(lf("stack misaligned at the end of the file")), this.errors.length > 0 || (this.ei.expandLdlit(this), this.clearLabels(), this.iterLines(), this.finalEmit = !0, this.reallyFinalEmit = this.disablePeepHole, this.iterLines(), this.errors.length > 0 || this.disablePeepHole)))) {
      var _e1102 = 5;

      for (var t = 0; t < _e1102 && (console.debug("Peephole OPT, pass ".concat(t)), this.peepPass(t == _e1102), 0 != this.peepOps); ++t) {
        ;
      }
    }
  }

}

class AbstractProcessor {
  constructor() {
    this.file = null, this.encoders = {}, this.instructions = {};
  }

  toFnPtr(e, t, n) {
    return e;
  }

  wordSize() {
    return -1;
  }

  computeStackOffset(e, t) {
    return t;
  }

  is32bit(e) {
    return !1;
  }

  emit32(e, t, n) {
    return null;
  }

  postProcessRelAddress(e, t) {
    return t;
  }

  postProcessAbsAddress(e, t) {
    return t;
  }

  peephole(e, t, n) {}

  registerNo(e, t) {
    return null;
  }

  getAddressFromLabel(e, t, n) {
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
    return null;
  }

  isPop(e) {
    return !1;
  }

  isPush(e) {
    return !1;
  }

  isAddSP(e) {
    return !1;
  }

  isSubSP(e) {
    return !1;
  }

  testAssembler() {
    assert(!1);
  }

  expandLdlit(e) {}

  addEnc(e, t, n) {
    var r = {
      name: e,
      pretty: t,
      encode: n,
      isRegister: /^\$[sr]\d/i.test(e),
      isImmediate: /^\$i\d/i.test(e),
      isRegList: /^\$[sr]l\d/i.test(e),
      isLabel: /^\$l[a-z]/i.test(e)
    };
    return this.encoders[e] = r, r;
  }

  inrange(e, t, n) {
    return Math.floor(t) != t || t < 0 || t > e ? null : n;
  }

  inminmax(e, t, n, r) {
    return Math.floor(n) != n || n < e || n > t ? null : r;
  }

  inseq(e, t) {
    var n = e.indexOf(t);
    return n < 0 ? null : n;
  }

  inrangeSigned(e, t, n) {
    return Math.floor(t) != t || t < -(e + 1) || t > e ? null : n & (e << 1 | 1);
  }

  addInst(e, t, n, r) {
    var a = new Instruction(this, e, t, n, r);
    return this.instructions.hasOwnProperty(a.name) || (this.instructions[a.name] = []), this.instructions[a.name].push(a), a;
  }

  addInst32(e, t, n) {
    var r = 2147483648;
    return assert(!!(t & r)), assert(!!(n & r)), this.addInst(e, t &= ~r, n &= ~r, !0);
  }

}

function tokenize(e) {
  var t = [],
      n = "";

  e: for (var r = 0; r < e.length; ++r) {
    switch (e[r]) {
      case "[":
      case "]":
      case "!":
      case "{":
      case "}":
      case ",":
        n && (t.push(n), n = ""), t.push(e[r]);
        break;

      case " ":
      case "\t":
      case "\r":
      case "\n":
        n && (t.push(n), n = "");
        break;

      case "/":
        if ("/" == e[r + 1]) break e;
        break;

      case ";":
        break e;

      default:
        n += e[r];
    }
  }

  return n && (t.push(n), n = ""), t[0] ? t : null;
}

function parseString(e) {
  e = e.replace(/\\\\/g, "\\B").replace(/\\(['\?])/g, (e, t) => t).replace(/\\[z0]/g, "\0").replace(/\\x([0-9a-f][0-9a-f])/gi, (e, t) => "\\u00" + t).replace(/\\B/g, "\\\\");

  try {
    return JSON.parse(e);
  } catch (e) {
    return null;
  }
}

function emitErr(e, t) {
  return {
    stack: null,
    opcode: null,
    error: e,
    errorAt: t
  };
}

function expectError(e, t) {
  var n = new File$1(e);
  n.emit(t), 0 == n.errors.length && oops("ASMTEST: expecting error for: " + t);
}

function tohex(e) {
  return e < 0 || e > 65535 ? ("0x" + e.toString(16)).toLowerCase() : ("0x" + ("000" + e.toString(16)).slice(-4)).toLowerCase();
}

function expect$1(e, t) {
  var n = [],
      r = t.replace(/^([0-9a-fA-F]{4,8})\s/gm, (e, t) => (n.push(parseInt(t.slice(0, 4), 16)), 8 == t.length && n.push(parseInt(t.slice(4, 8), 16)), "")),
      a = new File$1(e);
  a.throwOnError = !0, a.disablePeepHole = !0, a.emit(r), a.errors.length > 0 && (console.debug(a.errors[0].message), oops("ASMTEST: not expecting errors")), a.buf.length != n.length && oops("ASMTEST: wrong buf len");

  for (var _e1103 = 0; _e1103 < n.length; ++_e1103) {
    a.buf[_e1103] != n[_e1103] && oops("ASMTEST: wrong buf content at " + _e1103 + " , exp:" + tohex(n[_e1103]) + ", got: " + tohex(a.buf[_e1103]));
  }
}

var asmDeps = {
  softmax: ["expf_asm"]
},
    asmFns = {
  expf_asm: "\n// based on https://stackoverflow.com/questions/29381117\nexpf_asm:\n\tvldr.32\ts15, .L10\n\tvcmpe.f32\ts0, s15\n\tvmrs\tAPSR_nzcv, FPSCR\n\tbmi\t.L5\n\tvldr.32\ts15, .L10+4\n\tvcmpe.f32\ts0, s15\n\tvmrs\tAPSR_nzcv, FPSCR\n\tbgt\t.L9\n\tvldr.32\ts15, .L10+8\n\tvldr.32\ts9, .L10+12\n\tvldr.32\ts6, .L10+16\n\tvldr.32\ts7, .L10+20\n\tvldr.32\ts10, .L10+24\n\tvldr.32\ts8, .L10+28\n\tvldr.32\ts11, .L10+32\n\tvldr.32\ts12, .L10+36\n\tvldr.32\ts13, .L10+40\n\tvmul.f32\ts15, s0, s15\n\tvmov.f32\ts14, #1.0\n\tvadd.f32\ts15, s15, s9\n\tvsub.f32\ts15, s15, s9\n\tvfma.f32\ts0, s15, s6\n\tvcvt.s32.f32\ts9, s15\n\tvfma.f32\ts0, s15, s7\n\tvmov.f32\ts15, s10\n\tvfma.f32\ts15, s8, s0\n\tvmov\tr3, s9\t// int\n\tvfma.f32\ts11, s15, s0\n\tvfma.f32\ts12, s11, s0\n\tvfma.f32\ts13, s12, s0\n\tvmov.f32\ts15, s13\n\tvmov.f32\ts13, s14\n\tvfma.f32\ts13, s15, s0\n\tvfma.f32\ts14, s13, s0\n\tvmov\tr2, s14\t// int\n\tadd\tr3, r2, r3, lsl #23\n\tvmov\ts0, r3\t// int\n\tbx\tlr\n.L9:\n\tvldr.32\ts15, .L10+44\n\tvmov.f32\ts14, #1.0\n\tvdiv.f32\ts0, s14, s15\n\tbx\tlr\n.L5:\n\tvldr.32\ts0, .L10+44\n\tbx\tlr\n.L11:\n\t.align\t2\n.L10:\n\t.word\t3265921024\n\t.word\t1118699520\n\t.word\t1069066811\n\t.word\t1262485504\n\t.word\t3207688704\n\t.word\t3049242254\n\t.word\t1007234926\n\t.word\t984915968\n\t.word\t1026207149\n\t.word\t1042983464\n\t.word\t1056964603\n\t.word\t0\n",
  softmax: "\nsoftmax:\n\tcmp\tr1, #1\n\tpush\t{r3, r4, r5, lr}\n\tvldr.32\ts5, [r0]\n\tbls\t.L13\n\tadds\tr3, r0, #4\n\tadd\tr2, r0, r1, lsl #2\n.L16:\n\tvldmia.32\tr3!, {s15}\n\tvcmp.f32\ts15, s5\n\tvmrs\tAPSR_nzcv, FPSCR\n\tit\tgt\n\tvmovgt.f32\ts5, s15\n\tcmp\tr2, r3\n\tbne\t.L16\n.L17:\n\tmovs\tr4, #0\n\tvmov\ts4, r4\n\tmov\tr5, r0\n.L19:\n\tvldr.32\ts0, [r5]\n\tvsub.f32\ts0, s0, s5\n\tbl\texpf_asm\n\tadds\tr4, #1\n\tcmp\tr1, r4\n\tvadd.f32\ts4, s4, s0\n\tvstmia.32\tr5!, {s0}\n\tbhi\t.L19\n\tmovs\tr3, #0\n.L20:\n\tvldr.32\ts14, [r0]\n\tvdiv.f32\ts15, s14, s4\n\tadds\tr3, #1\n\tcmp\tr1, r3\n\tvstmia.32\tr0!, {s15}\n\tbhi\t.L20\n\tpop\t{r3, r4, r5, pc}\n.L13:\n\tcmp\tr1, #0\n\tbne\t.L17\n\tpop\t{r3, r4, r5, pc}\n"
},
    unrollLimit = 10;
var OpCode, Reg, F16Mode;

function assert$1(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : "assertion failed";
  if (!e) throw new Error("ir: " + t);
}

function addParamBytes(e, t) {
  assert$1(0 == (e.weightPtr & t.length - 1)), e.weightBuffer || (e.weightBuffer = new Uint8Array(128));
  var n = e.weightPtr + t.length;

  if (n + 3 > e.weightBuffer.length) {
    var _t744 = new Uint8Array(2 * n);

    _t744.set(e.weightBuffer), e.weightBuffer = _t744;
  }

  e.weightBuffer.set(t, e.weightPtr), e.weightPtr = n;
}

function addFloat32(e, t) {
  assert$1(null != t && !isNaN(t)), e.weightAsm += ".float ".concat(t, "\n");
  var n = float32ToUInt32(t);
  addParamBytes(e, [n >> 0 & 255, n >> 8 & 255, n >> 16 & 255, n >> 24 & 255]);
}

function addFloat16(e, t) {
  assert$1(null != t && !isNaN(t)), e.weightAsm += ".float16 ".concat(t, "\n");
  var n = float16toUInt16(t);
  addParamBytes(e, [n >> 0 & 255, n >> 8 & 255]);
}

function alignWeights(e) {
  for (; 3 & e.weightPtr;) {
    addParamBytes(e, [0]);
  }

  e.weightAsm += ".balign 4\n";
}

function addWeight(e, t) {
  e.opts.float16weights ? addFloat16(e, t) : addFloat32(e, t);
}

function addBias(e, t) {
  addFloat32(e, t);
}

function weightOffset(e) {
  return assert$1(0 == (3 & e.weightPtr)), e.weightPtr >> 2;
}

function stringifyComment(e) {
  return e ? "// " + e.replace(/\n/g, "\n// ") : "";
}

function indent(e) {
  return "  " + e.replace(/\n$/, "").replace(/\n/g, "\n  ") + "\n";
}

function numCycles(e) {
  var t = 0,
      n = null;

  var r = e => e < 4096 ? 1 : 2;

  for (var a of e) {
    switch (a.opcode) {
      case OpCode.comment:
      case OpCode.label:
        break;

      case OpCode.repeat:
        t += (numCycles(a.body) + 4 + (a.isDef ? 1 : 0)) * a.num + 1;
        break;

      case OpCode.loadWeightAddr:
        t += 2 + r(4 * a.num);
        break;

      case OpCode.loadDataAddr:
        t += r(4 * a.num + 8);
        break;

      case OpCode.addPtr:
        null == a.src ? t += r(4 * a.num) : (1 != a.num && (a.src > Reg.Zero ? a.src == Reg.Zero + 1 || (a.src == Reg.Zero + 2 ? t++ : t += 2) : t++), t += 2), t += 1 == a.num ? 1 : 3;
        break;

      case OpCode.loadFConst:
        t += 0 == a.num ? 2 : 1 == a.num ? 1 : 4;
        break;

      case OpCode.load:
      case OpCode.store:
        t += 1 + a.num;
        break;

      case OpCode.relu:
        t += 6;
        break;

      case OpCode.vmax:
        t += 4, a.src != a.dst && t++;
        break;

      case OpCode.vmul:
      case OpCode.vadd:
        t += a.src === n || a.srcAlt === n ? 2 : 1, n = a.dst;
        break;

      case OpCode.vcvt:
        t += 1;
        break;

      case OpCode.fcall:
        t += "softmax" == a.fname ? 200 + 150 * a.num : 500 + 500 * a.num;
        break;

      default:
        throw new Error("bad op " + a.opcode);
    }
  }

  return t;
}

function toThumb(e, t) {
  var n;
  var r = {},
      a = !!e.opts.testInput && !!e.opts.includeTest;
  var s = "";

  var o = e => 4 * (e + 2),
      i = ["0x30470f62  // magic", "0x46344c4d  // more magic; ML4F", "_start_model-_header // header size", "_end-_header // total size of compiled object", "_weights-_header // offset of weights", a ? "_testInput-_header" : "0 // no tests", a ? "_testOutput-_header" : "0 // no tests", "".concat(o(e.arenaSize), " // arena size"), "".concat(o(0), "  // offset of input data"), "1 // input type - float32", "".concat(o(e.outputOffset), "  // offset of output data"), "1 // output type - float32"];

  for (var _e1104 = 0; _e1104 < 4; ++_e1104) {
    i.push("0 // padding");
  }

  h(e.inputShape, "input"), h(e.outputShape, "output");
  var l = "";

  for (; (null === (n = t[0]) || void 0 === n ? void 0 : n.opcode) == OpCode.comment;) {
    l += stringifyComment(t.shift().fname) + "\n";
  }

  var u = {},
      c = "".concat(stringifyComment(e.stats), "\n    .cpu cortex-m4\n    .text\n    .arch armv7e-m\n    .syntax unified\n    .thumb\n    .thumb_func\n    .fpu fpv4-sp-d16\n// ABI: r0 -> points to magic, r1 -> points to RAM arena\n_header:\n");

  for (var _e1105 of i) {
    f(".word ".concat(_e1105));
  }

  var p = 0;
  u[Reg.InputPtr] = 1, u[Reg.OutputPtr] = 2, u[Reg.KernelPtr] = 3, u[Reg.DataDescPtr] = 7, f("_start_model:"), f("push {r4,r5,r6,r7,r8,r9,r10,r11,r12,lr}"), f("mov ".concat($(Reg.DataDescPtr), ", r1")), f("ldr r1, [r0, #4*4] // weight offset"), f("adds r1, r0 // weight addr"), f("str r1, [".concat($(Reg.DataDescPtr), ", #0]")), f("movs r1, #0"), f("str r1, [".concat($(Reg.DataDescPtr), ", #4]")), I(t), f("pop {r4,r5,r6,r7,r8,r9,r10,r11,r12,pc}");

  for (var _e1106 of Object.keys(r)) {
    for (var _t745 of asmDeps[_e1106] || []) {
      r[_t745] = !0;
    }
  }

  for (var _e1107 of Object.keys(r)) {
    f(asmFns[_e1107]);
  }

  return f(".balign 4"), f("_weights:\n".concat(e.weightAsm)), a && (d("_testInput", e.opts.testInput), d("_testOutput", e.opts.testOutput)), f("_end:"), c;

  function d(e, t) {
    f("".concat(e, ":"));

    for (var _e1108 of t) {
      f(".float ".concat(_e1108));
    }
  }

  function h(e, t) {
    for (var _n440 of e) {
      null != _n440 && i.push("".concat(_n440, " // ").concat(t, " shape"));
    }

    i.push("0 // end of ".concat(t, " shape"));
  }

  function m(e, t) {
    assert$1(!u[e]);
    var n = {},
        r = {};

    for (var _e1109 of Object.keys(u)) {
      n[_e1109] = u[_e1109], r[n[_e1109]] = !0;
    }

    var a = -1;

    for (var _e1110 = 4; _e1110 <= 12; ++_e1110) {
      if (!r[_e1110]) {
        a = _e1110;
        break;
      }
    }

    if (a < 0 && g("can't alloc " + e), u[e] = a, t) {
      var _e1111 = s;

      try {
        s += "    ", t();
      } finally {
        s = _e1111, u = n;
      }
    }
  }

  function f(e) {
    y(e) && g("wrong reg: " + e), c += s + e + "\n";
  }

  function g(e) {
    throw new Error("internal thumb error: " + e);
  }

  function $(e) {
    if (null == e) return "<fake>";
    if (e <= Reg.S31) return "s" + (e - Reg.S0);
    if (e >= Reg.Zero) return "#" + (e - Reg.Zero);
    var t = u[e];
    return null == t ? "<fake:" + regName(e) + ">" : "r" + t;
  }

  function y(e) {
    return e.indexOf("<fake") >= 0;
  }

  function b(e) {
    return /^r[0-7]$/.test(e);
  }

  function x(e, t) {
    t <= 255 && b(e) ? f("movs ".concat(e, ", #").concat(t)) : f("movw ".concat(e, ", #").concat(t));
  }

  function v(e, t, n) {
    Math.abs(n) < 4096 ? f(n < 0 ? "subw ".concat(e, ", ").concat(t, ", #").concat(-n) : "addw ".concat(e, ", ").concat(t, ", #").concat(n)) : (assert$1(t != e), x(e, n), f("adds ".concat(e, ", ").concat(t, ", ").concat(e)));
  }

  function I(e) {
    for (var _t746 of e) {
      S(_t746);
    }
  }

  function C(e) {
    return "{" + range(e.num).map(t => $(e.dst + t)).join(",") + "}";
  }

  function S(e) {
    var t = $(e.dst);
    var n = $(e.src),
        a = $(e.srcAlt),
        s = e.increment ? "!" : "";

    switch (e.opcode) {
      case OpCode.label:
        f("".concat(e.fname, ":"));
        break;

      case OpCode.comment:
        f(stringifyComment(e.fname));
        break;

      case OpCode.repeat:
        assert$1(e.num >= 1), m(e.dst, () => {
          t = $(e.dst);
          var n = ".l." + p++;
          x(t, e.isDef ? 0 : e.num), f("".concat(n, ":  // rep ").concat(e.num)), I(e.body), e.isDef ? (f("adds ".concat(t, ", #1")), f("cmp ".concat(t, ", #").concat(e.num)), f("blt ".concat(n))) : (b(t) ? f("subs ".concat(t, ", #1")) : f("subs ".concat(t, ", ").concat(t, ", #1")), f("bne ".concat(n)));
        });
        break;

      case OpCode.loadWeightAddr:
        f("ldr r0, [".concat($(Reg.DataDescPtr), ", #0]")), v(t, "r0", 4 * e.num);
        break;

      case OpCode.loadDataAddr:
        v(t, $(Reg.DataDescPtr), o(e.num));
        break;

      case OpCode.addPtr:
        if (y(t) && e.isDef && (m(e.dst), t = $(e.dst)), null == e.src) v(t, a, 4 * e.num);else {
          if (1 != e.num) {
            if (x("r0", 4 * e.num), "#" == n[0]) {
              var _e1112 = +n.slice(1);

              0 == _e1112 ? x("r0", 0) : 1 == _e1112 || (2 == _e1112 ? f("adds r0,r0") : (assert$1(t != a), x(t, _e1112), f("muls r0, ".concat(t))));
            } else f("muls r0, ".concat(n));
          } else "#" == n[0] ? x("r0", +n.slice(1) << 2) : f("lsls r0, ".concat(n, ", #2"));
          f("adds ".concat(t, ", ").concat(a, ", r0"));
        }
        break;

      case OpCode.loadFConst:
        0 == e.num ? f("vldr ".concat(t, ", [").concat($(Reg.DataDescPtr), ", #4]")) : e.num == Number.NEGATIVE_INFINITY ? (f("movw r0, #0xff80"), f("lsls r0, r0, #16"), f("vmov ".concat(t, ", r0"))) : f("vmov ".concat(t, ", #").concat(e.num, "e+0"));
        break;

      case OpCode.load:
        assert$1(e.f16Mode != F16Mode.On), f("vldm ".concat(n).concat(s, ", ").concat(C(e)));
        break;

      case OpCode.store:
        f("vstm ".concat(n).concat(s, ", ").concat(C(e)));
        break;

      case OpCode.relu:
        f("ldr r0, [".concat(t, ", #0]")), f("cmp r0, #0"), f("it lt"), f("movwlt r0, #0"), f("stm ".concat(t, "!, {r0}"));
        break;

      case OpCode.vmul:
        f("vmul.f32 ".concat(t, ", ").concat(n, ", ").concat(a));
        break;

      case OpCode.vadd:
        f("vadd.f32 ".concat(t, ", ").concat(n, ", ").concat(a));
        break;

      case OpCode.vcvt:
        f("".concat(e.fname, " ").concat(t, ", ").concat(n));
        break;

      case OpCode.vmax:
        assert$1(t != a), n != t && f("vmov ".concat(t, ", ").concat(n)), f("vcmp.f32 ".concat(t, ", ").concat(a)), f("vmrs APSR_nzcv, FPSCR"), f("it mi"), f("vmovmi.f32 ".concat(t, ", ").concat(a));
        break;

      case OpCode.fcall:
        f("mov r0, ".concat(t)), x("r1", e.num), f("bl ".concat(e.fname)), r[e.fname] = !0;
        break;

      default:
        g("bad op " + e.opcode);
    }
  }
}

function toJS(e, t) {
  var n = "";

  if (t.opcode == OpCode.repeat) {
    var r = regName(t.dst);
    n = "for (let ".concat(r, " = 0; ").concat(r, " < ").concat(t.num, "; ").concat(r, "++) {\n").concat(indent(toJSs(e, t.body)), "}\n");
  } else n = stringify1(t);

  return n.indexOf("???") >= 0 && oops("invalid register in: " + n), n;
}

function stringify(e) {
  return e.map(stringify1).join("");
}

function stringify1(e) {
  var t = null == e.dst ? null : regName(e.dst),
      n = null == e.src ? null : regName(e.src),
      r = null == e.srcAlt ? null : regName(e.srcAlt);

  switch (e.opcode) {
    case OpCode.label:
      return stringifyComment("label: " + e.fname) + "\n";

    case OpCode.comment:
      return isBreak(e) ? "debugger\n" : stringifyComment(e.fname) + "\n";

    case OpCode.repeat:
      return "for (let ".concat(t, " = 0; ").concat(t, " < ").concat(e.num, "; ").concat(t, "++) {\n").concat(indent(stringify(e.body)), "}\n");

    case OpCode.loadWeightAddr:
      return "".concat(t, " = weightOff + ").concat(e.num, "\n");

    case OpCode.loadDataAddr:
      return "".concat(t, " = dataOff + ").concat(e.num, "\n");

    case OpCode.addPtr:
      return null == e.src ? "".concat(t, " = ").concat(r, " + ").concat(e.num, "\n") : "".concat(t, " = ").concat(r, " + ").concat(n).concat(1 == e.num ? "" : " * " + e.num, "\n");

    case OpCode.loadFConst:
      return "".concat(t, " = ").concat(e.num, "\n");

    case OpCode.load:
      {
        var _t747 = "",
            _r438 = e.dst + 0;

        if (e.increment) for (var a = 0; a < e.num; ++a) {
          _t747 += "".concat(regName(_r438++), " = ").concat(e.fname || "mem", "[").concat(n, "++]\n");
        } else for (var _a309 = 0; _a309 < e.num; ++_a309) {
          _t747 += "".concat(regName(_r438++), " = mem[").concat(n, " + ").concat(_a309, "]\n");
        }
        return _t747;
      }

    case OpCode.store:
      {
        var _t748 = "",
            _r439 = e.dst + 0;

        if (e.increment) for (var _a310 = 0; _a310 < e.num; ++_a310) {
          _t748 += "mem[".concat(n, "++] = ").concat(regName(_r439++), "\n");
        } else for (var _a311 = 0; _a311 < e.num; ++_a311) {
          _t748 += "mem[".concat(n, " + ").concat(_a311, "] = ").concat(regName(_r439++), "\n");
        }
        return _t748;
      }

    case OpCode.relu:
      return "if (mem[".concat(t, "] < 0) mem[").concat(t, "] = 0; ").concat(t, "++\n");

    case OpCode.vmul:
      return "".concat(t, " = f32(").concat(n, " * ").concat(r, ")\n");

    case OpCode.vadd:
      return "".concat(t, " = f32(").concat(n, " + ").concat(r, ")\n");

    case OpCode.vmax:
      return "".concat(t, " = Math.max(").concat(n, ", ").concat(r, ")\n");

    case OpCode.fcall:
      return "".concat(e.fname, "(").concat(t, ", ").concat(e.num, ")\n");

    case OpCode.vcvt:
      return "".concat(t, " = rt.").concat(e.fname.replace(/\./g, "_"), "(").concat(n, ")\n");

    default:
      throw new Error("bad op " + e.opcode);
  }
}

function regName(e) {
  if (e <= Reg.S31) return "s" + (e - Reg.S0);
  if (e >= Reg.Zero) return "" + (e - Reg.Zero);
  if (e >= Reg.Tmp0) return "tmp" + (e - Reg.Tmp0);
  if (e >= Reg.Index0) return "idx" + (e - Reg.Index0);

  switch (e) {
    case Reg.InputPtr:
      return "input";

    case Reg.KernelPtr:
      return "kernel";

    case Reg.OutputPtr:
      return "output";

    default:
      return "???" + e;
  }
}

function toJSs(e, t) {
  return t.map(t => toJS(e, t)).join("");
}

!function (e) {
  e[e.comment = 0] = "comment", e[e.label = 1] = "label", e[e.repeat = 2] = "repeat", e[e.loadWeightAddr = 3] = "loadWeightAddr", e[e.loadDataAddr = 4] = "loadDataAddr", e[e.addPtr = 5] = "addPtr", e[e.loadFConst = 6] = "loadFConst", e[e.load = 7] = "load", e[e.store = 8] = "store", e[e.vmul = 9] = "vmul", e[e.vmax = 10] = "vmax", e[e.vadd = 11] = "vadd", e[e.vcvt = 12] = "vcvt", e[e.relu = 13] = "relu", e[e.fcall = 14] = "fcall";
}(OpCode || (OpCode = {})), function (e) {
  e[e.S0 = 0] = "S0", e[e.S1 = 1] = "S1", e[e.S15 = 15] = "S15", e[e.S31 = 32] = "S31", e[e.InputPtr = 200] = "InputPtr", e[e.OutputPtr = 201] = "OutputPtr", e[e.KernelPtr = 202] = "KernelPtr", e[e.DataDescPtr = 203] = "DataDescPtr", e[e.Index0 = 300] = "Index0", e[e.Tmp0 = 400] = "Tmp0", e[e.Zero = 500] = "Zero", e[e.One = 501] = "One";
}(Reg || (Reg = {})), function (e) {
  e[e.Off = 0] = "Off", e[e.On = 1] = "On", e[e.Even = 2] = "Even", e[e.Odd = 3] = "Odd";
}(F16Mode || (F16Mode = {}));
var repIdx = 0;

function repeatIdx(e, t) {
  var n = Reg.Index0 + repIdx++;
  return {
    opcode: OpCode.repeat,
    dst: n,
    num: e,
    body: t(n),
    isDef: !0
  };
}

function repeat(e, t) {
  var n = repeatIdx(e, t);
  return n.isDef = !1, n;
}

function comment(e) {
  return {
    opcode: OpCode.comment,
    fname: e
  };
}

function label(e) {
  return {
    opcode: OpCode.label,
    fname: e
  };
}

function loadWeightAddr(e, t) {
  return assert$1(t >= 0), {
    opcode: OpCode.loadWeightAddr,
    dst: e,
    num: t
  };
}

function relaxWeights() {
  var e = addPtr(Reg.KernelPtr, null, 0);
  return e.fname = "relax", e;
}

function loadDataAddr(e, t) {
  return assert$1(t >= 0), {
    opcode: OpCode.loadDataAddr,
    dst: e,
    num: t
  };
}

function addPtr(e, t) {
  var n = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 1;
  var r = arguments.length > 3 ? arguments[3] : undefined;
  return r || (r = e), {
    opcode: OpCode.addPtr,
    dst: e,
    src: t,
    srcAlt: r,
    num: n
  };
}

function load0(e) {
  return {
    opcode: OpCode.loadFConst,
    dst: e,
    num: 0
  };
}

function loadMInf(e) {
  return {
    opcode: OpCode.loadFConst,
    dst: e,
    num: Number.NEGATIVE_INFINITY
  };
}

function load(e, t, n, r) {
  return {
    opcode: OpCode.load,
    dst: e,
    src: n,
    num: t,
    increment: r
  };
}

function load16(e, t, n) {
  return {
    opcode: OpCode.load,
    dst: e,
    src: n,
    num: t,
    increment: !0,
    f16Mode: F16Mode.On
  };
}

function loadWeight(e, t, n) {
  var r = Reg.KernelPtr;
  return e.opts.float16weights ? load16(t, n, r) : load(t, n, r, !0);
}

function store(e, t, n, r) {
  return {
    opcode: OpCode.store,
    src: e,
    dst: t,
    num: n,
    increment: r
  };
}

function relu(e) {
  return {
    opcode: OpCode.relu,
    dst: e,
    increment: !0
  };
}

function vmul(e, t, n) {
  return {
    opcode: OpCode.vmul,
    dst: e,
    src: t,
    srcAlt: n
  };
}

function vmax(e, t, n) {
  return n == e && ([t, n] = [n, t]), {
    opcode: OpCode.vmax,
    dst: e,
    src: t,
    srcAlt: n
  };
}

function vadd(e, t, n) {
  return {
    opcode: OpCode.vadd,
    dst: e,
    src: t,
    srcAlt: n
  };
}

function vcvt(e, t, n) {
  return {
    opcode: OpCode.vcvt,
    dst: t,
    src: n,
    fname: e
  };
}

function fcall(e, t, n) {
  return {
    opcode: OpCode.fcall,
    fname: e,
    dst: t,
    num: n
  };
}

function flatten() {
  var t = [],
      n = e => {
    e && t.push(e);
  };

  for (var _len11 = arguments.length, e = new Array(_len11), _key11 = 0; _key11 < _len11; _key11++) {
    e[_key11] = arguments[_key11];
  }

  for (var _t749 of e) {
    if (Array.isArray(_t749)) for (var _e1113 of _t749) {
      if (Array.isArray(_e1113)) for (var _t750 of _e1113) {
        n(_t750);
      } else n(_e1113);
    } else n(_t749);
  }

  return t;
}

function isRelax(e) {
  return e.opcode == OpCode.addPtr && "relax" == e.fname;
}

function isBreak(e) {
  return e.opcode == OpCode.comment && "BREAK" == e.fname;
}

function isOddF16(e) {
  var t = 0;

  for (var n of e) {
    n.opcode == OpCode.load && n.f16Mode && (t += n.num), isRelax(n) && (t = t + 1 & -2);
  }

  return !!(1 & t);
}

function fixupAndMarkF16(e) {
  return function e(t) {
    var n = [];

    for (var r of t) {
      if (r.opcode == OpCode.repeat) assert$1(!isOddF16(r.body)), r.body = e(r.body), n.push(r);else if (r.opcode == OpCode.load && r.f16Mode) {
        var _e1114 = 0,
            _t751 = !1;

        r.f16Mode == F16Mode.Odd ? (_e1114 = 1 + (r.num >> 1), n.push(addPtr(r.src, Reg.One, -1)), 1 & r.num || (_t751 = !0)) : r.f16Mode == F16Mode.Even ? (_e1114 = r.num + 1 >> 1, 1 & r.num && (_t751 = !0)) : assert$1(!1);
        var a = load(r.dst, _e1114, r.src, !0);
        a.fname = "memU32", n.push(a);
        var s = r.dst + _e1114 - 1;

        for (var _e1115 = r.num - 1; _e1115 >= 0; --_e1115) {
          n.push(vcvt(_t751 ? "vcvtb.f32.f16" : "vcvtt.f32.f16", r.dst + _e1115, s)), _t751 && s--, _t751 = !_t751;
        }
      } else n.push(r);
    }

    return n;
  }(function e(t) {
    var n = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;
    var r = n ? 1 : 0;

    var a = () => !!(1 & r),
        s = [];

    for (var _n441 of t) {
      if (_n441 = cloneOp(_n441), _n441.opcode != OpCode.repeat) s.push(_n441), _n441.opcode == OpCode.load && _n441.f16Mode && (assert$1(_n441.f16Mode == F16Mode.On), _n441.f16Mode = a() ? F16Mode.Odd : F16Mode.Even, r += _n441.num), isRelax(_n441) && (r = r + 1 & -2);else {
        if (0 == _n441.num) continue;

        var _t752 = a(),
            o = _n441.body,
            i = e(o, _t752);

        if (_n441.body = i.ops, i.odd != _t752) {
          if (_n441.isDef && (console.log(stringify([_n441])), assert$1(!1)), 1 == _n441.num) pushRange(s, i.ops), r++;else {
            var _a312 = 1 & _n441.num;

            _n441.num >>= 1;
            var l = e(o, i.odd);
            assert$1(l.odd == _t752), _n441.body = i.ops.concat(l.ops), s.push(_n441), _a312 && (pushRange(s, e(o, _t752).ops), r++);
          }
        } else s.push(_n441);
      }
    }

    return {
      ops: s,
      odd: !!(1 & r)
    };
  }(e).ops);
}

function cloneOp(e) {
  return {
    opcode: e.opcode,
    dst: e.dst,
    src: e.src,
    srcAlt: e.srcAlt,
    isDef: e.isDef,
    f16Mode: e.f16Mode,
    increment: e.increment,
    num: e.num,
    body: e.body,
    fname: e.fname
  };
}

function optimize(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};

  var n = e => e && null != t[e] ? t[e] : e,
      r = [];

  for (var a of e) {
    switch (a = cloneOp(a), a.dst = n(a.dst), a.src = n(a.src), a.srcAlt = n(a.srcAlt), a.opcode) {
      case OpCode.repeat:
        if (0 == a.num) ;else if (1 == a.num) t[a.dst] = Reg.Zero, pushRange(r, optimize(a.body, t));else {
          a.body = optimize(a.body, t);

          var _e1116 = !a.isDef && 2 * a.body.length < unrollLimit;

          if (a.num * a.body.length < 2 * unrollLimit) for (var _e1117 = 0; _e1117 < a.num; ++_e1117) {
            t[a.dst] = Reg.Zero + _e1117, pushRange(r, optimize(a.body, t));
          } else if (_e1116) {
            var _e1118 = unrollLimit / a.body.length | 0,
                _t753 = a.body.slice();

            for (var _n443 = 1; _n443 < _e1118; ++_n443) {
              pushRange(a.body, _t753);
            }

            var _n442 = a.num / _e1118 | 0;

            r.push(a);
            var s = a.num - _n442 * _e1118;
            a.num = _n442;

            for (var _e1119 = 0; _e1119 < s; ++_e1119) {
              pushRange(r, _t753);
            }
          } else r.push(a);
        }
        break;

      case OpCode.addPtr:
        (a.dst != a.srcAlt || 0 != a.num && a.src != Reg.Zero) && r.push(a);
        break;

      default:
        r.push(a);
    }
  }

  return r;
}

function reset() {
  repIdx = 0;
}

var inited$1 = !1;
var compilers = {
  Conv2D: {
    compile: compileConv,
    computePaddedInputShape: paddingConv
  },
  Conv1D: {
    compile: compileConv,
    computePaddedInputShape: paddingConv
  },
  MaxPooling1D: {
    compile: compileMaxPooling,
    computePaddedInputShape: paddingPool,
    needsMInfPadding: !0
  },
  MaxPooling2D: {
    compile: compileMaxPooling,
    computePaddedInputShape: paddingPool,
    needsMInfPadding: !0
  },
  Dense: {
    compile: compileDense
  },
  Dropout: {},
  Flatten: {},
  InputLayer: {},
  Reshape: {}
},
    numFPRegs = 32,
    numTmpRegs = 8;

function unsupported(e) {
  throw new Error("Unsupported operator or config: " + e);
}

function assert$2(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : "assertion failed";
  e || unsupported(t);
}

function getLayerInfo(e) {
  var t = e.__ml4f_info;
  return t || (t = {
    layer: e
  }, e.__ml4f_info = t), t;
}

function validateConfig(e) {
  var t = e.layer.getConfig();
  e.model.opts.verbose && console.log(e.inputShape, e.outputShape, t), 4 == e.inputShape.length ? (4 != e.inputShape.length && 3 != e.inputShape.length && unsupported("inputShape: " + e.inputShape.length), "channelsLast" != t.dataFormat && unsupported("dataFormat: " + t.dataFormat)) : 3 != e.inputShape.length && unsupported("inputShape: " + e.inputShape.length), t.dtype && "float32" != t.dtype && unsupported("dtype: " + t.dtype);
}

function addActivation(e, t) {
  var n = t.layer.getConfig(),
      r = shapeElts(t.outputShape);
  "linear" != n.activation && (e.push(loadDataAddr(Reg.OutputPtr, t.outputOff)), "relu" == n.activation ? e.push(repeat(r, () => [relu(Reg.OutputPtr)])) : "softmax" == n.activation ? e.push(fcall("softmax", Reg.OutputPtr, r)) : unsupported("activation: " + n.activation));
}

function paddingConv(e) {
  var t = e.layer.getConfig(),
      n = e.inputShape.slice();

  for (var r = 1; r <= t.kernelSize.length; ++r) {
    var a = t.strides[r - 1],
        s = e.outputShape[r] * a + t.kernelSize[r - 1] - a;
    assert$2(s >= n[r]), n[r] = s;
  }

  return n;
}

function paddingPool(e) {
  var t = e.layer.getConfig(),
      n = e.inputShape.slice();

  for (var r = 1; r <= t.poolSize.length; ++r) {
    var a = e.outputShape[r] * t.strides[r - 1];
    a > n[r] && (n[r] = a);
  }

  return n;
}

function compileConv(e) {
  var t = e.layer.getConfig(),
      n = numFPRegs >> 1,
      r = numFPRegs >> 1;
  validateConfig(e);

  var a = 2 == t.kernelSize.length,
      s = e.layer.weights[0].read().arraySync(),
      o = a ? s : [s],
      i = e => (e = e.slice(), a || e.unshift(1), e),
      [l, u] = i(t.kernelSize),
      [c, p] = i(t.strides),
      [d, h, m] = i(e.inputShape.slice(1)),
      [f, g, $] = i(e.outputShape.slice(1));

  assert$2(l <= d, "KH2"), assert$2(u <= h, "KW2"), assert$2(o.length == l, "KH"), assert$2(o[0].length == u, "KW"), assert$2(o[0][0].length == m, "CH"), assert$2(o[0][0][0].length == t.filters, "F"), assert$2($ == t.filters, "FF");
  var y = e.model,
      b = weightOffset(y),
      x = t.useBias ? e.layer.weights[1].read().arraySync() : null;

  for (var _e1120 = 0; _e1120 < t.filters; _e1120++) {
    x && addBias(y, x[_e1120]);

    for (var _t754 = 0; _t754 < l; _t754++) {
      for (var _n444 = 0; _n444 < u; _n444++) {
        for (var _r440 = 0; _r440 < m; ++_r440) {
          addWeight(y, o[_t754][_n444][_r440][_e1120]);
        }
      }

      alignWeights(y);
    }
  }

  var v = [loadWeightAddr(Reg.KernelPtr, b), repeatIdx(t.filters, a => {
    var s = [],
        o = t => {
      t.push(loadDataAddr(Reg.OutputPtr, e.outputOff)), t.push(addPtr(Reg.OutputPtr, a));
    };

    return o(s), s.push(t.useBias ? load(Reg.S0, 1, Reg.KernelPtr, !0) : load0(Reg.S0)), s.push(repeat(g * f, () => [store(Reg.OutputPtr, Reg.S0, 1, !1), addPtr(Reg.OutputPtr, null, t.filters)])), s.push(repeatIdx(l, a => {
      var s = [],
          i = u * m;
      var l = 0;

      var _loop58 = function _loop58(_u62) {
        l = i - _u62, l > r && (l = r), s.push(loadWeight(y, n, l)), s.push(loadDataAddr(Reg.InputPtr, e.inputOff + _u62)), s.push(addPtr(Reg.InputPtr, a, h * m)), o(s);
        var d = p * m,
            $ = c * h * m;
        s.push(repeat(f, () => [repeat(g, () => flatten(load(Reg.S0, l, Reg.InputPtr, !0), addPtr(Reg.InputPtr, null, d - l), range(l + 1).map(e => [e < l ? vmul(e, e, e + n) : null, e >= 2 ? vadd(Reg.S0, Reg.S0, e - 1) : null]), load(Reg.S1, 1, Reg.OutputPtr, !1), vadd(Reg.S0, Reg.S0, Reg.S1), store(Reg.OutputPtr, Reg.S0, 1, !1), addPtr(Reg.OutputPtr, null, t.filters))), addPtr(Reg.InputPtr, null, $ - g * d)]));
      };

      for (var _u62 = 0; _u62 < i; _u62 += l) {
        _loop58(_u62);
      }

      return s.push(relaxWeights()), s;
    })), s.push(relaxWeights()), s;
  })];
  return addActivation(v, e), v;
}

function compileMaxPooling(e) {
  var t = e.layer.getConfig(),
      n = 2 == t.poolSize.length;
  validateConfig(e);

  var r = e => (e = e.slice(), n || e.unshift(1), e),
      [a, s] = r(t.poolSize),
      [o, i] = r(t.strides),
      [l, u, c] = r(e.inputShape.slice(1)),
      [p, d, h] = r(e.outputShape.slice(1));

  assert$2(a <= l, "KH2"), assert$2(s <= u, "KW2"), assert$2(c == h, "CH"), a - 1 > numTmpRegs && unsupported("too high MaxPool2D area");
  var m = u * c;
  return [repeatIdx(c, t => {
    var n = [loadDataAddr(Reg.OutputPtr, e.outputOff), addPtr(Reg.OutputPtr, t), loadDataAddr(Reg.InputPtr, e.inputOff), addPtr(Reg.InputPtr, t)],
        r = range(a - 1).map(e => Reg.Tmp0 + e);
    r.unshift(Reg.InputPtr);

    for (var _e1121 = 1; _e1121 < a; ++_e1121) {
      var _t755 = addPtr(r[_e1121], null, m * _e1121, Reg.InputPtr);

      _t755.isDef = !0, n.push(_t755);
    }

    return n.push(repeat(p, () => flatten(repeat(d, () => {
      var e = [];

      for (var _t756 = 0; _t756 < a; ++_t756) {
        for (var _n445 = 0; _n445 < s; ++_n445) {
          var _a313 = 0 == _t756 && 0 == _n445 ? Reg.S0 : Reg.S1;

          e.push(load(_a313, 1, r[_t756], !0), addPtr(r[_t756], null, c - 1)), _a313 != Reg.S0 && e.push(vmax(Reg.S0, Reg.S0, _a313));
        }

        e.push(addPtr(r[_t756], null, (i - s) * c));
      }

      return e.push(store(Reg.OutputPtr, Reg.S0, 1, !0), addPtr(Reg.OutputPtr, null, c - 1)), e;
    }), r.map(e => addPtr(e, null, o * m - d * i * c))))), n;
  })];
}

function compileDense(e) {
  var t = e.layer.getConfig(),
      n = (numFPRegs >> 1) - 2,
      r = Reg.S1,
      a = r + n;
  2 != e.inputShape.length && unsupported("inputShape: " + e.inputShape.length), t.dtype && "float32" != t.dtype && unsupported("dtype: " + t.dtype);
  var s = e.layer.weights[0].read().arraySync(),
      o = e.inputShape[1];
  assert$2(s.length == o, "IH"), assert$2(s[0].length == t.units, "UN");
  var i = e.model,
      l = weightOffset(i),
      u = t.useBias ? e.layer.weights[1].read().arraySync() : null;

  for (var _e1122 = 0; _e1122 < t.units; _e1122++) {
    u && addBias(i, u[_e1122]);

    for (var _t757 = 0; _t757 < o; ++_t757) {
      addWeight(i, s[_t757][_e1122]);
    }

    alignWeights(i);
  }

  var c = [loadWeightAddr(Reg.KernelPtr, l), loadDataAddr(Reg.OutputPtr, e.outputOff), repeat(t.units, () => {
    var s = [];
    s.push(t.useBias ? load(Reg.S0, 1, Reg.KernelPtr, !0) : load0(Reg.S0)), s.push(loadDataAddr(Reg.InputPtr, e.inputOff));

    var l = e => flatten(load(r, e, Reg.InputPtr, !0), loadWeight(i, a, e), range(e + 1).map(t => [t < e ? vmul(r + t, r + t, a + t) : null, t >= 1 ? vadd(Reg.S0, Reg.S0, r + t - 1) : null])),
        u = o / n | 0;

    u > 0 && s.push(repeat(u, () => l(n)));
    var c = o - u * n;
    return c > 0 && pushRange(s, l(c)), s.push(store(Reg.OutputPtr, Reg.S0, 1, !0)), s.push(relaxWeights()), s;
  })];
  return addActivation(c, e), c;
}

function noop(e) {
  return [];
}

function shapeElts(e) {
  var t = 1;

  for (var n of e) {
    null != n && (t *= n);
  }

  return t;
}

function fixupCompileInfo(e) {
  void 0 === e.testable && (e.testable = !!e.compile), e.compile || (void 0 === e.inPlace && (e.inPlace = !0), e.compile = noop), e.computePaddedInputShape || (e.computePaddedInputShape = e => e.inputShape.slice());
}

function isInPlace(e) {
  var t;
  return !!(null === (t = compilers[e.getClassName()]) || void 0 === t ? void 0 : t.inPlace);
}

function needMInfPadding(e) {
  var t;
  return !!(null === (t = compilers[e.getClassName()]) || void 0 === t ? void 0 : t.needsMInfPadding);
}

function shapeToString(e) {
  return "[".concat(e.filter(e => null != e).join(","), "]");
}

function assignLayerInfos(e, t) {
  inited$1 || (inited$1 = !0, Object.values(compilers).forEach(fixupCompileInfo)), reset(), t.verbose && e.summary();
  var n = e.layers[0].batchInputShape,
      r = {
    weightPtr: 0,
    weightBuffer: new Uint8Array(128),
    weightAsm: "",
    inputShape: n,
    outputShape: null,
    outputOffset: -1,
    arenaSize: -1,
    minArenaSize: -1,
    opts: t,
    stats: ""
  };
  var a,
      s = [shapeElts(n), 0],
      o = 0,
      i = s[0];

  var l = e => i = Math.max(e, i);

  for (var _t758 of e.layers) {
    var _e1123 = getLayerInfo(_t758);

    _e1123.model = r, _e1123.inputShape = a ? a.outputShape : n, _e1123.outputShape = _t758.computeOutputShape(_e1123.inputShape);

    var _i87 = compilers[_t758.getClassName()],
        _u63 = _i87 ? _i87.computePaddedInputShape(_e1123) : _e1123.inputShape.slice();

    _e1123.inputOff = o, _e1123.rawInputShape = _e1123.inputShape.slice();

    var _c41 = shapeElts(_u63);

    shapeElts(_e1123.inputShape) != _c41 ? (o = 0 == o ? 1 : 0, _e1123.rawInputOff = _e1123.inputOff, _e1123.inputOff = o, _e1123.inputShape = _u63, _c41 > s[o] && (s[o] = _c41), l(_c41 + shapeElts(_e1123.rawInputShape))) : _e1123.rawInputOff = null;

    var _p39 = shapeElts(_e1123.outputShape);

    isInPlace(_t758) ? (l(shapeElts(_e1123.inputShape)), l(shapeElts(_e1123.outputShape))) : (l(shapeElts(_e1123.inputShape) + shapeElts(_e1123.outputShape)), o = 0 == o ? 1 : 0), _e1123.outputOff = o, _p39 > s[o] && (s[o] = _p39), a = _e1123;
  }

  r.outputShape = a.outputShape;
  var u = s[0];

  for (var _t759 of e.layers) {
    var _e1124 = getLayerInfo(_t759);

    _e1124.inputOff && (_e1124.inputOff = u), _e1124.outputOff && (_e1124.outputOff = u), _e1124.rawInputOff && (_e1124.rawInputOff = u), _e1124.stats = {
      name: _t759.name
    };
  }

  var c = s[0] + s[1];
  return r.arenaSize = c, r.minArenaSize = i, c > 1.2 * i && console.log("possible arena shrink with wiser allocation: " + (c / i).toFixed(3) + "x"), r;
}

function compilePadding(e) {
  var t = [comment("padding")];
  if (null == e.rawInputOff) return t;

  var n = e.rawInputShape.length >= 4,
      r = e => ((e = e.slice()).shift(), n || e.unshift(1), e),
      [a, s, o] = r(e.rawInputShape),
      [i, l, u] = r(e.inputShape);

  assert$2(o == u);
  var c = l - s,
      p = c >> 1,
      d = c - p,
      h = i - a,
      m = h >> 1,
      f = h - m,
      g = numFPRegs >> 1,
      $ = numFPRegs - g,
      y = Reg.S0 + g;
  t.push(needMInfPadding(e.layer) ? loadMInf(Reg.S0) : load0(Reg.S0));

  for (var _e1125 = 1; _e1125 < g; ++_e1125) {
    t.push(vadd(Reg.S0 + _e1125, Reg.S0, Reg.S0));
  }

  t.push(loadDataAddr(Reg.InputPtr, e.rawInputOff)), t.push(loadDataAddr(Reg.OutputPtr, e.inputOff));
  var b = d + p,
      x = d + f * l;
  return t.push(...v(m * l + p)), t.push(repeat(a - 1, () => flatten(I(s), v(b)))), t.push(...I(s)), t.push(...v(x)), t;

  function v(e) {
    var t = [],
        n = (e *= o) % g,
        r = (e - n) / g;
    return r && t.push(repeat(r, () => [store(Reg.OutputPtr, Reg.S0, g, !0)])), n && t.push(store(Reg.OutputPtr, Reg.S0, n, !0)), t;
  }

  function I(e) {
    var t = [],
        n = (e *= o) % $,
        r = (e - n) / $;
    return r && t.push(repeat(r, () => [load(y, $, Reg.InputPtr, !0), store(Reg.OutputPtr, y, $, !0)])), n && t.push(load(y, n, Reg.InputPtr, !0), store(Reg.OutputPtr, y, n, !0)), t;
  }
}

function optimizeWithComment(e, t, n) {
  e.float16weights && (t = fixupAndMarkF16(t));
  var r = numCycles(t);
  e.optimize && (t = optimize(t));
  var a = numCycles(t);
  n.unoptimizedCycles += r, n.optimizedCycles += a;
  var s = r ? "".concat(a, " cycles (").concat((100 * (r - a) / r).toFixed(1), "% opt)") : "(no computation)";
  return r && t.unshift(comment(s)), {
    opcodes: t,
    optinfo: s
  };
}

function statsShape(e) {
  return e.filter(e => null != e);
}

function compileModelCore(m, opts) {
  var modelInfo = assignLayerInfos(m, opts);
  void 0 === opts.optimize && (opts.optimize = !0);
  var ops = [],
      layerStats = [],
      layer0 = getLayerInfo(m.layers[0]),
      layerN = getLayerInfo(m.layers[m.layers.length - 1]),
      totalStats = {
    name: "TOTAL",
    inputShape: statsShape(layer0.rawInputShape || layer0.inputShape),
    outputShape: statsShape(layerN.outputShape),
    arenaBytes: 0,
    codeBytes: 0,
    weightBytes: 0,
    unoptimizedCycles: 0,
    optimizedCycles: 0
  };

  for (var _e1126 of m.layers) {
    var t = getLayerInfo(_e1126);
    t.stats.unoptimizedCycles = 0, t.stats.optimizedCycles = 0, t.stats.arenaBytes = 0, t.stats.inputShape = statsShape(t.rawInputShape || t.inputShape), t.stats.outputShape = statsShape(t.outputShape);
    var n = layerStats.length;

    if (layerStats.push(t.stats), ops.push([label("begin_" + n)]), null != t.rawInputOff) {
      var _e1127 = optimizeWithComment(opts, compilePadding(t), t.stats);

      ops.push(_e1127.opcodes), t.stats.arenaBytes = shapeElts(t.rawInputShape) + shapeElts(t.inputShape) << 2, t.stats.hasPadding = !0;
    }

    var r = compilers[_e1126.getClassName()];

    if (r) {
      var _n446 = weightOffset(modelInfo),
          a = optimizeWithComment(opts, r.compile(t), t.stats);

      t.stats.weightBytes = weightOffset(modelInfo) - _n446 << 2;
      var s = "data: ".concat(shapeToString(t.inputShape), "@").concat(t.inputOff, " => ").concat(shapeToString(t.outputShape), "@").concat(t.outputOff),
          o = "Layer: ".concat(_e1126.getClassName(), "; ").concat(s);
      a.opcodes.unshift(comment(o)), opts.verbose && console.log(o + " " + a.optinfo), ops.push(a.opcodes);
    } else unsupported("layer: " + _e1126.getClassName());

    t.stats.unoptimizedCycles && (t.stats.arenaBytes = Math.max(t.stats.arenaBytes, shapeElts(t.inputShape) + shapeElts(t.outputShape) << 2)), totalStats.unoptimizedCycles += t.stats.unoptimizedCycles, ops.push([label("end_" + n)]);
  }

  var flat = flatten(ops);
  var lastInfo = getLayerInfo(m.layers[m.layers.length - 1]);
  modelInfo.outputOffset = lastInfo.outputOff;
  var cycles = numCycles(flat),
      cycleinfo = "total cycles: ".concat(cycles, " (").concat((cycles / 84e3).toFixed(3), "ms at 84MHz)");
  modelInfo.stats = cycleinfo, totalStats.optimizedCycles = cycles, opts.verbose && console.log(modelInfo.stats), modelInfo.weightBuffer = modelInfo.weightBuffer.slice(0, modelInfo.weightPtr);
  var js = "\n".concat(stringifyComment(modelInfo.stats), "\n((weights, mkRuntime) => {\n    \"use strict\";\n    const weightOff = ").concat(modelInfo.arenaSize, "\n    const dataOff = 0\n    const mem = new Float32Array(weightOff + ").concat(weightOffset(modelInfo), ")\n    mem.fill(1000.2342)\n    new Uint8Array(mem.buffer).set(weights, weightOff << 2)\n    const memU32 = new Uint32Array(mem.buffer)\n    const rt = mkRuntime(mem)\n    const { softmax, f32 } = rt\n    return (inputs => {\n        if (inputs.length != ").concat(shapeElts(getLayerInfo(m.layers[0]).rawInputShape), ")\n            throw new Error(\"invalid input size\")\n        mem.set(inputs, dataOff)\n        let input, output, kernel\n        let ").concat(range(numTmpRegs).map(e => "tmp" + e).join(", "), "\n        let ").concat(range(numFPRegs).map(e => "s" + e).join(", "), "\n\n").concat(toJSs(modelInfo, flat), "\n        \n        return mem.slice(").concat(lastInfo.outputOff, ", ").concat(lastInfo.outputOff + shapeElts(lastInfo.outputShape), ")\n    })\n})\n"),
      execute = eval(js)(modelInfo.weightBuffer, mkRuntime);
  var thumb = "";

  if (opts.includeTest && opts.testOutput && opts.testOutputFromJS) {
    var _e1128 = opts.testOutput;
    opts.testOutput = execute(opts.testInput), thumb = toThumb(modelInfo, flat), opts.testOutput = _e1128;
  } else thumb = toThumb(modelInfo, flat);

  var res = {
    execute,
    js,
    thumb,
    machineCode: null,
    options: opts,
    memInfo: null,
    timeInfo: modelInfo.stats,
    stats: {
      total: totalStats,
      layers: layerStats
    }
  };
  return res;
}

function mkRuntime(e) {
  return {
    softmax: (t, n) => {
      var r = e[t];

      for (var _a314 = 1; _a314 < n; ++_a314) {
        r = Math.max(e[t + _a314], r);
      }

      var a = 0;

      for (var s = 0; s < n; ++s) {
        a += e[t + s] = Math.exp(e[t + s] - r);
      }

      for (var _r441 = 0; _r441 < n; ++_r441) {
        e[t + _r441] /= a;
      }
    },
    f32: e => {
      var t = new Float32Array(1);
      return t[0] = e, t[0];
    },
    vcvtb_f32_f16: e => float16AsUintToFloat(65535 & e),
    vcvtt_f32_f16: e => float16AsUintToFloat(e >> 16 & 65535)
  };
}

var thumbRegs = {
  r0: 0,
  r1: 1,
  r2: 2,
  r3: 3,
  r4: 4,
  r5: 5,
  r6: 6,
  r7: 7,
  r8: 8,
  r9: 9,
  r10: 10,
  r11: 11,
  r12: 12,
  sp: 13,
  r13: 13,
  lr: 14,
  r14: 14,
  pc: 15,
  r15: 15
},
    armConditions = {
  eq: 0,
  ne: 1,
  cs: 2,
  hs: 2,
  cc: 3,
  lo: 3,
  mi: 4,
  pl: 5,
  vs: 6,
  vc: 7,
  hi: 8,
  ls: 9,
  ge: 10,
  lt: 11,
  gt: 12,
  le: 13,
  "": 14,
  al: 14
};
var fpRegs;

class ThumbProcessor extends AbstractProcessor {
  constructor() {
    if (super(), this.runtimeIsARM = !1, !fpRegs) {
      fpRegs = {};

      for (var _e1129 = 0; _e1129 < 32; ++_e1129) {
        fpRegs["s" + _e1129] = _e1129;
      }
    }

    var e = function e(_e1130) {
      var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : !1;

      for (var n of Object.keys(armConditions)) {
        (14 != armConditions[n] || t) && _e1130(n, armConditions[n]);
      }
    };

    this.addEnc("$r0", "R0-7", e => this.inrange(7, e, e)), this.addEnc("$r1", "R0-7", e => this.inrange(7, e, e << 3)), this.addEnc("$r2", "R0-15", e => this.inrange(15, e, 7 & e | (8 & e) << 4)), this.addEnc("$r3", "R0-15", e => this.inrange(15, e, e << 3)), this.addEnc("$r4", "R0-7", e => this.inrange(7, e, e << 6)), this.addEnc("$r5", "R0-7", e => this.inrange(7, e, e << 8)), this.addEnc("$r01", "R0-7", e => this.inrange(7, e, e | e << 3)), this.addEnc("$i0", "#0-255", e => this.inrange(255, e, e)), this.addEnc("$i1", "#0-1020", e => this.inrange(255, e / 4, e >> 2)), this.addEnc("$i2", "#0-510", e => this.inrange(127, e / 4, e >> 2)), this.addEnc("$i3", "#0-7", e => this.inrange(7, e, e << 6)), this.addEnc("$i4", "#0-31", e => this.inrange(31, e, e << 6)), this.addEnc("$i5", "#0-124", e => this.inrange(31, e / 4, e >> 2 << 6)), this.addEnc("$i6", "#1-32", e => 0 == e ? null : 32 == e ? 0 : this.inrange(31, e, e << 6)), this.addEnc("$i7", "#0-62", e => this.inrange(31, e / 2, e >> 1 << 6)), this.addEnc("$i32", "#0-2^32", e => 1), this.addEnc("$rl0", "{R0-7,...}", e => this.inrange(255, e, e)), this.addEnc("$rl1", "{LR,R0-7,...}", e => 16384 & e ? this.inrange(255, -16385 & e, 256 | 255 & e) : this.inrange(255, e, e)), this.addEnc("$rl2", "{PC,R0-7,...}", e => 32768 & e ? this.inrange(255, -32769 & e, 256 | 255 & e) : this.inrange(255, e, e)), this.addEnc("$la", "LABEL", e => this.inrange(255, e / 4, e >> 2)).isWordAligned = !0, this.addEnc("$lb", "LABEL", e => this.inrangeSigned(127, e / 2, e >> 1)), this.addEnc("$lb11", "LABEL", e => this.inrangeSigned(1023, e / 2, e >> 1)), this.addInst("adcs  $r0, $r1", 16704, 65472), this.addInst("add   $r2, $r3", 17408, 65280), this.addInst("add   $r5, pc, $i1", 40960, 63488), this.addInst("add   $r5, sp, $i1", 43008, 63488), this.addInst("add   sp, $i2", 45056, 65408).canBeShared = !0, this.addInst("adds  $r0, $r1, $i3", 7168, 65024), this.addInst("adds  $r0, $r1, $r4", 6144, 65024), this.addInst("adds  $r01, $r4", 6144, 65024), this.addInst("adds  $r5, $i0", 12288, 63488), this.addInst("adr   $r5, $la", 40960, 63488), this.addInst("ands  $r0, $r1", 16384, 65472), this.addInst("asrs  $r0, $r1", 16640, 65472), this.addInst("asrs  $r0, $r1, $i6", 4096, 63488), this.addInst("bics  $r0, $r1", 17280, 65472), this.addInst("bkpt  $i0", 48640, 65280), this.addInst("blx   $r3", 18304, 65415), this.addInst("bx    $r3", 18176, 65408), this.addInst("cmn   $r0, $r1", 17088, 65472), this.addInst("cmp   $r0, $r1", 17024, 65472), this.addInst("cmp   $r2, $r3", 17664, 65280), this.addInst("cmp   $r5, $i0", 10240, 63488), this.addInst("eors  $r0, $r1", 16448, 65472), this.addInst("ldmia $r5!, $rl0", 51200, 63488), this.addInst("ldmia $r5, $rl0", 51200, 63488), this.addInst("ldr   $r0, [$r1, $i5]", 26624, 63488), this.addInst("ldr   $r0, [$r1, $r4]", 22528, 65024), this.addInst("ldr   $r5, [pc, $i1]", 18432, 63488), this.addInst("ldr   $r5, $la", 18432, 63488), this.addInst("ldr   $r5, [sp, $i1]", 38912, 63488).canBeShared = !0, this.addInst("ldr   $r5, [sp]", 38912, 63488).canBeShared = !0, this.addInst("ldrb  $r0, [$r1, $i4]", 30720, 63488), this.addInst("ldrb  $r0, [$r1, $r4]", 23552, 65024), this.addInst("ldrh  $r0, [$r1, $i7]", 34816, 63488), this.addInst("ldrh  $r0, [$r1, $r4]", 23040, 65024), this.addInst("ldrsb $r0, [$r1, $r4]", 22016, 65024), this.addInst("ldrsh $r0, [$r1, $r4]", 24064, 65024), this.addInst("lsls  $r0, $r1", 16512, 65472), this.addInst("lsls  $r0, $r1, $i4", 0, 63488), this.addInst("lsrs  $r0, $r1", 16576, 65472), this.addInst("lsrs  $r0, $r1, $i6", 2048, 63488), this.addInst("mov   $r2, $r3", 17920, 65280), this.addInst("movs  $r0, $r1", 0, 65472), this.addInst("movs  $r5, $i0", 8192, 63488), this.addInst("muls  $r0, $r1", 17216, 65472), this.addInst("mvns  $r0, $r1", 17344, 65472), this.addInst("negs  $r0, $r1", 16960, 65472), this.addInst("nop", 18112, 65535), this.addInst("orrs  $r0, $r1", 17152, 65472), this.addInst("pop   $rl2", 48128, 65024), this.addInst("push  $rl1", 46080, 65024), this.addInst("rev   $r0, $r1", 47616, 65472), this.addInst("rev16 $r0, $r1", 47680, 65472), this.addInst("revsh $r0, $r1", 47808, 65472), this.addInst("rors  $r0, $r1", 16832, 65472), this.addInst("sbcs  $r0, $r1", 16768, 65472), this.addInst("sev", 48960, 65535), this.addInst("stm   $r5!, $rl0", 49152, 63488), this.addInst("stmia $r5!, $rl0", 49152, 63488), this.addInst("stmea $r5!, $rl0", 49152, 63488), this.addInst("str   $r0, [$r1, $i5]", 24576, 63488).canBeShared = !0, this.addInst("str   $r0, [$r1]", 24576, 63488).canBeShared = !0, this.addInst("str   $r0, [$r1, $r4]", 20480, 65024), this.addInst("str   $r5, [sp, $i1]", 36864, 63488).canBeShared = !0, this.addInst("str   $r5, [sp]", 36864, 63488).canBeShared = !0, this.addInst("strb  $r0, [$r1, $i4]", 28672, 63488), this.addInst("strb  $r0, [$r1, $r4]", 21504, 65024), this.addInst("strh  $r0, [$r1, $i7]", 32768, 63488), this.addInst("strh  $r0, [$r1, $r4]", 20992, 65024), this.addInst("sub   sp, $i2", 45184, 65408), this.addInst("subs  $r0, $r1, $i3", 7680, 65024), this.addInst("subs  $r0, $r1, $r4", 6656, 65024), this.addInst("subs  $r01, $r4", 6656, 65024), this.addInst("subs  $r5, $i0", 14336, 63488), this.addInst("svc   $i0", 57088, 65280), this.addInst("sxtb  $r0, $r1", 45632, 65472), this.addInst("sxth  $r0, $r1", 45568, 65472), this.addInst("tst   $r0, $r1", 16896, 65472), this.addInst("udf   $i0", 56832, 65280), this.addInst("uxtb  $r0, $r1", 45760, 65472), this.addInst("uxth  $r0, $r1", 45696, 65472), this.addInst("wfe", 48928, 65535), this.addInst("wfi", 48944, 65535), this.addInst("yield", 48912, 65535), this.addInst("cpsid i", 46706, 65535), this.addInst("cpsie i", 46690, 65535), e((e, t) => this.addInst("b".concat(e, " $lb"), 53248 | t << 8, 65280)), this.addInst("b     $lb11", 57344, 63488), this.addInst("bal   $lb11", 57344, 63488), this.addInst("bl    $lb", 61440, 63488), this.addInst("bb    $lb", 57344, 63488), this.addInst("ldlit   $r5, $i32", 18432, 63488), this.addEnc("$RL0", "{R0-15,...}", e => this.inrange(65535, e, e)), this.addEnc("$R0", "R0-15", e => this.inrange(15, e, e << 8)), this.addEnc("$R1", "R0-15", e => this.inrange(15, e, e << 16)), this.addEnc("$R2", "R0-15", e => this.inrange(15, e, e << 12)), this.addEnc("$R3", "R0-15", e => this.inrange(15, e, e << 0)), this.addEnc("$I0", "#0-4095", e => this.inrange(4095, e, 255 & e | (1792 & e) << 4 | (2048 & e) << 15)), this.addEnc("$I1", "#0-4095", e => this.inrange(4095, e, e)), this.addEnc("$I2", "#0-65535", e => this.inrange(65535, e, 255 & e | (1792 & e) << 4 | (2048 & e) << 15 | (61440 & e) << 4)), this.addEnc("$I3", "#0-31", e => this.inrange(31, e, (3 & e) << 6 | e >> 2 << 12)), this.addEnc("$LB", "LABEL", e => {
      var t = e >> 1 & 2047 | (e >> 12 & 63) << 16 | (e >> 18 & 1) << 13 | (e >> 19 & 1) << 11 | (e >> 20 & 1) << 26;
      return null == this.inrangeSigned(1048575, e / 2, t) ? null : t;
    }), this.addEnc("$S0", "S0-31", e => this.inrange(31, e, e >> 1 << 0 | (1 & e) << 5)), this.addEnc("$S1", "S0-31", e => this.inrange(31, e, e >> 1 << 12 | (1 & e) << 22)), this.addEnc("$S2", "S0-31", e => this.inrange(31, e, e >> 1 << 16 | (1 & e) << 7)), this.addEnc("$SL0", "{S0-S31}", e => {
      if (!(e |= 0)) return null;
      var t = 0;

      for (; t < 32 && 0 == (e & 1 << t);) {
        t++;
      }

      if (!(e >>>= t)) return null;
      var n = 0;

      for (; 1 & e;) {
        e >>= 1, n++;
      }

      return e ? null : (e = t) >> 1 << 12 | (1 & e) << 22 | n;
    }), this.addInst32("push  $RL0", 3912040448, 4294901760), this.addInst32("pop   $RL0", 3904700416, 4294901760), this.addInst32("addw  $R0, $R1, $I0", 4060086272, 4226842624), this.addInst32("subw  $R0, $R1, $I0", 4070572032, 4226842624), this.addInst32("ldr   $R2, [$R1, $I1]", 4174381056, 4293918720), this.addInst32("str   $R2, [$R1, $I1]", 4173332480, 4293918720), this.addInst32("movw  $R0, $I2", 4064280576, 4226842624), this.addInst32("add   $R0, $R1, $R3, lsl $I3", 3942645760, 4293951488), this.addInst32("subs  $R0, $R1, $i0", 4054843392, 4293951488), this.addInst32("sub   $R0, $R1, $i0", 4053794816, 4293951488), this.addInst32("adds  $R0, $R1, $i0", 4044357632, 4293951488), this.addInst32("add   $R0, $R1, $i0", 4043309056, 4293951488), e((e, t) => this.addInst32("b".concat(e, " $LB"), 4026564608 | t << 22, 4223717376), !0), e((e, t) => this.addInst("it ".concat(e), 48904 | t << 4, 65535), !0), this.addInst32("vabs.f32     $S1, $S0", 4004514496, 4290711504), this.addInst32("vadd.f32     $S1, $S2, $S0", 3996125696, 4289728336), this.addInst32("vmul.f32     $S1, $S2, $S0", 3995077120, 4289728336), this.addInst32("vcmpe.f32    $S1, #0.0", 4004842176, 4290711536), this.addInst32("vcmpe.f32    $S1, $S0", 4004776640, 4290711504), this.addInst32("vcmp.f32     $S1, #0.0", 4004842048, 4290711536), this.addInst32("vcmp.f32     $S1, $S0", 4004776512, 4290711504), this.addInst32("vdiv.f32     $S1, $S2, $S0", 4001368576, 4289728336), this.addInst32("vfma.f32     $S1, $S2, $S0", 4003465728, 4289728336), this.addInst32("vfms.f32     $S1, $S2, $S0", 4003465792, 4289728336), this.addInst32("vfnma.f32    $S1, $S2, $S0", 4002417216, 4289728336), this.addInst32("vfnms.f32    $S1, $S2, $S0", 4002417152, 4289728336), this.addInst32("vmla.f32     $S1, $S2, $S0", 3791654160, 4289728272), this.addInst32("vmls.f32     $S1, $S2, $S0", 3793751312, 4289728272), this.addInst32("vneg.f32     $S1, $S0", 4004579904, 4290711504), this.addInst32("vsqrt.f32    $S1, $S0", 4004580032, 4290711504), this.addInst32("vsub.f32     $S1, $S2, $S0", 3996125760, 4289728336), this.addInst32("vstmdb       $R1!, $SL0", 3978299904, 4289728256), this.addInst32("vstmia       $R1!, $SL0", 3969911296, 4289728256), this.addInst32("vstmia       $R1, $SL0", 3967814144, 4289728256), this.addInst32("vstm         $R1!, $SL0", 3969911296, 4289728256), this.addInst32("vstm         $R1, $SL0", 3967814144, 4289728256), this.addInst32("vldmdb       $R1!, $SL0", 3979348480, 4289728256), this.addInst32("vldmia       $R1!, $SL0", 3970959872, 4289728256), this.addInst32("vldmia       $R1, $SL0", 3968862720, 4289728256), this.addInst32("vldm         $R1!, $SL0", 3970959872, 4289728256), this.addInst32("vldm         $R1, $SL0", 3968862720, 4289728256), this.addInst32("vldr         $S1, [$R1, $i1]", 3985639936, 4289728256), this.addInst32("vstr         $S1, [$R1, $i1]", 3984591360, 4289728256), this.addInst32("vldr         $S1, [$R1]", 3985639936, 4289728256), this.addInst32("vmrs         APSR_nzcv, fpscr", 4008835600, 4294967295), this.addInst32("vmrs         APSR_nzcv, FPSCR", 4008835600, 4294967295), this.addInst32("vmov.f32     $S1, $S0", 4004514368, 4290711504), this.addInst32("vmov         $S2, $R2", 3992979984, 4293922687), this.addInst32("vmov         $R2, $S2", 3994028560, 4293922687), this.addInst32("vldr         $S1, $la", 3986622976, 4290711296), this.addInst32("vmov.f32     $S1, #1.0", 4004973056, 4290711536), this.addInst32("vcvt.s32.f32 $S1, $S0", 4005366464, 4290711504), this.addInst32("vcvtb.f32.f16 $S1, $S0", 4004645440, 4290711504), this.addInst32("vcvtt.f32.f16 $S1, $S0", 4004645568, 4290711504), this.addInst32("vcvtb.f16.f32 $S1, $S0", 4004710976, 4290711504), this.addInst32("vcvtt.f16.f32 $S1, $S0", 4004711104, 4290711504);
  }

  stripCondition(e) {
    if (e.length >= 5) {
      var t = e.indexOf(".");
      var n = "",
          r = !1;
      if (t > 0 && (n = e.slice(t), e = e.slice(0, t), ".32" == n && (r = !0, n = "")), armConditions[e.slice(-2)]) return e.slice(0, -2) + n;
      if (r) return e;
    }

    return null;
  }

  toFnPtr(e, t, n) {
    return this.runtimeIsARM && /::/.test(n) ? e + t & -2 : e + t | 1;
  }

  wordSize() {
    return 4;
  }

  is32bit(e) {
    return "bl" == e.name || "bb" == e.name || e.is32bit;
  }

  postProcessAbsAddress(e, t) {
    return (t ^= 1) - e.baseOffset;
  }

  emit32(e, t, n) {
    var r = !!(t % 2);
    r && (t = t + 1 & -4);
    var a = t >> 1;
    if (assert(null != a), (0 | a) != a || !(-2097152 < a && a < 2097152)) return emitErr("jump out of range", n);
    var s = 2047 & a,
        o = a >> 11 & 1023;
    return {
      opcode: 4026531840 & a ? 62464 | o : 61440 | o,
      opcode2: r ? 59392 | s : 63488 | s,
      stack: 0,
      numArgs: [t],
      labelName: n
    };
  }

  expandLdlit(e) {
    var t,
        n = !1,
        r = [],
        a = {},
        s = 1;

    for (var o = 0; o < e.lines.length; ++o) {
      var i = e.lines[o];

      if (r.push(i), "instruction" == i.type && i.instruction && "ldlit" == i.instruction.name) {
        if (!t) {
          var _r443 = i.location + 900,
              _a315 = o + 1;

          for (; _a315 < e.lines.length && !(e.lines[_a315].location > _r443); ++_a315) {
            var _n447 = e.lines[_a315].getOp();

            ("b" == _n447 || "bb" == _n447 || "pop" == _n447 && "pc" == e.lines[_a315].words[2]) && (t = e.lines[_a315]);
          }

          if (t) n = !1;else for (n = !0; --_a315 > o;) {
            if ("instruction" == e.lines[_a315].type) {
              t = e.lines[_a315];
              break;
            }
          }
        }

        var _r442 = i.words[1],
            l = "#" + i.words[3],
            u = lookup(a, l);
        u || (u = "_ldlit_" + ++s, a[l] = u), i.update("ldr ".concat(_r442, ", ").concat(u));
      }

      if (i === t) {
        t = null;

        var _o158 = [],
            _l69 = "_jmpwords_" + ++s;

        n && _o158.push("bb " + _l69), _o158.push(".balign 4");

        for (var _e1131 of Object.keys(a)) {
          _o158.push(a[_e1131] + ": .word " + _e1131.slice(1));
        }

        n && _o158.push(_l69 + ":");

        for (var _t760 of _o158) {
          e.buildLine(_t760, r);
          var _n448 = r[r.length - 1];
          _n448.scope = i.scope, _n448.lineNo = i.lineNo;
        }

        a = {};
      }
    }

    e.lines = r;
  }

  getAddressFromLabel(e, t, n) {
    var r = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : !1;
    var a = e.lookupLabel(n);
    if (null == a) return null;
    var s = e.location() + 4;
    return r && (s &= 4294967292), a - s;
  }

  isPop(e) {
    return 48128 == e;
  }

  isPush(e) {
    return 46080 == e;
  }

  isAddSP(e) {
    return 45056 == e;
  }

  isSubSP(e) {
    return 45184 == e;
  }

  peephole(e, t, n) {
    var r = this.encoders.$lb11,
        a = this.encoders.$lb;

    function s(e, t) {
      return null != e.encode(t.numArgs[0] + 8) && null != e.encode(t.numArgs[0] - 8) && null != e.encode(t.numArgs[0]);
    }

    var o = e.getOp(),
        i = !1;
    "bne" != o && "beq" != o || ("b" == t.getOp() && 0 == e.numArgs[0] && (i = !0), "bb" == t.getOp() && 2 == e.numArgs[0] && (i = !0)), "bb" == o && s(r, e) ? e.update("b " + e.words[1]) : "b" == o && -2 == e.numArgs[0] ? e.update("") : "bne" == o && i && s(a, t) ? (e.update("beq " + t.words[1]), t.update("")) : "beq" == o && i && s(a, t) ? (e.update("bne " + t.words[1]), t.update("")) : "push" != o || 16384 != e.numArgs[0] || "push" != t.getOp() || 16384 & t.numArgs[0] ? "pop" == o && "pop" == t.getOp() && 32768 == t.numArgs[0] ? (e.update(e.text.replace("}", ", pc}")), t.update("")) : "push" == o && "pop" == t.getOp() && e.numArgs[0] == t.numArgs[0] ? (assert(e.numArgs[0] > 0), e.update(""), t.update("")) : "push" == o && "pop" == t.getOp() && 4 == e.words.length && 4 == t.words.length ? (assert("{" == e.words[1]), e.update("mov " + t.words[2] + ", " + e.words[2]), t.update("")) : n && "movs $r5, $i0" == e.getOpExt() && "mov $r0, $r1" == t.getOpExt() && e.numArgs[0] == t.numArgs[1] && clobbersReg(n, e.numArgs[0]) ? (e.update("movs r" + t.numArgs[0] + ", #" + e.numArgs[1]), t.update("")) : "pop" == o && singleReg(e) >= 0 && "push" == t.getOp() && singleReg(e) == singleReg(t) ? (e.update("ldr r" + singleReg(e) + ", [sp, #0]"), t.update("")) : "push" == o && "ldr $r5, [sp, $i1]" == t.getOpExt() && singleReg(e) == t.numArgs[0] && 0 == t.numArgs[1] ? t.update("") : n && "push" == o && singleReg(e) >= 0 && preservesReg(t, singleReg(e)) && "pop" == n.getOp() && singleReg(e) == singleReg(n) && (e.update(""), n.update("")) : (e.update(t.text.replace("{", "{lr, ")), t.update(""));
  }

  registerNo(e, t) {
    if (!e) return null;
    e = e.toLowerCase();
    var n = thumbRegs;
    "S" == t.name[1] && (n = fpRegs);
    var r = n[e];
    return void 0 === r ? null : r;
  }

  testAssembler() {
    expectError(this, "lsl r0, r0, #8"), expectError(this, "push {r17}"), expectError(this, "mov r0, r1 foo"), expectError(this, "movs r14, #100"), expectError(this, "push {r0"), expectError(this, "push lr,r0}"), expectError(this, "b #+11"), expectError(this, "b #+10240000"), expectError(this, "bne undefined_label"), expectError(this, ".foobar"), expect$1(this, "0200      lsls    r0, r0, #8\nb500      push    {lr}\n2064      movs    r0, #100        ; 0x64\nb401      push    {r0}\nbc08      pop     {r3}\nb501      push    {r0, lr}\nbd20      pop {r5, pc}\nbc01      pop {r0}\n4770      bx      lr\n0000      .balign 4\ne6c0      .word   -72000\nfffe\n"), expect$1(this, "4291      cmp     r1, r2\nd100      bne     l6\ne000      b       l8\n1840  l6: adds    r0, r0, r1\n4718  l8: bx      r3\n"), expect$1(this, "          @stackmark base\nb403      push    {r0, r1}\n          @stackmark locals\n9801      ldr     r0, [sp, locals@1]\nb401      push    {r0}\n9802      ldr     r0, [sp, locals@1]\nbc01      pop     {r0}\n          @stackempty locals\n9901      ldr     r1, [sp, locals@1]\n9102      str     r1, [sp, base@0]\n          @stackempty locals\nb002      add     sp, #8\n          @stackempty base\n"), expect$1(this, "b090      sub sp, #4*16\nb010      add sp, #4*16\n"), expect$1(this, '6261      .string "abc"\n0063      \n'), expect$1(this, '6261      .string "abcde"\n6463      \n0065      \n'), expect$1(this, "3042      adds r0, 0x42\n1c0d      adds r5, r1, #0\nd100      bne #0\n2800      cmp r0, #0\n6b28      ldr r0, [r5, #48]\n0200      lsls r0, r0, #8\n2063      movs r0, 0x63\n4240      negs r0, r0\n46c0      nop\nb500      push {lr}\nb401      push {r0}\nb402      push {r1}\nb404      push {r2}\nb408      push {r3}\nb520      push {r5, lr}\nbd00      pop {pc}\nbc01      pop {r0}\nbc02      pop {r1}\nbc04      pop {r2}\nbc08      pop {r3}\nbd20      pop {r5, pc}\n9003      str r0, [sp, #4*3]\n");
  }

}

function preservesReg(e, t) {
  return "movs $r5, $i0" == e.getOpExt() && e.numArgs[0] != t;
}

function clobbersReg(e, t) {
  return !!("pop" == e.getOp() && e.numArgs[0] & 1 << t);
}

function singleReg(e) {
  assert("push" == e.getOp() || "pop" == e.getOp());
  var t = 0,
      n = -1,
      r = e.numArgs[0];

  for (; r > 0;) {
    1 & r && (n = -1 == n ? t : -2), r >>= 1, t++;
  }

  return n >= 0 ? n : -1;
}

var epsF32 = 2e-5,
    epsF16 = .0045;

function mkProcessorFile() {
  var e = new File$1(new ThumbProcessor());
  return e.ei.testAssembler(), e.disablePeepHole = !0, e.lookupExternalLabel = e => null, e.normalizeExternalLabel = e => e, e.throwOnError = !0, e;
}

function throwAssemblerErrors(e) {
  if (e.errors.length > 0) throw new Error(e.errors[0].message);
}

function assemble(e) {
  var t = mkProcessorFile();
  t.emit(e), throwAssemblerErrors(t);
  var n = new Uint8Array(t.buf.length << 1);

  for (var _e1132 = 0; _e1132 < t.buf.length; ++_e1132) {
    n[_e1132 << 1] = 255 & t.buf[_e1132], n[1 + (_e1132 << 1)] = t.buf[_e1132] >> 8 & 255;
  }

  return {
    binary: n,
    procFile: t
  };
}

function randomTensor(e) {
  var t = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 1;
  var n = shapeElts(e = e.map(e => null == e ? 1 : e));
  return dist.tidy(() => dist.tensor(range(n).map(e => t * randomSFloat())).reshape(e));
}

function isNear(e, t, n) {
  var r = Math.abs(e - t);
  return r < n || r / (Math.abs(e) + Math.abs(t)) < n;
}

function optionsWithTestData(e, t) {
  t = flatClone(t);
  var n = 0,
      r = 0;

  var _loop59 = function _loop59() {
    var s = randomTensor(e.inputs[0].shape),
        o = e.predict(s).flatten().arraySync();
    var i = 0,
        l = 1;

    for (var _e1133 of o) {
      i += _e1133, l *= _e1133;
    }

    if (!(Math.abs(i - 1) < .1)) {
      a();
      return "break";
    }

    if (l > r && (r = l, a()), n++ > (t.includeTest ? 1e3 : 100) || r > .1) {
      l || a();
      return "break";
    }

    function a() {
      t.testInput = s.flatten().arraySync(), t.testOutput = o;
    }
  };

  for (;;) {
    var _ret4 = _loop59();

    if (_ret4 === "break") break;
  }

  return t;
}

function compileModel(e, t) {
  var n = compileModelCore(e, t),
      r = assemble(n.thumb);
  n.machineCode = r.binary;
  var a = 0;

  for (var _e1134 of n.stats.layers) {
    _e1134.codeBytes = r.procFile.lookupLabel("end_" + a) - r.procFile.lookupLabel("begin_" + a), a++;
  }

  var s = getStatsFromBin(n.machineCode, n.stats.total);
  return n.memInfo = s.info, n;
}

function validateCompilation(e) {
  var t = e.options,
      n = t.testOutput,
      r = e.execute(t.testInput);
  e.options.verbose && console.log("Test output", r);
  var a = 0;

  for (var _e1135 = 0; _e1135 < r.length && (isNear(n[_e1135], r[_e1135], t.float16weights ? epsF16 : epsF32) || (console.log("at ".concat(_e1135, " ").concat(n[_e1135], "[exp] - ").concat(r[_e1135], " = ").concat(n[_e1135] - r[_e1135])), a++, !(a > 5))); ++_e1135) {
    ;
  }

  if (a) throw new Error("mismatch");
}

function compileAndTest(e, t) {
  var n;

  try {
    return n = compileModel(e, t = optionsWithTestData(e, t)), validateCompilation(n), n;
  } catch (r) {
    throw t.info && console.log(t.info), n && t.verbose || (t.verbose = !0, n = compileModelCore(e, t)), console.log(n.js), console.log("Failing model: ", e.name), r;
  }
}

function readU32(e, t) {
  return (e[t] | e[t + 1] << 8 | e[t + 2] << 16 | e[t + 3] << 24) >>> 0;
}

function readU32s(e) {
  var t = [];

  for (var n = 0; n < e.length; n += 4) {
    t.push(readU32(e, n));
  }

  return t;
}

function getStatsFromBin(e, t) {
  var [n, r, a, s, o, i, l, u] = readU32s(e.slice(0, 64));
  if (809963362 != n) return null;
  var c = i || s,
      p = o - a,
      d = 100 * p / c,
      h = s - c;

  function m(e) {
    return (e / 1024).toFixed(2) + "k";
  }

  var f = "model: ".concat(m(c), "; code: ").concat(m(p), " (").concat(d.toFixed(1), "%); arena: ").concat(m(u), "; test ").concat(m(h));
  return t && (t.arenaBytes = u, t.codeBytes = p, t.weightBytes = c - p), {
    info: f,
    modelSize: c,
    codeSize: p,
    testSize: h,
    totalSize: s,
    arenaSize: u
  };
}

var compileAndTest_1 = compileAndTest,
    compileModel_1 = compileModel;
var _excluded = ["worker"];

function addLayer(e, t, n) {
  var r;
  var a = e.inputs[0].fields.expand_button.value;

  switch (e.type) {
    case "model_block_conv1d_layer":
      r = conv1d$2(t ? {
        inputShape: t,
        kernelSize: [a.kernelSize],
        strides: a.strideSize,
        filters: a.numFilters,
        activation: a.activation,
        padding: "same"
      } : {
        kernelSize: [a.kernelSize],
        strides: a.strideSize,
        filters: a.numFilters,
        activation: a.activation,
        padding: "same"
      });
      break;

    case "model_block_maxpool1d_layer":
      r = maxPooling1d$1(t ? {
        inputShape: t,
        poolSize: [a.poolSize],
        padding: "same"
      } : {
        poolSize: [a.poolSize],
        padding: "same"
      });
      break;

    case "model_block_avgpool1d_layer":
    case "model_block_avgpool2d_layer":
      break;

    case "model_block_conv2d_layer":
      r = conv2d$5(t ? {
        inputShape: t,
        kernelSize: [a.kernelSize, a.kernelSize],
        strides: a.strideSize,
        filters: a.numFilters,
        activation: a.activation,
        padding: "same"
      } : {
        kernelSize: [a.kernelSize, a.kernelSize],
        strides: a.strideSize,
        filters: a.numFilters,
        activation: a.activation,
        padding: "same"
      });
      break;

    case "model_block_maxpool2d_layer":
      r = maxPooling2d$1(t ? {
        inputShape: t,
        poolSize: [a.poolSize, a.poolSize],
        padding: "same"
      } : {
        poolSize: [a.poolSize, a.poolSize],
        padding: "same"
      });
      break;

    case "model_block_dropout_layer":
      r = dropout$3({
        rate: a.rate
      });
      break;

    case "model_block_flatten_layer":
      r = t ? flatten$4({
        inputShape: t
      }) : flatten$4();
      break;

    case "model_block_dense_layer":
      r = dense$1({
        units: n || a.numUnits,
        activation: n ? "softmax" : a.activation
      });
      break;

    default:
      console.error("Received an invalid layer type");
  }

  return r;
}

function buildDefaultModel(e, t, n) {
  e.add(conv2d$5({
    inputShape: t,
    kernelSize: [4, 4],
    strides: 1,
    filters: 16,
    padding: "same",
    activation: "relu"
  })), e.add(maxPooling2d$1({
    poolSize: [2, 2],
    padding: "same"
  })), e.add(dropout$3({
    rate: .1
  })), e.add(conv2d$5({
    kernelSize: [2, 2],
    strides: 1,
    filters: 16,
    padding: "same",
    activation: "relu"
  })), e.add(maxPooling2d$1({
    poolSize: [2, 2],
    padding: "same"
  })), e.add(dropout$3({
    rate: .1
  })), e.add(conv2d$5({
    kernelSize: [2, 2],
    strides: 1,
    filters: 16,
    padding: "same",
    activation: "relu"
  })), e.add(dropout$3({
    rate: .1
  })), e.add(flatten$4()), e.add(dense$1({
    units: n,
    activation: "softmax"
  }));
}

function buildModelFromJSON(e, t) {
  var n = sequential$1();
  var r;
  if ("default" == t) e.inputShape.push(1), buildDefaultModel(n, e.inputShape, e.outputShape), r = {
    loss: "categoricalCrossentropy",
    optimizer: "adam",
    metrics: ["acc"],
    epochs: 250
  };else {
    "2d" == e.convolutionType && e.inputShape.push(1);
    var s = t.inputs.filter(e => "LAYER_INPUTS" == e.name)[0].child;
    var o = addLayer(s, e.inputShape, null);
    var a;
    n.add(o), s && (null == (a = s.children) || a.forEach((t, r) => {
      o = addLayer(t, null, r == s.children.length - 1 ? e.outputShape : null), n.add(o);
    }));
    var i = t.inputs[1].fields.expand_button.value;
    r = {
      loss: i.lossFn,
      optimizer: i.optimizer,
      metrics: [i.metrics],
      epochs: i.numEpochs
    };
  }
  return {
    model: n,
    params: r
  };
}

var handlers = {
  compile: function () {
    var _compile = _asyncToGenerator(function* (e) {
      var {
        data: t
      } = e,
          {
        model: n,
        params: r
      } = buildModelFromJSON(t.model, t.modelBlockJSON);
      var a, s;
      yield n.save({
        save: e => {
          a = e;
          var t = {
            modelArtifactsInfo: {
              dateSaved: new Date(),
              modelTopologyType: "JSON"
            }
          };
          return Promise.resolve(t);
        }
      }), a.weightData = null;

      try {
        s = yield compileModel_1(n, {
          verbose: !1,
          float16weights: !0,
          optimize: !0
        });
      } catch (t) {
        return console.error("Error with getting model stats during compiling: ", t), _extends({}, e, {
          data: void 0
        });
      }

      var o = [...s.stats.layers, s.stats.total];
      return _extends({}, e, {
        data: {
          modelJSON: a,
          modelStats: o,
          trainingParams: r
        }
      });
    });

    function compile(_x140) {
      return _compile.apply(this, arguments);
    }

    return compile;
  }(),
  train: function () {
    var _train = _asyncToGenerator(function* (e) {
      var {
        data: t
      } = e;
      if (t.xData[0].length != t.model.inputShape[0] || t.xData[0][0].length != t.model.inputShape[1]) return console.error("Input data does not match expected shape of model."), _extends({}, e, {
        data: void 0
      });
      var n = t.model.modelJSON,
          r = yield loadLayersModel$1({
        load: () => Promise.resolve(n)
      });
      var a = tensor3d$1(t.xData, [t.xData.length, t.model.inputShape[0], t.model.inputShape[1]]);
      n.modelTopology.config.layers[0].class_name.indexOf("2D") > -1 && (a = a.expandDims(3));
      var s = oneHot$5(tensor1d$1(t.yData, "int32"), t.model.labels.length),
          o = t.trainingParams;

      try {
        r.compile({
          loss: o.loss,
          optimizer: o.optimizer,
          metrics: o.metrics
        });
      } catch (t) {
        return console.error("Error with model.compile during training: ", t), _extends({}, e, {
          data: void 0
        });
      }

      var i,
          l = [];

      try {
        yield r.fit(a, s, {
          epochs: o.epochs,
          validationSplit: t.xData.length > 40 ? .1 : 0,
          callbacks: {
            onEpochEnd
          }
        }).then(e => {
          l = e.history.acc;
        });
      } catch (t) {
        return console.error("Error with model.fit during training: ", t), _extends({}, e, {
          data: void 0
        });
      }

      yield r.save({
        save: e => {
          i = e;
          var t = {
            modelArtifactsInfo: {
              dateSaved: new Date(),
              modelTopologyType: "JSON"
            }
          };
          return Promise.resolve(t);
        }
      });
      var u = i.weightData;
      var c;
      i.weightData = null;

      try {
        c = yield compileAndTest_1(r, {
          verbose: !1,
          includeTest: !0,
          float16weights: !0,
          optimize: !0
        });
      } catch (e) {
        console.error("Error compiling arm model during training: ", e);
      }

      return _extends({}, e, {
        data: {
          modelWeights: u,
          trainingLogs: l,
          armModel: JSON.stringify(c)
        }
      });
    });

    function train(_x141) {
      return _train.apply(this, arguments);
    }

    return train;
  }(),
  predict: function () {
    var _predict = _asyncToGenerator(function* (e) {
      var {
        data: t
      } = e,
          n = t.model.modelJSON;
      n.weightData = new Uint32Array(t.model.weights).buffer;
      var r = yield loadLayersModel$1({
        load: () => Promise.resolve(n)
      });
      var a,
          s = tensor$1(t.zData);
      n.modelTopology.config.layers[0].class_name.indexOf("2D") > -1 && (s = s.expandDims(3));

      try {
        a = yield r.predict(s);
      } catch (t) {
        return console.error("Error with model.predict during prediction: ", t), _extends({}, e, {
          data: void 0
        });
      }

      var o = yield a.argMax(1).dataSync(),
          i = yield a.dataSync(),
          l = [],
          u = t.zData.length,
          c = t.model.labels.length;

      for (var _e1136 = 0; _e1136 < u; _e1136++) {
        var _n449 = {};

        for (var _r444 = 0; _r444 < c; _r444++) {
          _n449[t.model.labels[_e1136 * c + _r444]] = i[_e1136 * c + _r444];
        }

        l.push(_n449);
      }

      return _extends({}, e, {
        data: {
          predictAll: l,
          predictTop: o
        }
      });
    });

    function predict(_x142) {
      return _predict.apply(this, arguments);
    }

    return predict;
  }()
};

function dispatchAsyncMessages(_x143) {
  return _dispatchAsyncMessages.apply(this, arguments);
}

function _dispatchAsyncMessages() {
  _dispatchAsyncMessages = _asyncToGenerator(function* (e) {
    try {
      var t = handlers[e.type];
      return yield null == t ? void 0 : t(e);
    } catch (e) {
      return void console.error(e);
    }
  });
  return _dispatchAsyncMessages.apply(this, arguments);
}

function handleMessage(_x144) {
  return _handleMessage.apply(this, arguments);
}

function _handleMessage() {
  _handleMessage = _asyncToGenerator(function* (e) {
    var t = e.data,
        {
      worker: n
    } = t;
    if (_objectWithoutPropertiesLoose(t, _excluded), "tf" !== n) return;
    var r = yield dispatchAsyncMessages(t);
    self.postMessage(r);
  });
  return _handleMessage.apply(this, arguments);
}

function onEpochEnd(e, t) {
  self.postMessage({
    type: "progress",
    data: t
  });
}

self.addEventListener("message", handleMessage), console.debug("jacdac tf: worker registered");

/***/ })

}]);
//# sourceMappingURL=8e0cf18a-741567923b4a3aa35532.js.map